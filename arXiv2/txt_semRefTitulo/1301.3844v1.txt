

This paper describes a Bayesian method for
learning causal networks using samples that were
selected in a non-random manner from a
population of interest. Examples of data obtained
by non-random sampling include convenience
samples and case-control data in which a fixed
number of samples with and without some
condition is collected; such data are not
uncommon. The paper describes a method for
combining data under selection with prior beliefs
in order to derive a posterior probability for a
model of the causal processes that are generating
the data in the population of interest. The priors
include beliefs about the nature of the non-random
sampling procedure. Although exact application of
the method would be computationally intractable
for most realistic datasets, efficient special-case
and approximation methods are discussed. Finally,
the paper describes how to combine learning under
selection with previous methods for learning from
observational and experimental data that are
obtained on random samples of the population of
interest. The net result is a Bayesian methodology
that supports causal modeling and discovery from
a rich mixture of different types of data.
1 INTRODUCTION

Causal knowledge is central to science and to many other
areas of inquiry.
Experimental studies, such as
randomized controlled trials (RCTs), often provide the
most trustworthy methods we have for establishing causal
relationships from data. Such studies, while potentially
highly informative, may not be safe, ethical, logistically
feasible, or financially worthwhile. Observational data are
passively observed. Such data are more readily available
than experimental data, and indeed, most databases are
observational. Researchers have developed methods for
causal modeling and discovery from observational data that
are an unbiased sample from cases generated by a causal
process of interest (Cooper and Herskovits 1992; Spirtes,
et al. 1993; Heckerman, et al. 1995; Pearl 2000).

Not infrequently, however, observational data consists of a
biased sample of the cases generated by the causal process
of interest. The samples appear in a dataset due to some
selection criteria or effect. Such a sample1 is said to be
subject to
As one example, a robot can
only directly sample the terrain it can physically explore,
which may not be representative of the entire terrain of
interest. As another example, patients who come to an
emergency room may not be representative (in all
important ways) of patients in the entire population of
interest2. Indeed, selection bias has been demonstrated
empirically in several areas of medicine, as for example in
(Gerber, et al. 1982). Nonetheless, we would like to use
data collected in a given setting to induce causal
relationships for that setting as well as for the broader
population. This paper describes a method for modeling
causal relationships under selection. Such modeling can be
applied in performing causal discovery.

selection bias.

The concept of selection bias is well known (Sackett
1979). The idea of using a variable to represent selection
is described in (Wermuth, et al. 1994). In (Spirtes, et al.
1993, Section 9.3) researchers discuss causal modeling
from observational data when a population is sampled
according to some particular selection criteria (e.g., all
patients above a certain weight). Their approach
distinguishes among causal models by using tests of
conditional independence, rather than by using a Bayesian
approach. In (Cooper 1995), numerous conditions under
which causal structure and parameters can (and cannot) be
learned from conditional-independence tests are described,
when there is selection; a special-case Bayesian analysis of
causal modeling under selection also is proposed. A
general algorithm for causal discovery using conditional
independence tests is developed in (Spirtes, et al. 1995).
The unique contribution of the current paper is to describe
a general Bayesian method for causal modeling and
discovery under selection.

Throughout the paper we use as synonyms the nouns

sample and selection, the verbs sample and select, and the
terms sampled and selected.
2 In this paper, the term population of interest means a .set
of cases obtained by unbiased sampling from the cases
generated by a causal process of interest. We use the term
total population synonymously with population of interest.

99

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

2

BACKGROUND

causal network

A causal Bayesian network (or
for short) is
a Bayesian network in which each arc is interpreted as a
direct causal influence between a parent node (variable) and
a child node, relative to the other nodes in the network
(Pearl 1988). Figure 1 illustrates a hypothetical causal
network structure, which contains five nodes. The
probabilities (parameters) that are associated with this
causal network structure are not shown.
history of
smoking

.

-

lung cancer

�

"'(;;\ weight
\&J loss

fatigue �

Figure 1: A hypothetical causal Bayesian network
structure.
The causal network structure in Figure 1 indicates, for
example, that a
can causally influence
whether
is present, which in turn can causally
influence whether a patient experiences

history of smoking
lung cancer

fatigue.

The causal Markov condition gives the conditional
independence relationships that are specified by a causal
network:

A node is independent of its non-descendants (i.e.,
non-effects) given its parents (i.e., its direct causes).
The causal Markov condition permits the joint
distribution of the variables in a causal network to be
factored as follows (Pearl 1988):

n

n

I K) =

IJ P(x;

I lr; , K) ,

i=l

where X; denotes a state of variable X;, n; denotes a joint
state of the parents of Xi, and K denotes background
knowledge.
3

A BAYESIAN ANALYSIS

Researchers previously have described Bayesian approaches
for deriving the posterior probability
I
K) of
causal network structure
given data
subject to
background knowledge K. Doing so requires (1) that a
prior
I K) on each possible causal network structure
can be assigned, and (2) that a
I
K) of the data given the model structure can be
derived (Cooper and Herskovits 1992, Heckerman, et al.
1995). In the current paper, we focus on deriving
K) when
contains data obtained under
I
selection. While we concentrate on discrete variables and

M,

P(M
P(D M,
P(D M,

P(M D,
D,

marginal likelihood

D

M

D

case
M.

A
/®�

P(x1 ,x2 ,...,xn

Due to space limitations, in this paper we do not describe
how to learn the parameters (i.e., the probabilities) on
given and K. However, given what is described here, in
combination with previous literature on parameter
learning in causal networks (Cooper and Herskovits 1992,
Heckerman, et al. 1995), the task is conceptually
straightforward.
3.1 THE BASIC MODEL

@
bronchitiS
�
chroni�

summation, the generalization of the concepts to
continuous variables and integration will be obvious.

A
denotes a set of values, one value for each variable
in
A case can be either measured (all values known),
unmeasured (no values known), or partially measured
(some values known). In this paper, we assume there is an
underlying causal process that is generating cases that
constitute the population of interest. We use C to denote
all the cases in the population of interest, regardless of
whether those cases are measured, unmeasured, partially
measured, or some combination thereof.

Assumption
M

1. The cases C were generated by random
sampling from the distribution of a causal network B with
structure and parameters (}M·
We will use Cr to denote the sampled cases and CF to
denote the unsampled cases. Set C is the union of Cr and
C F· Although by Assumption 1 we assume that C was
generated by random sampling from the distribution
defined by B, in general this does not imply that each of
C T and C F are themselves random samples from the
distribution defined by B. In general, they will not be.

Assumption

2. Case selection is a causal event that can be
modeled within a causal network that has a variable
representing whether a case was selected.
To represent selection, we introduce a variable called S
into model
that has states T and F, which designate
whether a given case was sampled (7) or not (F) (Cooper
1995). Let the term
designate all the
variables in
including S. Let the term
denote all the variables i n
excluding S. We
will use to denote the number of domain variables in
In each case in C r, variable
has the value T,
representing that the case was sampled. In each case in
CF, variable has the value F, denoting that it was not
sampled. Thus, S never has a missing value, because we
know that a case either was or was not sampled.

M

M,

variables
n

model variables
M,
S

domain
M.

S

Example: Part 1.
Table 1 shows an example dataset containing the five
domain variables from Figure 1 and seven total cases that
constitute the population of interest. The values of S also
are included. For this example, we might suppose (quite
hypothetically) that there is a town with a total
population of seven people, and that population count is
known to us. Each of these people is a separate case.
Three people in town have visited a
It is the
presence of fatigue that has caused these patient cases to

fatigue clinic.

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

100

S

appear as samples in the clinic's database. In Table 1,
has the value T for all three selected cases and the value F
for the four unselected cases. Also, variable X4, which
represents
has the value T in all selected cases; in
principle, however, X4 might have had the value F in
some of the selected cases, because it is possible that the
clinic would see a few people without fatigue. Most of the
unselected cases do not have fatigue, but note that one
does; in general, we do not expect that all cases in the
population that are prone to being sampled will in fact be
sampled.

history of

fatigue,

smoking

A�
��

@
bronrhitis
�
chronic

�

fatigue

Table 1: An example set of cases.
selected
cases
T
T
F
T
F
F
F
F
T

XI
Xz
x3
x4
Xs

T
T
T

s

T
F
T

T

T

F

F

T
T

T

T

F

mr

unselected
cases
F
T
T
F
F
F
F
F
F
F
F
F

T

S.

mr,

mF,

M.

mF.

mr

T m

mF,

P(S

P(S

mr, mF,

=

mr
mr, mF,

=

Continuing the example, Figure 2 shows a possible
causal network structure to be evaluated using the known
data in Table 1 and our prior beliefs.

S

As a prior for given its parents, we might, for example,
use a Dirichlet distribution for which
T I X4 T,
3,
4, K) 0.9,
T I X4 F,
3,
4, K)
0.01, and the equivalent prior sample size is
assumed to be 1 (Heckerman, et al. 1995).
=

mF

=

=

mT

m

=

P(S

P(S

=

=

Let Dr denote the data that are known about the cases in
Since for now we are assuming no missing values or
latent variables, Dr contains a value for each variable in
each case in
Let DF denote data that are known for the
cases in
Since these cases were not sampled, the only
variable for which we know its value is
which has the
value F for each case in
Let D denote the union of the
known values in D and D F• which are all the data
available to us.

CT.

CF.

CT.

T

S,

CF.

Example: Part 3
We want to investigate the causal relationships among the
five variables in the total population of seven cases. Table
2 shows the values that we know (as T and F) and the
values we do not know (as question marks). Set D
consists of the values that are known. Notice that for the
unselected cases, the sole variable for which we know a
value is variable
because we know these four cases
were indeed unselected.

S,

=

Example: Part 2

=

mp

D

S:

mT

v

Figure 2: A modified version of Figure 1, which
shows the explicit representation of selection
using variable
Variables
and F a r e
explained in the text.

F

S

=

\..

weight
loss

selection

The. parents of
include the domain variables (e.g.,
fatigue) that are modeled as causally influencing whether a
case is sampled. Let ns denote those variables. For the
moment, we will assume that these variables are all
measured, but later in this section we generalize to allow
latent variables as well. We will include two additional
variables as parents of
variable
which denotes the
number of sampled cases, and variable
which denotes
the number of unsampled cases. These two variables will
be considered part of model
For now, we assume their
values are known and are part of background knowledge K.
The total number of cases in the population is then mr +
The reason for having
and mF as parents of S is
that the probability that a case is selected from the total
population will in general depend on the size of that
population (m + F) and the size of the sampled set
For a given state of the domain parents ns, as
increases relative to
typically
Tins,
K) will increase, although in general the rate of increase
will be sensitive to the value of ns. In the limit of
+
1,
Tins,
K) 1 for each
state of ns.

mrf(mr mF)

Xi

�

T
F
F
F

D

(mr).

lung cancer

=

=

mT

=

mF

Table 2: Data that are known when deriving the
marginal likelihood.

XI
Xz
x3
x4
Xs
s

selected
cases
F
T
T
T
F
F
T
F
F

T
T
T

T

T

F

F

T

T

?
?
?
?
?
F

unselected
cases
?
?
?
?
?
?
?
?
?
?
F
F

?
?
?
?
?
F
D

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

D,

As stated above, on the path to deriving P(M I
K), we
derive
I M, K). To do so, we will sum over the
missing values of all the domain variables in all the cases
in
we use
to denote the set over which we sum.
The marginal likelihood of interest is therefore expressed
as follows:

P(D

C F;

P(D I

HF

M,K)=

LP(D,Hp I

M,K).

(1)

HF

In the example, since there are 4 x 5
20 unknown
variable values in the population of seven cases, Equation
2
I will sum over the 2 0 states of
=

HF.

The appeal of Equation 1 is that it expresses the marginal
likelihood
I M, K) on sampled cases in terms of a
sum of marginal likelihoods on the total population of
cases. This is useful because researchers previously have
developed methods for deriving the marginal likelihood on
the total population of cases, which is not subject to
selection (Cooper and Herskovits 1992, Geiger and
Heckerman 1994, Heckerman, et al. 1995).

P(D

In general, the size of the population will not be known
with certainty, and thus,
will be a random variable.
Accordingly, we modify Equation I to sum over the
possible values of
as shown in Equation 2. In deriving
I M, K), for fixed
the parameter
is a constant,
and thus for notational simplicity we will assume that
is part of background knowledge K.

mF

P(D

mF

DT

mT

P(D I M,K)=
LLP(D,Hp I M,mp,K)P(mp I

mT

101

and consider the modified network to be B', the generating
network. In B', X2 and X3 are marginally independent. If
we condition on S in B ', then in general X2 and X3 will
be dependent, because they are d-connected (Pearl 1988).
The selected population involves conditioning on S T.
Thus, in the selected population, X2 and X3 will likely be
dependent, although they have no causal relationship
between them
To estimate
causal relationships for the selected population, we first
need to estimate those relationships for the total
population, then use that model to estimate the
relationships for the selected population by setting S T.
=

even in the selected population.

=

3.2 EXTENSIONS TO THE BASIC MODEL

As a generalization, suppose some modeled variables are
latent, and thus, they have no measurements, even in the
selected cases. In the example, if Xi were a latent variable,
then the first row of Table 2 would contain all question
marks. To derive the marginal likelihood of data
we
can modify Equation 2 to include an additional inner sum
that sums over the values of the latent variables for the
cases in

D,

CT.

As another extension, consider multiple forms of case
selection. If sets of cases were selected based on different
criteria, then we simply need to create values for S that
designate which selection criterion was used for each set of
cases. Equation 2 will remain applicable. The following
example illustrates the basic idea.

Example: Part 4
M,K).

(2)

mFHF

Suppose that in the town of seven people there is also a

smoking clinic, consisting of two people who are seeking
help to stop smoking. Let S
sc denote selection for
these two cases. As before, let S
fc designate selection
for patients seen at the fatigue clinic. Finally, let S
us
=

mF

Often, belief about
might be independent of causal
network structure M, and thus, the last term in Equation 2
would simplify to be
I K).

P(mF

We close this section with two relatively subtle, but
important points. Set
does not need to contain the
entire population of interest (e.g., the entire county), but
only an unbiased subset that includes the sampled cases
(e.g., the town). Thus, if the town population is a random
sample of the county population, defining as the town
population is sufficient for deriving an unbiased marginal
likelihood using Equation 2. Clearly less computation
will be required when the number of unselected cases is
fewer. The key condition is that be an unbiased sample
from the distribution defined by the generating causal
network of interest.

C

=

=

represent the absence of selection for those people in the
town who were not sampled. The modified dataset is
3
shown in Table 3.
Table 3: Data on three subpopulations, two of
which were sampled.

C

xi
x2
x3
x4
Xs
s

C

It may seem that if we are content to learn only about
causal relationships for the sampled population, then we
need not be concerned with modeling the unsampled
population. Unfortunately, this is not so. The reason is
that all causal network learning (of which we are aware)
assumes a random sample from the joint distribution
defined by B. The selected cases for which we have data are
not a random sample. The following simple example
illustrates the problem. Remove node Xi from Figure 2,

fatigue
clinic
cases
T
F
T
F
F
T
T
T
T
F

(c

(c

smoking
clinic
cases
T
T
F
F
T
F
T
F
T
F

T
F
F
T
F

(c

sc

sc

unsampled
cases
?
?
?
?
?

us

?
?
?
?
?

us

3

For simplicity, in the example we assume that no one
goes to both the fatigue clinic and the smoking clinic. To

handle such a situation, we can create an additional
selection value, namely S
fc_and_sc, to represent those
cases that appear in both the subpopulations.
==

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

102

Figure 3 modifies Figure 2 to include the new influence of
the smoking variable on selection. The prior distribution
of S given its parents also would be specified, but for
brevity is not shown here.
history of
smoking

chronic
bronchitis

r&)

�

�

lung cancer

..,lght

�
@
loss
I
msc
mfc � ' .----- mus
---. 0
fatigue

Figure 3: An extension of Figure 2 that models
selection of two subpopulations.

HF in the equation with
D

So far, we have only discussed examples in which S is a
child of one or more domain variables. However, S could
also be a parent of some domain variables, if the selection
event can causally influence the domain variables. For
example, consider that the selected population consists
just of people who visit the smoking clinic. Some of
them may feel less fatigued than similar people in the
entire population, because psychologically these smokers
feel good about making an effort to improve their health
by going to the smoking clinic. Thus, there would be an
arc from
to S and an arc from S to

fatigue.4
4

history of smoking

APPLICATIONS OF THE MODEL

In this section, we briefly describe how we can apply the
method in Section 3 for causal modeling under selection
when using a convenience sample and when using case­
control data.

convenience sample

A
is a dataset that is collected because
it is available, not necessarily because it is representative
of the population of interest. Case-series reports in
medicine are one type of convenience sample. The fatigue­
clinic example in Section 3 involves a convenience

4

To handle the situation in which selection is also based

on fatigue, we would need to add a temporal dimension to
the model, in order to avoid directed cycles. We do not
pursue that detail here, but only note that in modeling more
complex, real-world events, temporal modeling will often

come into play (see Section 6).

In case-control studies, which are common in medical
research, an investigator identifies
people with a given
condition (the cases) and
people without the condition
(the controls). Often the condition is a disease, and the
task is to discover the factors that causally contribute to
having the disease. To model case-control studies, we can
apply the method in Section 3 that involves using three
values for S, namely the values
and
Let
be the number of unsampled
cases. The parents of S are the domain variables that the
investigator used as criteria to select the
cases and the
controls; the variables
and
are parents of S
as well.

m1

m2

selection

To apply Equation 2, we replace

sample. As another example, consider a survey that is
distributed to a random sample of the population of
interest. The people who complete and return the survey
are a convenience sample. Arguably, most observational
databases are convenience samples, at least to some
extent. That is, few observational databases appear to
represent a truly random sample of the entire population
of cases that were generated by the causal process of
interest. We can model with a convenience sample by
using values T (selected) and F (unselected) for variable S,
as in Section 3. For some modeling tasks, we may know
the domain variables that influence selection. Thus, we
need not search over models that contain different parents
of S. In other situations, such search may be required;
doing so would indicate the most likely causes of
selection.

unsampled (us).
m2

5

case, control,

m3

mt. m2 ,

m3

m1

COMPUTATIONAL ISSUES

In this section, we prove two complexity results. We then
discuss some special-case and approximation methods.

Theorem

1

Deriving

NP-hard.

P(D I M, K)

under selection is

Proof In (Cooper 1990), 3-SAT is reduced to causal
network inference by using a network structure that
includes a single node that has parents but no children. Let
S be that node. In the reduction, the inference task required
to solve the 3-SAT problem is to derive
= F) By
assuming an empty set of selected cases (i.e.,
0) and
a single unselected case (i.e.,
= 1), Equation 1 derives
= F) for any model M, based on that model's prior
probabilities. Thus, Equation 1 solves the 3-SAT
problem.

mF

P(S

P(S
mT

.

=

D

Theorem 2
Finding the network structure M that
maximizes
M, K) under selection is NP-hard.
Proof In the absence of selection, (Chickering 1996)
showed that finding a network structure M that maximizes
M, K) is NP-hard. For the same problem under
selection, assume a structure prior in which there is zero
probability that S has any domain variables in M as
parents. Then Chickering's problem reduces to (indeed is
equivalent to) finding the network structure M that
maximizes
M, K) under selection.

P(D I

P(D I

P(D I

D

103

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

A proof parallel to the one in Theorem 2 can be used to
reduce Bayesian network inference in the absence of
selection (Cooper 1990) to Bayesian network inference
under selection. Thus, for a given structure and database
inference under selection also is NP-hard.

M

D,

We now consider a method that can improve the efficiency
of solving Equation 1. Let denote the set consisting of
variable S and the ancestors of S. Let A denote the nodes

A

M that are not in A. Let MA designate the subgraph of
M on just the nodes A. Likewise, let MA designate the
subgraph of M on just the nodes in A. For the cases in
Cp, let H� represent the state of the variables in A that
have missing values, and let H� represent the state of the
in

et al. 1995)5. For example, the class of models that use
multinomial distributions with Dirichlet priors satisfy
these conditions (Heckerman, et al. 1995). Using such a
class, suppose S and its ancestors form a tree, that is, each
internal node has one parent. We can apply Bayes rule to
the prior parameters on B in order to reverse all arcs away
from S (Shachter 1989), yielding a tree with the same
connectivity, but no arcs into S. All trees with the same
connectivity are Markov equivalent. We are assuming a
model class in which Markov equivalence implies
likelihood equivalence. By likelihood equivalence, the
marginal likelihood for the transformed causal network
will be the same as that of the original network. Figure 4a
shows an example, where the cloud denotes an arbitrary
causal subnetwork. In that figure, and its three ancestors
form a tree.6

S

variables in A that have missing values. With this
notation, we can rewrite Equation 1 as follows:

P(D I M,K)=
LP(D,HF I M,K)
Hp

= L LP(D,H�,H� I M,K)
HFAHF
A"

Figure 4a: The original network.

= L[LP(H� I H�,D, M,K)]P(D,H�IM,K)

(3)

A
A HF
HF

Since for the cases in Cp we have by construction that A
contains no nodes with fixed states, then the sum over the
probabilities of the states of

Hj

is equal to 1. Thus the

inner sum of Equation 3 (shown in square brackets) is 1
for any state of

H� in the outer sum. Therefore, Equation

3 simplifies to be:

P(D I M,K)= L P(D,H�IM,K).

S

By reversing the arcs in that tree away from we create
the network in Figure 4b that is Markov equivalent to the
network in Figure 4a. Given the likelihood-equivalence
assumption, the model in 4b will have the same marginal
likelihood as the model in 4a for any dataset. Therefore,
applying the line of reasoning above for when
is a root
node, we can use the network in Figure 4b to solve for
K) directly, without summation. We emphasize
that this mathematical transformation does not change the
semantics of the original network (Figure 4a) being
scored, but rather, it merely scores that network
efficiently.

S

P(D I M,

(4)

Hj

Thus, to derive the marginal likelihood, for the unselected
cases we need only sum over the states of the nodes that
are ancestors of S. If S were a root node in
the sum in
Equation 4 vanishes, and we simply compute
K)
directly, without any need to model the unselected cases.
Rarely will S be a root note in
however, because case
selection is typically modeled as having a cause, and thus,
S will have parents.

M,
P(D I M,

M,

S

Nevertheless, we could transform M so that is a root
node. Suppose we are using a class of causal network
models for which Markov equivalence (aka independence
equivalence) implies likelihood equivalence (Heckerman,

5 Two Bayesian network structures

M1

and

M2

are Markov

equivalent

iff they contain the same set of nodes and they
represent the same conditional independence relationships
among those nodes. M 1 and M 2 are likelihood equivalent
iff they contain the same set of nodes and for every
possible dataset D it holds that P(D I M1)
P(D I Mz).
=

6 If m F and m T are added as parents of S, we will no longer
have a tree. If m F and m T are constants, however, we can
X3 as the only parent of S. Indeed, m T is already

represent

assumed to be a constant, relative to a given D T· In
computing P(D,

Hp I M, mp, K)

in Equation 2, we solve for

the marginal likelihood with m F set to a fixed value. Thus,
in reversing arcs away from S, mp and mrdo not need to be
represented as parents of S.

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

104

6

LEARNING FROM A MIXTURE
OF TYPES OF DATA

In this section, we describe how to model causal
relationships when there are observational and
experimental data, some of which are sampled under
selection and some of which are sampled randomly from
the population of interest.

Cob

Figure 4b: The transformed network.
If S and its ancestors do not form a tree, heuristically we
could reverse arcs (Shachter 1989) away from S anyway,
thereby creating a network in which S is a root node. We
then can derive
K) without summation. There
are, however, at least two problems with this approach.
First, based on the line of reasoning in the proof of
Theorem 1, it follows that the reversal task is NP-hard,
and thus, quite likely intractable in the worst cases.
Second, for non-tree-structured ancestors of S, the arc­
reversal method will generate a Bayesian network that
contains more parameters than the original network.
Therefore, in general the marginal likelihood of the
reversed network structure will not equal the marginal
likelihood of the original network structure.

P(D I M,

ob

We will represent manipulation of a variable X by a
variable Qx, which has the same values as X, plus the
value
that indicates a non-experimental case that is
simply observed (see (Cooper and Yoo 1999) for details).
Qx represents the value to which the experimenter intended
to manipulate X. Ideally, Qx has no parents (and thus, its
value is randomly set) and it deterministically controls X.
That ideal may not be realized. As an example of
imperfect control, a patient might initially agree to be in a
study and to take a medication, but later refuse to take it
reliably. If a case is not part of an experiment to
manipulate X, then as stated, Qx
. By introducing Qx
variables, we transform learning with a mixture of
experimental data and observational data into learning with
observational data alone, since Q x is just another
observation (Cooper and Yoo 1999).

ne

=

M1

Figure 5 shows an example, where
is the original
network structure, and
is the network structure after
arc reversal. If the variables are binary and the
probabilities (parameters) are represented using binomial
distributions, then the joint probability distribution on
is defined by 8 parameters, whereas the distribution on
is defined by 10 parameters.

M2

mob

Let
be a set of
cases that are randomly selected
from the population of interest. In the general case, the
event of random selection may itself causally influence
some of the domain variables. We can create a value
for S that indicates an observational case that was
randomly selected.

M1
M2

ne

In general, whether an experimental case appears in

dataset

D may depend on the outcome of the experiment for that

case. For example, patients who become ill from side­
effects of a medication may leave the study unannounced.
Thus, a model might contain an arc from a
variable to the variable S. We can create a value
for S which indicates that data for the case (including
outcomes) is recorded in the experiment's dataset.

drug side
ex

effects

Example
Mode/M1

Mode/M2

Figure 5: Original model M1 and reversed model
M2, which contains arcs reversed away from S.
As a heuristic patch, we might approximate the marginal
likelihood by using a measure like the BIC score (Geiger,
et al. 1996) that contains a likelihood term that represents
how well the model predicts the data and another term that
represents the number of model parameters. The reversed
model could be used to derive the likelihood term (e.g.,
whereas the parameter count would equal the number
of parameters in the original model (e.g.,
It is an
open problem to characterize and investigate how closely
this heuristic score will approximate the correct marginal
likelihood under different conditions.

M2),

M1).

Figure 6 shows a causal network structure, which has a
few changes from the network structures shown in Section
3. As in that section, this model represents a
about the underlying causal processes; it is not necessarily
the generating network B. In Figure 6, variable X
is modeled as being experimentally
manipulated in some cases. X4
is modeled as the
sole domain variable directly influencing case selection.

hypothesis
2

(current smoker)

(fatigue)

Table 4 contains a dataset used in deriving the marginal
likelihood for the causal network in Figure 6 (as well as
used in deriving the marginal likelihood of other possible
causal network hypotheses that we wish to consider).
Three of .the cases in Table 4 are observational cases
obtained under selection (S
two cases involve an
experimental manipulation (S
two are observational
cases that were randomly sampled (S
), and two cases
=

fc),
ex),

=

=

ob

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

us).7
X1

remain unsampled (S
Of course, a real dataset
typically would have many more cases of each type. In
this example, variables
and X3 are latent. Variable
was experimentally manipulated in two
cases.
=

(current smoker)

X2

past history

�

current
'mokr

T means that the study participant was encouraged

not to smoke, regardless of whether or not the participant
had a history of smoking.
F means that the

Qx 2

=

experimenter made no attempt (one way or the other) to
influence the participant's smoking behavior; thus, this
experiment is only partially controlled.
means

Qx2

randomly, as represented in Figure 6 by

=

ne

Qx2
Qx2 having no

parents.

D

'"'ur

"

fatigue

m
ob

=

that the case was not part of the experiment. In the two
cases that are in the experiment, the value of
was set

of smoking

�
®
� / \..
s;i) hmg
/ "-..
�
�

Qx2

105

By using temporal causal networks (Dean and Kanazawa
1988) we can represent more complex types of data
mixtures in which selection and experimentation occur
over time. For example, at time
a set of cases is
selected according to some criteria (e.g., patients who
arrive at a medical clinic during a given period). We
represent this initial selection process as S to

w'Jght
Joss

t0

•

+ . �m�-- mus
rcm �----

=

selection

Figure 6: A causal network structure for modeling with
observational and experimental data, some of which is
sampled under selection and some of which is sampled
randomly from the population of interest.

medical_clinic. All those patients are asked to participate
in an experimental study, and at time t1 a subset agree to
participate (St1 agree_to__participate). At time t2 the
=

experiment is performed by randomly assigning subjects
to either the experimental or the control treatment. At
time t3 a subset of the original subjects have remained in
the study (St3
and their outcomes
=

Table 4: Example of a mixture of cases that
could be used fior causaI Ieammg.
.
fatigue
clinic
cases

Qxz
x,
Xz
x3
x4
Xs
s

smoking
experimental
cases

randomly
sampled
observationa!
cases

unsampled
cases

7

ne

ne

ne

T

F

ne

ne

ne

ne

?

?

?

?

?

?

?

?

?

F

T

F

T

F

T

F

?

?

?

?

?

?

?

?

?

?

?

T

T

T

T

F

F

F

?

?

T

F

F

T

F

F

F

?

?

fc

fc

fc

ex

ex

ob

ob

us us

7
To keep the example simple, we assume that the
experimental cases (S
ex) are mutually exclusive of the
observational cases obtained by random selection (S
ob).
We further assume that those experimental and
observational cases were randomly sampled from the total
population of nine cases. Taking a random sample of cases
might of course select some patients who also attended the
fatigue clinic. Therefore, in Table 4 the value S
fc
denotes the fatigue-clinic patients who were not randomly
sampled. For the experiment, the two randomly selected
individuals are assumed to agree to participate in the study;
once enrolled, the value of
is assigned randomly for
=

=

=

each of these participants.

Q x2

remained_in_study)

are measured and recorded. It is not uncommon in
medicine for data to have a history as complex (or more
complex) as the one in this example. The methods in this
paper provide a basis for modeling both simple and
complex forms of selection.
SUMMARY AND FUTURE WORK

This paper focuses on how to model causal processes
using data that are obtained under selection. By developing
a general model, it hopefully provides a useful foundation
for further investigation. Key issues yet to be explored
include the conditions under which causal network
structure can be identified from data obtained under
selection (possibly in combination with other types of
data). Also, to attain computational tractability, it will be
important to explore and characterize (both theoretically
and empirically) approximations to the exact method
described here. The usefulness of the model and its
implementation will of course ultimately rest on how
well they help us perform causal modeling and discovery
with real data.
Acknowledgments

The research reported here was supported by NSF grant
IIS-9812021 and by NLM grant R01-LM06696. I thank
Clark Glymour, Mehmet Kayaalp, Subramani Mani,
Stefano Monti, Peter Spirtes, Changwon Yoo, and the
UAI-2000 reviewers for helpful comments on earlier drafts
of this paper. I also thank Constantin Aliferis for helpful
discussions about causal modeling with temporal data
obtained under selection.

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

106

