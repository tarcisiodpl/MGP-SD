

A key issue in the handling of temporal
data is the treatment of persistence; in most
approaches it consists in inferring defeasi­
ble conlusions by extrapolating from the ac­
tual knowledge of the history of the world;
we propose here a gradual modelling of per­
sistence, following the idea that persistence
is decreasing (the further we are from the
last time point where a fluent is known to
be true, the less certainly true the fluent
is); it is based on possibility theory, which
has strong relations with other well-known
ordering-based approaches to nonmonotonic
reasoning. We compare our approach with
Dean and Kanazawa's probabilistic projec­
tion. We give a formal modelling of the
decreasing persistence problem. Lastly, we
show how to infer nonmonotonic conclusions
using the principle of decreasing persistence.
1

Introduction

The use of persistence in order to draw nonmonotonic
conclusions has been widely studied. Most approaches
select models having the minimal set of changing flu­
ents. Thus, in these approaches, a propositional fluent
f true at a given time point will tend to remain true
indefinitely, provided that no other proposition being
contradictory with f is observed at a later time point;
this is an extremely adventurous choice, and it may be
often unrealistic, because some fluents have only a lim­
ited tendency to persist (for instance, given that it is
raining at t0, it is not reasonable to infer that it is still
certainly raining one week later). Let us now consider
a second typical case, where a fluent f is known to be
true at time to and known to be false at a later time
point it, nothing being known inbetween (for instance,
it is raining at 10 am, and it is not raining at 6 pm).
In this figure, there must be a time point h in (t0, h)
*Much of this work

was done

iting Linkoping University

while this author was vis­

Jerome Lang

*

IRIT
Universite Paul Sabatier
F-31062 Toulouse Cedex
France
email: lang@irit.fr
when f changes its truth value from true to false (this
is known as the clipping problem). Chronological min­
imization (Shoham 88) and similar approaches prefer
models where fluents change at the latest possible time
point; this has been argued as being often unreason­
able (see (Sandewall 92) for a discussion) and several
other approaches have been proposed which reject the
latter principle, and, cautiously, do not conclude any­
thing about f within (t0, tt). For instance, the logic
for time of action proposed in (Sandewall 92) will con­
clude that the truth value of f is occluded during
(t0, t1). Borillo & Gaume's (90) three-valued extension
of Kowalski & Sergot's event calculus will also give a
cautious result. We argue that these cautious results
assuming complete ignorance within the whole inter­
val are not always realistic, since we are not always
completely ignorant of what happens at time points
being very close to one of the bounds of the interval
(thus, in our example it is rather sure it is still raining
at 10.05 am and rather sure it is not raining at 5.55
pm). The transition model given in (Cordier & Siegel
92) enables to specify explicitely whether fluents tend
to persist or not depending on some applications con­
ditions, and has thus a rich expression power, but how­
ever it cannot express that persistence may decrease
gradually.
The reason why all these approaches cannot model de­
creasing persistence is clearly their lack of graduality;
consider again the first raining example (forward pro­
jection); one is likely to believe that rains is almost
certainly true a short time after 10.00, and not to be­
lieve anything at all after a very long time (say, one
week later); note that in this latter case -,f should not
be believed either; we are too far from a time-point
when the truth value off is known for assuming any­
thing: we are thus in a state of complete ignorance
about the truth value of f. Between these two ex­
treme states of knowledge, there is a lot of intermedi­
ary states, since the further from 10.00, the less cer­
tain we are that it is still raining: as time goes on, the
amount of ignorance increases. This principle will be
called increasing ignorance about persistence, or,
for the sake of brevity, decreasing persistence, al­
though we prefer the former formulation: indeed, what

470

Driankov and Lang

is gradually decreasing is not persistence of truth but
persistence of our belief about truth; see (Asher 93) for
a study of persistence of truth vs. persistence of be­
lief. This graduality in persistence can be expressed in
a qualitative way using ordering relations or in a more
quantitative way using numerical measures of uncer­
tainty.

and also with bounded projection (see Section 3).
After recalling the bases of possibility theory and its
use in nonmonotonic reasoning, we will give a formal
presentation of our approach, and lastly we will show
how to use decreasing persistence in order to infer non­
monotonic conclusions.

To our knowledge, there has been essentially one ap­
proach to modelling persistence in a gradual way,
namely Dean and Kanazawa's probabilistic projection
(Dean & Kanazawa 89a,b) (see also (Haddawy 90) for
a temporal probability logic for reasoning about ac­
tions). They distinguish between 2 kinds of proposi­
tions, namely facts (or fluents) and events; a fact is a
proposition which, once true, tends to persist, i.e. to
remain true for some time without additional effort;
events are instantaneous, and they do not persist, but
they tend to change the truth value of some fluents.
Note that all facts have a starting point and an ending
point (possibly infinite); if a fluent is true, becomes
false and then becomes true again, it must be consid­
ered as two different instances ("tokens") of the same
fact. Dean and Kanazawa propose an elaborate prob­
abilistic model for persistence, taking account for each
fact of its natural tendency to persist, represented by a
survivor function S(8) = p(holds(f, t)iholds(f, t- 8))
(probability that f survives at least for 8 time units),
and of the probabilities of events changing the truth
value of the fluent. Thus probabilistic prediction
comes down to computing the probability of f being
still true at t, or equivalently, the density function of
the clipping point of f, i.e. the time point when it
becomes false.

2

However, probabilistic prediction is not well-suited to
dealing with fluents which may change their value sev­
eral times; besides, a probabilistic modelling of persis­
tence does not express that we become more and more
ignorant about the truth value of a formula when time
goes on. Let us consider the following example, where
we know that it is raining at time t0 (and that we
do not know anything about what will happen after­
wards). Dean and Kanazawa's approach will conclude
that the probability of "raining" at t0 + f is close to
1 iff is close to 0, which is intended; however, it will
also conclude that if we are very far from t0, raining
is false, which is of course not intended. A first idea
for treating this case correctly would be to model per­
sistence with an asymptotic probability (which is ac­
tually the probability a priori that it is raining, inde­
pendently from earlier and later observations); but it
still does not express increasing ignorance, since prob­
ability theory is well-suited to modelling chance, but
can not deal correctly with ignorance (see (Dubois &
Prade.88)); possibility theory (Zadeh 78) is much more
adapted to the representation of states of partial or
complete ignorance.
A last point is that Dean and Kanazawa's probabilistic
projection is only done forwards; our possibilistic ap­
proach also deals with backwards projection problems,

Background on possibilistic logic

Let L be a classical propositional language (where T
and .1. denote tautology and contradiction, respec­
tively) and n be the classical set of interpretations
associated with L. A possibility distribution is a map­
ping 1r from n to [0, 1]. 1r is said to be normalized iff
3w E 0 such that 1r(w) = 1. By convention, 1r rep­
resents some background knowledge about where the
real world is; in particular, 1r( w) = 0 means that w
1 that nothing prevents
is not possible, and 1r(w )
w from being the real world.
When 1r(w ) > 1r(w'),
w is a preferred candidate to w' for being the real
world. A possibility distribution leads to evaluate in­
duces two mappings on L, namely a possibility mea­
sure II(tp) = Supwl=cp1r(w ) which evaluates the extent
to which tp is consistent with the available knowledge
expressed by 1r, and a necessity (or certainty) mea­
sure N(cp) = Infwl=.,cp(1- 1r(w)) = 1- II(-.tp), which
evaluates the extent to which tp is entailed by the
available knowledge. We have Vtp, '1/J, N(<p /1. 'lj;) =
min(N(tp),N('lj;)). Note that while N(cp) = 1 means
that <p is certainly true, N(cp) = 0 means only that
cp is not certain at all.Complete ignorance about <p
is expressed by N (<p) = N (-.tp) = 0. Since pos­
sibility distributions are not required to be normal­
ized, it may be the case that N(.l.) > 0. Note that
we have V<p, min(N(cp), N(-.cp)) = N(.l.). Note that
what is essential in possibility theory is not the pre­
cise value of certainty degrees, but their ordinal na­
ture: indeed certainty degrees can be used to rank
formulas of L. Namely, it is equivalent to work with
necessity measures or with (qualitative) necessity re­
lations (see (Dubois, Prade 91)) defined by ?..N defined
by V<p, '1/J, <p ?..N 'ljJ iff N(<p) ?.. N('lj;), meaning that <p is
at least as certain as 'lj;.
=

A possibilistic knowledge base (Dubois et al. 91a)
is a finite set of necessity-valued formulas K =
{('Pi a;) , i = 1, n} where ai represents a lower bound of
the necessity degree N(<pi)· A possibility distribution
1r on n satisfies K iff Vi, N ( <p;) ?.. a;, where N is the
necessity measure induced by 1r. Logical consequence
is then defined by K F (e {3) iff any possibility dis­
tribution satisfying K satisfies (E {3). The fuzzy set of
models of a possibilistic knowledge base has for mem­
bership function the least specific possibility distribu­
tion satisfying the constraints N (<pi) ?.. a;, i = 1, n.
This possibility distribution 7rK is defined by: Vw E n,
1r:K(w ) = mini=l,n{1 - a;,w F -.cpi} .
Possibilistic
logic allows for partial inconsistency, occuring there
is no normalized possibility distribution satisfying I<,
which means that K F ( .1. {3) for some strictly positive

Possibilistic decreasing persistence

{3. The quantity Max{f3, I< F= ( l. {3)} is called incon­
sistency degree of I<, denoted by I ncons(I<) . It can be
shown that I ncons(I<) = Nk(l.) = 1-Supwen?rf<(w).

persistence consists in extrapolating N(free) in the in­
terval (10.00, +oo); an example of persistence function
is shown on Figure 1.

In (Dubois et al. 91b), possibilistic logic was extended
to a timed version which handles both uncertainty and
time; basically, a timed possibilistic knowledge base
consists in a collection of possibilistic knowledge bases
indexed by time points varying on a given time scale
T; so, instead of considering possibility distributions
(resp. necessity measures), we consider collections of
possibility distributions {?rt, t E T} (resp. collections
of necessity measures { Nt, t E T}).
From a possibilistic knowledge base K, it is possi­
ble to define a nonmonotonic inference relation (see
(Dubois Prade 91)) 1-x by: <p 1-x t/J iff NK (cp __,.
tf;) > Nk(-.cp). Note that in the particular case
where <p = T, we get the following (abbreviating
T I-t tf; in I-t tf;): 1- t/J iff Nk(t/J) > Nk(l.) iff
Nt (tf;) > I ncons( I<). It has been shown that 1-K en­
joys all "desirable" properties that nonmonotonic in­
ference relations "should" satisfy, including rational
monotonicity (Dubois, Prade 91).
3

Possibilistic decreasing persistence:
the extrapolation problem

3.1

Informal presentation of the
extrapolation problem

The general principle of decreasing persistence is,
given a factual temporal knowledge base and some in­
formation about the persistence of some given fluent
f, to derive uncertain information about f in the in­
tervals when the truth value off is unknown. Let us
start with motivating examples.
Example 1 (unbounded forward extrapolation): let us
consider the fluent free of a given parking place which
may or may not be free at any time-point t. Sup­
pose that all we know about free is that it holds up
to to = 10.00 (and we do not anything about it af­
terwards). We would like to extrapolate, using some
knowledge describing how our ignorance about the
persistence of free increases, the following uncertain
facts: the certainty (necessity) degree of free, which
is 1 at 10.00 (since free is known to be true), should
be close to 1 when t is close to 10.00 (we recall that
N(free) expresses to which point free is entailed by
the knowledge of reference; here it is obvious that at
time points close to 10.00, free is entailed, to some
certainty degree close to 1, by both the fact that it
holds at 10.00 and the general principle of decreasing
persistence); then, the further t is from 10.00, the less
certain we are that free is true; and there should also
be a point from which on we are too far from 10.00 to
be even weakly certain that free still holds, i.e. from
which on N(free) = 0 (then we are in a state of com­
plete ignorance about free, i.e. we haveN(-.free) = 0
too). So, in this example the principle of decreasing

471

tO

Figure 1: unbounded forward extrapolation
Example 2 (unbounded backward extrapolation): as­
sume now that free is known to be true from 10.00
on (we do not know anything about it before) and we
have to infer uncertain facts about the past of the flu­
ent (this problem is also called postdiction) . This case
is very similar to forward extrapolation (in a symmet­
ric way), and all previous remarks hold.
Example 3 (bounded extrapolation without change):
now, assume that free is known to be true up to
10.00, and from 10.30 on, nothing is known about f ree
during the interval (10.00, 10.30). Traditional non­
gradual approaches to persistence are too optimistic
since they conclude by default that free holds every­
where in (10.00, 10.30], since nothing tells· us that a
change ocurred. However this is not always realistic,
especially if the considered interval is long (relatively
to the considered fluent). The most intuitive kind of
extrapolation on [10.00, 10.30] tells that the further
from one of the two reference time-points 10.00 and
10.30, the less certain we are that free still holds (see
figure 2). The fact that free holds at the two extrem­
ities of the interval should be a confirmation that free
holds in any arbitrary point of the interval; in other
words, for instance, we should be at least as certain
that free holds at 10.15 in this situation than in the
situation of Example 1. In some cases, the interval
length may be too long for us to be somewhat certain
that the fluent does not change within the interval;
for instance, consider free within [10.00, 18.00]. See
Figure 2.

Nt (f)

Nt (f)
f

Figure 2: bounded extrapolation without change
Example 4 (bounded extrapolation with change): now,
assume free is true up to 10.00, and false from 10.30
on; again, nothing is known during (10.00, 10.30).
Traditional non-gradual approaches are too cautious
since they conclude that free is unknown within

472

Driankov and Lang

(10.00, 10.30); however, a more realistic (and more in­
formative) extrapolation would tell that free is rather
certainly true if we are very close to 10.00 (the closer,
the more certain; but it should nevertheless decrease
faster than in Examples 1 and 3), and rather certainly
false if we are very close to 10.30 (again, the closer,
the more certain). See Figure 3.

base is maintained consistent, or by considering all
contingent formulas as Unknown at inconsistent time­
points.
The partial history H induced by!{ is the logical clo­
sure of !{, i.e. the collection of all Cn( Kt), for t vary­
ing in T. We will denote the belief status (True, False
or Unknown) of <p at to by Ht(<p).
3.2.2

tO

t1

Figure 3: bounded extrapolation with change
3.2

Formalizing possibilistic decreasing
persistence

First, it is primordial to state the distinction be­
tween factual knowledge and knowledge about persis­
tence. The first one expresses what we know about
the world during the time scale of reference and en­
ables us only to draw certain, monotonic conclusions
(for instance "it was raining from 10.00 to 11.00, and
it was not raining at 12.30"), while the second one
expresses what we know about the general behaviour
of fluents (for instance, "raining tends to persist but
usually no more than a couple of hours") and, together
with factual knowledge, enables us to draw uncertain
and defeasible conclusions.
3.2.1

Factual knowledge

Factual knowledge consists in an generally incomplete
knowledge about the the world at every time point.
It will be represented in a traditional way, by reify­
ing time. Let T= (-co, +co) be the time scale of
reference. Let L be a propositional logical language;
atomic propositions which are allowed to vary along
time are called ftuents. A timed knowledge base /{ is a
finite set of timed formulas T : <p, where T is a subset of
T (generally an interval) and <p a well-formed formula
of L. T : <p expresses that <p holds for any time point
t in T. The cut of!{ at t0 is the classical knowledge
base Kt0 = {T : <p E K I to E K }; clearly, a formula
<p is known to be true at t0 iff <p E Cn(Kt0), where
Cn denotes logical closure, and known to be false at
to iff -,<p E Cn(Kt0); if <p is neither True nor False
at t0 then <p is said to be unknown at to. Note that
there is a fourth possible status for <p at to, due to the
possibility that Kt0 be inconsistent (in which case <p is
both True and False); note that the set { True, False,
Unknown, Inconsistent } is the well-known 4-valued
lattice of (Belnap 77). However, for the sake of clarity,
in this paper we will deliberately ignore inconsistent
time-points (i.e. time-points t such that Kt is incon­
sistent), either by assuming that the timed knowledge

Persistence extrapolation problems

Let f be a propositional fluent, and let H be a partial
history on the time scale T. A time-point t will said to
be informative for f iff Ht(/)=True or Ht(f)=False.
The set of all informative time-points off is denoted
by ITP(f). For practical reasons we need to require
that partial histories satisfy the following property: H
is said to be closed iff for any elementary fluent f,
ITP(<p) is a closed subset of T, i.e. a (possibly infi­
nite) union of intervals of T which have one of these
4 forms: [a, b] (possibly a= b), [a, +co), (-co, b] or
(-co, +co). H being a closed partial history, a time­
point tis said to be a reference time-point for f w.r.t.
H iff t is at the leftest or at the rightest extremity of
one of the intervals constituting ITP(!). The com­
plementary of ITP(f), i.e. the set of all time points t
when Ht(/)= Unknown, is a (possibly infinite) union
of airwise disjoint open intervals, called maximal non­
informative intervals off w.r.t. H; if ITP(!) :f. 0,
their form is either (-co, t0) or (tn, +co) or (t;, ti+l),
where all t;'s are reference time points forf w.r.t. H
(it may be the case that t; =t;+1). From now on we
exclude the trivial case ITP(f) = 0 (i.e. the truth
value of f is always unkwown) since it is completely
uninteresting (persistence cannot apply).
A persistence extrapolation problem consists in a closed
history H, an elementary fluent f and a maximal non­
informative interval I for f w.r.t. H. The various
examples presented informally in Section 3.1 suggest
the following classification of persistence extrapolation
problems:
•

•

•

a persistence extrapolation problem (H, f, I) is an
unbounded extrapolation problem iff I= (tn, +co)
(forward extrapolation), or I = (-co, t0) (back­
ward extrapolation).
a persistence extrapolatioa problem (H, f, I) is a
bounded extrapolation problem without change iff
I= (t;, ti+l) and Ht, ( f )= Ht,+1(!).
a persistence extrapolation problem (H, f, I) is a
bounded extrapolation problem with change iff I=
(t;, ti+l) and Ht,(f) :f. Ht,+1(<p).

3.2.3

Decreasing persistence functions and
decreasing persistence schemata for
fluents

Having stated persistence extrapolation problems, we
are now giving a general methodology for solving them.

Possibilistic decreasing persistence

Informally, extrapolation based on decreasing persis­
tence consists in inferring by default a truth-value,
with some certainty degree, to a fluent at time-points
where its truth-value is not definitely known. Of
course, the way to cope with it may depend not only
on the involved fluent, but on the class (backward,
forward, ...) of the extrapolati�m problem and when
it occurs. Let I be a maximal non-informative inter­
val for f w.r.t. H. A persistence function for (!, I)
is a mapping from I to [0, 1) which associates to any
t in I the necessity degree N1(!) of f at t. Thus,
persistence functions extrapolate uncertain knowledge
from factual knowledge by using the general princi­
ple of decreasing persistence. Obviously, the prob­
lem is tractable only if the user can specify persis­
tence functions in a general way (for instance, "in a
forward extrapolation problem starting at to the ne­
cessity degree of free decreases linearly and reaches 0
at t0 + 1.00 if t0 is during the day and at to + 4.00 if
t0 is during the night"). This is a decreasing persis­
tence schema. Once applied to a given partial history,
a persistence schema is "instanciated" to persistence
functions. If H is a partial history and Pers denotes
a set of persistence schemata for a subset of the flu­
ents involved in H, then Apply(Pers, H) denotes the
application of Pers to H. Note that Apply(Pers, H)
is a collection of possibilistic knowledge bases (one for
each t, denoted by Apply(Pers, H)1). In next Sec­
tion we investigate some of the properties that persis­
tence schemata should preferably satisfy in order to be
in accordance with the general principle of decreasing
pereistence, and we propose some examples of persis­
tence schemata.
4

From qualitative to quantitative
axioms for persistence schemata

473

is, Dl should sometimes not be required (for instance,
for periodic or " usually periodic" fluents with a known
period, like "sleep").

j/ull infinite persistence
_.l5 ymptotic persistence
----�

asymptotically

-==-t-� limited persistence
0 L-----"'+-Jo..��---�
limited persistencet
no persistence at all

Figure 4: some forward persistence functions
On Figure 4 we have represented continuous functions
satisfying D1 (except no persistence at al0; note that
any persistence function satisfying Dl and continuity
is of one of the four following types shown on figure 4.
Among other possible requirements, one could require
the persistence function to be strictly decreasing on
[t0, +oo) (which rules out limited persistence func­
tions) or, which is weaker, strictly decreasing in the
right neighbourhood of to.
These requirements can be formulated in very simi­
lar ways for all other classes of extrapolation problems
(for the sake of brevity we will omit doing it).
Backward extrapolation
This is very analogous to the case of forward persis­
tence, except that persistence is "increasing" (but, of
course, still decreasing with respect to the distance to
the nearest reference time point): given a backward
extrapolation problem (H,f, ( -oo, t0):
D2. N1(f) is non-decreasing on ( -oo, t0]

Independently from the exact shape of the persistence
function of a fluent f im an interval I, there are some
very general properties that is may be desirable to im­
pose. We give a first set of very basic axioms which are
completely qualitative (since they do not use the met­
ric nature of T and [0, 1]); we propose then a second
set of more debatable properties, which are qualitative
with respect to necessity degrees but quantitative with
respect to time.

Bounded extrapolation without change
Let (H, f, (to, t1)) be a bounded extrapolation prob­
lem without change (without loss of generality, f be­
ing True at both to and tl).
D3. 3t* E (to, t1] such that N1(!) is is non-increasing
in (to, t*] and non-decreasing in (h, ti).
Strictness in the neighbourhoods of t0 and t1 would
ensure that t* E (to, t1)). Note that the persistence
function needs not to be symmetrical. Some admissi­
ble functions are shown on figure 5.

4.1

When the persistence function is continuous, it is nec­
essarily of one of the 3 following types, shown on figure
5, depending on the minimal value of N1(!) on [to, t1):
full persistence, where "'t E [to, t1), Nt(f) = 1; elastic
persistence, where Min1e[to,t.]N1(!) E (0, 1); and par­
tially elastic persistence, where Min1e[t0,tt]Nt (!) = 0.
Elastic persistence should occur whenever the interval
[t0, tl] is short enough for the fluent to always remain
somewhat certain; if the interval is too long, then we
only have partially elastic persistence, and there are
some time points within the interval when it cannot
be guaranteed that the fluent is still somewhat cer-

Basic axioms for persistence functions

These very basic axioms just ensure that persistence is
well respecting the principle of increasing ignorance.
Forward extrapolation
Let ( H,f,(t0, +oo)) be a forward extrapolation prob­
lem.
Dl. N1(f) is non-increasing on (t0, +oo)
Obviously, Dl does not restrict a lot the possible per­
sistence functions; typical examples of functions satis­
fying Dl are shown in Figure 4. But, however basic it

474

Driankov and Lang

full persistence

f

f

no persistence at all

Figure 5: some functions for bounded extrapolation
without change
tain. Consider for example the fluent free (again the
parking place); if it is known that free holds at 10.00
and at 10.10, nothing being about its truth value in­
between, it is reasonable to consider the case of elas­
tic persistence (for it is almost certain that the place
has remained free for the whole interval); now, if it
is known that free holds January 1st at 10.00 and at
May 1st at 10.00, nothing being known about its truth
value inbetween, then it is of course not reasonable to
assume the same, since for time points far from both
January 1st 10.00 and May 1st 10.00 it should be ab­
solutely not certain that free still holds.
Bounded extrapolation with change
Let (H,f ,(to,ti)) be a bounded extrapolation problem
with change (without loss of generality, f being True
at to and False at t1). If we assume we do not want
to generate partially inconsistent time-points (which
is very reasonable), it must be always the case that
min(N1(f), Nt(-,J)) = 0, thus the following axiom:
D4. 3t', t", with to S t' S t" S t1 such that N1(f) is
non-increasing in [to,t'], N1( f ) = 0 in [t',t1], Nt(_,J) =
0 in [to , t"] and N1( -, f ) is non-decreasing in [t",t1].
4.2

Semi-quantitative axioms for decreasing
persistence

The axioms we have given so far are very weak; in this
subsection we give stronger axioms which do not use
the metric properties of the certainty scale [0, 1] but
which use the metric properties of the temporal scale.
4.2.1

Homogeneity

The main condition for a fluent being homogeneous is
that the way it behaves with respect to decreasing per­
sistence depends only on the class of the extrapolation
problem and the time length of the interval, but not
on when the interval starts. For instance, while the
fluent "ra.ining" may well be considered homogeneous
on a time scale of 24 hours, it cannot be the case for
the free parking place which will more certainly remain
free after some period of time, say, at 10 pm than at 10
am. So, homogeneity should not always be required.
However, in many cases, even if a fluent is definitely
not homogeneous on the whole time scale, it can often

be considered homogeneous on some shorter subinter­
vals. The exact formulation of homogeneity is however
more complex and expresses monotonicity conditions
with respect to interval lengths. Let us now write for­
mally some of the numerous homogeneity conditions.
From now on, f is a homogeneous fluent over the whole
time scale.
Case 1: monotonicity for two bounded extrapolation
problems without change
Let H be a partial history; let (H,f ,(t0,t1)) and
(H,f,(tz, t3)) be two bounded extrapolation problems
without change, the truth value of f at the bounds
of both intervals being identical (say, Tr ue ). Homo­

geneity tells us that the shorter the interval, the more
certain of the persistence of f in the interval. For in­
stance; if free is homogeneous over [8.00, 12.00], and
is known to be true at 9.00, 9.10, 11.00 and 11.20,
free holding at 9.01 should be at least as certain than
free holding at 11.01, and similarly, free holding at
9.09 should be at least as certain than free holding at
11.19, for rather obvious reasons. Assume without loss
of generality that t1- to S t3- tz, and let 8 = t1-t0;
then
Hl.
Vx E [0,8],Nto+x(f) S Nt,+x (f) and Vx E
[0, 8], N t1-x(f) S Nt3-x(f)
As an immediate consequence, if t1-t 0 = t3-t2,then
Vx E [0,8],Nto+x(f) = Nt2+xCf), i.e. the persistence
function is exactly the same within two intervals of the
same length.
·

Case 2: monotonicity between forward extrapolation
and bounded extrapolation without change
Let (H, f, (to,t1)) be a bounded extrapolation prob­
lem without change and (H, f,(t2,+oo)) be a forward
extrapolation problem (!being True at t0,t1 and t2).
Let 8 = t1 -to. Then homogeneity tells that persis­
tence should decrease at least as fast within [t3,+oo)
as in [to, tl] , which writes
H2. Vx E [0, 8],Nto+x(f) 2:: Nt1+x(f).
Case 3: bounded with change/ bounded with change
Suppose we have two bounded extrapolation problems
with change concerning the same fluent f, within the
two intervals (to , t1) and (tz, t3), the truth value off
at to and t2 being the same (say, True). T hen, homo­
geneity tells us that the shorter the interval, the faster
persistence decreases f in the interval (contrarily to
what happens in the case of bounded persistence with­
out change where the shorter the interval, the slower
persistence decreases). Let us assume without loss of
generality that t1 -to S t3 -t2 and let 8 = t1 -to ;
then we get
H3. Vx E [0,8],Nto+x (f) 2:: Nt,+ x ( f )
and Vx E [0,8], Nt1-x ( -, f ) S Nt,-x(-,f ).

For the sake of brevity, we omit writing monotonic­
ity conditions for the other cases (bounded without
change( backward, bounded with change/ bounded
without change, bounded with change/ forward).

Possibilistic decreasing persistence

4.2.2

Other metric axioms

Among the other axioms we may require for some fiu­
ents, we can consider for instance forward/backward
symmetry, which means that the fluent behaves sym­
metrically with respect to forward and backward ex­
trapolation. Note that a lot of fiuents don't (for
instance, consider the well-known fluent alive of
the Yale Shoooting Problem). Assuming both for­
ward/backward symmetry and homogeneity for f im­
plies that backwards and forwards extrapolation func­
tions are symmetric of each other, that functions for
bounded persistence without change are symmetric
relatively to the middle of the considered interval, and
a symmetry property concerning bounded persistence.
A stronger possible requirement (often too strong) is
symmetry with respect to negation: the truth value
"true" of the fluent tends to persist exactly the same
way as the truth value "false". Among other things,
it implies that, for a bounded persistence with change
problem, the increasing functions for f (resp. •f) and
the increasing function for •g (resp. f) are symmetric
of each other.
4.3

Quantitative persistence functions

All the previous requirements do not enforce precise
persistence functions. This last step (necessary for
practical application) has to be done by the user. For
instance, a reasonable choice for a family of persistence
schemata consists in piecewise linear functions.
5

Inferring nonmonotonic conclusions
from decreasing persistence

In Section 2, we have seen how, from a possibilistic
knowledge base, it is possible to define a nonmono­
tonic inference relation. So, since the application of
decreasing persistence principles to a partial history
gives us a possibilistic knowledge base, it is then pos­
sible to draw some non monotonic inferences. More
formally, let H be a partial history on a time scale T,
and let Pers be a set of persistence schemata for a sub­
set of the fluents involved in H. Let App/y(Pers, H)
be the application of Pers to H as defined in Section
3. Now, for any t, let Nt be the necessity measure
obtained by the application of the principle of mini­
mum specificity (as in Section 2) to Apply(Pers, H)t·
Then, for any t E T, we can define the nonmonotonic
inference relation l"'t as in Section 2. Let us now give
a detailed exampl e.
Example

Let us consider two machines A and B which may be
either working or in failure at any time point. Let
A and B be propositional fiuents, A (resp. B) being
true iff A (resp. B) is working. Both machines are
considered equivalent with respect to persistence; fur­
thermore we assume that A and B are homogeneous

475

on T, and the persistence functions of A and •A are
represented on figure 6 (the time unit being the day).

0.2

I
I
I
I
I
I
I

.. 1 .

- - ·----

1
I

tO

t0+10

tO

t0+3

F igure 6:
Let us briefly comment these two persistence func­
tions. The asymptotic value of 0.2 in the forward per­
sistence function of works means that the certainty
degree by default of works is 0.2, i.e. it is somewhat
certain that machine work, independently from persis­
tence considerations. The fastly decreasing persistence
of •works is due to the existence of repairmen (failing
machines tend to be repaired in short delays). Let I<
be the following timed knowledge base: machine A is
known to be working from 0 to 10, machine B is known
to be working from 17 to 30 and we know that at least
one of the two machines is not in a failure state at time
15; formally:
K = {[0, 10]: A; [15]: -,A v ·B; [17, 30]: B}.
Now, consider the fluent A. We have successively
a backward extrapolation problem on ( -co, 0), and
then a forward extrapolation problem on (10, +oo ).
Applying the decreasing persistence schemata, we get
the following certainty degrees at time 15: Ni5(A) =
0.5; Ni5(B) = 0.8 and (without needing persis­
tence schemata) Ni5(•A V ·B) = 1. We have also
Ni5(•A) = min(Ni5(•AV•B), Ni5(B)) = 0.8. More­
over we get Ni5(j_) = min(Ni5(A), Ni5(B), Ni5(•A V
•B)) = 0.5; hence, the knowledge has an inconsistency
degree at time 15.
Since Ni5(....A
., ) = 0.8 > Ni5(j_), we have 1"'15 •A;
similarly we have 1"'15 B, but we do not have 1"'15 A.
or l"'1s •B. This is due to the fact that the closest
time point when B is true is closer to 15 than the clos­
est time point where A is true.
Note also that at t = 35, we have Nj5(B) = 0.5 and
N35(j_) == 0, so we have /"'35 B.
6

Concluding remarks

In this paper we have shown that possibility theory
is well-suited for modelling gradually decreasing per­
sistence, mainly because it is adequate to represent­
ing ;;tates of partial or complete ignorance. More­
over, since necessity orderings and similar construc­
tions have been proved to be well-suited for perform­
ing nonmonotonic deductions, this framework provides
us with a general methodology for inferring uncertain,
defeasible conclusions from a "hard facts" knowledge
base and some persistence schemata describing, for
each fluent, how ignorance increases with respect to

476

Driankov and Lang

its persistence.

J.M Dunn, eds.), 8-37.

We think of pursuing our work in many directions.
First of all, in this paper we considered decreasing per­
sistence schemata only for atomic fluents; this leads to
some problems when only disjunctions of fluents are
known (see (Schrag 92) for a study of problems cre­
ated by disjunction in reasoning about persistence).
For instance, consider the partial history where f V g
is True at t0, nothing else being known. Since both
fluents I and g have the Unknown status at t0, we
can apply persistence schemata to none of them; and
since there is no persistence schema for I V g, we will
get Nto+f(f V g) = 0 \If > 0, i.e. no persistence
at all for I V g. This could be avoided by applying
persistence to non-atomic formulas as well; however,
this leads to many technical problems, because per­
sistence schemata of different formulas sharing fluents
obviously interact. This is a topic left for further re­
search.

Salem Benferhat, Didier Dubois, Henri Prade (1992),
Representing default rules in possibilistic logic, Proc.
KR'92, 673-684.

We could also generalize our study to non­
propositional fluents (i.e. whose domain is not True,
False), which should not cause any trouble; we also
think to incorporate decreasing persistence principles
with non-gradual approaches dealing not only with
persistence but more generally with time and action,
such as in (Sandewall 92). Another easy generalisa­
tion of our work would consist in starting from a timed
knowledge base already pervaded with uncertainty (i.e.
from a possibilistic knowledge base) and to extrapolate
necessity measures in a similar way. Moreover, work of
Section 4 can be extended; in particular, it would be
interesting to make a classification of fluents with re­
spect to how they behave w.r.t decreasing persistence
(adding other properties such as periodicity, ...).
Then, it would be interesting to generalize the prin­
ciple of decreasing persistence to spatial reasoning
(extrapolating the truth value of a fluent at a point
(x, y, z) by considering some close points where its
truth value is known). Integrating both temporal and
spatial "persistence" could enable us to infer defeasible
conclusions from knowledge about time, space and mo­
tion. Next step would be a formal logical study of such
a methodology, which could use notions of distances or
similarity measures between worlds as in (Ruspini 91).
Acknowledgements

We would like to thank Patrick Doherty, Didier Dubois
and Henri Prade for helpful discussions. This work has
been supported by the European ESPRIT Basic Re­
search Action # 6156 entitled "Defeasible Reasoning
and Uncertainty Management Systems (DRUMS-2)".
