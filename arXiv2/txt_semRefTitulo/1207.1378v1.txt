
The local Markov condition for a DAG to be
an independence map of a probability distribution is well known. For DAGs with latent
variables, represented as bi-directed edges in
the graph, the local Markov property may invoke exponential number of conditional independencies. This paper shows that the number of conditional independence relations required may be reduced if the probability distributions satisfy the composition axiom. In
certain types of graphs, only linear number of
conditional independencies are required. The
result has applications in testing linear structural equation models with correlated errors.

1

Introduction

The use of graphical models for encoding distributional and causal assumptions is now fairly standard
(see, for example, [Pearl, 1988, Spirtes et al., 1993,
Pearl, 2000]). The most common such representation involves a directed acyclic graph (DAG), called
a Bayesian network, over a set of variables. The statistical information encoded in a Bayesian network is
completely captured by conditional independence relationships among the variables. The set of conditional independence relationships encoded in a DAG
can be read by d-separation criterion, which provide
the global Markov property for DAGs. A local Markov
property specifies a much smaller set of conditional independencies that will imply (using the laws of probability, typically semi-graphoid axioms) all other conditional independencies which hold under the global
Markov property. A well-known local Markov property for DAGs is that each variable is conditionally
independent of its non-descendants given its parents.
When some variables in a DAG model are not observed, called latent or hidden variables, DAGs with

Jin Tian
Department of Computer Science
Iowa State University
Ames, IA 50011
jtian@cs.iastate.edu

bi-directed edges (↔) have been used to represent the
conditional independence relations among observed
variables [Pearl, 2000, Richardson and Spirtes, 2002].
DAGs with bi-directed edges have also been used
to represent linear structural equation models
(SEMs) with correlated errors, called path diagrams [Wright, 1934].
A DAG with bi-directed
edges is called an acyclic directed mixed graph
(ADMG) in [Richardson, 2003]. A natural extension of the d-separation criterion, called m-separation
(see Section 2.1) can be applied to ADMGs which
provides the global Markov property for ADMGs
[Spirtes et al., 1998, Koster, 1999, Richardson, 2003].
A local Markov property for ADMGs is given in
[Richardson, 2003], which, in the worst case, may
invoke an exponential number of conditional independence relations, a sharp difference with the local
Markov property for DAGs, where only one conditional independence relation is associated with each
vertex.
In this paper, we seek to improve the local Markov
property for ADMGs given in [Richardson, 2003] in
the situation that the probability distributions also
satisfy the composition axiom. The intended application is in linear SEMs, which are widely used
in the social sciences and economics [Duncan, 1975,
Bollen, 1989]. In a linear SEM, variables are typically
assumed to have normal distribution, and conditional
independence relations will correspond to zero partial
correlations, namely, a partial correlation ρxy.Z = 0
if and only if x is independent of y given Z. An
important task in SEM applications is to test the
model against data. The conventional method involves fitting the covariance matrix, while recently
an alternative approach has been proposed which involves testing for the vanishing partial correlations
[Spirtes et al., 1998, Pearl, 2000]. The advantages of
using such local tests instead of the traditional global
fitting tests are discussed in [Pearl, 2000]. The path
diagrams for linear SEMs without correlated errors
are DAGs, and based on the local Markov property

for DAGs, only one vanishing partial correlation test
is needed for each variable [Pearl and Meshkat, 1999].
On the other hand, the path diagrams for linear SEMs
with correlated errors are ADMGs, and we may need
exponential number of vanishing partial correlation
tests based on the local Markov property given in
[Richardson, 2003]. For this local test method to be
applicable in models with correlated errors, it is therefore important to reduce the number of conditional
independencies invoked by the local Markov property.
It is known that normal distributions satisfy the composition axiom, which motivates our search for reduced local Markov property for probability distributions satisfying the composition axiom.
In Section 2, we give basic notation and definitions,
and present the local Markov property developed in
[Richardson, 2003]. In Section 3, we show that for a
class of ADMGs, the local Markov property for probability distributions satisfying the composition axiom
will invoke only one conditional independence relation
for each vertex. In Section 4, we provide two lemmas under which the local Markov property can be
reduced for a general ADMG, one assuming the composition axiom and the other not. We also provide a
procedure that will incorporate the two lemmas and
list all the conditional independence relations invoked
by the reduced local Markov property. In Section 5,
we show the usefulness of the results in Section 3 and 4
in testing linear SEMs. Section 6 concludes the paper.

2
2.1

Background
Notation and Definitions

For a vertex x in an ADMG G, paG (x) ≡ {v|v → x
in G} is the set of parents of x. spG (x) ≡ {v|v ↔ x
in G} is the set of spouses of x. anG (x) ≡ {v|v →
· · · → x in G or v = x} is the set of ancestors of
x. And deG (x) ≡ {v|v ← · · · ← x in G or v = x}
is the set of descendants of x. These definitions will
be applied to sets of vertices, so that, for example,
paG (A) ≡ ∪x∈A paG (x), spG (A) ≡ ∪x∈A spG (x), etc.
A path is said to be a mixed directed path from α to β
if it contains at least one directed edge and every edge
on the path is either of the form γ ↔ δ, or γ → δ with
δ between γ and β. A mixed directed path from α to
β together with an edge β → α or β ↔ α is called a
mixed directed cycle.
For example, the path a → c ↔ d → b ↔ a in the
graph in Figure 1 forms a mixed directed cycle.
A non-endpoint vertex z on a path is called a collider if
two arrowheads on the path meet at z, i.e. → z ←, ↔
z ↔, ↔ z ←, → z ↔; all other non-endpoint vertices

a

b

c

d

Figure 1: An ADMG with a mixed directed cycle.
on a path are non-colliders, i.e. ← z →, ← z ←,
→ z →, ↔ z →, ← z ↔. A path between vertices x
and y in an ADMG is said to be m-connecting given a
set of vertices Z if
(i) every non-collider on the path is not in Z, and
(ii) every collider on the path is an ancestor of a vertex
in Z.
If there is no path m-connecting x and y given Z, then
x and y are said to be m-separated given Z. Sets X and
Y are said to be m-separated given Z, if for every pair
x, y, with x ∈ X and y ∈ Y , x and y are m-separated
given Z.
A probability distribution P is said to satisfy the mseparation global Markov property for G if for arbitrary
disjoint sets X, Y, Z,
X is m-separated from Y given Z in G ⇒ I(X, Z, Y )
where I(X, Z, Y ) denotes that X is conditionally independent of Y given Z. The set of probability distributions that satisfy the m-separation global Markov
property with respect to G is denoted Pm .
It is well-known that probabilistic conditional independencies satisfy the following so-called semi-graphoid
axioms [Pearl, 1988]:
• Symmetry
I(X, Z, Y ) ⇐⇒ I(Y, Z, X)
• Decomposition
I(X, Z, Y ∪ W ) =⇒ I(X, Z, Y ) & I(X, Z, W )
• Weak Union
I(X, Z, Y ∪ W ) =⇒ I(X, Z ∪ W, Y )
• Contraction
I(X, Z, Y ) & I(X, Z ∪ Y, W ) =⇒ I(X, Z, Y ∪ W )
where X, Y , Z, and W are disjoint sets of variables.
Some probability distributions, for example normal
distributions, also satisfy the following composition
axiom
• Composition
I(X, Z, Y ) & I(X, Z, W ) =⇒ I(X, Z, Y ∪ W )

2.2

The Ordered Local Markov Property for
ADMGs

In this section, we describe the local Markov property
introduced by [Richardson, 2003]. An ordering(≺) on
the vertices of G is said to be consistent with G if
x ≺ y ⇒ y ∈an(x).
/
Given a consistent ordering ≺, let
preG,≺ (x) ≡ {v|v ≺ x or v = x}. A c-component of
G is a maximal set of vertices in G such that any two
vertices in the set are connected by a path on which
every edge is of the form ↔; a vertex that is not connected to any bi-directed edge forms a c-component by
itself. For example, the graph in Figure 1 is composed
of c-components {a, b} and {c, d}. The district of x in
G is the c-component of G that includes x. Thus,
disG (x) ≡ {v|v ↔ · · · ↔ x in G or v = x}.
For example, in Figure 1, we have disG (a) = {a, b} and
disG (d) = {c, d}. A set A is said to be ancestral if it
is closed under the ancestor relation, i.e. if anG (A) =
A. Let GA denote the induced subgraph of G on the
vertex set A, formed by removing from G all vertices
that are not in A, and all edges that do not have both
endpoints in A. If A is an ancestral set in an ADMG
G, and x is a vertex in A that has no children in A
then the Markov blanket of vertex x with respect to the
induced subgraph on A, denoted mb(x, A) is defined to
be
mb(x, A) ≡ paGA (disGA (x)) ∪ (disGA (x) \ {x}) .
For example, for an ancestral set A = anG ({a, c}) =
{a, c, d, e} in Figure 2, we have
mb(a, A) = {d, c}.
A probability distribution P satisfies the ordered local
Markov property for G with respect to a consistent
ordering ≺, if, for any x and ancestral set A such that
x ∈ A ⊆ preG,≺ (x),
I({x}, mb(x, A), A \ (mb(x, A) ∪ {x})).

(1)

The set of probability distributions that satisfy the
ordered local Markov property for G under ordering ≺
is denoted Pl (G, ≺).
The following theorem [Richardson, 2003] shows the
equivalence between the ordered local Markov property and the global Markov property.

Therefore the (smaller) set of conditional independencies specified in the local Markov property (1) will imply all other conditional independencies which hold under the global Markov property. It is possible to further reduce the number of conditional independence
relations in the local Markov property (1). An ancestral set A, with x ∈ A ⊆ preG,≺ (x) is said to be
maximal with respect to the Markov blanket mb(x, A)
if, whenever there is a set B such that A ⊆ B ⊆
preG,≺ (x) and mb(x, A) =mb(x, B), then A = B.
For example, suppose that we are given an ordering
≺: h ≺ f ≺ i ≺ g ≺ a ≺ b ≺ e ≺ d ≺ c for
the graph G in Figure 3(a). While an ancestral set
A = anG ({a, c}) = {a, f, h, c, g, i, e} is maximal with
respect to the Markov blanket mb(c, A) = {g, e}, an
ancestral set A0 = anG ({c}) = {i, g, e} is not. It is
shown that we only need to consider ancestral sets A
which are maximal with respect to mb(x, A) in the
local Markov property (1) [Richardson, 2003].
Even though we only consider maximal ancestral sets,
the ordered local Markov property may still invoke
exponential number of conditional independence relations. For example, for a vertex x, if disG (x) ⊆
preG,≺ (x) and disG (x) has a clique of n vertices joined
by bi-directed edges, then there are at least O(2n−1 )
different Markov blankets.

3

ADMGs without Mixed Directed
Cycles Assuming Composition
Axiom

In this section, we show that if an ADMG has no mixed
directed cycle and the probability distribution satisfies composition axiom, then a linear number of conditional independence relations are enough to imply
all the other conditional independence relations which
hold under the global Markov property.
Let Pm,comp (G) be the set of probability distributions obeying composition axiom that satisfy the mseparation global Markov property with respect to G.
Let V be the set of vertices in G. Let
f(x, G) ≡ paG (x) ∪ deG ({x} ∪ spG (x)).

(2)

Let Pl,comp (G) be the set of probability distributions
obeying composition axiom that satisfy the following
local Markov property:
∀x ∈ V,

I({x}, paG (x), V \ f(x, G)).

(3)

Theorem 1 [Richardson, 2003] If G is an ADMG
and ≺ is a consistent ordering then

Theorem 2 If an ADMG G has no mixed directed
cycle, then

Pm (G) = Pl (G, ≺).

Pl,comp (G) = Pm,comp (G).

e

Proof: Let Pl,comp (G, ≺) be the set of probability distributions that satisfy composition axiom and the ordered local Markov property for G under ordering ≺.
By Theorem 1, for any consistent ordering ≺, we have
Pl,comp (G, ≺) = Pm,comp (G). We show that for some
consistent ordering ≺, Pl,comp (G) ⊆ Pl,comp (G, ≺) and
Pm,comp (G) ⊆ Pl,comp (G).
To show Pm,comp (G) ⊆ Pl,comp (G), we need to prove
that any vertex x is m-separated from V \f(x, G) given
paG (x) in G with no mixed directed cycle. Suppose
some vertex x is not m-separated from V \f(x, G) given
paG (x). This would be true only if some vertex in
spG (x) is an ancestor of x. Then, there would be a
mixed directed cycle involving x.
We now show that we can construct a consistent ordering ≺ such that Pl,comp (G) ⊆ Pl,comp (G, ≺) holds.
We do the following to get the desired ordering.

2. Let ≺G0 be any consistent ordering on V 0 . Replace each vertex x0 in ≺G0 with the set of vertices cm(x0 ) arbitrarily ordered. Let ≺G be the
resulting ordering.
Since the vertices in every c-component are consecutive in ≺G , for any x in V ,
(4)

Next, we show that Pl,comp (G) ⊆ Pl,comp (G, ≺G )
holds. Let P ∈ Pl,comp (G). We will show that the
set of conditional independence relations in (3) imply
the following conditional independence relations given
by the ordered local Markov property for the vertex x.
For any maximal ancestral set A such that
x ∈ A ⊆ preG,≺G (x)
I({x}, mb(x, A), A \ (mb(x, A) ∪ {x})).

(5)

First, observe that for any vertex y in disGA (x), we
have
A \ (paGA (y) ∪ {y} ∪ spGA (y)) ⊆ V \ f(y, G),

a

b

c

Figure 2: An ADMG with no mixed directed cycle.
since A ⊆ V and A∩f(y, G) = paGA (y)∪{y}∪spGA (y).
So, by (3), for all y in disGA (x), we have
I({y}, paGA (y), A \ (paGA (y) ∪ {y} ∪ spGA (y))).

(7)

Let S1 = paGA (disGA (x)) \ paGA (y) and S2 = A \
(mb(x, A) ∪ {x}).
It follows that

1. Given G = (V, E), we combine all vertices in a ccomponent into one vertex. Let V 0 be the resulting set of vertices. For each x0 ∈ V 0 , let cm(x0 ) be
the set of corresponding vertices in V which are
combined into x0 . We put a directed edge from
α ∈ V 0 to β ∈ V 0 if and only if there is a directed edge from some vertex in cm(α) to some
vertex in cm(β) (Since G has no mixed directed
cycle, if there is a directed edge from some vertex
in cm(α) to some vertex in cm(β) then there exists no directed edge from any vertex in cm(β) to
any vertex in cm(α)). Let G0 = (V 0 , E 0 ) be the
resulting graph. Then G0 is a DAG because G has
no mixed directed cycle.

preG,≺G (x) ∩ (deG (disG (x)) \ disG (x)) = ∅.

d

(6)

S1 ⊆ A \ (paGA (y) ∪ {y} ∪ spGA (y)) and
S2 ⊆ A \ (paGA (y) ∪ {y} ∪ spGA (y)).

(8)
(9)

Also, we have
S1 ∩ S2 = ∅,

(10)

since S1 ⊆ mb(x, A). So,
I({y}, paGA (y), S1 ∪ S2 ) by decomposition
I({y}, paGA (y) ∪ S1 , S2 ) by weak union

(11)
(12)

I(disGA (x), paGA (disGA (x)),
A \ (mb(x, A) ∪ {x}) by composition

(13)

I({x}, paGA (disGA (x)) ∪ (disGA (x) \ {x}),
A \ (mb(x, A) ∪ {x})) by weak union.

(14)

That is,
I({x}, mb(x, A), A \ (mb(x, A) ∪ {x})).

(15)


As an example, consider the ADMG in Figure 2 which
has no mixed directed cycles. For a consistent ordering
e ≺ d ≺ a ≺ b ≺ c, the ordered local Markov property
(1) for maximal ancestral sets A involves the following
conditional independencies
I({a}, {d}, {e}), I({b}, {d}, {e}), I({b}, {a, d}, {e}),
I({c}, {d}, {e}), I({c}, {a, d}, {e}), I({c}, {b, d}, {e}),
I({c}, {a, b, d}, {e}).
(16)
The local Markov property in (3) invokes the following
conditional independencies
I({a}, {d}, {e}), I({b}, {d}, {e}), I({c}, {d}, {e}),
(17)

which, by Theorem 2 imply other conditional independencies in (16).
For the special case of graphs containing only bidirected edges,1 [Kauermann, 1996] provides a local
Markov property for probability distributions obeying
the composition axiom as follows:
∀x ∈ V,

I({x}, ∅, V \ ({x} ∪ spG (x))).

(18)

Since a graph containing only bi-directed edges is a
special case of ADMGs without mixed directed cycles, the local Markov property given in (3) is applicable, and it turns out that (3) reduces to (18) for
graphs containing only bi-directed edges. Therefore
the local Markov property in (3) includes that given
in [Kauermann, 1996] as a special case.

4

Reducing the Local Markov
Property

When an ADMG G has mixed directed cycles, the conditional independencies in (3) may not even hold in G.
In this section, we show that we can still reduce the
number of the conditional independence relations in
the ordered local Markov property (1) with or without
assuming the composition axiom
The following lemma allows us to remove some redundant conditional independence relations assuming
composition axiom.
Lemma 1 Given a consistent ordering ≺, suppose for
a vertex x, the following holds.
All vertices in disG (x) ∩ preG,≺ (x)

Proof: Consider the first statement. Suppose some
vertex y in disG (x)∩preG,≺ (x) is not m-separated from
V \ f(y, G) given paG (y). This would be possible only
if a vertex in spG (y) were an ancestor of y. Suppose a
vertex in spG (y) were a parent of y. Then, (20) would
not hold. Also, if a vertex in spG (y) were an ancestor
of but not parent of y, then (19) would not hold.
The proof of the second statement is the same as that
of Theorem 2 except that (7) comes from (21) not (3).

Although it is not possible to place all vertices in every
c-component consecutively in a consistent ordering for
a graph with mixed directed cycles, we can still put
all vertices in some c-components consecutively or at
least some subset of the vertices in some c-components
consecutively in an ordering and then we can apply
Lemma 1 for these c-components.
We now give a condition by which a conditional independence relation renders another conditional independence relation redundant.
Lemma 2 Given an ADMG G, a consistent ordering ≺ for G and a vertex x, assume that for all
y ∈ preG,≺ (x) \ {x}, and maximal ancestral set S such
that y ∈ S ⊆ preG,≺ (y),
I({y}, mb(y, S), S \ (mb(y, S) ∪ {y})).

(23)

Let A = preG,≺ (x) and A0 be a maximal ancestral set
such that x ∈ A0 ⊆ preG,≺ (x). Let Y = disGA (x) \
disGA0 (x), Y1 = disGA (x) \ (A0 ∩ disGA (x)) and Y2 =
Y \ Y1 . If Y2 = ∅ and paG (Y ) ⊆ mb(x, A0 ), then

(19)

I({x}, mb(x, A), A \ (mb(x, A) ∪ {x}))

are consecutive in ≺

(24)

implies

and
for any two vertices α, β in disG (x) ∩ preG,≺ (x),
there is no directed edge between α and β. (20)

I({x}, mb(x, A0 ), A0 \ (mb(x, A0 ) ∪ {x})).
Proof: We have

Then, any vertex y in disG (x) ∩ preG,≺ (x) is mseparated from V \ f(y, G) given paG (y).
Assume that the probability distribution obeys the composition axiom. If, for all y ∈ disG (x) ∩ preG,≺ (x),
I({y}, paG (y), V \ f(y, G)),

(21)

then
for any maximal ancestral set A such that
x ∈ A ⊆ preG,≺ (x)
I({x}, mb(x, A), A \ (mb(x, A) ∪ {x})).

(22)

1
[Kauermann, 1996] actually used undirected graphs
with dashed edges which are Markov equivalent to graphs
with only bi-directed edges (see [Richardson, 2003] for discussions).

(25)

mb(x, A) = mb(x, A0 ) ∪ Y ∪ paG (Y )

(26)

and
A \ (mb(x, A) ∪ {x})


= A0 \ (mb(x, A0 ) ∪ {x} ∪ Y2 ∪ paG (Y ))


∪ deG (Y1 ) \ Y1

(27)

Plugging (26) and (27) into (24), we get

I {x}, mb(x, A0 ) ∪ Y ∪ paG (Y ),


A0 \ (mb(x, A0 ) ∪ {x} ∪ Y2 ∪ paG (Y ))


(28)
∪ deG (Y1 ) \ Y1 .

It follows from decomposition axiom that
I({x}, mb(x, A0 ) ∪ Y ∪ paG (Y ),
A0 \ (mb(x, A0 ) ∪ {x} ∪ Y2 ∪ paG (Y ))).

(29)

Also we have
I(Y1 , mb(x, A0 ) ∪ Y2 ∪ paG (Y ),
A0 \ (mb(x, A0 ) ∪ {x} ∪ Y2 ∪ paG (Y ))),

(30)

since Y1 is m-separated from A0 \ (mb(x, A0 ) ∪ {x} ∪
Y2 ∪ paG (Y )) given mb(x, A0 ) ∪ Y2 ∪ paG (Y ) and by
(23). Then, from (29), (30) and contraction axiom, we
have
0

I({x}, mb(x, A ) ∪ Y2 ∪ paG (Y ),
A0 \ (mb(x, A0 ) ∪ {x} ∪ Y2 ∪ paG (Y ))).

(31)

Since Y2 = ∅ and paG (Y ) ⊆ mb(x, A0 ),
I({x}, mb(x, A0 ), A0 \ (mb(x, A0 ) ∪ {x}))

(32)

holds. 
Note that Lemma 2 can be applied to probability
distributions that do not satisfy composition axiom
since the proof does not depend on composition axiom.
Thus, this lemma can be used to reduce some redundant conditional independence relations for a general
probability distribution.
Using the two lemmas above, we now give a procedure
that, given a general ADMG, produces the set of conditional independence relations R needed to derive the
global Markov property for probability distributions
obeying composition axiom. We do the following.
1. We generate a consistent ordering that will give
as few conditional independence relations as possible. The method in Section 3 is modified a little
bit to deal with mixed directed cycles. For each
bi-directed edge α ↔ β, check if there exists a
mixed directed path between α and β.
- If there is no mixed directed path between
α and β, then combine the two vertices into
one. If there is a vertex γ which is adjacent
to both α and β, then there are 9 possibilities for the edges among α, β, and γ. However, only 3 cases are relevant. (i) If we have
α → γ, β → γ, then these become one edge
αβ → γ. (ii) If we have α ← γ, β ← γ, then
these become one edge αβ ← γ. (iii) If we
have α ↔ γ, β ↔ γ, then these become one
edge αβ ↔ γ. Other cases would imply that
there is a mixed directed cycle involving the
3 vertices.

a

h

i

h

i

f

g

f

g

b

c

ab

c

d

e

(a)

de
(b)

Figure 3: An example ADMG.
- If there is a mixed directed path between α
and β, then remove the bi-directed edge between α and β.
We repeat this until no bi-directed edge is left. Let
G0 be the resulting DAG. Then, we topologically
sort G0 and get a consistent ordering ≺G0 for G0 .
We replace each combined vertex x0 in ≺G0 with
the original vertices in G arbitrarily ordered. Let
≺G be the resulting ordering.
2. Let R = ∅. We examine every vertex x in ≺G
starting from the first vertex in the ordering. If
the conditions (19) and (20) in Lemma 1 for x are
satisfied, then do
R ← R ∪ I({x}, paG (x), V \ f(x, G)).
Otherwise, we do the following.
Let A =
preG,≺G (x). First, do
R ← R ∪ I({x}, mb(x, A), A \ (mb(x, A) ∪ {x})).
Then, we check for each smaller ancestral set A0
if I({x}, mb(x, A), A \ (mb(x, A) ∪ {x})) implies
I({x}, mb(x, A0 ), A0 \ (mb(x, A0 ) ∪ {x})) by the
condition described in Lemma 2. If the condition is not met, we do
R ← R ∪ I({x}, mb(x, A0 ), A0 \ (mb(x, A0 ) ∪ {x})).
We repeat this until every maximal ancestral set
has been examined.
Note that, in the above Step 2, when we find that
the conditions (19) and (20) in Lemma 1 are satisfied for a vertex x, only one conditional independence relation I({x}, paG (x), V \ f(x, G)) needs to be
added to R, since the conditional independence relations I({y}, paG (y), V \ f(y, G)) for all y in (disG (x) ∩
preG,≺ (x)) \ {x} must have been added to R in the
previous steps, and thus by Lemma 1 we can derive
(22) from these conditional independence relations.
We show the application of the preceding procedure by
considering the graph G in Figure 3(a). In Step 1, G
is converted into G0 shown in Figure 3(b). Note that
the bi-directed edge b ↔ c is removed because there is
a mixed directed path b → d ↔ e → c between b and

c. Let ≺G0 = h ≺ f ≺ i ≺ g ≺ ab ≺ ed ≺ c. Then,
≺G = h ≺ f ≺ i ≺ g ≺ a ≺ b ≺ e ≺ d ≺ c. For
x = h, f, i, g, a, b, e and d, the condition in Lemma 1 is
satisfied. For example, for b, we have

independence relation I({c}, {g, e}, {h, f, i, a}). Let
A = anG ({a, d, c}) = {h, f, i, g, a, b, e, d, c} and A0 =
anG ({c, a}) = {h, f, i, g, a, e, c}. Then, we have
=

disGA (c) \ disGA0 (c)

=
=

{a, b, c} \ {c}
{a, b}

Y1

=
=

disGA (c) \ (A0 ∩ disGA (c))
{a, b, c} \ {a, c} = {b}

Y2

=

Y \ Y1 = {a, b} \ {b} 6= ∅.

Y

disG (b) ∩ preG,≺G (b)
= {a, b, c} ∩ {h, f, i, g, a, b} = {a, b}.
a and b are consecutive in ≺G and there is no directed
edge between a and b. So, only one conditional independence relation for each x ∈ {h, f, i, g, a, b, e, d} is
added to R. However, for c, the condition in Lemma 1
is not met since vertices in
disG (c) ∩ preG,≺G (c)
= {a, b, c} ∩ {h, f, i, g, a, b, e, d, c}
= {a, b, c}
are not placed consecutively in ≺G . So, we resort to
the ordered local Markov property. The maximal ancestral sets we need to consider are
anG ({a, d, c})
anG ({d, c})
anG ({c, a})

=

{h, f, i, g, a, b, e, d, c}

= {h, f, i, g, b, e, d, c}
= {h, f, i, g, a, e, c}

Their corresponding conditional independence relations are
I({c}, {a, b, g, e, f }, {h, i, d}),
I({c}, {b, g, e, f }, {h, i, d}),
I({c}, {g, e}, {h, f, i, a}).

The condition in Lemma 2 is not met in this case.
Thus, we put the conditional independence relation
I({c}, {g, e}, {h, f, i, a}) into R.
Therefore, for the graph G in Figure 3(a), 10
conditional independence relations (one each for
h, f, i, g, a, b, e, d and two for c) are sufficient to derive
all the other conditional independence relations that
hold under the global Markov property. As a comparison, the ordered local Markov property (1) invokes 13
conditional independencies (one each for h, f, i, g, a, e,
two each for b and d, and three for c).

5

Applications in Testing Linear
SEMs

A linear SEM over a set of random variables V =
{v1 , . . . , vn } is given by a set of structural equations of
the form
X
vj =
cji vi + j , j = 1, . . . , n,
(33)
i<j

First, we take the largest ancestral set anG ({a, d, c})
and put its corresponding conditional independence relation I({c}, {a, b, g, e, f }, {h, i, d}) into R.
Then, we proceed to check for the ancestral set
anG ({d, c}) whether its corresponding conditional independence relation I({c}, {b, g, e, f }, {h, i, d}) is implied by I({c}, {a, b, g, e, f }, {h, i, d}).
Let A =
anG ({a, d, c}) = {h, f, i, g, a, b, e, d, c} and A0 =
anG ({d, c}) = {h, f, i, g, b, e, d, c}. Then, we have
Y

Y1
Y2
paG (Y )

=

disGA (c) \ disGA0 (c)

=
=

{a, b, c} \ {b, c}
{a}

= disGA (c) \ (A0 ∩ disGA (c)) = {a}
= Y \ Y1 = ∅ and
= {f } ⊆ {b, g, e, f } = mb(c, A0 ).

Thus, by Lemma 2, I({c}, {b, g, e, f }, {h, i, d}) is implied by I({c}, {a, b, g, e, f }, {h, i, d}) and will not be
added to R.
Finally we check the ancestral set anG ({c, a}) =
{h, f, i, g, a, e, c} and its corresponding conditional

where the summation is over the variables in V judged
to be immediate causes of vj . cji is called a path coefficient. j ’s represent “error” terms and are assumed
to have normal distribution. The model structure can
be represented by an ADMG G, called a path diagram,
as follows: the nodes of G are the variables v1 , . . . , vn ;
there is a directed edge from vi to vj in G if vi appears
in the structural equation for vj , that is, cji 6= 0; there
is a bi-directed edge between vi and vj if the error
terms i and j have non-zero correlation. For example, the graph in Figure 2 can serve as the path
diagram for the following SEM,
e = e
d = c1 e + d
a = c2 d + a
b = c3 d + b
c = c4 d + c
Cov(a , b ) 6= 0
Cov(a , c ) 6= 0
Cov(b , c ) 6= 0

(34)

In a linear SEM, conditional independence relations
will correspond to zero partial correlations, that is, a
partial correlation ρxy.Z vanishes (ρxy.Z = 0 if and
only if x is m-separated from y given Z in the path
diagram [Spirtes et al., 1998, Koster, 1999]).
One important task in SEM applications is to test the
model against data. One approach for this task is to
test for the hypothesis ρxy.Z = 0 in the data if whenever x is m-separated from y given Z in the path diagram of the model. We only need to test for the set
of vanishing partial correlations specified by the local
Markov property which will imply all vanishing partial
correlations that hold under the global Markov property. In general, we may need exponential number of
vanishing partial correlation tests based on the ordered
local Markov property (1) given in [Richardson, 2003].
For this test method to be applicable in practice, it
is therefore important to reduce the number of conditional independencies invoked by the local Markov
property. It is known that normal distributions satisfy the composition axiom, therefore the results presented in Section 3 and 4 can be used to reduce the
number of vanishing partial correlation tests. As an
example, consider the SEM given in (34). If we use
the ordered local Markov property (1), then we need
to test for the vanishing of the following set of partial
correlations (see(16)):
{ρae.d , ρbe.d , ρbe.ad , ρce.d , ρce.ad , ρce.bd , ρce.abd }. (35)
On the other hand, based on the result in Section 3,
we only need to test for the vanishing of the following
(see(17)):
{ρae.d , ρbe.d , ρce.d }.

(36)

The number of tests needed is substantially reduced.

6

Conclusion

We show that the potentially exponential number of
conditional independence relations invoked by the local Markov property in ADMGs may be reduced if
the probability distributions satisfy the composition
axiom. In ADMGs with no mixed directed cycles,
only linear number of conditional independence relations are required. In ADMGs with mixed directed
cycles, we give two conditions under which reduction
is possible and we provide a procedure for doing the
reduction. The results have important applications in
testing linear SEMs.
Acknowledgements
The authors thank the anonymous reviewers for helpful comments. This research was partly supported by
NSF grant IIS-0347846.

