
Computing the probability of evidence even with
known error bounds is NP-hard. In this paper we
address this hard problem by settling on an easier
problem. We propose an approximation which
provides high confidence lower bounds on probability of evidence but does not have any guarantees in terms of relative or absolute error. Our
proposed approximation is a randomized importance sampling scheme that uses the Markov inequality. However, a straight-forward application
of the Markov inequality may lead to poor lower
bounds. We therefore propose several heuristic
measures to improve its performance in practice.
Empirical evaluation of our scheme with stateof-the-art lower bounding schemes reveals the
promise of our approach.

1

Introduction

Computing the probability of evidence even with known
error bounds is NP-hard [Dagum and Luby, 1993]. In this
paper we address this hard problem by proposing an approximation that gives high confidence lower bounds on
the probability of evidence but does not have any guarantees of relative or absolute error.
Previous
work
on
bounding
the
probability
of
evidence
comprises
of
deterministic
approximations
[Dechter and Rish, 2003,
Leisink and Kappen, 2003, Bidyuk and Dechter, 2006a]
and sampling based randomized approximations
[Cheng, 2001, Dagum and Luby, 1997].
An approximation algorithm for computing the lower bound is
deterministic if it always outputs an approximation that
is a lower bound. On the other hand, an approximation
algorithm is randomized if the approximation fails with
some probability δ > 0. The work in this paper falls under
the class of randomized approximations.

Randomized
approximations
[Cheng, 2001,
Dagum and Luby, 1997] use known inequalities such
as the Chebyshev and the Hoeffding inequalities
[Hoeffding, 1963] for lower (and upper) bounding
the probability of evidence. The Chebyshev and Hoeffding
inequalities provide bounds on how the sample mean
of N independently and identically distributed random
variables deviates from the actual mean. The main idea
in [Cheng, 2001, Dagum and Luby, 1997] is to express
the problem of computing the probability of evidence as
the problem of computing the mean (or expected value)
of independent random variables and then use the mean
over the sampled random variables to bound the deviation
from the actual mean. The problem with these previous
approaches is that the number of samples required to
guarantee high confidence lower (or upper) bounds is
inversely proportional to the probability of evidence (or
the actual mean). Therefore, if the probability of evidence
is arbitrarily small (e.g. < 10−20 ), a large number of
samples (approximately 1019 ) are required to guarantee
the correctness of the bounds.
We alleviate this problem, which arises from the dependence of the Hoeffding and Chebyshev inequalities on
the number of samples N, by using the Markov inequality which is independent of N. Recently, the Markov inequality was used to lower bound the number of solutions of a Satisfiability formula [Gomes et al., 2007] showing good empirical results. We adapt this scheme to compute lower bounds on probability of evidence and extend
it in several ways. First, we show how importance sampling can be used to obtain lower bounds using the Markov
inequality. Second, we address the difficulty associated
with the approach presented in [Gomes et al., 2007] in that
with the increase in number of samples the lower bound is
likely to decrease by proposing several parametric heuristic methods. Third, we show how the probability of evidence of belief networks with zero probabilities can be efficiently estimated by using the Markov inequality in conjunction with a recently proposed SampleSearch scheme
[Gogate and Dechter, 2007]. Finally, we provide empirical
results demonstrating the potential of our new scheme by

142

GOGATE ET AL.

comparing against state-of-the-art bounding schemes such
as bound propagation [Leisink and Kappen, 2003] and its
improvements [Bidyuk and Dechter, 2006b].
The rest of the paper is organized as follows. In section 2,
we discuss preliminaries and related work. In section 3, we
present our lower bounding scheme and propose various
heuristics to improve it. In section 4, we describe how the
SampleSearch scheme can be used within our lower bounding scheme. Experimental results are presented in section
5 and we end with a summary in section 6.

2

Preliminaries and Previous work

We represent sets by bold capital letters and members of a
set by capital letters. An assignment of a value to a variable
is denoted by a small letter while bold small letters indicate
an assignment to a set of variables.
Definition 1. (belief networks) A belief network (BN) is a
graphical model P = hZ, D, Pi, where Z = {Z1 , . . . , Zn }
is a set of random variables over multi-valued domains
D = {D1 , . . . , Dn }. Given a directed acyclic graph G over
Z, P = {Pi }, where Pi = P(Zi |pa(Zi )) are conditional probability tables (CPTs) associated with each Zi . The set
pa(Zi ) is the set of parents of the variable Zi in G. A belief network represents a probability distribution over Z,
P(Z) = ∏ni=1 P(Zi |pa(Zi )). An evidence set E = e is an instantiated subset of variables.
Definition 2 (Probability of Evidence). Given a belief network P and evidence E = e, the probability of evidence
P(E = e) is defined as:
n

P(e) =

∑ ∏ P(Z j |pa(Z j ))|E=e

(1)

Z\E j=1

To compute the probability of evidence by importance sampling, we use the substitution:
n

f (x) = P(z, e) =

∏ P(Z j |pa(Z j ))|E=e ,
j=1

X = Z\E

(4)

For the rest of the paper, assume M = P(e) and f (x) =
∏nj=1 P(Z j |pa(Z j ))|E=e .
Several choices are available for the proposal distribution Q(x) ranging from the prior distribution as in likelihood weighting to more sophisticated alternatives such as
IJGP-Sampling [Gogate and Dechter, 2005] and EPIS-BN
[Yuan and Druzdzel, 2006] where the output of belief propagation is used to compute the proposal distribution.
As in prior work [Cheng and Druzdzel, 2000], we assume
that the proposal distribution is expressed in a factored
product form dictated by the belief network: Q(X) =
∏ni=1 Qi (Xi |X1 , . . . , Xi−1 ) = ∏ni=1 Qi (Xi |Yi ), where Yi ⊆
{X1 , . . . , Xi−1 }, Qi (Xi |Yi ) = Q(Xi |X1 , . . . , Xi−1 ) and |Yi | < c
for some constant c. When Q is given in a product form ,
we can generate a full sample from Q as follows. For i
= 1 to n, sample Xi = xi from the conditional distribution
Q(Xi |X1 = x1 , . . . , Xi−1 = xi−1 ) and set Xi = xi . This is often referred to as an ordered Monte Carlo sampler.
2.2

Related Work

[Dagum and Luby, 1997] provide an upper bound on the
number of samples N required to guarantee that for any
b computed using Equation 3 apε , δ > 0, the estimate M
proximates M with relative error ε with probability at least
1 − δ . Formally,
b ≤ M(1 + ε )] > 1 − δ
Pr[M(1 − ε ) ≤ M

(5)

The specific bound on N that the authors derive is:
The notation h(Z)|E=e stands for a function h over Z \ E
with the assignment E = e.
2.1

N≥

Importance sampling [Rubinstein, 1981] is a simulation
technique commonly used to evaluate the following sum:
M = ∑x∈X f (x) for some real function f . The idea is to
generate samples x1 , . . . , xN from a proposal distribution Q
(satisfying f (x) > 0 ⇒ Q(x) > 0) and then estimate M as
follows:

b= 1
M
N

N

∑ w(xi ) , where

i=1

w(xi ) =

f (xi )
Q(xi )

4
2
ln
Mε 2 δ

(6)

These bounds were later improved by [Cheng, 2001] to
yield:

Computing Probability of Evidence Using
Importance Sampling

f (x)
f (x)
Q(x) = EQ [
]
M = ∑ f (x) = ∑
Q(x)
Q(x)
x∈X
x∈X

N≥

(2)

(3)

w is often referred to as the sample weight. It is known
b = M [Rubinstein, 1981].
that the expected value E(M)

1
1
2
ln
M (1 + ε )ln(1 + ε ) − ε δ

(7)

In both these bounds (Equations 6 and 7) N is inversely
proportional to M and therefore when M is small, a large
number of samples are required to achieve an acceptable
confidence level (1 − δ ) > 99%.
A bound on N is required because [Dagum and Luby, 1997,
Cheng, 2001] use Chebyshev and Hoeffding inequalities
which depend on N for correctness. Instead, we could use
the Markov inequality which is independent of N and still
achieve high confidence lower bounds. The independence
from N allows us to use even a single sample to derive
lower bounds. The only caveat is that our proposed method
does not have any guarantees in terms of relative error ε .
We describe our method in the next section.

GOGATE ET AL.

3

Markov Inequality to lower bound P(e)

Definition 3 (Markov Inequality). For any random variable
X and k > 1, Pr(X ≥ kE[X]) ≤ 1k
[Gomes et al., 2007] show how the Markov inequality can
be used to obtain probabilistic lower bounds on the number
of solutions of a satisfiability/constraint satisfaction problem. Using the same approach, we present a small modification of importance sampling for obtaining lower bounds
on the probability of evidence (see Algorithm 1). The algorithm generates k independent samples from a proposal
(x)
distribution Q and returns the minimum αfQ(x)
(minCount
in Algorithm 1) over the k-samples.
Algorithm 1 Markov-LB ( f , Q, k, α > 1)
1:
2:
3:
4:
5:
6:

minCount ← ∞
for i = 1 to k do
Generate a sample xi from Q
f (xi )
IF minCount > α ∗Q(xi ) THEN minCount =
end for
Return minCount

f (xi )
α ∗Q(xi )

T HEOREM 1 (Lower Bound). With probability of at least
1 − 1/α k , Markov-LB returns a lower bound on M = P(e)
Proof. Consider an arbitrary sample xi .
It is clear
from the discussion in section 2 that the expected value
of f (xi )/Q(xi ) is equal to M.
Therefore, by the
f (xi )
Pr( α ∗Q(x
i)

Markov inequality, we have
> M) < 1/α .
Since, the generated k samples are independent, the
f (xi )
k
probability Pr(minki=1 α ∗Q(x
i ) > M) < 1/α and therefore
i

f (x )
1
Pr(minki=1 [ α ∗Q(x
i ) ] ≤ M) > 1 − α k .

The problem with Algorithm 1 is that unless the variance
of f (x)/Q(x) is very small, we expect the lower bound to
decrease with increase in the number of samples k. In practice, given a required confidence of δ = α k , one can decrease α as k is increased.
Note that each sample in Algorithm 1 provides a lower
bound with probability > (1 − 1/α ). We can replace the
sample by any procedure that provides a lower bound with
probability > (1 − 1/α ) and therefore in the following
we propose several heuristic methods to compute a lower
bound with probability > (1 − 1/α ).
3.1

3.2

143

Using the maximum over N samples

We can even use the maximum instead of the average over
the N i.i.d samples and still achieve a confidence of 1 −
1/α . Given a set of N independent events such that each
event occurs with probability > (1 − 1/β ), the probability
that all events occur is > (1 − 1/β )N . Consequently, we
can prove that:
Proposition 1. Given N i.i.d. samples generated from Q,
(xi )
N
Pr(maxNi=1 [ βfQ(x
i ) ] < M) > (1 − 1/β ) .
Therefore, by setting (1 − 1/β )N = 1 − 1/α (i.e. β =
1/[1 − (1 − 1/α )1/N ]) and recording the maximum value of
f (xi )/β Q(xi ) over the N samples, we can achieve a lower
bound on M with confidence (1 − 1/α ).
Again the problem with this method is that increasing the
number of samples increases β and consequently the lower
bound decreases. However, when the variance of the random variables f (xi )/Q(xi ) is large, the maximum value is
likely to be larger than the sample average. Another approach to utilize the maximum over the N samples is to use
the martingale inequalities.
3.3

Using the martingale Inequalities

In this subsection, we show how the martingale theory can
be used to obtain lower bounds on P(e).
Definition 4 (Martingale). A sequence of random variables
X1 , . . . , XN is a martingale with respect to another sequence
Z1 , . . . , ZN defined on a common probability space Ω iff
E[Xi |Z1 , . . . , Zi−1 ] = Xi−1 for all i.
Given i.i.d. samples (x1 , . . . , xN ) generated from Q, note
i

p
f (x )
that the sequence Λ1 , . . . , ΛN , where Λ p = ∏i=1
MQ(xi )
forms a martingale as shown below:

E[Λ p |x1 , . . ., x p−1 ]

E[Λ p−1 ∗

=
p

f (x )
1
p−1 ] = 1,
E[ M∗Q(x
p ) |x , . . . , x

Because,

we

have

|x1 , . . . , x p−1 ]

E[Λ p
= Λ p−1 as required. The expected
value E[Λ1 ] = 1 and for such martingales which have
a mean of 1, [Breiman, 1968] provides the following
extension of the Markov inequality:
Pr(maxN
i=1 Λi > α ) ≤

Using Average over N samples

One obvious way is to use the importance sampling estimab Because E[M]
b = M, by Markov inequality M/
b α is a
tor M.
lower bound of M with confidence 1 − 1/α . As the number
of samples increases, the average becomes more stable and
is likely to increase the minimum value over the k iterations
of Algorithm 1.

f (x p )
|x1 , . . ., x p−1 ]
M ∗ Q(x p )
f (x p )
Λ p−1 ∗ E[
|x1 , . . ., x p−1 ]
M ∗ Q(x p )

=

1
α

(8)

and therefore,
i

f (x j )
1
) > α) ≤
j)
MQ(x
α
j=1

Pr((maxN
i=1 ∏

(9)

From
Inequality
9,
we
can
see
that
f (x j ) 1/i
1
i
N
maxi=1 ( α ∏ j=1 [ Q(x j ) ]) is a lower bound on M with a

144

GOGATE ET AL.

confidence of (1 − 1/α ). In general one could use any
randomly selected permutation of the samples (x1 , . . . , xN )
and apply inequality 9.
Another related extension of Markov inequality for martingales deals with the order statistics of the sample. Let
f (x(1) )
MQ(x(1) )

(N)

(2)

f (x )
f (x )
≤ MQ(x
(2) ) ≤ . . . ≤ MQ(x(N) ) be the order statistics
of the sample. Using martingale theory, [Kaplan, 1987]
proved that the random variable

f (x(N− j+1) )

i

Θ∗ = maxN
i=1 ∏

j=1

N
i

M ∗ Q(x(N− j+1) ) ∗

satisfies the inequality Pr(Θ∗ > α ) ≤ 1/α . Therefore,
f (x(N− j+1) )

i

Pr((maxN
i=1 ∏

j=1

From
maxNi=1 ( α1

M ∗ Q(x(N− j+1) ) ∗

Inequality

10,

f (x(N− j+1) )
∏ij=1 [ Q(x(N− j+1) ) N ])1/i
( )

N
i

we
is

) > α) ≤

can
a

1
α

(10)

see

that

lower

bound

i

on M with a confidence of (1 − 1/α ).
To summarize in this section, we have proposed four
heuristic ways to improve Algorithm 1 (1) The average
method, (2) The max method and (3) The martingale random permutation method and (4) The martingale order
statistics method.

4

In the following example, we show how constraints can be
extracted from the CPTs.

Overcoming Rejection: Using
SampleSearch with Markov-LB

One problem with importance sampling based algorithms
is the so-called rejection problem and in this section
we discuss how to alleviate this problem in MarkovLB by using the recently proposed SampleSearch scheme
[Gogate and Dechter, 2007].
4.1

The rejection problem has been largely ignored in the importance sampling community except the work on adaptive
importance sampling techniques [Hernández et al., 1998,
Cheng and Druzdzel, 2000, Yuan and Druzdzel, 2006]. In
[Gogate and Dechter, 2005], we initiated a new approach
of reducing the amount of rejection by using constraint processing methods. The main idea is to express the zero probabilities in the belief network using constraints.
Definition 5 (constraint network). A constraint network
(CN) is defined by a 3-tuple, R = hZ, D, Ci, where Z is
a set of variables Z = {Z1 , . . . , Zn }, associated with a set
of discrete-valued domains, D = {D1 , . . . , Dn }, and a set of
constraints C = {C1 , . . . ,Cr }. Each constraint Ci is a relation RSi defined on a subset of variables Si ⊆ Z. The
relation denotes all compatible tuples of the cartesian product of the domains of Si . A solution is an assignment of
values to all variables z = (Z1 = z1 , . . . , Zn = zn ), zi ∈ Di ,
such that z belongs to the natural join of all constraints i.e.
z ∈ RS1 ⊲⊳ . . . ⊲⊳ RSr . The constraint satisfaction problem
(CSP) is to determine if a constraint network has a solution,
and if so, to find one. When we write R(z), we mean that
z satisfies all the constraints in R.

Rejection Problem

Given a positive belief network that expresses the probability distribution P(Z) = ∏ni=1 P(Zi |Z1 , . . . , Zi−1 ) and an
empty evidence set, all full samples generated by the ordered Monte Carlo sampler along the ordering Z1 , . . . , Zn
are guaranteed to have a non-zero weight. However, in
presence of both zero probabilities and evidence the ordered Monte Carlo sampler may generate samples which
have zero weight because the sample may conflict with the
evidence and zero probabilities. Formally, if the proposal
distribution Q is such that the probability of sampling an assignment from the set {x| f (x) = 0} is substantially larger
than the probability of sampling an assignment from the set
{x| f (x) > 0}, a large number of samples generated from Q
will have zero weight. In fact, in the extreme case if no
positive weight samples are generated, the lower bound reported by the Markov-LB scheme will be trivially zero.

Figure 1: An example Belief Network.
Example 1. Figure 1 presents a belief network over 6
binary variables. The CPTs associated with C and G
have zero probabilities. The constraint extracted from
the CPT of C is the relation RA,C = {(0, 0), (1, 0), (1, 1)}
while the CPT of G yields the constraint relation RD,F,G =
{(0, 0, 0)(0, 1, 0), (1, 0, 1), (1, 1, 0)}. Namely, each ”0” tuple in a CPT corresponds to a no-good, and therefore does
not appear in the corresponding relation.
Our importance sampling scheme called IJGP-Sampling
[Gogate and Dechter, 2005] uses constraint propagation to
reduce rejection. Given a partial sample (x1 , . . . , x p ), constraint propagation prunes values in the domains of future variables Xp+1 , . . . , Xn which are inconsistent with
(x1 , . . . , x p ).
However, we observed recently that when a substantial number of zero probabilities are present or when

GOGATE ET AL.
there are many evidence variables, the level of constraint
propagation achieved by IJGP is not effective and often
few/no consistent samples will be generated. Therefore in
[Gogate and Dechter, 2007], we proposed a more aggressive approach that searches explicitly for a non-zero weight
sample yielding the SampleSearch scheme.
Algorithm 2 SampleSearch
Input: The proposal distribution Q(x) = ∏ni=1 Qi (xi |x1 , . . ., xi−1 ),
hard constraints R that represent zeros in f (x)
Output: A sample x = (x1 , . . ., xn ) satisfying all constraints in R
1: i = 1, D′i = Di (copy domains), Q′i (Xi ) = Qi (Xi ) (copy distribution), x = φ
2: while 1 ≤ i ≤ n do
3: if D′i is not empty then
4:
Sample Xi = xi from Q′i and remove it from D′i
5:
if (x1 , . . ., xi ) violates any constraints in R then
6:
set Qi (xi |x1 , . . ., xi−1 ) = 0 and normalize Q′i
7:
Goto Step 3
8:
end if
9:
x = x ∪ xi , i = i + 1, D′i = Di , Q′i (Xi |x1 , . . ., xi−1 ) =
Qi (Xi |x1 , . . ., xi−1 )
10: else
11:
x = x\xi−1 .
12:
set Q′i−1 (Xi−1 = xi−1 |x1 , . . ., xi−2 ) = 0 and normalize.
13:
set i = i − 1
14: end if
15: end while
16: Return x

4.2

The SampleSearch scheme

An ordered Monte Carlo sampler samples variables in the
order hX1 , . . . , Xn i from the proposal distribution Q and rejects a partial or full sample (x1 , . . . , xi ) if it violates any
constraints in R (R models zero probabilities in f ). Upon
rejecting a (partial or full) sample, the sampler starts sampling anew from the first variable in the ordering. Instead, we propose the following modification. We can set
Qi (Xi = xi |x1 , . . . , xi−1 ) = 0 (to reflect that (x1 , . . . , xi ) is not
consistent), normalize Qi and re-sample Xi from the normalized distribution. The newly sampled value may be
consistent in which case we can proceed to variable Xi+1
or it may be inconsistent. If we repeat the process we
may reach a point where Qi (Xi |x1 , . . . , xi−1 ) is 0 for all values of Xi . In this case, (x1 , . . . , xi−1 ) is inconsistent and
therefore we need to change the distribution at Xi−1 by setting Qi−1 (Xi−1 = xi−1 |x1 , . . . , xi−2 ) = 0, normalize and resample Xi−1 . We can repeat this process until a globally
consistent full sample that satisfies all constraints in R is
generated. By construction, this process always yields a
globally consistent full sample.
Our proposed SampleSearch scheme is described as Algorithm 2. It is a depth first backtracking search (DFS) over
the state space of consistent partial assignments searching
for a solution to a constraint satisfaction problem R, whose
value selection is guided by Q.

145

It can be proved that SampleSearch generates independently and identically distributed samples from the
backtrack-free distribution which we define below.
Definition 6 (Backtrack-free distribution ). Given a distribution Q(X) = ∏Ni=1 Qi (Xi |X1 , . . . , Xi−1 ), an ordering O =
hx1 , . . . , xn i and a set of constraints R, the backtrack-free
distribution QR is the distribution:
n

QR (x) = ∏ QRi (xi |x1 , . . ., xi−1 )

(11)

i=1

where QRi (xi |x1 , . . . , xi−1 ) is given by:
QRi (xi |x1 , . . ., xi−1 ) =

Qi (xi |x1 , . . ., xi−1 )
1 − ∑x′i ∈Bi Qi (x′i |x1 , . . ., xi−1 )

(12)

where Bi = {x′i ∈ Di |(x1 , . . . , xi−1 , x′i ) can not be extended
to a solution of R} and xi ∈
/ Bi . Note that by definition,
f (x) = 0 ⇒ QR (x) = 0 and vice versa.

T HEOREM 2. [Gogate and Dechter, 2007] SampleSearch
generates independently and identically distributed samples from the backtrack-free distribution.
Given that the backtrack-free distribution is the sampling
distribution of SampleSearch, we can use SampleSearch
within the importance sampling framework as follows. Let
(x1 , . . . , xN ) be a set of i.i.d samples generated by SampleSearch. Then we can estimate M = ∑x∈X f (x) as:
N
i
b = 1 ∑ f (x )
M
N i=1 QR (xi )

(13)

Although SampleSearch was described using the naive
backtracking algorithm, in principle we can integrate any
systematic CSP/SAT solver that employs advanced search
schemes with sampling through our SampleSearch scheme.
Since the current implementations of SAT solvers are very
efficient, we represent the zero probabilities in the belief network using cnf (SAT) expressions and use Minisat
[Sorensson and Een, 2005] as our SAT solver.
Computing QR (x) given a sample x:
From Definition 6, we notice that to compute the components QRi (xi |x1 , . . . , xi−1 ) for a sample x = (x1 , . . . , xn ), we
have to determine the set Bi = {x′i ∈ Di |(x1 , . . . , xi−1 , x′i ) can
not be extended to a solution of R}. The set Bi can be
determined by checking for each x′i ∈ Di if the partial assignment (x1 , . . . , xi−1 , x′i ) can be extended to a solution of
R. To speed up this checking at each branch point, we use
the Minisat SAT solver [Sorensson and Een, 2005]. Minisat should be invoked a maximum of O(n ∗ (d − 1)) times
where n is the number of variables and d is the maximum
domain size.
In [Gogate and Dechter, 2007], we found that the SampleSearch based importance sampling scheme outperforms all
competing approaches when a substantial number of zero

146

GOGATE ET AL.

probabilities are present in the belief network. Therefore,
we employ SampleSearch as a sampling technique within
Markov-LB when a substantial number of zero probabilities are present. It should be obvious that when Samplei
Search is used, we should use QfR(x(x)i ) as a random variable
instead of

5
5.1

f (xi )
Q(xi )

P(c1 , ..., cq , e), q < |C|, for a polynomial number of partially instantiated tuples of subset C, resulting in:
h

k′

i=1

i=1

L
P(e) ≥ ∑ P(ci , e) + ∑ PBP
(ci1 , ..., ciq , e)

(15)

L (c , ..., c , e) is obtained using
where lower bound PBP
q
1
bound propagation. Although bound propagation bounds
marginal probabilities, it can be used to bound any joint
probability P(z) as follows:

in the Markov-LB scheme.

Empirical Evaluation
Competing Algorithms

L
L
PBP
(z) = ∏ PBP
(zi |z1 , ..., zi−1 )

(16)

i

Markov-LB with SampleSearch and IJGP-sampling:
The performance of importance sampling based algorithms is highly dependent on the proposal distribution
[Cheng and Druzdzel, 2000, Yuan and Druzdzel, 2006]. It
was shown that computing the proposal distribution from
the output of a Generalized Belief Propagation scheme
of Iterative Join Graph Propagation (IJGP) yields better empirical performance than other available choices
[Gogate and Dechter, 2005]. Therefore, we use the output
of IJGP to compute the proposal distribution Q. The complexity of IJGP is time and space exponential in its i-bound,
a parameter that bounds cluster sizes. We use a i-bound of 3
in all our experiments. The preprocessing time for computing the proposal distribution using IJGP (i = 3) was negligible (< 2 seconds for the hardest instances).
We experimented with four versions of Markov-LB (a)
Markov-LB as given in Algorithm 1, (b) Markov-LB with
the average heuristic, (c) Markov-LB with the martingale
random permutation heuristic and (d) Markov-LB with the
martingale order statistics heuristic. In all our experiments,
we set α = 2 and k = 7 which gives us a correctness confidence of 1 − 1/27 ≈ 99.2% on our lower bounds. Finally,
we set N = 100 for the heuristic methods. Also note that
when the belief network is positive we use IJGP-sampling
but when the belief network has zero probabilities, we use
SampleSearch whose initial proposal distribution Q is computed from the output of IJGP.
Bound Propagation with Cut-set Conditioning We also
experimented with the state of the art any-time bounding
scheme that combines sampling-based cut-set conditioning
and bound propagation [Leisink and Kappen, 2003] and
which is a part of Any-Time Bounds framework for bounding posterior marginals [Bidyuk and Dechter, 2006a].
Given a subset of variables C ⊂ X\E, we can compute
P(e) exactly as follows:
k

P(e) = ∑ P(ci , e)

(14)

i=1

The lower bound on P(e) is obtained by computing
P(ci , e) for h high probability tuples of C (selected
through sampling) and bounding the remaining probability mass by computing a lower bound PL (c1 , ..., cq , e) on

L (z |z , ..., z
where lower bound PBP
i 1
i−1 ) is computed
directly by bound propagation.
We use here the
same variant of bound propagation described in
[Bidyuk and Dechter, 2006b] that is used by the AnyTime Bounds framework. The lower bound obtained by
Eq. 15 can be improved by exploring a larger number of
tuples h. After generating h tuples by sampling, we can
stop the computation at any time after bounding p < k′ out
of k′ partially instantiated tuples and produce the result.

In our experiments we run the bound propagation with cutset conditioning scheme until convergence or until a stipulated time bound has expired. Finally, we should note that
the bound propagation with cut-set conditioning scheme
provides deterministic lower and upper bounds on P(e)
while our Markov-LB scheme provides only a lower bound
and it may fail with a probability δ ≤ 0.01.
5.1.1 Evaluation Criteria
We experimented with six sets of benchmark belief networks (a) Alarm networks (b) CPCS networks, (c) Randomly generated belief networks, (d) Linkage networks,
(e) Grid networks and (f) Two-layered deterministic networks. Note that only linkage, grid and deterministic networks have zero probabilities.
On each network instance, we compare log relative error
between the exact probability of evidence and the lower
bound reported by the competing techniques. Formally, if
Pexact is the actual probability of evidence and Papp is the
approximate probability of evidence, we compute the logrelative error as follows:
∆ = Abs(

log(Pexact ) − log(Papp )
)
log(Pexact )

(17)

Note that the exact P(e) for most instances is available from
the UAI competition web-site 1 . The exact P(e) for the
two layered deterministic networks was computed using
AND/OR search [Dechter and Mateescu, 2004].
We compute the log relative error instead of the usual relative error because when the probability of evidence is
1 http://ssli.ee.washington.edu/∼bilmes/uai06InferenceEvaluation/

GOGATE ET AL.

Table 1: Results on various benchmarks. The columns Min, Avg,
Per and Ord give the log-relative-error ∆ for the minimum, the
average, the martingale random permutation and the martingale
order statistics heuristics respectively. The last two columns provide log-relative-error ∆ and time for the bound propagation with
cut-set conditioning scheme. In the first column N is the number
of variables, D is the maximum domain size and E is the number
of evidence variables. Time is in seconds. The column best LB
reports the best lower bound reported by all competing scheme
whose log-relative error is highlighted in each row.

(N, D, |E|)
Alarm
(100,2,36)
(100,2,51)
(125,2,55)
(125,2,71)
(125,2,46)
CPCS
(360,2,20)
(360,2,30)
(360,2,40)
(360,2,50)
(422,2,20)
(422,2,30)
(422,2,40)
(422,2,50)
Random
(53,50,6)
(54,50,5)
(57,50,6)
(58,50,8)
(76,50,15)

Exact
P(e)

IJGP-sampling-Markov-LB
Bound
Min Avg Per Ord
Propagation
∆
∆
∆
∆ Time ∆ Time

Best
LB

2.8E-13
3.6E-18
1.8E-19
4.3E-26
8.0E-18

0.157 0.031 0.040 0.059
0.119 0.023 0.040 0.045
0.095 0.020 0.021 0.030
0.124 0.016 0.024 0.030
0.185 0.023 0.061 0.064

0.2
0.1
0.2
0.2
0.1

0.090
0.025
0.069
0.047
0.102

22.3
5.6
36.0
19.3
31.6

1.1E-13
1.4E-18
7.7E-20
1.6E-26
3.3E-18

1.3E-25
7.6E-22
1.2E-33
3.4E-38
7.2E-21
2.7E-57
6.9E-87
1.4E-73

0.012 0.012 0.000 0.001
0.045 0.015 0.010 0.010
0.010 0.009 0.000 0.000
0.022 0.009 0.002 0.000
0.028 0.016 0.001 0.001
0.005 0.005 0.000 0.000
0.003 0.003 0.000 0.000
0.007 0.004 0.000 0.000

1.2
1.2
1.2
1.2
8.4
8.3
8.1
8.5

0.002
0.000
0.000
0.000
0.002
0.000
0.001
0.001

13.2
16.3
26.8
19.2
120
120
120
120

1.3E-25
7.6E-22
1.2E-33
3.4E-38
6.8E-21
2.7E-57
6.9E-87
1.3E-73

0.235 0.029 0.063 0.025 0.8
0.408 0.036 0.095 0.013 0.6
0.131 0.024 0.013 0.024 0.8
0.521 0.022 0.079 0.041 0.9
0.039 0.007 0.007 0.012 2.0
SampleSearch-Markov-LB
Exact Min Avg Per Ord
P(e)
∆
∆
∆
∆ Time

4.0E-11
2.1E-09
1.9E-11
1.6E-14
1.5E-26

0.028 1.5
0.131 4.6
0.147 5.9
0.134 13.0
0.056 19.1
Bound
Propagation
∆ Time

(N, D, |E|)
Grid
(1156,2,120) 9.1E-12 0.256 0.040 0.106 0.047 3.5 0.946
(1444,2,150) 2.4E-12 0.208 0.094 0.111 0.107 5.3 3.937
(1444,2,150) 3.5E-15 0.269 0.090 0.131 0.097 5.3 3.067
(1444,2,150) 4.9E-10 0.243 0.093 0.090 0.108 4.3 5.380
(1444,2,150) 4.6E-11 0.103 0.086 0.065 0.069 5.7 4.458
(1444,2,150) 5.2E-14 0.127 0.100 0.079 0.098 3.7 3.456
Linkage
(777,36,78) 2.8E-54 0.243 0.176 0.169 0.153 8.6 1.022
(2315,36,159) 8.8E-72 0.390 0.340 0.347 0.340 40.7 1.729
(1740,36,202) 1.4E-111 0.438 0.235 0.323 0.235 30.8 0.984
(2155,36,252) 7.5E-151 0.196 0.128 0.196 0.128 41.6 0.298
(2140,36,216) 6.1E-114 0.419 0.311 0.354 0.311 48.3 1.560
(749,36,66) 2.2E-45 0.954 0.780 0.949 0.761 9.3 5.314
(1820,36,155) 2.1E-91 0.258 0.215 0.236 0.208 45.8 2.209
(2155,36,169) 1.4E-110 0.475 0.374 0.435 0.374 128.2 0.712
(1020,36,135) 2.8E-79 0.262 0.198 0.225 0.185 18.4 1.385
Two-layered
(1000,2,800) 8.8E-26 0.059 0.024 0.032 0.029 12.2 11.01
(1000,2,800) 3.2E-28 0.076 0.030 0.045 0.042 10.5 9.95
(1000,2,800) 1.2E-27 0.061 0.019 0.020 0.024 7.7 10.19
(1000,2,800) 4.3E-26 0.109 0.050 0.060 0.061 13.0 10.87
(1000,2,800) 1.2E-26 0.115 0.036 0.055 0.046 20.5 10.61

2.2E-11
1.6E-09
1.4E-11
8.1E-15
9.4E-27
Best
LB

33.9
600
600
600
600
600

3.3E-12
2.0E-13
1.7E-16
7.2E-11
9.6E-12
4.6E-15

3600
3600
3600
3600
3600
3600
3600
3600
3600

1.8E-62
6.3E-96
1.2E-137
4.2E-170
4.0E-149
2.4E-79
3.0E-110
1.2E-151
8.9E-94

3600
3600
3600
3600
3600

2.2E-26
4.9E-29
3.9E-28
2.3E-27
1.4E-27

extremely small the relative error between the exact and
the approximate probability of evidence will be arbitrarily
close to 1 and we would need a large number of digits to
determine the best performing competing scheme.
5.2

Results

Our results are summarized in Table 1. We see that our
new strategy of Markov-LB scales well with problem size
and provides good quality high-confidence lower bounds

147

on most problems. It clearly outperforms the bound propagation with cut-set conditioning scheme. We discuss the
results in detail below.
The Alarm networks The Alarm networks are one of the
earliest belief networks designed by medical experts for
monitoring patients in intensive care. The evidence in these
networks was set at random. These networks have between 100-125 binary nodes. We can see that Markov-LB
is slightly superior to the bound propagation based scheme
accuracy-wise, but is far more efficient time-wise. Among
the different versions of Markov-LB, the average heuristic
performs better than the martingale heuristics. The minimum heuristic is the worst performing heuristic.
The CPCS networks The CPCS networks are derived
from the Computer-based Patient Case Simulation system
[Pradhan et al., 1994]. The nodes of CPCS networks correspond to diseases and findings and conditional probabilities
describe their correlations. The CPCS360b and CPCS422b
networks have 360 and 422 variables respectively. We report results on the two networks with 20,30,40 and 50 randomly selected evidence nodes. We see that the lower
bounds reported by the bound propagation based scheme
are slightly better than Markov-LB on the CPCS360b networks but they take far more time. However, on the
CPCS422b networks, Markov-LB has better performance
than the bound propagation based scheme. The martingale
heuristics (the random permutation and the order statistics)
have better performance than the average heuristic. Again,
the minimum heuristic has the worst performance. Note
that we stop each algorithm after 2 mins of run-time if the
algorithm has not terminated by itself.
Random networks The random networks are randomly
generated graphs available from the UAI competition website. The evidence nodes are generated at random. The
networks have between 53 and 76 nodes and the maximum
domain size is 50. We see that Markov-LB is better than the
bound propagation based scheme on all random networks.
The random permutation and the ordered statistics martingale heuristics are slightly better than the average heuristic
on most instances.
Grid Networks The Grid instances are also available from
the UAI competition web-site. All nodes in the Grid are
binary and evidence nodes are selected at random. The
Grid networks have substantial amount of determinism and
therefore we employ the SampleSearch based importance
sampling scheme to compute the lower bound. Here, we
stop each algorithm after 10 minutes if it has not terminated by itself. We notice that the performance of MarkovLB is significantly better than the bound propagation based
scheme on all instances.
Linkage networks The linkage instances are generated by converting a Pedigree to a Bayesian network
[Fishelson and Geiger, 2003]. These networks have be-

148

GOGATE ET AL.

tween 777-2315 nodes with a maximum domain size of
36 and are much larger than the Alarm, the CPCS, and
the random networks. On these networks, we ran each
algorithm until termination or until a time-bound of 1hr
expired. The Linkage instances have a large number of
zero probabilities which makes them hard for traditional
importance sampling based schemes because of the rejection problem. Therefore, in all our experiments on linkage instances we used the SampleSearch based importance
sampling scheme. On Linkage instances, IJGP-sampling
did not return a single non-zero weight sample (not shown
in Table 1) in more than one-hour of run-time yielding a
lower bound of 0. We see that the bound propagation based
scheme yields inferior lower bounds as compared to the
SampleSearch based Markov-LB scheme. However, we
notice that the log-relative-error is significantly higher for
Markov-LB on the linkage instances than the Alarm, the
CPCS, and the random instances. We suspect that this is
because the quality of the proposal distribution computed
from the output of IJGP is not as good on the linkage instances as compared to other instances. Finally, we notice
that the average and the martingale-heuristics perform better than the min heuristic on all instances with the martingale order statistics heuristic being the best performing
heuristic.

using the SampleSearch scheme. Our experimental results
on a range of benchmarks show that our new lower bounding scheme outperforms the state-of-the-art bound propagation scheme and provides high confidence good quality
lower bounds on most instances.

Deterministic two-layered networks Our final domain
is that of completely deterministic two-layered networks.
Here, the first layer is a set of root nodes connected to a second layer of leaf nodes. The CPTs of the root node are such
that each value in the domain is equally likely while the
CPTs associated with the leaf nodes are deterministic i.e.
each CPT entry is either one or a zero. All nodes are binary.
The evidence set is all the leaf nodes instantiated to a value.
We experimented with 5 randomly generated 1000-variable
two-layered networks each with 800 leaf nodes which are
set to true (evidence). We employ the SampleSearch based
importance sampling scheme for these networks because
these instances have zero probabilities. We see that the average and the martingale heuristics are the best performing heuristics while the min-heuristic performs the worst.
The SampleSearch based Markov-LB scheme shows significantly better performance than the bound propagation
based scheme.

[Dechter and Mateescu, 2004] Dechter, R. and Mateescu, R. (2004). Mixtures of
deterministic-probabilistic networks and their and/or search space. In UAI.

6

Conclusion and Summary

In this paper, we proposed a randomized approximation algorithm, Markov-LB for computing high confidence lower
bounds on probability of evidence. Markov-LB is based on
importance sampling and the Markov inequality. A straight
forward application of the Markov inequality may lead to
poor lower bounds and therefore we suggest various heuristic measures to improve Markov-LB’s performance. We
also show how the performance of Markov-LB can be improved further on belief networks with zero probabilities by

ACKNOWLEDGEMENTS
This work was supported in part by the NSF under award
numbers IIS-0331707 and IIS-0412854.



The paper introduces AND/OR importance sampling for probabilistic graphical models. In contrast to importance sampling, AND/OR importance sampling caches samples in the AND/OR
space and then extracts a new sample mean from
the stored samples. We prove that AND/OR importance sampling may have lower variance than
importance sampling; thereby providing a theoretical justification for preferring it over importance sampling. Our empirical evaluation demonstrates that AND/OR importance sampling is far
more accurate than importance sampling in many
cases.

1

Introduction

Many problems in graphical models such as computing
the probability of evidence in Bayesian networks, solution
counting in constraint networks and computing the partition
function in Markov random fields are summation problems,
defined as a sum of a function over a domain. Because these
problems are NP-hard, sampling based techniques are often
used to approximate the sum. The focus of the current paper
is on importance sampling.
The main idea in importance sampling [Geweke, 1989,
Rubinstein, 1981] is to transform the summation problem
to that of computing a weighted average over the domain
by using a special distribution called the proposal (or importance) distribution. Importance sampling then generates
samples from the proposal distribution and approximates
the true average over the domain by an average over the
samples; often referred to as the sample average. The sample average is simply a ratio of the sum of sample weights
and the number of samples, and it can be computed in a
memory-less fashion since it requires keeping only these
two quantities in memory.
The main idea in this paper is to equip importance sampling
with memoization or caching in order to exploit conditional

independencies that exist in the graphical model. Specifically, we cache the samples on an AND/OR tree or graph
[Dechter and Mateescu, 2007] which respects the structure
of the graphical model and then compute a new weighted
average over that AND/OR structure, yielding, as we show,
an unbiased estimator that has a smaller variance than the
importance sampling estimator. Similar to AND/OR search
[Dechter and Mateescu, 2007], our new AND/OR importance sampling scheme recursively combines samples that
are cached in independent components yielding an increase
in the effective sample size which is part of the reason that
its estimates have lower variance.
We present a detailed experimental evaluation comparing
importance sampling with AND/OR importance sampling
on Bayesian network benchmarks. We observe that the
latter outperforms the former on most benchmarks and in
some cases quite significantly.
The rest of the paper is organized as follows. In the next
section, we describe preliminaries on graphical models, importance sampling and AND/OR search spaces. In sections
3, 4 and 5 we formally describe AND/OR importance sampling and prove that its sample mean has lower variance
than conventional importance sampling. Experimental results are described in section 6 and we conclude with a discussion of related work and summary in section 7.

2 Preliminaries
We represent sets by bold capital letters and members of a
set by capital letters. An assignment of a value to a variable
is denoted by a small letter while bold small letters indicate
an assignment to a set of variables.
Definition 2.1 (belief networks). A belief network (BN) is
a graphical model R = (X, D, P), where X = {X1 , . . . , Xn }
is a set of random variables over multi-valued domains
D = {D1 , . . . , Dn }. Given a directed acyclic graph G over
X, P = {Pi }, where Pi = P(Xi |pa(Xi )) are conditional probability tables (CPTs) associated with each Xi . pa(Xi ) is
the set of parents of the variable Xi in G. A belief network represents a probability distribution over X, P(X) =

0

AND

C

AND

0

OR

B

[A]

B

OR

0

E

D

B [AB]

0

[CBA] C

F

G

E [EAB]

[DBC] D

(a)

0

1

OR

D

D

0

0

C

E

AND

AND

1

C

OR

1

0 1 0 1

(b)

1

0

1

B
C

OR
AND

B

1
AND

A

1

A

OR

B

A

OR

A

0

1

D

D

0

1

0 1 0 1

C

E

0

1

D

D

0 1 0 1

C

E

C

E

E

1

C

E

C

E

0

1

AND

0

1

OR

D

D

0

1

0

1

D

D

0

1

0

1

D

D

0

1

0

1

D

D

0

1

E

0

1

D

D

0

1

AND

0 1 0 1

0 1 0 1

(c)

0 1 0 1

(d)

Figure 1: (a) Bayesian Network, (b) Pseudo-tree (c) AND/OR tree (d) AND/OR search graph
∏ni=1 P(Xi |pa(Xi )). An evidence set E = e is an instantiated
subset of variables.The moral graph (or primal graph) of a
belief network is the undirected graph obtained by connecting the parent nodes and removing direction.
Definition 2.2 (Probability of Evidence). Given a belief
network R and evidence E = e, the probability of evidence
P(E = e) is defined as:
n

P(e) =

∑ ∏ P(X j |pa(X j ))|E=e

(1)

X\E j=1

The notation h(X)|E=e stands for a function h over X \ E
with the assignment E = e.
2.1

AND/OR search spaces

We can compute probability of evidence by search, by accumulating probabilities over the search space of instantiated variables. In the simplest case, this process defines an
OR search tree, whose nodes represent partial variable assignments. This search space does not capture the structure of the underlying graphical model. To remedy this
problem, [Dechter and Mateescu, 2007] introduced the notion of AND/OR search space. Given a bayesian network
R = (X, D, P), its AND/OR search space is driven by a
pseudo tree defined below.
Definition 2.3 (Pseudo Tree). Given an undirected graph
G = (V, E), a directed rooted tree T = (V, E) defined on all
its nodes is called pseudo tree if any arc of G which is not
included in E is a back-arc, namely it connects a node to an
ancestor in T .
Definition 2.4 (Labeled AND/OR tree). Given a graphical model R = hX, D, Pi, its primal graph G and a backbone pseudo tree T of G, the associated AND/OR search
tree, has alternating levels of AND and OR nodes. The OR
nodes are labeled Xi and correspond to the variables. The
AND nodes are labeled hXi , xi i and correspond to the value
assignments in the domains of the variables. The structure
of the AND/OR search tree is based on the underlying backbone tree T . The root of the AND/OR search tree is an OR
node labeled by the root of T .
Each OR arc, emanating from an OR node to an
AND node is associated with a label which can
be derived from the CPTs of the bayesian network

[Dechter and Mateescu, 2007]. Each OR node and AND
node is also associated with a value that is used for computing the quantity of interest.
Semantically, the OR states represent alternative assignments, whereas the AND states represent problem decomposition into independent subproblems, all of which
need be solved.
When the pseudo-tree is a chain,
the AND/OR search tree coincides with the regular OR
search tree. The probability of evidence can be computed from a labeled AND/OR tree by recursively computing the value of all nodes from leaves to the root
[Dechter and Mateescu, 2007].
Example 2.5. Figure 1(a) shows a bayesian network over
seven variables with domains of {0, 1}. F and G are evidence nodes. Figure 1(c) shows the AND/OR-search tree
for the bayesian network based on the Pseudo-tree in Figure
1(b). Note that because F and G are instantiated, the search
space has only 5 variables.
2.2 Computing Probability of Evidence Using
Importance Sampling
Importance sampling [Rubinstein, 1981] is a simulation
technique commonly used to evaluate the sum, M =
∑x∈X f (x) for some real function f . The idea is to generate
samples x1 , . . . , xN from a proposal distribution Q (satisfying f (x) > 0 ⇒ Q(x) > 0) and then estimate M as follows:
M=

∑

x∈X

f (x) =

f (x)

f (x)

∑ Q(x) Q(x) = EQ [ Q(x) ]

(2)

x∈X

N
i
b = 1 ∑ w(xi ) , where w(xi ) = f (x )
M
N i=1
Q(xi )

(3)

w is often referred to as the sample weight. It is known that
b = M [Rubinstein, 1981].
the expected value E(M)
To compute the probability of evidence by importance sampling, we use the substitution:
n

f (x) = ∏ P(X j |pa(X j ))|E=e

(4)

j=1

Several choices are available for the proposal distribution Q(x) ranging from the prior distribution as in likelihood weighting to more sophisticated alternatives such as

IJGP-Sampling [Gogate and Dechter, 2005] and EPIS-BN
[Yuan and Druzdzel, 2006] where the output of belief propagation is used to compute the proposal distribution.
As in prior work [Cheng and Druzdzel, 2000], we assume that the proposal distribution is expressed in a factored product form: Q(X) = ∏ni=1 Qi (Xi |X1 , . . . , Xi−1 ) =
∏ni=1 Qi (Xi |Yi ), where Yi ⊆ {X1 , . . . , Xi−1 }, Qi (Xi |Yi ) =
Q(Xi |X1 , . . . , Xi−1 ) and |Yi | < c for some constant c. We
can generate a full sample from Q as follows. For i =
1 to n, sample Xi = xi from the conditional distribution
Q(Xi |X1 = x1 , . . . , Xi−1 = xi−1 ) and set Xi = xi .

3

AND/OR importance sampling

We first discuss computing expectation by parts; which
forms the backbone of AND/OR importance sampling. We
then present the AND/OR importance sampling scheme
formally and derive its properties.
3.1

Estimating Expectation by Parts

In Equation 2, the expectation of a multi-variable function
is computed by summing over the entire domain. This
method is clearly inefficient because it does not take into
account the decomposition of the multi-variable function as
we illustrate below.
Consider the tree graphical model given in Figure 2(a).
Let A = a and B = b be the evidence variables. Let
Q(ZXY ) = Q(Z)Q(X|Z)Q(Y |Z) be the proposal distribution. For simplicity, let us assume that f (Z) = P(Z),
f (XZ) = P(Z|X)P(A = a|X) and f (Y Z) = P(Z|Y )P(B =
b|Y ). We can express probability of evidence P(a, b) as:
f (Z) f (XZ) f (Y Z)
Q(Z)Q(X|Z)Q(Y |Z)
Q(Z)Q(X|Z)Q(Y
|Z)
XY Z


f (Z) f (XZ) f (Y Z)
=E
Q(Z)Q(X|Z)Q(Y |Z)

P(a, b) =

(5)

We can decompose the expectation in Equation 5 into
smaller components as follows:

Z

f (Z)Q(Z)
Q(Z)

∑
X

f (XZ)Q(X|Z)
Q(X|Z)

!

∑
Y

f (Y Z)Q(Y |Z)
Q(Y |Z)

!

 

f (Z)
f (XZ)
f (Y Z)
P(a, b) = ∑
E
|Z E
|Z Q(Z)
Q(X|Z)
Q(Y |Z)
Z Q(Z)



 

f (XZ)
f (Y Z)
f (Z)
E
|Z E
|Z
P(a, b) = E
Q(Z)
Q(X|Z)
Q(Y |Z)

1
gX\
(Z = j) =
Nj

f (xi , Z = j)I(xi , Z = j)
Q(xi , Z = j)

∑

f (yi , Z = j)I(yi , Z = j)
Q(yi , Z = j)

i=1
N
i=1

(9)

From Equation 8, we can now derive the following unbiased
estimator for P(a, b):
1
N

=

N j f (Z = j)gX\
(Z = j)gY\
(Z = j)
Q(Z = j)
j=0
1

∑

(10)

Importance sampling on the other hand would estimate
P(a, b) as follows:
1
^
P(a,
b) =
N

(7)
×

(8)

N

∑

where I(xi , Z = j) (or I(yi , Z = j)) is an indicator function
which is 1 iff the tuple (xi , Z = j) ( or (yi , Z = j) ) is generated in any of the N samples and 0 otherwise.

(6)

By definition, Equation 7 can be written as:


Assume
that
we
are
given
samples
(z1 , x1 , y1 ), . . . , (zN , xN , yN ) generated from Q decomposed according to Figure 2(a). For simplicity, let {0, 1} be
the domain of Z and let Z = 0 and Z = 1 be sampled
h N0 andi
f (XZ)
|Z
N1 times respectively. We can approximate E Q(X|Z)
h
i
f (Y Z)
and E Q(Y |Z) |Z by gX\
(Z = j) and gY\
(Z = j) defined
below:

\
P(a,
b)

The quantities in the two brackets in Equation 6 are, by definition, conditional expectations of a function over X and Y
respectively given Z. Therefore, Equation 6 can be written
as:


Importance sampling ignores the decomposition of expectation while approximating it by the sample average. Our
new algorithm estimates the true expectation by decomposing it into several conditional expectations and then approximating each by an appropriate weighted average over the
samples. Since computing expectation by parts is less complex than computing expectation by summing over the domain; we expect that approximating it by parts will be easier as well. We next illustrate how to estimate expectation
by parts on our example Bayesian network given in Figure
2(a).

1
gY\
(Z = j) =
Nj

∑

P(a, b) = ∑

We will refer to Equations of the form 8 as expectation by
parts borrowing from similar terms such as integration and
summation by parts. If the domain size of all variables is
d = 3, for example, computing expectation using Equation 5 would require summing over d 3 = 33 = 27 terms
while computing the same expectation by parts would require summing over d + d 2 + d 2 = 3 + 32 + 32 = 21 terms.
Therefore, exactly computing expectation by parts is clearly
more efficient.

1
Nj

1

f (Z = j)

∑ N j Q(Z = j)

j=0
N

f (xi , Z = j) f (yi , Z = j)

∑ Q(xi |Z = j)Q(Y i |Z = j) I(xi , yi , Z = j)

(11)

i=1

where I(xi , yi , Z = j) is an indicator function which is 1 iff
the tuple (xi , yi , Z = j) is generated in any of the N samples
and 0 otherwise.

Z
P(Z)
Z

Z=0

Z=1

0.8

0.2

P(X|Z)

X=0

X=1

X=2

Z=0

0.3

0.4

0.3

P(Y|Z)

Y=0

Y=1

Y=2

Z=1

0.2

0.7

0.1

Z=0

0.5

0.1

0.4

Z=1

0.2

0.6

0.2

P(B|Y)

B=0

Y

X
P(A|X)

A=0

A=1

X=0

0.1

0.9

X=1

0.2

0.8

X=2

0.6

A

B

0.4

B=1

Y=0

0.2

0.9

Y=1

0.7

0.8

Y=2

0.1

0.4

Evidence A=0, B=0

<1.6,2>

0

Sample #

Z

X

Y

1

0

1

0

2

0

2

1

3

1

1

1

4

1

2

0

X

X

Y

2

0

Y
<0.12,1>
<0.08,1>

<0.14,1>

<0.16,1>

Q(XYZ)=uniform distribution

(a)

1

<0.36,1> <0.2,1>
1

P( Z = 1) 0.2
=
= 0.4
Q( Z = 1) 0.5

<0.4,2>

<0.28,1>

1

<0.84,1>
1

2

0

1

P( X = 1 | Z = 0) P( A = 0 | X = 1) (0.4)(0.2)
=
= 0.16
Q( X = 1 | Z = 0)
0.5

(b)

(c)

Figure 2: (a) Bayesian Network, its CPTs, (b) Proposal Distribution and Samples (c) AND/OR sample tree
Equation 10 which is an unbiased estimator of expectation
by parts given in Equation 8 provides another rationale for
preferring it over the usual importance sampling estimator
given by Equation 11. In particular in Equation 10, we
estimate two functions defined over the random variables
X|Z = z and Y |Z = z respectively from the generated samples. In importance sampling, on the other hand, we estimate a function over the joint random variable XY |Z = z using the generated samples. Because the samples for X|Z = z
and Y |Z = z are considered independently in Equation 10,
N j samples drawn over the joint random variable XY |Z = z
in Equation 11 correspond to a larger set N j ∗ N j = N 2j of
virtual samples. We know that [Rubinstein, 1981] the variance (and therefore the mean-squared error) of an unbiased
estimator decreases with an increase in the effective sample
size. Consequently, our new estimation technique will have
lower error than the conventional approach.
In the following subsection, we discuss how the AND/OR
structure can be used for estimating expectation by parts
yielding the AND/OR importance sampling scheme.
3.2

Computing Sample Mean in AND/OR-space

In this subsection, we formalize the ideas of estimating
expectation by parts on a general AND/OR tree starting
with some required definitions. We define the notion of an
AND/OR sample tree which is restricted to the generated
samples and which will be used to compute the AND/OR
sample mean. The labels on this AND/OR tree are set to
account for the importance weights.
Definition 3.1 (Arc Labeled AND/OR Sample Tree).
Given a a graphical model R = hX, D, Pi, a pseudo-tree
T (V, E) , a proposal distribution Q = ∏ni=1 Q(Xi |Anc(Xi ))
such that Anc(Xi ) is a subset of all ancestors of Xi in
T , a sequence of assignments (samples) S and a complete
AND/OR search tree φT , an AND/OR sample tree SAOT is
constructed from φT by removing all edges and corresponding nodes which are not in S i.e. they are not sampled.
The Arc-label for an OR node Xi to an AND node Xi = xi
in SAOT is a pair hw, #i where:
P(Xi =xi ,anc(xi ))
• w = Q(X
is called the weight of the arc.
i =xi |anc(xi ))
anc(xi ) is the assignment of values to all variables

from the node Xi to the root node of SAO and P(Xi =
xi , anc(xi )) is the product of all functions in R that
mention Xi but do not mention any variable ordered
below it in T given (Xi = xi , anc(xi )).
• # is the frequency of the arc. Namely, it is equal to
the number of times the assignment (Xi = xi , anc(xi ))
is sampled.
Example 3.2. Consider again the Bayesian network given
in Figure 2(a). Assume that the proposal distribution
Q(XY Z) is uniform. Figure 2(b) shows four hypothetical random samples drawn from Q. Figure 2(c) shows the
AND/OR sample tree over the four samples. Each arc from
an OR node to an AND node in the AND/OR sample tree
is labeled with appropriate frequencies and weights according to Definition 3.1. Figure 2(c) shows the derivation of
arc-weights for two arcs.
The main virtue of arranging the samples on an AND/OR
sample tree is that we can exploit the independencies to define the AND/OR sample mean.
Definition 3.3 (AND/OR Sample Mean). Given a
AND/OR sample tree with arcs labeled according to Definition 3.1, the value of a node is defined recursively as
follows. The value of leaf AND nodes is ”1” and the value
of leaf OR nodes is ”0”. Let C(n) denote the child nodes
and v(n) denotes the value of node n. If n is a AND node
then: v(n) = ∏n′ ∈C(n) v(n′ ) and if n is a OR node then
v(n) =

∑n′ ∈C(n) (#(n, n′ )w(n, n′ )v(n′ ))
∑n′ ∈C(n) #(n, n′ )

The AND/OR sample mean is the value of the root node.
We can show that the value of an OR node is equal to an
unbiased estimate of the conditional expectation of the variable at the OR node given an assignment from the root to
the parent of the OR node. Since all variables, except the
evidence variables are unassigned at the root node, the value
of the root node equals the AND/OR sample mean which is
an unbiased estimate of probability of evidence. Formally,
T HEOREM 3.4. The AND/OR sample mean is an unbiased
estimate of probability of evidence.
Example 3.5. The calculations involved in computing the
sample mean on the AND/OR sample tree on our example

(2 ×1.6 × 0.0442) + (2 × 0.4 × 0.092)
= 0.05376
4
Z
<1.6,2>

<0.4,2>

0.26 * 0.17 = 0.0442

0.2 * 0.46 = 0.092

0

1
0.28 + 0.12
0.16 + 0.36
= 0.2
= 0.26
0.2 + 0.14
2
= 0.17
2
2
X
X
Y
<0.12,1>
<0.36,1> <0.2,1>
<0.08,1>
<0.16,1>
<0.14,1>
<0.28,1>
1

2

0

1

1

2

0

0.08 + 0.84
= 0.46
2
Y

constant domain size), the time complexity of computing
AND/OR sample mean is O(nN) (same as importance sampling) and its space complexity is O(nN) (the space complexity of importance sampling is constant).

4 Variance Reduction

<0.84,1>
1

Figure 3: Computation of Values of OR and AND nodes in
a AND/OR sample tree. The value of root node is equal to
the AND/OR sample mean
Bayesian network given in Figure 2 are shown in Figure
3. Each AND node and OR node in Figure 3 is marked
with a value that is computed recursively using definition
3.3. The value of OR nodes X and Y given Z = j ∈ {0, 1}
is equal to gX\
(Z = j) and gY\
(Z = j) respectively defined
in Equation 9. The value of the root node is equal to the
AND/OR sample mean which is equal to the sample mean
computed by parts in Equation 10.
Algorithm 1 AND/OR Importance Sampling
Input: an ordering O = (X1 , . . . , Xn ),a Bayesian network BN and
a proposal distribution Q
Output: Estimate of Probability of Evidence
1: Generate samples x1 , . . . , xN from Q along O.
2: Build a AND/OR sample tree SAOT for the samples x1 , . . . , xN
along the ordering O.
3: Initialize all labeling functions hw, #i on each arc from an Ornode n to an And-node n′ using Definition 3.1.
4: FOR all leaf nodes i of SAOT do
5: IF And-node v(i)= 1 ELSE v(i)=0
6: For every node n from leaves to the root do
7: Let C(n) denote the child nodes of node n
8: IF n = hX, xi is a AND node, then v(n) = ∏n′ ∈C(n) v(n′ )
9: ELSE if n = X is a OR node then
∑n′ ∈C(n) (#(n, n′ )w(n, n′ )v(n′ ))
v(n) =
.
∑n′ ∈C(n) #(n, n′ )
10: Return v(root node)

We now have the necessary definitions to formally present
the AND/OR importance sampling scheme (see Algorithm
1). In Steps 1-3, the algorithm generates samples from Q
and stores them on an AND/OR sample tree. The algorithm then computes the AND/OR sample mean over the
AND/OR sample tree recursively from leaves to the root in
Steps 4 − 9. We can show that the value v(n) of a node
in the AND/OR sample tree stores the sample average of
the subproblem rooted at n, subject to the current variable
instantiation along the path from the root to n. If n is the
root, then v(n) is the AND/OR sample mean which is our
AND/OR estimator of probability of evidence. Finally, we
summarize the complexity of computing AND/OR sample
mean in the following theorem:
T HEOREM 3.6. Given N samples and n variables (with

In this section, we prove that the AND/OR sample mean
may have lower variance than the sample mean computed
using importance sampling (Equation 3).
T HEOREM 4.1 (Variance Reduction). Variance of AND/OR
sample mean is less than or equal to the variance of importance sampling sample mean.
Proof. The details of the proof are quite complicated and
therefore we only provide the intuitions involved. As noted
earlier the guiding principle of AND/OR sample mean is to
take advantage of conditional independence in the graphical model. Let us assume that we have three random variables X, Y and Z with the following relationship: X and Y
are independent of each other given Z (similar to our example Bayesian network). The expression for variance derived
here can be used in an induction step (induction is carried
on the nodes of the pseudo tree) to prove the theorem.
In this case, importance sampling generates samples
((x1 , y1 , z1 ), . . . , (xN , yN , zN )) along the order hZ, X, Yi and
estimates the mean as follows:
∑Ni=1 xi yi zi
(12)
N
Without loss of generality, let {z1 , z2 } be the domain of Z
and let these values be sampled N1 and N2 times respectively. We can rewrite Equation 12 as follows:

µ IS (XYZ) =

µ IS (XYZ) =

1
N

2

∑ N j zj

j=1

∑Ni=1 xi yi I(z j , xi , yi )
Nj

(13)

where I(z j , xi , yi ) is an indicator function which is 1 iff the
partial assignment (z j , xi , yi ) is generated in any of the N
samples and 0 otherwise.
AND/OR sample mean is defined as:
µ AO (XYZ) =

1
N

2

∑ Njz j

j=1



∑Ni=1 xi I(z j ,xi )
Nj



∑Ni=1 yi I(z j ,yi )
Nj



(14)

where I(x j , zi ) (and similarly I(y j , zi )) is an indicator function which equals 1 when one of the N samples contains the
tuple (x j , zi ) (and similarly (y j , zi ))) and is 0 otherwise.
By simple algebraic manipulations, we can prove that the
variance of estimator µ IS (XYZ) is given by:
Var(µ IS (XYZ)) =

2



∑ z2j Q(zj )

j=1

µ (X|z j )2V (Y|z j )+

!

2
µ (Y|z j ) V (X|z j ) +V (X|z j )V (Y|zj ) /N − µXYZ
/N
2

(15)

Similarly, the variance of AND/OR sample mean is given
by:
Var(µ AO (XYZ)) =

2



∑ z2j Q(zj )

j=1

µ (X|z j )2V (Y|z j )

!
V (X|z j )V (Y|zj ) 
2
/N
+ µ (Y|z j ) V (X|z j ) +
/N − µXYZ
Nj
2

(16)

where µ (X|z j ) and V (X|z j ) are the conditional mean and
variance respectively of X given Z = z j . Similarly, µ (Y|z j )
and V (Y|z j ) are the conditional mean and variance respectively of Y given Z = z j .
From Equations 15 and 16, if N j = 1 for all j, then we can
see that the Var(µ AO (XYZ)) = Var(µ IS (XYZ)). However
if N j > 1, Var(µ AO (XYZ)) < Var(µ IS (XYZ)). This proves
that the variance of AND/OR sample mean is less than or
equal to the variance of conventional sample mean on this
special case. As noted earlier using this case in induction
over the nodes of a general pseudo-tree completes the proof.

5

Estimation in AND/OR graphs

Next, we describe a more powerful algorithm for
estimating mean in AND/OR-space by moving from
AND/OR-trees to AND/OR graphs as presented in
[Dechter and Mateescu, 2007]. An AND/OR-tree may contain nodes that root identical subtrees. When such unifiable
nodes are merged, the tree becomes a graph and its size
becomes smaller. Some unifiable nodes can be identified
using contexts defined below.
Definition 5.1 (Context). Given a belief network and the
corresponding AND/OR search tree SAOT relative to a
pseudo-tree T , the context of any AND node hXi , xi i ∈ SAOT
, denoted by context(Xi ), is defined as the set of ancestors
of Xi in T , that are connected to Xi and descendants of Xi .
The context minimal AND/OR graph is obtained by merging all the context unifiable AND nodes. The size of the
largest context is bounded by the tree width w∗ of the
pseudo-tree [Dechter and Mateescu, 2007]. Therefore, the
time and space complexity of a search algorithm traversing
the context-minimal AND/OR graph is O(exp(w∗ )).
Example 5.2. For illustration, consider the contextminimal graph in Figure 1(e) of the pseudo-tree from Figure 1(c). Its size is far smaller that that of the AND/OR tree
from Figure 2(c) (30 nodes vs. 38 nodes). The contexts of
the nodes can be read from the pseudo-tree in Figure 1(b)
as follows: context(A) = {A}, context(B) = {B,A}, context(C) = {C,B,A}, context(D) = {D,C,B} and context(E) =
{E,A,B}.
The main idea in AND/OR-graph estimation is to store all
samples on an AND/OR-graph instead of an AND/OR-tree.

Similar to an AND/OR sample tree, we can define an identical notion of an AND/OR sample graph.
Definition 5.3 ( Arc labeled AND/OR sample graph).
Given a complete AND/OR graph φG and a set of samples S
, an AND/OR sample graph SAOG is obtained by removing
all nodes and arcs not in S from φG . The labels on SAOG are
set similar to that of an AND/OR sample tree (see Definition 3.1).
Example 5.4. The bold edges and nodes in Figure 1(c) define an AND/OR sample tree. The bold edges and nodes in
Figure 1(d) define an AND/OR sample graph corresponding to the same samples that define the AND/OR sample
tree in Figure 1(c).
The algorithm for computing the sample mean on AND/OR
sample graphs is identical to the algorithm for AND/ORtree (Steps 4-10 of Algorithm 1). The main reason in moving from trees to graphs is that the variance of the sample
mean computed on an AND/OR sample graph can be even
smaller than that computed on an AND/OR sample tree.
More formally,
T HEOREM 5.5. Let V (µAOG ), V (µAOT ) and V (µIS ) be the
variance of AND/OR sample mean on an AND/OR sample
graph, variance of AND/OR sample mean on an AND/OR
sample tree and variance of sample mean of importance
sampling respectively. Then given the same set of input
samples:
V (µAOG ) ≤ V (µAOT ) ≤ V (µIS )
We omit the proof due to lack of space.
T HEOREM 5.6 (Complexity of computing AND/OR graph
sample mean). Given a graphical model with n variables,
a psuedo-tree with treewidth w∗ and N samples, the time
complexity of AND/OR graph sampling is O(nNw∗ ) while
its space complexity is O(nN).

6 Experimental Evaluation
6.1 Competing Algorithms
The performance of importance sampling based algorithms is highly dependent on the proposal distribution
[Cheng and Druzdzel, 2000]. It was shown that computing
the proposal distribution from the output of a Generalized
Belief Propagation scheme of Iterative Join Graph Propagation (IJGP) yields better empirical performance than other
available choices [Gogate and Dechter, 2005]. Therefore,
we use the output of IJGP to compute the proposal distribution Q. The complexity of IJGP is time and space exponential in its i-bound, a parameter that bounds cluster sizes.
We use a i-bound of 5 in all our experiments.
We experimented with three sampling algorithms for
benchmarks which do not have determinism: (a) (pure)
IJGP-sampling, (b) AND/OR-tree IJGP-sampling and (c)
AND/OR-graph IJGP-sampling. Note that the underlying
scheme for generating the samples is identical in all the

2.35e-11
2.3e-11
2.25e-11
2.2e-11
2.15e-11
2.1e-11
2.05e-11
2e-11
1.95e-11
1.9e-11
10

20

30

Grid Networks All Grid instances have 1444 binary nodes
and between 5-10 evidence nodes. From Figures 5(a) and
5(b), we can see that AND/OR-graph SampleSearch and
AND/OR-tree SampleSearch are substantially better than
pure SampleSearch.
Linkage Networks The linkage instances are generated by converting a Pedigree to a Bayesian network
[Fishelson and Geiger, 2003]. These networks have between 777-2315 nodes with a maximum domain size of
36. Note that it is hard to compute exact probability of evidence in these networks [Fishelson and Geiger, 2003]. We
observe from Figures 6(a),(b) (c) and (d) that AND/ORgraph SampleSearch is substantially more accurate than
AND/OR-tree SampleSearch which in turn is substantially
more accurate than pure SampleSearch. Notice the logscale in Figures 6 (a)-(d) which means that there is an order of magnitude difference between the errors. Our results
suggest that AND/OR-graph and tree estimators yield far
better performance than conventional estimators especially
on problems in which the proposal distribution is a bad approximation of the posterior distribution.

70

80

90

100

Random BN-102 : n=76,d=50,|E|=15
2.2e-26
2.15e-26
2.1e-26
2.05e-26
2e-26
1.95e-26
1.9e-26
1.85e-26
1.8e-26
1.75e-26
1.7e-26
20

30

40

50

60

70

80

90

100

Time in Seconds
IJGP-Sampling
AND/OR-Graph-IJGP-Sampling
AND/OR-Tree-IJGP-Sampling
Exact

(b)

Figure 4: Random Networks
Grids BN-30: n=1156,d=2,|E|=120
3e-11

P(e)

2.5e-11
2e-11
1.5e-11
1e-11
5e-12
100

200

300

400

500

600

700

800

900 1000

Time in Seconds
SampleSearch
AND/OR-Graph-SampleSearch
AND/OR-Tree-SampleSearch
Exact

(a)
Grids BN-40 : n=1444,d=2,|E|=150

P(e)

Random Networks From Figures 4(a) and 4(b), we see
that AND/OR-graph sampling is better than AND/OR-tree
sampling which in turn is better than pure IJGP-sampling.
However there is not much difference in the error because
the proposal distribution seems to be a very good approximation of the posterior.

60

(a)

10

Our results are presented in Figures 4-6. Each Figure shows
approximate probability of evidence as a function of time.
The bold line in each Figure indicates the exact probability of evidence. The reader can visualize the error from
the distance between the approximate curves and the exact line. For lack of space, we show only part of our results. Each Figure shows the number of variables n, the
maximum-domain size d and the number of evidence nodes
|E| for the respective benchmark.

50

IJGP-Sampling
AND/OR-Graph-IJGP-Sampling
AND/OR-Tree-IJGP-Sampling
Exact

Results

We experimented with three sets of benchmark belief networks (a) Random networks, (b) Linkage networks and (c)
Grid networks. Note that only linkage and grid networks
have zero probabilities on which we use SampleSearch.The
exact P(e) for most instances is available from the UAI
2006 competition web-site.

40

Time in Seconds

P(e)

6.1.1

Random BN-98 : n=57,d=50,|E|=6

P(e)

methods. What changes is the method of accumulating the
samples and deriving the estimates. On benchmarks which
have zero probabilities or determinism, we use the SampleSearch scheme introduced by [Gogate and Dechter, 2007]
to overcome the rejection problem. We experiment with the
following versions of SampleSearch on deterministic networks: (a) pure SampleSearch, (b) AND/OR-tree SampleSearch and (c) AND/OR-graph SampleSearch.

7.5e-14
7e-14
6.5e-14
6e-14
5.5e-14
5e-14
4.5e-14
4e-14
3.5e-14
3e-14
100

200

300

400

500

600

700

800

900 1000

Time in Seconds
SampleSearch
AND/OR-Graph-SampleSearch
AND/OR-Tree-SampleSearch
Exact

(b)

Figure 5: Grid Networks

7 Related Work and Summary
The work presented in this paper is related to the
work by [Hernndez and Moral, 1995, Kjærulff, 1995,
Dawid et al., 1994] who perform sampling based inference on a junction tree. The main idea in these
papers is to perform message passing on a junction
tree by substituting messages which are too hard to
compute exactly by their sampling-based approx-

Log P(e)

linkage-instance n=777,d=36,|E|=78
-122
-123
-124
-125
-126
-127
-128
-129
-130
-131
1000

1500

2000

2500

3000

3500

4000

4500

5000

Time in Seconds
SampleSearch
AND/OR-Graph-SampleSearch
AND/OR-Tree-SampleSearch
Exact

(a)

Log P(e)

linkage-instance n=1820,d=36,|E|=155
-200
-210
-220
-230
-240
-250
-260
-270
-280
1000

1500

2000

2500

3000

3500

4000

4500

5000

Time in Seconds
SampleSearch
AND/OR-Graph-SampleSearch
AND/OR-Tree-SampleSearch
Exact

linkage-instance n=1020,d=36,|E|=135

This work was supported in part by the NSF under award
numbers IIS-0331707, IIS-0412854 and IIS-0713118 and
the NIH grant R01-HG004175-02.

-175
-180

Log P(e)

To summarize, the paper introduces a new sampling based
estimation technique called AND/OR importance sampling. The main idea of our new scheme is to derive statistics on the generated samples by using an AND/OR tree or
graph that takes advantage of the independencies present
in the graphical model. We proved that the sample mean
computed on an AND/OR tree or graph may have smaller
variance than the sample mean computed using the conventional approach. Our experimental evaluation is preliminary but quite promising showing that on most instances
AND/OR sample mean has lower error than importance
sampling and sometimes by significant margins.
Acknowledgements

(b)

-185
-190
-195
-200



Many representation schemes combining firstorder logic and probability have been proposed
in recent years. Progress in unifying logical and
probabilistic inference has been slower. Existing methods are mainly variants of lifted variable elimination and belief propagation, neither
of which take logical structure into account. We
propose the first method that has the full power
of both graphical model inference and first-order
theorem proving (in finite domains with Herbrand
interpretations). We first define probabilistic theorem proving, their generalization, as the problem of computing the probability of a logical formula given the probabilities or weights of a set of
formulas. We then show how this can be reduced
to the problem of lifted weighted model counting, and develop an efficient algorithm for the latter. We prove the correctness of this algorithm,
investigate its properties, and show how it generalizes previous approaches. Experiments show
that it greatly outperforms lifted variable elimination when logical structure is present. Finally, we
propose an algorithm for approximate probabilistic theorem proving, and show that it can greatly
outperform lifted belief propagation.

1

INTRODUCTION

Unifying first-order logic and probability enables uncertain
reasoning over domains with complex relational structure,
and is a long-standing goal of AI. Proposals go back to
at least Nilsson [27], with substantial progress within the
UAI community starting in the 1990s (e.g., [1, 19, 40]), and
added impetus from the new field of statistical relational
learning starting in the 2000s [16]. Many well-developed
representations now exist (e.g., [9, 14, 23]), but the state
of inference is less advanced. For the most part, inference
is still carried out by converting models to propositional
form (e.g., Bayesian networks) and then applying standard
propositional algorithms. This typically incurs an exponen-

tial blowup in the time and space cost of inference, and forgoes one of the chief attractions of first-order logic: the
ability to perform lifted inference, i.e., reason over large
domains in time independent of the number of objects they
contain, using techniques like resolution theorem proving
[32].
In recent years, progress in lifted probabilistic inference has
picked up. An algorithm for lifted variable elimination was
proposed by Poole [29] and extended by de Salvo Braz [10]
and others. Lifted belief propagation was introduced by
Singla and Domingos [38] and extended by others (e.g.,
[21, 36]). These algorithms often yield impressive efficiency gains compared to propositionalization, but still fall
well short of the capabilities of first-order theorem proving,
because they ignore logical structure, treating potentials as
black boxes. This paper proposes the first full-blown probabilistic theorem prover, capable of exploiting both lifting
and logical structure, and having standard theorem proving
and standard graphical model inference as special cases.
Our solution is obtained by reducing probabilistic theorem
proving (PTP) to lifted weighted model counting. We first
do the corresponding reduction for the propositional case,
extending previous work by Darwiche [6] and Sang et al.
[34] (see also [4]). We then lift this approach to the firstorder level, and refine it in several ways. We show that
our algorithm can be exponentially more efficient than firstorder variable elimination, and is never less efficient (up to
constants). For domains where exact inference is not feasible, we propose a sampling-based approximate version of
our algorithm. Finally, we report experiments in which PTP
greatly outperforms first-order variable elimination and belief propagation, and discuss future research directions.

2

LOGIC AND THEOREM PROVING

We begin with a brief review of propositional logic, firstorder logic and theorem proving [15]. The simplest formulas in propositional logic are atoms: individual symbols representing propositions that may be true of false in a
given world. More complex formulas are recursively built
up from atoms and the logical connectives ¬ (negation),
∧ (conjunction), ∨ (disjunction), ⇒ (implication) and ⇔

Algorithm 1 TP(KB K, query Q)
KQ ← K ∪ {¬Q}
return ¬SAT(CNF(KQ ))

(equivalence). For example, ¬A ∨ (B ∧ C) is true iff A is
false or B and C are true. A knowledge base (KB) is a set of
logical formulas. The fundamental problem in logic is determining entailment, and algorithms that do this are called
theorem provers. A knowledge base K entails a query formula Q iff Q is true in all worlds where all the formulas
in K are true, a world being an assignment of truth values to all atoms. A world is a model of a KB iff the KB
is true in it. Theorem provers typically first convert K and
Q to conjunctive normal form (CNF). A CNF formula is
a conjunction of clauses, each of which is a disjunction of
literals, each of which is an atom or its negation. For example, the CNF of ¬A ∨ (B ∧ C) is (¬A ∨ B) ∧ (¬A ∨ C). A
unit clause consists of a single literal. Entailment can then
be computed by adding ¬Q to K and determining whether
the resulting KB KQ is satisfiable, i.e., whether there exists
a world where all clauses in KQ are true. If not, KQ is unsatisfiable, and K entails Q. Algorithm 1 shows this basic
theorem proving schema. CNF(K) converts K to CNF, and
SAT(C) returns True if C is satisfiable and False otherwise.
The earliest theorem prover is the Davis-Putnam algorithm
(henceforth called DP) [8]. It makes use of the resolution
rule: if a KB contains the clauses A1 ∨ . . . ∨ An and B1 ∨
. . . ∨ Bm , where the a’s and b’s represent literals, and some
literal Ai is the negation of some literal Bj , then the clause
A1 ∨ . . . ∨ Ai−1 ∨ Ai+1 ∨ . . . ∨ An ∨ B1 ∨ . . . ∨ Bj−1 ∨
Bj+1 ∨ . . . ∨ Bm can be added to the KB. For each atom
A in the KB, DP resolves every pair of clauses C1 , C2 in
KB such that C1 contains A and C2 contains ¬A, adds the
result to the KB, and deletes C1 and C2 . If at some point
the empty clause is derived, the KB is unsatisfiable, and the
query formula (previously negated and added to the KB) is
therefore proven. As Dechter [11] points out, DP is in fact
just the variable elimination algorithm for the special case
of 0-1 potentials.
Modern propositional theorem provers use the DPLL algorithm [7], a variant of DP that replaces the elimination step
with a splitting step: instead of eliminating all clauses containing the chosen atom A, resolve all clauses in the KB
with A, simplify and recurse, and do the same with ¬A. If
both recursions fail, the KB is unsatisfiable. DPLL has linear space complexity, compared to exponential for DavisPutnam. DPLL is the basis of the algorithms in this paper.
First-order logic inherits all the features of propositional
logic, and in addition allows atoms to have internal structure. An atom is now a predicate symbol, representing a
relation in the domain of interest, followed by a parenthesized list of variables and/or constants, representing objects. For example, Friends(Anna, x) is an atom. A
ground atom has only constants as arguments. First-order
logic has two additional connectives, ∀ (universal quan-

tification) and ∃ (existential quantification). For example,
∀x Friends(Anna, x) means that Anna is friends with everyone, and ∃x Friends(Anna, x) means that Anna has at
least one friend. In this paper, we assume that domains are
finite (and therefore function-free) and that there is a oneto-one mapping between constants and objects in the domain (Herbrand interpretations).
As long as the domain is finite, first-order theorem proving
can be carried out by propositionalization: creating atoms
from all possible combinations of predicates and constants,
and applying a propositional theorem prover. However, this
is potentially very inefficient. A more sophisticated alternative is first-order resolution [32], which proceeds by resolving pairs of clauses and adding the result to the KB until
the empty clause is derived. Two first-order clauses can be
resolved if they contain complementary literals that unify,
i.e., there is a substitution of variables by constants or other
variables that makes the two literals identical up to the negation sign. Conversion to CNF is carried out as before, with
the additional step of removing all existential quantifiers by
a process called skolemization.
First-order logic allows knowledge to be expressed vastly
more concisely than propositional logic. For example, the
rules of chess can be stated in a few pages in first-order
logic, but require hundreds of thousands in propositional
logic. Probabilistic logical languages extend this power to
uncertain domains. The goal of this paper is to similarly
extend the power of first-order theorem proving.

3

PROBLEM DEFINITION

Following Nilsson [27], we define probabilistic theorem
proving as the problem of determining the probability of an
arbitrary query formula Q given a set of logical formulas Fi
and their probabilities P (Fi ). For the problem to be well
defined, the probabilities must be consistent, and Nilsson
[27] provides a method for verifying consistency. Probabilities estimated by maximum likelihood from an observed
world are guaranteed to be consistent [13]. In general, a set
of formula probabilities does not specify a complete joint
distribution over the atoms appearing in them, but one can
be obtained by making the maximum entropy assumption:
the distribution contains no information beyond that specified by the formula probabilities [27]. Finding the maximum entropy distribution given a set of formula probabilities is equivalent to learning a maximum-likelihood loglinear model whose features are the formulas; many algorithms for this purpose are available (iterative scaling, gradient descent, etc.) [13].
We call a set of formulas and their probabilities together
with the maximum entropy assumption a probabilistic
knowledge base (PKB). Equivalently, a PKB can be directly
defined as a log-linear model with the formulas as features
and the corresponding weights or potential values. Potentials are the most convenient form, since they allow determinism (0-1 probabilities) without recourse to infinity. If x

LWSAT

Lifted

TP 1

PTP = LWMC

LMC

MPE = WSAT
ted
igh
e
W Counting

PI = WMC

TP 0 = SAT
MC
Figure 1: Inference problems addressed in this paper. TPo and
TP1 is propositional and first-order theorem proving respectively,
PI is probabilistic inference (computing marginals), MPE is computing the most probable explanation, SAT is satisfiability, MC is
model counting, W is weighted and L is lifted. A = B means A
can be reduced to B.

is a world and Φi (x) is the potential corresponding to formula Fi , by convention (and without loss of generality) we
let Φi (x) = 1 if Fi is true, and Φi (x) = φi ≥ 0 if the formula is false. Hard formulas have φi = 0 and soft formulas have φi > 0. In order to compactly subsume standard
probabilistic models, we interpret a universally quantified
formula as a set of features, one for each grounding of the
formula, as in Markov logic [14]. A PKB {(Fi , φi )} thus
represents the joint distribution
1 Y ni (x)
P (X = x) =
φ
,
(1)
Z i i
where ni (x) is the number of false groundings of Fi in x,
and Z is a normalization constant (the partition function).
We can now define PTP succinctly as follows:
Probabilistic theorem proving (PTP)
Input: Probabilistic KB K and query formula Q
Output: P (Q|K)
If all formulas are hard, a PKB reduces to a standard logical KB. Determining whether a KB K logically entails a
query Q is equivalent to determining whether P (Q|K) = 1
[14]. Graphical models are easily converted into equivalent PKBs [4]. Conditioning on evidence is done by adding
the corresponding hard ground atoms to the PKB, and the
conditional marginal of an atom is computed by issuing the
atom as the query. Thus PTP has both logical theorem proving and inference in graphical models as special cases. In
this paper we solve PTP by reducing it to lifted weighted
model counting. Model counting is the problem of determining the number of worlds that satisfy a KB. Weighted
model counting can be defined as follows [4]. Assign a
weight to each literal, and let the weight of a world be the
product of the weights of the literals that are true in it. Then
weighted model counting is the problem of determining the
sum of the weights of the worlds that satisfy a KB:

Algorithm 2 WCNF(PKB K)
for all (Fi , φi ) ∈ K s.t. φi > 0 do
K ← K ∪ {(Fi ⇔ Ai , 0)} \ {(Fi , φi )}
C ← CNF(K)
for all ¬Ai literals do W¬Ai ← φi
for all other literals L do WL ← 1
return (C, W )

Algorithm 3 PTP(PKB K, query Q)
KQ ← K ∪ {(Q, 0)}
return WMC(WCNF(KQ ))/WMC(WCNF(K))

addressed by this paper. Generality increases in the direction of the arrows. We first propose an algorithm for
propositional weighted model counting and then lift it to
first-order. The resulting algorithm is applicable to all the
problems in the diagram. (Weighted SAT/MPE inference
requires replacing sums with maxes and an additional traceback step, but we do not pursue this here; cf. Park [28], and
de Salvo Braz [10] on the lifted case.)

4

PROPOSITIONAL CASE

This section generalizes the Bayesian network inference
techniques in Darwiche [5] and Sang et al. [34] to arbitrary propositional PKBs, evidence, and query formulas.
Although this is of value in its own right, its main purpose
is to lay the groundwork for the first-order case.
The probability of a formula is the sum of the probabilities
of the worlds that satisfy it. Thus to compute the probability
of a formula Q given a PKB K it suffices to compute the
partition function of K with and without Q added as a hard
formula:
P
Q
Z(K ∪ {(Q, 0)})
x 1Q (x)
i Φi (x)
P (Q|K) =
=
Z(K)
Z(K)
(2)
where 1Q (x) is the indicator function (1 if Q is true in x
and 0 otherwise).
In turn, the computation of partition functions can be reduced to weighted model counting using the procedure in
Algorithm 2. This replaces each soft formula Fi in K by
a corresponding hard formula Fi ⇔ Ai , where Ai is a new
atom, and assigns to every ¬Ai literal a weight of φi (the
value of the potential Φi when Fi is false).
Theorem 1 Z(K) = WMC(WCNF(K)).

Weighted model counting (WMC)
Input: CNF C and set of literal weights W
Output: Sum of weights of worlds that satisfy C

Proof. If a world violates any of the hard clauses in K or
any of the Fi ⇔ Ai equivalences, it does not satisfy C and is
therefore not counted. The weight of each remaining world
x is the product of the weights of the literals that are true in
x. By the Fi ⇔ Ai equivalences
and the weights assigned
Q
by WCNF(K), this is i Φi (x). (Recall that Φi (x) = 1 if
Fi is true in x and Φi (x) = φi otherwise.) Thus x’s weight
is the unnormalized probability of x under K. Summing
these yields the partition function Z(K).
2

Figure 1 depicts graphically the set of inference problems

Equation 2 and Theorem 1 lead to Algorithm 3 for PTP.

Algorithm 4 WMC(CNF C, weights W )

Algorithm 5 LWMC(CNF C, substs. S, weights W )

// Base case
if all clauses
Q in C are satisfied then
return A∈A(C) (WA + W¬A )
if C has an empty unsatisfied clause then return 0
// Decomposition step
if C can be partitioned into CNFs C1 , . . . , Ck sharing no
atoms then
Qk
return i=1 WMC(Ci , W )
// Splitting step
Choose an atom A
return WA WMC(C|A; W ) + W¬A WMC(C|¬A; W )

// Lifted base case
if all clauses
Q in C are satisfied then
return A∈A(C) (WA + W¬A )nA (S)
if C has an empty unsatisfied clause then return 0
// Lifted decomposition step
if there exists a lifted decomposition {C1,1 , . . . , C1,m1 ,
. . . , Ck,1
Q,k. . . , Ck,mk } of C under S then
return i=1 [LWMC(Ci,1 , S, W )]mi
// Lifted splitting step
Choose an atom A
(1)
(l)
Let {ΣA,S , . . . , ΣA,S } be a lifted split of A for C under S

Pl

(Compare with Algorithm 1.) WMC(C, W ) can be any
weighted model counting algorithm [4]. Most model counters are variations of Relsat, itself an extension of DPLL
[3]. Relsat splits on atoms until the CNF is decomposed
into sub-CNFs sharing no atoms, and recurses on each subCNF. This decomposition is crucial to the efficiency of the
algorithm. In this paper we use a weighted version of Relsat, shown in Algorithm 4. A(C) is the set of atoms that
appear in C. C|A denotes the CNF obtained by resolving
each clause in C with A, which results in removing ¬A
from all clauses it appears in, and setting to Satisfied all
clauses in which A is true. Notice that, unlike in DPLL, satisfied clauses cannot simply be deleted, because we need to
keep track of which atoms they are over for model counting
purposes. However, they can be ignored in the decomposition step, since they introduce no dependencies. The atom
to split on in the splitting step can be chosen using various
heuristics [35].
Theorem 2 Algorithm WMC(C,W ) correctly computes the
weighted model count of CNF C under literal weights W .
Proof sketch. If all clauses in C are satisfied, all assignments to the atoms
Q in C satisfy it, and the corresponding
total weight is A∈A(C) (WA + W¬A ). If C has an empty
unsatisfied clause, it is unsatisfiable given the truth assignment so far, and the corresponding weighted count is 0. If
two CNFs share no atoms, the WMC of their conjunction is
the product of the WMCs of the individual CNFs. Splitting
on an atom produces two disjoint sets of worlds, and the total WMC is therefore the sum of the WMCs of the two sets,
weighted by the corresponding literal’s weight.
2

5

FIRST-ORDER CASE

We now lift PTP to the first-order level. We consider first
the case of PKBs without existential quantifiers. Algorithms 2 and 3 remain essentially unchanged, except that
formulas, literals and CNF conversion are now first-order.
In particular, for Theorem 1 to remain true, each new atom
Ai in Algorithm 2 must now consist of a new predicate
symbol followed by a parenthesized list of the variables and
constants in the corresponding formula Fi . The proof of the
first-order version of the theorem then follows by propositionalization. Lifting Algorithm 4 is the focus of the rest of
this section.

fi
LWMC(C|σj ; Sj , W )
return i=1 ni WAti W¬A
where ni , ti , fi , σj and Sj are as in Proposition 3

We begin with some necessary definitions. A substitution
constraint is an expression of the form x = y or x 6= y, where
x is a variable and y is either a variable or a constant. (Much
richer substitution constraint languages are possible, but we
adopt the simplest one that allows PTP to subsume both
standard function-free theorem proving and first-order variable elimination.) Two literals are unifiable under a set of
substitution constraints S if there exists at least one ground
literal consistent with S that is an instance of both, up to the
negation sign. A (C, S) pair, where C is a first-order CNF
whose variables have been standardized apart and S is a set
of substitution constraints, represents the ground CNF obtained by replacing each clause in C with the conjunction
of its groundings that are consistent with the constraints in
S. For example, using upper case for constants and lower
case for variables, if C = R(B, C) ∧ (¬R(x, y) ∨ S(y, z))
and S = {x = y, z 6= B}, (C, S) represents the ground CNF
R(B, C)∧(¬R(B, B)∨S(B, C))∧(¬R(C, C)∨S(C, C)). Clauses
with equality substitution constraints can be abbreviated in
the obvious way (e.g., T(x, y, z) with x = y and z = C can
be abbreviated as T(x, x, C)).
We lift the base case, decomposition step, and splitting step
of Algorithm 4 in turn. The result is shown in Algorithm 5.
In addition to the first-order CNF C and weights on firstorder literals W , LWMC takes as an argument an initially
empty set of substitution constraints S which, similar to
logical theorem proving, is extended along each branch of
the inference as the algorithm progresses.
5.1

LIFTING THE BASE CASE

The base case changes only by raising each first-order atom
A’s sum of weights to nA (S), the number of groundings of
A compatible with the constraints in S. This is necessary
and sufficient since each atom A has nA (S) groundings,
and all ground atoms are independent because the CNF is
satisfied irrespective of their truth values. Note that nA (S)
is the number of groundings of A consistent with S that can
be formed using all the constants in the original CNF.

5.2

LIFTING THE DECOMPOSITION STEP

Clearly, if C can be decomposed into two or more CNFs
such that no two CNFs share any unifiable literals, a lifted
decomposition of C is possible (i.e., a decomposition of C
into first-order CNFs on which LWMC can be called recursively). But the symmetry of the first-order representation can be further exploited. For example, if the CNF
C can be decomposed into k CNFs C1 , . . . , Ck sharing no
unifiable literals and such that for all i, j, Ci is identical to
Cj up to a renaming of the variables and constants,1 then
LWMC(C) = [LWMC(C1 )]k . We formalize these conditions below.
Definition 1 The set of first-order CNFs {C1,1 , . . . ,
C1,m1 , . . . , Ck,1 , . . . , Ck,mk } is called a lifted decomposition of CNF C under substitution constraints S if, given
S, it satisfies the following three properties: (i) C =
C1,1 ∧ . . . ∧ Ck,mk ; (ii) no two Ci,j ’s share any unifiable
literals; (iii) for all i, j, j 0 , such that j 6= j 0 , Ci,j is identical
to Ci,j 0
Proposition 1 If {C1,1 , . . . , C1,m1 , . . . , Ck,1 , . . . , Ck,mk }
is a lifted decomposition of C under S, then
k
Y
LWMC(C, S, W ) =
[LWMC(Ci,1 , S, W )]mi . (3)
i=1

Rules for identifying lifted decompositions can be derived
in a straightforward manner from the inversion argument in
de Salvo Braz [10] and the power rule in Jha et al. [20].
An example of such a rule is given in the definition and
proposition below. Note that this rule is more general than
de Salvo Braz’s inversion elimination [10].
Definition 2 A set of variables X = {x1 , . . . , xm } is called
a decomposer of a CNF C if it has the following three properties: (i) X is the union of all variables appearing as the
same argument of a predicate R in C; (ii) every xi in X
appears in all atoms of a clause in C; (iii) if xi and xj appear as arguments of a predicate R0 , they must appear as
the same argument of R0 . (R0 may or may not be the same
as R.)
For example, {x1 , x2 } is a decomposer of the CNF (R(x1 )∨
S(x1 , x3 )) ∧ (R(x2 ) ∨ T(x2 , x4 )). Given a decomposer
{x1 , . . . , xm } and a CNF C, it is easy to see that for every
pair of substitutions of the form SX = {x1 = X, . . . , xm = X}
and SY = {x1 = Y, . . . , xm = Y}, with X 6= Y, the CNFs CX
and CY obtained by applying SX and SY to C do not share
any unifiable literals. A decomposer thus yields a lifted decomposition. Given a CNF, a decomposer can be found in
linear time.
When there are no substitution constraints on the variables
in the decomposer, as in the example above, all CNFs
formed by substituting the variables in the decomposer
with a constant are identical. Thus, k = 1 in Equation
3 and m1 equals the number of constants (objects) in the
1
Henceforth, when we say that two clauses are identical, we
mean that they are identical up to a renaming of constants and
variables.

PKB. However, when there are substitution constraints, the
CNFs may not be identical. For example, given the CNF
(R(x1 ) ∨ S(x1 , x3 )) ∧ (R(x2 ) ∨ T(x2 , x4 )) and substitution
constraints {x1 6= A, x2 6= B}, the CNF formed by substituting {x1 = A, x2 = B} is not identical to the CNF formed by
substituting {x1 = C, x2 = C}.
Intuitively, if all the clauses in the CNF have the same set
of groundings relative to the decomposer, then any two
CNFs formed by substituting the variables in the decomposer with any two (valid) distinct constants will be identical. Thus, we need to split the CNF into disjoint CNFs
that have identical groundings relative to the decomposer.
We can achieve this by considering all possible combinations of the substitution constraints. For instance, we
can decompose our example CNF into the following four
CNFs, each of which has an identical set of groundings
relative to x1 and x2 (for readability, we do not standardize variables apart and show the constraints separately for
each CNF): (1) (R(x1 ) ∨ S(x1 , x3 )) ∧ (R(x2 ) ∨ T(x2 , x4 )),
{x1 6= A, x1 6= B, x2 6= A, x2 6= B}; (2) (R(x1 ) ∨ S(x1 , x3 )) ∧
(R(x2 ) ∨ T(x2 , x4 )), {x1 6= A, x1 = B, x2 6= A, x2 = B};
(3) (R(x1 ) ∨ S(x1 , x3 )) ∧ (R(x2 ) ∨ T(x2 , x4 )), {x1 = A,
x2 = A, x1 6= B, x2 6= B}; and (4) (R(x1 ) ∨ S(x1 , x3 )) ∧
(R(x2 ) ∨ T(x2 , x4 )), {x1 = A, x1 = B, x2 = A, x2 = B}. Notice that the fourth CNF has no valid groundings and can be
removed.
In general, a CNF can be partitioned into subsets of identical but disjoint CNFs using constraint satisfaction techniques, as in Kisynski and Poole [22]. In summary:
Proposition 2 Let X = {x1 , . . . , xt } be a decomposer
of C. Let {{X1,1 , . . . , X1,m1 }, . . . , {Xk,1 , . . . , Xk,mk }} be a
partition of the constants in the domain and let C 0 =
{CX1,1 , . . . , CX1,m1 , . . . , CXk,1 , . . . , CXk,mk } be a partition of C
such that (i) for all i, j, j 0 such that j 6= j 0 , CXi,j is identical to CXi,j0 , and (ii) CXi,mi is a CNF formed by substituting
each variable in X by the constant Xi,mi . Then C 0 is a lifted
decomposition of C under S.
5.3

LIFTING THE SPLITTING STEP

Splitting on a non-ground atom means splitting on all
groundings of it consistent with the current substitution
constraints S. Naively, if the atom has c groundings consistent with S this will lead to a sum of 2c recursive calls
to LWMC, one for each possible truth assignment to the c
ground atoms. However, in general these calls will have
repeated structure and can be replaced by a much smaller
number. The lifted splitting step exploits this.
We introduce some notation and definitions. Let σA,S denote a truth assignment to the groundings of atom A consistent with substitution constraints S, and let ΣA,S denote
the set of all possible such assignments. Let C|σA,S denote the CNF formed by removing ¬A from all clauses
it appears in, and setting to Satisfied all ground clauses
that are satisfied because of σA,S . This can be done in a
lifted manner by updating the substitution constraints asso-

ciated with each clause. For instance, consider the clause
R(x) ∨ S(x, y) and substitution constraint {x 6= A}, and suppose the domain is {A, B, C} (i.e., these are all the constants
appearing in the PKB). Given the assignment R(A) = False,
R(B) = True, R(C) = False and ignoring satisfied clauses,
the clause becomes S(x, y) and the constraint set becomes
{x 6= A, x 6= B}. R(x) is removed from the clause because
all of its groundings are instantiated. The constraint x 6= B
is added because the assignment R(B) = True satisfies all
groundings in which x = B.
(1)

(l)

Definition 3 The partition {ΣA,S , . . . , ΣA,S } of ΣA,S is
called a lifted split of atom A for CNF C under substitu(i)
tion constraints S if every part ΣA,S satisfies the following
(i)

two properties: (i) all truth assignments in ΣA,S have the
(i)

same number of true atoms; (ii) for all pairs σj , σk ∈ ΣA,S ,
C|σj is identical to C|σk .
(1)

(l)

Proposition 3 If {ΣA,S , . . . , ΣA,S } is a lifted split of A for
C under S, then
l
X
fi
ni WAti W¬A
LWMC(C|σj ; Sj , W )
LWMC(C, S, W ) =
i=1
(i)

(i)

where ni = |ΣA,S |, σj ∈ ΣA,S , ti and fi are the number of true and false atoms in σj , respectively, and Sj is
S augmented with the substitution constraints required to
form C|σj .
Again, we can derive rules for identifying a lifted split by
using the counting arguments in de Salvo Braz [10] and the
generalized binomial rule in Jha et al. [20]. We omit the
details for lack of space. In the worst case, lifted splitting defaults to splitting on a ground atom. In most inference problems, the PKB will contain many hard ground
unit clauses (the evidence). Splitting on the corresponding ground atoms then reduces to a single recursive call to
LWMC for each atom. In general, the atom to split on in Algorithm 5 should be chosen with the goal of yielding lifted
decompositions in the recursive calls (for example, using
lifted versions of the propositional heuristics [35]).
Notice that the lifting schemes used for decomposition and
splitting in Algorithm 5 by no means exhaust the space of
possible probabilistic lifting rules. For example, Jha et al.
[20] and Milch et al. [24] contain examples of other lifting
rules. Searching for new probabilistic lifted inference rules,
and positive and negative theoretical results about what can
be lifted, looks like a fertile area for future research.
The theorem below follows from Theorem 2 and the arguments above.
Theorem 3 Algorithm LWMC(C, ∅, W ) correctly computes the weighted model count of CNF C under literal
weights W .
5.4

EXTENSIONS

Although most probabilistic logical languages do not include existential quantification, handling it in PTP is desirable for the sake of logical completeness. This is compli-

cated by the fact that skolemization is not sound for model
counting (skolemization will not change satisfiability but
can change the model count), and so cannot be applied.
The result of conversion to CNF is now a conjunction of
clauses with universally and/or existentially quantified variables (e.g., [∀x∃y (R(x, y) ∨ S(y))] ∧ [∃u∀v∀w T(u, v, w)]).
Algorithm 5 now needs to be able to handle clauses of this
form. If no universal quantifier appears nested inside an
existential one, this is straightforward, since in this case
an existentially quantified clause is just a compact representation of a longer one. For example, if the domain is
{A, B, C}, the unit clause ∀x∃y R(x, y) represents the clause
∀x (R(x, A) ∨ R(x, B) ∨ R(x, C)). The decomposition and
splitting steps in Algorithm 5 are both easily extended to
handle such clauses without loss of lifting (and the base
case does not change). However, if universals appear inside existentials, a first-order clause now corresponds to a
disjunction of conjunctions of propositional clauses. For
example, if the domain is {A, B}, ∃x∀y (R(x, y) ∨ S(x, y))
represents (R(A, A)∨S(A, A))∧(R(A, B)∨S(A, B))∨(R(B, A)∨
S(B, A)) ∧ (R(B, B) ∨ S(B, B)). Whether these cases can be
handled without loss of lifting remains an open question.
Several optimizations of the basic LWMC procedure in Algorithm 5 can be readily ported from the algorithms PTP
generalizes. These optimizations can tremendously improve the performance of LWMC.
Unit Propagation When LWMC splits on atom A, the
clauses in the current CNF are resolved with the unit clauses
A and ¬A. This results in deleting false atoms, which may
produce new unit clauses. The idea in unit propagation is
to in turn resolve all clauses in the new CNF with all the
new unit clauses, and continue to do this until no further
unit resolutions are possible. This often produces a much
smaller CNF, and is a key component of DPLL that can also
be used in LWMC. Other techniques used in propositional
inference that can be ported to LWMC include pure literals, clause learning, clause indexing, and random restarts
[3, 35, 4].
Caching/Memoization In a typical inference, LWMC will
be called many times on the same subproblems. The solutions of these can be cached when they are computed,
and reused when they are encountered again. (Notice that a
cache hit only requires identity up to renaming of variables
and constants.) This can greatly reduce the time complexity
of LWMC, but at the cost of increased space complexity. If
the results of all calls to LWMC are cached (full caching),
in the worst case LWMC will use exponential space. In
practice, we can limit the cache size to the available memory and heuristically prune elements from it when it is full.
Thus, by changing the cache size, LWMC can explore various time/space tradeoffs. Caching in LWMC corresponds
to both caching in model counting [35] and recursive conditioning [5] and to memoization of common subproofs in
theorem proving [39].
Knowledge-Based Model Construction KBMC first uses
logical inference to select the subset of the PKB that is rel-

evant to the query, and then propositionalizes the result and
performs standard probabilistic inference on it [40]. A similar effect can be obtained in PTP by noticing that in Equation 2 factors that are common to Z(K ∪ {(Q, 0)}) and
Z(K) cancel out and do not need to be computed. Thus we
can modify Algorithm 3 as follows: (i) simplify the PKB
by unit propagation starting from evidence atoms, etc.; (ii)
drop from the PKB all formulas that have no path of unifiable literals to the query; (iii) pass to LWMC only the remaining formulas, with an initial S containing the substitutions required for the unifications along the connecting
path(s).
5.5

THEORETICAL PROPERTIES

We now theoretically compare the efficiency of PTP and
first-order variable elimination (FOVE) [29, 10].
Theorem 4 PTP can be exponentially more efficient than
FOVE.
Proof sketch. We provide a constructive proof. Consider the
hard CNF (R1 (x1 ) ∨ R2 (x1 , x2 ) ∨ R3 (x2 , x3 )) ∧ (¬R1 (x1 ) ∨
R2 (x2 , x1 ) ∨ R4 (x2 , x3 )) ∧ (R1 (x1 )). Neither counting elimination [10] nor inversion elimination [29] is applicable
here, and therefore the complexity of FOVE will be the
same as that of (propositional) variable elimination, i.e., exponential in the treewidth. The treewidth of the CNF is
polynomial in the domain size (number of constants), and
therefore variable elimination and by extension FOVE will
require exponential time. On the other hand, PTP will solve
this problem in polynomial time. Since R1 (x1 ) is a unit
clause, PTP will remove the first clause because it is satisfied (clause deletion). It will then remove R1 from the
second clause (unit propagation), yielding the hard CNF
R2 (x2 , x1 ) ∨ R4 (x2 , x3 ). PTP will solve this reduced CNF
by first running lifted decomposition (x2 is a decomposer)
followed by two lifted splits over R2 (A, x1 ) and R3 (A, x3 ).
Thus, the overall time complexity of PTP is polynomial in
the domain size.
2
Theorem 5 LWMC with full caching has the same worstcase time and space complexity as FOVE.
The proof of Theorem 5 is a little involved. The main insight for this result comes from previous work on recursive
conditioning [5] and AND/OR search [12]. Specifically,
these papers show that the worst-case time and space complexity of propositional WMC with caching (and without
unit propagation and clause deletion) is the same as that
of variable elimination (VE) (exponential in the treewidth).
Specifically the authors show that both WMC and VE are
graph traversal schemes that operate by traversing the same
graph in a top-down and bottom-up manner respectively.
Lifting can be seen as a way of compressing this graph via
Propositions 1 and 3; specifically by aggregating nodes in
the graph that behave similarly. Since FOVE is a lifted
analog of VE, it traverses the compressed lifted graph in
a bottom-up manner while LWMC with caching traverses
it in a top-down manner; assuming that they use the same

rules for lifting. Since the lifting rules used by LWMC are
at least as general as FOVE, its worst-case time and space
complexity is the same as FOVE.
De Salvo Braz’s FOVE [10] and lifted BP [38] completely
shatter the PKB in advance. This may be wasteful because
many of those splits may not be necessary. Like Poole [29]
and Ng et al. [26], LWMC splits only as needed.
5.6

DISCUSSION

PTP yields new algorithms for several of the inference
problems in Figure 1. For example, ignoring weights and
replacing products by conjunctions and sums by disjunctions in Algorithm 5 yields a lifted version of DPLL for
first-order theorem proving (cf. [2]).
Of the standard methods for inference in graphical models, propositional PTP is most similar to recursive conditioning [5] and AND/OR search [12] with context-sensitive
decomposition and caching, but applies to arbitrary PKBs,
not just Bayesian networks. Also, PTP effectively performs
formula-based inference [17] when it splits on one of the
auxiliary atoms introduced by Algorithm 2.
PTP realizes some of the benefits of lazy inference for relational models [31] by keeping in lifted form what lazy
inference would leave as default.

6

APPROXIMATE INFERENCE

LWMC lends itself readily to Monte Carlo approximation,
by replacing the sum in the splitting step with a random
choice of one of its terms, calling the algorithm many times,
and averaging the results. This yields the first lifted sampling algorithm.
We first apply this importance sampling approach [33] to
WMC, yielding the MC-WMC algorithm. The two algorithms differ only in the last line. Let Q(A|C, W )
denote the importance or proposal distribution over A
given the current CNF C and literal weights W . Then
WA
we return Q(A|C,W
) MC-WMC(C|A; W ) with probability
W¬A
Q(A|C, W ), or Q(¬A|C,W
) MC-WMC(C|¬A; W ) otherwise. By importance sampling theory [33] and by the law
of total expectation, it is easy to show that:

Theorem 6 If Q(A|C, W ) satisfies WMC(C|A; W ) > 0
⇒ Q(A|C, W ) > 0 for all atoms A and its true and false
assignments, then the expected value of the quantity output by MC-WMC(C, W ) equals WMC(C, W ). In other
words, MC-WMC(C, W ) yields an unbiased estimate of
WMC(C, W ).
An estimate of WMC(C, W ) is obtained by running
MC-WMC(C, W ) multiple times and averaging the results.
By linearity of expectation, the running average is also unbiased. It is well known that the accuracy of the estimate
is inversely proportional to its variance [33]. The variance
can be reduced by either running MC-WMC more times or
by choosing Q that is as close as possible to the posterior

#Objs.
10
20
50
Clause PTP FOVE PTP FOVE PTP FOVE
Size ↓
3 14.5 18.93 34.5 93.45 82.1 X
5 23.9 X 43.5 X 132.4 X
7
8.2
X 18.7 X 37.1 X
9
2.3
X
5.2
X 15.9 X

distribution P (or both). Thus, for MC-WMC to be effective in practice, at each point, given the current CNF C, we
should select Q(A|C, W ) that is as close as possible to the
marginal probability distribution of A w.r.t. C and W .
The following simple procedure can be used to construct
the proposal distribution Q. Let A be an atom that needs
to be sampled and (abusing notation) let o = (A1 , . . . , An )
be an ordering of its ground atoms (we select the ordering randomly). Given a truth assignment to the previous
i − 1 atoms, let ni,t and ni,f denote the number of ground
clauses that are satisfied by assigning Ai to true and false
respectively. Then, we use Q(Ai |A1 , . . . , Ai−1 , C, W ) =
ni,t WA /(ni,t WA + ni,f W¬A ). Thus we perform only a
one-step look ahead for constructing Q. In future, we envision using more sophisticated heuristics.
MC-WMC suffers from the rejection problem [18]: it may
return a zero. We can solve this problem by either backtracking when a sample is rejected or by generating samples
from the backtrack-free distribution [18].
Next, we present a lifted version of MC-WMC, which is
obtained by replacing the (last line of the) lifted splitting
step in LWMC by the following lifted sampling step:
return

fi
t
ni WAi W¬A
(i)
Q(ΣA,S )

MC-LWMC(C|σj ; Sj , W )

where ni , ti , fi , σj and Sj are as in Proposition 3

In the lifted sampling step, we construct a distribution Q
(i)
over the lifted split and sample an element ΣA,S from it.
Then we weigh the sampled element w.r.t. Q and call the al(i)
gorithm recursively on the CNF conditioned on σj ∈ ΣA,S .
Notice that A is a first-order atom and the distribution
(i)
Q(ΣA,S ) is defined in a lifted manner. However, seman(i)

tically, each ΣA,S represents all of groundings of A and
(i)

therefore given a ground assignment σj ∈ ΣA,S , the prob(i)

ability of sampling σj is QG (σj ) = Q(ΣA,S )/ni . Thus,
ignoring the decomposition step, MC-LWMC is equivalent
to MC-WMC that uses QG to sample all the groundings
of A. In the decomposition step, given a set of identical
and disjoint CNFs, we simply sample just one of the CNFs
and raise our estimate to the appropriate count. The correctness of this step follows from the fact that the expected
value of the product of k identical and independent random
variables R1 , . . . , Rk equals E[R1 ]k , and (σR1 )k is an unbiased estimate of E[R1 ]k where σR1 is a random sample of
R1 . Therefore, the following theorem immediately follows
from Theorem 6.
(i)

Theorem 7 If Q(ΣA,S ) satisfies WMC(C|σj ; Sj , W ) >
(i)
Q(ΣA,S )

(i)
ΣA,S

0⇒
> 0 for all elements
of the lifted split
of A for C under S, then MC-LWMC(C, S, W ) yields an
unbiased estimate of WMC(C, W ).
MC-LWMC has smaller variance than MC-WMC and is
therefore likely to have higher accuracy. The smaller variance is due to the smaller time complexity of MC-LWMC,

Table 1: Impact of increasing the number of objects and clause
size on the time complexity of FOVE and PTP. Time is in seconds.
‘X’ indicates that the algorithm ran out of memory.
which in turn is due to the decomposition step. Recall that
we group identical and independent CNFs, sample just one
CNF from the group, and raise the estimate by the number
of members in the group. Thus, for each lifted decomposition of size mi > 1, we have a factor of mi speedup. Therefore, given a specific time bound, the estimate returned by
MC-LWMC will be based on a larger sample size (or more
runs) than the one returned by MC-WMC.

7
7.1

EXPERIMENTS
EXACT INFERENCE

In this subsection, we compare the performance of PTP and
FOVE on randomly generated and link prediction PKBs.
We implemented PTP in C++ and ran all our experiments
on a Linux machine with a 2.33 GHz Intel Xeon processor
and 2GB of RAM. We used a constraint solver based on
forward checking to implement the substitution constraints.
We used the following heuristics for splitting. At any point,
we prefer an atom which yields the smallest number of recursive calls to LWMC (i.e., an atom that yields maximum
lifting). We break ties by selecting an atom that appears in
the largest number of ground clauses; this number can be
computed using the constraint solver. If it is the same for
two or more atoms, we break ties randomly.
Random PKBs with Varying Clause Size In the first set
of experiments, we show that PTP’s advantage relative to
FOVE increases with clause length. In order to compare
the performance in a controlled setting, we generated random PKBs parameterized by five integer constants: n, m, s,
e and c, where n is the number of predicates, m is the number of clauses, s is the number of literals in each clause, e is
the number of evidence atoms, and c is the number of constants in the domain. The PKB is generated as follows. All
predicates are unary. We generate m clauses by randomly
selecting s predicates and negating each with probability
0.5. We then choose e ground atoms as evidence, each of
which is set to either True or False with equal probability.
We set n = m = 40, varied s from 3 to 9 in increments of
2 and c from 10 to 50, and set e = c/10. Table 1 shows the
impact of increasing the number of objects c and the clause
size s on the time complexity of FOVE and PTP. The results
are averaged over 10 PKBs. We can see that PTP always
dominates FOVE. When the PKB has small clauses, PTP is
only slightly better than FOVE. However, when the clauses
are large, PTP is substantially better than FOVE, which runs

Negative log likelihood

Time (seconds)

100000
10000
1000
100
10
1
0.1
0.01

PTP
FOVE

10000
1000
100
10
Lifted-BP
MC-SAT
MC-WMC
MC-LWMC

1
0.1
0.01

10 20 30 40 50 60 70 80

0

10

Percentage of evidence objects
(a)
Negative log likelihood

Time (seconds)

100000

PTP
FOVE

10000
1000
100
10
1
0.1
0.01
100

200

300

400

Link Prediction We experimented with a simple PKB consisting of two clauses: GoodProf(x) ∧ GoodStudent(y) ∧
Advises(x, y) ⇒ FutureProf(y) and Coauthor(x, y) ⇒
Advises(x, y). The PKB has two types of objects: professors (x) and students (y). Given data on a subset of papers
and “goodness” of professors and students, the task is to be
predict who advises whom and who is likely to be a professor in the future.
We evaluated the performance of FOVE and PTP along two
dimensions: (i) the number of objects and (ii) the amount
of evidence. We varied the number of objects from 10 to
1000 and the number of evidence atoms from 10% to 80%.
Figure 2(a) shows the impact of increasing the number of
evidence atoms on the performance of the two algorithms
on a link prediction PKB with 100 objects. FOVE runs
out of memory (typically after around 20 minutes of run
time) after the percentage of evidence atoms rises above
40%. PTP solves all the problems and is also much faster
than FOVE (notice the log-scale on the y-axis). Figure 2(b)
shows the impact of increasing the number of objects on a
link prediction PKB with 20% of the atoms set as observed.
We can see that FOVE is unable to solve any problems after the number of objects is increased beyond 100 because
it runs out of memory. PTP, on the other hand, solves all

50

60

50

60

100
10
Lifted-BP
MC-SAT
MC-WMC
MC-LWMC

1
0.1
0.01
10

20

30

40

Time (minutes)
(b)

(b)

out of memory on all the instances, typically after around
20 minutes of run time. When large clauses are present, unit
propagation is very effective and causes a large amount of
pruning. Because of this, PTP is much faster than FOVE.

40

1000

Number of objects

time complexity of FOVE and PTP in the link prediction domain.
The number of objects in the domain is 100. (b) Impact of increasing the number of objects on the time complexity of FOVE
and PTP in the link prediction domain, with 20% of the atoms set
as evidence.

30

10000

0

500

Figure 2: (a) Impact of increasing the amount of evidence on the

20

Time (minutes)
(a)

Figure 3: Negative log-likelihood of the data as a function of time
for lifted BP, MC-SAT, MC-WMC and MC-LWMC on (a) the entity resolution (Cora) and (b) the collective classification domains.

problems in less than 100s.
7.2

APPROXIMATE INFERENCE

In this subsection, we compare the performance of MCLWMC, MC-WMC, lifted belief propagation [38], and
MC-SAT [30] on two domains. We used the entity resolution (Cora) and collective classification datasets and
Markov logic networks used in Singla and Domingos [37]
and Poon and Domingos [30] respectively. The Cora
dataset contains 1295 citations to 132 different research papers. The inference task here is to detect duplicate citations, authors, titles and venues. The collective classification dataset consists of about 3000 query atoms.
Since computing the exact posterior marginals is infeasible
in these domains, we used the following evaluation method.
We partitioned the data into two equal-sized sets: evidence
set and test set. We then computed the probability of each
ground atom in the test set given all atoms in the evidence
set using the four inference algorithms. We measure the
error using negative log-likelihood of the data according to
the inference algorithms (the negative log-likelihood is a
sampling approximation of the K-L divergence to the datagenerating distribution, shifted by its entropy).
The results, averaged over 10 runs, are shown in Figures
3(a) and 3(b). The figures show how the log-likelihood of
the data varies with time for the four inference algorithms
used. We see that MC-LWMC has the lowest negative loglikelihood of all algorithms by a large margin. It significantly dominates MC-WMC in about 2 minutes of run-time
and is substantially superior to both lifted BP and MC-SAT

(notice the log scale). This shows the advantages of approximate PTP over lifted BP and ground inference.

8

CONCLUSION

Probabilistic theorem proving (PTP) combines theorem
proving and probabilistic inference. This paper proposed
an algorithm for PTP based on reducing it to lifted weighted
model counting, and showed both theoretically and empirically that it has significant advantages compared to previous
lifted probabilistic inference algorithms. An implementation of PTP will be available in the Alchemy system [25].
Directions for future research include: extension of PTP
to infinite, non-Herbrand first-order logic; new lifted inference rules; theoretical analysis of liftability; porting to PTP
more speedup techniques from logical and probabilistic inference; lifted splitting heuristics; better handling of existentials; variational PTP algorithms; better importance distributions; approximate lifting; answering multiple queries
simultaneously; applications; etc.
Acknowledgements This research was partly funded by
ARO grant W911NF-08-1-0242, AFRL contract FA8750-09-C0181, DARPA contracts FA8750-05-2-0283, FA8750-07-D-0185,
HR0011-06-C-0025, HR0011-07-C-0060 and NBCH-D030010,
NSF grants IIS-0534881 and IIS-0803481, and ONR grant
N00014-08-1-0670. The views and conclusions contained in this
document are those of the authors and should not be interpreted as
necessarily representing the official policies, either expressed or
implied, of ARO, DARPA, NSF, ONR, or the U.S. Government.



The paper investigates parameterized approximate message-passing schemes that are based on
bounded inference and are inspired by Pearl’s belief propagation algorithm (BP). We start with the
bounded inference mini-clustering algorithm and then move to the iterative scheme called Iterative
Join-Graph Propagation (IJGP), that combines both iteration and bounded inference. Algorithm
IJGP belongs to the class of Generalized Belief Propagation algorithms, a framework that allowed
connections with approximate algorithms from statistical physics and is shown empirically to surpass the performance of mini-clustering and belief propagation, as well as a number of other stateof-the-art algorithms on several classes of networks. We also provide insight into the accuracy of
iterative BP and IJGP by relating these algorithms to well known classes of constraint propagation
schemes.

1. Introduction
Probabilistic inference is the principal task in Bayesian networks and is known to be an NP-hard
problem (Cooper, 1990; Roth, 1996). Most of the commonly used exact algorithms such as jointree clustering (Lauritzen & Spiegelhalter, 1988; Jensen, Lauritzen, & Olesen, 1990) or variableelimination (Dechter, 1996, 1999; Zhang, Qi, & Poole, 1994), and more recently search schemes
(Darwiche, 2001; Bacchus, Dalmao, & Pitassi, 2003; Dechter & Mateescu, 2007) exploit the network structure. While significant advances were made in the last decade in exact algorithms, many
real-life problems are too big and too hard, especially when their structure is dense, since they are
time and space exponential in the treewidth of the graph. Approximate algorithms are therefore
necessary for many practical problems, although approximation within given error bounds is also
NP-hard (Dagum & Luby, 1993; Roth, 1996).

c 2010 AI Access Foundation. All rights reserved.

M ATEESCU , K ASK , G OGATE & D ECHTER

The paper focuses on two classes of approximation algorithms for the task of belief updating.
Both are inspired by Pearl’s belief propagation algorithm (Pearl, 1988), which is known to be exact
for trees. As a distributed algorithm, Pearl’s belief propagation can also be applied iteratively to
networks that contain cycles, yielding Iterative Belief Propagation (IBP), also known as loopy belief
propagation. When the networks contain cycles, IBP is no longer guaranteed to be exact, but in
many cases it provides very good approximations upon convergence. Some notable success cases
are those of IBP for coding networks (McEliece, MacKay, & Cheng, 1998; McEliece & Yildirim,
2002), and a version of IBP called survey propagation for some classes of satisfiability problems
(Mézard, Parisi, & Zecchina, 2002; Braunstein, Mézard, & Zecchina, 2005).
Although the performance of belief propagation is far from being well understood in general,
one of the more promising avenues towards characterizing its behavior came from analogies with
statistical physics. It was shown by Yedidia, Freeman, and Weiss (2000, 2001) that belief propagation can only converge to a stationary point of an approximate free energy of the system, called
Bethe free energy. Moreover, the Bethe approximation is computed over pairs of variables as terms,
and is therefore the simplest version of the more general Kikuchi (1951) cluster variational method,
which is computed over clusters of variables. This observation inspired the class of Generalized
Belief Propagation (GBP) algorithms, that work by passing messages between clusters of variables.
As mentioned by Yedidia et al. (2000), there are many GBP algorithms that correspond to the same
Kikuchi approximation. A version based on region graphs, called “canonical” by the authors, was
presented by Yedidia et al. (2000, 2001, 2005). Our algorithm Iterative Join-Graph Propagation is
a member of the GBP class, although it will not be described in the language of region graphs. Our
approach is very similar to and was independently developed from that of McEliece and Yildirim
(2002). For more information on BP state of the art research see the recent survey by Koller (2010).
We will first present the mini-clustering scheme which is an anytime bounded inference scheme
that generalizes the mini-bucket idea. It can be viewed as a belief propagation algorithm over a tree
obtained by a relaxation of the network’s structure (using the technique of variable duplication). We
will subsequently present Iterative Join-Graph Propagation (IJGP) that sends messages between
clusters that are allowed to form a cyclic structure.
Through these two schemes we investigate: (1) the quality of bounded inference as an anytime
scheme (using mini-clustering); (2) the virtues of iterating messages in belief propagation type
algorithms, and the result of combining bounded inference with iterative message-passing (in IJGP).
In the background section 2, we overview the Tree-Decomposition scheme that forms the basis
for the rest of the paper. By relaxing two requirements of the tree-decomposition, that of connectedness (via mini-clustering) and that of tree structure (by allowing cycles in the underlying graph),
we combine bounded inference and iterative message-passing with the basic tree-decomposition
scheme, as elaborated in subsequent sections.
In Section 3 we present the partitioning-based anytime algorithm called Mini-Clustering (MC),
which is a generalization of the Mini-Buckets algorithm (Dechter & Rish, 2003). It is a messagepassing algorithm guided by a user adjustable parameter called i-bound, offering a flexible tradeoff
between accuracy and efficiency in anytime style (in general the higher the i-bound, the better the
accuracy). MC algorithm operates on a tree-decomposition, and similar to Pearl’s belief propagation algorithm (Pearl, 1988) it converges in two passes, up and down the tree. Our contribution
beyond other works in this area (Dechter & Rish, 1997; Dechter, Kask, & Larrosa, 2001) is in: (1)
Extending the partition-based approximation for belief updating from mini-buckets to general treedecompositions, thus allowing the computation of the updated beliefs for all the variables at once.
280

J OIN -G RAPH P ROPAGATION A LGORITHMS

This extension is similar to the one proposed by Dechter et al. (2001), but replaces optimization
with probabilistic inference. (2) Providing empirical evaluation that demonstrates the effectiveness
of the idea of tree-decomposition combined with partition-based approximation for belief updating.
Section 4 introduces the Iterative Join-Graph Propagation (IJGP) algorithm. It operates on a
general join-graph decomposition that may contain cycles. It also provides a user adjustable i-bound
parameter that defines the maximum cluster size of the graph (and hence bounds the complexity),
therefore it is both anytime and iterative. While the algorithm IBP is typically presented as a generalization of Pearl’s Belief Propagation algorithm, we show that IBP can be viewed as IJGP with the
smallest i-bound.
We also provide insight into IJGP’s behavior in Section 4. Zero-beliefs are variable-value pairs
that have zero conditional probability given the evidence. We show that: (1) if a value of a variable
is assessed as having zero-belief in any iteration of IJGP, it remains a zero-belief in all subsequent
iterations; (2) IJGP converges in a finite number of iterations relative to its set of zero-beliefs; and,
most importantly (3) that the set of zero-beliefs decided by any of the iterative belief propagation
methods is sound. Namely any zero-belief determined by IJGP corresponds to a true zero conditional probability relative to the given probability distribution expressed by the Bayesian network.
Empirical results on various classes of problems are included in Section 5, shedding light on
the performance of IJGP(i). We see that it is often superior, or otherwise comparable, to other
state-of-the-art algorithms.
The paper is based in part on earlier conference papers by Dechter, Kask, and Mateescu (2002),
Mateescu, Dechter, and Kask (2002) and Dechter and Mateescu (2003).

2. Background
In this section we provide background for exact and approximate probabilistic inference algorithms
that form the basis of our work. While we present our algorithms in the context of directed probabilistic networks, they are applicable to any graphical model, including Markov networks.
2.1 Preliminaries
Notations: A reasoning problem is defined in terms of a set of variables taking values on finite
domains and a set of functions defined over these variables. We denote variables or subsets of
variables by uppercase letters (e.g., X, Y, Z, S, R . . .) and values of variables by lower case letters
(e.g., x, y, z, s). An assignment (X1 = x1 , . . . , Xn = xn ) can be abbreviated as x = (x1 , . . . , xn ).
For a subset of variables S, DS denotes the Cartesian product of the domains of variables in S. xS
is the projection of x = (x1 , . . . , xn ) over a subset S. We denote functions by letters f , g, h, etc.,
and the scope (set of arguments) of the function f by scope(f ).
D EFINITION 1 (graphical model) (Kask, Dechter, Larrosa, & Dechter, 2005) A graphical model
M is a 3-tuple, M = hX, D, Fi, where: X = {X1 , . . . , Xn } is a finite set of variables; D =
{D1 , . . . , Dn } is the set of their respective finite domains of values; F = {f1 , . . . , fr } is a set
of positive real-valued discrete functions, each defined over a subset of variables Si ⊆ X, called
its scope, and denoted by scope(f
P i ). A graphical model typically has an associated combination
1
operator ⊗, (e.g., ⊗ ∈ {Π, } - product, sum). The graphical model represents the combination
1. The combination operator can also be defined axiomatically (Shenoy, 1992).

281

M ATEESCU , K ASK , G OGATE & D ECHTER

of all its functions: ⊗ri=1 fi . A graphical model has an associated primal graph that captures the
structural information of the model:
D EFINITION 2 (primal graph, dual graph) The primal graph of a graphical model is an undirected graph that has variables as its vertices and an edge connects any two vertices whose corresponding variables appear in the scope of the same function. A dual graph of a graphical model has
a one-to-one mapping between its vertices and functions of the graphical model. Two vertices in the
dual graph are connected if the corresponding functions in the graphical model share a variable.
We denote the primal graph by G = (X, E), where X is the set of variables and E is the set of
edges.
D EFINITION 3 (belief networks) A belief (or Bayesian) network is a graphical model B =
hX, D, G, P i, where G = (X, E) is a directed acyclic graph over variables X and P = {pi },
where pi = {p(Xi | pa (Xi ) ) } are conditional probability tables (CPTs) associated with each variable Xi and pa(Xi ) = scope(pi )−{Xi } is the set of parents of Xi in G. Given a subset of variables
S, we will write P (s) as the probability P (S = s), where s ∈ DS . A belief network represents
a probability distribution over X, P (x1 , . . . ., xn ) = Πni=1 P (xi |xpa(Xi ) ). An evidence set e is an
instantiated subset of variables. The primal graph of a belief network is called a moral graph. It
can be obtained by connecting the parents of each vertex in G and removing the directionality of
the edges. Equivalently, it connects any two variables appearing in the same family (a variable and
its parents in the CPT).
Two common queries in Bayesian networks are Belief Updating (BU) and Most Probable Explanation (MPE).
D EFINITION 4 (belief network queries) The Belief Updating (BU) task is to find the posterior
probability of each single variable given some evidence e, that is to compute P (Xi |e). The Most
Probable Explanation (MPE) task is to find a complete assignment to all the variables having maximum probability given the evidence, that is to compute argmaxX Πi pi .
2.2 Tree-Decomposition Schemes
Tree-decomposition is at the heart of most general schemes for solving a wide range of automated
reasoning problems, such as constraint satisfaction and probabilistic inference. It is the basis for
many well-known algorithms, such as join-tree clustering and bucket elimination. In our presentation we will follow the terminology of Gottlob, Leone, and Scarcello (2000) and Kask et al. (2005).
D EFINITION 5 (tree-decomposition, cluster-tree) Let B = hX, D, G, P i be a belief network. A
tree-decomposition for B is a triple hT, χ, ψi, where T = (V, E) is a tree, and χ and ψ are labeling
functions which associate with each vertex v ∈ V two sets, χ(v) ⊆ X and ψ(v) ⊆ P satisfying:
1. For each function pi ∈ P , there is exactly one vertex v ∈ V such that pi ∈ ψ(v), and
scope(pi ) ⊆ χ(v).
2. For each variable Xi ∈ X, the set {v ∈ V |Xi ∈ χ(v)} induces a connected subtree of T .
This is also called the running intersection (or connectedness) property.
We will often refer to a node and its functions as a cluster and use the term tree-decomposition and
cluster-tree interchangeably.
282

J OIN -G RAPH P ROPAGATION A LGORITHMS

D EFINITION 6 (treewidth, separator, eliminator) Let D = hT, χ, ψi be a tree-decomposition of
a belief network B. The treewidth (Arnborg, 1985) of D is maxv∈V |χ(v)| − 1. The treewidth of
B is the minimum treewidth over all its tree-decompositions. Given two adjacent vertices u and
v of a tree-decomposition, the separator of u and v is defined as sep(u, v) = χ(u) ∩ χ(v), and
the eliminator of u with respect to v is elim(u, v) = χ(u) − χ(v). The separator-width of D is
max(u,v) |sep(u, v)|. The minimum treewidth of a graph G can be shown to be identical to a related
parameter called induced-width (Dechter & Pearl, 1987).
Join-tree and cluster-tree elimination (CTE) In both Bayesian network and constraint satisfaction communities, the most used tree-decomposition method is join-tree decomposition (Lauritzen
& Spiegelhalter, 1988; Dechter & Pearl, 1989), introduced based on relational database concepts
(Maier, 1983). Such decompositions can be generated by embedding the network’s moral graph G
into a chordal graph, often using a triangulation algorithm and using its maximal cliques as nodes in
the join-tree. The triangulation algorithm assembles a join-tree by connecting the maximal cliques in
the chordal graph in a tree. Subsequently, every CPT pi is placed in one clique containing its scope.
Using the previous terminology, a join-tree decomposition of a belief network B = hX, D, G, P i is
0
a tree T = (V, E), where V is the set of cliques of a chordal graph G that contains G, and E is a set
of edges that form a tree between cliques, satisfying the running intersection property (Maier, 1983).
Such a join-tree satisfies the properties of tree-decomposition and is therefore a cluster-tree (Kask
et al., 2005). In this paper, we will use the terms tree-decomposition and join-tree decomposition
interchangeably.
There are a few variants for processing join-trees for belief updating (e.g., Jensen et al., 1990;
Shafer & Shenoy, 1990). We adopt here the version from Kask et al. (2005), called cluster-treeelimination (CTE), that is applicable to tree-decompositions in general and is geared towards space
savings. It is a message-passing algorithm; for the task of belief updating, messages are computed
by summation over the eliminator between the two clusters of the product of functions in the originating cluster. The algorithm, denoted CTE-BU (see Figure 1), pays a special attention to the
processing of observed variables since the presence of evidence is a central component in belief
updating. When a cluster sends a message to a neighbor, the algorithm operates on all the functions
in the cluster except the message from that particular neighbor. The message contains a single combined function and individual functions that do not share variables with the relevant eliminator. All
the non-individual functions are combined in a product and summed over the eliminator.
Example 1 Figure 2a describes a belief network and Figure 2b a join-tree decomposition for it.
Figure 2c shows the trace of running CTE-BU with evidence G = ge , where h(u,v) is a message that
cluster u sends to cluster v.
T HEOREM 1 (complexity of CTE-BU) (Dechter et al., 2001; Kask et al., 2005) Given a Bayesian
network B = hX, D, G, P i and a tree-decomposition hT, χ, ψi of B, the time complexity of CTE∗
BU is O(deg · (n + N ) · dw +1 ) and the space complexity is O(N · dsep ), where deg is the maximum
degree of a node in the tree-decomposition, n is the number of variables, N is the number of nodes
in the tree-decomposition, d is the maximum domain size of a variable, w∗ is the treewidth and sep
is the maximum separator size.

283

M ATEESCU , K ASK , G OGATE & D ECHTER

Algorithm CTE for Belief-Updating (CTE-BU)
Input: A tree-decomposition hT, χ, ψi, T = (V, E) for B = hX, D, G, P i. Evidence variables
var(e).
Output: An augmented tree whose nodes are clusters containing the original CPTs and the
messages received from neighbors. P (Xi , e), ∀Xi ∈ X.
Denote by H(u,v) the message from vertex u to v, nev (u) the neighbors of u in T excluding v,
cluster(u) = ψ(u) ∪ {H(v,u) |(v, u) ∈ E},
clusterv (u) = cluster(u) excluding message from v to u.

• Compute messages:
For every node u in T , once u has received messages from all nev (u), compute message to node
v:
1. Process observed variables:
Assign relevant evidence to all pi ∈ ψ(u)
2. Compute the combined function:
X

h(u,v) =

Y

f

elim(u,v) f ∈A

where A is the set of functions in clusterv (u) whose scope intersects elim(u, v).
Add h(u,v) to H(u,v) and add all the individual functions in clusterv (u) − A
Send H(u,v) to node v.
• Compute P (Xi , e):
For every Xi ∈ X let u be a vertex in T such that Xi ∈ χ(u). Compute P (Xi , e) =
P
Q
χ(u)−{Xi } ( f ∈cluster(u) f )

Figure 1: Algorithm Cluster-Tree-Elimination for Belief Updating (CTE-BU).
A

1

χ (1) = { A, B, C}
ψ (1) = { p(a ), p(b | a ), p(c | a, b)}

1

ABC
BC

B

2
C

D

χ ( 2) = { B , C , D , F }
ψ (2) = { p(d | b), p( f | c, d }

2 BCDF

E

BF

3

χ (3) = {B, E , F }
ψ (3) = { p (e | b, f )}

4

χ (4) = {E , F , G}
ψ (4) = { p( g | e, f )}

3

F
G

(a)

BEF
EF

4

(b)

EFG

h (1 , 2 ) ( b , c ) =

∑
(b , c ) = ∑
a

h ( 2 ,1 )

p ( a ) ⋅ p (b | a ) ⋅ p (c | a , b )
p ( d | b ) ⋅ p ( f | c , d ) ⋅ h( 3, 2 ) (b , f )

d,f

h( 2 ,3 ) (b , f ) =

∑
h( 3 , 2 ) ( b , f ) = ∑
e

p (d | b)

h( 3 , 4 ) ( e , f ) =

p ( e | b , f ) ⋅ h( 2 ,3 ) (b , f )

c ,d

∑

p ( f | c, d )

h (1 , 2 ) ( b , c )

p ( e | b , f ) ⋅ h( 4 ,3 ) ( e , f )

b

h( 4 ,3 ) ( e , f ) = p ( G = g e | e , f )

(c)

Figure 2: (a) A belief network; (b) A join-tree decomposition; (c) Execution of CTE-BU.

3. Partition-Based Mini-Clustering
The time, and especially the space complexity, of CTE-BU renders the algorithm infeasible for problems with large treewidth. We now introduce Mini-Clustering, a partition-based anytime algorithm
which computes bounds or approximate values on P (Xi , e) for every variable Xi .
284

J OIN -G RAPH P ROPAGATION A LGORITHMS

Procedure MC for Belief Updating (MC-BU(i))
2. Compute the combined mini-functions:
Make an (i)-size mini-cluster partitioning of clusterv (u), {mc(1), . . . , mc(p)};
P
Q
h1(u,v) = elim(u,v) f ∈mc(1) f
Q
hi(u,v) = maxelim(u,v) f ∈mc(i) f i = 2, . . . , p
add {hi(u,v) |i = 1, . . . , p} to H(u,v) . Send H(u,v) to v.
Compute upper bounds P (Xi , e) on P (Xi , e):
For every Xi ∈ X let u ∈ V be a cluster such that Xi ∈ χ(u). Make (i) mini-clusters from
cluster(u), {mc(1), . . . , mc(p)}; Compute P (Xi , e) =
P
Q
Qp
Q
( χ(u)−Xi f ∈mc(1) f ) · ( k=2 maxχ(u)−Xi f ∈mc(k) f ).

Figure 3: Procedure Mini-Clustering for Belief Updating (MC-BU).
3.1 Mini-Clustering Algorithm
Combining all the functions of a cluster into a product has a complexity exponential in its number
of variables, which is upper bounded by the induced width. Similar to the mini-bucket scheme
(Dechter, 1999), rather than performing this expensive exact computation, we partition the cluster into p mini-clusters mc(1), . . . , mc(p), each having at most
Pi variables,
Q where i is an accuracy parameter. Instead of computing by CTE-BU h(u,v) =
elim(u,v)
f ∈ψ(u) f , we can divide the functions
of ψ(u)
mc(k), k ∈ {1, . . . , p}, and rewrite h(u,v) =
P into p mini-clusters
Qp Q
P
Q
f
=
∈mc(k) f . By migrating the summation operator into
elim(u,v)
elim(u,v)
f ∈ψ(u)
Q
P k=1 fQ
p
each mini-cluster, yielding k=1 elim(u,v) f ∈mc(k) f , we get an upper bound on h(u,v) . The
resulting algorithm is called MC-BU(i).
Consequently, the combined functions are approximated via mini-clusters, as follows. Suppose
u ∈ V has received messages from all its neighbors other than v (the message from v is ignored even
if received). The functions in clusterv (u) that are to be combined are partitioned into mini-clusters
{mc(1), . . . , mc(p)}, each one containing at most i variables. Each mini-cluster is processed by
summation over the eliminator, and the resulting combined functions as well as all the individual
functions are sent to v. It was shown by Dechter and Rish (2003) that the upper bound can be
improved by using the maximization operator max rather than the summation operator sum on some
mini-buckets. Similarly, lower bounds can be generated by replacing sum with min (minimization)
for some mini-buckets. Alternatively, we can replace sum by a mean operator (taking the sum and
dividing by the number of elements in the sum), in this case deriving an approximation of the joint
belief instead of a strict upper bound.
Algorithm MC-BU for upper bounds can be obtained from CTE-BU by replacing step 2 of the
main loop and the final part of computing the upper bounds on the joint belief by the procedure given
in Figure 3. In the implementation we used for the experiments reported here, the partitioning was
done in a greedy brute-force manner. We ordered the functions according to their sizes (number of
variables), breaking ties arbitrarily. The largest function was placed in a mini-cluster by itself. Then,
we picked the largest remaining function and probed the mini-clusters in the order of their creation,
285

M ATEESCU , K ASK , G OGATE & D ECHTER

1

ABC

BC

H (1, 2)

h(11, 2 ) (b, c) := ∑ p (a ) ⋅ p (b | a ) ⋅ p(c | a, b)
a
1
( 2 ,1)

h

H ( 2,1)

(b) := ∑ p (d | b) ⋅ h(13, 2 ) (b, f )
d, f

h(22,1) (c) := max p ( f | c, d )
d, f

2

BCDF
1
( 2 , 3)

h

H ( 2 , 3)
BF

3

BEF

EF

c ,d

h(22,3) ( f ) := max p( f | c, d )
c,d

1
( 3, 2 )

(b, f ) := ∑ p(e | b, f ) ⋅ h(14,3) (e, f )

H ( 3, 2 )

h

H ( 3, 4 )

h(13, 4 ) (e, f ) := ∑ p (e | b, f ) ⋅ h(12,3) (b) ⋅ h(22,3) ( f )

H ( 4 , 3)

4

(b) := ∑ p (d | b) ⋅ h(11, 2 ) (b, c)

e

b

1
( 4 , 3)

h

(e, f ) := p(G = g e | e, f )

EFG

Figure 4: Execution of MC-BU for i = 3.
trying to find one that together with the new function would have no more than i variables. A new
mini-cluster was created whenever the existing ones could not accommodate the new function.
Example 2 Figure 4 shows the trace of running MC-BU(3) on the problem in Figure 2. First, evidence G = ge is assigned in all CPTs. There are no individual functions to be sent from cluster 1
to cluster 2. Cluster 1 contains only 3 variables,
χ(1) = {A, B, C}, therefore it is not partitioned.
P
p(a)
·
p(b|a) · p(c|a, b) is computed and the message
The combined function h1(1,2) (b, c) =
a
1
H(1,2) = {h(1,2) (b, c)} is sent to node 2. Now, node 2 can send its message to node 3. Again, there
are no individual functions. Cluster 2 contains 4 variables, χ(2) = {B, C, D, F }, and a partitioning is necessary: MC-BU(3) can choose
P mc(1) = {p(d|b), h(1,2) (b,2c)} and mc(2) = {p(f |c, d)}.
1
The combined functions h(2,3) (b) = c,d p(d|b) · h(1,2) (b, c) and h(2,3) (f ) = maxc,d p(f |c, d) are
computed and the message H(2,3) = {h1(2,3) (b), h2(2,3) (f )} is sent to node 3. The algorithm continues until every node has received messages from all its neighbors. An upper bound on p(a, G = ge )
can now be computed by choosing cluster
1, which contains variable A. It doesn’t need partitionP
ing, so the algorithm just computes b,c p(a) · p(b|a) · p(c|a, b) · h1(2,1) (b) · h2(2,1) (c). Notice that
unlike CTE-BU which processes 4 variables in cluster 2, MC-BU(3) never processes more than 3
variables at a time.
It was already shown that:
T HEOREM 2 (Dechter & Rish, 2003) Given a Bayesian network B = hX, D, G, P i and the evidence e, the algorithm MC-BU(i) computes an upper bound on the joint probability P (Xi , e) of
each variable Xi (and each of its values) and the evidence e.
T HEOREM 3 (complexity of MC-BU(i)) (Dechter et al., 2001) Given a Bayesian network B =
hX, D, G, P i and a tree-decomposition hT, χ, ψi of B, the time and space complexity of MC-BU(i)
is O(n · hw∗ · di ), where n is the number of variables, d is the maximum domain size of a variable
and hw∗ = maxu∈T |{f ∈ P |scope(f ) ∩ χ(u) 6= φ}|, which bounds the number of mini-clusters.
286

J OIN -G RAPH P ROPAGATION A LGORITHMS







   
 



" %&
"

#$ '  " & 
! ! !

   


!! !! !!

!

 



""  &&""'%&&
()* $  

   






 
!



+

Figure 5: Node duplication semantics of MC: (a) trace of MC-BU(3); (b) trace of CTE-BU.
Semantics of Mini-Clustering The mini-bucket scheme was shown to have the semantics of relaxation via node duplication (Kask & Dechter, 2001; Choi, Chavira, & Darwiche, 2007). We
extend it to mini-clustering by showing how it can apply as is to messages that flow in one direction
(inward, from leaves to root), as follows. Given a tree-decomposition D, where CTE-BU computes
a function h(u,v) (the message that cluster u sends to cluster v), MC-BU(i) partitions cluster u into p
mini-clusters u1 , . . . , up , which are processed independently and then the resulting functions h(ui ,v)
are sent to v. Instead consider a different decomposition D0 , which is just like D, with the exception that (a) instead of u, it has clusters u1 , . . . , up , all of which are children of v, and each variable
appearing in more than a single mini-cluster becomes a new variable, (b) each child w of u (in D) is
a child of uk (in D0 ), such that h(w,u) (in D) is assigned to uk (in D0 ) during the partitioning. Note
that D0 is not a legal tree-decomposition relative to the original variables since it violates the connectedness property: the mini-clusters u1 , . . . , up contain variables elim(u, v) but the path between
the nodes u1 , . . . , up (this path goes through v) does not. However, it is a legal tree-decomposition
relative to the new variables. It is straightforward to see that H(u,v) computed by MC-BU(i) on D
is the same as {h(ui ,v) |i = 1, . . . , p} computed by CTE-BU on D0 in the direction from leaves to
root.
If we want to capture the semantics of the outward messages from root to leaves, we need to generate a different relaxed decomposition (D00 ) because MC, as defined, allows a different partitioning
in the up and down streams of the same cluster. We could of course stick with the decomposition in
D0 and use CTE in both directions which would lead to another variant of mini-clustering.
Example 3 Figure 5(a) shows a trace of the bottom-up phase of MC-BU(3) on the network in Figure
4. Figure 5(b) shows a trace of the bottom-up phase of CTE-BU algorithm on a problem obtained
from the problem in Figure 4 by splitting nodes D (into D0 and D00 ) and F (into F 0 and F 00 ).
The MC-BU algorithm computes an upper bound P (Xi , e) on the joint probability P (Xi , e).
However, deriving a bound on the conditional probability P (Xi |e) is not easy when the exact
287

M ATEESCU , K ASK , G OGATE & D ECHTER

Random Bayesian N=50 K=2 P=2 C=48
0.20
0.18
0.16

Avg abs error

0.14
0.12
0.10
0.08
#ev=0
#ev=10
#ev=20
#ev=30

0.06
0.04
0.02
0.00
0

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

Number of iterations

Figure 6: Convergence of IBP (50 variables, evidence from 0-30 variables).
value of P (e) is not available. If we just try to divide (multiply) P (Xi , e) by a constant, the
result is not
P necessarily an upper bound on P (Xi |e). It is easy to show that normalization,
P (xi , e)/ xi ∈Di P (xi , e), with the mean operator is identical to normalization of MC-BU output
when applying the summation operator in all the mini-clusters.
MC-BU(i) is an improvement over the Mini-Bucket algorithm MB(i), in that it allows the computation of P (Xi , e) for all variables with a single run, whereas MB(i) computes P (Xi , e) for just
one variable, with a single run. When computing P (Xi , e) for each variable, MB(i) has to be run
n times, once for each variable, an algorithm we call nMB(i). It was demonstrated by Mateescu
et al. (2002) that MC-BU(i) has up to linear speed-up over nMB(i). For a given i, the accuracy of
MC-BU(i) can be shown to be not worse than that of nMB(i).
3.2 Experimental Evaluation of Mini-Clustering
The work of Mateescu et al. (2002) and Kask (2001) provides an empirical evaluation of MC-BU
that reveals the impact of the accuracy parameter on its quality of approximation and compares with
Iterative Belief Propagation and a Gibbs sampling scheme. We will include here only a subset of
these experiments which will provide the essence of our results. Additional empirical evaluation of
MC-BU will be given when comparing against IJGP later in this paper.
We tested the performance of MC-BU(i) on random Noisy-OR networks, random coding networks, general random networks, grid networks, and three benchmark CPCS files with 54, 360 and
422 variables respectively (these are belief networks for medicine, derived from the Computer based
Patient Case Simulation system, known to be hard for belief updating). On each type of network we
ran Iterative Belief Propagation (IBP) - set to run at most 30 iterations, Gibbs Sampling (GS) and
MC-BU(i), with i from 2 to the treewidth w∗ to capture the anytime behavior of MC-BU(i).
The random networks were generated using parameters (N,K,C,P), where N is the number of
variables, K is their domain size (we used only K=2), C is the number of conditional probability
tables and P is the number of parents in each conditional probability table. The parents in each table
are picked randomly given a topological ordering, and the conditional probability tables are filled
288

J OIN -G RAPH P ROPAGATION A LGORITHMS

0
|e| 10
20

NHD
max

IBP

MC-BU(2)

MC-BU(5)

MC-BU(8)

0
0
0
0
0
0
0
0
0

mean
0
0
0
0
0
0
0
0
0
0
0
0

N=50, P=2, 50 instances
Abs. Error
max

1.6E-03
1.1E-03
5.7E-04
1.1E-03
7.7E-04
2.8E-04
3.6E-04
1.7E-04
3.5E-05

mean
9.0E-09
3.4E-04
9.6E-04
1.1E-03
8.4E-04
4.8E-04
9.4E-04
6.9E-04
2.7E-04
3.2E-04
1.5E-04
3.5E-05

Rel. Error

max

1.9E+00
1.4E+00
7.1E-01
1.4E+00
9.3E-01
3.5E-01
4.4E-01
2.0E-01
4.3E-02

mean
1.1E-05
4.2E-01
1.2E+00
1.3E+00
1.0E+00
5.9E-01
1.2E+00
8.4E-01
3.3E-01
3.9E-01
1.9E-01
4.3E-02

Time
max

0.056
0.048
0.039
0.070
0.063
0.058
0.214
0.184
0.123

mean
0.102
0.081
0.062
0.057
0.049
0.039
0.072
0.066
0.057
0.221
0.190
0.127

Table 1: Performance on Noisy-OR networks, w∗ = 10: Normalized Hamming Distance, absolute
error, relative error and time.

randomly. The grid networks have the structure of a square, with edges directed to form a diagonal
flow (all parallel edges have the same direction). They were generated by specifying N (a square
integer) and K (we used K=2). We also varied the number of evidence nodes, denoted by |e| in
the tables. The parameter values are reported in each table. For all the problems, Gibbs sampling
performed consistently poorly so we only include part of its results here.
In our experiments we focused on the approximation power of MC-BU(i). We compared two
versions of the algorithm. In the first version, for every cluster, we used the max operator in all its
mini-clusters, except for one of them that was processed by summation. In the second version, we
used the operator mean in all the mini-clusters. We investigated this second version of the algorithm
for two reasons: (1) we compare MC-BU(i) with IBP and Gibbs sampling, both of which are also
approximation algorithms, so it would not be possible to compare with a bounding scheme; (2) we
observed in our experiments that, although the bounds improve as the i-bound increases, the quality
of bounds computed by MC-BU(i) was still poor, with upper bounds being greater than 1 in many
cases.2 Notice that we need to maintain the sum operator for at least one of the mini-clusters. The
mean operator simply performs summation and divides by the number of elements in the sum. For
example, if A, B, C are binary variables (taking values 0 and 1), and f (A, B, C) is the aggregated
function of one mini-cluster,
and elim = {A, B}, then computing the message h(C) by the mean
P
operator gives: 1/4 A,B∈{0,1} f (A, B, C).
We computed the exact solution and used three different measures of accuracy: 1) Normalized
Hamming Distance (NHD) - we picked the most likely value for each variable for the approximate
and for the exact, took the ratio between the number of disagreements and the total number of variables, and averaged over the number of problems that we ran for each class; 2) Absolute Error (Abs.
Error) - is the absolute value of the difference between the approximate and the exact, averaged
over all values (for each variable), all variables and all problems; 3) Relative Error (Rel. Error) - is
the absolute value of the difference between the approximate and the exact, divided by the exact,
averaged over all values (for each variable), all variables and all problems. For coding networks,
2. Wexler and Meek (2008) compared the upper/lower bounding properties of the mini-bucket on computing probability
of evidence. Rollon and Dechter (2010) further investigated heuristic schemes for mini-bucket partitioning.

289

M ATEESCU , K ASK , G OGATE & D ECHTER

10
|e| 20
30

N=50, P=3, 25 instances
Abs. Error

NHD
max

mean
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0

IBP
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0

MC-BU(2)

MC-BU(5)

MC-BU(8)

MC-BU(11)

MC-BU(14)

max

1.3E-03
5.3E-04
2.3E-04
1.0E-03
4.6E-04
2.0E-04
6.6E-04
1.8E-04
3.4E-05
2.6E-04
3.8E-05
6.4E-07
4.2E-05
0
0

mean
1.3E-04
3.6E-04
6.8E-04
9.6E-04
4.0E-04
1.9E-04
8.3E-04
4.1E-04
1.9E-04
5.7E-04
1.8E-04
3.4E-05
2.4E-04
3.8E-05
6.4E-07
4.1E-05
0
0

Rel. Error
max

Time

mean
7.9E-01
2.2E+00
4.2E+00
5.8E+00
2.4E+00
1.2E+00
5.1E+00
2.4E+00
1.2E+00
3.5E+00
1.0E+00
2.1E-01
1.5E+00
2.3E-01
4.0E-03
2.4E-01
0
0

8.2E+00
3.1E+00
1.4E+00
6.4E+00
2.7E+00
1.2E+00
4.0E+00
1.1E+00
2.1E-01
1.6E+00
2.3E-01
4.0E-03
2.5E-01
0
0

max

mean
0.242
0.184
0.121
0.108
0.077
0.064
0.133
0.105
0.095
0.509
0.406
0.308
2.378
1.439
0.624
7.875
2.093
0.638

0.107
0.077
0.064
0.133
0.104
0.098
0.498
0.394
0.300
2.339
1.421
0.613
7.805
2.075
0.630

Table 2: Performance on Noisy-OR networks, w∗ = 16: Normalized Hamming Distance, absolute
error, relative error and time.
Noisy-OR networks, N=50, P=3, evid=20, w*=16, 25 instances

Noisy-OR networks, N=50, P=3, evid=10, w*=16, 25 instances

1e+0

1e+0

MC
IBP
Gibbs Sampling

MC
IBP
Gibbs Sampling

1e-1

Absolute error

Absolute error

1e-1

1e-2

1e-3

1e-2

1e-3

1e-4

1e-4

1e-5

1e-5
0

2

4

6

8

10

12

14

16

0

2

4

6

8

10

12

14

16

i-bound

i-bound

Figure 7: Absolute error for Noisy-OR networks.
we report only one measure, Bit Error Rate (BER). In terms of the measures defined above, BER
is the normalized Hamming distance between the approximate (computed by an algorithm) and the
actual input (which in the case of coding networks may be different from the solution given by
exact algorithms), so we denote them differently to make this semantic distinction. We also report
the time taken by each algorithm. For reported metrics (time, error, etc.) provided in the Tables, we
give both mean and max values.
In Figure 6 we show that IBP converges after about 5 iterations. So, while in our experiments
we report its time for 30 iterations, its time is even better when sophisticated termination is used.
These results are typical of all runs.

290

J OIN -G RAPH P ROPAGATION A LGORITHMS

Random networks, N=50, P=2, k=2, evid=0, w*=10, 50 instances

Random networks, N=50, P=2, k=2, evid=10, w*=10, 50 instances

0.16

0.16

MC
Gibbs Sampling
IBP

0.14

0.14

MC
Gibbs Sampling
IBP

0.12

0.10

Absolute error

Absolute error

0.12

0.08
0.06
0.04

0.10
0.08
0.06
0.04

0.02

0.02

0.00

0.00

0

2

4

6

8

10

0

2

4

i-bound

6

8

10

i-bound

Figure 8: Absolute error for random networks.
BER

σ = .22
max
mean

IBP
GS
MC-BU(2)
MC-BU(4)
MC-BU(6)
MC-BU(8)

0.000
0.483
0.002
0.001
0.000
0.000

0.000
0.483
0.002
0.001
0.000
0.000

IBP
GS
MC-BU(2)
MC-BU(4)
MC-BU(6)
MC-BU(8)
MC-BU(10)

0.000
0.506
0.006
0.006
0.005
0.002
0.001

0.000
0.506
0.006
0.006
0.005
0.002
0.001

σ = .26
σ = .32
σ = .40
max
mean
max
mean
max
mean
N=100, P=3, 50 instances, w*=7
0.000 0.000 0.002 0.002 0.022 0.022
0.483 0.483 0.483 0.483 0.483 0.483
0.004 0.004 0.024 0.024 0.068 0.068
0.002 0.002 0.018 0.018 0.046 0.045
0.000 0.000 0.004 0.004 0.038 0.038
0.000 0.000 0.002 0.002 0.023 0.023
N=100, P=4, 50 instances, w*=11
0.000 0.000 0.002 0.002 0.013 0.013
0.506 0.506 0.506 0.506 0.506 0.506
0.015 0.015 0.043 0.043 0.093 0.094
0.017 0.017 0.049 0.049 0.104 0.102
0.011 0.011 0.035 0.034 0.071 0.074
0.004 0.004 0.022 0.022 0.059 0.059
0.001 0.001 0.008 0.008 0.033 0.032

σ = .51
max
mean

Time

0.088
0.483
0.132
0.110
0.106
0.091

0.088
0.483
0.131
0.110
0.106
0.091

0.00
31.36
0.08
0.08
0.12
0.19

0.075
0.506
0.157
0.158
0.151
0.121
0.101

0.075
0.506
0.157
0.158
0.150
0.122
0.102

0.00
39.85
0.19
0.19
0.29
0.71
1.87

Table 3: Bit Error Rate (BER) for coding networks.

Random Noisy-OR networks results are summarized in Tables 1 and 2, and Figure 7. For NHD,
both IBP and MC-BU gave perfect results. For the other measures, we noticed that IBP is more
accurate when there is no evidence by about an order of magnitude. However, as evidence is added,
IBP’s accuracy decreases, while MC-BU’s increases and they give similar results. We see that
MC-BU gets better as the accuracy parameter i increases, which shows its anytime behavior.
General random networks results are summarized in Figure 8. They are similar to those for
random Noisy-OR networks. Again, IBP has the best result only when the number of evidence
variables is small. It is remarkable how quickly MC-BU surpasses the performance of IBP as
evidence is added (for more, see the results of Mateescu et al., 2002).
Random coding networks results are given in Table 3 and Figure 9. The instances fall within the
class of linear block codes, (σ is the channel noise level). It is known that IBP is very accurate for
this class. Indeed, these are the only problems that we experimented with where IBP outperformed
MC-BU throughout. The anytime behavior of MC-BU can again be seen in the variation of numbers
in each column and more vividly in Figure 9.
291

M ATEESCU , K ASK , G OGATE & D ECHTER

Coding networks, N=100, P=4, sigma=.51, w*=12, 50 instances

Coding networks, N=100, P=4, sigma=.22, w*=12, 50 instances

0.18

0.007
MC
IBP

0.006

MC
IBP

0.16

0.005

Bit Error Rate

Bit Error Rate

0.14
0.004
0.003
0.002

0.12

0.10

0.001

0.08
0.000

0.06
0

2

4

6

8

10

0

12

2

4

6

8

10

12

i-bound

i-bound

Figure 9: Bit Error Rate (BER) for coding networks.
Grid 15x15, evid=10, w*=22, 10 instances

Grid 15x15, evid=10, w*=22, 10 instances

0.06

12
MC
IBP

0.05

MC
IBP

10

Time (seconds)

Absolute error

8
0.04

0.03

0.02

6

4

2
0.01

0

0.00
0

2

4

6

8

10

12

14

16

18

0

2

4

6

i-bound

8

10

12

14

16

18

i-bound

Figure 10: Grid 15x15: absolute error and time.
Grid networks results are given in Figure 10. We notice that IBP is more accurate for no evidence
and MC-BU is better as more evidence is added. The same behavior was consistently manifested
for smaller grid networks that we experimented with (from 7x7 up to 14x14).
CPCS networks results We also tested on three CPCS benchmark files. The results are given
in Figure 11. It is interesting to notice that the MC-BU scheme scales up to fairly large networks,
like the real life example of CPCS422 (induced width 23). IBP is again more accurate when there
is no evidence, but is surpassed by MC-BU when evidence is added. However, whereas MC-BU
is competitive with IBP time-wise when i-bound is small, its runtime grows rapidly as i-bound
increases. For more details on all these benchmarks see the results of Mateescu et al. (2002).
Summary Our results show that, as expected, IBP is superior to all other approximations for
coding networks. However, for random Noisy-OR, general random, grid networks and the CPCS
networks, in the presence of evidence, the mini-clustering scheme is often superior even in its weakest form. The empirical results are particularly encouraging as we use an un-optimized scheme that
exploits a universal principle applicable to many reasoning tasks.

292

J OIN -G RAPH P ROPAGATION A LGORITHMS

CPCS 422, evid=0, w*=23, 1 instance

CPCS 422, evid=10, w*=23, 1 instance

0.05

0.05
MC
IBP

MC
IBP

0.04

Absolute error

Absolute error

0.04

0.03

0.02

0.01

0.03

0.02

0.01

0.00

0.00
2

4

6

8

10

12

14

16

18

2

4

6

i-bound

8

10

12

14

16

18

i-bound

Figure 11: Absolute error for CPCS422.

4. Join-Graph Decomposition and Propagation
In this section we introduce algorithm Iterative Join-Graph Propagation (IJGP) which, like miniclustering, is designed to benefit from bounded inference, but also exploit iterative message-passing
as used by IBP. Algorithm IJGP can be viewed as an iterative version of mini-clustering, improving
the quality of approximation, especially for low i-bounds. Given a cluster of the decomposition,
mini-clustering can potentially create a different partitioning for every message sent to a neighbor.
This dynamic partitioning can happen because the incoming message from each neighbor has to be
excluded when realizing the partitioning, so a different set of functions are split into mini-clusters for
every message to a neighbor. We can define a version of mini-clustering where for every cluster we
create a unique static partition into mini-clusters such that every incoming message can be included
into one of the mini-clusters. This version of MC can be extended into IJGP by introducing some
links between mini-clusters of the same cluster, and carefully limiting the interaction between the
resulting nodes in order to eliminate over-counting.
Algorithm IJGP works on a general join-graph that may contain cycles. The cluster size of the
graph is user adjustable via the i-bound (providing the anytime nature), and the cycles in the graph
allow the iterative application of message-passing. In Subsection 4.1 we introduce join-graphs and
discuss their properties. In Subsection 4.2 we describe the IJGP algorithm itself.
4.1 Join-Graphs
D EFINITION 7 (join-graph decomposition) A join-graph decomposition for a belief network B =
hX, D, G, P i is a triple D = hJG, χ, ψi, where JG = (V, E) is a graph, and χ and ψ are labeling
functions which associate with each vertex v ∈ V two sets, χ(v) ⊆ X and ψ(v) ⊆ P such that:
1. For each pi ∈ P , there is exactly one vertex v ∈ V such that pi ∈ ψ(v), and scope(pi ) ⊆
χ(v).
2. (connectedness) For each variable Xi ∈ X, the set {v ∈ V |Xi ∈ χ(v)} induces a connected
subgraph of JG. The connectedness requirement is also called the running intersection property.

293

M ATEESCU , K ASK , G OGATE & D ECHTER

2,4

1,2,4

2,3,4

A

C
1,4

2,3,4

A

3,4

B

2,4

1,2,4

C
1,4

1,3,4

B

a)

3
1,3,4

b)

Figure 12: An edge-labeled decomposition.
We will often refer to a node in V and its CPT functions as a cluster3 and use the term joingraph decomposition and cluster-graph interchangeably. Clearly, a join-tree decomposition or a
cluster-tree is the special case when the join-graph D is a tree.
It is clear that one of the problems of message propagation over cyclic join-graphs is overcounting. To reduce this problem we devise a scheme, which avoids cyclicity with respect to any
single variable. The algorithm works on edge-labeled join-graphs.
D EFINITION 8 (minimal edge-labeled join-graph decompositions) An edge-labeled join-graph
decomposition for B = hX, D, G, P i is a four-tuple D = hJG, χ, ψ, θi, where JG = (V, E)
is a graph, χ and ψ associate with each vertex v ∈ V the sets χ(v) ⊆ X and ψ(v) ⊆ P and θ
associates with each edge (v, u) ⊂ E the set θ((v, u)) ⊆ X such that:
1. For each function pi ∈ P , there is exactly one vertex v ∈ V such that pi ∈ ψ(v), and
scope(pi ) ⊆ χ(v).
2. (edge-connectedness) For each edge (u, v), θ((u, v)) ⊆ χ(u) ∩ χ(v), such that ∀Xi ∈ X,
any two clusters containing Xi can be connected by a path whose every edge label includes
Xi .
Finally, an edge-labeled join-graph is minimal if no variable can be deleted from any label while
still satisfying the edge-connectedness property.
D EFINITION 9 (separator, eliminator of edge-labeled join-graphs) Given two adjacent vertices
u and v of JG, the separator of u and v is defined as sep(u, v) = θ((u, v)), and the eliminator of u
with respect to v is elim(u, v) = χ(u) − θ((u, v)). The separator width is max(u,v) |sep(u, v)|.
Edge-labeled join-graphs can be made label minimal by deleting variables from the labels while
maintaining connectedness (if an edge label becomes empty, the edge can be deleted). It is easy to
see that,
Proposition 1 A minimal edge-labeled join-graph does not contain any cycle relative to any single
variable. That is, any two clusters containing the same variable are connected by exactly one path
labeled with that variable.
Notice that every minimal edge-labeled join-graph is edge-minimal (no edge can be deleted), but
not vice-versa.
3. Note that a node may be associated with an empty set of CPTs.

294

J OIN -G RAPH P ROPAGATION A LGORITHMS

Example 4 The example in Figure 12a shows an edge minimal join-graph which contains a cycle
relative to variable 4, with edges labeled with separators. Notice however that if we remove variable 4 from the label of one edge we will have no cycles (relative to single variables) while the
connectedness property is still maintained.
The mini-clustering approximation presented in the previous section works by relaxing the jointree requirement of exact inference into a collection of join-trees having smaller cluster size. It
introduces some independencies in the original problem via node duplication and applies exact inference on the relaxed model requiring only two message passings. For the class of IJGP algorithms
we take a different route. We choose to relax the tree-structure requirement and use join-graphs
which do not introduce any new independencies, and apply iterative message-passing on the resulting cyclic structure.
Indeed, it can be shown that any join-graph of a belief network is an I-map (independency map,
Pearl, 1988) of the underlying probability distribution relative to node-separation. Since we plan
to use minimally edge-labeled join-graphs to address over-counting problems, the question is what
kind of independencies are captured by such graphs.
D EFINITION 10 (edge-separation in edge-labeled join-graphs) Let D = hJG, χ, ψ, θi, JG =
(V, E) be an edge-labeled decomposition of a Bayesian network B = hX, D, G, P i. Let NW , NY ⊆
V be two sets of nodes, and EZ ⊆ E be a set of edges in JG. Let W, Y, Z be their corresponding
sets of variables (W = ∪v∈NW χ(v), Z = ∪e∈EZ θ(e)). We say that EZ edge-separates NW and
NY in D if there is no path between NW and NY in the JG graph whose edges in EZ are removed.
In this case we also say that W is separated from Y given Z in D, and write hW |Z|Y iD . Edgeseparation in a regular join-graph is defined relative to its separators.
T HEOREM 4 Any edge-labeled join-graph decomposition D = hJG, χ, ψ, θi of a belief network
B = hX, D, G, P i is an I-map of P relative to edge-separation. Namely, any edge separation in D
corresponds to conditional independence in P .
Proof: Let M G be the moral graph of BN . Since M G is an I-map of P , it is enough to prove that
JG is an I-map of M G. Let NW and NY be disjoint sets of nodes and NZ be a set of edges in JG,
and W, Z, Y be their corresponding sets of variables in M G. We will prove:
hNW |NZ |NY iJG =⇒ hW |Z|Y iM G
by contradiction. Since the sets W, Z, Y may not be disjoint, we will actually prove that hW −
Z|Z|Y − ZiM G holds, this being equivalent to hW |Z|Y iM G .
Supposing hW − Z|Z|Y − ZiM G is false, then there exists a path α = γ1 , γ2 , . . . , γn−1 , β = γn
in M G that goes from some variable α = γ1 ∈ W − Z to some variable β = γn ∈ Y − Z without
intersecting variables in Z. Let Nv be the set of all nodes in JG that contain variable v ∈ X, and
let us consider the set of nodes:
S = ∪ni=1 Nγi − NZ
We argue that S forms a connected sub-graph in JG. First, the running intersection property
ensures that every Nγi , i = 1, . . . , n, remains connected in JG after removing the nodes in NZ
(otherwise, it must be that there was a path between the two disconnected parts in the original JG,
which implies that a γi is part of Z, which is a contradiction). Second, the fact that (γi , γi+1 ), i =
295

M ATEESCU , K ASK , G OGATE & D ECHTER

1, . . . , n − 1, is an edge in the moral graph M G implies that there is a conditional probability table
(CPT) on both γi and γi+1 , i = 1, . . . , n − 1 (and perhaps other variables). From property 1 of the
definition of the join-graph, it follows that for all i = 1, . . . , n − 1 there exists a node in JG that
contains both γi and γi+1 . This proves the existence of a path in the mutilated join-graph (JG with
NZ pulled out) from a node in NW containing α = γ1 to the node containing both γ1 and γ2 (Nγ1
is connected), then from that node to the one containing both γ2 and γ3 (Nγ2 is connected), and
so on until we reach a node in NY containing β = γn . This shows that hNW |NZ |NY iJG is false,
concluding the proof by contradiction. 2
Interestingly however, deleting variables from edge labels or removing edges from edge-labeled
join-graphs whose clusters are fixed will not increase the independencies captured by edge-labeled
join-graphs. That is,
Proposition 2 Any two (edge-labeled) join-graphs defined on the same set of clusters, sharing (V ,
χ, ψ), express exactly the same set of independencies relative to edge-separation, and this set of
independencies is identical to the one expressed by node separation in the primal graph of the
join-graph.
Proof: This follows by looking at the primal graph of the join-graph (obtained by connecting any
two nodes in a cluster by an arc over the original variables as nodes) and observing that any edgeseparation in a join-graph corresponds to a node separation in the primal graph and vice-versa. 2
Hence, the issue of minimizing computational over-counting due to cycles appears to be unrelated to the problem of maximizing independencies via minimal I-mapness. Nevertheless, to avoid
over-counting as much as possible, we still prefer join-graphs that minimize cycles relative to each
variable. That is, we prefer minimal edge-labeled join-graphs.
Relationship with region graphs There is a strong relationship between our join-graphs and the
region graphs of Yedidia et al. (2000, 2001, 2005). Their approach was inspired by advances in
statistical physics, when it was realized that computing the partition function is essentially the same
combinatorial problem that expresses probabilistic reasoning. As a result, variational methods from
physics could have counterparts in reasoning algorithms. It was proved by Yedidia et al. (2000,
2001) that belief propagation on loopy networks can only converge (when it does so) to stationary
points of the Bethe free energy. The Bethe approximation is only the simplest case of the more
general Kikuchi (1951) cluster variational method. The idea is to group the variables together in
clusters and perform exact computation in each cluster. One key question is then how to aggregate
the results, and how to account for the variables that are shared between clusters. Again, the idea
that everything should be counted exactly once is very important. This led to the proposal of region
graphs (Yedidia et al., 2001, 2005) and the associated counting numbers for regions. They are
given as a possible canonical version of graphs that can support Generalized Belief Propagation
(GBP) algorithms. The join-graphs accomplish the same thing. The edge-labeled join-graphs can
be described as region graphs where the regions are the clusters and the labels on the edges. The
tree-ness condition with respect to every variable ensures that there is no over-counting.
A very similar approach to ours, which is also based on join-graphs appeared independently by
McEliece and Yildirim (2002), and it is based on an information theoretic perspective.

296

J OIN -G RAPH P ROPAGATION A LGORITHMS

Algorithm Iterative Join-Graph Propagation (IJGP)
Input An arc-labeled join-graph decomposition hJG, χ, ψ, θi, JG = (V, E) for B = hX, D, G, P i. Evidence variables var(e).
Output An augmented graph whose nodes are clusters containing the original CPTs and the messages received
from neighbors. Approximations of P (Xi |e), ∀Xi ∈ X.
Denote by h(u,v) the message from vertex u to v, nev (u) the neighbors of u in JG excluding v.
cluster(u) = ψ(u) ∪ {h(v,u) |(v, u) ∈ E}.
clusterv (u) = cluster(u) excluding message from v to u.
• One iteration of IJGP:
For every node u in JG in some topological order d and back, do
1. Process observed variables:
Assign relevant evidence to all pi ∈ ψ(u) χ(u) := χ(u) − var(e), ∀u ∈ V
2. Compute individual functions:
Include in H(u,v) each function in clusterv (u) whose scope does not contain variables in elim(u, v).
Denote by A the remaining functions.
P
Q
3. Compute and send to v the combined function: h(u,v) = elim(u,v) f ∈A f .
Send h(u,v) and the individual functions H(u,v) to node v.
Endfor
• Compute an approximation of P (Xi |e):
For every Xi ∈ X let u be
P a vertex in JG
Q such that Xi ∈ χ(u).
Compute P (Xi , e) = α χ(u)−{Xi } ( f ∈cluster(u) f )

Figure 13: Algorithm Iterative Join-Graph Propagation (IJGP).
4.2 Algorithm IJGP
Applying CTE iteratively to minimal edge-labeled join-graphs yields our algorithm Iterative JoinGraph Propagation (IJGP) described in Figure 13. One iteration of the algorithm applies messagepassing in a topological order over the join-graph, forward and back. When node u sends a message
(or messages) to a neighbor node v it operates on all the CPTs in its cluster and on all the messages
sent from its neighbors excluding the ones received from v. First, all individual functions that share
no variables with the eliminator are collected and sent to v. All the rest of the functions are combined
in a product and summed over the eliminator between u and v.
Based on the results by Lauritzen and Spiegelhalter (1988) and Larrosa, Kask, and Dechter
(2001) it can be shown that:
T HEOREM 5
1. If IJGP is applied to a join-tree decomposition it reduces to join-tree clustering, and therefore it is guaranteed to compute the exact beliefs in one iteration.
∗
2. The time complexity of one iteration of IJGP is O(deg · (n + N ) · dw +1 ) and its space
complexity is O(N · dθ ), where deg is the maximum degree of a node in the join-graph, n
is the number of variables, N is the number of nodes in the graph decomposition, d is the
maximum domain size, w∗ is the maximum cluster size and θ is the maximum label size.
For proof, see the properties of CTE presented by Kask et al. (2005).

297

M ATEESCU , K ASK , G OGATE & D ECHTER

3

A
2
B

C

a)

A

AB

3

A
A

B

b)

1

ABC

2
AB

A

A

1
AB

ABC

c)

Figure 14: a) A belief network; b) A dual join-graph with singleton labels; c) A dual join-graph
which is a join-tree.

The special case of Iterative Belief Propagation Iterative belief propagation (IBP) is an iterative application of Pearl’s algorithm that was defined for poly-trees (Pearl, 1988), to any Bayesian
network. We will describe IBP as an instance of join-graph propagation over a dual join-graph.
D EFINITION 11 (dual graphs, dual join-graphs) Given a set of functions F = {f1 , . . . , fl } over
scopes S1 , . . . , Sl , the dual graph of F is a graph DG = (V, E, L) that associates a node with
each function, namely V = F and an edge connects any two nodes whose function’s scope share a
variable, E = {(fi , fj )|Si ∩ Sj 6= φ}. L is a set of labels for the edges, each edge being labeled
by the shared variables of its nodes, L = {lij = Si ∩ Sj |(i, j) ∈ E}. A dual join-graph is an edgelabeled edge subgraph of DG that satisfies the connectedness property. A minimal dual join-graph
is a dual join-graph for which none of the edge labels can be further reduced while maintaining the
connectedness property.
Interestingly, there may be many minimal dual join-graphs of the same dual graph. We will
define Iterative Belief Propagation on any dual join-graph. Each node sends a message over an edge
whose scope is identical to the label on that edge. Since Pearl’s algorithm sends messages whose
scopes are singleton variables only, we highlight minimal singleton-label dual join-graphs.
Proposition 3 Any Bayesian network has a minimal dual join-graph where each edge is labeled by
a single variable.
Proof: Consider a topological ordering of the nodes in the acyclic directed graph of the Bayesian
network d = X1 , . . . , Xn . We define the following dual join-graph. Every node in the dual graph
D, associated with pi is connected to node pj , j < i if Xj ∈ pa(Xi ). We label the edge between pj
and pi by variable Xj , namely lij = {Xj }. It is easy to see that the resulting edge-labeled subgraph
of the dual graph satisfies connectedness. (Take the original acyclic graph G and add to each node
its CPT family, namely all the other parents that precede it in the ordering. Since G already satisfies
connectedness so is the minimal graph generated.) The resulting labeled graph is a dual graph with
singleton labels. 2

Example 5 Consider the belief network on 3 variables A, B, C with CPTs 1.P (C|A, B),
2.P (B|A) and 3.P (A), given in Figure 14a. Figure 14b shows a dual graph with singleton labels on the edges. Figure 14c shows a dual graph which is a join-tree, on which belief propagation
can solve the problem exactly in one iteration (two passes up and down the tree).

298

J OIN -G RAPH P ROPAGATION A LGORITHMS

Algorithm Iterative Belief Propagation (IBP)
Input: An edge-labeled dual join-graph DG = (V, E, L) for a Bayesian network B = hX, D, G, P i. Evidence e.
Output: An augmented graph whose nodes include the original CPTs and the messages received from neighbors. Approximations of P (Xi |e), ∀Xi ∈ X. Approximations of P (Fi |e), ∀Fi ∈ B.
Denote by: hvu the message from u to v; ne(u) the neighbors of u in V ; nev (u) = ne(u) − {v}; luv the
label of (u, v) ∈ E; elim(u, v) = scope(u) − scope(v).
• One iteration of IBP
For every node u in DJ in a topological order and back, do:
1. Process observed variables
Assign evidence variables to the each pi and remove them from the labeled edges.
2. Compute and send to v the function:
X
Y
hvu =
(pu ·
hui )
elim(u,v)

{hu
i ,i∈nev (u)}

Endfor
• Compute approximations of P (Fi |e), P (Xi |e):
For every Xi ∈QX let u be the vertex of family Fi in DJ,
P (Fi , e) = α( hu ,u∈ne(i) hui ) · pu ;
P i
P (Xi , e) = α scope(u)−{Xi } P (Fi , e).

Figure 15: Algorithm Iterative Belief Propagation (IBP).
For completeness, we present algorithm IBP, which is a special case of IJGP, in Figure 15. It
is easy to see that one iteration of IBP is time and space linear in the size of the belief network. It
can be shown that when IBP is applied to a minimal singleton-labeled dual graph it coincides with
Pearl’s belief propagation applied directly to the acyclic graph representation. Also, when the dual
join-graph is a tree IBP converges after one iteration (two passes, up and down the tree) to the exact
beliefs.
4.3 Bounded Join-Graph Decompositions
Since we want to control the complexity of join-graph algorithms, we will define it on decompositions having bounded cluster size. If the number of variables in a cluster is bounded by i, the
time and space complexity of processing one cluster is exponential in i. Given a join-graph decomposition D = hJG, χ, ψ, θi, the accuracy and complexity of the (iterative) join-graph propagation
algorithm depends on two different width parameters, defined next.
D EFINITION 12 (external and internal widths) Given an edge-labeled join-graph decomposition
D = hJG, χ, ψ, θi of a network B = hX, D, G, P i, the internal width of D is maxv∈V |χ(v)|, while
the external width of D is the treewidth of JG as a graph.
Using this terminology we can now state our target decomposition more clearly. Given a graph
G, and a bounding parameter i we wish to find a join-graph decomposition D of G whose internal
width is bounded by i and whose external width is minimized. The bound i controls the complexity
of join-graph processing while the external width provides some measure of its accuracy and speed
of convergence, because it measures how close the join-graph is to a join-tree.
299

M ATEESCU , K ASK , G OGATE & D ECHTER

Algorithm Join-Graph Structuring(i)
1. Apply procedure schematic mini-bucket(i).
2. Associate each resulting mini-bucket with a node in the join-graph, the variables of the
nodes are those appearing in the mini-bucket, the original functions are those in the minibucket.
3. Keep the edges created by the procedure (called out-edges) and label them by the regular
separator.
4. Connect the mini-bucket clusters belonging to the same bucket in a chain by in-edges
labeled by the single variable of the bucket.

Figure 16: Algorithm Join-Graph Structuring(i).
Procedure Schematic Mini-Bucket(i)
1. Order the variables from X1 to Xn minimizing (heuristically) induced-width, and associate a bucket for each variable.
2. Place each CPT in the bucket of the highest index variable in its scope.
3. For j = n to 1 do:
Partition the functions in bucket(Xj ) into mini-buckets having at most i variables.
For each mini-bucket mb create a new scope-function (message) f where scope(f ) =
{X|X ∈ mb} − {Xi } and place scope(f) in the bucket of its highest variable. Maintain
an edge between mb and the mini-bucket (created later) of f .

Figure 17: Procedure Schematic Mini-Bucket(i).
We can consider two classes of algorithms. One class is partition-based. It starts from a given
tree-decomposition and then partitions the clusters until the decomposition has clusters bounded by
i. An alternative approach is grouping-based. It starts from a minimal dual-graph-based join-graph
decomposition (where each cluster contains a single CPT) and groups clusters into larger clusters
as long as the resulting clusters do not exceed the given bound. In both methods one should attempt
to reduce the external width of the generated graph-decomposition. Our partition-based approach
inspired by the mini-bucket idea (Dechter & Rish, 1997) is as follows.
Given a bound i, algorithm Join-Graph Structuring(i) applies the procedure Schematic MiniBucket(i), described in Figure 17. The procedure only traces the scopes of the functions that would
be generated by the full mini-bucket procedure, avoiding actual computation. The procedure ends
with a collection of mini-bucket trees, each rooted in the mini-bucket of the first variable. Each of
these trees is minimally edge-labeled. Then, in-edges labeled with only one variable are introduced,
and they are added only to obtain the running intersection property between branches of these trees.
Proposition 4 Algorithm Join-Graph Structuring(i) generates a minimal edge-labeled join-graph
decomposition having bound i.
Proof: The construction of the join-graph specifies the vertices and edges of the join-graph, as well
as the variable and function labels of each vertex. We need to demonstrate that 1) the connectedness
property holds, and 2) that edge-labels are minimal.

300

J OIN -G RAPH P ROPAGATION A LGORITHMS

G: (GFE)

GFE

P(G|F,E)
EF

E: (EBF)

(EF)

EBF

P(E|B,F)

P(F|C,D)

F: (FCD)

(BF)

BF
F

FCD

BF

CD

D: (DB)

(CD)

P(D|B)

CDB
CB

C: (CAB) (CB)

P(C|A,B)

B
CAB
BA

B: (BA)

(AB)

A: (A)

(A)

(B)

P(B|A)

BA
A
P(A)

A

(b)

(a)

Figure 18: Join-graph decompositions.
Connectedness property specifies that for any 2 vertices u and v, if vertices u and v contain
variable X, then there must be a path u, w1 , . . . , wm , v between u and v such that every vertex on
this path contains variable X. There are two cases here. 1) u and v correspond to 2 mini-buckets
in the same bucket, or 2) u and v correspond to mini-buckets in different buckets. In case 1 we
have 2 further cases, 1a) variable X is being eliminated in this bucket, or 1b) variable X is not
eliminated in this bucket. In case 1a, each mini-bucket must contain X and all mini-buckets of the
bucket are connected as a chain, so the connectedness property holds. In case 1b, vertexes u and v
connect to their (respectively) parents, who in turn connect to their parents, etc. until a bucket in
the scheme where variable X is eliminated. All nodes along this chain connect variable X, so the
connectedness property holds. Case 2 resolves like case 1b.
To show that edge labels are minimal, we need to prove that there are no cycles with respect to
edge labels. If there is a cycle with respect to variable X, then it must involve at least one in-edge
(edge connecting two mini-buckets in the same bucket). This means variable X must be the variable
being eliminated in the bucket of this in-edge. That means variable X is not contained in any of the
parents of the mini-buckets of this bucket. Therefore, in order for the cycle to exist, another in-edge
down the bucket-tree from this bucket must contain X. However, this is impossible as this would
imply that variable X is eliminated twice. 2

Example 6 Figure 18a shows the trace of procedure schematic mini-bucket(3) applied to the problem described in Figure 2a. The decomposition in Figure 18b is created by the algorithm graph
structuring. The only cluster partitioned is that of F into two scopes (FCD) and (BF), connected by
an in-edge labeled with F.
A range of edge-labeled join-graphs is shown in Figure 19. On the left side we have a graph
with smaller clusters, but more cycles. This is the type of graph IBP works on. On the right side
we have a tree decomposition, which has no cycles at the expense of bigger clusters. In between,
there could be a number of join-graphs where maximum cluster size can be traded for number of
cycles. Intuitively, the graphs on the left present less complexity for join-graph algorithms because
the cluster size is smaller, but they are also likely to be less accurate. The graphs on the right side
301

M ATEESCU , K ASK , G OGATE & D ECHTER

A

A

A

C

ABC

AB
ABDE

BC

BE

C

A

A

ABC

AB

C

BCE

C
BC

BC

ABDE

ABCDE

DE

CE

CDE

C
DE

CE

CE

CDEF

CDEF

CDEF

CDEF
F

FGH

H

FGH

H

FGI

GH

GI

F

H

GHIJ

H

FGH
H
F

F

F
FG

ABCDE

BCE

C
DE

BCE

FGI

GI

F
F

GH

GHIJ

FGI

GH

GI

GHI
GHIJ

FGHI

GHIJ

more accuracy
less complexity

Figure 19: Join-graphs.
are computationally more complex, because of the larger cluster size, but they are likely to be more
accurate.
4.4 The Inference Power of IJGP
The question we address in this subsection is why propagating the messages iteratively should help.
Why is IJGP upon convergence superior to IJGP with one iteration and superior to MC? One clue
can be provided when considering deterministic constraint networks which can be viewed as “extreme probabilistic networks”. It is known that constraint propagation algorithms, which are analogous to the messages sent by belief propagation, are guaranteed to converge and are guaranteed
to improve with iteration. The propagation scheme of IJGP works similar to constraint propagation
relative to the flat network abstraction of the probability distribution (where all non-zero entries
are normalized to a positive constant), and propagation is guaranteed to be more accurate for that
abstraction at least.
In the following we will shed some light on the IJGP’s behavior by making connections with
the well-known concept of arc-consistency from constraint networks (Dechter, 2003). We show
that: (a) if a variable-value pair is assessed as having a zero-belief, it remains as zero-belief in
subsequent iterations; (b) that any variable-value zero-beliefs computed by IJGP are correct; (c) in
terms of zero/non-zero beliefs, IJGP converges in finite time. We have also empirically investigated
the hypothesis that if a variable-value pair is assessed by IBP or IJGP as having a positive but very
close to zero belief, then it is very likely to be correct. Although the experimental results shown in
this paper do not contradict this hypothesis, some examples in more recent experiments by Dechter,
Bidyuk, Mateescu, and Rollon (2010) invalidate it.

302

J OIN -G RAPH P ROPAGATION A LGORITHMS

4.4.1 IJGP

AND

A RC -C ONSISTENCY

For any belief network we can define a constraint network that captures the assignments having
strictly positive probability. We will show a correspondence between IJGP applied to the belief
network and an arc-consistency algorithm applied to the constraint network. Since arc-consistency
algorithms are well understood, this correspondence not only proves the target claims, but may
provide additional insight into the behavior of IJGP. It justifies the iterative application of belief
propagation, and it also illuminates its “distance” from being complete.
D EFINITION 13 (constraint satisfaction problem) A Constraint Satisfaction Problem (CSP) is a
triple hX, D, Ci, where X = {X1 , . . . , Xn } is a set of variables associated with a set of discretevalued domains D = {D1 , . . . , Dn } and a set of constraints C = {C1 , . . . , Cm }. Each constraint
Ci is a pair hSi , Ri i where Ri is a relation Ri ⊆ DSi defined on a subset of variables Si ⊆ X and
DSi is a Cartesian product of the domains of variables Si . The relation Ri denotes all compatible
tuples of DSi allowed by the constraint. A projection operator π creates a new relation, πSj (Ri ) =
{x|x ∈ DSj and ∃y, y ∈ DSi \Sj and x∪y ∈ Ri }, where Sj ⊆ Si . Constraints can be combined with
the join operator 1, resulting in a new relation, Ri 1 Rj = {x|πSi (x) ∈ Ri and πSj (x) ∈ Rj }.
A solution is an assignment of values to all the variables x = (x1 , . . . , xn ), xi ∈ Di , such that
∀Ci ∈ C, xSi ∈ Ri . The constraint network represents its set of solutions, 1i Ci .
Given a belief network B, we define a flattening of the Bayesian network into a constraint
network called f lat(B), where all the zero entries in a probability table are removed from the corresponding relation. The network f lat(B) is defined over the same set of variables and has the same
set of domain values as B.
D EFINITION 14 (flat network) Given a Bayesian network B = hX, D, G, P i, the flat network
f lat(B) is a constraint network, where the set of variables is X, and for every Xi ∈ X and its
CPT P (Xi |pa(Xi )) ∈ B we define a constraint RFi over the family of Xi , Fi = {Xi } ∪ pa(Xi ) as
follows: for every assignment x = (xi , xpa(Xi ) ) to Fi , (xi , xpa(Xi ) ) ∈ RFi iff P (xi |xpa(Xi ) ) > 0.
T HEOREM 6 Given a belief network B = hX, D, G, P i, where X = {X1 , . . . , Xn }, for any tuple
x = (x1 , . . . , xn ): PB (x) > 0 ⇔ x ∈ sol(f lat(B)), where sol(f lat(B)) is the set of solutions of
the flat constraint network.
Proof: PB (x) > 0 ⇔ Πni=1 P (xi |xpa(Xi ) ) > 0 ⇔ ∀i ∈ {1, . . . , n}, P (xi |xpa(Xi ) ) > 0 ⇔ ∀i ∈
{1, . . . , n}, (xi , xpa(Xi ) ) ∈ RFi ⇔ x ∈ sol(f lat(B)). 2
Constraint propagation is a class of polynomial time algorithms that are at the center of constraint processing techniques. They were investigated extensively in the past three decades and the
most well known versions are arc-, path-, and i-consistency (Dechter, 1992, 2003).
D EFINITION 15 (arc-consistency) (Mackworth, 1977) Given a binary constraint network
(X, D, C), the network is arc-consistent iff for every binary constraint Rij ∈ C, every value v ∈ Di
has a value u ∈ Dj s.t. (v, u) ∈ Rij .

303

M ATEESCU , K ASK , G OGATE & D ECHTER

Note that arc-consistency is defined for binary networks, namely the relations involve at most
two variables. When a binary constraint network is not arc-consistent, there are algorithms that
can process it and enforce arc-consistency. The algorithms remove values from the domains of
the variables that violate arc-consistency until an arc-consistent network is generated. There are
several versions of improved performance arc-consistency algorithms, however we will consider a
non-optimal distributed version, which we call distributed arc-consistency.
D EFINITION 16 (distributed arc-consistency algorithm) The
algorithm
distributed
arcconsistency is a message-passing algorithm over a constraint network. Each node is a variable,
and maintains a current set of viable values Di . Let ne(i) be the set of neighbors of Xi in the
constraint graph. Every node Xi sends a message to any node Xj ∈ ne(i), which consists of the
values in Xj ’s domain that are consistent with the current Di , relative to the constraint Rji that
they share. Namely, the message that Xi sends to Xj , denoted by Dij , is:
Dij ← πj (Rji 1 Di )

(1)

Di ← Di ∩ (1k∈ne(i) Dki )

(2)

and in addition node i computes:

Clearly the algorithm can be synchronized into iterations, where in each iteration every node
computes its current domain based on all the messages received so far from its neighbors (Eq. 2), and
sends a new message to each neighbor (Eq. 1). Alternatively, Equations 1 and 2 can be combined.
The message Xi sends to Xj is:
Dij ← πj (Rji 1 Di 1k∈ne(i) Dki )

(3)

Next we will define a join-graph decomposition for the flat constraint network so that we can
establish a correspondence between the join-graph decomposition of a Bayesian network B and the
join-graph decomposition of its flat network f lat(B). Note that for constraint networks, the edge
labeling θ can be ignored.
D EFINITION 17 (join-graph decomposition of the flat network) Given a join-graph decomposition D = hJG, χ, ψ, θi of a Bayesian network B, the join-graph decomposition Df lat =
hJG, χ, ψf lat i of the flat constraint network f lat(B) has the same underlying graph structure
JG = (V, E) as D, the same variable-labeling of the clusters χ, and the mapping ψf lat maps
each cluster to relations corresponding to CPTs, namely Ri ∈ ψf lat (v) iff CPT pi ∈ ψ(v).
The distributed arc-consistency algorithm of Definition 16 can be applied to the join-graph decomposition of the flat network. In this case, the nodes that exchange messages are the clusters
(namely the elements of the set V of JG). The domain of a cluster of V is the set of tuples of the
join of the original relations in the cluster (namely the domain of cluster u is ./R∈ψf lat (u) R). The
constraints are binary, and involve clusters of V that are neighbors. For two clusters u and v, their
corresponding values tu and tv (which are tuples representing full assignments to the variables in
the cluster) belong to the relation Ruv (i.e., (tu , tv ) ∈ Ru,v ) if the projections over the separator (or
labeling θ) between u and v are identical, namely πθ((u,v)) tu = πθ((u,v)) tv .
304

J OIN -G RAPH P ROPAGATION A LGORITHMS

We define below the algorithm relational distributed arc-consistency (RDAC), that applies distributed arc-consistency to any join-graph decomposition of a constraint network. We call it relational to emphasize that the nodes exchanging messages are in fact relations over the original
problem variables, rather than simple variables as is the case for arc-consistency algorithms.
D EFINITION 18 (relational distributed arc-consistency algorithm: RDAC over a join-graph)
Given a join-graph decomposition of a constraint network, let Ri and Rj be the relations of two
clusters (Ri and Rj are the joins of the respective constraints in each cluster), having the scopes Si
and Sj , such that Si ∩ Sj 6= ∅. The message Ri sends to Rj denoted h(i,j) is defined by:
h(i,j) ← πSi ∩Sj (Ri )

(4)

where ne(i) = {j|Si ∩ Sj 6= ∅} is the set of relations (clusters) that share a variable with Ri . Each
cluster updates its current relation according to:
Ri ← Ri 1 (1k∈ne(i) h(k,i) )

(5)

Algorithm RDAC iterates until there is no change.
Equations 4 and 5 can be combined, just like in Equation 3. The message that Ri sends to Rj
becomes:
h(i,j) ← πSi ∩Sj (Ri 1 (1k∈ne(i) h(k,i) ))

(6)

To establish the correspondence with IJGP, we define the algorithm IJGP-RDAC that applies
RDAC in the same order of computation (schedule of processing) as IJGP.
D EFINITION 19 (IJGP-RDAC algorithm) Given the Bayesian network B = hX, D, G, P i, let
Df lat = hJG, χ, ψf lat , θi be any join-graph decomposition of the flat network f lat(B). The algorithm IJGP-RDAC is applied to the decomposition Df lat of f lat(B), and can be described as
IJGP applied to D, with the following modifications:
Q
1. Instead of , we use 1.
P
2. Instead of , we use π.
3. At end end, we update the domains of variables by:
Di ← Di ∩ πXi ((1v∈ne(u) h(v,u) ) 1 (1R∈ψ(u) R))

(7)

where u is the cluster containing Xi .
Note that in algorithm IJGP-RDAC, we could first merge all constraints in each cluster u into
a single constraint Ru =1R∈ψ(u) R. From our construction, IJGP-RDAC enforces arc-consistency
over the join-graph decomposition of the flat network. When the join-graph Df lat is a join-tree,
IJGP-RDAC solves the problem namely it finds all the solutions of the constraint network.

305

M ATEESCU , K ASK , G OGATE & D ECHTER

Proposition 5 Given the join-graph decomposition Df lat = hJG, χ, ψf lat , θi, JG = (V, E), of
the flat constraint network f lat(B), corresponding to a given join-graph decomposition D of a
Bayesian network B = hX, D, G, P i, the algorithm IJGP-RDAC applied to Df lat enforces arcconsistency over the join-graph Df lat .
Proof: IJGP-RDAC applied to the join-graph decomposition Df lat = hJG, χ, ψf lat , θi, JG =
(V, E), is equivalent to applying RDAC of Definition 18 to a constraint network that has vertices V
as its variables and {1R∈ψ(u) R|u ∈ V } as its relations. 2
Following the properties of convergence of arc-consistency, we can show that:
Proposition 6 Algorithm IJGP-RDAC converges in O(m · r) iterations, where m is the number of
edges in the join-graph and r is the maximum size of a separator Dsep(u,v) between two clusters.
Proof: This follows from the fact messages (which are relations) between clusters in IJGP-RDAC
change monotonically, as tuples are only successively removed from relations on separators. Since
the size of each relation on a separator is bounded by r and there are m edges, no more than O(m·r)
iterations will be needed. 2
In the following we will establish an equivalence between IJGP and IJGP-RDAC in terms of
zero probabilities.
Proposition 7 When IJGP and IJGP-RDAC are applied in the same order of computation, the
messages computed by IJGP are identical to those computed by IJGP-RDAC in terms of zero / nonzero probabilities. That is, h(u,v) (x) 6= 0 in IJGP iff x ∈ h(u,v) in IJGP-RDAC.
Proof: The proof is by induction. The base case is trivially true since messages h in IJGP are initialized to a uniform distribution and messages h in IJGP-RDAC are initialized to complete relations.
The induction step. Suppose that hIJGP
(u,v) is the message sent from u to v by IJGP. We will show
IJGP −RDAC
IJGP −RDAC
that if hIJGP
where h(u,v)
is the message sent by IJGP(u,v) (x) 6= 0, then x ∈ h(u,v)
RDAC from u to v. Assume that the claim holds for all messages received by u from its neighbors.
Let f ∈ clusterv (u) in IJGP and Rf be the corresponding relation in IJGP-RDAC,
and
P
Q t be an asIJGP
signment of values to variables in elim(u, v). We have h(u,v) (x) 6= 0 ⇔ elim(u,v) f f (x) 6= 0
Q
⇔ ∃t, f f (x, t) 6= 0 ⇔ ∃t, ∀f, f (x, t) 6= 0 ⇔ ∃t, ∀f, πscope(Rf ) (x, t) ∈ Rf ⇔ ∃t, πelim(u,v) (1Rf
IJGP −RDAC
IJGP −RDAC
. 2
⇔ x ∈ h(u,v)
πscope(Rf ) (x, t)) ∈ h(u,v)

Next we will show that IJGP computing marginal probability P (Xi = xi ) = 0 is equivalent to
IJGP-RDAC removing xi from the domain of variable Xi .
Proposition 8 IJGP computes P (Xi = xi ) = 0 iff IJGP-RDAC decides that xi 6∈ Di .
Proof: According to Proposition 7 messages computed by IJGP and IJGP-RDAC are identical in
terms of zero probabilities. Let f ∈ cluster(u) in IJGP and Rf be the corresponding relation in
IJGP-RDAC, and t be an assignment of values to variables in χ(u)\Xi . We will show that when
IJGP computes P (Xi = xi ) = 0 (upon convergence), then IJGP-RDAC computes xi 6∈ Di . We
306

J OIN -G RAPH P ROPAGATION A LGORITHMS

Q
Q
P
have P (Xi = xi ) =
f f (xi , t) = 0 ⇔ ∀t, ∃f, f (xi , t) = 0 ⇔
f f (xi ) = 0 ⇔ ∀t,
X\Xi
∀t, ∃Rf , πscope(Rf ) (xi , t) 6∈ Rf ⇔ ∀t, (xi , t) 6∈ (1Rf Rf (xi , t)) ⇔ xi 6∈ Di ∩ πXi (1Rf Rf (xi , t))
⇔ xi 6∈ Di . Since arc-consistency is sound, so is the decision of zero probabilities. 2
Next we will show that P (Xi = xi ) = 0 computed by IJGP is sound.
T HEOREM 7 Whenever IJGP finds P (Xi = xi ) = 0, then the probability P (Xi ) expressed by the
Bayesian network conditioned on the evidence is 0 as well.
Proof: According to Proposition 8, whenever IJGP finds P (Xi = xi ) = 0, the value xi is removed
from the domain Di by IJGP-RDAC, therefore value xi ∈ Di is a no-good of the network f lat(B),
and from Theorem 6 it follows that PB (Xi = xi ) = 0. 2
In the following we will show that the time it takes IJGP to find all P (Xi = xi ) = 0 is bounded.
Proposition 9 IJGP finds all P (Xi = xi ) = 0 in finite time, that is, there exists a number k, such
that no P (Xi = xi ) = 0 will be found after k iterations.
Proof: This follows from the fact that the number of iterations it takes for IJGP to compute P (Xi =
xi ) = 0 is exactly the same number of iterations IJGP-RDAC takes to remove xi from the domain
Di (Proposition 7 and Proposition 8), and the fact the IJGP-RDAC runtime is bounded (Proposition
6). 2
Previous results also imply that IJGP is monotonic with respect to zeros.
Proposition 10 Whenever IJGP finds P (Xi = xi ) = 0, it stays 0 during all subsequent iterations.
Proof: Since we know that relations in IJGP-RDAC are monotonically decreasing as the algorithm
progresses, it follows from the equivalence of IJGP-RDAC and IJGP (Proposition 7) that IJGP is
monotonic with respect to zeros. 2

4.4.2 A F INITE P RECISION P ROBLEM
On finite precision machines there is the danger that an underflow can be interpreted as a zero
value. We provide here a warning that an implementation of belief propagation should not allow
the creation of zero values by underflow. We show an example in Figure 20 where IBP’s messages
converge in the limit (i.e., in an infinite number of iterations), but they do not stabilize in any finite
number of iterations. If all the nodes Hk are set to value 1, the belief for any of the Xi variables as a
function of iteration is given in the table in Figure 20. After about 300 iterations, the finite precision
of our computer is not able to represent the value for Bel(Xi = 3), and this appears to be zero,
yielding the final updated belief (.5, .5, 0), when in fact the true updated belief should be (0, 0, 1).
Notice that (.5, .5, 0) cannot be regarded as a legitimate fixed point for IBP. Namely, if we would
initialize IBP with the values (.5, .5, 0), then the algorithm would maintain them, appearing to have
a fixed point, but initializing IBP with zero values cannot be expected to be correct. When we

307

M ATEESCU , K ASK , G OGATE & D ECHTER

X1

Prior for Xi

H3

H1

X3

X2

Xi

P ( Xi )

1

.45

2

.45

3

.1

H2
Hk Xi

CPT for Hk

Xj

P ( Hk | Xi , Xj )

1

1

2

1

1

2

1

1

1

3

3

1

1

… …

0

#iter

Bel(Xi = 1) Bel(Xi = 2) Bel(Xi = 3)

1

.45

.45

.1

2

.49721

.49721

.00545

3

.49986

.49986

.00027

100

…

…

1e-129

200

…

…

1e-260

300

.5

.5

0

True
belief

0

0

1

Figure 20: Example of a finite precision problem.
initialize with zeros we forcibly introduce determinism in the model, and IBP will always maintain
it afterwards.
However, this example does not contradict our theory because, mathematically, Bel(Xi = 3)
never becomes a true zero, and IBP never reaches a quiescent state. The example shows that a close
to zero belief network can be arbitrarily inaccurate. In this case the inaccuracy seems to be due to
the initial prior belief which are so different from the posterior ones.
4.4.3 ACCURACY OF IBP ACROSS B ELIEF D ISTRIBUTION
We present an empirical evaluation of the accuracy of IBP’s prediction for the range of belief distribution from 0 to 1. These results also extend to IJGP. In the previous section, we proved that zero
values inferred by IBP are correct, and we wanted to test the hypothesis that this property extends
to  small beliefs (namely, that are very close to zero). That is, if IBP infers a posterior belief close
to zero, then it is likely to be correct. The results presented in this paper seem to support the hypothesis, however new experiments by Dechter et al. (2010) show that it is not true in general. We
do not have yet a good characterization of the cases when the hypothesis is confirmed.
To test this hypothesis, we computed the absolute error of IBP per intervals of [0, 1]. For a given
interval [a, b], where 0 ≤ a < b ≤ 1, we use measures inspired from information retrieval: Recall
Absolute Error and Precision Absolute Error.
Recall is the absolute error averaged over all the exact posterior beliefs that fall into the interval
[a, b]. For Precision, the average is taken over all the approximate posterior belief values computed
by IBP to be in the interval [a, b]. Intuitively, Recall([a,b]) indicates how far the belief computed
by IBP is from the exact, when the exact is in [a, b]; Precision([a,b]) indicates how far the exact is
from IBP’s prediction, when the value computed by IBP is in [a, b].
Our experiments show that the two measures are strongly correlated. We also show the histograms of distribution of belief for each interval, for the exact and for IBP, which are also strongly
correlated. The results are given in Figures 21 and 22. The left Y axis corresponds to the histograms
(the bars), the right Y axis corresponds to the absolute error (the lines).
We present results for two classes of problems: coding networks and grid network. All problems
have binary variables, so the graphs are symmetric about 0.5 and we only show the interval [0, 0.5].
The number of variables, number of iterations and induced width w* are reported for each graph.

308

J OIN -G RAPH P ROPAGATION A LGORITHMS

Recall Abs. Error

noise = 0.20

noise = 0.40

0.4

Absolute Error

0.45

0.3

0
0.35

0.35

0.01

0.2

0%

0.02

0.25

0%

0.03

0.1

0%

0.04

0.15

5%

Precision Abs. Error
0.05

0

10%

5%
0.4

10%

5%

0.45

10%

0.3

15%

0.2

20%

15%

0.25

20%

15%

0.1

20%

0.15

25%

0

30%

25%

0.05

30%

25%

0.4

30%

0.45

35%

0.3

40%

35%

0.35

40%

35%

0.2

40%

0.25

45%

0.1

45%

0.15

45%

0

50%

0.05

IBP Histogram
50%

0.05

Percentage

Exact Histogram
50%

noise = 0.60

Figure 21: Coding, N=200, 1000 instances, w*=15.
Recall Abs. Error

evidence = 0

evidence = 10

0.004
0.003
0.002
0.001

Absolute Error

0.005

0.4

0.45

0.3

0.35

0.2

0.25

0.1

0.15

0
0

0.4

0.45

0.3

0.35

0%
0.2

0%
0.25

5%
0.1

10%

5%
0.15

10%

0

15%

0.05

20%

15%

0.4

20%

0.45

25%

0.3

30%

25%

0.35

30%

0.2

35%

0.25

40%

35%

0.1

40%

0.15

45%

0

45%

Precision Abs. Error

0.05

IBP Histogram

50%

0.05

Percentage

Exact Histogram
50%

evidence = 20

Figure 22: 10x10 grids, 100 instances, w*=15.
Coding networks IBP is famously known to have impressive performance on coding networks.
We tested on linear block codes, with 50 nodes per layer and 3 parent nodes. Figure 21 shows the
results for three different values of channel noise: 0.2, 0.4 and 0.6. For noise 0.2, all the beliefs
computed by IBP are extreme. The Recall and Precision are very small, of the order of 10−11 . So,
in this case, all the beliefs are very small ( small) and IBP is able to infer them correctly, resulting
in almost perfect accuracy (IBP is indeed perfect in this case for the bit error rate). When the noise
is increased, the Recall and Precision tend to get closer to a bell shape, indicating higher error for
values close to 0.5 and smaller error for extreme values. The histograms also show that less belief
values are extreme as the noise is increased, so all these factors account for an overall decrease
in accuracy as the channel noise increases. These networks are examples with a large number of
-small probabilities and IBP is able to infer them correctly (absolute error is small).
Grid networks We present results for grid networks in Figure 22. Contrary to the case of coding
networks, the histograms show higher concentration of beliefs around 0.5. However, the accuracy is
still very good for beliefs close to zero. The absolute error peaks close to 0 and maintains a plateau,
as evidence is increased, indicating less accuracy for IBP.

5. Experimental Evaluation
As we anticipated in the summary of Section 3, and as can be clearly seen now by the structuring
of a bounded join-graph, there is a close relationship between the mini-clustering algorithm MC(i)
309

M ATEESCU , K ASK , G OGATE & D ECHTER

IBP
#it
1

5

10

MC

#evid
0
5
10
0
5
10
0
5
10
0
5
10

0.02988
0.06178
0.08762
0.00829
0.05182
0.08039
0.00828
0.05182
0.08040

Absolute error
IJGP
i=2
i=5
0.03055 0.02623
0.04434 0.04201
0.05777 0.05409
0.00636 0.00592
0.00886 0.00886
0.01155 0.01073
0.00584 0.00514
0.00774 0.00732
0.00892 0.00808

IBP
i=8
0.02940
0.04554
0.05910
0.00669
0.01123
0.01399
0.00495
0.00708
0.00855

0.04044 0.04287 0.03748
0.05303 0.05171 0.04250
0.06033 0.05489 0.04266

0.06388
0.15005
0.23777
0.01726
0.12589
0.21781
0.01725
0.12590
0.21782

Relative error
IJGP
i=5
0.05677
0.12056
0.14278
0.01239
0.01965
0.02553
0.01069
0.01628
0.01907

i=2
0.15694
0.12340
0.18071
0.01326
0.01967
0.03014
0.01216
0.01727
0.02101

IBP
i=8
0.07153
0.11154
0.15686
0.01398
0.02494
0.03279
0.01030
0.01575
0.02005

0.08811 0.09342 0.08117
0.12375 0.11775 0.09596
0.14702 0.13219 0.10074

0.00213
0.00812
0.01547
0.00021
0.00658
0.01382
0.00021
0.00658
0.01382

KL distance
IJGP
i=5
0.00208
0.00478
0.00768
0.00015
0.00026
0.00042
0.00010
0.00017
0.00024

i=2
0.00391
0.00582
0.00915
0.00014
0.00024
0.00055
0.00012
0.00018
0.00028

IBP
i=8
0.00277
0.00558
0.00899
0.00018
0.00044
0.00073
0.00010
0.00016
0.00029

0.00403 0.00435 0.00369
0.00659 0.00636 0.00477
0.00841 0.00729 0.00503

0.0017
0.0013
0.0013
0.0066
0.0060
0.0048
0.0130
0.0121
0.0109

Time
IJGP
i=5
0.0058
0.0052
0.0036
0.0226
0.0185
0.0138
0.0436
0.0355
0.0271

i=2
0.0036
0.0040
0.0040
0.0145
0.0120
0.0100
0.0254
0.0223
0.0191

i=8
0.0295
0.0200
0.0121
0.1219
0.0840
0.0536
0.2383
0.1639
0.1062

0.0159 0.0173 0.0552
0.0146 0.0158 0.0532
0.0119 0.0143 0.0470

Table 4: Random networks: N=50, K=2, C=45, P=3, 100 instances, w*=16.

and IJGP(i). In particular, one iteration of IJGP(i) is similar to MC(i). MC sends messages up and
down along the clusters that form a set of trees. IJGP has additional connections that allow more
interaction between the mini-clusters of the same cluster. Since this is a cyclic structure, iterating is
facilitated, with its virtues and drawbacks.s
In our evaluation of IJGP(i), we focus on two different aspects: (a) the sensitivity of parametric
IJGP(i) to its i-bound and to the number of iterations; (b) a comparison of IJGP(i) with publicly
available state-of-the-art approximation schemes.
5.1 Effect of i-bound and Number of Iterations
We tested the performance of IJGP(i) on random networks, on M-by-M grids, on the two benchmark CPCS files with 54 and 360 variables, respectively and on coding networks. On each type
of networks, we ran IBP, MC(i) and IJGP(i), while giving IBP and IJGP(i) the same number of
iterations.
We use the partitioning method described in Section 4.3 to construct a join-graph. To determine
the order of message computation, we recursively pick an edge (u,v), such that node u has the fewest
incoming messages missing.
For each network except coding, we compute the exact solution and compare the accuracy
using the absolute and relative error, as before, as well as the KL (Kullback-Leibler) distance Pexact (X = a) · log(Pexact (X = a)/Papproximation (X = a)) averaged over all values, all variables
and all problems. For coding networks we report the Bit Error Rate (BER) computed as described
in Section 3.2. We also report the time taken by each algorithm.
The random networks were generated using parameters (N,K,C,P), where N is the number of
variables, K is their domain size, C is the number of conditional probability tables (CPTs) and P
is the number of parents in each CPT. Parents in each CPT are picked randomly and each CPT
is filled randomly. In grid networks, N is a square number and each CPT is filled randomly. In
each problem class, we also tested different numbers of evidence variables. As before, the coding
networks are from the class of linear block codes, where σ is the channel noise level. Note that we
are limited to relatively small and sparse problem instances because our evaluation measures are
based on comparing against exact figures.
Random networks results for networks having N=50, K=2, C=45 and P=3 are given in Table 4
and in Figures 23 and 24. For IJGP(i) and MC(i) we report 3 different values of i-bound: 2, 5, 8. For
IBP and IJGP(i) we report results for 3 different numbers of iterations: 1, 5, 10. We report results
310

J OIN -G RAPH P ROPAGATION A LGORITHMS

Random networks, N=50, K=2, P=3, evid=5, w*=16
0.010

IJGP 1 it
IJGP 2 it
IJGP 3 it
IJGP 5 it
IJGP 10 it
IJGP 15 it
IJGP 20 it
MC
IBP 1 it
IBP 2 it
IBP 3 it
IBP 5 it
IBP 10 it

0.008

KL distance

0.006

0.004

0.002

0.000

0

1

2

3

4

5

6

7

8

9

10

11

i-bound

(a) Performance vs. i-bound.
Random networks, N=50, K=2, P=3, evid=5, w*=16
0.010

IBP
IJGP(2)
IJGP(10)

0.008

KL distance

0.006

0.004

0.002

0.000

0

5

10

15

20

25

30

35

Number of iterations

(b) Convergence with iterations.

Figure 23: Random networks: KL distance.
for 3 different numbers of evidence: 0, 5, 10. From Table 4 and Figure 23a we see that IJGP(i)
is always better than IBP (except when i=2 and number of iterations is 1), sometimes by an order
of magnitude, in terms of absolute error, relative error and KL distance. IBP rarely changes after 5
iterations, whereas IJGP(i)’s solution can be improved with more iterations (up to 15-20). As theory
predicted, the accuracy of IJGP(i) for one iteration is about the same as that of MC(i). But IJGP(i)
improves as the number of iterations increases, and is eventually better than MC(i) by as much as
an order of magnitude, although it clearly takes more time, especially when the i-bound is large.

311

M ATEESCU , K ASK , G OGATE & D ECHTER

Random networks, N=50, K=2, P=3, evid=5, w*=16
1.0
IJPG 1 it
IJGP 2 it
IJGP 3 it
IJGP 5 it
IJGP 10 it
IJGP 15 it
IJGP 20 it
MC
IBP 1 it
IBP 20 it

Time (seconds)

0.8

0.6

0.4

0.2

0.0

0

1

2

3

4

5

6

7

8

9

10

11

i-bound

Figure 24: Random networks: Time.
IBP
#it
1

5

10

MC

#evid
0
5
10
0
5
10
0
5
10
0
5
10

0.03524
0.05375
0.07094
0.00358
0.03224
0.05503
0.00352
0.03222
0.05503

Absolute error
IJGP
i=2
i=5
0.05550 0.04292
0.05284 0.04012
0.05453 0.04304
0.00393 0.00325
0.00379 0.00319
0.00364 0.00316
0.00352 0.00232
0.00357 0.00248
0.00347 0.00239

IBP
i=8
0.03318
0.03661
0.03966
0.00284
0.00296
0.00314
0.00136
0.00149
0.00141

0.05827 0.04036 0.01579
0.05973 0.03692 0.01355
0.05866 0.03416 0.01075

0.08075
0.16380
0.23624
0.00775
0.11299
0.19403
0.00760
0.11295
0.19401

Relative error
IJGP
i=5
0.10252
0.09889
0.12492
0.00702
0.00710
0.00756
0.00502
0.00549
0.00556

i=2
0.13533
0.13225
0.14588
0.00849
0.00844
0.00841
0.00760
0.00796
0.00804

IBP
i=8
0.07904
0.09116
0.12202
0.00634
0.00669
0.01313
0.00293
0.00330
0.00328

0.13204 0.08833 0.03440
0.13831 0.08213 0.03001
0.14120 0.07791 0.02488

0.00289
0.00725
0.01232
0.00005
0.00483
0.00994
0.00005
0.00483
0.00994

KL distance
IJGP
i=5
0.00602
0.00570
0.00681
0.00007
0.00007
0.00009
0.00003
0.00003
0.00003

i=2
0.00859
0.00802
0.00905
0.00006
0.00006
0.00006
0.00005
0.00005
0.00005

IBP
i=8
0.00454
0.00549
0.00653
0.00010
0.00010
0.00019
0.00001
0.00002
0.00001

0.00650 0.00387 0.00105
0.00696 0.00348 0.00099
0.00694 0.00326 0.00075

0.0010
0.0016
0.0013
0.0049
0.0053
0.0036
0.0090
0.0096
0.0090

Time
IJGP
i=5
0.0106
0.0092
0.0072
0.0347
0.0309
0.0271
0.0671
0.0558
0.0495

i=2
0.0053
0.0041
0.0038
0.0152
0.0131
0.0127
0.0277
0.0246
0.0223

i=8
0.0426
0.0315
0.0256
0.1462
0.1127
0.0913
0.2776
0.2149
0.1716

0.0106 0.0142 0.0382
0.0102 0.0130 0.0342
0.0099 0.0116 0.0321

Table 5: 9x9 grid, K=2, 100 instances, w*=12.

Figure 23a shows a comparison of all algorithms with different numbers of iterations, using the
KL distance. Because the network structure changes with different i-bounds, we do not necessarily
see monotonic improvement of IJGP with i-bound for a given number of iterations (as is the case
with MC). Figure 23b shows how IJGP converges with more iterations to a smaller KL distance
than IBP. As expected, the time taken by IJGP (and MC) varies exponentially with the i-bound (see
Figure 24).
Grid networks results with networks of N=81, K=2, 100 instances are very similar to those of
random networks. They are reported in Table 5 and in Figure 25, where we can see the impact
of having evidence (0 and 5 evidence variables) on the algorithms. IJGP at convergence gives the
best performance in both cases, while IBP’s performance deteriorates with more evidence and is
surpassed by MC with i-bound 5 or larger.
CPCS networks results with CPCS54 and CPCS360 are given in Table 6 and Figure 26, and are
even more pronounced than those of random and grid networks. When evidence is added, IJGP(i)
is more accurate than MC(i), which is more accurate than IBP, as can be seen in Figure 26a.
Coding networks results are given in Table 7. We tested on large networks of 400 variables, with
treewidth w*=43, with IJGP and IBP set to run 30 iterations (this is more than enough to ensure
312

J OIN -G RAPH P ROPAGATION A LGORITHMS

Grid network, N=81, K=2, evid=5, w*=12
0.010
IJGP 1 it
IJGP 2 it
IJGP 3 it
IJGP 5 it
IJGP 10 it
MC
IBP 1 it
IBP 2 it
IBP 3 it
IBP 5 it
IBP 10 it

0.008

KL distance

0.006

0.004

0.002

0.000

0

1

2

3

4

5

6

7

8

9

10

11

i-bound

(a) Performance vs. i-bound.
Grid network, N=81, K=2, evid=5, w*=12
7e-5
IJGP 20 iterations
(at convergence)
6e-5

KL distance

5e-5

4e-5

3e-5

2e-5

1e-5

0
1

2

3

4

5

6

7

8

9

10

11

i-bound

(b) Fine granularity for KL.

Figure 25: Grid 9x9: KL distance.
convergence). IBP is known to be very accurate for this class of problems and it is indeed better
than MC. However we notice that IJGP converges to slightly smaller BER than IBP even for small
values of the i-bound. Both the coding network and CPCS360 show the scalability of IJGP for large
size problems. Notice that here the anytime behavior of IJGP is not clear.
In summary, we see that IJGP is almost always superior to both IBP and MC(i) and is sometimes
more accurate by several orders of magnitude. One should note that IBP cannot be improved with
more time, while MC(i) requires a large i-bound for many hard and large networks to achieve
reasonable accuracy. There is no question that the iterative application of IJGP is instrumental to its
success. In fact, IJGP(2) in isolation appears to be the most cost-effective variant.

313

M ATEESCU , K ASK , G OGATE & D ECHTER

IBP
#it

1

5

10

MC

1
10
20
MC

#evid

Absolute error
IJGP
i=2
i=5

Relative error
IJGP
i=5

IBP
i=8

i=2
0.02716
0.05736
0.08475
0.00064
0.04067
0.07302
0.00064
0.04067
0.07302

0.08966
0.09007
0.09156
0.00033
0.00124
0.00215
0.00018
0.00078
0.00123
0.05648
0.05687
0.06002

KL distance
IJGP
i=5

IBP
i=8

CPCS54
0.07761 0.05616
0.07676 0.05856
0.08246 0.06687
0.00255 0.00225
0.00194 0.00203
0.00298 0.00302
0.00029 0.00031
0.00071 0.00080
0.00109 0.00122
0.05128 0.03047
0.05314 0.03713
0.05318 0.03409

Time
IBP

i=2
0.00041
0.00199
0.00357
7.75e-7
0.00161
0.00321
7.75e-7
0.00161
0.00321

0.00583
0.00573
0.00567
0.00000
0.00000
0.00001
0.0000
0.00000
4.0e-6
0.00218
0.00201
0.00216

0.00512
0.00493
0.00506
0.00002
0.00001
0.00003
0.00000
0.00000
3.0e-6
0.00171
0.00186
0.00177

i=8
0.00378
0.00366
0.00390
0.00001
0.00001
0.00002
0.00000
0.00000
4.0e-6
0.00076
0.00098
0.00091

0.0097
0.0072
0.005
0.0371
0.0337
0.0290
0.0736
0.0633
0.0575

i=2

IJGP
i=5

i=8

0.0137
0.0094
0.0047
0.0334
0.0215
0.0144
0.0587
0.0389
0.0251
0.0144
0.0103
0.0094

0.0146
0.0087
0.0052
0.0384
0.0260
0.0178
0.0667
0.0471
0.0297
0.0125
0.0126
0.0090

0.0275
0.0169
0.0115
0.0912
0.0631
0.0378
0.1720
0.1178
0.0723
0.0333
0.0346
0.0295

0
5
10
0
5
10
0
5
10
0
5
10

0.01324
0.02684
0.03915
0.00031
0.01874
0.03348
0.00031
0.01874
0.03348

0.03747
0.03739
0.03843
0.00016
0.00058
0.00101
0.00009
0.00037
0.00058
0.02721
0.02702
0.02825

0.03183
0.03124
0.03426
0.00123
0.00092
0.00139
0.00014
0.00034
0.00051
0.02487
0.02522
0.02504

0.02233
0.02337
0.02747
0.00110
0.00098
0.00144
0.00015
0.00038
0.00057
0.01486
0.01760
0.01600

10
20
10
20
10
20
10
20

0.26421
0.26326
0.01772
0.02413
0.01772
0.02413

0.14222
0.12867
0.00694
0.00466
0.00003
0.00001
0.03389
0.02715

0.13907
0.12937
0.00121
0.00115
3.0e-6
9.0e-6
0.01984
0.01543

CPCS360
0.14334 7.78167 2119.20 2132.78 2133.84 0.17974 0.09297 0.09151 0.09255 0.7172 0.5486 0.5282 0.4593
0.13665 370.444 28720.38 30704.93 31689.59 0.17845 0.08212 0.08269 0.08568 0.6794 0.5547 0.5250 0.4578
0.00258 1.06933 6.07399 0.01005 0.04330 0.017718 0.00203 0.00019 0.00116 7.2205 4.7781 4.5191 3.7906
0.00138 62.99310 26.04308 0.00886 0.01353 0.02027 0.00118 0.00015 0.00036 7.0830 4.8705 4.6468 3.8392
3.0e-6
1.06933 0.00044
8.0e-6
7.0e-6
0.01771
5.0e-6
0.0
0.0
14.4379 9.5783 9.0770 7.6017
9.0e-6
62.9931 0.00014 0.00013 0.00004 0.02027
0.0
0.0
0.0
13.6064 9.4582 9.0423 7.4453
0.01402
0.65600 0.20023 0.11990
0.01299 0.00590 0.00390
2.8077 2.7112 2.5188
0.00957
0.81401 0.17345 0.09113
0.01007 0.00444 0.00234
2.8532 2.7032 2.5297

Table 6: CPCS54 50 instances, w*=15; CPCS360 10 instances, w*=20.

σ
0.22 IJGP
MC
0.28 IJGP
MC
0.32 IJGP
MC
0.40 IJGP
MC
0.51 IJGP
MC
0.65 IJGP
MC

2
0.00005
0.00501
0.00062
0.02170
0.00238
0.04018
0.01202
0.08726
0.07664
0.15396
0.19070
0.21890

IJGP 0.36262
MC 0.25281

Bit Error Rate
i-bound
4
6
8
0.00005 0.00005 0.00005
0.00800 0.00586 0.00462
0.00062 0.00062 0.00062
0.02968 0.02492 0.02048
0.00238 0.00238 0.00238
0.05004 0.04480 0.03878
0.01188 0.01194 0.01210
0.09762 0.09272 0.08766
0.07498 0.07524 0.07578
0.16048 0.15710 0.15452
0.19056 0.19016 0.19030
0.22056 0.21928 0.21904
Time
0.41695 0.86213 2.62307
0.21816 0.31094 0.74851

10
0.00005
0.00392
0.00062
0.01840
0.00238
0.03558
0.01192
0.08334
0.07554
0.15180
0.19056
0.21830

IBP
0.00005
0.00064
0.00242
0.01220
0.07816
0.19142

9.23610 0.019752
2.33257

Table 7: Coding networks: N=400, P=4, 500 instances, 30 iterations, w*=43.

5.2 Comparing IJGP with Other Algorithms
In this section we provide a comparison of IJGP with state-of-the-art publicly available schemes.
The comparison is based on a recent evaluation of algorithms performed at the Uncertainty in AI
2008 conference4 . We will present results on solving the belief updating task (also called the task
of computing posterior node marginals - MAR). We first give a brief overview of the schemes that
we experimented and compared with.
1. EDBP - Edge Deletion for Belief Propagation
4. Complete results are available at http://graphmod.ics.uci.edu/uai08/Evaluation/Report.

314

J OIN -G RAPH P ROPAGATION A LGORITHMS

CPCS360, evid=10, w*=20
0.20
IJGP 1 it
IJGP 10 it
IJGP 20 it
MC
IBP 1 it
IBP 10 it
IBP 20 it

0.18
0.16

KL distance

0.14
0.12
0.10
0.08
0.06
0.04
0.02
0.00

0

1

2

3

4

5

6

7

8

9

10

11

i-bound

(a) Performance vs. i-bound.
CPCS360, evid=10, w*=20
6e-6
IJGP 20 iterations
(at convergence)
5e-6

KL distance

4e-6

3e-6

2e-6

1e-6

0

1

2

3

4

5

6

7

8

9

10

11

i-bound

(b) Fine granularity for KL.

Figure 26: CPCS360: KL distance.
EDBP (Choi & Darwiche, 2006a, 2006b) is an approximation algorithm for Belief Updating.
It solves exactly a simplified version of the original problem, obtained by deleting some of
the edges of the problem graph. Edges to be deleted are selected based on two criteria:
quality of approximation and complexity of computation (tree-width reduction). Information
loss from lost dependencies is compensated for by introducing auxiliary network parameters.
This method corresponds to Iterative Belief Propagation (IBP) when enough edges are deleted
to yield a poly-tree, and corresponds to generalized BP otherwise.
2. TLSBP - A truncated Loop series Belief propagation algorithm

315

M ATEESCU , K ASK , G OGATE & D ECHTER

TLSBP is based on the loop series expansion formula of Chertkov and Chernyak (2006) which
specifies a series of terms that need to be added to the solution output by BP so that the exact
solution can be recovered. This series is basically a sum over all so-called generalized loops in
the graph. Unfortunately, because the number of these generalized loops can be prohibitively
large, the series is of little value. The idea in TLSBP is to truncate the series by decomposing
all generalized loops into simple and smaller loops, thus limiting the number of loops to be
summed. In our evaluation, we used an implementation of TLSBP available from the work
of Gomez, Mooji, and Kappen (2007). The implementation can handle binary networks only.
3. EPIS - Evidence Pre-propagation Importance Sampling
EPIS (Yuan & Druzdzel, 2003) is an importance sampling algorithm for Belief Updating. It is
well known that sampling algorithms perform poorly when presented with unlikely evidence.
However, when samples are weighted by an importance function, good approximation can be
obtained. This algorithm computes an approximate importance function using loopy belief
propagation and -cutoff heuristic. We used an implementation of EPIS available from the
authors. The implementation works on Bayesian networks only.
4. IJGP - Iterative Join-Graph Propagation
In the evaluation, IJGP(i) was first run with i=2, until convergence, then with i=3, until convergence, etc. until i= treewidth (when i-bound=treewidth, the join-graph becomes a join-tree
and IJGP becomes exact). As preprocessing, the algorithm performed SAT-based variable domain pruning by converting zero probabilities in the problem to a SAT problem and performing singleton-consistency enforcement. Because the problem size may reduce substantially,
in some cases, this preprocessing step may have a significant impact on the time-complexity
of IJGP, amortized over the increasing i-bound. However, for a given i-bound, this step improves the accuracy of IJGP only marginally.
5. SampleSearch
SampleSearch (Gogate & Dechter, 2007) is a specialized importance sampling scheme for
graphical models that contain zero probabilities in their CPTs. On such graphical models,
importance sampling suffers from the rejection problem in that it generates a large number
of samples which have zero weight. SampleSearch circumvents the rejection problem by
sampling from the backtrack-free search space in which every assignment (sample) is guaranteed to have non-zero weight. The backtrack-free search space is constructed on the fly by
interleaving sampling with backtracking style search. Namely, when a sample is supposed
to be rejected because its weight is zero, the algorithm continues instead with systematic
backtracking search, until a non zero weight sample is found. For the evaluation version,
the importance distribution of SampleSearch was constructed from the output of IJGP with
i-bound of 3. For more information on how the importance distribution is constructed from
the output of IJGP, see the work by Gogate (2009).
The evaluation was conducted on the following benchmarks (see footnote 4 for details):
1. UAI06-MPE - from UAI-06, 57 instances, Bayesian networks (40 instances were used).
2. UAI06-PE - from UAI-06, 78 instances, Bayesian networks (58 instances were used).
316

J OIN -G RAPH P ROPAGATION A LGORITHMS

IJGP
EDBP
TLSBP
EPIS
SampleSearch

WCSPs BN2O Grids Linkage Promedas UAI06-MPE UAI06-PE Relational
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
√
Table 8: Scope of our experimental study.
Score vs KL distance
1
Score vs KL distance
0.9
0.8

Score

0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0.2

0.4

0.6

0.8

1

KL distance

Figure 27: Score as a function of KL distance.
3. Relational Bayesian networks - constructed from the Primula tool, 251 instances, binary variables, large networks with large tree-width, but with high levels of determinism (30 instances
were used).
4. Linkage networks - 22 instances, tree-width 20-35, Markov networks (5 instances were used).
5. Grids - from 12x12 to 50x50, 320 instances, treewidth 12-50.
6. BN2O networks - Two-layer Noisy-OR Bayesian networks, 18 instances, binary variables, up
to 55 variables, treewidth 24-27.
7. WCSPs - Weighted CSPs, 97 instances, Markov networks (18 instances were used).
8. Promedas - real-world medical diagnosis, 238 instances, tree-width 1-60, Markov networks
(46 instances were used).
√
Table 8 shows the scope of our experimental study. A indicates that the solver was able to
√
handle the benchmark type and therefore evaluated on it while a lack of a indicates otherwise.
We measure the performance of the algorithms in terms of a KL-distance based score. Formally,
the score of a solver on a problem instance is equal to 10−avgkld where avgkld is the average KL
distance between the exact marginal (which was computed using the UCLA Ace solver, see Chavira
& Darwiche, 2008) and the approximate marginal output by the solver. If a solver does not output a
solution, we consider its KL-distance to be ∞. A score lies between 0 and 1, with 1 indicating that
the solver outputs exact solution while 0 indicating that the solver either does not output a solution
or has infinite average KL distance. Figure 27 shows the score as a function of KL distance.
317

M ATEESCU , K ASK , G OGATE & D ECHTER

In Figures 28-35 we report the results of experiments with each of the problem sets. Each
solver has a timeout of 20 minutes on each problem instance; when solving a problem, each solver
periodically outputs the best solution found so far. Using this, we can compute, for each solver, at
any point in time, the total sum of its scores over all problem instances in a particular set, called
SumScore(t). On the horizontal axis, we have the time and on the vertical axis, the SumScore(t).
The higher the curve of a solver is, the better (the higher the score).
In summary, we see that IJGP shows the best performance on the first four classes of networks
(UAI-MPE, UAI-PE, Relational and Linkage), it is tied with other algorithms on two classes (Grid
and BN2O), and is surpassed by EDBP on the last two classes (WCSPs and Promedas). EPIS and
SampleSearch, which are importance sampling schemes, are often inferior to IJGP and EDBP. In
theory, the accuracy of these importance sampling schemes should improve with time. However,
the rate of improvement is often unknown in practice. On the hard benchmarks that we evaluated
on, we found that this rate is quite small and therefore the improvement cannot be discerned from
the Figures. We discuss the results in detail below.
As mentioned earlier, TLSBP works only on binary networks (i.e., two variables per function)
and therefore it was not evaluated on WCSPs, Linkage, UAI06-MPE and UAI06-PE benchmarks.
The UAI-MPE and UAI-PE instances were used in the UAI 2006 evaluation of exact solvers (for
details see the report by Bilmes & Dechter, 2006). Exact marginals are available on 40 UAI-MPE
instances and 58 UAI-PE instances. The results for UAI-MPE and UAI-PE instances are shown
in Figures 28 and 29 respectively. IJGP is the best performing scheme on both benchmark sets
reaching a SumScore very close to the maximum possible value in both cases after about 2 minutes
of CPU time. EDBP and SampleSearch are second best in both cases.
Relational network instances are generated by grounding the relational Bayesian networks using
the Primula tool (Chavira, Darwiche, & Jaeger, 2006). Exact marginals are available only on 30
out of the submitted 251 instances. From Figure 30, we observe that IJGP’s SumScore steadily
increases with time and reaches a value very close to the maximum possible score of 30 after about
16 minutes of CPU time. SampleSearch is the second best performing scheme. EDBP, TLSBP and
EPIS perform quite poorly on these instances reaching the SumScore of 10, 13 and 13 respectively
after 20 minutes of CPU time.
The Linkage instances are generated by converting linkage analysis data into a Markov network
using the Superlink tool (Fishelson & Geiger, 2003). Exact marginals are available only on 5 out of
the 22 instances. The results are shown in Figure 31. After about one minute of CPU time, IJGP’s
SumScore is close to 5 which remains steady thereafter while EDBP only reaches a SumScore of 2
in 20 minutes. SampleSearch is the second best performing scheme while EDBP is third best.
The results on Grid networks are shown in Figure 32. The sink node of the grid is the evidence
node. The deterministic ratio p is a parameter specifying the fraction of nodes that are deterministic,
that is, whose values are determined given the values of their parents. The evaluation benchmark
set consists of 30 instances having p = 50%,75% and 90% with exact marginals available on 27
instances only. EPIS, IJGP, SampleSearch and EDBP are in a close tie on this network, while
TLSBP has the lowest performance. While hard to see, EPIS is just slightly the best performing
scheme, IJGP is the second best followed by SampleSearch and EDBP. On this instances IJGP’s
SumScore increases steadily with time.
The results on BN2O instances appear in Figure 33. This is again a very close tie, in this case
of all five algorithms. IJGP has a minuscule decrease of SumScore with time from 17.85 to 17.7.
Although in general an improvement in accuracy is expected for IJGP with higher i-bound, it is not
318

J OIN -G RAPH P ROPAGATION A LGORITHMS

Approximate Mar Problem Set uai06-mpe

40
35

Sum Score

30
25
20
15
10
5
0
0

2

4

6

8

10

12

14

16

18

20

Time in minutes
SampleSearch

IJGP

EDBP

EPIS

Figure 28: Results on UAI-MPE networks. TLSBP is not plotted because it cannot handle UAIMPE benchmarks.

Approximate Mar Problem Set uai06-pe

50

Sum Score

40

30

20

10

0
0

2

4

6

8

10

12

14

16

18

20

Time in minutes
SampleSearch

IJGP

EDBP

EPIS

Figure 29: Results on UAI-PE networks. TLSBP is not plotted because it cannot handle UAI-PE
benchmarks.

319

M ATEESCU , K ASK , G OGATE & D ECHTER

Approximate Mar Problem Set Relational
35

30

Sum Score

25

20

15

10

5

0
0

2

4

6

8

10

12

14

16

18

20

18

20

Time in minutes
SampleSearch
IJGP

EDBP
TLSBP

EPIS

Figure 30: Results on relational networks.

Approximate Mar Problem Set Linkage
6

5

Sum Score

4

3

2

1

0
0

2

4

6

8

10

12

14

16

Time in minutes
SampleSearch

IJGP

EDBP

Figure 31: Results on Linkage networks. EPIS and TLSBP are not plotted because they cannot
handle Linkage networks.

320

J OIN -G RAPH P ROPAGATION A LGORITHMS

Approximate Mar Problem Set Grids

25

Sum Score

20

15

10

5

0
0

2

4

6

8

10

12

14

16

18

20

16

18

20

Time in minutes
SampleSearch
IJGP

EDBP
TLSBP

EPIS

Figure 32: Results on Grid networks.

Approximate Mar Problem Set bn2o
18
16

Sum Score

14
12
10
8
6
4
2
0
0

2

4

6

8

10

12

14

Time in minutes
SampleSearch
IJGP

EDBP
TLSBP

EPIS

Figure 33: Results on BN2O networks. All solvers except IJGP quickly converge to the maximum
possible score of 18 and are therefore indistinguishable in the Figure.

321

M ATEESCU , K ASK , G OGATE & D ECHTER

Approximate Mar Problem Set WCSPs
18
16
14

Sum Score

12
10
8
6
4
2
0
0

2

4

6

8

10

12

14

16

18

20

Time in minutes
SampleSearch

IJGP

EDBP

Figure 34: Results on WCSPs networks. EPIS and TLSBP are not plotted because they cannot
handle WCSPs.

Approximate Mar Problem Set Promedas
45
40
35

Sum Score

30
25
20
15
10
5
0
0

2

4

6

8

10

12

14

16

18

20

Time in minutes
SampleSearch

IJGP

EDBP

TLSBP

Figure 35: Results on Promedas networks. EPIS is not plotted because it cannot handle Promedas
benchmarks, which are Markov networks.

322

J OIN -G RAPH P ROPAGATION A LGORITHMS

guaranteed, and this is an example when it does not happen. The other solvers reach the maximum
possible SumScore of 18 (or very close to it) after about 6 minutes of CPU time.
The WCSP benchmark set has 97 instances. However we used only the 18 instances for which
exact marginals are available. Therefore the maximum SumScore that an algorithm can reach is
18. The results are shown in Figure 34. EDBP reaches a SumScore of 17 after almost 3 minutes
of CPU time while IJGP reaches a SumScore of 13 after about 3 minutes. The SumScores of
both IJGP and EDBP remain unchanged in the interval from 3 to 20 minutes. After looking at the
raw results, we found that IJGP’s score was zero on 5 instances out of 18. This was because the
singleton consistency component implemented via the SAT solver did not finish in 20 minutes on
these instances. Although the singleton consistency step generally helps to reduce the practical time
complexity of IJGP on most instances, it adversely affects it on these WCSP instances.
The Promedas instances are Noisy-OR binary Bayesian networks (Pearl, 1988). These instances
are characterized by extreme marginals. Namely, for a given variable, the marginals are of the form
(1 − , ) where  is a very small positive constant. Exact marginals are available only on 46 out of
the submitted 238 instances. On these structured problems (see Figure 35), we see that EDBP is the
best performing scheme reaching a SumScore very close to 46 after about 7 minutes of CPU time
while TLSBP and IJGP are able to reach a SumScore of about 40 in 20 minutes.

6. Related Work
There are numerous lines of research devoted to the study of belief propagation algorithms, or
message-passing schemes in general. Throughout the paper we have mentioned and compared with
other related work, especially in the experimental evaluation section. We give here a short summary
of the developments in belief propagation and present some related schemes that were not mentioned
before. For additional information see also the recent review by Koller (2010).
About a decade ago, Iterative Belief Propagation (Pearl, 1988) received a lot of interest from
the information theory and coding community. It was realized that two of the best error-correcting
decoding algorithms were actually performing belief propagation in networks with cycles. The
LDPC code (low-density parity-check) introduced long time ago by Gallager (1963), is now considered one of the most powerful and promising schemes that often performs impressively close to
Shannon’s limit. Turbo codes (Berrou, Glavieux, & Thitimajshima, 1993) are also very efficient in
practice and can be understood as an instance of belief propagation (McEliece et al., 1998).
A considerable progress towards understanding the behavior and performance of BP was made
through concepts from statistical physics. Yedidia et al. (2001) showed that IBP is strongly related
to the Bethe-Peierls approximation of variational (Gibbs) free energy in factor graphs. The Bethe
approximation is a particular case of the more general Kikuchi (1951) approximation. Generalized
Belief Propagation (Yedidia et al., 2005) is an application of the Kikuchi approximation that works
with clusters of variables, on structures called region graphs. Another algorithm that employs the
region-based approach is Cluster Variation Method (CVM) (Pelizzola, 2005). These algorithms
focus on selecting a good region-graph structure to account for the over-counting (and over-overcounting, etc.) of evidence. We view generalized belief propagation more broadly as any belief
propagation over nodes which are clusters of functions. Within this view IJGP, and GBP as defined
by Yedidia et al. (2001), as well as CVM, are special realizations of generalized belief propagation.
Belief Propagation on Partially Ordered Sets (PBP) (McEliece & Yildirim, 2002) is also a generalized form of Belief Propagation that minimizes the Bethe-Kikuchi variational free energy, and

323

M ATEESCU , K ASK , G OGATE & D ECHTER

that works as a message-passing algorithm on data structures called partially ordered sets, which
has junction graphs and factor graphs as examples. There is one-to-one correspondence between
fixed points of PBP and stationary points of the free energy. PBP includes as special cases many
other variants of belief propagation. As we noted before, IJGP is basically the same as PBP.
Expectation Propagation (EP) (Minka, 2001) is a an iterative approximation algorithm for computing posterior belief in Bayesian networks. It combines assumed-density filtering (ADF), an
extension of the Kalman filter (used to approximate belief states using expectations, such as mean
and variance), with IBP, and iterates until these expectations are consistent throughout the network.
TreeEP (Minka & Qi, 2004) deals with cyclic problem by reducing the problem graph to a tree subgraph and approximating the remaining edges. The relationship between EP and GBP is discussed
by Welling, Minka, and Teh (2005).
Survey Propagation (SP) (Braunstein et al., 2005) solves hard satisfiable (SAT) problems using a
message-passing algorithm on a factor graph consisting of variable and clause nodes. SP is inspired
by an algorithm called Warning Propagation (WP) and by BP. WP can determine if a tree-problem is
SAT, and if it is then it can provide a solution. BP can compute the number of satisfying assignments
for a tree-problem, as well as the fraction of the assignments where a variable is true. These two
algorithms are used as heuristics to define the SP algorithm, that is shown to be more efficient
than either of them on arbitrary networks. SP is still a heuristic algorithm with no guarantee of
convergence. SP was inspired by the new concept of “cavity method” in statistical physics, and can
be interpreted as BP where variables can not only take the values true or false, but also the extra
“don’t care” value. For a more detailed treatment see the book by Mézard and Montanari (2009).

7. Conclusion
In this paper we investigated a family of approximation algorithms for Bayesian networks, that
could also be extended to general graphical models. We started with bounded inference algorithms
and proposed Mini-Clustering (MC) scheme as a generalization of Mini-Buckets to arbitrary tree
decompositions. Its power lies in being an anytime algorithm governed by a user adjustable i-bound
parameter. MC can start with small i-bound and keep increasing it as long as it is given more time,
and its accuracy usually improves with more time. If enough time is given to it, it is guaranteed to
become exact. One of its virtues is that it can also produce upper and lower bounds, a route not
explored in this paper.
Inspired by the success of iterative belief propagation (IBP), we extended MC into an iterative
message-passing algorithm called Iterative Join-Graph Propagation (IJGP). IJGP operates on general join-graphs that can contain cycles, but it is sill governed by an i-bound parameter. Unlike IBP,
IJGP is guaranteed to become exact if given enough time.
We also make connections with well understood consistency enforcing algorithms for constraint
satisfaction, giving strong support for iterating messages, and giving insight into the performance
of IJGP (IBP). We show that: (1) if a value of a variable is assessed as having zero-belief in any
iteration of IJGP, then it remains a zero-belief in all subsequent iterations; (2) IJGP converges in a
finite number of iterations relative to its set of zero-beliefs; and, most importantly (3) that the set
of zero-beliefs decided by any of the iterative belief propagation methods is sound. Namely any
zero-belief determined by IJGP corresponds to a true zero conditional probability relative to the
given probability distribution expressed by the Bayesian network.

324

J OIN -G RAPH P ROPAGATION A LGORITHMS

Our experimental evaluation of IJGP, IBP and MC is provided, and IJGP emerges as one of the
most powerful approximate algorithms for belief updating in Bayesian networks.



In this paper, we consider Hybrid Mixed Networks (HMN) which are Hybrid Bayesian Networks that allow discrete deterministic information to be modeled explicitly in the form of constraints. We present two approximate inference
algorithms for HMNs that integrate and adjust
well known algorithmic principles such as Generalized Belief Propagation, Rao-Blackwellised
Importance Sampling and Constraint Propagation to address the complexity of modeling and
reasoning in HMNs. We demonstrate the performance of our approximate inference algorithms
on randomly generated HMNs.

1 INTRODUCTION
In this paper, we present and evaluate approximate inference algorithms for Hybrid Mixed Networks which are Hybrid Bayesian Networks that contain discrete deterministic
information in the form of constraints. Our work is motivated by a real-world application of reasoning about cartravel activity of individuals. This application was modeled
using Dynamic Bayesian Networks and requires expressing
discrete and continuous variables as well as deterministic
discrete constraints.
The two popular approximate inference algorithms used for
inference in Dynamic Bayesian Networks (DBN) are RaoBlackwellised Particle Filtering [Doucet et al., 2000] and
Expectation Propagation [Heskes and Zoeter, 2002]. These
algorithms use Importance Sampling, exact inference and
Generalized Belief Propagation (GBP) on a Bayesian Network, which is a basic structural component of a DBN. We
seek to extend these algorithms to our application in which
the basic structural component is a Hybrid Mixed Network
(HMN).
We show how exact inference algorithms like join-tree
clustering and a parameterized GBP algorithm called It-

erative Join Graph Propagation (IJGP) can be extended
to HMNs in a straightforward way. However, extending
Rao-Blackwellised Importance Sampling algorithms (RBSampling) to HMNs using the straightforward way results
in poor performance. This is because in HMNs every sample that violates a constraint will receive zero weight and
will be rejected. To remedy this problem, we suggest a new
Importance Sampling algorithm called IJGP-RB-Sampling
which uses the output of IJGP as an importance function
and we view it as the main contribution of this paper.
We performed experiments on random HMNs to compare
how IJGP, pure RB-Sampling and IJGP-RB-Sampling perform relative to each other in terms of accuracy when given
the same amount of time. Our empirical results suggest
that IJGP-RB-Sampling is always better than pure RBSampling and dominates IJGP as the constraint tightness
increases.
The rest of the paper is organized as follows. Section 2
defines HMNs and presents some preliminaries. In the
two subsequent sections, we describe how to extend join
tree clustering and Iterative Join Graph Propagation to
HMNs. We follow by describing IJGP-RB-Sampling for
performing effective Rao-Blackwellised Importance Sampling in HMNs. We then present empirical results on random HMNs and conclude with a discussion of related work
and summary.

2 PRELIMINARIES AND DEFINITIONS
A graphical model is defined by a collection of functions,
over a set of variables, conveying probabilistic or deterministic information, whose structure is captured by a graph.
D EFINITION 2.1 A graphical model is a triplet (X, D, F)
where 1. X = {x1 , x2 , . . . , xn } is a finite set of variables, 2.
D = {D1 , . . . , Dn } is a set of domains of values in which Di
is a domain of Xi and 3. F = {F1 , F2 , . . . , Fm } is a set of
real-valued functions. The scope of functions fi denoted as
scope( fi ) ⊆ X, is the set of arguments of fi .

D EFINITION 2.2 The primal graph of a graphical model
is an undirected graph that has variables as its vertices
and an edge connects any two variables that appear in the
scope of the same function.
Two graphical models of interest in this paper are Hybrid Bayesian Networks and Constraint Networks. A Hybrid Bayesian Network (HBN) [Lauritzen, 1992] B =
(X, D, P) is defined over a directed acyclic graph G =
(X, E) and its functions Pi = {P(xi |pai )} where pai is
the set of parent nodes of xi . X is the set of variables
partitioned into
discrete ∆ and continuous Γ variables,
S
i.e. X = Γ ∆. The graph structure G is restricted in
that continuous variables cannot have discrete variables
as their child nodes. The conditional distribution of continuous variables are given by a linear Gaussian model:
P(xi |I = i, Z = z) = N(α(i) + β(i) ∗ z, γ(i)) xi ∈ Γ where
Z and I are the set of continuous and discrete parents of
xi respectively and N(µ, σ) is a multi-variate normal distribution. The network represents a joint distribution over
all its variables given by a product of all its CPDs. A
Constraint network [Dechter, 2003] R = (X, D,C), has
C = {C1 ,C2 , . . . ,Cm } as its functions also called as constraints. Each constraint Ci is a relation Ri defined over a
subset of the variables Si ⊆ X and denotes the combination
of values that can be assigned simultaneously. A Solution
is an assignment of values to all the variables such that no
constraint is violated. The primary query is to decide if the
Constraint Network is consistent (whether it has a solution)
and if so find one or all solutions.
Using
the
Mixed
Network
framework [Dechter and Mateescu, 2004] for augmenting
Bayesian Networks with constraints, we can extend HBNs
to include discrete constraints, yielding Hybrid Mixed
Networks (HMNs). Formally,
D EFINITION 2.3 (Hybrid Mixed Network) Given a HBN
B = (X, D, P) that expresses the joint probability PB and
given a Constraint Network R = (∆, D∆ ,C) that expresses
a set of solutions ρ, a Hybrid Mixed Network (HMN) based
on B and R denoted by M(B, R) is created from B and R
as follows. The discrete variables ∆ and their domains are
shared and the relationships include the CPDs in P and the
constraints in C. We assume that the Constraint Network
is always consistent and so the HMN expresses the conditional probability PM(X): PM (x) = PB (x|x ∈ ρ) i f x ∈ ρ
and 0 otherwise.
Example 2.1 Figure 1 shows a HBN and a Constraint Network yielding a HMN over variables {A,B,C,D,F,G} where
D and G are continuous variables (drawn as squares) and
the rest are discrete (drawn as circles).
D EFINITION 2.4 (Graph Decomposition) Given a graphical model (X, D, F), a graph decomposition is a triplet
(GD, χ, ψ) where GD(V, E) is a graph and χ and ψ are

Figure 1: Example HMN consisting of a HBN and a Constraint Network
labeling functions which associate with each vertex v ∈ V
two sets, χ(v) ⊆ X and ψ(v) ⊆ F such that, (1) For each
function fi ∈ F, there is exactly one vertex v ∈ V such
that fi ∈ ψ(v), and scope( fi ) ⊆ χ(v), (2) For each variable
xi ∈ X, the set of {v ∈ V |xi ∈ χ(v)} induces a connected
subgraph of G (called the running intersection property).
The width of a graph-decomposition is w = max|χ(v)| −
1. A join-tree-decomposition is a graph-decomposition in
which the graph is a tree while join-graph-decompositions
(JG(i)) are graph-decompositions in which the width is
bounded by i.
Example 2.2 Figure 2 showing (a) primal graph, (b) joingraph-decomposition and (c) join-tree-decomposition of
the example HMN shown in Figure 1.
Another relevant notion is that of w-cutset. Given a graphical model (X, D, F) , the w-cutset is the set of variables
X1 ⊆ X whose removal from the graphical model yields a
graphical model whose treewidth is bounded by w.
This paper focuses on the problem of computing the posterior marginal distribution (or beliefs) at each variable given
evidence i.e. P(xi |e). This problem is known to be NP-hard
and so we resort to approximations.

3 EXACT INFERENCE IN HMNs
In this section, we extend a class of exact inference algorithms based on join-tree-clustering [Lauritzen, 1992] from
HBNs to HMNs. This algorithm will serve as a basis for the
Generalized Belief Propagation scheme described in section 4 which will be investigated empirically as a standalone scheme and also as a component in our Importance
Sampling scheme described in section 5.
The join-tree-clustering algorithm for HMNs can be derived in a straightforward way by incorporating ideas from
[Lauritzen, 1992] and we describe it here for completeness sake (see Figure 3). The exact inference algorithm
in [Lauritzen, 1992] works by first forming a join-tree-

Figure 2: Graph decompositions of HMN in Figure 1.
Algorithm Join-tree-clustering-hmn
• Input: A Hybrid Mixed Network MN = (X, D, P,C) and Evidence e
• Output: A join-tree-decomposition containing the original functions and
the messages.
1. Instantiate Evidence
2. Create a special-join-tree-decomposition Π = (GD(V, E), χ, ψ).
3. Select a strong-root α using a method from Lauritzen [Lauritzen, 1992].
4. Let [e1 , . . . , ek ] be a DFS-ordering of edges from the strong root α
of Π.
5. Call Message-Passing(Π, [e1 , . . . , ek ])
6. Call Message-Passing(Π, [ek , . . . , e1 ])

to form a single function PC. Here, multiplication can be
performed on the functions in P0 and C0 separately using
the operators in [Lauritzen, 1992] and [Dechter, 2003] respectively to compute a single probabilistic function P and
a single constraint relation C. These two functions P and
C can be multiplied by deleting all tuples in P that are not
present in C to form the required function PC.
We comment on two major technical points for the algorithm given in Figure 3. Firstly, to be sound the join-treeclustering algorithm must satisfy the strong root property
as required by HBNs [Lauritzen, 1992]:

Procedure Message-Passing
• Input: A graph-decomposition (GD(V, E), χ, ψ) for a HMN and an ordering of edges P = [e1 , . . . , ek ] where ei ∈ E.
• Output: An graph-decomposition containing new messages and functions.
• for j = 1 to k do
1. Compute messages: Let e j = (u, v)
Compute m(u,
w v), the message that vertex u sends to vertex v,
w
¡N
¢
w
m(u, v) = w
f ∈cl(u), f 6=m(u,v) f
Ä
u−sep(u,v)

where cl(u) = ψ(u) ∪ {m(vk , u)|(vk , u) ∈ E}
2. Send message m(v j , v) to v.

Figure 3: Join-tree-clustering for HMNs
decomposition and then passing messages between individual cliques of a join-tree-decomposition. A message
from node Ni to N j is constructed by first multiplying all
messages and functions in Ni excluding the message from
N j and then marginalizing the product over the separator between Ni and NN
j . The operators of marginalization
⇓ and multiplication
required for message-passing on
a join-tree-decomposition of a HMN can be constructed
in a straightforward way by combining the operators in
[Lauritzen, 1992] and [Dechter, 2003] that work on HBNs
and constraint relations respectively. We will now briefly
comment on how the multiplication operator can be derived. Let us assume we want to multiply a collection of
probabilistic functions P0 and a set of constraint relations C0
(which consist of discrete tuples allowed by the constraint)

D EFINITION 3.1 (Strong Root) Given
a
join-treedecomposition (GD(V, E), χ, ψ), a node r ∈ V is a
strong-root iff for all neighboring nodes c and d with c
closer to r than d, we have that sep(c, d) ⊆ ∆ or d \ c ⊆ Γ
where Γ is the set of continuous variables and ∆ is the set
of discrete variables.
A sufficient condition to ensure that there is at least one
strong root in a join-tree-decomposition is to use an ordering for triangulation in which all continuous variables are
ordered before discrete variables. We call such join-treedecompositions as special-join-tree-decompositions (see
Figure 2(c)).
Finally, because Gaussian nodes can be processed in polynomial time, the complexity of processing each clique is
exponential only in the number of discrete variables in the
clique. We capture this property using the definition of
adjusted-width.
D EFINITION 3.2 Given
a
join-graph-decomposition
(GD, χ, ψ), the adjusted-width of a join-graph decomposition is w = max |χ(v) ∩ ∆| − 1. The adjusted-treewidth of
join-tree-decomposition is equal to its adjusted-width.
It is straight forward to show that [Lauritzen, 1992]:
T HEOREM 3.1 Given a HMN MN(X, D, P,C) and evidence
e, algorithm Join-tree-clustering-hmn is sound. For discrete variables, the marginal at each clique computed by
multiplying the messages and functions in each clique is

exact while for continuous variables the marginal is exact
in the sense that it has the correct first and second moments
as the exact marginal.
time-complexity
of
Join-treeT HEOREM 3.2 The
clustering-hmn is O(|∆| ∗ |Γc |3 ∗ d w∗+1 )). Here Γc is
the maximum number of continuous variables in the clique
of a join-tree-decomposition, d is the maximum domain
size of the discrete variables, ∆ is the set of discrete
variables in the HMN and w∗ is the adjusted-treewidth of
the special-join-tree-decomposition used.

4 ITERATIVE JOIN GRAPH
PROPAGATION
In this section, we extend an approximate inference algorithm called Iterative Join Graph Propagation (IJGP)
to HMNs. IJGP(i) [Dechter et al., 2002] is parameterized Generalized Belief Propagation algorithm which operates on a join-graph-decomposition having less than i +
1 variables in each clique. The complexity of IJGP(i)
is bounded exponentially by i, also called the i-bound.
This algorithm was defined for discrete Bayesian Networks
in [Dechter et al., 2002].
IJGP(i) can be extended to HMNs in a straight-forward
way by iteratively applying the message-passing procedure
given in Figure 3 to a join-graph-decomposition until a
maximum number of iterations is performed or until the
algorithm converges.
An important technical difference between the extension of IJGP(i) to HMNs and the original IJGP(i) algorithm [Dechter et al., 2002] is that i stands for adjustedwidth rather than width.
T HEOREM 4.1 The complexity of IJGP(i) when applied to
HMN is O((|∆| + n) ∗ d i ∗ |Γc |3 ) where |∆| is the number
of discrete variables, d is the maximum-domain size of the
discrete variables, i is the adjusted-i-bound, n is the number of nodes in a join-graph and |Γc | is the maximum number of continuous variables in any clique of the join-treedecomposition used.

5

RAO-BLACKWELLISED
IMPORTANCE SAMPLING

In this section, we propose an effective Importance Sampling for HMNs. We will first review Importance Sampling algorithms for computing posterior distribution and
then review w-cutset sampling which is a special version of
the Rao-Blackwellisation concept. Subsequently, we discuss how an Importance Sampling algorithm would run
into problems when hard constraints are present. We end
the section by presenting an algorithm called IJGP-RBSampling that remedies these problems by using Iterative

Join Graph Propagation to generate an effective proposal
distribution.
Sampling methods are used for approximate inference in
Bayesian Networks and are useful in cases when the distribution is hard to compute analytically using exact inference. The virtue of sampling schemes is that they are
guaranteed to yield the correct posterior distribution when
they converge and they use only linear space. An important
class of sampling algorithms is Importance Sampling for
Bayesian Networks. The idea here is that since we cannot
sample from the true posterior P(X|e) (while it is NP-hard
to compute), we will sample from an approximation Q(X)
such that the ratio w = β ∗ P(X = x|e)/Q(X = x)1 is known
up to a normalizing constant β. We can then compute the
fj
required posterior marginal as P(xi = x|e) = ∑ j f j (x) ∗ w
fj
where f j (x) is the sample that agrees with xi = x and w
fj =
are the normalized importance weights computed as w
w j / ∑k wk . Ideally, the proposal distribution should have
the following properties: (1) It is easy to sample from (2) It
allows easy evaluation of the value Q(X = x) for each sample so that the weights can be computed in a cost-effective
manner and (3) If P(X) 6= 0 then Q(X) 6= 0. The last property ensures that Importance Sampling converges to the
true posterior in limit of convergence [Geweke, 1989].
It is well known that any sampling scheme over multidimensional space can be assisted by Rao-Blackwellised
sampling, namely by sampling over a subspace. We
now describe w-cutset sampling which is a special version of Rao-Blackwellised (RB) sampling. w-cutset sampling [Bidyuk and Dechter, 2003] is a method that combines exact inference and sampling and provides a systematic scheme for sampling from a subset of variables. The
idea is that given an assignment to a set of variables it might
be possible to compute the remaining distribution analytically. More formally, in w-cutset sampling we partition the
set of variables X into two subsets X = X1 ∪ X2 such that
the treewidth of the graphical model when X1 is removed
is bounded by w. Each w-cutset sample consists of an assignment of values to X1 = x1 and a belief state P(X2 |x1 ).
The variables in the set X1 are sampled and the remaining
X2 variables are solved exactly using exact algorithms like
join-tree-clustering.
We can straightforwardly adapt w-cutset Importance Sampling to Hybrid Bayesian Networks (HBNs). Since exact
inference is polynomial if all nodes are Gaussian, w-cutset
sampling in HBNs can be done by sampling only a subset of the discrete variables [Lerner, 2002]. Extending this
idea to HMNs, suggests that we sample the discrete variables using a suitable proposal distribution and discard all
samples that violate one or more constraints. This method
can be inefficient. For example, if we use the prior as
the proposal distribution (as in Likelihood weighting) and
1 This

is usually called Biased Importance Sampling

Algorithm IJGP-RB-Sampling
• Input: A Hybrid Mixed Network MN(X, D, P,C) and Evidence e. Integer i, k, w
and N.
• Output: Estimate of P(X|e).
• Perform Iterative Join-graph propagation on MN with i-bound=i and number of
iterations=k. Let us call its output Π.
• Partition the Variables of HMN into X1 and X2 such that the adjusted-treewidth of
a special- join-tree-decomposition of X2 is bounded by w.
• Create a bucket-tree BT (V, ψ) from Π such that V contains only variables in X1 .
• For i = 1 to N do

Figure 4: An ordered Buckets structure for the join-graphdecomposition in Figure 2. m(x,y) is the message sent by
node x to node y.
the prior is such that solutions to the constraint portion are
highly unlikely, a large number of samples will be rejected
(because P(X i = 0) for a sample X i and so weight would
be 0).
On the other hand, if we want to make the sample rejection rate zero we would have to use a proposal distribution Q such that all samples from Q are solutions of the
constraint portion. One way to find this proposal distribution is to make the Constraint Network backtrack-free (perhaps using adaptive-consistency [Dechter, 2003]) along an
ordering of variables and then sample along a reverse ordering. However, adaptive-consistency can be costly unless the treewidth of the constraint portion is small. Thus
on one hand, zero-rejection rate implies using a costly inference procedure and on the other hand, sampling from a
proposal distribution that ignores the constraints may result
in a high rejection rate.
We propose to exploit the middle ground between the
two extremes by combining the Constraint Network
and the Bayesian Network into a single approximate
distribution Q using IJGP(i). By using IJGP(i) we
are likely to reduce the rejection-rate because it applies constraint-propagation in the form of relational
i-consistency [Dechter and Mateescu, 2003] , namely
it removes many inconsistent tuples [Dechter, 2003].
Note that the output of IJGP(i) can be used to
generate a proposal distribution because as shown
in [Dechter and Mateescu, 2003] P(X|e) > 0 implies that
Q(X|e) > 0 where Q(X|e) is the distribution of IJGP(i).
We now describe a method to generate samples from the
output of IJGP(i). Here, given an ordering π = hx1 , . . . , x j i
of the discrete variables to be sampled, we first compute an
approximate marginal denoted by Q(x1 ) from the output
of IJGP(i) and then sample x1 from Q(x1 ). Then, we set
the sampled value x1 = a1 as evidence, run IJGP(i), compute the marginal Q(x2 |x1 = a1 ) and sample x2 from this
marginal. The above process is repeated until all variables
are sampled. The method is inefficient however, requiring O(|X1 | ∗ exp(i) ∗ N ∗ d) time for generating all samples

1. si = Generate a sample from BT along the order d of BT for the set of
variables X1 .
2. Use join-tree-clustering to compute the distribution on X2 by setting evidence as e ∪ X1 = si . Lets call it ri .
3. Reject the sample if ri is not a solution.
4. Compute the importance weights wi of si .
• Normalize the importance weights wi .
• Output the samples [si , ri ] and the normalized weights wi

Figure 5: IJGP-RB-Sampling for Hybrid Mixed Networks

where X1 are the sampled variables, N is the number of
samples, i is the i-bound used and d is the maximum domain size.
Instead, we use a simplified method in which IJGP(i) is applied just once yielding a time-complexity of O(exp(i) +
N ∗ |X1 | ∗ d) to generate all samples. The simplified method
uses a special data-structure of ordered buckets. Given
a collection of functions and messages as the output of
IJGP(i) and an ordering π = hx1 , . . . , x j i of the discrete
variables to be sampled, we construct the ordered buckets structure as follows. We associate a bucket with each
variable xi in π and consider only those functions and messages, Fπ whose scope is included in {x j , . . . , x1 }. We then
start processing from i= j to 1 putting all functions in Fπ
that mention xi in the bucket of xi . Once the ordered buckets structure is created, we sample along the order from i
= 1 to j. The construction procedure guarantees that when
we sample a variable xi from its bucket, all variables ordered before xi are instantiated and there is only a single
un-instantiated variable in each function in the bucket of xi .
So, the time-complexity to sample each bucket is bounded
by O(d) yielding a time-complexity of O(N ∗ |X1 | ∗ d) to
generate all samples. An example ordered buckets structure
for the join-graph-decomposition in Figure 2(b) is given in
Figure 4.
We now describe how to compute the weight of each
sample. According to Rao-Blackwellised Importance
Sampling theory [Geweke, 1989, Doucet et al., 2000], the
weight of each sample X1k over variables X1 is given by
wk = P0 /Q0 such that P0 /Q0 = β ∗ P(X1k |e)/Q(X1k |e), where
β is a constant. We can determine the quantity P(X1k , e) using join-tree-clustering while we can compute Q(X1k , e) (up
to a normalizing constant) from the ordered buckets struc-

ture described above by multiplying individual probabilities. Now since Q(e) = 1, we have
required.

P(X1k ,e)
Q(X1k ,e)

= β∗

P(X1k |e)
,
Q(X1k |e)

as

An important advantage of using IJGP(i) in addition to
constraint-propagation is that it may yield good approximation to the true posterior thereby proving to be an ideal
candidate for proposal distribution. The integration of the
ideas expressed above into a formal algorithm called IJGPRB-sampling is given in Figure 5. The algorithm first runs
IJGP(i) for k iterations to generate an approximation to the
true posterior. Then, it partitions the variables X into two
sets X1 and X2 such that the treewidth of the special jointree-decomposition of X2 is bounded by w using a method
proposed in [Bidyuk and Dechter, 2004]. It then creates an
ordered bucket structure over X1 from the output of IJGP(i)
and performs Importance Sampling using the ordered buckets structure as described above. We conclude that:
T HEOREM 5.1 The complexity of IJGP-RB-Sampling(i,w)
is O([N ∗ d w+1 ∗ |Γc |3 ∗ |∆|] + [(|∆| + n) ∗ d i ∗ |Γc |3 ]) where
∆ is the set of discrete variables, d is the maximum-domain
size, i is the adjusted-i-bound, w is the adjusted-w-cutset,
n is the number of nodes in the join-graph and |Γc | is the
maximum number of continuous variables in the clique of
the join-graph-decomposition.

6 EXPERIMENTAL EVALUATION
We tested the performance of IJGP(i), pure RBSampling and IJGP-RB-Sampling(i,w) on randomly
generated HMNs.
We used a parametric model
(N1 , N2 , K,C1 ,C2 , P, T ) where N1 is the number of
discrete variables, N2 is the number of Gaussian Variables,
K is the domain-size for each discrete variable, C1 is the
number of constraints allowed and T is the tightness or
the number of forbidden tuples in each constraint, C2 is
the number of conditional probability distributions (CPDs)
and P is the number of parents in each CPD. Parents in
each CPD are picked randomly and each CPD is filled
randomly. Note that each Gaussian CPDs was assigned a
mean and variance randomly chosen in the range (0, 1).
Also no Gaussian variables have discrete children in our
random problems. The constraint portion is generated
according to Model B [Smith, 1994]. In Model B, for a
given N1 and K, we select C1 constraints uniformly at
random from the available N(N − 1)2 binary constraints
and then for each constraint we select exactly T tuples
(called as constraint tightness) as no-goods (or forbidden)
from the available K 2 tuples.
We generated two classes of problems (a) a 50-variable
set with parameters (40, 10, 4, 80, 35, 3, T ) and T was varied with values 4, 6 and 8 and (b) a 100-variable-set with
parameters (90, 10, 4, 180, 95, 3, T ) and T was varied with
values 4, 6 and 8. In each problem class, 10% of the vari-

ables were randomly selected as evidence variables. Each
algorithm was given the same amount of time for computing approximate posterior Beliefs. For the 50-variableset, we let each algorithm run for 20s while for the 100variable-set we let each algorithm run for 100s. The choice
of these time-bounds was arbitrary. Also for each IJGPRB-Sampling(i,w) algorithm instance IJGP(i) is run for 10
iterations only.
For each network, we compute the exact solution using the
join-tree-clustering algorithm and compare the accuracy of
algorithms using: 1. Absolute error - the absolute value of
the difference between the approximate and the exact, averaged over all values, all variables and all problems. 2. Relative error - the absolute value of the difference between
the approximate and the exact, divided by the exact, averaged over all values, all variables and all problems. 3.
KL distance - Pe (xi ) ∗ log(Pe (xi )/Pa (xi )) averaged over all
values, all variables and all problems where Pe and Pa are
the exact and approximate probability values for variable xi
respectively.
For IJGP(i), we experimented with i-bounds of 2, 4 and 6
while for IJGP-RB-Sampling (i, w), we experimented with
i-bound and w of 2, 4 and 6 each. We also experimented
with a w-cutset Importance Sampling algorithm (or pure
RB-Sampling) with w being set to 0, 2, 4 and 6. Thus,
we have a total of 16 algorithms in our experimental setup. We tabulate the results using a 4x4 matrix for each
combination of the problem-set, value of tightness T and
accuracy-scheme (KL-distance, relative and approximate
error). The rows of the matrix are labeled from w=0 to
w=6 in increments of 2 corresponding to the w values used
while the columns are labeled from i = 0 to i = 6 corresponding to the i-bound used. Note that the column-vector
i = 0 gives the results for w-cutset sampling while the row
vector w = 0 gives results for IJGP(i) (except for i = 0
when it gives results for w-cutset sampling). The rest of the
matrix contains results for IJGP-RB-Sampling for different
values of i and w (see Tables 1 and 2).
6.1 EXPERIMENTS ON THE 50-VARIABLE-SET
Results on the 50-variable-set are given in Table 1. The
results are averaged over 100 instances each. Here, we
see that IJGP(i) has slightly better accuracy than IJGP-RBSampling when the problem tightness is low (T = 4) (see
Figure 5, Table 1). However, as we increase the tightness
to (T = 8) the performance of IJGP(i) is worse than IJGPRB-Sampling (see Figure 6, Table 1). As expected the performance of w-cutset sampling improves as w is increased.
However IJGP-RB-sampling shows only a slight improvement in accuracy with increase in w. The accuracy of wcutset sampling is always worse than IJGP(i) and IJGPRB-Sampling and also it deteriorates more rapidly as the
tightness is increased (see Table 1).

Table 1: Table showing absolute error, relative error and K-L distance for 50-variable-set.
w=0
w=2
w=4
w=6

i=0
0.03123
0.02124
0.01782
0.01892

Relative Error
i=2
i=4
0.00746
0.00727
0.00872
0.00823
0.00843
0.00757
0.00914
0.00803

i=6
0.00709
0.00737
0.00934
0.00805

i=0
0.00772
0.00503
0.00439
0.00414

Absolute Error
i=2
i=4
0.00184
0.00177
0.00213
0.00198
0.00195
0.00173
0.00208
0.00189

i=6
0.00164
0.00178
0.00209
0.00208

i=0
0.00062
0.00042
0.00032
0.00037

K-L distance
i=2
i=4
0.00013
0.00012
0.00017
0.00016
0.00013
0.00014
0.00016
0.00015

i=6
0.00012
0.00011
0.00016
0.00016

w=0
w=2
w=4
w=6

0.0569
0.05294
0.04543
0.04593

0.01692
0.01234
0.01182
0.01221

0.01224
0.01123
0.01078
0.01223

0.01329
0.01142
0.01234
0.01287

0.01393
0.01293
0.01098
0.01103

0.004
0.00301
0.00218
0.00301

0.00287
0.00276
0.00248
0.00296

0.03023
0.00275
0.00301
0.00309

0.00114
0.00104
0.000874
0.00088

0.00031
0.00023
0.00021
0.00023

0.00024
0.00019
0.00021
0.00024

0.00024
0.00022
0.00023
0.00025

w=0
w=2
w=4
w=6

0.10234
0.09029
0.09102
0.07928

0.02393
0.01721
0.00927
0.01023

0.01872
0.01089
0.01102
0.01394

0.01908
0.01056
0.01012
0.01234

0.02559
0.02257
0.02276
0.01982

0.00598
0.0043
0.00232
0.00256

0.00468
0.00272
0.00276
0.00349

0.00477
0.00264
0.00253
0.00309

0.0020
0.00177
0.0018
0.0016

0.00044
0.00034
0.00016
0.00016

0.00036
0.00020
0.0002
0.00026

0.00036
0.00021
0.00016
0.00022

T

4

6

8

Figure 6: Figure comparing relative error of IJGP and
IJGP-RB-Sampling (i,w) for T=4 for 50-variable set

Figure 8: Figure comparing relative error of IJGP and
IJGP-RB-Sampling (i,w) for T=4 for 100-variable set

Figure 7: Figure comparing relative error of IJGP and
IJGP-RB-Sampling (i,w) for T=8 for 50-variable set

Figure 9: Figure comparing relative error of IJGP and
IJGP-RB-Sampling (i,w) for T=8 for 100-variable set

6.2 EXPERIMENTS ON THE 100-VARIABLE-SET

7 RELATED WORK AND SUMMARY

Results on the 100-variable-set are given in Table 2. The
results are averaged over 100 instances each. Here, we
see that unlike the 50-variable-set, IJGP(i) has comparable accuracy to IJGP-RB-Sampling when the tightness is
low (T = 4) (see Figure 7 and Table 2). However, as we
increase tightness (T = 8), the accuracy of IJGP(i) is considerably worse than IJGP-RB-Sampling (see Figures 7, 8
and Table 2). Also RB-Sampling is significantly worse than
IJGP-RB-Sampling for various values of w (see Table 2).

A Mixed Network framework for representing deterministic and uncertain information was presented in
[Larkin and Dechter, 2003, Dechter and Mateescu, 2004].
These previous works also describe exact inference algorithms for Mixed Networks with the restriction that all variables should be discrete. Our work goes beyond these previous works in that we describe approximate inference algorithms for the Mixed Network framework and allow continuous Gaussian nodes.

Table 2: Table showing absolute error, relative error and K-L distance for 100-variable-set.
w=0
w=2
w=4
w=6

i=0
0.06676
0.04220
0.04055
0.03756

Relative Error
i=2
i=4
0.01734
0.01692
0.01841
0.01829
0.01926
0.01697
0.01942
0.01765

i=6
0.01684
0.01542
0.01911
0.02069

i=0
0.01487
0.01117
0.00937
0.00916

Absolute Error
i=2
i=4
0.00369
0.00320
0.00517
0.00414
0.00429
0.00393
0.00431
0.00455

i=6
0.00318
0.00350
0.00428
0.00490

i=0
0.00128
0.00094
0.00071
0.00083

K-L distance
i=2
i=4
0.00025
0.00024
0.00039
0.00037
0.00026
0.00032
0.00036
0.00036

i=6
0.00023
0.00025
0.00041
0.00039

w=0
w=2
w=4
w=6

0.11526
0.10788
0.10970
0.10043

0.03369
0.02658
0.02333
0.02799

0.02629
0.02291
0.02468
0.02848

0.02136
0.02467
0.02632
0.02889

0.03103
0.02913
0.02431
0.02192

0.00956
0.00713
0.00512
0.00668

0.00609
0.00600
0.00571
0.00621

0.06205
0.00577
0.00706
0.00646

0.00254
0.00220
0.00203
0.00204

0.00064
0.00046
0.00042
0.00047

0.00053
0.00039
0.00043
0.00054

0.00047
0.00046
0.00047
0.00055

w=0
w=2
w=4
w=6

0.22601
0.18253
0.19833
0.15385

0.04838
0.03674
0.01964
0.02392

0.04366
0.02384
0.02253
0.03256

0.04342
0.02183
0.02295
0.02902

0.05453
0.04509
0.04555
0.03890

0.01416
0.01026
0.00527
0.00509

0.01023
0.00574
0.00645
0.00762

0.01105
0.00624
0.00601
0.00633

0.00477
0.00386
0.00355
0.00311

0.00098
0.00081
0.00035
0.00036

0.00081
0.00046
0.00039
0.00061

0.00082
0.00048
0.00033
0.00050

T

4

6

8

A class of approximate inference algorithms called IJGP(i)
described in [Dechter et al., 2002] handles only discrete
variables. In our work, we extend IJGP(i) to include Gaussian variables and discrete constraints.
Importance Sampling is a commonly used algorithm for
sampling in Bayesian Networks [Geweke, 1989]. A main
step in Importance Sampling is choosing a proposal distribution that is as close as possible to the target distribution.
We show how a bounded inference procedure like IJGP(i)
can be used to select a good proposal distribution.
The main algorithmic contribution of this paper is presenting a class of Rao-Blackwellised Importance Sampling algorithms, IJGP-RB-Sampling for HMNs which integrates
a Generalized Belief Propagation component with a RaoBlackwellised Importance Sampling scheme for effective
sampling in presence of constraints.
Our experimental results are preliminary but very encouraging. Our results on randomly generated HMNs show that
IJGP-RB-Sampling is almost always superior to pure wcutset sampling (RB-Sampling) which does not use IJGP
as a importance function. Our results also show that IJGPRB-Sampling has better accuracy than IJGP when the problem tightness is high or when the number of solutions to the
constraint portion of HMNs is low.
ACKNOWLEDGEMENTS
This work was supported in part by the NSF under
award numbers 0331707, 0331690 and by NSF grant IIS0412854.

[Dechter, 2003] Dechter, R. (2003). Constraint Processing. Morgan Kaufmann.
[Dechter et al., 2002] Dechter, R., Kask, K., and Mateescu, R. (2002). Iterative join graph propagation. In
UAI ’02, pages 128–136. Morgan Kaufmann.
[Dechter and Mateescu, 2003] Dechter, R. and Mateescu,
R. (2003). A simple insight into iterative belief propagation’s success. UAI-2003.
[Dechter and Mateescu, 2004] Dechter, R. and Mateescu,
R. (2004). Mixtures of deterministic-probabilistic networks and their and/or search space. In Proceedings of
the 20th Annual Conference on Uncertainty in Artificial
Intelligence (UAI-04).
[Doucet et al., 2000] Doucet, A., de Freitas, N., Murphy,
K. P., and Russell, S. J. (2000). Rao-blackwellised particle filtering for dynamic bayesian networks. In UAI2000.
[Geweke, 1989] Geweke, J. (1989). Bayesian inference
in econometric models using monte carlo integration.
Econometrica, 57(6):1317–39.
[Heskes and Zoeter, 2002] Heskes, T. and Zoeter, O.
(2002). Expectation propagation for approximate inference in dynamic bayesian networks. In UAI-2002.
[Larkin and Dechter, 2003] Larkin, D. and Dechter, R.
(2003). Bayesian inference in the presence of determinism. In AI-STATS-2003.



Inference in graphical models consists of repeatedly multiplying and summing out potentials. It
is generally intractable because the derived potentials obtained in this way can be exponentially large. Approximate inference techniques
such as belief propagation and variational methods combat this by simplifying the derived potentials, typically by dropping variables from them.
We propose an alternate method for simplifying
potentials: quantizing their values. Quantization causes different states of a potential to have
the same value, and therefore introduces contextspecific independencies that can be exploited to
represent the potential more compactly. We use
algebraic decision diagrams (ADDs) to do this
efficiently. We apply quantization and ADD reduction to variable elimination and junction tree
propagation, yielding a family of bounded approximate inference schemes. Our experimental tests show that our new schemes significantly
outperform state-of-the-art approaches on many
benchmark instances.

1

INTRODUCTION

Many widely used approximate inference algorithms such
as mini-bucket elimination (Dechter and Rish, 2003) and
the generalized mean-field algorithm (Xing et al., 2003) are
essentially scope-based approximations. The approximation is invoked when either the factors of the posterior distribution or intermediate functions generated during the execution of a variable elimination algorithm are too large to
fit in memory or too time-consuming to compute. Since the
time and memory cost of processing a function is exponential in its scope size (in this paper, we consider only discrete
graphical models), these schemes reduce complexity by approximating a large-scope function by several small-scope
functions. For instance, the generalized mean field algorithm approximates each component Pi of the posterior distribution by a tractable component Qi defined over a subset

of the scope of Pi such that the KL divergence between Qi
and Pi is minimized. The reasons for the popularity of the
scope-based approach are obvious; it is a very natural and
simple idea, it is easy to implement and its complexity can
be easily controlled.
In this paper, we propose a fundamentally different but
complementary class of range-based approximations: the
main idea is to quantize a function by mapping a number of
distinct values in its range to a single value. When the number of distinct values in the range is reduced, the function
becomes more compressible and the time required to manipulate it may decrease substantially. Unfortunately, if we
represent functions using tables, namely if we store a real
number for every possible configuration of all variables appearing in the function’s scope, quantization will be useless
because we will not reduce the representation size. In other
words, we need structured representations to take advantage
of quantization.
Many structured representations have been proposed in
literature such as confactors (Poole and Zhang, 2003),
sparse representations (Larkin and Dechter, 2003), algebraic decision diagrams (ADDs) (Chavira and Darwiche,
2007), arithmetic circuits (Darwiche, 2003), AND/OR
multi-valued decision diagrams (Mateescu et al., 2008)
and formula-based representations (Gogate and Domingos,
2010). When a function has a large number of similar values (as a result of quantization or not), the size and compute
time of these representations can be exponentially smaller
than the tabular representation. Although one can use any
of these structured representations or combinations to compactly represent a quantized function, in this paper we propose to use ADDs (Bahar et al., 1993). ADDs are canonical representations of functions, and have many efficient
manipulation algorithms. In particular, all inference operations: multiplication, maximization, and elimination can
be efficiently implemented using standard ADD operations.
Another advantage of ADDs is that there is a large literature
on them. This has led to the wide availability of many efficient open source software implementations (e.g., CUDD
Somenzi (1998)), which can be leveraged to efficiently and
quickly implement the ideas presented in this paper.

Quantization is a general principle that can be applied to a
variety of probabilistic inference algorithms. In this paper,
we apply it to two standard algorithms: bucket (or variable)
elimination (Dechter, 1999) and the junction tree algorithm
(Lauritzen and Spiegelhalter, 1988), yielding approximate,
anytime and coarse-to-fine versions of these schemes. Just
like mini-bucket elimination (Dechter and Rish, 2003) and
related iterative algorithms such as expectation propagation
(Minka, 2001) and generalized belief propagation (Yedidia
et al., 2004), one can view our new schemes as running exact inference on a simplified version of the graphical model.
All approximate schemes proposed to date define a simplified model as a low treewidth model.1 However, treewidth
is an overly strong condition for determining feasibility of
exact inference (Chavira and Darwiche, 2008). For example, algorithms such as ADD-VE (Chavira and Darwiche, 2007) and formula decomposition and conditioning
(Gogate and Domingos, 2010) can solve problems having
large treewidth by taking advantage of context-specific independence (or identical potential values) (Boutilier et al.,
1996) and determinism. Quantization artificially introduces
context-specific independence and thus enables us to define
a new class of approximations that take advantage of the efficiency and power of the aforementioned schemes by simplifying the graphical model in a much finer manner.
We present experimental results on four classes of benchmark problems: Ising models, logistics planning instances,
networks for medical diagnosis and coding networks. Our
experiments show that schemes that utilize quantization
and ADD reduction significantly outperform state-of-theart bounding and approximate inference approaches when
the graphical model has a large number of similar probability values or local structure such as determinism and
context-specific independence. When the network does not
have these properties, our algorithms are slightly inferior to
the best-performing state-of-the-art scheme but superior to
other state-of-the-art approaches.
The rest of the paper is organized as follows. Section 2 describes background. Section 3 presents quantization. Section 4 presents approximate inference schemes based on
quantization. Experimental results are presented in Section
5 and we conclude in Section 6.

2

PRELIMINARIES

2.1

MARKOV NETWORKS

For simplicity, we focus on Markov networks defined over
bi-valued variables. Our approach can be easily applied
1

The only exception we are aware of is the recent work of
(Lowd and Domingos, 2010), who compile an arithmetic circuit
(which are structured representations similar to ADDs) from dependent samples generated from the posterior distribution. Our
approach is very different, and empirically seems to yield much
greater speedups (although to date there is no head-to-head comparison in the same domains because an implementation of the
Lowd and Domingos scheme is not available).

to multi-valued variables, and other graphical models such
as Bayesian networks and Markov logic (Domingos and
Lowd, 2009). Let X = {X1 , . . . , Xn } be a set of bivalued (Boolean) variables taking values from the domain
{0, 1} (or {False,True}). A Markov network denoted by
M, is a pair (X, F) where X is a set of variables and
F = {F1 , . . . , Fm } is a collection of potentials or realvalued Boolean functions of the form {0, 1}k → R+ . Each
potential Fi is defined over a subset of variables, denoted
by V (Fi ) ⊂ X, also called its scope. The set of values in
the range of Fi is denoted by R(Fi ). A Markov network
represents the following probability distribution:
Pr(x) =

m
1 Y
Fi (xV (Fi ) )
Z i=1

(1)

where x is a 0/1 truth assignment to all variables X ∈
X, xV (F
is the projection of x on the scope of Fi and
Pi ) Q
m
Z =
x
i=1 Fi (xV (Fi ) ) is the normalization constant,
also called the partition function.
In this paper, we will focus on the approximating the partition function Z and the marginal distribution P (Xi = xi )
at each variable Xi . Our approach can be easily extended
to other problems such as computing the most probable explanation (MPE).
2.2 ALGEBRAIC DECISION DIAGRAMS
An algebraic decision diagram (ADD) is an efficient graph
representation of a real-valued Boolean function. It is a directed acyclic graph (DAG) in which each leaf node is labeled by a real value and each non-leaf decision node is
labeled by a variable. Each decision node has two outgoing arcs corresponding to the true and false assignments of
the corresponding variable. ADDs enforce a strict variable
ordering from the root to the leaf node and impose the following three constraints on the DAG: (i) no two arcs emanating from a decision node can point to the same node,
(ii) if two decision nodes have the same variable label, then
they cannot have (both) the same true child node and the
same false child node and (iii) no two leaf nodes are labeled
by the same real value. ADDs that do not satisfy these constraints are referred to as unreduced ADDs (while those that
do are called reduced ADDs). An unreduced ADD can be
reduced by merging isomorphic subgraphs and eliminating
any nodes whose two children are isomorphic (for details,
see Bahar et al. (1993)). ADDs are canonical representations of real-valued Boolean functions, namely, two functions will have the same ADD (under the same variable ordering) iff they are the same.
Figure 1 shows a real-valued Boolean function and its corresponding ADD.
All inference operations (including sum, product, elimination, etc.) can be efficiently implemented using ADDs; their
complexity is polynomial in the size of the corresponding
ADDs. Unfortunately, the time and memory constants involved in using ADDs are much larger than those involved

A
0
0
0
0
1
1
1
1

B
0
0
1
1
0
0
1
1

C Value
0 0.1
1 0.12
0 0.1
1 0.12
0 0.12
1 0.12
0
0
1
0

A

B

C

0

0.12

(a)

0.1

(b)

Figure 1: (a) A real-valued Boolean function and (b) its ADD
representation. Bold edges in the ADD correspond to true assignments and dashed edges correspond to false assignments. Leaf
nodes correspond to the real-values in the range of the function.
A

B

0

A

C

0.115

(a)

B

0

0.115

(b)

Figure 2: (a) An unreduced ADD obtained by applying quantization [(0.12, 0.1) → 0.115, (0) → 0] to the ADD given in Figure
1(b) and (b) Reduced ADD obtained from the ADD of (a).

in using tables. Because of this, ADD-based elimination
(and multiplication) may be more expensive, both timewise and memory-wise, even when they perform fewer numeric operations than table-based elimination (and multiplication). However, when a function has a substantial
amount of context-specific independence, the ADD operations can be significantly faster.

3

QUANTIZATION

Quantization is the process of replacing a range of real numbers by a single number. Formally, a quantization function
denoted by Q, is a many-to-one mapping from a set T to a
set Q of real numbers, where |T| ≥ |Q|. Let F be a real
valued Boolean function, Q be a set of real numbers and Q
be a quantization function from R(F ) to Q. We say that a
function FQ is a quantization of F w.r.t. Q if FQ is constructed from F by replacing each value w in the range of
F by Q(w). Quantization may reduce the size of the ADD
of a function, but it will never increase it. Formally:
Proposition 1. Let FQ denote the quantization of F w.r.t.
Q. Then, the ADD of FQ is smaller than or equal to the
ADD of F .
Figure 2 demonstrates the effect of quantization on the size
of the ADD given in Figure 1(b).
As mentioned in the introduction, the main problem in approximate inference is to find a small bounded function that
approximates a large intractable function such that the approximation error is minimized. Assuming that we represent the function using ADDs and approximate using quantizations, we can formalize this problem as follows.

Quantization Problem: Given a function F , an integer
constant k and an error measure D (e.g., KL divergence,
mean-squared error, etc.), find a (optimal) quantization FQ
of F such that:
• Size Constraint: The size of the ADD of FQ is less
than or equal to k.
• Error Constraint: There does not exist a quantization
FQ′ of F such that the size of the ADD of FQ′ is less
than or equal to k and D(F, FQ′ ) < D(F, FQ ).
Unfortunately, finding an optimal quantization is extremely
hard because the quantization problem is a multi-objective
constrained optimization problem. Therefore, we propose
the following three heuristics.
Our first heuristic optimizes for error and solves the following relaxation: given an integer l and an ADD φF (φF
represents a function F ) having t leaves, find an ADD φFQ
(that represents the quantization FQ of F ) having l leaves
such that D(F, FQ ) is minimized. This problem can be
solved in O(lt) time using dynamic programming and matrix searching (see Wu (1991) for details). Given l, the
relaxation optimizes FQ in terms of the error measure D
while disregarding the size of the ADD of FQ (although
since l < t, φFQ will be smaller than φF ). To use this
heuristic for solving the quantization problem, we have to
determine the value of l that will yield an ADD having less
than k + 1 nodes. To find l, we use binary search. We call
this heuristic the min-error heuristic.
Our second heuristic solves the following relaxation: given
an integer l and an ADD φF having t leaves, find an ADD
φFQ having l leaves such that there does not exist an ADD
φFQ′ that has l leaves but fewer nodes than φFQ (FQ′ is a
quantization of F ). Unfortunately, this relaxation is much
harder to solve than the relaxation that optimizes the error. Therefore, we use the following (heuristic) technique
to solve it. As before, we perform a binary search over l
starting with l = t/2. At each search point, we select a leaf
node and merge it with another leaf that shares the largest
number of parents with it (ties broken by the relative difference between the leaf values). When two leaves having the
same parent are merged, the parent will point to the same
leaf node in the new (unreduced) ADD and will be deleted
when the ADD is reduced. Notice that the heuristic ignores
the error measure D (except when breaking ties) and reduces the ADD size by merging as fewer leaves as possible.
Therefore, we call this heuristic the min-merge heuristic.
In practice, we can run both heuristics in parallel, compute the error between the original function and the quantized function obtained using each heuristic, and choose the
quantized function having the smallest error. We call this
heuristic the min-error-merge heuristic.
We will evaluate the performance of both the heuristics as
well as the combination in the experimental section. Note
that when approximations without bounding guarantees are

Algorithm 1: ABQ(k)
Input: A Markov network M and a size bound k
Output: An estimate of the partition function of M
begin
Heuristically select a variable ordering o = (X1 , . . . , Xn ).
Express each potential of M as an ADD.
// Create Buckets
Let BXi be the bucket of Xi . Put each ADD in the bucket of
its highest ordered variable.
Z=1
for i = n downto 1 do
repeat
// Process the Bucket of Xi
if BXi contains
only one ADD φ1 then
P
φ = Xi φ 1
Put φ in the bucket of its highest ordered
variable. If φ has no variables then Z = Z × φ
Delete φ1 from BXi
else
Heuristically select φ1 and φ2 from BXi .
φ = φ1 × φ2
Delete φ1 and φ2 from BXi .
if the size of φ is greater than k then
// Quantization step
φq = ADD formed by repeatedly quantizing
and reducing φ until its size is less than k.
Put φq in BXi .
else
Put φ in BXi .

end

until BXi is empty
return Z

desired, we assign the median value of the merged leaves
to the new leaf. When upper (or lower) bounds are desired,
we assign the maximum (or the minimum) value instead.

4

APPROXIMATION BY
QUANTIZATION

In this section, we apply quantization and ADD reduction
to two standard inference algorithms: (i) bucket or variable
elimination (Dechter, 1999), and (ii) junction tree propagation (Lauritzen and Spiegelhalter, 1988). Applying quantization and ADD reduction to the former yields a one-pass
algorithm for computing the partition function similar to
mini-bucket elimination (Dechter and Rish, 2003), and applying it to the latter yields an iterative algorithm that can
compute posterior marginal distribution at each variable,
similar to expectation propagation (Minka, 2001).
4.1

ONE-PASS APPROXIMATION BY
QUANTIZATION (ABQ)

Before describing our algorithm, we give background on
bucket elimination. Bucket elimination (BE) (Dechter,
1999) is an exact algorithm for computing the partition
function. The algorithm maintains a database of valid functions that is partitioned into buckets, one for each variable.

Given an ordering o of variables, the algorithm partitions
the potentials of a Markov network by putting each potential in the bucket of the highest ordered variable in its scope.
The algorithm operates by eliminating variables one by one,
along o. A variable X is eliminated by computing a product
of all the functions in its bucket, and then summing out X
from this product. This creates a new function, whose scope
is the union of the scopes of all functions that mention X,
minus {X}. The algorithm then deletes the functions involving X (namely the bucket of X) from the database of
valid functions, adds the newly created function to it and
continues. The function (a real number) created by eliminating the last bucket equals the partition function. It is
known that the time and space complexity of BE is exponential in the treewidth of the Markov network.
BE assumes tabular representation of functions. It can be
easily extended to use ADDs yielding the ADD-BE algorithm, first presented in (Chavira and Darwiche, 2007). In
ADD-BE, we represent all functions using ADDs and use
ADD operators for elimination and multiplication. Unfortunately, just like BE, it is an exact algorithm and is therefore not scalable to interesting real-world applications.
We propose to make ADD-BE practical by quantizing large
ADDs generated during its execution. Algorithm 1 describes the proposed scheme. The algorithm takes as input
a Markov network M and a size bound k and outputs an
estimate of the partition function. It is essentially a standard ADD-based bucket elimination algorithm except for
the quantization step. Here, given an ADD whose size is
greater than k, we repeatedly merge its leaf nodes using the
heuristics described in the previous section, until its size is
smaller than k. Note that when k = ∞ the algorithm runs
full bucket elimination and is equivalent to the ADD-BE
algorithm of (Chavira and Darwiche, 2007). Thus, ABQ
represents an anytime, anyspace bounded approximation of
ADD-BE, controlled by the size bound k.
We mention an important technical detail which can positively impact both the complexity and accuracy of ABQ.
Notice that after quantizing an ADD, some variables may
become irrelevant (for example, variable C is irrelevant to
the ADD of Figure 2(b) because it does not appear in any
of its internal nodes). Thus, instead of adding the quantized ADD to the current bucket, we can safely transfer it
to the bucket of its highest ordered relevant variable. Note
that variables may also become irrelevant when we multiply
two ADDs or eliminate the bucket variable from the ADD.
Obviously, we can use the same approach in these cases too
and transfer the newly generated ADD to the bucket of its
highest ordered relevant variable.
The time and space complexity of Algorithm 1 is summarized in the following theorem:
Theorem 1. The time complexity of ABQ(k) is O(mk 2 )
where m is the number of potentials and k is the size bound.
Its space complexity is O(max(mk, k 2 )).
Algorithm 1 can be easily extended to yield an upper

Algorithm 2: IABQ(k)

Procedure send-message(u, v, k)

Input: A Markov network M and a ADD size-bound k
Output: A set of junction tree cliques containing potentials and
messages received from neighbors
begin
Construct a junction tree for M
Let (e1 , . . . , el ) be an ordering of edges of the junction-tree
for message-passing from leaves to the root
repeat
for i = 1 to l do
Let ei = (ui , vi )
send-message(ui , vi , k)
for i = l downto 1 do
Let ei = (ui , vi )
send-message(vi , ui , k)

Input: Cliques u and v of a junction tree and a constant k
Output: v with the old message (ADD) from u replaced by a
new message
begin
Let (φu,1 , . . . , φu,k ) be a heuristic ordering of the ADDs
currently in the clique u except the message received from v
φu,v = 1
for i = 1 to k do
φu,v = φu,v × φu,i
if the size of φu,v is greater than k then
// Quantization step
φu,v = ADD formed by repeatedly quantizing and
reducing φu,v until its size is smaller than k
Let sep(u,
P v) = clique(u) ∩ clique(v)
φu,v = clique(u)\sep(u,v) φu,v
Replace the old message from u in v with φu,v

until convergence or timeout
end
end

(lower) bound on the partition function. All we have to do
is ensure that the quantization function Q(x) used by ABQ
is an upper (lower) approximation, namely ∀w FQ (w) ≥
F (w) (∀w FQ (w) ≤ F (w)). Trivially, a quantization function that replaces each value in the interval by the maximum
(minimum) value is an upper (lower) approximation. Formally,
Theorem 2. If all quantizations in Algorithm ABQ(k)
use a quantization function Q satisfying ∀w FQ (w) ≥
F (w), then the output of ABQ(k) is an upper bound on
the partition function. On the other hand, if Q satisfies
∀w FQ (w) ≤ F (w), then ABQ(k) yields a lower bound
on the partition function.
4.2

ITERATIVE APPROXIMATION BY
QUANTIZATION (IABQ)

In this section, we will show how to approximate the junction tree algorithm (Lauritzen and Spiegelhalter, 1988) using quantization and ADD reduction. The junction tree algorithm is a message-passing algorithm over a modified
graph called the junction tree, which is obtained by clustering together variables of a Markov network until the network becomes a tree. The clusters are also called cliques.
Each clique is associated with a subset of potentials such
that the scope of each potential is covered by the variables in the cliques. The message-passing works as follows.
First, we designate an arbitrary cluster as the root and send
messages in two passes: from the leaves to the root (inward
pass) and then from the root to the leaves (outward pass).
The message that a clique u sends to its neighbor v is constructed as follows. In clique u, we multiply all the potentials associated with u, with all the messages received from
its neighbors except v, and then eliminate all variables that
appear in u but not in v. The time and space complexity of
the junction tree algorithm is exponential in the maximum
cluster size of the junction tree used.
We can construct an approximate version of the junctiontree algorithm using quantization and ADD reduction in

a straight-forward manner. Algorithm 2 describes our approach. The algorithm first constructs a junction tree for the
Markov network and then sends messages along its edges
using the send-message procedure. In the send-message
procedure, we send a message from a clique u to clique
v by multiplying all ADDs corresponding to the messages
(except the one received from v) and potentials. Just as
in ABQ, if the size of the product ADD is larger than k,
we recursively apply quantization and ADD reduction until
its size is smaller than or equal to k. Since, the message
propagation is performed on a tree, the algorithm will always converge in two passes (assuming that the quantization heuristics do not change between passes).
IABQ belongs to the class of sum-product expectation
propagation (EP) algorithms (see Minka (2001) and Koller
and Friedman (2009), Chapter 11) which perform inference by sending approximate messages. In practice, we
can further improve the accuracy of IABQ by performing
belief-update propagation instead of sum-product propagation. Belief-update IABQ constructs the message from
clique u to clique v by first multiplying, and quantizing if
necessary, all the incoming messages (including the one received from v). Then, it projects the resulting factor on
sep(u, v) and divides it by the message φv,u received from
v (thus unlike sum-product IABQ, belief-update IABQ requires the division operation). Belief-update IABQ is not
guaranteed to converge in two passes and may not converge
at all. However, as we shall see in the experimental section,
when it does converge, it often converges very quickly (in
10-30 iterations) and yields highly accurate estimates.
IABQ yields a new class of bounded EP algorithms. Existing bounded EP algorithms use treewidth to determine
feasibility of inference. In particular, in the junction tree algorithm, the message between u and v corresponds to a (local) fully-connected (clique) graphical model over the separator sep(u, v). Existing EP algorithms ensure tractability
by sending bounded treewidth messages (achieved by introducing new conditional independencies between the sepa-

rator variables). IABQ, on the other hand, can create messages having substantially larger treewidth than existing EP
algorithms. This is because it uses quantization and ADDs
to introduce context-specific independencies between the
separator variables.

5

EXPERIMENTS

In this section, we compare the performance of ABQ and
IABQ with other algorithms from the literature. We also
evaluate the impact of various quantization heuristics on accuracy. We experimented with instances from four benchmark domains: (i) logistics planning (Sang et al., 2005),
(ii) linear block coding, (iii) Promedas Bayesian networks
for medical diagnosis (Wemmenhove et al., 2007) and (iv)
Ising models. We implemented our algorithms in C++. We
ran our experiments on a Linux machine with a 2.33 GHz
Intel Xeon quad-core processor and 16 GB of RAM. We
gave each algorithm a memory limit of 2GB and (unless
otherwise specified) a time limit of 2 hours. We used the
CUDD package (Somenzi, 1998) to implement ADDs. We
used the minfill ordering heuristic for constructing the junction tree in IABQ and for eliminating variables in ABQ.
5.1

EXPERIMENTS EVALUATING THE
BOUNDING POWER OF ABQ

When exact results are not available, evaluating the capability of approximate schemes is problematic because the
quality of the approximation (namely how close the approximation is to the exact) cannot be assessed. To allow
some comparison on large, hard instances, we evaluate the
upper bounding power of ABQ, and compare it with three
algorithms from literature: mini-bucket elimination (MBE)
(Dechter and Rish, 2003; Rollon and Dechter, 2010), Treereweighted Belief Propagation (TRW) (Wainwright et al.,
2003) and Box propagation (BoxProp) (Mooij and Kappen, 2008). For a fair comparison, we also compare with
our own ADD based implementation of mini-bucket elimination (ADD-MBE). ADD-MBE represents all messages
and potentials in the MBE algorithm using ADDs instead
of tables (both ADD-MBE and ABQ use the same variable ordering). BoxProp was derived for bounding posterior probabilities and therefore Z is obtained by applying
the chain rule to individual bounds on posteriors. We experimented with anytime versions of MBE, ADD-MBE and
ABQ. Namely, we start with a crude size-bound, k = 2, and
increase it progressively by multiplying it by 2, until the algorithm runs out of memory or time. Recall that in ABQ,
k bounds the size of the ADD. In MBE, it bounds the size
of the new functions created by the algorithm. The results
in this subsection were obtained using the min-error-merge
heuristic described in Section 3 (we compare the impact of
heuristics on accuracy in the next subsection).
Note that almost all the instances that we consider in this
subsection are quite hard and the exact value of their par-

Instance

(n,d,m,w)

ABQ
MBE BoxProp TRW ADD-MBE
Z
Z
Z
Z
Z
∆
∆
∆
∆
∆
Logistics planning
log-1
(939,2,3785,26) 5e+20 7e+67 9e+108 4e+48
6e+20
0
2.27
4.25
1.34
0.00129
log-2
(1337,2,24777,51) 2e+66 2e+242
X
X
1e+68
0
2.66
0.0275
log-3
(1413,2,29487,56) 2e+52 1e+59
X
X
9e+58
0
0.128
0.127
log-4
(2303,2,20963,52) 3e+69 4e+356
X
X
1e+90
0
4.13
0.296
log-5
(2701,2,29534,51) 3e+110 2e+427
X
X
6e+125
0
2.87
0.139
Medical Diagnosis: Promedas networks
or chain 100 (1110,2,1125,59) 1e-06
0.01
8e+03 4e+24
0.009
0
0.661
1.66
5.17
0.653
or chain 110 (1163,2,1176,70) 2e+05 2e+07 4e+21 2e+50
1e+07
0
0.401
3.15
8.65
0.344
or chain 120 (1511,2,1524,76) 2e+02 1e+06 4e+41 7e+53
7e+05
0
1.52
16.5
21.6
1.45
or chain 132 (646,2,717,26)
4e-09
2e-05
0.03
1e+14
4e-07
0
0.443
0.819
2.66
0.241
Coding networks
BN 130
(255,2,511,53)
6e-52
2e-49
2e-30
3e-45
9e-50
0
0.0499 0.421
0.13
0.0432
BN 131
(255,2,511,53)
3e-48
8e-50
4e-33
7e-45
1e-47
0.0307
0
0.34
0.1
0.0427
BN 132
(255,2,511,53)
5e-51
2e-48
2e-34
4e-45
6e-49
0
0.0518
0.33
0.117
0.0414
BN 133
(255,2,511,56)
1e-46
1e-45
7e-28
1e-43
5e-45
0
0.0181 0.407 0.0628
0.0333
BN 134
(255,2,511,55)
1e-48
1e-47
6e-31
3e-44
6e-45
0
0.0174 0.368 0.0901
0.0755
Ising models
29x29
(841,2,1624,29) 7e+1933 1e+1917 9e+2102 1e+2576 1e+1948
0.00879
0
0.097
0.344
0.0162
31x31
(961,2,1860,31) 3e+2229 8e+2226 5e+2578 9e+2576 1e+2259
0.00115
0
0.158
0.157
0.0144
33x33
(1023,2,2112,33) 1e+2557 4e+2543 4e+2753 5e+3352 6e+2562
0.00527
0
0.0826 0.318
0.00754
35x35
(1225,2,2380,35) 1e+2928 1e+2898 5e+2901 2e+3761 1e+2933
0.0104
0
0.00128 0.298
0.0121

Table 1: Table showing the upper bound on the partition function
and the log-relative difference ∆ for ABQ, MBE and BoxProp,
TRW and ADD-MBE. Each algorithm was given a time limit of 2
hours and a memory limit of 2 GB. The best performing scheme is
highlighted by bold in each row. ’X’ indicates that the algorithm
did not return a value.

tition function is not known (except for the logistics instances). Table 1 shows the results. The first column
shows the instance name. The second column shows various statistics for the instance such as the number of variables (n), the domain size (d), the number of potentials (p)
and the upper bound on treewidth obtained using the minfill ordering heuristic (w). Columns 3, 4, 5, 6 and 7 show the
upper bound on the partition function computed by ABQ,
MBE, BoxProp, TRW and ADD-MBE respectively. For
each scheme, we also report the relative difference ∆ (defined below) between the log of the best known upper bound
UBest and the log of the upper bound U output by the current scheme.
∆=

log(U ) − log(UBest )
log(UBest )

(2)

The log-relative difference provides a quantitative measure for assessing the relative approximation quality of the
bounding schemes (smaller is better).
Logistics planning instances Our first domain is that of
logistics planning (the networks are available from (Sang

et al., 2005)). Given prior probabilities on actions and facts,
the task is to compute the probability of evidence. From Table 1, we can see that ABQ significantly outperforms MBE,
ADD-MBE, TRW and BoxProp on all instances (the logrelative difference is quite large). ADD-MBE is much superior to MBE on most instances. This is because the domain
has a large amount of determinism and identical probability
values which ADD-MBE exploits effectively. ADD-MBE
is worse than ABQ suggesting that quantization-based approximations are much better in terms of accuracy than
MBE-based approximations.
Medical Diganosis: Promedas networks Our second domain is that of noisy-OR medical diagnosis networks generated by the Promedas expert system for internal medicine
(Wemmenhove et al., 2007). The global architecture of the
diagnostic model in Promedas is similar to the QMR-DT
medical diagnosis networks (Shwe et al., 1991). Each network can be specified using a two layer bipartite graph in
which the top layer consists of diseases and the bottom layer
consists of symptoms. If a disease causes a symptom, there
is an edge from the disease to the symptom. The networks
are available from UAI 2008 evaluation website (Darwiche
et al., 2008). From Table 1, we can see that ABQ is superior
to MBE, ADD-MBE, TRW and BoxProp on all instances
(notice that for all instances the log-relative difference between ADD based schemes and others is quite large).
Coding networks Our third domain is random coding networks from the class of linear block codes (Kask and
Dechter, 1999) (the networks are available from the UAI
2008 evaluation website (Darwiche et al., 2008)). From Table 1, we can see that ABQ outperforms MBE, TRW and
BoxProp on all instances, except BN 131. On this network,
MBE is slightly better than ABQ (because of the overhead
of ADDs). On all other networks, ABQ is slightly superior
to MBE. ADD-MBE is worse than ABQ on all instances.
Again, our results on the coding networks clearly demonstrate that quantization with ADD reduction is a better approximation strategy than MBE.
Ising models Our last domain is that of Ising models which
are n × n pair-wise grid networks. They are specified using potentials defined over each edge and each node. Each
node potential is given by (γ, 1/γ) where γ is drawn uniformly between 0 and 1. The edge potentials are either
(θ, 1/θ, 1/θ, θ) or their mirror image (1/θ, θ, θ, 1/θ) where
θ is drawn uniformly between 1 and β (β is called the
coupling strength). We use β = 100 to generate our networks. From Table 1, we can see that ABQ outperforms
BoxProp, TRW and ADD-MBE on these models. However,
it is slightly inferior to MBE (notice that the log-relative
difference between ABQ and MBE is very small).
Intuitively, ABQ should do well when the graphical model
contains many similar or identical probability values in
each potential. Ising models are interesting in this respect because they represent the worst possible case for
ABQ, with no determinism or context-specific structure at

Instance

min-error-merge min-error min-merge
Z
Z
Z
∆
∆
∆
Logistics planning
log-1
5.64e+20
5.64e+20 5.64e+20
0
0
0
log-2
1.52e+66
1.42e+69 9.08e+66
0
0.0449
0.0117
log-3
2.04e+52
3.26e+50 1.36e+48
0.0868
0.0495
0
log-4
2.9e+69
4.04e+82
2.9e+69
0
0.189
0
log-5
2.57e+110
3.57e+115 8.36e+109
0.00444
0.0512
0
Medical Diganosis: Promedas networks
or chain 100
1.27e-06
6.15e-07
3.04e-06
0.0508
0
0.112
or chain 110
1.62e+05
1.4e+05
6.62e+05
0.0125
0
0.131
or chain 120
242
3.99e+04 1.38e+07
0
0.931
2
or chain 132
3.72e-09
3.72e-09
3.72e-09
0
0
0
Coding networks
BN 130
6e-52
2e-40
6e-52
0
0.225
0
BN 131
2.59e-48
7.54e-42
2.59e-48
0
0.136
0
BN 132
4.98e-51
6.1e-40
4.98e-51
0
0.22
0
BN 133
1.48e-46
1.74e-41
1.48e-46
6.55e-06
0.111
0
BN 134
1.46e-48
7.26e-41
1.15e-47
0
0.161
0.0187
Ising models
29x29
7.08e+1933
2.04e+2002 7.08e+1933
0
0.0354
0
31x31
2.95e+2229
1.78e+2338 2.63e+2264
0
0.0488
0.0156
33x33
1.02e+2557
1.91e+2636 1.02e+2557
0
0.031
0
35x35
1.15e+2928
7.76e+3031 1.15e+2928
0
0.0355
0

Table 2: Table showing the impact of the three quantization
heuristics: (i) min-error-merge, (ii) min-error and (iii) min-merge
on the upper bound output by ABQ. For each heuristic, we also
report the log-relative error ∆.

all. Remarkably, ABQ still outperforms BoxProp, TRW
and ADD-MBE on these models. In our initial experiments it also outperformed MBE, but it does slightly worse
than the latest version, which is the one reported in Table 1. MBE employs sophisticated partitioning heuristics
(Rollon and Dechter, 2010) that could also be incorporated
into ABQ, and many other optimizations characteristic of
a mature system; its good performance relative to ABQ is
likely due to these improvements, rather than to the basic
algorithm. However, there is in general a tradeoff in using
ADDs versus tables, as shown by the ADD-MBE results:
ADDs can be exponentially smaller and faster by taking advantage of context-specific independence and determinism,
but ADDs incur higher overhead than tables, so the latter
may be preferable when there is no structure to exploit.
Overall, we see that that ABQ always outperforms TRW,
BoxProp and ADD-MBE, and outperforms MBE on all domains except Ising models. ABQ’s advantage increases
with the the amount of (approximate or exact) contextspecific independence and determinism in the domain, but
ABQ still does quite well even when these are absent.

IJGP
IABQ
Gibbs

1
0.1
0.01
0.001
0.0001
1000

2000

3000

4000

Time (seconds)

Average KL Divergence

IJGP
IABQ
Gibbs

0.1
0.01
0.001
0.0001
1000

2000

3000

4000

Time (seconds)
(b)

Figure 3: KL divergence vs. Time plots for IJGP, Gibbs sampling
and IABQ for (a) logistics planning instance log-3 and (b) 18 x 18
Ising model.

5.2

EXPERIMENTS EVALUATING THE
QUANTIZATION HEURISTICS

In this subsection, we evaluate the performance of the three
quantization heuristics described in Section 3. Table 2
shows the results. We can see that the min-error-merge
heuristic performs the best overall. The min-merge heuristic is only slightly inferior to the min-error-merge heuristic.
The min-error heuristic is inferior to the min-merge heuristic except on the promedas networks. The promedas networks have many similar probability values (approximate
context-specific independence) which the min-error heuristic exploits quite effectively. On the other hand, the Ising
models represent the worst possible case for the min-error
heuristic because the intermediate potentials generated during ABQs execution have almost no similar probability values.
5.3

IABQ(K=100)
IABQ(K=1000)
IABQ(K=20000)

1
0.1
0.01
0.001
0.0001
0

5

10 15 20 25 30 35 40 45 50

Figure 4: KL divergence vs. Number of iterations for IABQ

Ising model 18x18
1

log-3 (logistics planning instance)
10

Number of iterations

(a)

10

Average KL Divergence

Average KL Divergence

log-3 (logistics planning instance)
10

EXPERIMENTS EVALUATING THE
ACCURACY OF IABQ

In this subsection, we evaluate the accuracy of belief-update
IABQ for computing posterior marginals. We compare
IABQ with Iterative Join Graph propagation (IJGP) (Mateescu et al., 2010), a state-of-the-art generalized belief
propagation scheme (IJGP won 2 out of the 3 marginal estimation categories at the 2010 UAI approximate evaluation
challenge (Elidan and Globerson, 2010)). As a baseline, we

compare with Gibbs sampling (Geman and Geman, 1984).
We ran both IJGP and IABQ as anytime algorithms. Both
algorithms take as input a size parameter which determine
their complexity. We vary this parameter starting with its
lowest possible value, progressively increasing it until the
algorithm runs out of memory or time. We ran each algorithm for 1 hour and gave each algorithm a memory limit
of 2GB. Both IJGP and IABQ may or may not converge
to a fixed point. Therefore, we ran each for 50 iterations
or until convergence, whichever was earlier. Convergence
is detected by comparing the absolute difference between
messages at the current and previous iteration.
We measure performance using the KL divergence. Let
P (Xi ) and Q(Xi ) denote the exact and approximate
marginals of variable Xi . Then, the average KL divergence
is defined as:


1 X X
P (xi )
KL(P, A) =
P (xi ) log
|X|
Q(xi )
x
Xi ∈X

i

For brevity, we only describe our results for two sample instances: (a) a logistics planning instance, and (b) a 18 x
18 Ising model. Average KL divergence vs. time plots for
these instances are given in Figure 3. Our results are consistent with the empirical evidence in the previous subsection.
Specifically, when the graphical model has many identical
or similar probability values, IABQ dominates IJGP (e.g.,
on the log-3 instance). However, when the graphical model
does not have these properties, IJGP is slightly better than
IABQ because of the overhead of ADDs.
Figure 4 shows the impact of increasing the number of iterations on the accuracy of IABQ for different values of the
size bound parameter k. We can see that IABQ converges
to its fixed point in about 10-20 iterations. Its accuracy typically increases with k and with the number of iterations.
This shows that the belief-update IABQ performs better
than sum-product IABQ (sum-product IABQ is equivalent
to running just one iteration of belief-update IABQ).

6 CONCLUSION
The most challenging problem in approximate inference is
how to approximate a large function that is computation-

ally infeasible by a collection of tractable functions. The
paper proposes to solve this problem using quantization.
Quantization replaces a number of values in the range of
a function by a single value, and thus artificially introduces
context-specific independence. Conventional tabular representations of functions are inadequate at exploiting this
structure. We therefore proposed to use structured representations such as algebraic decision diagrams (ADDs).
We showed how quantization can be applied to two standard algorithms in probabilistic inference, variable elimination and junction tree propagation, yielding two new
schemes: (i) A one-pass algorithm that can be used to approximate and bound the partition function and (ii) An iterative algorithm that can be used for approximating posterior
marginals. Our new approximate schemes significantly enhance the class of approximations considered by existing
algorithms, which constrain their approximations to have
low treewidth. By imposing context-specific independencies between variables via quantization, our new algorithms
construct structured approximations in the high treewidth
space. Our empirical evaluation demonstrates that schemes
that employ quantization often yield more accurate results
than schemes that do not. Thus approximation by quantization is a promising approach for future investigations.
Acknowledgements This research was partly funded by
ARO grant W911NF-08-1-0242, AFRL contract FA8750-09-C0181, DARPA contracts FA8750-05-2-0283, FA8750-07-D-0185,
HR0011-06-C-0025, HR0011-07-C-0060 and NBCH-D030010,
NSF grants IIS-0534881 and IIS-0803481, and ONR grant
N00014-08-1-0670. The views and conclusions contained in this
document are those of the authors and should not be interpreted as
necessarily representing the official policies, either expressed or
implied, of ARO, DARPA, NSF, ONR, or the U.S. Government.



Computing the probability of a formula given
the probabilities or weights associated with other
formulas is a natural extension of logical inference to the probabilistic setting. Surprisingly,
this problem has received little attention in the literature to date, particularly considering that it includes many standard inference problems as special cases. In this paper, we propose two algorithms for this problem: formula decomposition
and conditioning, which is an exact method, and
formula importance sampling, which is an approximate method. The latter is, to our knowledge, the first application of model counting to
approximate probabilistic inference. Unlike conventional variable-based algorithms, our algorithms work in the dual realm of logical formulas. Theoretically, we show that our algorithms
can greatly improve efficiency by exploiting the
structural information in the formulas. Empirically, we show that they are indeed quite powerful, often achieving substantial performance
gains over state-of-the-art schemes.

1 Introduction
The standard task in the field of automated reasoning is to
determine whether a set of logical formulas (the knowledge
base KB) entails a query formula Q. (The formulas could
be propositional or first-order; in this paper we focus on
the propositional case.) Logic’s lack of a representation for
uncertainty severely hinders its ability to model real applications, and thus many methods for adding probability to it
have been proposed. One of the earliest is Nilsson’s probabilistic logic (Nilsson, 1986), which attaches probabilities
to the formulas in the KB and uses these to compute the
probability of the query formula. One problem with this
approach is that the formula probabilities may be inconsistent, yielding no solution, but consistency can be verified

and enforced (Nilsson, 1986). Another problem is that in
general a set of formula probabilities does not completely
specify a distribution, but this is naturally solved by assuming the maximum entropy distribution consistent with the
specified probabilities (Nilsson, 1986; Pietra et al., 1997).
A more serious problem is the lack of efficient inference
procedures for probabilistic logic. This contrasts with the
large literature on inference for graphical models, which
always specify unique and consistent distributions (Pearl,
1988). However, the representational flexibility and compactness of logic is highly desirable, particularly for modeling complex domains. This issue has gained prominence in
the field of statistical relational learning (SRL) (Getoor and
Taskar, 2007), which seeks to learn models with both logical and probabilistic aspects. For example, Markov logic
represents knowledge as a set of weighted formulas, which
define a log-linear model (Domingos and Lowd, 2009).
Formulas with probabilities with the maximum entropy assumption and weighted formulas are equivalent; the problem of converting the former to the latter is equivalent to
the problem of learning the maximum likelihood weights
(Pietra et al., 1997). In this paper we assume weighted formulas, but our algorithms are applicable to formulas with
probabilities by first performing this conversion.
Another reason to seek efficient inference procedures for
probabilistic logic is that inference in graphical models can
be reduced to it (Park, 2002). Standard inference schemes
for graphical models such as junction trees (Lauritzen
and Spiegelhalter, 1988) and bucket elimination (Dechter,
1999) have complexity exponential in the treewidth of the
model, making them impractical for complex domains.
However, treewidth can be overcome by exploiting structural properties like determinism (Chavira and Darwiche,
2008) and context-specific independence (Boutilier, 1996).
Several highly efficient algorithms accomplish this by encoding a graphical models as sets of weighted formulas and
applying logical inference techniques to them (Sang et al.,
2005; Chavira and Darwiche, 2008).
All of these algorithms are variable-based, in that they explore the search space defined by truth assignments to the

variables. In this paper, we propose a new class of algorithms that explore the search space defined by truth assignments to arbitrary formulas, including but not necessarily those contained in the original specification. Our
formula-based schemes generalize variable-based schemes
because a variable is a special case of a formula, namely a
unit clause. For deriving exact answers, we propose to exhaustively search the space of truth assignments to formulas, yielding the formula decomposition and conditioning
(FDC) scheme. FDC performs AND/OR search (Dechter
and Mateescu, 2007) or recursive conditioning (Darwiche,
2001), with and without caching, over the space of formulas, utilizing several Boolean constraint propagation and
pruning techniques.
Even with these techniques, large complex domains will
still generally require approximate inference. For this, we
propose to compute an importance distribution over the formulas, yielding formula importance sampling (FIS). Each
sample in FIS is a truth assignment to a set of formulas.
To compute the importance weight of each such sampled
assignment, we need to know its model count (or number
of solutions). These model counts can either be computed
exactly, if it is feasible, or approximately using the recently
introduced approximate model counters such as SampleCount (Gomes et al., 2007) and SampleSearch (Gogate and
Dechter, 2007b). To the best of our knowledge, this is the
first work that harnesses the power of model counting for
approximate probabilistic inference. We prove that if the
model counts can be computed accurately, formula importance sampling will have smaller variance than variablebased importance sampling and thus should be preferred.
We present experimental results on three classes of benchmark problems: random Markov networks, QMR-DT networks from the medical diagnosis domain and Markov
logic networks. Our experiments show that as the number of variables in the formulas increases, formula-based
schemes not only dominate their variable based counterparts but also state-of-the-art exact algorithms such as
ACE (Chavira and Darwiche, 2008) and approximate
schemes such as MC-SAT (Poon and Domingos, 2006) and
Gibbs sampling (Geman and Geman, 1984).
The rest of the paper is organized as follows. Section 2
describes background. Section 3 presents formula decomposition and conditioning. Section 4 presents formula importance sampling. Experimental results are presented in
Section 5 and we conclude in Section 6.

2 Background
2.1 Notation
Let X = {X1 , . . . , Xn } be a set of propositional variables that can be assigned values from the set {0, 1} or
{False,True}. Let F be a propositional formula over X.

A model or a solution of F is a 0/1 truth assignment to
all variables in X such that F evaluates to True. We will
assume throughout that F is in CNF, namely it is a conjunction of clauses, a clause being a disjunction of literals.
A literal is a variable Xi or its negation ¬Xi . A unit clause
is a clause with one literal. Propositional Satisfiability or
SAT is the decision problem of determining whether F has
any models. This is the canonical NP-complete problem.
Model Counting is the problem of determining the number
of models of F , it is a #P-complete problem.
We will denote formulas by letters F , G, and H, the set
of solutions of F by Sol(F ) and its number of solutions
by #(F ). Variables are denoted by letters X and Y . We
denote sets by bold capital letters e.g., X, Y etc. Given a
set X = {X1 , . . . , Xn } of variables, x denotes a truth assignment (x1 , . . . , xn ), where Xi is assigned the value xi .
Clauses are denoted by the letters C, R, S and T . Discrete
functions are denoted by small Greek letters, e.g. φ, ψ, etc.
The variables involved in a function φ, namely the scope of
φ is denoted by V (φ). Similarly, the variables of a clause C
are denoted by V (C). Given an assignment x to a superset
X of Y, xY denotes the restriction of x to Y.
The expected value of a random
P variable X with respect to
a distribution Q is EP
Q [X] =
x∈X xQ(x). The variance
of x is V arQ [X] = x∈X (x − EQ [X])2 Q(x).

In this paper, we advocate using a collection of weighted
propositional formulas instead of the conventional tabular
representations to encode the potentials in Markov random
fields (MRFs) or conditional probability tables in Bayesian
networks. Specifically, we will use the following representation, which we call as propositional MRF or PropMRF in
short. A PropMRF is a Markov logic network (Richardson
and Domingos, 2006) in which all formulas are propositional. It is known that any discrete Markov random field or
a Bayesian network can be encoded as a PropMRF (Park,
2002; Sang et al., 2005; Chavira and Darwiche, 2008).

D EFINITION 1 (Propositional MRFs). A propositional
MRF (PropMRF), denoted by M is a triple (X, C, R)
where X is a set of n Boolean variables, C =
{(C1 , w1 ), . . . , (Cm , wm )} is a set of m soft (weighted)
clauses and R = {R1 , . . . , Rp } is a set of p hard clauses.
Each soft clause is a pair (Ci , wi ) where Ci is a clause and
wi is a real number. We will denote by FM = R1 ∧. . .∧Rp ,
the CNF formula defined by the hard clauses of M. The
primal graph of a PropMRF has variables as its vertices
and an edge between any two nodes that are involved in the
same hard or soft clause.
We can associate a discrete function φi with each soft
clause (Ci , wi ), defined as follows:

exp(wi ) If x evaluates Ci to True
φi (xV (Ci ) ) =
1
Otherwise

The probability distribution associated with M is given by:
PM (x) =



Qm

1
ZM

i=1

0

φi (xV (φi ) )

If x ∈ Sol(FM )
Otherwise

(1)

where ZM is the normalization constant; often referred to
as the partition function. ZM is given by:
m
Y

X

ZM =

φi (xV (φi ) )

Note that if M has no soft clauses, then ZM equals the
number of models of the formula FM . Thus, model counting is a special case of computing ZM .
We will focus on the query of finding the probability of a
CNF formula G, denoted by P (G). By definition:
X
PM (x)
P (G) =
x∈Sol(FM ∧G)

1
Z

=

X

=

m
Y

φi (xV (φi ) )

(4)

x∈Sol(FM ∧G) i=1
′
. Because
From Equations 3 and 4, we get P (G) = ZZM
M
computing P (G) is equivalent to computing a ratio of two
partition functions, in the sequel, we will present formulabased algorithms for computing ZM only.

3 Exact Formula-based Inference
We first explain how to perform inference by variablebased conditioning and then show how it can be generalized via formula-based conditioning. Consider the expression for ZM (See Equation 2). Given assignments Xj and
¬Xj , we can express ZM as:
ZM

X

=

m
Y

φi (xV (φi ) )

x∈Sol(FM ∧Xj ) i=1

+

X

m
Y

φi (xV (φi ) )

(5)

x∈Sol(FM ∧¬Xj ) i=1

= ZMXj + ZM¬Xj

Figure 1: An example PropMRF.
(AVBVCVDVE, w1)
(AVBVCVFVG,w2)
(DVEVH,w3)
(FVGVJ,w4)
Left arcs are True
arcs and right arcs
are False arcs

exp(w1+w2) .22
(DVEVH,w3)
(FVGVJ,w4)

A

(DVEVH,w3) (FVGVJ,w4) ¬A
(BVCVDVE, w1) (BVCVFVG,w2)

Decompose
(DVEVH,w3)

(FVGVJ,w4)

Figure 2: Figure demonstrating the simplification steps after con-

(3)

x∈Sol(FM ∧G) i=1

X

weight
w1
w2
w3
w4

ditioning on variable A for the PropMRFgiven in Figure 1.

φi (xV (φi ) )

If we add all the clauses of G to the hard clauses of M
yielding another PropMRF M′ , then the partition function
ZM′ of M′ is given by:
Z M′

Clause
A∨B∨C ∨D∨E
A∨B∨C ∨F ∨G
D∨E∨H
F ∨G∨J

(2)

x∈Sol(FM ) i=1

m
Y

ClauseID
S1
S2
S3
S4

(6)

where MX and M¬X are PropMRFs obtained by adding
X and ¬X to the set of hard clauses of M respectively.
Then, one can perform conditioning to compute ZMXj and
ZM¬Xj , recursively for each PropMRF until all variables

in X have been instantiated. Conditioning by itself is not
that useful. For example, if the PropMRF has no hard
clauses, then conditioning would perform 2n summations.
However, one can augment it with various simplification
schemes such as Boolean constraint propagation, and utilize problem decomposition, yielding powerful schemes in
practice. These and other ideas form the backbone of many
state-of-the-art schemes such as ACE (Chavira and Darwiche, 2008) and Cachet (Sang et al., 2005). To simplify a
PropMRF, we can apply any parsimonious operators - operators which do not change its partition function. In particular, we can remove all clauses which evaluate to True
from the set of hard clauses. These clauses are redundant.
Examples of operations that aid in identifying such hard
clauses are unit propagation, resolution and subsumption
elimination. For example, given a hard clause A, the hard
clause A ∨ B is redundant and can be removed because it
is subsumed within A. Similarly, A could be removed after unit propagation, because it always evaluates to True.
We can simplify the soft clauses based on the hard clauses
by removing all soft clauses which evaluate to either True
or False, multiplying the partition function with an appropriate constant to account for their removal. For example,
given a hard clause A, the soft clause A ∨ B having weight
w is always satisfied and can be removed, by multiplying
the partition function by exp(w)1 .
Another advancement that we can use is problem decomposition (Darwiche, 2001; Dechter and Mateescu, 2007).
The idea here is that if the soft and hard clauses of a
PropMRF can be partitioned into k > 1 sets such that any
two clauses in any of the k sets have no variables in com1
Note that if we remove a variable that is not a unit clause
from all the hard and soft clauses, then we have to multiply the
partition function by 2.

(AVBVCVDVE, w1)
(AVBVCVFVG,w2)
(DVEVH,w3)
(FVGVJ,w4)
Left arcs are True
arcs and right arcs
are False arcs

Algorithm 1: Formula Decomposition and Conditioning
(FDC)
Input: A PropMRF M
Output: ZM
begin
w = 0;
1. Simplify
begin
Simplify the hard and soft clauses;
Add the weights of all soft clauses which evaluate to
True to w;
Remove all soft clauses which evaluate to either True or
False from M. Update w to account for variables
completely removed from all formulas;
if FM has an empty clause then
return 0
if FM has only unit clauses then
return exp(w)

AVBVC

(DVE, w1) (FVG,w2), ¬A, ¬ B, ¬ C
(DVEVH,w3) (FVGVJ,w4)

(DVEVH,w3)
(FVGVJ,w4)
A VBVC

Decompose
Decompose
(DVEVH,w3)

(FVGVH,w4)

A VBVC

(DVE,w1)
(DVEVH,w3)
DVE

DVE

(FVG,w2)
(FVGVJ,w4)
FVG

(H,w3)
¬D
¬E

FVG

(J,w4)
¬F
¬G

end
2. Decompose
begin
if the primal graph of M is decomposable into k
components then
Let M1 , M2 , ..., Mk be the PropMRF’s
corresponding to the k components;
return exp(w) × F DC(M1 ) × . . . × F DC(Mk )

Figure 3: Search space of Formula Decomposition and
Conditioning for an example PropMRF
mon, then the partition function equals the product of the
partition functions of the k PropMRFs induced by each set.
The following example demonstrates simplification and decomposition on an example PropMRF.
E XAMPLE 1. Consider the PropMRF shown in Figure 1.
After conditioning on A and simplifying using Boolean
constraint propagation, we get two PropMRFs shown under the True (left) and false (right) branches of A in Figure
2. The PropMRF at the True branch contains only two soft
clauses which have no variables in common. Thus, they
could be decomposed into two PropMRFs as shown. The
contribution to the partition function due to the True branch
of A is then simply a product of the partition functions of
the two PropMRFs and exp(w1 + w2 ) × 22 .
Our main observation is that we can condition on arbitrary
formulas instead of variables. Formally, given an arbitrary
formula Hj , we can express ZM as:
ZM

X

=

m
Y

φi (xV (φi ) )

x∈Sol(FM ∧Hj ) i=1

+

X

m
Y

φi (xV (φi ) )

(7)

x∈Sol(FM ∧¬Hj ) i=1

= ZMHj + ZM¬Hj

(8)

When combined with Boolean constraint propagation and
problem decomposition, this seemingly simple idea is quite
powerful because it can yield a smaller search space, as we
demonstrate in the following example. In some cases, these
reductions could be significant.
E XAMPLE 2. Consider again the PropMRF shown in Figure 1. The first two clauses share a sub-clause A ∨ B ∨ C.
If we condition first on A ∨ B ∨ C, we get the search space
shown in Figure 3, which has only 7 leaf nodes. One can

end
3. Condition
begin
Heuristically choose a formula R to condition on;
Add hard clauses logically equivalent to R and ¬R to
M yielding MR and M¬R respectively;
return exp(w) × (F DC(MR ) + F DC(M¬R ))
end
end

verify that if we condition only on the variables instead of
arbitrary formulas, the best ordering scheme will explore
12 leaf nodes. (This search space is not shown because of
lack of space. It can be worked out using Figure 2.)
Algorithm Formula Decomposition and Conditioning
(FDC) is presented as Algorithm 1. It takes as input a
PropMRF M. The first step is the simplification step
in which we reduce the size of the hard and the soft
clauses using techniques such as unit propagation, resolution and subsumption elimination. In the decomposition step (Step 2), we decompose M into independent
PropMRFs if its primal graph is decomposable. Each of
them are then solved independently. Note that this is a
very important step and is the primary reason for efficiency
of techniques such as recursive conditioning (Darwiche,
2001) and AND/OR search (Dechter and Mateescu, 2007).
In fact, the whole idea in performing simplification and
heuristic conditioning is to split the PropMRF into several
PropMRF’s that can be solved independently. Finally, in
the conditioning step, we heuristically select a formula R
to condition on and then recurse on the true and the false
assignments to R.

We summarize the dominance of FDC over VDC (where
VDC is same as FDC except that we condition only on unit
clauses in Step 3) in the following proposition.
P ROPOSITION 1. Given a PropMRF M, let SM,F and
SM,V be the number of nodes in the smallest search space
explored by FDC and VDC respectively. Then SM,F ≤
SM,V . Sometimes, this inequality can be strict.
Improvements
We consider two important improvements. First, note that
if we are not careful, the algorithm as presented may yield
a super-exponential search space. For example, if we condition on a set of arbitrary formulas, none of which simplify the PropMRF, we may end up conditioning on a
super-exponential number of formulas. Trivially, to guarantee at least an exponential search space in the size of the
clausal specification, the formula selected for conditioning
must reduce/simplify at least one soft clause or at least one
hard clause. Second, we can augment FDC with component caching and clause learning as in Cachet (Sang et al.,
2005) and use w-cutset conditioning (Dechter, 1999) in a
straight forward manner. We omit the details.
3.1 Related work
FDC generalizes variable-based conditioning schemes such
as recursive conditioning (Darwiche, 2001), AND/OR
search (Dechter and Mateescu, 2007) and value elimination (Bacchus et al., 2003) because all we have to do is
restrict our conditioning to unit clauses. FDC also generalizes weighted model counting (WMC) approaches such
as ACE (Chavira and Darwiche, 2008) and Cachet (Sang
et al., 2005). These weighted model counting approaches
introduce additional Boolean variables to model each soft
clause. Conditioning on these Boolean variables is equivalent to conditioning on the soft clauses present in the
PropMRF. Thus, FDC can simulate WMC by restricting
its conditioning to not only the unit clauses but also the soft
clauses already present in the PropMRF. Finally, FDC is
related to streamlined constraint reasoning (SCR) approach
of (Gomes and Sellmann, 2004). The idea in SCR is to add
a set of streamlining formulas to the input formula in order
to cut down the size of its solution space in a controlled
manner. The goal of streamlining is solving a Boolean Satisfiability (or a Constraint Satisfaction) problem while FDC
uses (streamlined) formulas for weighted model counting.

4 Formula Importance Sampling
In this section, we generalize conventional variable-based
importance sampling to formula importance sampling and
show that our generalization yields new sampling schemes
having smaller variance. We first present background on
variable-based importance sampling.

4.1 Variable-Based Importance Sampling
Importance sampling (Rubinstein, 1981) is a general
scheme which can be used to approximate any quantity
such as ZM which can be expressed as a sum of a function over a domain. The main idea is to use an importance
distribution Q, which satisfies PM (x) > 0 ⇒ Q(x) > 0
and express ZM as follows:
ZM

=
=

X

m
Y

Q(x)
Q(x)
x∈Sol(F ) i=1
Q


I(x) m
i=1 φi (xV (φi ) )
EQ
Q(x)
φi (xV (φi ) ) ×

(9)

where I(x) is an indicator function which is 1 if x is a solution of FM and 0 otherwise.
Given N independent and identical (i.i.d.) samples
(x(1) , . . . , x(N ) ) drawn from Q, we can estimate ZM usbN , defined below:
ing Z
(i)
(i) Qm
N
1 X I(x ) j=1 φj (xV (φj ) )
b
ZN =
N i=1
Q(x(i) )

(10)

bN ] = ZM ,
It is known (Rubinstein, 1981) that EQ [Z
namely it is unbiased. The mean squared error (MSE) of
bN is given by:
Z
Q
i
h
I(x) m
i=1 φi (xV (φi ) )
V arQ
Q(x)
bN ) =
M SE(Z
(11)
N
Thus, we can reduce the mean squared error by either reducing the variance (given in the numerator) or by increasing the number of samples N (or both).

4.2 Formula-based Importance Sampling
Importance sampling can be extended to the space of
clauses (or formulas) in a straight forward manner. Let
H = {H1 , . . . , Hr } be a set of arbitrary formulas over the
variables X of M, and let h = (h1 , . . . , hr ) be a truth assignment to all the clauses in H. Let H be such that every consistent truth assignment h evaluates all soft clauses
to either True or False. Note that this condition is critical. Trivially, if H equals the set of soft clauses, then the
condition is satisfied. Let Fh be the formula corresponding to conjunction (H1 = h1 ∧ . . . ∧ Hr = hr ) and let
xh ∈ Sol(Fh ). Given a function φ, let xh,V (φ) be the restriction of xh to the scope of φ. Then, given an importance
distribution U (H), we can rewrite ZM as:
Q
X #(Fh ∧ FM ) × m
i=1 φi (xh,V (φi ) )
U (h)
ZM =
U (h)
h∈H
Qm


#(Fh ∧ FM ) × i=1 φi (xh,V (φi ) )
(12)
= EU
U (h)

Algorithm 2: Formula Importance Sampling (FIS)

4.3 Variance Reduction

Input: A PropMRFM and an importance distribution U (H)
over a set of clauses H = {H1 , . . . , Hr }
Output: An unbiased estimate of ZM
begin
e = 0, N = 0
Z
repeat
qb = 1 (Backtrack-free probability is stored here),
G = FM and h = φ
for i = 1 to |H| do
Let G1 = G ∧ Hi and G0 = G ∧ ¬Hi
if G0 and G1 have a solution (Checked using a SAT
solver) then
Sample hi from U (Hi |h)
h = h ∪ hi
qb = qb × U (Hi = hi |h)
G = G ∧ (Hi = hi )
else
if G0 is Satisfiable then
h = h ∪ (Hi = 0)
G = G ∧ (Hi = 0)
else
h = h ∪ (Hi = 1)
G = G ∧ (Hi = 1)

eN output by Algorithm 2 is likely to have
The estimate Z
bN given in Equation 10.
smaller mean squared error than Z
In particular, given a variable-based importance distribution Q(X), we can always construct a formula based importance distribution U (H) from Q(X), such that the variance
eN is smaller than that of Z
bN . Define:
of Z
X
Q(xh )
(14)
U (h) =

end

w = sum of weights of soft clauses satisfied by h
s = Estimate of model counts of G
e=Z
e + s × exp(w)/qb
Z
N =N +1
until timeout
e = Z/N
e
Z
e
return Z

Given N samples h(1) , . . . , h(N ) generated from U (H), we
eN , where:
can estimate ZM as Z
Qm
N
1 X #(Fh(i) ∧ FM ) × j=1 φj (xh(i) ,V (φj ) )
e
ZN =
N i=1
U (h(i) )

(13)

There are two issues that need to be addressed in order
to use Equation 13 for any practical purposes. First, the
importance distribution U (h) may suffer from the rejection problem (Gogate and Dechter, 2007a) in that we may
generate truth assignments (to clauses) which are inconsistent, namely their model count is zero. Note that this
could happen even if there are no hard clauses in M because the formula combinations considered may be inconsistent. Fortunately, if we ensure that U (h) = 0 whenever h is inconsistent, namely make U (h) backtrack-free
(Gogate and Dechter, 2007a), we can avoid this problem
altogether. Algorithm 2 outlines a procedure for constructing such a distribution using a complete SAT solver (for example Minisat (Sorensson and Een, 2005)). Second, computing #(Fh(j) ∧ FM ) exactly may be too time consuming. In such cases, we can use state-of-the-art approximate
counting techniques such as ApproxCount (Wei and Selman, 2005), SampleCount (Gomes et al., 2007) and SampleSearch (Gogate and Dechter, 2007b).

xh ∈Sol(Fh ∧FM )

Intuitively, each sample from U (H) given by Equation 14
is heavy in the sense that it corresponds to #(FM ∧ Fh )
samples from Q(xh ). Because of this larger sample size,
eN is smaller than that of Z
bN (assuming
the variance of Z
that #(FM ∧ Fh ) can be computed efficiently). The only
caveat is that generating samples from U (H) is more expensive. Formally (the proof is provided in the extended
version of the paper available online),
T HEOREM 1. Given a PropMRF M, a proposal distribution Q(X) defined over the variables of M, a set of formulas H = {H1 , . . . , Hr } and a distribution U (H) defined as
eN is less than or equal to
in Equation 14, the variance of Z
bN .
that of Z

We can easily integrate FIS with other variance reduction schemes such as Rao-Blackwellisation (Casella
and Robert, 1996) and AND/OR sampling (Gogate and
Dechter, 2008). These combinations can lead to interesting
time versus variance tradeoffs. We leave these improvements for future work. We describe how U (H) can be constructed in practice in the next section.

5 Experiments
5.1 Exact Inference
We compared “Formula Decomposition and Conditioning
(FDC)” against “Variable Decomposition and Conditioning (VDC)”, variable elimination (VE) (Dechter, 1999) and
ACE (Chavira and Darwiche, 2008) (which internally uses
the C2D compiler (Darwiche, 2004)) for computing the
partition function on benchmark problems from three domains: (a) Random networks, (b) medical diagnosis networks and (c) Relational networks. ACE, FDC and VDC
use the same clausal representation while VE uses tabular
representation. Note that the domains are deliberately chosen to elucidate the properties of FDC, in particular, to verify our intuition that as size of the clauses increases, FDC
is likely to dominate VDC.
We implemented FDC and VDC on top of RELSAT
(Roberto J. Bayardo Jr. and Pehoushek, 2000), which is
a SAT model counting algorithm. As mentioned earlier,
after conditioning on a formula, we use various Boolean

Problem
Random
40-40-3
40-40-5
40-40-7
40-40-9
50-50-3
50-50-5
50-50-7
50-50-9
60-60-3
60-60-5
60-60-7
60-60-9
QMRDT
40-40-5
40-40-7
40-40-9
40-40-11
50-50-5
50-50-7
50-50-9
50-50-11
60-60-5
60-60-7
60-60-9
60-60-11
FS
fs-25-5
fs-27-5
fs-29-5
fs-31-5
Cora
Cora2
Cora3

w

FDC

VDC

ACE

VE

10.80
23.00
29.80
33.40
12.60
28.40
36.00
42.20
15.00
33.80
44.00
49.60

0.08
11.81
11.77
1.71
0.02
278.25
167.79
20.97
0.08
X
X
218.28

0.08
10.57
245.63
326.42
0.02
257.45
1139.06
1187.28
0.11
X
X
X

0.60
108.37
13.37
14.37
0.73
56.94
294.30
113.52
0.58
X
X
X

0.01
1.69
X
X
0.02
X
X
X
0.04
X
X
X

16.80
22.20
24.00
25.20
22.80
30.00
34.00
33.00
26.00
34.60
40.40
45.00

2.03
6.39
22.20
18.20
14.53
545.23
33.30
28.43
244.05
56.40
97.20
72.10

1.26
6.73
44.51
69.00
14.96
517.71
883.04
554.01
203.32
1096.62
1180.94
X

1.17
3.87
9.40
10.08
9.14
379.41
357.06
495.96
310.37
637.23
554.01
488.10

1.17
7.93
X
X
3.63
X
X
X
X
X
X
X

22.80
24.80
26.60
29.40

30.93
151.56
391.65
1312.90

26.86
135.22
371.74
892.20

333.20
353.64
119.23
357.65

8.53
X
X
X

12.00
32.00

0.17
3902.20

0.14
X

1.84
X

0.04
X

Table 1: Average runtime in seconds of the four algorithms used
in our study over 10 random instances for each problem. We gave
each solver a time-bound of 3 hrs and a memory bound of 2GB.
X indicates that either the memory or time bound was exceeded.
The second column gives the average treewidth.

propagation, pruning techniques such as unit propagation, clause learning, subsumption elimination and resolution. Also, similar to Cachet (Sang et al., 2005), we use
component caching and similar to w-cutset conditioning
(Dechter, 1999), we invoke bucket elimination at a node
if the treewidth of the (remaining) PropMRF at the node is
less than 16.
Since FDC is a DPLL-style backtracking search scheme,
its performance is highly dependent upon a good branching heuristic (that selects the next clause to condition on).
In our implementation, we used a simple dynamic heuristic of conditioning on the largest sub-clause (unit clause in
case of VDC) that is common to most hard and soft clauses,
ties broken arbitrarily. The main intuition for this heuristic
is that branching on the largest common sub-clause would
cause the most propagation, yielding the most reduction in
the search space size. We also tried a few other heuristics,
both static and dynamic, such as (i) conditioning on a subclause C (and its negation) that causes the most unit propa-

gations (but one has to perform unit propagations for each
candidate clause, which can be quite expensive in practice)
(ii) graph partitioning heuristics based on the min-fill, mindegree and hmetis orderings; these heuristics are used by
solvers such as ACE (Chavira and Darwiche, 2008) and
AND/OR search (Dechter and Mateescu, 2007) and (iii)
Entropy-based heuristics. The results for these heuristics
show a similar trend as the results for the heuristic used in
our experiments, with the latter performing better on an average. We leave the development of sophisticated formulaordering heuristics for future work.
Table 1 shows the results. For each problem, we generated
10 random instances. For each instance, we set 5% of randomly chosen variables as evidence. Each row shows the
average time in seconds for each problem.
5.1.1 Random networks
Our first domain is that of random networks. The networks are generated using the model (n, m, s), where n
is the number of (Boolean) variables, m is the number
of weighted clauses and s is the size of each weighted
clause. Given n variables X = {X1 , . . . , Xn }, each clause
Ci (for i = 1 to m) is generated by randomly selecting
s (distinct) random variables from X and negating each
with probability 0.5. For our experiments, we set n = m
and experimented with three values for n and m: n, m ∈
{40, 50, 60}. s was varied from 3 to 9 in increments of 2.
A random problem (n, m, s) is designated as n − m − s in
Table 1. We see that FDC dominates VDC as s increases.
ACE is often inferior to FDC and often inferior to VDC. As
expected, variable elimination which does not take advantage of the structure of the formulas is the fastest scheme
when the treewidth is small but is unable to solve any problems having treewidth greater than 24.
5.1.2 Medical Diagnosis
Our second domain is a version of QMR-DT medical diagnosis networks (Shwe et al., 1991) as used in Cachet (Sang
et al., 2005). Each problem can be specified using a two
layer bipartite graph in which the top layer consists of diseases and the bottom layer consists of symptoms. If a disease causes a symptom, there is an edge from the disease
to the symptom. We have a weighted unit clause for each
disease and a weighted clause for each symptom, which is
simply a logical OR of the diseases that cause it (in (Sang
et al., 2005), this clause was hard. We attach an arbitrary
weight to it to make the problem harder). For our experiments, we varied the numbers of diseases and symptoms
from 40 to 60. For each symptom, we varied the number of
diseases that can cause it from 5 to 11 in increments of 2.
The diseases for each symptom are chosen randomly.
A QMR-DT problem (d, f, s) is designated as d − f − s in
Table 1. We can see that as the size of the clauses increases,

FDC performs better than VDC. FDC also dominates ACE
as the problem size increases.
5.1.3 Relational networks
Our final domain is that of relational networks. We experimented with the Friends and Smokers networks and the
Entity resolution networks.
In the friends and smokers networks (FS), we have
three first order predicates smokes(x), which indicates
whether a person smokes, cancer(x), which indicates
whether a person has cancer, and f riends(x, y), which
indicates who are friends of whom. The probabilistic
model is defined by assigning weights to two logical constraints, f riends(x, y) ∧ smokes(x) ⇒ smokes(y) and
smokes(x) ⇒ cancer(x). Given a domain for x and
y, a PropMRF can be generated from these two logical
constraints by considering all possible groundings of each
predicate. We experimented with different domain sizes for
x and y ranging from 25 to 34. From Table 1, we can see
that the time required by FDC is almost the same as VDC.
This is because the size of the clauses is small (≤ 3). ACE
dominates both FDC and VDC.
Entity resolution is the problem of determining which
observations correspond to the same entity. In our experiments, we consider the problem of matching citations of scientific papers.
We used the CORA
Markov logic network given in the Alchemy tutorial (Kok et al., 2004).
This MLN has ten predicates such as Author(bib, author), T itle(bib, title),
SameAuthor(author, author), SameT itle(title, title)
etc. and clauses ranging from size 2 to 6. The clauses
express relationship such as: if two fields have high similarity, then they are (probably) the same; if two records are
the same, their fields are the same, and vice-versa; etc. We
experimented with domain sizes of 2 and 3 for each of the
5 first-order variables present in the domain. The problems
are denoted as cora2 and cora3 respectively. From Table
1, we can see that FDC is the only algorithm capable of
solving the largest instance.
5.2 Approximate Inference
We compared “Formula importance sampling (FIS)”
against “Variable importance sampling (VIS)” and stateof-the-art schemes such as MC-SAT (Poon and Domingos, 2006) and Gibbs sampling available in Alchemy (Kok
et al., 2004) on the three domains described above. For both
VIS and FIS, we chose to construct the importance distribution Q from the output of a Belief propagation scheme
(BP), because BP was shown to yield a better importance
function than other approaches in previous studies (Yuan
and Druzdzel, 2006; Gogate and Dechter, 2005).
We describe next, how the method described in (Gogate

and Dechter, 2005) can be adapted to construct an importance distribution over formulas. Here, we first run BP
(or Generalized Belief Propagation (Yedidia et al., 2004))
over a factor (or region) graph in which the nodes are the
variables and the factors are the hard and the soft clauses.
Let (C1 , . . . , Cm ) be an ordering over the soft clauses.
Given a truth assignment to the first i − 1 soft clauses
ci−1 = (c1 , . . . , ci−1 ), we compute U (Ci |ci−1 ) as follows.
We first simplify the formula F = FM ∧ Fci−1 , possibly
deriving new unit clauses. Let φCi be the marginal distribution at the factor corresponding to the clause Ci in the
output of BP. Then, U (Ci |ci−1 ) is given by:
X
U (Ci = T rue|ci−1 ) ∝
(15)
IF,Ci (y)φCi (y)
y∈φCi

where IF,Ci (y) = 1 if y evaluates Ci to True but does not
violate any unit clause in F , and 0 otherwise. Note that the
importance distribution Q over the variables is a special
case of the scheme described above in which we construct
a distribution over all the unit clauses.
We implemented Algorithm 2 as follows. Notice that the
algorithm requires a SAT solver and a model counter. We
used Minisat (Sorensson and Een, 2005) as our SAT solver.
For model counting, we use the RELSAT model counter
whenever exact counting was feasible2 and the approximate solver SampleSearch (Gogate and Dechter, 2007b)
whenever it wasn’t.
We measure the performance of the sampling schemes using the sum Kullback-Leibler divergence (KLD) between
the exact and the approximate posterior marginals for each
variable given evidence. Time versus sum KLD plots for
two representative problems from each domain are shown
in Figures 4, 5 and 6. We can clearly see that as the size of
the clauses increases, FIS outperforms VIS, MC-SAT and
Gibbs sampling.

6 Summary and Conclusion
In this paper, we introduced a new formula-based approach
for performing exact and approximate inference in graphical models. Formula-based inference is attractive because:
(a) it generalizes standard variable-based inference, (b) it
yields several new efficient algorithms that are not possible
by reasoning just over the variables and (c) it fits naturally
within the recent research efforts in combining logical and
probabilistic Artificial Intelligence.
Our empirical evaluation shows that formula-based approach is especially suitable for domains having large
clauses. Such clauses are one of the main reasons for using logic instead of tables for representing potentials or
2

Exact counting was invoked if the number of variables was
less than 100, which was the case for most networks that we experimented with, except the relational benchmarks.

10

10
1
0.1

0.1

Sum KLD

Sum KLD

1

0.01
0.001

0.01
0.001
0.0001

0.0001

1e-05

1e-05

1e-06
0

200

400

600

800

1000

1200

0

200

Time in seconds
MC-SAT
Gibbs sampling

600

800

1000

1200

Time in seconds

FormulaIS
VariableIS

MC-SAT
Gibbs sampling

(a) Random problem (n = 50, m = 50, s = 5)

FormulaIS
VariableIS

(a) QMR-DT problem (d = 50, f = 50, s = 5)

100

100

10

10
1

Sum KLD

1

Sum KLD

400

0.1
0.01
0.001

0.1
0.01
0.001
0.0001

0.0001

1e-05

1e-05

1e-06
0

200

400

600

800

1000

1200

0

Time in seconds
MC-SAT
Gibbs sampling

400

600

800

1000

1200

Time in seconds

FormulaIS
VariableIS

(b) Random problem (n = 50, m = 50, s = 7)

200

MC-SAT
Gibbs sampling

FormulaIS
VariableIS

(b) QMR-DT problem (d = 50, f = 50, s = 11)

Figure 4: Time versus Sum KLD plots for 2 Random instances.

Figure 5: Time versus Sum KLD plots for 2 QMR-DT networks.

CPTs in graphical models. In particular, conventional tabular representations require space exponential in the number of variables in the scope of the potential, while if the
potential can be summarized using a constant number of
clauses, we only require linear space. Since an efficient
inference scheme is one of the main bottleneck in learning PropMRFs having large clauses, we believe that our
formula-based approach to inference can lead to new structure and weight learning schemes that learn large weighted
clauses from data.

D030010, NSF grants IIS-0534881 and IIS-0803481, and
ONR grant N00014-08-1-0670. The views and conclusions contained in this document are those of the authors
and should not be interpreted as necessarily representing
the official policies, either expressed or implied, of ARO,
DARPA, NSF, ONR, or the United States Government.

Our work can be extended in several ways. In particular,
we envision formula-based versions of various inference
schemes such as variable elimination, belief propagation
and Markov Chain Monte Carlo (MCMC) sampling. One
of these schemes, namely formula elimination trivially follows from this work, as it is known that conditioning works
along the reverse direction of elimination (Dechter, 1999).
Also, we envision the development of lifted versions of all
the formula-based schemes proposed in this paper.
Acknowledgements
This research was partly funded by ARO grant W911NF08-1-0242, AFRL contract FA8750-09-C-0181, DARPA
contracts
FA8750-05-2-0283,
FA8750-07-D-0185,
HR0011-06-C-0025, HR0011-07-C-0060 and NBCH-




of our approach on a complex dynamic domain of a person’s transportation routines.

This paper describes a general framework called
Hybrid Dynamic Mixed Networks (HDMNs)
which are Hybrid Dynamic Bayesian Networks
that allow representation of discrete deterministic
information in the form of constraints. We propose approximate inference algorithms that integrate and adjust well known algorithmic principles such as Generalized Belief Propagation,
Rao-Blackwellised Particle Filtering and Constraint Propagation to address the complexity of
modeling and reasoning in HDMNs. We use
this framework to model a person’s travel activity over time and to predict destination and
routes given the current location. We present a
preliminary empirical evaluation demonstrating
the effectiveness of our modeling framework and
algorithms using several variants of the activity
model.

Focusing
on
algorithmic
issues,
the
most
popular
approximate
query
processing
algorithms
for
dynamic
networks
are
Expectation
propagation(EP)
[Heskes and Zoeter, 2002]
and
Rao-Blackwellised
Particle
Filtering
(RBPF) [Doucet et al., 2000].
We therefore extend
these algorithms to accommodate and exploit discrete
constraints in the presence of continuous probabilistic
functions. Extending Expectation Propagation to handle
constraints is easy, extension to continuous variables is a
little more intricate but still straightforward. The presence
of constraints introduces a principles challenge for Sequential Importance Sampling algorithms, however. Indeed the
main algorithmic contribution of this paper in presenting
a class of Rao-Blackwellised Particle Filtering algorithm,
IJGP-RBPF for HDMNs which integrates a Generalized
Belief Propagation component with a Rao-Blackwellised
Particle Filtering scheme.

1 INTRODUCTION
Modeling sequential real-life domains often requires the
ability to represent both probabilistic and deterministic information. Hybrid Dynamic Bayesian Networks (HDBNs)
were recently proposed for modeling such phenomena
[Lerner, 2002]. In essence, these are factored representation of Markov processes that allow discrete and continuous variables. Since they are designed to express uncertain
information they represent constraints as probabilistic entities which may have negative computational consequences.
To address this problem [Dechter and Mateescu, 2004,
Larkin and Dechter, 2003] introduced the framework of
Mixed Networks. In this paper we extend the Mixed Networks framework to dynamic environments, allow continuous Gaussian variables, yielding Hybrid Dynamic Mixed
Networks (HDMN). We address the algorithmic issues that
emerge from this extension and demonstrate the potential

Our motivation for developing HDMNs as a modeling
framework is a range of problems in the transportation literature that depend upon reliable estimates of the prevailing demand for travel over various time scales. At one
end of this range, there is a pressing need for accurate
and complete estimation of the global origins and destinations (O-D) matrix at any given time for an entire urban
area. Such estimates are used in both urban planning applications [Sherali et al., 2003] and integrated traffic control systems based upon dynamic traffic assignment techniques [Peeta and Zilaskopoulos, 2001]. Even the most advanced techniques, however, are hamstrung by their reliance upon out-dated, pencil-and-paper travel surveys and
sparsely distributed detectors in the transportation system.
We view the increasing proliferation of powerful mobile
computing devices as an opportunity to remedy this situation. If even a small sample of the traveling public
agreed to collect their travel data and make that data publicly available, transportation management systems could
significantly improve their operational efficiency. At the

other end of the spectrum, personal traffic assistants running on the mobile devices could help travelers replan their
travel when the routes they typically use are impacted by
failures in the system arising from accidents or natural disasters. A common starting point for these problems is to
develop an efficient formulation for learning and inferring
individual traveler routines like traveler’s destination and
his route to destination from raw data points.
The rest of the paper is organized as follows. In the next
section, we discuss preliminaries and introduce our modeling framework. We then describe two approximate inference algorithms for processing HDMN queries: an Expectation Propagation type and a Particle Filtering type.
Subsequently, we describe the transportation modeling approach and present preliminary empirical results on how
effectively a model is learnt and how accurately its predictions are given several models and a few variants of the
relevant algorithms.
We view the contribution of this paper in addressing a complex and highly relevant real life domain using a general
framework and domain independent algorithms, thus allowing systematic study of modeling, learning and inference in a non-trivial setting.

2 PRELIMINARIES AND DEFINITIONS
Hybrid Bayesian Networks (HBN) [Lauritzen, 1992] are
graphical models defined by a tuple B = (X, G, P), where X
is the set of variables
partitioned into discrete and continuS
ous ones X = Γ ∆, respectively, G is a directed acyclic
graph whose nodes corresponds to the variables. P =
{P1 , ..., Pn } is a set of conditional probability distributions
(CPDs). Given variable xi and its parents in the graph
pa(xi ), Pi = P(xi |pa(xi )). The graph structure G is restricted in that continuous variables cannot have discrete
variables as their child nodes. The conditional distribution of continuous variables are given by a linear Gaussian
model: P(xi |I = i, Z = z) = N(α(i) + β(i) ∗ z, γ(i))xi ∈ Γ
where Z and I are the set of continuous and discrete parents
of xi , respectively and N(µ, σ) is a multi-variate normal distribution. The network represents a joint distribution over
all its variables given by a product of all its CPDs.
A Constraint Network [Dechter, 2003] is a graphical model
R = (X, D,C), where X = {x1 , . . . , xn } is the set of variables, D = {D1 , . . . , Dn } is their respective discrete domains and C = {C1 ,C2 , . . . ,Cm } is the set of constraints.
Each constraint Ci is a relation Ri defined over a subset of
the variables Si ⊆ X and denotes the combination of values that can be assigned simultaneously. A Solution is an
assignment of values to all the variables such that no constraint is violated. The primary query is to decide if the
constraint network is consistent and if so find one or all
solutions.

The recently proposed Mixed Network framework [Dechter and Mateescu, 2004] for augmenting
Bayesian Networks with constraints, can immediately be
applied to HBNs yielding the Hybrid Mixed Networks
(HMNs). Formally, given a HBN B = (X, G, P) that
expresses the joint probability PB and given a constraint
network R = (X, D,C) that expresses a set of solutions ρ,
an HMN is a pair M = (B , R ). The discrete variables and
their domains are shared by B and R and the relationships
are those expressed in P and C. We assume that R is
consistent. The mixed network M = (B , R ) represents the
conditional probability PM (x) = PB (x|x ∈ ρ) i f x ∈ ρ and
0 otherwise.
Dynamic Bayesian Networks are Markov models whose
state-space and transition functions are expressed in a factored form using Bayesian Networks. They are defined by
a prior P(X0 ) and a state transition function P(Xt+1 |Xt ).
Hybrid Dynamic Bayesian Networks (HDBNs) allow continuous variables while Hybrid Dynamic Mixed Networks
(HDMNs) also permit explicit discrete constraints.
D EFINITION 2.1 A Hybrid Dynamic Mixed Network
(HDMN) is a pair (M0 , M→ ), defined over a set of variables X = {x1 , ..., xn }, where M0 is an HMN defined over
X representing P(X0 ). M→ is a 2-slice network defining
the stochastic process P(Xt+1 |Xt ). The 2-time-slice Hybrid
00
Mixed network (2-THMN) is an HMN defined over X 0 ∪ X
0
00
such that X and X are identical to X. The acyclic graph
0
of the probabilistic portion is restricted so that nodes in X
are root nodes and have no CPDs associated with them.
The constraints are defined the usual way. The 2-THMN
00
0
represents a conditional distribution P(X |X ).
The semantics of any dynamic network can be understood by unrolling the network to T time-slices. Namely,
T
P(X0:t ) = P(X0 ) ∗ ∏t=1
P(Xt |Xt−1 ) where each probabilistic component can be factored in the usual way, yielding a
regular HMN over T copies of the state variables.
The most common task over Dynamic Probabilistic Networks is filtering and prediction Filtering is the task of determining the belief state P(Xt |e0:t ) where Xt is the set of
variables at time t and e0:t are the observations accumulated
at time-slices 0 to t. Filtering can be accomplished in principle by unrolling the dynamic model and using any stateof-the art exact or approximate reasoning algorithm. The
join-tree-clustering algorithm is the most commonly used
algorithm for exact inference in Bayesian networks. It partitions the CPDs and constraints into clusters that interact
in a tree-like manner (the join-tree) and applies messagepassing between clusters. The complexity of the algorithm is exponential in a parameter called treewidth, which
is the maximum number of discrete variables in a cluster. However, the stochastic nature of Dynamic Networks
restricts the applicability of join-tree clustering considerably. In the discrete case the temporal structure implies

tree-width which equals to the number of state variables
that are connected with the next time-slice, thus making the
factored representation ineffective. Even worse, when both
continuous and discrete variables are present the effective
treewidth is O(T ) when T is the number of time slices, thus
making exact inference infeasible. Therefore the applicable approximate inference algorithms for Hybrid Dynamic
Networks are either sampling-based such as Particle Filtering or propagation-based such as Expectation Propagation.
In the next two sections, we will extend these algorithms to
HDMNs.

3 EXPECTATION PROPAGATION
In this section we extend an approximate inference algorithm called Expectation Propagation
(EP) [Heskes and Zoeter, 2002] from HDBNs to HDMNs.
The idea in EP (forward pass) is to perform Belief Propagation by passing messages between slices t and t + 1
along the ordering t = 0 to T . EP can be thought of as
an extension of Generalized Belief Propagation (GBP)
to HDBNs [Heskes and Zoeter, 2002]. For simplicity of
exposition, we will extend a GBP algorithm called Iterative
Join graph propagation [Dechter et al., 2002] to HDMNs
and call our technique IJGP(i)-S where ”S” denotes that
the process is sequential. The extension is rather straightforward and can be easily derived by integrating the results
in [Murphy, 2002, Dechter et al., 2002, Lauritzen, 1992,
Larkin and Dechter, 2003].
IJGP [Dechter et al., 2002] is a Generalized Belief Propagation algorithm which performs message passing on a
join-graph. A join-graph is collection of cliques or clusters
such that the interaction between the clusters is captured
by a graph. Each clique in a join-graph contains a subset
of variables from the graphical model. IJGP(i) is a parameterized algorithm which operates on a join-graph which
has less than i + 1 discrete variables in each clique. The
complexity of IJGP(i) is bounded exponentially by i , also
called the i-bound. In the message-passing step of IJGP(i),
a message is sent between any two nodes that are neighbors of each other in the join-graph. A message sent by
node Ni to N j is constructed by multiplying all the functions and messages in a node (except the message received
from N j ) and marginalizing on the common variables between N j and Ni (see [Dechter et al., 2002]).
IJGP(i) can be easily adapted to HDMNs (which we call
IJGP(i)-S) and we describe some technical details here
rather than a complete derivation due to lack of space. Note
that because we are performing online inference, we need
to construct the join-graph used by IJGP(i)-S in an online
manner rather than recomputing the join-graph every time
new evidence arrives. Murphy [Murphy, 2002] describes
a method to compute a join-tree in an online manner by
pasting together join-trees of individual time-slices using

special cliques called the interface. [Dechter et al., 2002]
describe a method to compute join-graphs from join-trees.
The two methods can be combined in a straightforward way
to come up with an online procedure for constructing a
join-graph. In this procedure, we split the interface into
smaller cliques such that the new cliques have less than
i + 1 variables. This construction procedure is shown in
Figure 1.
Message-passing is then performed in a sequential way as
follows. At each time-slice t, we perform message-passing
over nodes in t and the interface of t with t − 1 and t + 1
(shown by the ovals in Figure 1). The new functions computed in the interface of t with t + 1 are then used by t + 1,
when we perform message passing in t + 1.
Three important technical issues remain to be discussed.
First, message-passing requires the operations of multiplication and marginalization to be performed on functions
in each node. These operators can be constructed for
HDMNs in a straightforward way by combining the operators by [Lauritzen, 1992] and [Larkin and Dechter, 2003]
that work on HBNs and discrete mixed networks respectively. We will now briefly comment on how the multiplication operator can be derived. Let us assume we
want to multiply a collection of probabilistic functions P0
and a set of constraint relations C0 (which consist of only
discrete tuples allowed by the constraint) to form a single function PC. Here, multiplication can be performed
on the functions in P0 and C0 separately using the operators in [Lauritzen, 1992] and [Dechter, 2003] respectively
to compute a single probabilistic function P and a single
constraint relation C. These two functions P and C can be
multiplied by deleting all tuples in P that are not present in
C to form the required function PC.
Second, because IJGP(i)-S constructs join-graphs sequentially, the maximum-i-bound for IJGP(i)-S is bounded by
the treewidth of the time slice and its interfaces and not the
treewidth of the entire HDMN model (see Figure 1).

Figure 1: Schematic illustration of the Procedure used for
creating join-graphs and join-trees of HDMNs

Algorithm IJGP-RBPF
• Input: A Hybrid Dynamic Mixed Network (X, D, G, P,C)0:T and a observation sequence e0:T Integer N, w and i.
• Output: P(XT |e0:T )
• For t = 0 to T do
• Sequential Importance Sampling step:
1. Generalized Belief Propagation step
Use IJGP(i) to compute the proposal distribution Ωapp
2. Rao-Blackwellisation step
Partition the Variables Xt into Rt and Zt such that the treewidth of a join-tree of
Zt is w.
3. Sampling step
For i = 1 to N do
(a) Generate a Rti from Ωapp .
(b) reject sample if rti is not a solution. i=i-1;
(c) Compute the importance weights wti of Rti .
ci .
4. Normalize the importance weights to form w
t
• Selection step:
– Resample N samples from Rbti according to the normalized importance weights
ci to obtain new N random samples.
w
t

• Exact step:
– for i = 1 to N do
i , e , Rbi and
Use join-tree-clustering to compute the distribution on Zti given Zt−1
t t
d
i
R .
t−1

Figure 2: IJGP-RBPF for HDMNs
Third, IJGP(i) guarantees that the computations will be exact if i is equal to the treewidth. This is not true for IJGP(i)S in general as shown in [Lerner, 2002]. It can be proved
that:
T HEOREM 3.1 The complexity of IJGP(i)-S is O(((|∆t | +
n) ∗ d i ∗ Γt3 ) ∗ T ) where |∆t | is the number of discrete variables in time-slice t, d is the maximum-domain size of the
discrete variables, i is the i-bound used, n is the number
of nodes in a join-graph of the time-slice, Γt is the maximum number of continuous variables in the clique of the
join-graph used and T is the number of time-slices.

4 RAO-BLACKWELLISED PARTICLE
FILTERING
In this section, we will extend the Rao-Blackwellised Particle filtering algorithm [Doucet et al., 2000] from HDBNs
to HDMNs. Before, we present this extension, we will
briefly review Particle Filtering and Rao-Blackwellised
Particle Filtering (RBPF) for HDBNs.
Particle filtering uses a weighted set of samples or particles to approximate the filtering distribution. Thus, given
a set of particles Xt1 , . . . , XtN approximately distributed according to the target-filtering distribution P(Xt = M|e0:t ),
the filtering distribution is given by P(Xt = M|e0:t ) =
1/N ∑Ni=1 δ(Xti = M) where δ is the Dirac-delta function.
Since we cannot sample from P(Xt = M|e0:t ) directly, Parti-

cle filtering uses an appropriate (importance) proposal distribution Q(X) to sample from. The particle filter starts by
generating N particles according to an initial proposal distribution Q(X0 |e0 ). At each step, it generates the next state
i for each particle X i by sampling from Q(X
i
Xt+1
t+1 |Xt , e0:t ).
t
It then computes the weight of each particle based given by
wt = P(X)/Q(X) to compute a weighted distribution and
then re-samples from the weighted distribution to obtain a
set of un-biased or un-weighted particles.
Particle filtering often shows poor performance in highdimensional spaces and its performance can be improved
by sampling from a sub-space by using the RaoBlackwellisation (RB) theorem (and the particle filtering
is called Rao-Blackwellised Particle Filtering (RBPF)).
Specifically, the state Xt is divided into two-sets: Rt and
Zt such that only variables in set Rt are sampled (from a
proposal distribution Q(Rt ) ) while the distribution on Zt
is computed analytically given each sample on Rt (assuming that P(Zt |Rt , e0:t , Rt−1 ) is tractable). The complexity
of RBPF is proportional to the complexity of exact inference step i.e. computing P(Zt |Rt , e0:t , Rt−1 ) for each sample Rtk . w-cutset [Bidyuk and Dechter, 2004] is a parameterized way to select Rt such that the complexity of computing P(Zt |Rt , e0:t , Rt−1 ) is bounded exponentially by w. Below, we use the w-cutset idea to perform RBPF in HDMNs.
Since exact inference can be done in polynomial time if
a HDBN contains only continuous variables, a straightforward application of RBPF to HDBNs involves sampling
only the discrete variables in each time slice and exactly
inferring the continuous variables [Lerner, 2002].
Extending this idea to HDMNs, suggests that in each time
slice t we sample the discrete variables and discard all particles that violate the constraints in the time slice. Let us assume that we select a proposal distribution Q that is a good
approximation of the probabilistic filtering distribution but
ignores the constraint portion. The extension described
above can be inefficient because if the proposal distribution Q is such that it makes non-solutions to the constraint
portion highly probable, most samples from Q will be rejected (because these samples Rti will have P(Rti ) = 0 and
so the weight will be zero). Thus, on one extreme sampling
only from the Bayesian Network portion of each time-slice
may lead to potentially high rejection-rate.
On the other extreme, if we want to make the sample rejection rate zero we would have to use a proposal distribution Q0 such that all samples from this distribution
are solutions. One way to find this proposal distribution
is to make the constraint network backtrack-free (using
adaptive-consistency [Dechter, 2003] or exact constraint
propagation) along an ordering of variables and then sample along the reverse ordering. Another approach is to
use join-tree-clustering which combines probabilistic and
deterministic information and then sample from the join-

tree. However, both join-tree-clustering and adaptiveconsistency are time and space exponential in treewidth and
so they are costly when the treewidth is large. Thus on one
hand, zero-rejection rate implies using a potentially costly
inference procedure while on the other hand sampling from
a proposal distribution that ignores constraints may result
in a high rejection rate.
We propose to exploit the middle ground between the two
extremes by combining the constraint network and the
Bayesian Network into a single approximate distribution
Ωapp using IJGP(i) which is a bounded inference procedure. Note that because IJGP(i) has polynomial time complexity for constant i, we would not eliminate the samplerejection rate completely. However, by using IJGP(i) we
are more likely to reduce the rejection-rate because IJGP(i)
also achieves Constraint Propagation and it is well known
that Constraint Propagation removes many inconsistent
tuples thereby reducing the chance of sampling a nonsolution. [Dechter, 2003].
Another important advantage of using IJGP(i) is that
it yields very good approximations to the true posterior [Dechter et al., 2002] thereby proving to be an ideal
candidate for proposal distribution. Note that IJGP(i)
can be used as a proposal distribution because it can be
proved using results from [Dechter and Mateescu, 2003]
that IJGP(i) includes all supports of P(Xt |e0:t , Xt−1 ) (i.e.
P(Xt |e0:t , Xt−1 ) > 0 implies that the output of IJGP(i) viz.
Q > 0)
Note that IJGP(i) we use here is different from the algorithm IJGP(i)-S that we described in the previous section.
This is because in our RBPF procedure, we need to comk ,e )
pute an approximation to the distribution P(Rt |Rt−1
0:t
k
given the sample Rt−1
on variables Rt−1 and evidence e0:t .
IJGP(i) as used in our RBPF procedure works on HMNs
and can be derived using the results in [Dechter et al., 2002,
Lauritzen, 1992, Larkin and Dechter, 2003]. For lack of
space we do not describe the details of this algorithm (see a
companion paper [Gogate and Dechter, 2005] for details).
The integration of the ideas described above into a formal
algorithm called IJGP-RBPF is given in Figure 2. It uses
the same template as in [Doucet et al., 2000] and the only
step different in IJGP-RBPF from the original template is
the implementation of the Sequential Importance Sampling
step (SIS).
SIS is divided into three-steps: (1) In the Generalized
Belief Propagation step of SIS, we first perform Belief Propagation using IJGP(i) to form an approximation of the posterior (say Ωapp ) as described above.
(2) In the Rao-Blackwellisation step, we first partition the variables in a 2THMN into two sets Rt and
Zt using a method due to [Bidyuk and Dechter, 2004].
This method [Bidyuk and Dechter, 2004] removes minimal
variables Rt from Xt such that the treewidth of the remain-

Figure 3: Car Travel Activity model of an individual
ing network Zt is bounded by w. (3) In the sampling
step, the variables Rt are sampled from Ωapp . To generate a sample from Ωapp , we use a special data-structure
of ordered buckets which is described in a companion paper [Gogate and Dechter, 2005]. Importance weights are
computed as usual [Doucet et al., 2000].
Finally, the exact-step computes a distribution on Zt using join-tree-clustering for HMNs (see a companion paper [Gogate and Dechter, 2005] for details on join-treeclustering for HMNs). It can be proved that:
T HEOREM 4.1 The complexity of IJGP-RBPF(i,w) is
O([NR ∗ d w+1 + ((|∆| + n) ∗ (d i ∗ |Γ|3 ))] ∗ T ) where |∆| is
the number of discrete variables, d is the maximum-domain
size of the discrete variables, i is the adjusted-i-bound, w is
defined by w-cutset, n is the number of nodes in a joingraph, Γ is the number of continuous variables in a 2THMN, NR is the number of samples actually drawn and
T is the number of time-slices.

5

THE TRANSPORTATION MODEL

In this section, we describe the application of HDMNs to
a real-world problem of inferring car travel activity of individuals. The major query in our HDMN model is to predict where a traveler is likely to go and what his/her route
to the destination is likely to be, given the current location of the traveler’s car. This application was described
in [Liao et al., 2004] in a different context for detecting abnormal behavior in Alzheimer’s patients and they use a Abstract Hierarchical Markov Models (AHMM) for reasoning
about this problem. The novelty in our approach is not only
a more general modeling framework and approximate inference algorithms but also a domain independent implementation which allows an expert to add and test variants
of the model.
Figure 3 shows a HDMN model for modeling the car travel
activity of individuals. Note that the directed links express
the probabilistic relationships while the undirected (bold)

edges express the constraints.
We consider the roads as a Graph G(V, E) where the vertices V correspond to intersections while the edges E correspond to segments of roads between intersections. The
variables in the model are as follows. The variables dt and
wt represent the information about time-of-day and dayof-week respectively. dt is a discrete variable and has four
values (morning, a f ternoon, evening, night) while the variable wt has two values (weekend, weekday). Variable gt
represents the persons next goal (e.g. his office, home etc).
We consider a location where the person spends significant
amount of time as a proxy for a goal [Liao et al., 2004].
These locations are determined through a preprocessing
step by noting the locations in which the dwell-time is
greater than a threshold (15 minutes). Once such locations
are determined, we cluster those that are in close proximity
to simplify the goal set. A goal can be thought of as a set of
edges E1 ⊂ E in our graph representation. The route level
rt represents the route taken by the person to move from
one goal to other. We arbitrarily set the number of values
it can take to |gt |2 . The person’s location lt and velocity
vt are estimated from GPS reading yt . ft is a counter (essentially goal duration) that governs goal switching. The
Location lt is represented in the form of a two-tuple (a, w)
where a = (s1 , s2 ),a ∈ E and s1 , s2 ∈ V is an edge of the
map G(V, E) and w is a Gaussian whose mean is equal to
the distance between the person’s current position on a and
one of the intersections in a.
The probabilistic dependencies in the model are straightforward and can be found by tracing the arrows (see Figure 3). The constraints in the model are as follows. We
assume that a person switches his goal from one time slice
to another when he is near a goal or moving away from a
goal but not when he is on a goal location. We also allow a forced switch of goals when a specified maximum
time that he is supposed to spend at a goal is reached. This
is modeled by using a constant D. These assumptions of
switching between goals is modeled using the following
constraints between the current location, the current goal,
the next goal and the switching counters: (1)If lt−1 = gt−1
and Ft−1 = 0 Then Ft = D, (2) If lt−1 = gt−1 and Ft−1 > 0
Then Ft = Ft−1 − 1, (3) If lt−1 6= gt−1 and Ft−1 = 0 Then
Ft = 0 and (4) If lt−1 6= gt−1 and Ft−1 > 0 Then Ft = 0, (5)
If Ft−1 > 0 and Ft = 0 Then gt is given by P(gt |gt−1 ), (6) If
Ft−1 = 0and Ft = 0 Then gt is same as gt−1 , (7) If Ft−1 > 0
and Ft > 0 gt is same as gt−1 and (8) If Ft−1 = 0 and Ft > 0
gt is given by P(gt |gt−1 ).

6 EXPERIMENTAL RESULTS
The test data consists of a log of GPS readings collected
by one of the authors. The test data was collected over
a six month period at intervals of 1-5 seconds each. The
data consist of the current time, date, location and veloc-

ity of the person’s travel. The location is given as latitude
and longitude pairs. The data was first divided into individual routes taken by the person and the HDMN model
was learned using the Monte Carlo version of the EM algorithm [Liao et al., 2004, Levine and Casella, 2001].
We used the first three months’ data as our training
set while the remaining data was used as a test set.
TIGER/Line files available from the US Census Bureau
formed the graph on which the data was snapped. As specified earlier our aim is two-fold: (a) Finding the destination
or goal of a person given the current location and (b) Finding the route taken by the person towards the destination or
goal.
To compare our inference and learning algorithms, we use
three HDMN models. Model-1 is the model shown in Figure 3. Model-2 is the model given in Figure 3 with the
variables wt and dt removed from each time-slice. Model3 is the base-model which tracks the person without any
high-level information and is constructed from Figure 3 by
removing the variables wt , dt , ft , gt and rt from each timeslice.
We used 4 inference algorithms. Since EM-learning uses
inference as a sub-step, we have 4 different learning algorithms. We call these algorithms as IJGP-S(1), IJGPS(2) and IJGP-RBPF(1,1,N) and IJGP-RBPF(1,2,N) respectively. Note that the algorithm IJGP-S(i) (described
in Section 3) uses i as the i-bound. IJGP-RBPF(i,w,N) (described in Section 4) uses i as the i-bound for IJGP(i), w as
the w-cutset bound and N is the number of particles at each
time slice. Three values of N were used: 100, 200 and 500.
For EM-learning, N was 500. Experiments were run on a
Pentium-4 2.4 GHz machine with 2G of RAM. Note that
for Model-1, we only use IJGP-RBPF(1,1) and IJGP(1)-S
because the maximum i-bound in this model is bounded by
1 (see section 3).
6.1 FINDING DESTINATION OR GOAL OF A
PERSON
The results for goal prediction with various combinations
of models, learning and inference algorithms are shown
in Tables 1, 2 and 3. We define prediction accuracy as
the number of goals predicted correctly. Learning was
performed offline. Our slowest learning algorithm based
on GBP-RBPF(1,2) used almost 5 days of CPU time for
Model-1, and almost 4 days for Model-2—significantly
less than the period over which the data was collected. The
column ’Time’ in Tables 1, 2 and 3 shows the time for inference algorithms in seconds while the other entries indicate
the accuracy for each combination of inference and learning algorithms.
In terms of which model yields the best accuracy, we can
see that Model-1 achieves the highest prediction accuracy

of 84% while Model-2 and Model-3 achieve prediction accuracies of 77% and 68% respectively or lower.
For Model-1, to verify which algorithm yields the best
learned model we see that IJGP-RBPF(1,2) and IJGP(2)S yield an accuracy of 83% and 81% respectively while
for Model-2, we see that the average accuracy of IJGPRBPF(1,2) and IJGP(2)-S was 76% and 75% respectively.
From these two results, we can see that IJGP-RBPF(1,2)
and IJGP(2)-S are the best performing learning algorithms.
For Model-1 and Model-2, to verify which algorithm yields
the best accuracy given a learned model, we see that
IJGP(2)-S is the most cost-effective alternative in terms
time versus accuracy while IJGP-RBPF yields the best accuracy.
Table 1: Goal-prediction: Model-1
N
100
100
200
200
500
500

Inference
IJGP-RBPF(1,1)
IJGP-RBPF(1,2)
IJGP-RBPF(1,1)
IJGP-RBPF(1,2)
IJGP-RBPF(1,1)
IJGP-RBPF(1,2)
IJGP(1)-S
IJGP(2)-S
Average

Time
12.3
15.8
33.2
60.3
123.4
200.12
9
34.3

LEARNING
IJGP-RBPF
IJGP-S
(1,1)
(1,2)
(1)
(2)
78
80
79
80
81
84
78
81
80
84
77
82
80
84
76
82
81
84
80
82
84
84
81
82
79
79
77
79
74
84
78
82
79.625
82.875
78.25
81.25

6.2 FINDING THE ROUTE TAKEN BY THE
PERSON
To see how our models predict a person’s route, we use
the following method. We first run our inference algorithm
on the learned model and predict the route that the person
is likely to take. We then super-impose this route on the
actual route taken by the person. We then count the number
of roads that were not taken by the person but were in the
predicted route i.e. the false positives, and also compute
the number of roads that were taken by the person but were
not in the actual route i.e. the false negatives. The two
measures are reported in Table 4 for the best performing
learning models in each category: viz GBP-RBPF(1,2) for
Model-1 and Model-2 and GBP-RBPF(1,1) for Model-3.
As we can see Model-1 and Model-2 have the best route
prediction accuracy (given by low false positives and false
negatives).

Table 3: Goal Prediction Model-3
N
100
200
500

Inference
IJGP-RBPF(1,1)
IJGP-RBPF(1,1)
IJGP-RBPF(1,1)
IJGP(1)-S
Average

Time
2.2
4.7
12.45
1.23

LEARNING
IJGP-RBPF(1,1)
IJGP(1)-S
68
61
67
64
68
63
66
62
67.25
62.5

7 RELATED WORK
[Liao et al., 2004] and [Patterson et al., 2003] describe a
model based on AHMEM [Bui, 2003] and Hierarchical
Markov Models (HMMs) respectively for inferring highlevel behavior from GPS-data. Our model goes beyond
their model by representing two new variables day-of-week
and time-of-day which improves the accuracy in our model
by about 6%.
A mixed network framework for representing deterministic and uncertain information was presented
in [Dechter and Larkin, 2001, Larkin and Dechter, 2003,
Dechter and Mateescu, 2004]. These previous works also
describe exact inference algorithms for mixed networks
with the restriction that all variables should be discrete.
Our work goes beyond these previous works in that we describe approximate inference algorithms for the mixed network framework, allow continuous Gaussian nodes with
certain restrictions in the mixed network framework and
model discrete-time stochastic processes. The approximate inference algorithms called IJGP(i) described in
[Dechter et al., 2002] handled only discrete variables. In
our work, we extend this algorithm to include Gaussian
variables and discrete constraints. We also develop a sequential version of this algorithm for dynamic models.
Particle Filtering is a very attractive research
area [Doucet et al., 2000]. Particle Filtering in HDMNs
can be inefficient if non-solutions of constraint portion
have high probability of being sampled. We show how
to alleviate this difficulty by performing IJGP(i) before
sampling. This algorithm IJGP-RBPF yields the best
performance in our settings and might prove to be useful
in applications in which particle filtering is preferred.

Table 2: Goal Prediction: Model-2
N
100
100
200
200
500
500

Inference
IJGP-RBPF(1,1)
IJGP-RBPF(1,2)
IJGP-RBPF(1,1)
IJGP-RBPF(1,2)
IJGP-RBPF(1,1)
IJGP-RBPF(1,2)
IJGP(1)-S
IJGP(2)-S
Average

Time
8.3
14.5
23.4
31.4
40.08
51.87
6.34
10.78

LEARNING
IJGP-RBPF
IJGP-S
(1,1)
(1,2)
(1)
(2)
73
73
71
73
76
76
71
75
76
77
71
75
76
77
71
76
76
77
71
76
76
77
71
76
71
73
71
74
76
76
72
76
75
75.75
71.125
75.125

Table 4: False positives (FP) and False negatives for routes
taken by a person (FN)
N

100
200
100
200

INFERENCE
IJGP(1)
IJGP(2)
IJGP-RBPF(1,1)
IJGP-RBPF(1,1)
IJGP-RBPF(1,2)
IJGP-RBPF(1,2)

Model1
FP/FN
33/23
31/17
33/21
33/21
32/22
31/22

Model2
FP/FN
39/34
39/33
39/33
39/33
42/33
38/33

Model3
FP/FN
60/55
60/54
58/43

8 CONCLUSION AND FUTURE WORK
In this paper, we introduced a new modeling framework
called HDMNs, a representation that handles discrete-timestochastic processes, deterministic and probabilistic information on both continuous and discrete variables in a systematic way. We also propose a GBP-based algorithm
called IJGP(i)-S for approximate inference in this framework. The main algorithmic contribution of this paper
is presenting a class of Rao-Blackwellised particle filtering algorithm, IJGP-RBPF for HDMNs which integrates
a generalized belief propagation component with a RaoBlackwellised Particle Filtering scheme for effective sampling in the presence of constraints. Another contribution
of this paper is addressing a complex and highly relevant
real life domain using a general framework and domain independent algorithms. Directions for future work include
relaxing the restrictions made on dependencies between
discrete and continuous variables and developing an efficient EM-algorithm.

ACKNOWLEDGEMENTS
The first and third author were supported in part by National Science Foundation under award numbers 0331707
and 0331690. The second-author was supported in part by
the NSF grant IIS-0412854.


