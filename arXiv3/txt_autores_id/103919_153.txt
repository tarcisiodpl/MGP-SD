

We investigate the value of extending the
completeness of a decision model along dif­
ferent dimensions of refinement. Specifically,
we analyze the expected value of quantita­
tive, conceptual, and structural refinement of
decision models. We illustrate the key dimen­
sions of refinement with examples. The anal­
yses of value of model refinement can be used
to focus the attention of an analyst or an au­
tomated reasoning system on extensions of a
decision model associated with the greatest
expected value.
1

Introduction

The quality of recommendations for action generated
by decision analyses hinges on the fidelity of deci­
sion models. Indeed, the task of framing a decision
problem-enumerating feasible actions, outcomes, un­
certainties, and preferences-lies at the heart of deci­
sion analysis. Decision models that are too small or
coarse may be blind to details that may have signif­
icant effects on a decision recommendation. Unfor­
tunately, the refinement of decision models can take
a great amount of time, and can be quite costly in
time and expense. In some cases, actions are taken
well before a natural stopping point is reached in the
modeling process. In other cases, important distinc­
tions about actions and outcomes are recognized days
or months after a model is developed.
We have developed methods for probing the value of
key dimensions of decision-model refinement. We pose
the techniques as tools that can direct the attention of
an analyst or of an automated reasoning system to re­
fine aspects of a decision model along dimensions that
have the highest expected payoff. The methods also
can provide guidance on when it is best to cease addi­
tional refinement and to take immediate action in the
world. Our work differs from previous studies of the
*Currently at the Department of Industrial & Systems
Engineering, National University of Singapore.

Eric J. Horvitz

Palo Alto Laboratory
Rockwell International Science Center
444 High Street, Palo Alto, CA 94301
value of modeling (Watson & Brown, 1978; Nickerson
& Boyd, 1980) in that we develop a unifying framework
for probing the values of different classes of refinement,
and consider issues surrounding the direction of model
building and improvement under resource constraints.
Three fundamental dimensions of decision-model re­
finement are (1) quantitative refinement, (2) concep­
tual refinement, and (3) structural refinement. We will
explore methods for making decisions about which di­
mensions to refine, and the amount of effort to expend
on each form of refinement.
Quantitative refinement is the allocation of effort to re­
fine the uncertainties and utilities in a decision model.
There are two classes of quantitative refinement: (1)
uncertainty refinement, and (2) preference refinement.
Uncertainty refinement is effort to increase the accu­
racy of probabilities in a decision model. For example,
assessment may be focused on the tightening of bounds
or second-order probabilities over probabilities in a de­
cision model. Preference refinement is refinement of
numerical values representing the utilities associated
with different outcomes. For example, an analyst may
work to refine his uncertainty about the value that a
decision maker will associate with an outcome that has
not been experienced by his client.
Conceptual refinement is the refinement of the seman­
tic content of one or more distinctions in a decision
model. With conceptual refinement, we seek to modify
the precision or detail with which actions, outcomes,
and related random variables are defined. For exam­
ple, for a decision m:1ker deliberating about whether
to locate a party inside his home versus outside on
the patio, it may be important to extend the distinc­
tion "rain" to capture qualitatively different types of
precipitation, using such conceptually distinct notions
as "drizzle," "intermittent showers," and "downpour."
Likewise, with additional deliberation, he may real­
ize that there are additional options available to him.
Many of these additional alternatives are those that
would not be taken if there were no uncertainty about
the weather. For example, he might consider having
the party on the porch, or renting a tent to shelter the
guests in his yard.

Value of Decision-Model Refinement

Structural refinement is modeling effort that leads
to the addition or deletion of conditioning variables
or dependencies in a decision model. For exam­
ple, a decision maker may discover that an expensive
telephone-based weather service gives extremely accu­
rate weather forecasts, and wish to include the results
of a query to the service in his decision analysis.
These classes of refinement represent distinct dimen­
sions of effort to enhance a decision model. In the next
sections, we will develop equations that describe the
expected value of continuing to refine a model for each
dimension of refinement.
2

Expected Values of Decision-Model
Refinement

Let us now formalize measures of the expected value
of refinement (EVR) 1. For any dimension of EVR, we
seek to characterize our current state of uncertainty
about the outcome of an expenditure of effort to re­
fine a decision model. Experienced decision analysts
often have strong intuitions about the expected bene­
fits of refining a decision model in different ways. This
knowledge is based on expertise, and is conditioned
on key observables about the history and state of the
modeling process. Assume that we assess and repre­
sent such knowledge in terms of probability distribu­
tions over the value of the best decision available fol­
lowing model refinement, conditioned on key modeling
contexts.
To compute the E V:I}, we first determine the expected
value associated with the set of possible models we cre­
ate after refinement. We sum together the expected
utility of the best decision recommended by each pos­
sible revised model, weighted by the likelihood of each
model. Finally, we subtract this revised expected value
from the expected value of the decision recommended
by the unrefined model.
2.1

General Analysis

the weather and A represents the decision on party lo­
cation. The expected value of taking action ak, given
background information e' is

The expected value of the decision offered by this de­
cision model is
E[vle] = mfCLP(xile)v(ak,xi)·

(2)

i

Suppose the decision model can be refined via one of
several refinement procedures R. In general, R can
be parameterized by amount of effort (e.g., as char­
acterized by time) expended on the refinement. We
shall simplify our presentation by initially overlooking
such a parameterization. Note that e represents the
state prior to any refinement consideration; R repre­
sents information about the refinement prior to actual
refinement. Let R(e) denote the state of information
after a refinement requiring some prespecified effort.
Let J-lk denote the expected utility that will be ob­
tained for action ak. Before the refinement is carried
out, the values of J-lk are unknown. However, we can
assess a probability distribution over each of the val­
ues, given information about R and e. We denote this
distribution as p(J-lkiR,e). The expected utility given
refinement R is

If we cease model-refinement activity, we commit
to an action in the world based on all information
available-including P(J-lkIR,e). The expected utility
without refinement is

The EVR is
=

],

J-lk P(J-lkiR,e).

(4)

E[viR(e)]- E[viR,e].

(5)

E[viR,e] = max
k

EVR( R)

Figure 1: A basic decision model

175

l'k

In practice, the values J-lk and distributions P(J-lkIR, e)
are dependent on the specific type of refinement and
the amount of effort allocated. We shall now describe
specific properties of the three types of model refine­
ment and give examples of the detailed analysis of
computing the EVR for each. In each case, we shall
show how each of the analyses is related to the general
formulation captured in Equation (5).

Consider the simple decision problem with a single
state variable X and a single decision variable A, as
shown in Figure 1. In the party problem, X represents

2.2

1 We shall use the EVR to refer generally to the expected
value of refinement, but shall use more specific terms to
refer to alternate classes of refinement.

We start with a consideration of the value of efforts to
refine quantitative measures of likelihoods and prefer­
ences.

Expected Value of Quantitative
Refinement

176

Poh and Horvitz

2.2.1

Uncertainty Refinement

Consider the quantitative refinement on the state vari­
able X of the party-location problem. What is the
value of "extending the conversation" through expend­
ing effort to refine the probability distribution p(XIe)
with additional assessment. Let us first consider the
general case where the distrioution p(XIe) is continu­
ous. Assume that a continuous distribution is char­
acterized or approximated by a named distribution
and a parameter or a vector of parameters. Specifi­
cally, assume a functional form f for the probability
density function, such that for every reasonable dis­
tribution p(XIe), there exists a parameter or a set
of parameters {3, so that the the numerical approxi­
mation p(XIe) � /p(X) is within satisfactory limits.
Before the assessment is carried out, we cannot be cer­
tain about the outcome distribution; however, its out­
come might be described by a distribution of the form
p(f31R,e), which represents the decision maker's un­
certainty about the primary distribution parameter {3.
The expected value of the refinement is

l.

/p(x)v(ak,x)] (6)
{ p(f31R,e)[max
k
J{j
The expected value without performing the quantita­
tive refinement but taking account of knowledge an
agent lias about the potential outcome of refinement
procedure R is
E[viR(e)] =

E[viR,e] =

where

X

l. }fp /p(x)p(f31R,e)v(ak,x)
max
(7)
p(xiR,e)v(ak,x)
k l.

max
k

f.,(x2) = 17r = 'ii'. The

Hence f is linear in 1r and therefore
expected value given that quantitative
refinement is performed is, E[viR(e)]
=

1 p(TriR,e)max[Trv(ak,x!) +(1-Tr)v(ak,x2)]. (8)
k

.,

The expected value without the refinement but with
knowledge about the potential performance of R is
E[viR,eJ = max [7rv(a k' x!) + (1- 'ii')v(ak' X2)]. (9)
k
The above analysis can be extended to the general case
where the state variable X has possible states. In
this case, f3 consists of n-1 parameters ( 1r1, . . . ,Trn-1)·
Our analysis of EVRQU (R) can be related to the gen­
eral formulation in Equation (5) by defining the vari­
able
n

(10)
J.lk =7rv(ak,x1) + (1-7r)v(ak,x2)
for each action ak E A. The distributions p(J.lkIR,e)
can be derived from p(TriR,e).

We shall illustrate the concept of quantitative refine­
ment with a example drawn from the party problem.
Consider the problem of selecting a location for the
party given uncertainty about the weather. Let the al­
ternatives for the location be "Outdoor" (at) and "In­
door" (a2), and let the weather conditions be "Rain"
(xl) or "Sunny" (a2). Let 1r denote the probability
that it will rain. The utility values are,

X

Outdoor
Indoor

X

fi(XIR,e) =

i fp(x)p(f31R,e)

is the operative distribution for the authentic distribu­
tion p(XIe) (Tani, 1978; Logan, 1985).
The operative distribution is the distribution which
the decision maker should use if no further assess­
ment is performed. Let {3 be the parameter that
best approximates the operative distribution p(XIe),
i.e., the numerical approximation fi(XIe) � fp(X)
is within satisfactory limits. This is different from
� = fp /3 p(f31R,e) which denotes the mean of the sec­
ondary distribution.
The expected value of quantitative refinement on the
uncertainty on X with respect to assessment procedure
R, denoted EVRQU (R) is the difference between (6)
and (7).
Let us consider the case where the state variable X
is discrete with two states { :e1, :e2}. We are interested
in the value of improving the probabilities assessed for
p(x1le) and p(x2le). We denote the assessed values
of p(x1le) and p(x2le) by 1r and 1 - 1r, respectively.
The parameter which describes the primary distribu­
tion over X is f3 = 1r, and we have f.,(xl) = 1r and

1r.

0.00
0.67

Sunny (1- 1r)
1.00
0.57

The optimal locations as a function of 1r are
a*(1r) =

Outdoor
{ Indoor

if 7r � 0.38
if 7r > 0.38

1
�

g
�

.57

Figure 2: The optimal party location as a function of
the probability of rain (1r)

Let us suppose that the current uncertainty about 1r
can be described by a probability distribution whose
mean is 0.4. In this case, the optimal decision, without
further assessment, is to hold the party indoors, with
an expected utility of 0.61. However, a more accurate
assessment of the value of 1r might change the optimal

Value of Decision-Model Refinement

decision resulting in a potentially higher utility. With
refinement,

1 p(1riR,e)v(a*(1r),1r)

E[viR(e)]=

where

1-?r
0.57 + O.l?r

v(a*(1r), 1r)={

if 7r � 0.38
if 7r > 0.38

.50 5(0.57 O.l1r)d1r- 0.61
!.3
8 o.o57r2U8 - o.61
5[0.5711"

+

+

Notice that the above analysis was performed in the 7r­
domain. An alternative analysis and perspective which
will produce equivalent results can be performed in the
p-domains. This is done by a change of variables from
1r to p1 and p2 via Equation (10) . The resulting anal­
ysis would have to be displayed as a two-dimensional
graph.
2.2.2

Outdoor
Indoor

+

U +
0.6324- 0.610 0.0224
=

Let us again use the party problem to illustrate the
value of refining preferences. Since we can fix the util­
ity for the worst outcome (outdoor and rain) at zero,
and the utility for the best outcome (outdoors and
sunny) at one, we need only to consider the uncer­
tainty over further assessment of the values <jJ21 (in­
door and rain), and <P22 (indoor and sunny). Let the
uncertainty over these values be:
U[0.62, 0.72)
</J21
<P22 = U [0.52, 0.62)
The operative values for the preference values are,
=

Consider the case where 1r is uniformly distributed be­
tween the interval [0.3,0.5) . The expected value of re­
finement, EVRQU (R) , is then,

.!3038 5(1 - 1r)d1r
5.[7r-o.57r2 8

177

Preference Refinement

Let us now consider the expected value of quantitative
refinement of preference EVRQP(R). We seek to im­
prove the values of v(ak,x;) for each k and i. Let <Pki
denote the value that will be assessed, given that the
refinement is carried out. Let p(</JkiiR,e) denote the
uncertainty over the assessment for each v(ak. Xi)· The
expected value, given that the quantitative refinement
on preference is carried out, is E[viR(e)]

lw·<l>mn p(</Ju,...,<Pmn IR,e)[mkax�p(xde)<Pki]·

Sunny (.6
1.00
0.57

eu
0.60
0.61

The default choice without any further assessment is
to hold the party indoors with an expected utility of
0.61.
/l1 = 0.60
Jl2 = 0.4<P21 + 0.6</J22
In the example, there is no uncertainty over p1. The
utility, Jl2, displayed in Figure 3, is a linear sum of
two uniformly distributed variables, with a triangular
distribution p(J.t21R,e),
if .56 � /l2 � .61
400(J.t2 - .56)
0 - 400(J.t2 - .61) if .61 � Jl2 � .66
=
otherwise
and an expected value of 0.61.

{�

=

( 11)
The expected value without quantitative refinement on
preference but with knowledge about the performance
of R is
( 12)
E[viR,e]=m:xi:>(x;le)�ki

Rain (.4
0.00
0.67

Figure 3: The pdf for p2
Figure ( 4) shows the optimal value p* = maxk Jlk
as function of Jl2, where Jl1 is fixed at 0.60. The
EVRQP(R) is

i

.60 400(J.t2 - 0.56)(0.6)dJ.t2
!. 6
/.56.061 [20 - 400(J.t2 - 0.61)](0.6)dJ.t2
.66 [20 - 400(J.t2 - 0.61)]J.t2dJ.t2- 0.61
!.61
0.63733- 0.610=0.02733
+

where

r <Pki p(<PkiIe)
1</>ki
is the operative utility value for v(ak,aki). The
EVRQP(R) is the difference between ( 11) and (12).
This analysis can be related to the general formula­
tion in Equation ( 5) by defining the variable
�ki=

(13)
for each action ak E A. The distributions p(J.tkIR,e)
can be derived from the distributions p(<Pk;IR,e) .

+

=

2.3

Expected Value of Conceptual
Refinement

We shall now explore measures of the value of con­
ceptual refinement: ( 1) the value of refinement of the

178

Poh and Horvitz

The expected value given that the refinement is not
carried out, but with knowledge about the perfor­
mance of R is E[viR, e]

J.l.*
.66
.60

�'5[p(xule)¢k1 + p(x12le)<fok2 +

=

.56

.60

.66

definitions of state variables, EVRc8(R) and (2) the
refinement of definitions of actions, EVRCA(R).
2.3.1

Assume that our current decision model has a state
variable X
{ x1,x2} and decisions A
{a1,a 2}.
Now, let us consider the value of refining the state
x1 into x u and x12, such that the resulting state vari­
able is X' {xu,X12,x2}. We further assume that
the probability of the refined states p(xulx1,e) and
p(:r:12\x1,{) are known. As a result of the refinement,
we need to assess the utilities v(ak,x1i) for k 1, 2
and j 1, 2. Before these assessments are carried out,
the values v(ak, Xlj) are unknown. Let </lkj represent
the utilities (ak,x1i) that will be assessed if the as­
sessment is performed. In addition, we assume that
the decision maker is able to assess a set of probability
distributions p(¢ki IR,e), k 1,2 and j 1, 2 over
these utilities.
To assess the probabilities over the utilities, a possi­
ble conversation between the analyst and the decision
maker might be as follows:
=

=

=

=

p(xule)¢kl + p(x121e)¢k2 + p(x2ie)v(ak, x2), (16)
for action ak, k = 1,2 and deriving the distributions
P(J-!k I R,e) from the distributions p(¢kjiR, e).

To illustrate conceptual refinement, consider the ex­
pansion of the state of "Rain" into "Downpour" and
"Drizzle". Assume that a decision maker's assessment
of his uncertainty over the values of ¢12 (outdoor and
drizzle), </121 (indoor and downpour) , and ¢22 (indoor
and drizzle) are as follows:
v(¢12\ R,e)
vC<P21IR,e)
p(<J!22IR,e)

v

=

=

=

State-Variable Refinement

=

(15)
= 1,2)

1,2 and j
where <foki
is the operative value to be used when no refinement is
carried out. The EVRc8(R) for refining state variable
X to X' is just the difference between (14) and (15).
As before, we can simplify this analysis and relate it
to the general formulation of Equation (5) by defining
the variable J-lk
=

Figure 4: The optimal value JJ* as a function of jJ2

p(x2i{)v(ak,x2)]
Jrf>ki ¢ki p(¢kjl{), (k

=

In our previous conversation, you assigned a
utility u for outcomes at your point of in­
difference between an outcome and a lottery
with probability u for the best prospect and
probability 1- u for the worst prospect. Sup­
pose I were to ask you to assess the utility of
each of the refined outcomes. As we do not
have an unlimited amount of time to assess
these utilities, please give us an estimate now
of the probabilities describing the utility val­
ues assessed if you were to have enough time
to thoroughly reflect on your preferences and
2
knowledge about the outcomes.

The expected value resulting from the conceptual re­
finement of X to X' is E[vjR(e)]

f
p(¢u, </112, </121,¢n\R,e)
}</>u </>I2<!>21 </>22
(14)
�t1 [p(xule)¢k1+ p(xde)¢k2 +
p(x2le)v(ak,x2)] .

-----

2We could also perform this assessment in terms of
the utilities that would be assessed after some predefined
amount of time for reflection.

U[0.05,0.15)
U[0.67, 0.77]
U[0.57, 0.67)

=
=

The operative utilities are as follows:

Outdoor
Indoor

Rain (.4)
Down- Dnzzle
pour (.2)
(.2)
0.00
0.72

0.10
0.62

Sunny
(.6)
1.00
0.57

EV
0.62
0.61

Without refinement, the expected utility of holding
the party outdoors is 0.62 and the utility of having
the party indoors is 0.61. Since the two expected val­
ues are very close, further refinement might lead to
a better discrimination between the two choices. In
lieu of additional refinement, the default decision is to
have the party outdoors. Based on the distributions
over ¢ki, we define
J-1 1

J-12

=
=

0.2¢12 + 0.6
0.2¢21 + 0.2¢22 + 0.342

f-ll is uniformly distributed between 0.61 and
i.e. P(J.LI\R,e) U[0.61, 0.63), while JJ2 has a
triangular distribution p(JJ21R,e) (depicted in Figure

where
0.63,

5),

=

=

{

2500(J-!2- .59)
50- 2500(JJ2- .61)
0

if .59 � J-12 � .61
if .61 � /J2 � .63
otherwise.

Figure (6) shows the region over possible values of J-11
and J-12· The EVRc8(R) is
=

!.63 50 [1.61 2500(JJ2- 0.59)J-!1dJ.l2+
.61

.59

Value of Decision-Model Refinement

179

The expected value without the conceptual refinement
on action is,
E [vJR,e] =

where
Uki =
_

Figure 5: The pdf for J.l2

jill (50-2500(J.l2
.61

-

0.61) ] J.l1dJ.l2 +

Jir6a
ll (50- 2500(J.l2- 0.61)] J.l2dJ.l2] dJ.l1

-0.620 = 0.9208-0.620 = 0.3008
. 63

.61

....,

.59 _ .....,_

__

.61

llt

2.3.2

�

i1

=

...

q,n

p(¢1, ... ,¢n lR, e) [ Tt�;,
a
k

where
Uki =

{ v(a
k,x;)
1/Ji

� p(xde)uki]

(17)

if k = 1,2
if k=3.

ifk=1,2

if k=3.

The EVRCA(R) for refining action A to A' is then the
difference between (17) and (18). We can relate these
results to the general formulation of Equation (5) by
defining the variable
(19)

for each action ak. Note that J.l1 and J.l2 are determin­
istic, while the probability distribution p(J.laJR,e) can
be derived from the distributions p( ¢; IR, e) .
Let us consider the refinement of the example prob­
lem with the addition of a third action which-to hold
the party on the porch (aa). To complete the refine­
ment, we must assess the utility values ¢1 (porch and
downpour), ¢2 (porch and drizzle), and ¢a (porch and
sunny). For simplicity, we will assume that the deci­
sion maker is certain about the value of ¢a, which is
0.81. His uncertainty over ¢1 and ¢2 are
U(0.17,0.27]
U(0.37,0.47]

The operative utilities are as follows:

Action Refinement

Similar to extending the conversation about the def­
inition of states, the set of decision alternatives may
be increased with continuing modeling effort. Con­
sider the conceptual refinement of action A={ a , a2 }
by the addition of action aa. Let A' = { a1, a2,aa}.
Unlike state variable refinement, the set of refined ac­
tions need not be mutually exclusive. Indeed, they
need not even be mutually exhaustive as some alterna­
tives can be ruled out immediately, based on common
sense knowledge or dominance relationships (Wellman,
1988). As the result of action refinement we need to
assess the utilities v(aa,x;) for all x; E X. Let ¢; de­
notes the utility v(aa,x;) for each i, and let p(¢;JR, e)
be the uncertainty over each assessment. The expected
value offered by the refined model is E[vlR(�)]

.
a

{ ¢;UJtt=v(ak,Xi)

.63

Figure 6: The region of values for J.l1 and J.l2 where
J.l* =maxk J.lk

(18)

max L:p(x;Je)uki

k= 1, 2, a

Outdoor
Indoor
Porch

Rain .4)
Down- Dnzzle Sunny
pour (.2)
(.2)
(.6)
0
.72
.22

.10
.62
.42

1
.57
.81

EV
.620
.610
.614

The optimal action without further refinement is to
hold the party outdoors, with an expected utility of
0.62.

J.l1
J.l2
J.la

0.62
0.61
0.2¢t + 0.2¢2 + 0.6¢a

There is no uncertainty on J.lt and J.l2· However, as dis­
played in Figure 7, J.la is a linear sum of two uniformly
distributed variable and has a triangular distribution
of the form, p(J.laJR,e),
=

{�

400(J.la -.564)
0- 400(J.la .614)
-

if .564 � J.la � .614
if .614 � J.l2 � .664
otherwise

and has an expected value of 0.614.

180

Poh and Horvitz

a parameter f3y, such that the numerical approxima­
tion p(Y IR(e)) � f{3y (Y) is within satisfactory limits.
We let Px1Y represent the parameter for the distri­
bution p(XIY,R(e)). Let the distributions p(,By IR,e)
and p(,BYIX IR,e) represent the decision maker's un­
certainty about the parameters ,By and Pxw, respec­
tively. The expected value that results from the struc­
tural refinement via the addition ofY as a conditioning
variable for X, is E[v iR(e)

Figure 7: The ·pdf for J..L2

=

Figure (8) shows the optimal value J.L* = max,�: J.lk as
a function of J..La. The expected value of conceptual
refinement via addition of the third alternative is

1.614
.1.564620 400(J..La - 0.564)(0.62)dJ..La
.1.614664[20- 400(J..La- 0.614)](0.62)dJ..La
400(J..La- 0.614)]J..LadJ..La - 0.62
.0.62568620 [20-0.62
= 0.00568
+

[ 1

�

.620

Figure 8: The optimal value J.L* as a function of J..La
2.4

Expected Value of Structural Refinement

Figure 9: Structural refinement on node X
Finally, we consider the value of structural refine­
ment, EVR8(R), the value of increasing the number
of conditioning variables. Figure 9 depicts an exten­
sion of conversation based on structural refinement
of the state variable X of our simple decision prob­
lem by the addition of Y as a conditioning event for
X. For example, in the party problem, we may iden­
tify "wind speed" as a conditioning variable on the
forthcoming weather. We are interested in analyzing
the additional value that is gained by the addition
of Y as a conditioning variable for X. This struc­
tural refinement requires the assessment of the prob­
ability distributions p(YIR(e)) and p(XjY, R(e)). As
before, we assume a functional form f where, for ev­
ery reasonable distribution for p(YIR(e)) , there exists

1

]

The expected value without structural refinement is

f f� Y (y) Jxf f�XIY(x)v(a.�:,x), (21)
E [ v lR, e] =max
k }y

+

.664

f p(,ByjR,e) f P(PYixlR,e)
Jf3y
Jf3YIX
m;x /{1y(y) /(1xiY(x)v(a,�:,x) . (20)

where /Jy and Px!Y are the parameters for the opera­
tive distributions
fi(YIR,e)

=

f (jy (Y)p(pyIR,e) � ��y (Y)
J(jy /

and

f fr3y(X)p(Pxw IR,e)� f�XIY(X)
jf3xiY
respectively. The EVR5(R) for the variable X, with
respect to adding a new conditioning event Y , is just
the difference between (20) and (21). The case where
X and Y are discrete variables is treated in (Poh &
Horvitz, 1992).
A special form of structural refinement is the famil­
iar expected value of information (EVI). Within the
influence diagram representation, we can view the ob­
servation of evidence as the addition of arcs between
chance nodes and decisions. We describe the relation­
ship of EVI and other dimensions of model refinement
in (Poh & Horvitz, 1992).
p(XjY, R,e)=

3

Control of Refinement

Measures of EVR, computed from a knowledge base of
probabilistic expertise about the progress of model re­
finement, hold promise for providing guidance in con­
trolling decision modeling in consultation settings, as
well as within automated decision systems. In this sec­
tion, consider control techniques for making decisions
about the refinement of decision models.
3.1

Net Expected Value of Refinement

So far, we have considered only the value of alternative
forms of effort to expending effort to refine a model.
To consider the use of EVR measures, we must balance
the expected benefits of model refinement with (1) the
cost of the assessment effort, and (2) the increased

Value of Decision-Model Refinement

computational cost of solving more refined, and po­
tentially more complex, decision models. We define
the the net expected value of refinement, NEVR, as
the difference between the EVR and the cost of mak­
ing a refinement and increase in the cost of solving the
refined model. That is NEVR(R, t)
(22)
EVR[(R(t)), <J- Ca(ta) - Cc(b.(tc ))
where R(t) is a refinement parameterized by the time
expended on a particular refinement procedure, Ca is a
function converting assessment time, ta to cost, and Cc
is a function converting changes in the expected com­
putational time, required to solve the decision prob­
lem, b.(tc), to cost. In offline, consultation settings,
we can typically assume that changes in computational
costs, associated with the solving decision models of in­
creasingly complexity, are insignificant compared with
the costs of assessment. We can introduce uncertainty
into the costs functions with ease.
=

3.2

Decisions about Alternative Refinements

Let us assume that we wish to identify the best refine­
ment procedure to extend a decision model. For now,
let us assume that we have deterministic knowledge
about the cost of refinements. We shall assume that
the cost is a deterministic function of time3 and that
computational changes with refinement are insignifi­
cant.
We can control model building with a strategic op­
timization (Horvitz, 1990) that seeks to identify the
best refinement procedure and the amount of effort to
allocate to that procedure, i.e.,
(23)
arg maxEVR
[( R(t)), <J- C(t)
R,t
Given appropriate knowledge about decision model re­
finement, we solve such a maximization problem by
computing the ideal amount of effort to expend for
each available refinement methodology, choose the pro­
cedure R* with the greatest NEVR, and apply it for
the ideal amount of time, t* computed from the max­
imization. We halt refinement when all procedures
have NEVR(R, t) < 0 for all times t.
However, we need not be limited to considering single
procedures. In a more general analysis, we allow for
the interleaving of arbitrary sequences of refinement
procedures, where each refinement procedure can be
allocated an arbitrary amount of effort, and to con­
sider sequences of refinements with the greatest ex­
pected value. As any refinement changes a model, and,
thus, changes the value of refinement for future model­
ing efforts, the identification of a theoretically optimal
sequence requires a combinatorial search through all
possibilities. Let us consider several approximations

181

A practical approach to dodging the combinatorial
control problem is to consider predefined quantities of
effort, and to employ a myopic or greedy EVR control
procedure. With a greedy assumption, we simplify our
analysis of control strategies by making the typically
invalid assumption that we will halt modeling, solve
the decision model, and take an action following a sin­
gle expenditure of modeling effort. We can further sim­
plify such a myopic analysis by assuming a predefined,
constant amount of effort to employ in NEVR anal­
yses. We compute the EVR(R(T)) for all available
refinement procedures R, where T is some constant
amount of time, or a quantity of time TR T(R), a
constant amount of time keyed to specific procedures.
At each cycle, we compute the NEVR for all proce­
dures, and implement the refinement procedure with
the greatest NEVR. We iteratively repeat this greedy
analysis until the cost of all procedures is greater than
the benefit, at which time we solve the decision prob­
lem and take the recommended action. Figure (10)
shows a fragment of the graph of possible model re­
finement steps.
=

�
\

I

'

,

...

...

\

: quantitative

�-"'

\structural

J ..... .
,

\

; quantitative

�-"'

/
I'

structural

,

\

\

conceptual

�

� ...
-,
9 , ... ,
o--.o �_) o--.o �_)
,

1

,

� �

quantitative

1 ,

��

...

quantitative

Figure 10: Greedy control of model refinement with
iterative application of NEVR analyses
We can relax the myopia of the greedy analysis by al­
lowing varying amounts of lookahead. For example,
we can consider the NEVR of two refinement steps.
Such lookahead can be invoked when single steps yield
a negative NEVR for all refinement methods. We can
also make use of theoretical dominance results. For ex­
ample, we have shown in a more comprehensive paper
that the expected value of perfect information (EVPI)
is the upper bound on the value of any structural re­
finement (Poh & Horvitz, 1992).

to such an exhaustive search.

31n practice, a decision consultant may wish to consider
such multiattribute cost models as the cost in time, dollars,
and frustration associated with pursuit of different kinds
of assessments and refinements.

4

Discussion and Related Work

The value of the EVR methods hinges on the avail­
ability of probability distributions that describe the

182

Poh and Horvitz

outcomes of extending models in different ways. We
suspect that expert analysts rely on such probabilis­
tic modeling metaknowledge, and that relatively stable
probability distributions can be assessed for prototyp­
ical contexts and states of model completeness. We do
not necessarily have to rely on assessing an expert deci­
sion analyst's probability distributions about alterna­
tive outcomes of modeling. In an automated decision
support setting, we can collect statistics about model­
ing and modeling outcomes. Such data collection can
be especially useful for the application of EVR-based
control strategies to automated reasoning systems that
construct models dynamically (Breese, 1987; Goldman
& Breese, 1992).
We are not the first to explore the value of modeling
in decision analysis. The value of modeling was first
addressed by Watson and Brown (1978) and Nickerson
and Boyd (1980). The notion of reasoning about the
value of probability assessment with an explicit consid­
eration of how second-order distributions change with
assessment effort has been explored rigously by Lo­
gan (1985). Chang and Fung (1990) have considered
the problem of dynamically refining and coarsening of
state variables in Bayesian networks. They specified
a set of constraints that must be satisfied to ·ensure
that the coarsening and weakening operations do not
affect variables that are not involved. In particular,
the joint distribution of the Markov blanket excluding
the state variable itself must be preserved. However,
the value and cost of performing such operations were
not addressed. The form of refinement that we re­
fer to as structural refinement has also been examined
by Heckerman and Jimison (1987) in their work on
attention focusing in knowledge acquisition. Finally,
related work on control of reasoning and rational deci­
sion making under resource constraints, using analyses
of the expected value of computation and considering
decisions about the use of alternative strategies and al­
locations of effort, has been explored by Horvitz (1987,
1990) and Russell and Wefald (1989).
5

Summary and Conclusions

We introduced and distinguished the expected value of
quantitative, conceptual, and structural refinement of
decision models. We believe that the analyses of the
value of model refinement hold promise for controlling
the attention of decisions makers, and of automated
reasoning systems, on the best means of extending a
decision model. Such methods can also be employed
to determine when it is best to halt refinement proce­
dures and instead to solve a decision model to identify
a best action. We look forward to assessing expert
knowledge about the value of decision-model refine­
ment and testing these ideas in real decision analyses.
We are striving to automate the assessment of knowl­
edge about model refinement, as well as the iterative
cycle of EVR computation. We are implementing key
ideas described in this paper within the IDEAL influ-

ence diagram environment (Srinivas & Breese, 1990).
Reference

Breese, J. S. (1987).

Knowledge Representation and
Inference in Intelligent Decision Systems. Ph.D.

thesis, Department of EES, Stanford University.
Chang, K.-C., & Fung, R. (1990). Refinement and
coarsening of bayesian networks. In Proceedings
of the Sixth Conference on Uncertainty in Arti­
ficial Intelligence, pp. 475-482.

Goldman, R. P., & Breese, J. S. (1992). Integrating
model constrution and evaluation. In Proceed­
ings of the Eighth Conference on Uncertainty in
Artificial Intelligence, pp. 104-111.

Heckerman, D. E., & Jimison, H. (1987). A perspective
on confidence and its use in focusing attention
during knowledge acquistion. In Proceedings of
the Third Workshop on Uncertainty in Artificial
Intelligence, pp. 123-131.

Horvitz, E. J. (1987). Reasoning about beliefs and ac­
tions under computational resource constraints.
In Proceedings of the Third Workshop on Uncer­
tainty in Artificial Intelligence, pp. 429-439.
Horvitz, E. J. (1990). Computation and action under
bounded resources. Ph.D. thesis, Depts of Com­
puter Science and Medicine, Stanford University.
Logan, D. M. (1985). The Value of Probability Assess­
ment. Ph.D. thesis, Department of Engineering­
Economic Systems, Stanford University.
Nickerson, R. C., & Boyd, D. W. (1980). The use and
value of models in decision analysis. Operations
Research, 28(1), 139-155.
Poh, K. L., & Horvitz, E. J. (1992). Probing the
value of decision-model refinement. Technical
Report 85, Palo Alto Laboratory, Rockwell In­
ternational Science Center, Palo Alto, CA.
Russell, S., & Wefald, E. (1989). Principles of metar­
easoning. In Brachman, R. J., Levesque, H. J.,
& Reiter, R. (Eds. ) , KR'89, Proceedings of the
F irst International Conference on Principles of
Knowledge Representation and Reasoning, pp.

400-411 Morgan Kaufmann.
Srinivas, S., & Breese, J. (1990). IDEAL: A software
package for analysis of influence diagrams. In
Proceedings of the Sixth Conference on Uncer­
tainty in Artificial Intelligence.

Tani, S. N. (1978). A perspective on modeling in de­
cision analysis. Mangt Sci, 24(14), 1500-1506.
Watson, S. R., & Brown, R. V. (1978). The valua­
tion of decision analysis. Journal of the Royal
Statistical Society, 141 (Part 1) , 69-78.
Wellman, M. P. (1988). Formulation of tradeoffs in
planning under uncertainty. Ph.D. thesis, De­
partment of EECS, MIT.




Probabilistic conceptual network is a knowl­
edge representation scheme designed for
reasoning about concepts and categorical
abstractions in utility-based categorization.
The scheme combines the formalisms of ab­
straction and inheritance hierarchies from
artificial intelligence, and probabilistic net­
works from decision analysis. It provides
a common framework for representing con­
ceptual knowledge, hierarchical knowledge,
and uncertainty. It facilitates dynamic con­
struction of categorization decision models at
varying levels of abstraction. The scheme is
applied to an automated machining problem
for reasoning about the state of the machine
at varying levels of abstraction in support
of actions for maintaining competitiveness of
the plant.

Figure 1: Using a pc-net in utility-based categorization
1

Introduction

A probabilistic conceptual network (pc-net) is a
knowledge representation scheme designed to support
utility-based categorization ( Poh, 1993). In contrast
to the traditional approaches which are logic and
similarity-based ( Smith & Medin, 1981), utility-based
categorization considers the usefulness of the infor­
mation conveyed by the concepts, the actional con­
sequences, the desirability of the consequences of ac­
tions, the computational or cognitive resource require­
ment and availability, and the uncertainty about the
environment.

limited observations. It must conceptualizes the sit­
uation and decide on the most appropriate course of
action. It does so by solving a categorization decision­
model. However, different models at different lev­
els of categorical abstraction can be used. Each of
these models has different expected value of the recom­
mended action and different computational resource
requirement. The agent must therefore decide on the
best level of abstraction to construct the model so as to
achieve the best trade off between the expected value
of the recommended action and cost of computation.

We have developed a decision-theoretic approach for
utility-based categorical reasoning as shown in Figure
1, in contrast to previous work on abstraction in prob­
abilistic reasoning ( Horvitz, Heckerman, Ng, & Nath­
wani, 1989; Horvtiz & Klein, 1992) which were more
narrowly focused. In our view, a resource-constrained
agent operating in an uncertain world is given a set of

A probabilistic representation of conceptual categories
called a pc-net is used to represent the agent's knowl­
edge about the world. A level of conceptual abstraction
for a building a model is obtained by selecting a con­
ceptual cover from the pc-net. As illustrated in Figure
1, a conceptual cover is obtained by selecting a set of
mutually exclusive and exhaustive concepts from dif­
ferent levels in the pc-net1

• Also at Dept. of Industrial & Systems Engineering, N a­
tiona} University of Singapore, Kent Ridge, Singapore 0511

1

The notion of conceptual coverage in abstraction hier-

Probabilistic Conceptual Network

We have developed an incremental algorithm whereby
the reasoner iteratively specializes or generalizes the
conceptual cover. A concept is specialized by breaking
it up into a set of more specific subconcepts. A group
of concepts may be generalized by replacing them with
a single super-concept. At each iteration, changes are
made in order to achieve the highest expected im­
provement in overall utility (Poh, 1993). The proce­
dure applies the principles of decision-theoretic control
(Horvitz, 1987, 1990; Fehling & Breese, 1987; Russell
& Wefald, 1991) to iteratively decide between alloca­
tion of additional resources to refine the current set
of concepts, or to act immediately based on the cur­
rent action recommended by the model. This model
refinement approach is a special application of a more
general approach for refining general decision models
(Poh & Horvitz, 1993).
In this paper, we describe probabilistic conceptual net­
works and show how they may be used to repre­
sent both categorical and uncertain knowledge and
to facilitate the dynamic construction of categoriza­
tion decision models at varying levels of abstraction.
We present an example from automated machining.
We also compare our scheme with similarity net­
works (Heckerman, 1991) and other approaches to
knowledge-based decision model construction.
2

Integrating Uncertainty and
Categorical Knowledge

To perform utilitY.-based categorization, an intelligent
actor must expres; different dimensions or perspectives
of knowledge. First, she must be able to express cat­
egorical knowledge with some degree of modularity.
Categorical knowledge expresses facts about individ­
ual concepts in a given domain, i.e., it describes the
features and properties that characterize the concepts.
Second, the actor must represent categorical relations,
e.g, how one concept subsumes others. In particular,
the actor, when problem-solving, must decide which
concepts to use and at which levels of abstraction in
order to obtain a useful solution.
In artificial intelligence, abstraction hierarchies and
semantics nets (Lehmann, 1992) are graph-based for­
malisms that have been advocated for computer rep­
resentation of concepts and categorical knowledge.
They organize conceptual knowledge in levels of ab­
straction and make use of "inheritance" mechanisms
whereby concepts may share features and properties
with higher-level ones. Since feature information need
only be stored at the highest possible level of abstrac­
tion, maximum elegance and economy of storage is
achieved. These formalisms, however, are not easily
amenable to representing uncertainty in an elegant and
efficient manner.
In reasoning and decision making under uncertainty,
archies arose in discussions with Eric Horvitz.

167

specialized graph-based formalisms like influence di­
agrams (Howard & Matheson, 1981) have been ad­
vocated for computer representation of probabilistic
knowledge and decision models. These formalisms fo­
cus on the dependencies among the probabilistic vari­
ables. They encode probabilistic models as directed
graphs with the nodes representing the uncertain vari­
ables and the directed arcs denote possible probabilis­
tic dependence between variables. Each node encodes
a conditional probability distribution of that node's
variable given each combination of values of its direct
predecessors nodes. Various techniques have been de­
veloped over the last decade for probabilistic inference
and reasoning using this representation; see for exam­
ple Pearl (1988).
Pc-nets combine the formalisms of influence diagrams
with inheritance hierarchies by representing concepts
with influence diagrams and then linking these con­
ceptual diagrams in a hierarchy. By do so, pc-nets are
able to capture the best features of both formalisms
and to use them effectively in support of utility-based
categorization.
3

An Application

m

Automated

Machining

We will illustrate the use of pc-nets in utility-based
categorization with a real-world example of an auto­
mated machining problem. This is similar to an appli­
cation described by Agogino and Ramamurthi (1990).
Unattended or automated machining operations are
important parts of any intelligent manufacturing sys­
tem. It requires the automation of the human op­
erator's efforts to monitor and make appropriate ad­
justments to the state of the machine. An automated
machining system typically has sensors which acquire
data on (1) dimensions of the workpiece, (2) acous­
tic emission from the machining processes, (3) cutting
forces (dynamometer readings), and (4) electric cur­
rent (ammeter), etc. These data are then used to
determine the state of the machine and appropriate
action or actions are taken to ensure the continuous
operation of the plant so as to minimize production
cost, thereby maintaining competitiveness. The possi­
ble states of the machining process at various level of
abstraction are illustrated in Figure 2.
At the most abstract level, the state of the machin­
ing process is either "within variability limits" or "out
of variability limits." Refining the concept "out of
variability limits" are "tool failure," "sensor failure"
and "transient state." The latter occurs during entry
or exit of the cutting tool into the workpiece. Re­
fining "tool failure" are "tool chatter" which is typi­
cally characterized by an event in which an acoustic
emission signal increases dramatically in amplitude as
does the frequency content of the dynamometer. If left
unchecked, tool chatter can result in tool, workpiece or
machine damage. Remedies for this problem include

Poh and Fehling

168

Probabilistic Conceptual Network

4
4.1

--------

----

"'

oo

/ t "-, ,
I

'

�

t
l
t l
tool
wear chatter breakage
I

I

tf �

:

...

...

...

...

.......
.
.

I

tooi
failure
I
I

A

,

"

'

fiR��
., � 't-,'

_
_

I
I

...... ...

- ... ...

��

tr
'

,

'

acoustic dynamo'
ammeter
sensor
meter

I
I

I

;1

nt

�-

tool
entry

'

',

tOQl
eXIt

'
'

rl

ve cal ho zontal
chatter
cnatter

rti

Figure 2: Hierarchy for states of a machine
reducing the depth of cut or reducing the feed rate.
"Tool wear" is typically characterized by a gradual in­
crease in acoustic emissions, and by a gradual increase
in cutting force as measured by the dynamometer. A
tool that is worn out needs to be re-sharpened or re­
placed in order to achieve the desired surface finish
and dimensional tolerances. "Tool breakage" is typi­
cally characterized by an acoustic emission exhibiting
a hig� amplitude peak at the moment of tool fracture,
and followed by a sharp drop in signal amplitude to a
level below that of normal. It is also characterized by
a large rise in cutting forces, followed by a drop before
finally continuing at a value above the average. Tools
that are broken cannot perform any machining task
and must be replaced immediately.
This problem is interesting because under differing op­
erating conditions and situations, different levels of
abstraction in monitoring and reasoning may be de­
sired. For example, if the tool has been changed re­
cently, giving it a low prior probability that it will
fail soon, it may be more worthwhile to only moni­
tor at a more general level, i.e., "tool failure," "sensor
failure" and "transient state," rather than spent ex­
tra resources to differentiate the finer details. In other
words, the expected value of the information derived
from using more detailed concepts may not justify the
required additional computational resources. On the
other hand, if the tool has already been in used for
a long time, then it might be worth the extra effort
spent in monitoring and reasoning with more detailed
concepts, like for example at the level of "tool chat­
ter," "tool wear," "tool breakage," "sensor failure" and
"transient state." Also if the material currently being
machined is a difficult one, e.g., a high-carbon steel,
which is known to have caused occasional tool break­
age, then it may also be worthwhile to monitor at a
deeper level of detail. In another possible scenario,
suppose the some critical sensors are out of order, then
the only level of detail available might be at the most
abstract level whereby only two possible states are be­
ing monitored. The operator would then need to be
alerted to take any corrective action.

Definitions

A probabilistic conceptual network (pc-net) consists of
a probabilistic concept hierarchy (pc-hierarchy) con­
necting a set of probabilistic concept diagrams (pc­
diagrams).
Each node in the pc-hierarchy repre­
sents a concept, and the links in the hierarchy spec­
ify subsumption relations among the concepts thereby
organizing the concepts at various level of abstrac­
tion or specificity. Associated with each subsumption
link is a value indicating the conditional probability
that a concept holds given that its immediate super­
concept holds. Individually, each concept within the
pc-hierarchy is represented by a pc-diagram. We may
visualize a pc-net as a hierarchical organization of pc
diagrams.
A pc-diagram for a concept is a special probabilistic
influence diagram {pid) 2 representing the knowledge
about the probabilistic relations between the concept
and the features that characterize it. The concept is
represented as a deterministic node while the features
are represented by chance nodes. As a convention, we
direct arcs by default, from the concept to its feature
nodes. For each feature node F in the pc-diagram for
concept ck, we store a probability distribution of the
form
k
p(FICk, B (F))
where Bk {F) is the set of conditional predecessors
(possibly empty ) that excludes Ck. We shall assume
that background information e is used in all the prob­
ability distributions. We represent Ck as a determin­
istic node because we do not need the distribution
p(Fj--.Ck, Bk(F)). A pc-diagram for a concept pro­
vides information for discriminating that concept from
other concepts in a domain. Pc-diagrams allow knowl­
edge to be represented locally providing modularity in
the knowledge-base.
The value of a pc-net emanates from its ability to sup­
port utility-based categorization. As shown previously
in Figure 1, given a pc-net together, a conceptual cover
can be selected at some level of abstraction to con­
struct a categorization decision model corresponding
to that level of abstraction. We shall describe the pro­
cedures for model construction in Section 5.
Finally, pc-net uses an inheritance mechanism whereby
a concept may share information about features from
a concept higher up the hierarchy. It does so by tak­
ing advantage of a form of conditional independence
called subconcept independence3 which is not conve­
niently represented in ordinary influence diagram rep­
resentation. A feature is said to be subconcept inde­
pendent of a concept if knowledge about the feature
2 A pid is an influence diagram with only probabilistic
nodes and conditioning arcs.

3Section 6.1 compares subconcept independence with
"subset-independence" in similarity networks.

Probabilistic Conceptual Network

Feature

Description

AE-mag

acoustic emission magnitude

AAE-mag

change in acoustic emission magnitude

AE-freq

acoustic emission frequency

dyn-freq-x

cutting force frequency in x-direction

dyn-freq-y

cutting force frequency in y-direction

AE-mean

mean of the acoustic signal
change in the mean of the acoustic signal

AAE-mean
dyn-rms-x

cutting force in the x-direction

Adyn-rms-x

change in cutting force in the x-direction

dyn-rms-y

cutting force in the y-direction

Adyn-rms-y

change in cutting force in the y-direction

AE-peak

acoustic emission peak value

dyn-peak-x

peak cutting force in x-direction

dyn-peak-y

peak cutting force in y-direction

current

motor current

Table 1: Descriptions of features
does not affect the agent's belief about any of that
concept's subconcept. We will have more to say about
subconcept-independence in Section 4.5.
4.2

Automated Manufacturing Example

169

and the most specific subsumer of a set of concepts S =
{ C1,..., Cn} is denoted by �( C1 , ... , C,) or �(S).
p(C;ACj,e)
ci· we h avep(CiICi) Suppose C; �
p(Ci )
-9'
But C; � Cj implies that p(Ci 1\ Cj) = p(Cj)· There­
fore
(1)
·

In other words the subsumption probability is simply
the ratio of the prior probabilities of the concepts it
connects.
4.4

Feature Relations and Conceptual
Abstraction

Suppose we have already assessed a set of pc­
diagrams, we can combine them to produce a
more general super-concept. For example, given
the pc-diagrams for "tool chatter," "tool wear,"
and "tool breakage," we can obtain the pc-diagram
for "tool failure." In general, given Ck, set of
its most general subsumees �( ck)' and suppose
Bk(F) = UciE�(Ck)Bi(F) then p(F/Ck, Bk(F)) =
k
k
l::ciE�(ck) p(FJCj, Ck, B (F))p(Ci/Ck, B (F)). The
feature F is independent of Ck given any subcon­
cept Ci of Ck since once Ci is known to be true
then any information about ck will not have any
further effect on our belief on F. This implies
that (Fi/Ci, Ck, B k(F)) = p(Fi/Ci, Bk(F)). Like­
wise, Cj is independent of Bk(F) given Ck. Hence
p(F/Ck, Bk(F)) =
L p(F/Cj,Bk(F))p(Cj/Ck),
CjE�(Ck)

Figure 3: The pc-diagram for "tool chatter."
Figure 3 shows the pc-diagram "tool chatter." This
diagram comprises a deterministic node representing
"tool chatter" and a number of feature nodes whose
descriptions are given Table 1. An arc between two
feature nodes indicates that these two features may
not be conditionally independent given the concept
"tool chatter." For example, the arc between the node
"AE-mag" and the node "�AE-mag" indicates that
information about the current magnitude of acoustic
emission may provides information about the change
in magnitude of acoustictemission. The direction of
this arc could be reversed without any change in as­
sertion about possible dependency.
Figure 4 shows a fragment of the full pc-net for the
automated machining showing the concepts "tool fail­
ure," "tool chatter," "tool wear," "tool breakage,"
"sensor failure," and "transient state."
4.3

Probabilistic Subsumption Relations

We shall denote the fact C; is a subconcept of Cj by
C; � Cj. The set of the most general subsumees (i.e.
all the direct subconcepts) of Ck is denote by �(Ck) ,

which may be rewritten as
2:: p(F/Ci, Bi(F), Bk(F) \ Bi(F))p(Ci/Ck)·
CjE�(Ck)
But the set of conditioning features Bk(F) \ Bi(F) is
independent ofF given Cj. Hence p(F/Ck, Bk(F)) =

2::

CjE�(Ck)

p(Ci/Ck)p(F/Ci ,Bi(F)).

Hence if Ck is a concept in the pc-net and all the
pc-diagrams for the concepts in �( ck) has been as­
sessed, then the pc-diagram for ck may be derived
from those of its subconcepts. Formally, for any fea­
ture F, p(F/Ck, Bk(F))

L

CjE�(Ck)

where Bk(F)

=

p(Cj/Ck)p(F/Cj, Bi(F))

(2)

i(F)

U ci E �(Ck ) B

Equation (2) allows us to build the pc-net from bot­
tom up by propagating the probability distributions in
the pc-diagrams from the bottom of the hierarchy up
to the root of the hierarchy. This allows us to build

Poh and Fehling

170

---

---

�-,

\
\

p�
\
I
I
I

I
I

I
I
I
I
I

o
I
I
I
\
I

�
.

\
\
I
I
I

I

I
I
I

I

'
I
I

;4

'
I
I
I

I

Figure 4: A fragment of the pc-net for the automated machining problem
the pc-net by first constructing the pc-diagrams for
all the terminal or atomic concepts, and then the pc­
diagrams for the more general concepts may be derived
from the pc-diagrams below them. However, it is pos­
sible to simplify the pc-net by identifying subconcept
independence and take advantage of inheritance.
4.5

Feature Inheritance for
Subconcept-Independent Concepts

The principle of inheritance in pc-net is based on a
special type of independence that can hold among con­
cepts and features. Formally, we say that a feature F
is subconce pt independent of a concept C�: given B, if
and only if
(3)
for all feature values f ofF and for all subconcepts C;
of Ck. Intuitively, information about a feature that is
subconcept independent of a concept does not affect
the agent's belief about any of that concept's subcon­
cepts. An equivalent criterion for subconcept indepen­
dence is obtained using using Bayes' rule:

The last equation applies that for any pair of sub­
concepts C; and Cj of C�c, i.e., p(FjC;) = p(FICJ)·
Conversely, if the last equation holds then using
equation (2), p(FIC�:) = Lj p(CJICk)p(FICJ)
p(FIC;) Lj p(CjiCk)
Lj p(CjiCk)p(FIC;)

p(FjC;). Hence an equivalent criterion for subconcept
independence is:

We shall denote by F ..l�CkjB, the fact that F is sub­
concept independent of Ck given B. In cases where
the background knowledge is understood, the B may
be omitted. An interesting property about ..l� is that
once it has been established for a concept, it recur­
sively applies to all of its subconcepts (Poh, 1993).
That is,

The justification for the application of inheritance for
subconcept independent concepts for a feature is due
to equations (4) and (5). Since the probability dis­
tributions for the feature are identical, we need only
store them at the highest possible position.
To illustrate the idea of inheritance, consider the frag­
ment of the pc-net for "transient state," "tool exit"
and "tool entry" shown in Figure 4. The feature
"�rms current" is subconcept independent of "tran­
sient state." We do not need to explicitly store the
probability distributions for "�rms current" in the pc­
diagrams for "tool entry" and "tool exit." That is, we
may "omit" these probability distributions (and hence
the corresponding feature nodes) in their respective
pc-diagrams. When needed, the probability values are
filled in by inheriting them from "transient state."

Probabilistic Conceptual Network

5
5.1

171

Model Construction
Constructing Categorization Decision
Models

Figure 6: The categorization decision model

Figure 5: The categorization prob. influence diagram
We shall illustrate how a categorization decision model
may be constructed from the pc-net for the automated
machining problem. In this application, the prefer­
ence model may be expressed in the form v(Ak ,C;)
where Ak is an action that may be taken, like for ex­
ample, "reducing cutting speed", "reducing depth of
cut", etc. C; is any state of the machining operation
we have described earlier. v(Ak, C;) gives the utility
of the outcome by taking action Ak when the state of
the machining operation is C;.
Suppose the sensors report information on "AE­
mag," "AE-rms," "dyn-rms-x," "dyn-rms-y," and
"rms-current," and' our utility-based categorical rea­
soner described earlier, determines that the most ap­
propriate level of abstraction corresponds to the set of
concepts comprising "tool chatter," "tool wear," "tool
breakage," "sensor failure" and "transient state." We
can combine the respective pc-diagrams for these five
concepts to construct a categorization probabilistic in­
fluence diagram as shown in Figure 5. The graphical
structure of the combined categorization influence di­
agram is obtained by performing graphical union of
the individual pc-diagrams while treating each central
concept node as being the same node in each of the
individual pc-diagrams. Notice that the concept node
in the constructed diagram is now a probabilistic vari­
able (C) ranging over the five concepts used in its con­
struction. The conditional probabilities for each of the
feature nodes in the constructed diagram is obtain by
copying over their respective original values in the in­
dividual pc-diagrams. That is, for any feature F,
p(FIC = C;,B9(F)) = p(F;IC;,B;(F))
(7)
where Bg (F) is the set conditional predecessors of F
excluding C, in the constructed diagram.
The next step in the construction procedure is to com­
plete the diagram by turning it into a categorization
decision model as shown in Figure 6. This is done
by first, adding the decision and value node to reflect

the preference model described earlier. Next, infor­
mational arcs from the observed feature nodes to the
decision node are added. The completed categoriza­
tion influence diagram can now be solved using exist­
ing methods (Shachter, 1986).
5.2

Validity of the Constructions

An important characteristic of our decision model con­
struction procedure is that the final model so con­
structed must reflect as accurately as possible the state
of information originally asserted by the knowledge­
base and preference model. Our knowledge-base con­
tains assertions about concepts, their properties, and
the probabilistic relationships among them. Validity
of a probabilistic model construction depends on the
soundness of the construction procedure. Heckerman
(1991) suggests that soundness should be character­
ized by the preservation of the joint-distribution of the
variables involved across the construction. For pc-net,
it can be shown that if the pc-diagrams in a given con­
ceptual cover are mutually consistent, then the con­
struction is indeed sound (Poh, 1993).
6
6.1

Related Work
Probabilistic Similarity Networks

Probabilistic similarity network (Heckerman, 1991) is
a knowledge engineering tool for building probabilistic
influence diagrams. We shall briefly describe the sim­
ilarities and differences between pc-net and similarity
network here. A more comprehensive comparison is
available in (Poh, 1993). Both pc-net and similarity
networks are capable of building the same type of influ­
ence diagrams, but pc-net is able to do so at varying
levels of abstraction, whereas similarity network can
only do so at one level. Another major difference is
that pc-net is capable of representing categorical ab­
straction relations whereas similarity networks can't.
Another difference is that the probabilities in a pc-net
are assessed before categorical reasoning and model

172

Poh and Fehling

construction take place whereas in similarity networks,
all the knowledge maps are initially unassessed and are
carried out only after the global knowledge map has
been built.
Both pc-net and similarity network use some sort of
local influence diagrams for concept representation.
However, a local knowledge map in similarity network
is built based on a pair of concepts. There are also
differences between a pc-diagram and a hypothesis­
specific knowledge map {hs-map) in similarity net­
works. First, the concept node is included in the pc­
diagram, whereas, it is not part of the hs-map. Second,
a pc-diagram is always a connected graph whereas a
hs-map may not be. Finally, a pc-diagram has its
probabilities initially assessed whereas, a hs-map is
not.
The notion of subconcept independence in a pc-net
is analogous to subset independence used in conjunc­
tion with partitions in similarity networks. Similarity
networks use partitions to speed up assessment while
pc-net saves assessments and storage by using inheri­
tance mechanisms based on subconcept independence.
In pc-net terms, a partition for a feature in similarity
network can be viewed as an an abstracted concept
subsuming all the concepts in the partition. Further­
more, that feature is subconcept independent of the
abstracted concepts. Assessing the probability distri­
bution for the feature given the abstracted concept
and applying inheritance is equivalent to assessing the
probabilities within the partition.
6.2

Knowledge-Based Model Construction
Methods

Several approaches have been proposed for construc­
tion or building of influence diagrams. There ap­
proaches may be classified under two highly contrast­
ing methodologies. The first, known as the synthetic
approach ( Horvitz, 1991) starts with the empty influ­
ence diagram; nodes and arcs are added to the model
through some methods of inference based on simple
rules or relationships. These inferences are usually
driven by assertions about the world, goals, or utility
{Holtzman, 1989; Breese, 1987; Goldman & Charniak,
1990; Wellman, 1988). These approaches however,
usually do not have principled control over the degree
of abstraction or details in the model that they are
building other than using some heuristics. The second,
known as the reduction approach ( Horvitz, 1991) seeks
to custom-tailor comprehensive, intractable decision
problems to specific challenges at run time through a
pruning procedure that removes irrelevant distinctions
and dependencies (Heckerman & Horvitz, 1991).
The decision model construction approach based on
probabilistic conceptual networks developed in our re­
search does not commit to either of these two contrast­
ing approaches, but instead, employs mixed strategies.
The approach can be seen as synthetic to some ex­
tent in that it builds an influence diagram dynami-

cally at runtime. However, unlike the pure synthetic
approaches, the building blocks used by this approach
are not individual nodes and arcs, but rather modules
of localized influence diagrams. On the other hand,
the approach can be seen to be reducible in that mod­
ules of local influence diagram have been pre-assessed.
However, instead of pre-assessing a comprehensive in­
fluence diagram, pc-net does not commit to one large
influence diagram, but instead, is a comprehensive net­
works of related local probabilistic influence diagrams.
The approach here allows for reasoning about the re­
lationship among these local influence diagrams, and
combines only those that are relevant or are required
while discarding those not required in the decision
model it is building.
The advantage of our approach over that of the com­
prehensive model reduction approach, is that assess­
ing smaller and more focused local pc-diagrams is usu­
ally easier and more manageable as compared with at­
tempting to assess a huge comprehensive influence di­
agram. This local-to-global approach to constructing
large probabilistic influence diagrams has been demon­
strated with similarity networks.
The advantage of this approach over that of the com­
plete synthetic approach is that the construction pro­
cedure is controlled using well founded principles of
decision theory. We use a principled approach to rea­
son about the values of constructing different parts
of the model. The model being built can be custom­
tailored to the optimal level of abstraction and avoid
any unnecessary details. This is very important when
we consider computational or resource constraints.
7

Conclusion

Previous work on integrating uncertainty . and cate­
gorical knowledge representation has been done with
a broad range of emphases and purposes. Saffiotti
{1990) proposed a general framework for integrating
categorical and uncertainty knowledge. In particu­
lar, Shastri {1985) proposed a semantic-network-like
representation language for evidential reasoning using
the principle of maximum entropy. Similarly, Lin and
Goebel {1990) proposed a graphical scheme integrat­
ing probabilistic, causal and taxonomic knowledge for
abductive diagnostic reasoning. This latter formalism
has two types of links, namely "is-a" and "causal."
In classifier-based reasoning, term subsumption lan­
guages are being extended to accommodate plausible
inferences {Yen & Bonisson, 1990). More recently,
Leong {1992) proposed a network formalism using var­
ious kinds of links including "a kind of," temporal
precedence, qualitative probabilistic influence {Well­
man, 1988) and property relations ( "Context" ) . Many
of these formalisms have desirable features that we
need, but none has all.
Finally, by combining the formalisms of influence dia­
grams and abstraction hierarchies, pc-nets effectively

Probabilistic Conceptual Network

represent both categorical knowledge/relations and
uncertainty in a modular and compact way. It can
also support dynamic construction of a specific class
of decision model at varying levels of abstraction. We
have also demonstrated the applicability of pc-net to
real-world applications in automated machining.
Acknowledgements

We wish to thank Ross Shachter, Eric Horvitz and
the anonymous referees for their helpful comments and
suggestions on the content of this paper.
Reference

Agogino, A. M., & Ramamurthi, K. (1990). Real time
influence diagrams for monitoring and controling
mechanical systems. In Oliver, R. M., & Smith,
J. Q. (Eds.), Influence Diagrams, Belief Nets and
Decision Analysis, pp. 199-228. John Wiley.
Knowledge Representation and
Inference in Intelligent Decision Systems. Ph.D.

Breese, J. S. (1987).

thesis, Department of EES, Stanford University.
Fehling, M. R., & Breese, J. S. (1987). A compu­
tational model for decision-theoretic control of
problem solving under uncertainty. Technical
Memo 837-88-5, Rockwell International Science
Center, Palo Alto Laboratory, Palo Alto, CA.
Goldman, R. P., & Charniak, E. (1990). Dynamic con­
struction of belief networks. In Proceedings of the
6th Conference on Uncertainty in Artificial In­
telligence, pp. 90-97.

Beckerman, D. E. (1991).
works. MIT Press.

Probabilistic Similarity Net­

Beckerman, D. E., & Horvitz, E. J. (1991). Problem
formulation as the reduction of a decision model.
In Bonissone, P. P., Henrion, M., Kana!, L. N.,
& Lemmer, J. F. (Eds.), Uncertainty in Artificial
Intelligence 6, pp. 159-170. Elsevier Science.
Holtzman, S. (1989).
Addison-Wesley.

Intelligent Decision Systems.

Horvitz, E. J. (1987). Reasoning about beliefs and ac­
tions under computational resource constraints.
In Proceedings of th£; Third Workshop on Uncer­
tainty in Artificial Intelligence, pp. 429-439.
Computation and action under
bounded resources. Ph.D. thesis, Depts of Com­

Horvitz, E. J. (1990).

puter Science and Medicine, Stanford University.
Horvitz, E. J. (1991). Problem formulation and deci­
sions under scarce resources. In Working Notes of
the AAAI Workshop on Knowledge-Based Con­
struction of Decision Models.

Horvitz, E. J., Beckerman, D. E., Ng, K. C., & Nath­
wani, B. N. (1989). Heuristic abstraction in
the decision-theoretic pathfinder system. Report
KSL-89-24, Stanford University.

173

Horvtiz, E. J., & Klein, A. C. (1992). Utility-based ab­
straction for categorization. Technical Memoran­
dum 83, Rockwell International Science Center,
Palo Alto Laboratory.
Howard, R. A., & Matheson, J. E. (1981). Influence
diagrams. In Howard, R. A., & Matheson, J. E.
(Eds.), Readings on the principles and applica­
tions of decision analysis, Vol. 2, pp. 719-762,
1984. SDG, Menlo Park, California.
Lehmann, F. (Ed.). (1992). Semantic Networks in Ar­
tificial Intelligence. Pergamon Press.
Leong, T.-Y. (1992). Representing context-sensitive
knowledge in a network formalism: A prelimary
report. In Proceedings of the Eighth Confer­
ence on Uncertainty in Artificial Intelligence, pp.
166-173.
Lin, D., & Goebel, R. (1990). Integrating probabilistic,
taxonomic and causal knowledge in abductive di­
agnosis. In Proceedings of the 6th Conference on
Uncertainty in Artificial Intelligence, pp. 40-45.
Pearl, J. (1988). Probablistic Reasoning in Intelligent
Systems: Networks of Plausible Inference. Mor­
gan Kaufmann Publishers, San Mateo, CA.
Poh, K. L. (1993). Utility-based categorization. PhD
dissertation draft, Department of Engineering­
Economic Systems, Stanford University.
Poh, K. L., & Horvitz, E. J. (1993). Reasoning about
the value of decision-model refinement: methods
and applications. This volume.
Russell, S., & Wefald, E. (1991). Principles of metar­
easoning. Artificial Intelligence, 49, 361-395.
Saffiotti, A. (1990). A hybrid framework for represent­
ing uncertain knowledge. In AAAI-90, Proceed­
ings of the Eight National Conference on Artifi­
cial Intelligence, pp. 653-658.

Shachter, R. D. (1986). Evaluating influence diagrams.
Operations Research, 34(6), 871-882.
Shastri, L. (1985). Evidential reasoning in semantic
networks: A formal theory and its parallel im­
plementation. Ph.D. thesis, Department of Com­

puter Science, University of Rochester.
Smith, E. E., & Medin, D. L. (1981). Categories and
Concepts. Harvard University Press.
Wellman, M. P. (1988). Formulation of tradeoffs in
planning under uncertainty. Ph.D. thesis, Dept
of EECS, MIT .
Yen, J. , & Bonisson, P. P. (1990). Extending term sub­
sumption systems for uncertainty management.
In Proceedings of the 6th Conference on Uncer­
tainty in Artificial Intelligence, pp. 468-473.




In recent years, there have been intense research efforts to develop efficient methods for probabilistic
inference in probabilistic influence diagrams or belief networks. Many people have concluded that the best
methods are those based on undirected graph structures, and that those methods are inherently superior to
those based on node reduction operations on the influence diagram.

We show here that these two

approaches are essentially the same, since they are explicitly or implicity building and operating on the
same underlying graphical structures. In this paper we examine those graphical structures and show how

this insight can lead to an improved class of directed reduction methods.
1. Introduction

main results in this paper are based on the connections
Chyu has established between such diagrams and the

In recent years, there have been intense research efforts

undirected graph methods, allowing similar efficient

to develop efficient methods for probabilistic inference

computations using directed reduction operations [Chyu,

in probabilistic influence diagrams or belief networks.

1990a; Chyu,

As these networks become increasingly popular

connections and specialized reduction operations which

1990b].

By

recognizing

these

representations for capturing uncertainty in expert

exploit evidence nodes in the probabilistic influence

systems, the performance of inference procedures is

diagram [Shachter, 1989], we can obtain complexity of

essential for normative reasoning in real time. To date,

the same order with both undirected and directed

the best exact techniques for general probabilistic

reduction methods.

influence diagrams appear to those based on analogous
undirected graphical structures [Andersen et al., 1989;

In Sections 2 and 3 we introduce the notation and

Jensen et al., 1990a; Jensen et al., 1990b; Lauritzen and

framework of the directed probabilistic influence

Spiegelhalter, 1988; Shafer and Shenoy, 1990]. Some

diagram and undirected moral graph, respectively.

people have also concluded that those methods are

Section 4 explains the use of the arc reversal operation

inherently superior to those based on node reduction

to transform influence diagrams and Section 5 presents

operations on the influence diagram [Shachter, 1986;

the corresponding operations to incorporate evidence

We show here that these two

into the diagram. These pieces are integrated into a new

approaches are essentially the same, since they are

directed reduction method in Section 6, and some

Shachter, 1988].

explicitly or implicity building and operating on the

conclus�ons and extensions are presented in Section 7.

same underlying graphical structures. In this paper we

I
I
I
I

examine those graphical structures and show how this
insight can lead to an improved class of directed

2

•

Probabilistic Influence Diagrams

reduction methods.
A probabilistic influence diagram is a network built on
The key to this connection is the decomposable

a directed acyclic graph.

probabilistic influence diagram [Smith, 1989].

correspond to uncertain quantities, which can be

The

The nodes in the diagram

238

observed, while the arcs indicate the conditioning

A PID will be called a

I

decomposable PID O£liD if

relationships among those quantities. A decomposable

there is an arc between every two nodes with a common

probabilistic influence diagram is a special type of

child. It will be called decomposable with respect to

influence diagram whose properties will be explored

.D2dstj if

throughout this paper.

decomposable.

It can be shown that if a PID is

decomposable,

then

A probabilistic influence diagram

<fiiD is

a network

the subgraph induced by j's ancestral set is
every

subgraph

of

it

is

decomposable as well [Chyu, 1990b].

structure built on a directed acyclic graph (Howard and

A list of the nodes N in a directed graph is said to be

Matheson, 1984]. Each node j in the set N= { 1, ... .n }
corresponds to a random variable X j. Each variable Xj

ordered if none of the parents of a node follow it in the
list. Such a list exists if and only if there is no directed

has a set of possible outcomes and a conditional
probability distribution 7tj over those outcomes. The
conditioning variables for 7tj have indices in the set of

cycle among

parents or conditional predecessors CG) c N, and are
indicated in the graph by arcs into node j from the nodes
in C(j). Each variable Xj is initially unobserved, but at

the nodes.

Whenever a PID

is

decomposable with respect to a node j, there is a unique
ordered list for the ancestral set of j (Chyu, 1990b].
One graph will be said to be consistent with another if

both have the same nodes but the former has a subset of

some time its value Xj might become known. At that
point it becomes an evidence variable, its index is

conditions is said to be minimal if there is no other

included in the set of evidence variables E, and this is

graph consistent with it that satisfies those conditions.

the arcs of the latter.

A graph satisfying certain

represented in the diagram by drawing its node with
shading.

3.

Moral Graphs and Chordal Graphs

As a convention, lower case letters represent single
nodes in the graph and exact observations while upper
case letters represent sets of nodes and random variables.

If J is a set of nodes, J � N, then

XJ

Moral and chordal graphs are undirected graph structures

which correspond closely to PID's. The nodes have the

denotes the vector

same meanings, but there are many directed graphs

For example, the
of variables indexed by J.
conditioning variables for Xj are denoted by Xc(j) and

corresponding to any undirected one. To appreciate the
qualities of DPID's we need to explore the relationships

might take on values XC(j)·

between PID's and their undirected analogs.

In addition to the parents, we can defme the children or
(direct) successors of a node j. It is also convenient to

Given a PID, its corresponding moral mgh is obtained

keep track of the ancestors or indirect predecessors of

by adding undirected arcs between any nodes with a
common child and dropping the directions from all of

node j which are defined to include the parents of j.

the arcs.

Likewise, the ancestral set of node j is the ancestors of

example of incest in genetics [Jensen et al., 1990b] is

For example, a PID corresponding to an

node j, plus j itself. Finally, the nondescendants ND(j)

shown in Figure la and its corresponding moral graph

of node j are those nodes which are neither direct nor

is shown in Figure lb. The undirected arcs which were

indirect successors of node j. ND(j) does not include

added between nodes with common children are drawn

node j itself.

with dashed lines. Although the moral graph of a PID

Because there might be some observed evidence nodes in

same moral graph.

the diagram, some care must be taken to interpret the
meaning of the distribution 7t j within node j. When

A moral graph is called a chordal fmWh if every cycle of

there is no evidence then 7tj is simply the probability
for Xj given its conditioning variables, P (Xj I Xqj)l·

two nodes in the cycle which is not itself in the cycle.

is unique, there can be many PID's corresponding to the

four nodes or more possesses a £.h.Qa1, an

arc

between

However, in generalnj is defmed as conditional on its

(Chordal graphs are also called triana;ulated [Berge,

nondescendant evidence nodes,
P{ Xj I Xc(j)• XEnND(j) = XEriNI)(j)

of the nodes in an undirected graph is said to be

1973; Golumbic, 1980] and

}.

decomposable.)

A listing

�

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I
I
I
I

239

if, for every node j in the list, there are arcs between all

There is a strong relationship between DPID's and

of the nodes which are adjacent to j and precede it in the

chordal graphs, stated in following theorem.

list. A moral graph is chordal if and only if it has a
perfect list [Golumbic, 1980]. For example, the graph
shown in Figure l d is a minimal chordal graph
corresponding to the moral graph shown in Figure lb.
It is clearly chordal since ( B A C D F G H E I J
perfect list.

) is a

It is minimal because it would not be

Theorem 1
A PID is decomposable if and only if its ordered list
is perfect on its moral graph.

frQQt

Given a DPID, its moral graph can be obtained

I

chordal without both of the added arcs, drawn with

without adding any new arcs.

dashed lines. It is not unique, however, since there

decomposable its ordered list will be perfect for that

be many minimal chordal graphs corresponding to the

moral graph.

I

same moral graph. A perfect ordering can always be

Given a perfect list on a moral graph, directions

found, if one exists, by using maximum

be added to the undirected arcs from earlier nodes in

I

� [Tarjan and Yannakakis, 1984].

can

cardinality

Because it is

can

the list to later ones. This will be an ordered list for
the PID and the PID wiH be decomposable because
the list was perfect.

•)

We

can

always obtain a DPID from a chordal graph by

I

using one of its perfect lists as an ordered list. Such a

I

were added or modified from the original PID shown in

DPID is shown in Figure l c using the perfect list ( B A

C D F G H E I J ) . The dashed arcs are the ones that

Figure Ia.

that corresponding chordal graph, and any ordered list for

I

the DPID will be perfect for the chordal graph. There is
only one other result needed to characterize their
relationship, defining the minimal DPID in tenns of an

I
I

original PID and a desired or� ordered list.

Theorem 2.
Given a target ordered list and a moral graph, there

c)

corresponds a unique minimal DPID.

ftQQf:

I

Starting with the last node in the list, add undirected
arcs to the moral graph until the ordered list is

perfect, so it is an ordered list for the corresponding

I

DPID. There was no choice which arcs to add, and
the list would not be perfect if any of the new arcs
were not added, so the DPID is both unique and
minimal.

I

I
I

#

Although there is no unique minimal chordal graph in
general corresponding to a given moral graph, there is

I
I

Similarly, the moral graph for a DPID is

only one for which a target ordered list is perfect. As a
result, we can summarize the relationships between a
PID and its associated DPID's, moral graphs, and
Figure 1. Different graphical representations
for the incest example.

chordal graphs.

Given a PID there is a unique moral

graph. Given that moral graph and a target ordered list,

240

there is a unique minimal DPID. Finally, the moral
graph for the DPID is the minimal chordal graph
corresponding to the original PID for which the target
ordering is perfect

reverse in the target order. This algorithm creates the
minimal number of additional arcs. Its correctness is
given by the following theorem.
Theorem 3, Transforming toTarget DPID

4.

Influence Diagram Transformations

The arc reversal operation transforms one PID into
another with a different ordered list. In the process,
extra arcs often must be added to the PID. However,in
transforming to and from DPID's, we can guarantee
limits on the addition of those extra arcs.
The arc reversal operation transforms a PID by changing
the direction of one of the arcs [Olmsted, 1983;
Shachter, 1986]. Afterwards, each of the two nodes
inherits their common parents. The operation can be
interpreted as momentarily merging the two nodes and
then splitting them apart. The arc (i, j) is reversible if
it is the only directed path from i to j. Otherwise, a
directed cycle would be created by reversing the arc. The
general case for arc reversal is shown in Figure 2, in
which the arc (i,j) is reversed. Afterwards,A,B, and C
are parents for both i and j.

Figure 2. General Arc Reversal Operation.

Given a target ordered list and any PID, we can
transform the PID into another PID consistent with the
minimal DPID, using only arc reversal operations
[Chyu, 1990b; Shachter, 1990]. The algorithm
involves visiting each node j in the reverse target order:
reverse all arcs to j's successors which come before it in
the target order. Arcs must be reversed in the order they
appear in the current PID. but when there is a choice,

Given a PID and a target ordered list, a new PID
consistent with the corresponding minimal DPID can
be obtained through a sequence of arc reversals.

frQQt

The proof is by induction as we visit each node k in
the reverse target order. We have two induction
hypotheses: the current PID contains no arcs outside
of the target DPID and the target list after k is an
ordered list for the current PID.
To prove the theorem we must show that all of the
arcs reversed are reversible, and that the induction
hypotheses are maintained.

First, we show that the target list starting with k will
be ordered for the current PID. This follows,because
we reverse any arcs from k to successors which
precede it in the ordered list, and all of the other nodes
which follow k are already in the target order.
Second, we show that any arc (k, j) to be reversed is
indeed reversible. If this were not true, then there
must be some node i, k � i � j. If i belongs before
k then (k, i) would have been reversed before (k, j).
Therefore i must belong after k, but it is not properly
ordered since it precedes j. Thus we contradict the
induction hypotheses and it must be true that arc (k,
j) is reversible.
Finally,we must show that no arcs are created outside
of the target DPID. A new arc is created when we
reverse arc (k,j) only if there is some node i..%: which
is a parent of k or j and not of the other. Since all
nodes following k are in their target order, k must
follow both i and j in the target order. Now all
current arcs are by induction in the target chordal
graph, so this new arc is required for the target
#
ordering to be perfect
As a special case of this result, we can transform
between any two DPID's which have the same moral
graph,and hence correspond to the same chordal graph
[Chyu, 1990b; Smith, 1989].
Corollary I.
We can transform one DPID to another DPID
corresponding to the same chordal graph through a

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I

241

I
I

sequence of arc reversals.
By similar reasoning, it can be shown that any arc
reversal

operations

on

a

DPID

will

keep

it

decomposable [Chyu, 1990b]. However, the resulting

conditional distribution 1tk, P{ Xk I Xqk)• Xj = Xj },
no longer depends on X j- For example, if C were
observed in the DPID shown in Figure 1c, then after
evidence absorption we obtain the DPID shown in
Figure 3.

I

PID will not in general be a minimal DPID for the
starting PID and the target order.

The operation of evidence absorption does not destroy

I

Theorem 4.
1f a sequence of

the observed node to its children are absorbed.

I
I
I
I

the decomposability of a PID, since all of the arcs from
arc reversal operations are perfonned

Proposition I.

on a DPID, it will continue to be decomposable.

If evidence absorption is performed on a DPID, it
remains decomposable.

S.

Evidence Transformations
When evidence is absorbed at a node the distributions of

New observations are incorporated into a PID in two

its ancestors are affected indirectly. To propagate these

steps. First, the evidence is absorbed into the network

effects throughout the network, we must reorder the PID

and then it is propagated throughout the network using

so that the evidence node has no ancestors.

the evidence reversal operation, a variant of arc reversal.

reordering process consists of a sequence of specialized

In the process, new arcs are added until the PID

reversal operations. Evidence reversal of the arc (i, j) is

eventually becomes a DPID.

At all times, the PID

This

closely related to arc reversal, except that because the

successor node is observed there is no need for it to have

represents the posterior joint distribution.

a child afterward [Shachter, 1989]. The general case is
shown in Figure 4. It can be thought of as arc reversal

I

followed by evidence absorption, but it is more efficient
to recognize the

special properties of evidence reversal.

I
I

'

I
I
I
I
I
I
I

Figure 3. DPID after evidence absorption of C.

The operation of evi dence absor:ption maintains the
posterior joint distribution while recognizing the
observation of an exact value for a variable in the PID
[Lauritzen and Spiegelhalter, 1988; Shachter, 1989].
There is no longer any need to maintain distributions
with the other possible outcomes for the variable in its
node or in the nodes of its children. Therefore, when Xj
is observed at value Xjo the conditional distribution 1t j

,

becomes a likelihood function, P( X j = Xj I Xcu) } and
the arc to each child k of j is absorbed, since the

Figure 4. General Evidence Reversal Operation.

When evidence reversal is performed on arc (i,

j),

evidence node j moves one step closer to the start of an
ordered list for the PID.

In order for it to have no

ancestors, the operation will have to be performed on
each ancestor in reverse order.

This sequence of

evidence reversal operations is called e vidence
propuatio n [Lauritzen and Spiegelhalter, 1988;

I

242

Shachter, 1989]. Afterwards, node j will have neither

generality, suppose the arc from I to the evidence

parents nor children. For example, consider the part of

node is reversed before the arc from m. Afterwards m

the incest PID shown in Figure Sa.

will be a parent of I.

We have some

#

evidence about C, but it is not an exact observation of
C, so we create a variable K whose exact observation

By this same logic, if the ancestral set is already

describes the evidence for C. (Node K is created and

decomposable then no new arcs will be created by

absorbed at the same time, so it has no children and its

evidence propagation. Also, since the ancestral set will

distribution is simply a likelihood function for C.

be decomposable, and the ancestral set of the sink nodes

Because K has no children and only one parent, a DPID

(nodes without children) is the entire PID, evidence at

would remain decomposable after it was added.)

all of the sink nodes will result in a DPID.

Evidence propagation consists of evidence reversals with
C, A, and B in tum until node K is disconnected as
shown in Figure 5b, 5c, and 5d. There was a choice

Corollary 2.

When evidence propagation is performed on a DPID,
no new arcs are created.

whether to reverse A before B since they were not
ordered beforehand in the PID.

Notice that they are

ordered afterward and the PID has become a DPID in the
process, as will be proven in general below. Finally,

�Corollary
3.
Once evidence propagation has been perfomed from

the evidence could have originally related to multiple

all

sink

nodes

nodes as in shown in Figure 5e. This works best when

decomposable.

in

a

PID,

the

PID

will be

the nodes are a subset of a� [Golumbic, 1980].
Each node and its parents are contained in some clique.

Evidence propagation can be performed efficiently even
when evidence has been absorbed at multiple nodes in

b)

a)

the PID. Each unobserved node in the network has to
be visited once, in reverse graph order:

if it has no

evidence children, there is nothing to do; if it has
exactly one, then perform evidence reversal; otherwise it
must have multiple evidence children, and they can be

d)

c)

combined into one evidence child by multiplying their
likelihood functions so that a single evidence reversal
can be performed.

(If some of the multiple evidence

children have multiple parents, then the resulting
product has all of their parents.)

•>

In summary, the operations of evidence absorption and
evidence propagation eventually result in a DPID. If
the PID is already decomposable and evidence is only

Figure 5. Application of evidence propagation
on part of the incest example.

S.
* Theorem
Once evidence propagation has been performed from
node j in a PID, the PID will be decomposable with
respect to node j.
Proof:
Consider any node i with multiple parents in the
ancestral set for j, and let I and m be any two of those
parents.

Both I and m are parents of the evidence

node after the arc from i is reversed. Without loss of

within cliques, then those operations will never add new
arcs.

6.

I
I
I
I
I
I
I
I
I
I
I
I
I

Putting it All Together

In this section, we assemble the

I

results from

throughout the paper to develop a directed reduction
algorithm to compute the posterior joint distribution.
Because the choice of chordal graph is arbitrary, we can
obtain precisely the same chordal graph as in the best
undirected methods [Andersen et al., 1989; Jensen et al.,

I
I
I
I

I
I
I
I
I
I
I
I
I

243

1990a;

Jensen

et al., 1990b; Lauritzen and
1988; Shafer and Shenoy 1990) with
similar complexity using directed reduction operations.

absorbed and propagated while maintaining a PID

The first step in this process is to determine a target

observations, then evidence propagation should be

ordered list for the DPID. The list can either be selected

performed in reverse order thro ughout the PID to avoid

directly or, if a chordal graph is chosen instead, one of

duplicate operations.

Spiegelhalter

,

,

absorption and propagation. If the evidence is about
nodes in the same clique, then that evidence can be
consistent with the target DPID. If there are multiple

its perfec t lists should be used. One way to generate the
perfect list is to perform maximum cardinality search on

In this method, we maintain an updated posterior joint

the chordal graph, using an ordered list for the original

distribution for the PID given the evidence. If we desire

PID to break ties [Chyu, 1 990b; Tarjan and
Yannalcakis, 1984).

obtained through reduction operations [Shachter, 1988].

any general conditional distributions, they can be
If we want posterior marginal distributions for the

Using this list and the algorithm described in Section 4,

variables in the PID, they can be obtained by a

we can pre-reverse arcs to obtain a PID consistent with
a perfect list for

probability propagation process [Lauritzen and
S piegelh alter, 1988; Shachter, 1989] operati ng on the
cliques. By comparing the bask operations performed

the chordal graph is shown in Figure ld. We can pre­

by the different methods, we can verify that they have

reverse arcs from the original PID shown in F igure la

the same order of complexity. This is because at each

PID shown in Fig ure 6. The shaded,
dashed arcs would not appear in this PID, but we can

graphical structure and operating on data structures of

the unique minimal DPID. For example, given target
ordered list ( B A CD F G HE I 1

)

,

to obtain the

infer them from the target ordering.

If they were

present, we would have the DPID shown in Figure lc.

I

step they are performing similar tasks on the same
the same max i ma l dimensions. There can, of course, be
significant differences in the actual computation times.

Proposition 2.

The directed reduction method and the undirected

methods of HUGIN and Lauritzen-Spiegelhalter are of

I

the same order of complexity.

I

7.

We have shown that a directed red uction algorithm can

I
I
I
I
I
I
I

Conclusions and Extensions

perform operations on the same graph and of the same
order of complexity as the best undirected methods for
probabilistic inference. This result can be interpreted in
two ways. First, pre-reversals allow us to use the best
possible choice of chordal graph so we can Jearn from

Figure 6. riDfor evidence propagation afterpre­
reversals.

the undirected methods a superior straten for reduction.
Second, we can plainly see how the chordal graph

structure represents the w ors t case" for posterior ioim
"

We can n ow perform evidence absorption and

dependence. No matter what evidence (within cliques) is

propagation on the PID. In the process, the shaded,

observed, no additional arcs will be necessary to

dashed arcs in Figure 6 might have to be added. In the

represent the posterior PH>.

worst case, they will all appear and we will obtain the
If the evidence absorption is exact

Some natural extensions to the directed algorithm are to

evidence about nodes in the network, then those nodes
and their incident arcs will be absorbed through evidence

exploit efficiencies which have been developed in either

target DPID.

the directed or undirected representations.

244

In the directed representation, an important property is
that of a deterministic function, a variable whose
outcome is known with certainty given its parents'
outcomes. This introduces additional conditional
independence into the diagram which can be exploited
during evidence propagation. At the same, when the
PID is only being used to obtain posterior marginal
distributions for a subset of variables or with limited
observations, then the PID can be preprocessed to
eliminate variables that are irrelevant for the desired
results [Geiger et al., 1989; Shachter, 1988; Shachter,
1990]. This elimination can be performed on the
working PID or, if possible, before the target DPID is
determined.
Another promising hybrid might exploit the impressive
speed and simplicity of the HUG IN undirected method
[Andersen et al., 1989; Jensen et al., 1990a; Jensen et
al., 1990b] by maintaining joint distributions for a node
and its parents instead of conditional distributions. This
simplifies the operation of arc reversal, but does require
maintaining the full DPID instead of simply a PID
consistent with it. There are a couple of advantages to
using this method on undirected graphs which appear
applicable to directed methods as well. These
advantages are symmetric operations for evidence and
probability propagation and the recognition of zeros in
the sparse joint distribution matrices.

8.

Acknowledgements

We are grateful for the comments and suggestions of
Richard Barlow, Stephen Chyu, and Robert Fung.

9.



Recent interests in dynamic decision modeling
have led to the development of several
representation and inference methods. These
methods however, have limited application under
time critical conditions where a trade-off
between model quality and computational
tractability is essential. This paper presents an
approach to time-critical dynamic decision
A knowledge representation and
modeling.
modeling method called the time-critical
dynamic influence diagram is proposed. The
formalism has two forms. The condensed form
is used for modeling and model abstraction,
while the deployed form which can be converted
from the condensed form is used for inference
purposes. The proposed approach has the ability
to represent space-temporal abstraction within
the model. A knowledge-based meta-reasoning
approach is proposed for the purpose of selecting
the best abstracted model that provide the
optimal trade-off between model quality and
model tractability. An outline of the knowledge­
based model construction algorithm is also
provided.
1

INTRODUCTION

The goal of dynamic decision making is to select an
optimal course of action that satisfies some objectives in a
time-dependent environment. The decisions may be made
in different stages and each stage may varies in duration.
A number of dynamic decision modeling formalisms have
been proposed by various researchers. These include
dynamic influence diagrams (DIDs) (Tatman and
Shachter 1990), temporal influence diagrams (Provan
1993), Markov cycle trees (Beck and Pauker 1983),
stochastic trees (Hazen 1992), and Dynamo (Leong
1994). Although these models provide relatively efficient
methods for representing and reasoning in a time­
dependent domain, the process of computing the optimal

solution has remain intractable. A decision maker may
have to spend a large amount of time in the modeling and
solution processes that left very little or no time for the
action to be carried out. This problem is particularly
significant for large models involving temporal relations.
Existing approaches to modeling and solving dynamic
decision problems are therefore not appropriate for time­
critical applications. Hence a more effective and practical
approach to time-critical dynamic decision modeling is
needed.
Time-critical dynamic decision problems have been
discussed in several research communities. An important
part of decision analysis is the formulation of the decision
problem. Modeling time and the needs to deal with time­
pressured situations are considered to be the greatest
challenges in developing time-critical dynamic decision­
support systems. We believe that a major reason for this
perceived difficulty is the lack of modeling techniques
that provide explicit support for the modeling of temporal
processes, and for dealing with time-critical situations. In
this paper, we propose a formalism called time-critical
dynamic influence diagrams (TDID), that provide explicit
support for the modeling and solution of time-critical
dynamic decision problems.
In our approach we utilize the notion of abstraction to
simplify the computational complexity of large and
complex models. Previous research efforts on abstraction
had mainly focused on data abstraction. For example, the
KBTA (knowledge-based temporal abstraction) method
(Shahar 1997) is a knowledge-based framework for the
representation and application of the knowledge required
for abstraction of high-level concepts from time-oriented
data. Further research is needed on decision model
abstraction methods and the selection of best situation­
specific abstraction model. For a given domain, there
exists a suite of possible decision models specified at
different levels of space-temporal abstraction. Almost all
previous research relied on the domain experts to assess
the "goodness" of different abstractions. We adopt here
the use of meta-reasoning to select an optimal model
based on the best tradeoffs between decision quality and
computational complexity.

Time-Critical Dynamic Decision Making

This paper is organized as follows: In Section 2, we
present the time-critical dynamic influence diagram used
for the modeling and representation of time-critical
dynamic decision problems. In Section 3, we show the
applications of space and temporal abstractions using
TDID. In Section 4, we propose a model-based approach
to meta-reasoning for the selection of the best abstraction
model and describe the model construction process.
Finally, in Section 5, we conclude by summarizing and
provide directions for further research.
2

689

dependent (possibly equal) on X1• and X3 respectively. A
formal definition of time-critical dynamic influence
diagrams is given below.

TIME-CRITICAL DYNAMIC
DECISION MODELING

2.1 TIME-CRITICAL DYNAMIC INFLUENCE
DIAGRAM (TDID)
TDID is designed to facilitate the modeling and solution
of time-critical dynamic decision problems. It extends
standard influence diagram (Howard and Metheson 1981)
by including the concepts of temporal arcs and time
sequences.
It also incorporates dynamic influence
diagram (Tatman and Shachter 1990) as a representation
for inference purposes.

Figure 1: An Example Of A TDID In Condensed Form.

Tl=l

T2=2

T3=3

T3=4

A TDID model has two forms: the condensed form and
the deployed form. Figure 1 shows an example of the
condensed form. This form is mainly used to represent or
define the dynamic decision model and is the form used in
the modeling process. Figure 2 shows the deployed form
for the same model. It is used only for inference purposes
and is constructed from the condensed form. Although in
principle both forms can be converted to and from each
other, they serve different purposes in the modeling and
solution processes.
Each node in a TDID represents a set of time-indexed
variables. The set of time indices may be different from
one node to another, but they must be subsets of a master
time sequence. The arcs in a TDID are called temporal
arcs and they denote both probabilistic and temporal
(time-lag) relations among the variables. Solid arcs in the
condensed form represent instantaneous probabilistic
relations, while broken arcs represent time-lagged
probabilistic relations. TDID allows for the coexistence
of nodes of different temporal detail in the same model.
The TDID in Figure 1 has a master time sequence of
<1,2,3,4>. Node Y represents a set of chance variables
indexed by this time sequence, whereas node X represents
a set of chance variables indexed by the subsequence <1,
3>. In this example, variable X has been temporally
abstracted by omitting its value at some intermediate time
indices. This is evident from the deployed form in Figure
2 where nodes Yh Y2, Y3 and Y4 are represented while only
nodes X1 and X3 are probabilistically represented, and
nodes X2 and X4 are assumed to be deterministically

Figure 2: The Deployed Form Of The TDID In Figure

1

Definition: The condensed form of time-critical dynamic
influence diagrams is a 7-tuple <T"" D, C, V, A;, A1, P >
where
Tm is a set of time indices called the master time
sequence.

D is a set temporal decision variables. Each D E D is a
sequence of decision variables indexed by a time
sequence T0 � T m·
C is a set of temporal chance variables. Each C E C is a
sequence of chance variables indexed by a time sequence
Tc� Tm.

690

Xiang and Poh

V is a set of utility functions indexed by a time sequence
T vk:T.,.

Ai!;;;; (D u C) x (D u C u {V}) is a set of instantaneous
arcs
such
that
VX
E (D
uC
)
and
VYE ( D u C u{ V }), (X, Y) E Ai if and only if there
exists an instantaneous arc from node X to node Y..

P is a set conditional probability distributions. For each
chance node X E C, we assess a sequence of conditional
probability distributions p(Xi I n(Xi ) ) where i E Tx.
7r (X; ) is the set of nodes lj such that (Y, X) E A1 and j
=max { k I k E Ty, k < i } or (Y, X) E Ai and j = i.
,

A1!;;;; (D u C) x (D u C u {V}) is a set of time-lag arcs
such that VX E (D uC ) and VYE ( D u C u{ V }), (X,
Y) E A, if and only if there exists a time-lag arc from node
X to node Y.
__,
.
'
.
'
'
.

Intervention

(a)
2

0

3

(b)

Figure 3: TDID For Cardiac Arrest Example

Time-Critical Dynamic Decision Making

2.2 AN EXAMPLE
We shall use a medical example from the domain of
cardiac arrest (Ngo et al 1997) to illustrate the use of
TDID. In this problem, the goal of the medical treatment
is to maintain life and to prevent anoxic injury to the
brain. The observable variable is the electrocardiogram or
rhythm strip (cr). While patient survival is of primary
importance, cerebral damage must be taken into account
and can be viewed as part of the cost in a resuscitation
attempt. The length of time that patient has been without
cerebral blood flow (cbf) determines the period of anoxia
(poa). If the patient has ineffective circulation for more
than five minutes, there is a likelihood of sustaining
cerebral damage. This damage is persistent and its
severity increases as the period of anoxia increases.
Medical doctors treat a patient experiencing a cardiac
arrest with a variety of interventions and medications.
The cardiac arrest problem may be represented by the
TDID in condensed form as shown in Figure 3(a). We
have assumed that the master time sequence is <1,2,3>,
and all time sequences are the same as the master
sequence. The real time between two time indices is 1
minute. Figure 3(b) shows the deployed form for the
same model.
2.3

level of space abstraction and temporal abstraction.
Details of model abstraction in TDID are given in Section
3.
2.4

TDID models time explicitly. It describes time in a clear
and unambiguous manner. For example, in Figure 1, it is
clear that X is a possible cause of Y and that this causal
effect is delayed by 1 time unit. Through the use of
temporal arcs and time sequences, a TDID has the ability
to explicitly model how the underlying events evolve with
time.

CONVERTING THE CONDENSED FORM TO
DEPLOYED FORM

The algorithm for converting a TDID in condensed form
to its deployed form is as follows:
1.
2.

3.

4.

PROPERTIES OF TDID

We describe here the properties of TDID. First, we note
that both forms of the TDID can be converted to and from
each other. The condensed representation permits
parsimonious descriptions of models and model
abstraction. Inference using established algorithms for
solving dynamic influence diagrams is then carried out by
converting the condensed form to the deployed form and
then adding a super value node.

691

5.

The time pattern for the deployed form is determined
by master time sequence.
The graphical structure of the TDID without
temporal-lag arc is replicated N time, where N is the
number of time steps in the master time sequence.
Let ID; be the ith influence diagram for i=l, ..., N.
Connect the nodes in two different time slices
according the temporal lag arc.
For each the temporal arc do
For i = 1 to N-1 do
Add arc from the parent node in time
slice i to child node in time slice i+ 1;
Abstracting nodes
For each node X with time sequence Tx c Tm do
Partition Tm into abstraction groups with
members of Tx as the starting index of each
group.
For each partition do
The node indexed by the Tx is the
abstracted node. The other nodes in the
same partition are assumed to be equal
to the abstracted.
Eliminate any barren nodes (Shachter 1986).
Insert probability distribution for expanded each
node.

3 MODEL ABSTRACTION USING TDID

TDID provides a relatively high degree of reusability and
modifiability of models. For instance, we may use the
condensed form to describe a concise description of the
domain, and it can then be easily reused. TDID also
allows for dynamic modification of the model after the
deployed form is produced from the condensed form.

In this section we show how TDID provides a flexible,
expressive and efficient formalism for representing model
abstraction, including temporal abstraction and space
abstraction. Abstraction of knowledge from domain
experts provides high level building blocks that assists in
both the development and maintenance of large
knowledge-bases in decision-theoretic applications.
Briefly, model abstraction is the task of creating context­
sensitive interpretations of decision model in terms of
higher-level space context and temporal patterns. The
input to the model abstraction task is a set of abstraction
goals and domain-specific abstraction knowledge. The
output of the model abstraction task is a set of models at a
higher level of space-temporal abstraction (Shahar 1997;
Combi and Shahar 1997).

Finally, TDID supports model abstraction. It provides a
method to represent model abstraction, including different

In our approach, the model abstraction task is
decomposed into three sub-tasks: context interpretation,

TDID allows for flexible temporal patterns. Compared
with dynamic influence diagram in which temporal
patterns of interest are predefined, TDID has temporal
patterns that can be dynamically modified.

692

Xiang and Poh

space abstraction, and temporal abstraction. These tasks
are supported by a domain knowledge base. Context
interpretation is a set of relevant interpretation contexts,
such as relation between a temporal pattern, the context of
state in different abstraction levels and relations. Space
abstraction focuses on abstracting the network within a
time slice, including abstracting a group of state variables
based on concept context, and summarising influence
paths based on nodes reduction. Figure 4 shows an
example of space abstraction of the TDID in Figure 3(a).
This abstraction could be the result of a response to a
massive myocardial infraction where we need not
consider cerebral damage.
The CD node and all
subsequent barren nodes may be eliminated.

/''

..,

--- ......\

/
I

( .-------'.....__-(
'

I
I L-----....1
I .-----',--

4 MODEL SELECTION AND
CONSTRUCTION
In the previous section, we showed how model
abstraction may be applied in TDID. However, given a
specific problem there exists many different possible
space-temporal abstractions, and not all abstractions are
Most of the previous research had
equally good.
recognized the usefulness of abstraction and but had
relied on the domain experts to indicate the best level of
abstraction. Here we address the problem of finding the
best model among the set of possible space-temporal
abstractions using meta-reasoning.
4.1 META REASONING

Intervention

Figure 4: Space Abstraction Of The Model In Figure
3(a).
0

interpretations of the variables. In Figure 3, we assumed
that the master time sequence is <1 ,2,3>, and all time
sequences are the same as the master sequence. If all
time sequences are abstracted to the subsequence <I, 3>,
then the resulting time-abstracted TDID is shown in
Figure 5 where the nodes in time slice 2 have been
omitted.

3

Meta-reasoning (Horvitz, 1990; Russell, 1 991) enables a
system to direct the course of its computations according
to the current situation. In time critical applications, it is
necessary that decision making effort be directed towards
computation sequences that appear likely to yield good
decisions. It is also important to consider tradeoffs
between computational complexity and decision quality.
Figure 6 shows a decision-theoretic perspective of the
meta-reasoning process. The goal is to determine the best
abstraction model. For a specific problem, there exists a
set of possible space-temporal abstraction models. We
choose the best model based on trade-off between the
computation cost and model quality. The computation
cost is determined by computation time, while the model
quality directly affects the quality of the action taken.

Figure 5: Temporal abstraction of the TDID in Figure
3(a).
Time abstraction may be performed on TDID by
modifying the time sequences embedded in the model.
Temporal abstraction in TDID leads to new context

Figure 6: A Decision-theoretic perspective of meta­
reasoning

Time-Critical Dynamic Decision Making

We first consider model quality. For a given problem or
situation, there exists a suite of models for solving the
problem. Let M be a set of different space-temporal
abstraction models for the problem. For each model m; E
M, let the maximum expected utility it yields be u*(m;)
which we will use as a measure of the model quality.
Next, we consider the computation time. For a specific
algorithm used to solve the model, the computation time t
can be estimated by assessing a function C,(S;, N;) where
S; refers to the space complexity of the model m;, and N;
refers to the number of time intervals in model m;.
We use the term comprehensive value Uc(m;) to refer to
the overall utility that include both model quality and
computational time. The comprehensive value is a
function of the object-level utility u0, and the inference­
related cost, u; (Horvitz 1990). The object-level utility is
the value associated with the information represented by
the computed result of model m; without regard to the cost
of reasoning. The inference-related cost is the penalty
incurred while delaying action to arrive at the result. We
define the comprehensive utility as the difference between
the object-level utility u0(m;) u*(m;), and the inference­
related cost, u;(m;) C,(S;, N;). Hence we write:
=

=

u,(u0(m;),u;(m;)) = u*(m;) - C,(S;, N;}},

m;E

M.

different space-temporal abstraction models in domain
specified knowledge base and choose the "best" model
based on the consideration of computation cost and
quality.
Model quality may be approximated as follows: Suppose
that the available computation time is t, and M 9 is the
set of models whose computational time is less than or
equal to t, then model quality is

Q(M <r )

4.2 A KNOWLEDGE-BASED APPROACH TO
META-REASONING

=

'
max u (m; ) subject to

m; E M <r.

(2}

M ,, be the model whose maximum expected
'
utility is equal to Q(M ,, ) = u' (m ) , i.e., model m* has

Let

m' E

the highest quality among all models whose computation
time is less than or equal to t.
By expending some quantity of reasoning resource t, e.g.,
computation time, model quality can be enhanced since
the set of feasible models M ,, is now larger. We define
the comprehensive utility for a given computation time t
to be the difference between the object-level utility
Q(M") and the inference related cost u; (t). That is

(1)

The best model is that model with maximum u'"

693

u,(Q(M,,,t) = Q(M9 ) -u;(t)

(3)

We define the net change in u,. in return for an allocation
of some computational resource to reasoning, as the
expected value of computation (EVC) (Horvitz 1990). If
t0 is the amount of resources already committed, then the
EVC for expending further resources tis

or

We can use the EVC to compare the value of extending
the computation by different length of time and identify
the ideal computation resource t* with the greatest EVC,
i.e.,

t*

=

argmax [EVC(t)].

(5)

"
The best model is then the model m such that
Figure 7: A Practical Knowledge-based Approach To
Meta-reasoning.
The approach to meta-reasoning given in the previous
subsection is intractable. We propose here a tractable
approach to perform the meta-level analysis as shown in
Figure 7. The goal of the meta-analysis is now to
determine the length of time for computation, and then to
identify the best model for doing so. We will use a
knowledge base to support the process. We store a set of

'
u (m") = Q(M <r. ).

(6)

We observed that under time-critical conditions, meta­
reasoning can provide useful control of the computational
complexity by selecting the optimal abstraction model. In
particular, it provides a straight forward way of
incorporating flexibility to perform tradeoffs between the
object-level value and the inference-related cost.

694

4.3

Xiang and Poh

KNOWLEDGE-BASED MODEL
CONSTRUCTION

We describe briefly here the model construction process,
which is supported by a domain knowledge base. The
steps for the model construction process are:
1.

Given a time-critical dynamic decision problem,
specify the problem requirements, such as its urgency
and deadline.

2.

Select a set of models that satisfies the requirements
from the domain knowledge base.

3.

Select the optimal model from the set of modes based
on model quality and computation cost.

4.

Modify or customize the TDID according to user
requirements if necessary.

5.

The TDID is converted into the deployed form, a
super value node is added and the optimal solution
determined.

5

SUMMARY AND CONCLUSION

In this paper, we have proposed an approach to time­
critical dynamic decision making. The method is
independent of any particular problem domain. A
formalism for knowledge and model representation called
the time-critical dynamic influence diagram was
proposed. The TDID has two forms. The condensed form
is used mainly for modeling and space-temporal
abstraction, while the deployed is used only for inference
purposes.
We have shown how space and temporal
abstraction may be carried out with TDID. In order to
select the best abstracted model, we introduced the use of
meta-reasoning, and proposed a practical knowledge­
based approach to perform tradeoff between decision
quality and computational complexity.
Finally, we
provide an outline of the knowledge-based model
construction process.
Our work here is related to a number of previous work as
well as some on going ones. The idea of representing a
temporal sequence of probabilistic models into a compact
form had been reported by Aiiferis et. al. (1995, 1997).
These related work had mainly focused on bayesian
networks while our work here include temporal decisions.
The use of knowledge base to support temporal
abstraction of data had been investigated by Shahar and
Musen (1996). The use of meta-reasoning for directing
the course of computation have been investigated by
Horvitz (1990) and Russell (1991). The idea of using
expected value of refinement and value of computation to

direct model refinement and abstraction was briefly
described in Poh and Horvitz (1993).
Finally, the authors are presently working on the
application of the approach to a time-critical medical
domain involving head injury critical care in a hospital in
Singapore.
Acknowledgments

The authors would like to thank the Tze-Yun Leong,
David Harmanec and other research group members for
their helpful suggestions and comments on this work.
This work is partly supported by a strategic research grant
from the Singapore National Science and Technology
Board and Ministry of Education. Yanping is supported
by a National University of Singapore research
scholarship.

