. We consider a voting setting where candidates have preferences about
the outcome of the election and are free to join or leave the election. The corresponding candidacy game, where candidates choose strategically to participate
or not, has been studied by Dutta et al. [6], who showed that no non-dictatorial
voting procedure satisfying unanimity is candidacy-strategyproof, that is, is such
that the joint action where all candidates enter the election is always a pure strategy Nash equilibrium. In [7] Dutta et al. also showed that for some voting tree
procedures, there are candidacy games with no pure Nash equilibria, and that for
the rule that outputs the sophisticated winner of voting by successive elimination,
all games have a pure Nash equilibrium. No results were known about other voting rules. Here we prove several such results. For four candidates, the message is,
roughly, that most scoring rules (with the exception of Borda) do not guarantee
the existence of a pure Nash equilibrium but that Condorcet-consistent rules, for
an odd number of voters, do. For five candidates, most rules we study no longer
have this guarantee. Finally, we identify one prominent rule that guarantees the
existence of a pure Nash equilibrium for any number of candidates (and for an
odd number of voters): the Copeland rule. We also show that under mild assumptions on the voting rule, the existence of strong equilibria cannot be guaranteed.

1 Introduction
A main issue for the evaluation of voting rules is their ability to resist various sorts
of strategic behavior. Strategic behavior can come from the voters reporting insincere
votes (manipulation); from a third party, typically the chair, acting on the set of voters or
candidates (control), on the votes (bribery, lobbying), or on the voting rule (e.g., agenda
control). However, strategic behavior by the candidates has received less attention than
strategic behavior by the voters and (to a lesser extent) by the chair. One form thereof
involves choosing optimal political platforms. But probably the simplest form comes
from the ability of candidates to decide whether to run for the election or not, which is
the issue we address here. The following table summarizes this rough classification of
strategic behavior in voting, according to the identity of the strategizing agent(s) and to
another relevant dimension, namely what the strategic actions bear on—voters, votes or
candidates (we omit the agenda to keep the table small).

actions →
agents ↓
voters

voters

votes

strategic participation

manipulation

third party / chair

voter control

candidates

-

candidates

candidate control,
bribery, lobbying
cloning
strategic candidacy
-

Strategic candidacy does happen frequently in real-life elections, both in large-scale
political elections and in small-scale, low-stake elections (e.g., electing a chair in a research group, or—moving a little bit away from elections—reputation systems). Throughout the paper we consider a finite set of potential candidates, which we simply call
candidates when this is not ambiguous, and we make the following assumptions:
1.
2.
3.
4.
5.

each candidate may choose to run or not for the election;
each candidate has a preference ranking over candidates;
each candidate ranks himself on top of his ranking;
the candidates’ preferences are common knowledge among them;
the outcome of the election as a function of the set of candidates who choose to run
is common knowledge among the candidates.

With the exception of 3, these assumptions were also made in the original model
of Dutta et al. [6] which we discuss below. Assumption 2 amounts to saying that a
candidate is interested only in the winner of the election4 and has no indifferences or
incomparabilities. Assumption 3 (considered as optional in [6]) is a natural domain
restriction in most contexts. Assumptions 4 and 5 are common game-theoretic assumptions; note that we do not have to assume that the candidates know precisely how voters
will vote, nor even the number of voters; they just have to know the choice function
mapping every subset of candidates to a winner. Assumption 4 is required only when
strong Nash equilibria are considered.
Existing work on strategic candidacy is rather scarce. Dutta et al. [6,7] formulate
the strategic candidacy game and prove that no non-dictatorial voting procedure satisfying unanimity is candidacy-strategyproof (or equivalently, that for any non-dictatorial
voting procedure satisfying unanimity, there is a profile for which the joint action where
all candidates enter the election is not a pure Nash equilibrium). Then, Dutta et al. [7]
exhibit a (non-anonymous) voting tree rule for four candidates for which there is a candidacy game with no pure Nash equilibria. They also show that for the voting rule that
outputs the sophisticated outcome for voting by successive elimination, the existence
of a pure Nash equilibrium is guaranteed. Some of these results are discussed further
(together with simpler proofs) by Ehlers and Weymark [8], and extended to voting correspondences by Ereslan [9] and Rodriguez [15], and to probabilistic voting rules by
Rodriguez [14]. Brill and Conitzer [4] extend the analysis to also include strategic behavior by the voters. Polukarov et al. [13] study equilibrium dynamics in candidacy
4

In some contexts, candidates may have more refined preferences that bear for instance on the
number of votes they get, how their score compares to that of other candidates, etc. We do not
consider these issues here.

games, in which candidates may strategically decide to enter the election or withdraw
their candidacy. Obraztsova et al. [12] study strategic candidacy games with lazy candidates, whose utility function results form the outcome of the election minus a small
penalty for running for election.
Studying the equilibria of a candidacy game helps predicting the set of actual candidates and therefore the outcome of the vote. However, little is known about this: we only
know that for any reasonable voting rule, there are some candidacy games for which the
set of all candidates is not a pure Nash equilibrium, that there exist candidacy games
with no pure Nash equilibria, and that a specific rule, defined from the successive elimination procedure and assuming that voters reason by backward induction, all candidacy
games have a pure Nash equilibrium. We do not know, for instance, whether pure Nash
equilibria always exist for common voting rules such as plurality, Borda or Copeland.
In this paper, we go further in this direction and prove some positive as well as
some negative results. We first consider the case of four candidates and show that for an
odd number of voters, a pure Nash equilibrium always exists for Condorcet-consistent
rules, while for most scoring rules and as well as for single transferable vote and plurality with runoff, this is not the case. Over the five candidate frontier, we know very
few rules that, can still guarantee the existence of an equilibrium. We show that for the
Copeland rule, and an odd number of voters, there is always a pure Nash equilibrium,
whichever the number of candidates. On the negative side, we show that for most scoring rules, for at least four candidates, and for Borda, maximin, and the uncovered set
for at least five candidates, and for the top cycle with at least seven candidates, there are
candidacy games without pure Nash equilibria. We also prove a simple impossibility
theorem showing that strong Nash equilibria are not guaranteed to exist provided the
voting rule satisfies two mild conditions satisfied by most common rules.
The paper unfolds as follows. In Section 2 we define the strategic candidacy games
and give a few preliminary results. In Section 3 we focus on the case of four candidates.
The case of five candidates is considered in Section 4. Section 5 deals with candidacy
games with more candidates. In Section 6 we discuss strong Nash equilibria, and relate
the candidacy game to candidate control. Finally, in Section 7 we discuss further issues.

2 Model and preliminaries
In this section, we define the strategic candidacy model, show that it induces a normal
form game, and give preliminary results on the existence of Nash equilibria.
2.1 Voting rules
Let X = {x1 , x2 , . . . xm } be a set of potential candidates and N = {1, 2, . . . n} a set
of n voters. We assume n is odd, so that pairwise majority ties do not occur. While this
is a mild assumption when the number of voters is large, this implies a loss of generality
for some of our results, and when this is the case we will make it clear.
For any subset Y ⊆ X of the candidates, a Y -vote is a linear ordering over Y . A
Y -profile P = h≻1 , . . . , ≻n i is a collection of n Y -votes. Although voting rules are
often defined for a fixed set of candidates, here we define them for an arbitrary subset

of the set of potential candidates: a (resolute) voting rule maps every Y -profile, for
every Y ⊆ X, to a candidate in Y . We will only consider resolute rules; we will first
define their irresolute version and then assume that ties are broken up according to a
fixed priority relation over the candidates. Because voting rules are applied to varying
sets of candidates, we assume that the tie-breaking rule is defined as a linear ordering
on the whole set of potential candidates X, and projected to subsets of candidates: if x
has priority over y (noted x ⊲ y) when all potential candidates run, this will still be the
case for any set of candidates that contains x and y.
We now define the rules we will use in the paper. (For each of them we define its
irresolute version, its resolute version being obtained as explained above.)
Scoring rules. A scoring rule (for a varying set of candidates) is defined by a collection
of vectors S m = hs1 , . . . sm i for all m, with s1 ≥ s2 ≥ . . . ≥ sm and s1 > sm . For
each m and each i ≤ m, si is the number of points obtained by the candidate ranked
in position i, and the winning candidate(s) maximizes the sum of points obtained from
all votes. Formally speaking, defining a family of scoring rules requires to specify a
scoring vector for each size of a candidate set (for instance, h3, 1, 0i for three candidates,
h4, 3, 2, 0i for four candidates and so on). However, for the following classical rules,
these collections of vectors are defined in a natural way:
– plurality: S m = h1, 0, . . . 0i;
– veto (or antiplurality): S m = h1, . . . 1, 0i;
– Borda: S m = hm − 1, m − 2, . . . 1, 0i.
Condorcet-consistent rules. Let P be a profile and NP (c, x) be the number of votes in
P who rank c above x. The majority graph m(P ) associated with P is the graph whose
vertices are the candidates and containing an edge from x to y whenever NP (x, y) > n2
(we say that x beats y in m(P ), denoted by x →P y). Because n is odd, m(P ) is a
tournament, i.e, a complete asymmetric graph. A candidate c is a Condorcet winner if
c →P y for all y 6= c. A voting rule r is Condorcet-consistent if r(P ) = {c} whenever
there is a (unique) Condorcet winner c for P .
Given a profile P , the top cycle T C(P ) is the smallest S ⊆ X such that for every
x ∈ S and y ∈ X \ S, x →P y . The uncovered set U C(P ) is the set S ⊆ X of
candidates such that for any c ∈ S and for any other candidate x, if x →P c then there
is some y such that c →P y and y →P x. The maximin rule chooses the candidate(s)
c that maximize minx∈X\{c} NP (c, x). The Copeland rule chooses the candidate(s) c
that maximize |{x ∈ X|c →P x}|.
Rules based on iterative elimination of candidates. Plurality with runoff proceeds in
two rounds: we first select the two candidates x and y with highest plurality scores and
the second round chooses between them according to majority. Single transferable vote
(STV) proceeds in m − 1 rounds: at each round, the candidate with the lowest plurality
score among the remaining candidates (using tie-breaking if necessary) is eliminated.
2.2 Strategic candidacy
In addition to voters’ preferences over candidates, expressed by the voter profile P , we
assume that each candidate i too has a linear preference ordering ≻i over candidates.

We assume furthermore that the candidates’ preferences are self-supported—that is,
each candidates rank herself at the top of her ranking. Let P X = (PcX )c∈X denote the
candidates’ preference profile.
We assume that voters are sincere; therefore, when the set of candidates running
for election is Y ⊆ X, each voter i reports the restriction of ≻i to Y and the obtained
profile, denoted by P ↓Y , is the restriction of P to Y .
Given a fixed voter profile P , a voting rule r can be seen as mapping each Y ⊆ X
to a winner r(P ↓Y ) in Y . We use the notation Y 7→P,r x, or more simply, Y 7→ x when
there is no ambiguity, to denote that the outcome of rule r applied to profile P restricted
to the subset of candidates Y ⊆ X is x.
Each voting rule r induces a natural game form, where the set of players is given
by the set of potential candidates X, and the strategy set available to each player is
{0, 1} with 1 corresponding to entering the election and 0 standing for withdrawal of
candidacy. A state s of the game is a vector of strategies (sc )c∈X , where sc ∈ {0, 1}.
For convenience, we use s−z to denote (sc )c∈X\{z} —i.e., s reduced by the single entry
of player z. Similarly, for a state s we use sZ to denote the strategy choices of a coalition
Z ⊆ X and s−Z for the complement, and
 we write s = (sZ , s−Z ).
The outcome of a state s is r P ↓Y where c ∈ Y if and only if sc = 1.5 Coupled
with a voter profile P and a candidate profile P X , this defines a normal form game
Γ = hX, P, r, P X i with m players. Here, player c prefers outcome Γ (s) over outcome
Γ (s′ ) if ordering PcX ranks Γ (s) above Γ (s′ ).
2.3 Game-theoretic concepts
Having defined a normal form game, we can now apply standard game-theoretic solution concepts. Let Γ = hX, P, r, P X i be a candidacy game, and let s be a state in Γ .
We say that a coalition Z ⊆ X has an improving move in s if there is s′Z such that
Γ (s−Z , s′Z ) is preferred to Γ (s) by every z ∈ Z. In particular, the improving move is
unilateral if |Z| = 1. A state is a (pure strategy) Nash equilibrium (NE) if it has no
unilateral improving moves, and a k-NE if no coalition with |Z| ≤ k has an improving
move. A strong Nash equilibrium (SE) [1] is a state with no improving moves.
Example 1. Consider the game h{a, b, c, d}, P, r, P X i, where r is the Borda rule, and
P and P X are as follows:6
11
b c
dd
aa
c b
5

6

P
11
ca
dc
b b
ad

1
d
a
c
b

1
b
c
d
a

1
a
b
c
d

PX
ab c
ab c
dab
bda
c cd

d
d
a
c
b

When clear from the context, we use vector s to also denote the set of candidates Y that corresponds to state s; e.g., if X = {x1 , x2 , x3 }, we note {x1 , x3 } and (1,0,1) interchangeably.
In our examples, when the tie-breaking ordering is not specified it is assumed to be lexicographic. We generally omit curly brackets. The first row in P indicates the number of voters
casting the different ballots. We use the common convention of writing votes vertically, with
the topmost candidate being preferred.

The state (1,1,1,1) is not an NE: abcd 7→ c, but abc 7→ a, and d prefers a to c, so for
d, leaving is an improving move. Now, (1,1,1,0) is an NE, as noone has an improving
move neither by joining (d prefers a over c), or by leaving (obviously not a; if b or c
leaves then the winner is still a). It can be checked that this is also an SE.
2.4 Preliminary results
Regardless of the number of voters and the voting rule used, a straightforward observation is that a candidacy game with three candidates is guaranteed to possess an NE.
Note that this does not hold for SE.7
The first question which comes to mind is whether examples showing the absence
of NE transfer to larger set of candidates. They indeed do, under an extremely mild
assumption. We say that a voting rule is insensitive to bottom-ranked candidates (IBC)
if given any profile P over X = {x1 , . . . , xm }, if P ′ is the profile over X ∪ {xm+1 }
obtained by adding xm+1 at the bottom of every vote of P , then r(P ′ ) = r(P ). This
property is extremely weak (much weaker than Pareto efficiency) and is satisfied by
almost all ‘common’ voting rules.
Lemma 1. For any voting rule r satisfying IBC, if there exists Γ = hX, P, r, P X i with
no NE, then there exists Γ ′ = hX ′ , P ′ , r, P Y i with no NE, where |X ′ | = |X| + 1.
Proof. Take Γ with no NE, with X = {x1 , . . . , xm }. Let X ′ = X ∪ {xm+1 }, P ′ the
′
profile obtained from P by adding xm+1 at the bottom of every vote, and P X be the
candidate profile obtained by adding xm+1 at the bottom of every ranking of a candidate
xi , i < m, and whatever ranking for xm+1 . Let Y ⊆ X. Because Y is not an NE for
Γ , some candidate xi ∈ X has an interest to leave or to join, therefore Y is not an NE
either for Γ ′ . Now, consider Y ′ = Y ∪ {xm+1 }. If xi ∈ X has an interest to leave
(resp., join) Y , then because r satisfies IBC, the winner in Y ′ \ {xi } (resp., Y ′ ∪ {xi })
is the same as in Y \ {xi } (resp., Y ∪ {xi }), therefore xi ∈ X has an interest to leave
(resp., join) Y ′ , therefore Y ′ is not an NE.

We will use this induction lemma to extend some of our negative results to an arbitrary number of candidates. A noticeable exception is the veto rule, which does not
satisfy IBC. In Appendix A we provide a specific lemma to handle this rule.
The following result applies to any number of candidates and Condorcet-consistent
rules.
Proposition 1. Let Γ = hX, P, r, P X i be a candidacy game where r is Condorcetconsistent. If P has a Condorcet winner c then for any Y ⊆ X,
Y is an SE ⇔ Y is an NE ⇔ c ∈ Y .
The very easy proof can be found in Appendix A. If P has no Condorcet winner, the
analysis becomes more complicated. We provide results for this more general case in
the following sections.
7

Here is a counterexample (communicated to us by Markus Brill). The selection rule is abc 7→
b; ab 7→ a; ac 7→ c; bc 7→ c; it can be easily implemented by the scoring rule with scoring
vector (5, 4, 0i with 5 voters. Preferences of candidates are: a : a ≻ b ≻ c; b : b ≻ c ≻ a; c :
c ≻ a ≻ b. The group deviations are: in {a, b, c}, c leaves; in {a, b}, b leaves and c joins; in
{a, c}, b joins; in {b, c}, a joins; in {a}, c joins; in {b}, c joins; in {c}, a and b join.

3 The first frontier: four candidates
With only four potential candidates, we exhibit a sharp contrast between the Condorcetconsistent rules, for which a Nash equilibrium is guaranteed to exist (for odd n), and
many other voting rules.
3.1 Scoring rules
We make use of a powerful result by Saari [16] which states that for almost all scoring
rules, any choice function can result from a voting profile. For four candidates [17], we
define a Saari rule as a rule for which, when the scoring vector for three candidates is of
the form hw1 , w2 , 0i, then the vector for four candidates is not h3w1 , w1 + 2w2 , 2w2 , 0i.
For instance, plurality and veto are Saari rules, but the Borda rule is not a Saari rule. For
any Saari rule, any choice function can result from a voting profile [16,17]. This means
that our question boils down to check whether a choice function, together with some
coherent candidates’ preferences, can be found such that no NE exists with four candidates. We solved this question by encoding the problem as an Integer Linear Program
(ILP), the details of which can be found in Appendix B.
It turns out that such choice functions do exist. We depict one of them in Figure 1
(where arrows denote deviations and the right part of each cell denotes the winner),
which rules out the existence of an NE when taken with the candidates preferences:
a:a≻b≻c≻d
b: b≻a≻c≻d
c: c≻d≻a≻b
d:d≻a≻b≻c

abcd|d

abc|c

ab|a

a|a

abd|b

ad|d

ac|c

b|b

acd|a

cd|c

bcd|d

bc|b

c|c

Fig. 1. A choice function without NE

The following result then follows directly.

bd|b

d|d

Proposition 2. For four candidates, if r is a Saari rule, there are candidacy games
without Nash equilibria.
As a corollary, we get that:
Corollary 1. For plurality, veto (and more generally, for k-approval with any k), there
are candidacy games without NE.
Note that Saari’s result shows that counter-examples can be obtained for all these
scoring rules, but it does not directly provide the profile satisfying this choice function.
These profiles may involve a large number of voters. For plurality, we exhibit a profile
with 13 voters corresponding to the choice function given in Fig. 1, whose preferences
are shown on the left part of the table below. The right part of the table represents P X .
31
dd
c b
ac
ba

1
d
a
b
c

1
a
b
c
d

1
a
c
b
d

1
a
d
b
c

1
b
c
d
a

2
b
a
c
d

2
c
b
d
a

ab
ab
ba
c c
dd

c
c
d
a
b

d
d
a
b
c

Similar profiles can be obtained for other Saari rules. As for the Borda rule, which is
not a Saari rule, it stands as an exception:
Proposition 3. For Borda and m = 4, every candidacy game has an NE.
This result was obtained by a translation into an integer linear program, then run on
a computer. It relies on the fact that Borda rule can be computed from the weighted
majority graph, and by adding the corresponding constraints into the ILP (for the details
of this ILP, see Appendix B). The infeasibility of the resulting set of constraints shows
that no instances without NE can be constructed.
However, it takes only coalitions of pairs of agents to ruin this stability. Indeed, for
Borda and m = 4, there are candidacy games without 2-NE. This can be seen on the
following candidacy game:
11111abcd
b cdabab cd
ddab c caab
cac cddcda
ab bdabdb c
Only s1 = (0, 1, 1, 1) and s2 = (1, 1, 0, 1) are NE, with bcd 7→ b, and abd 7→ d. From
s1 the coalition {a, c} has an improving move to s2 as they both prefer d to b. From s2 ,
if b leaves and c joins, they reach (1, 0, 1, 1), with acd 7→ c and both prefer c to d.
3.2 Rules based on successive elimination
Let us now focus on plurality with runoff and single transferable vote. For these rules,
it is no longer the case that any choice function can be implemented by such rules. For
instance, for plurality with runoff, a necessary condition for the choice function to be
implementable is that, for any subset of candidates Y , |Y | ≥ 3, if r(Y ) = x, then

x must win in pairwise comparison against some candidate y ∈ Y \ {x}. For STV, a
stronger condition is even required: for any subset of candidates Y , if r(Y ) = x, it must
be the case that r(Z) = x for some set Z ⊂ Y such that |Z| = |Y − 1|.
We make no claim that these conditions are sufficient to ensure a possible implementation. However, by adding these constraints into our ILP, we generated a choice
function that we could in turn implement with a specific profile, thus providing us the
following result.
Proposition 4. For plurality with runoff and single transferable vote and m = 4, there
are candidacy games without NE.
Proof. We exhibit a counter-example with 9 voters. The tie-breaking is d ⊲ a ⊲ c ⊲ b.
11
aa
cd
b b
dc

1
b
a
c
d

1
b
c
a
d

1
b
d
c
a

1
c
b
d
a

1
c
d
a
b

1
d
a
b
c

1
d
c
a
b

ab
ab
ba
dc
cd

c
c
a
b
d

d
d
a
c
b


3.3 Condorcet-consistent rules
We now turn our attention to Condorcet-consistent rules. We recall that we assume the
number of voters n to be odd.
Proposition 5. For m = 4 (and n odd), if r is Condorcet-consistent then every candidacy game has an NE.
Proof. For any profile P , let GP the complete tournament obtained from the majority
graph associated with P . Although we do not assume that r is based on the majority
graph, we nevertheless prove our result by considering all possible tournaments on four
candidates (we shall get back to this point at the end of the proof). In the proof, when
we speak of an “NE in G” we mean an NE in any candidacy game for which the profile
P is associated with the majority graph G. There are four tournaments to consider (all
others are obtained from these ones by symmetry).
a

b

a

b

a

b

a

b

c

d

c

d

c

d

c

d

G1

G2

G3

G4

For G1 and G2 , any subset of X containing the Condorcet winner is an NE (see
Proposition 1). For G3 , we note that a is a Condorcet loser. That is, N (a, x) < N (x, a)
for all x ∈ {b, c, d}. Note that in this case, there is no Condorcet winner in the reduced
profile P ↓{b,c,d} as this would imply the existence of a Condorcet winner in P (case G1
or G2 ). W.l.o.g., assume that b beats c, c beats d, and d beats b. W.l.o.g. again, assume

that bcd 7→ b. Then, {b, c} is an NE. Indeed, in any set of just two candidates, none has
an incentive to leave. Now, a or d have no incentive to join as this would not change the
winner: in the former case, observe that b is the (unique) Condorcet winner in P ↓{a,b,c} ,
and the latter follows by our assumption. There is always an NE for G3 .
The proof for G4 is more complex and proceeds case by case. Since r is Condorcetconsistent, we have acd 7→ a, bcd 7→ c, ab 7→ b, ac 7→ a, ad 7→ a, bc 7→ c, bd 7→ d and
cd 7→ c. The sets of candidates for which r is undetermined are abcd, abc and abd.
We have the following easy facts: (i) if abcd 7→ a then acd is an NE, (ii) if abcd 7→ c
then bcd is an NE, (iii) if abc 7→ a then ac is an NE, (iv) if abd 7→ a then ad is an NE,
(v) if abc 7→ c then bc is an NE. The only remaining cases are:
1.
2.
3.
4.

abcd 7→ b, abc 7→ b, abd 7→ b.
abcd 7→ b, abc 7→ b, abd 7→ d.
abcd 7→ d, abc 7→ b, abd 7→ b.
abcd 7→ d, abc 7→ b, abd 7→ d.

In cases 1 and 3, ab is an NE. In case 2, if a prefers b to c then abc is an NE, and if
a prefers c to b, then bcd is an NE. In case 4, if a prefers c to d, then bcd is an NE; if
b prefers a to d, then ad is an NE; finally, if a prefers d to c and b prefers d to a, then
abcd is an NE. To conclude, observe that the proof never uses the fact that two profiles
having the same majority graph have the same winner.8

Thus, the picture for four candidates shows a sharp contrast. On one hand, we show
that “almost all scoring rules” [16], single transferable vote, and plurality with run-off,
may fail to have an NE. On the other hand, Condorcet-consistency alone suffices to
guarantee the existence of an NE.

4 The second frontier: five candidates
We start with scoring rules. Recall that for four candidates we had the non-existence
results for most rules, with Borda being a noticeable exception. We now show that five
candidates is enough for Borda to lose this guarantee of the existence of NE.
Proposition 6. For the Borda rule, with five candidates, there are candidacy games
without Nash equilibria.
Proof. The following counterexample has been obtained by applying the same ILP
technique as described in the previous section. We do not give the profile but only
its majority margin matrix, where the number corresponding to row x and column y is
NP (x, y) − NP (y, x); by Debord’s theorem [5], the existence of a profile P realizing
this matrix is guaranteed because all elements of the matrix have the same parity.
8

For instance, we may have two profiles P , P ′ both corresponding to G4 , such that r(P ) = a
and r(P ′ ) = b; the proof perfectly works in such a case.

a b c d e abcde
a − −3 −1 +1 +3 a b c d e
b +3 − −5 +1 −1 b a a c c
c +1 +5 − −5 −1 e e d e d
d −1 −1 +5 − −3 c c e a a
e −3 +1 +1 +3 − d d b b b
Below we give the explicit listing of all 31 states, introducing a notation that we shall
use throughout the paper: the outcome of the choice function (the winner in each state)
is given in boldface, and a deviation from this state is given next to each state, where
x+ (respectively x−) means that x has a profitable deviation by joining (respectively,
by leaving) this state. It can be seen that none of the 31 states is an NE.

a b+
b c+
c d+
d e+
e a+

ab c+
ac d+
ad b+
ae b+
bc d+
bd e+
be c+
cd e+
ce a+
de a+

abc d+
abd c+
abe c+
acd c−
ace e−
ade b+
bcd e+
bce b−
bde a+
cde a+

abcd e+
abce b−
abde c+ abcde b−
acde e−
bcde d−


Recall that for Condorcet-consistent rules, the existence of NE is guaranteed for
four candidates. For the maximin rule and the uncovered set rule, this existence result
stops at four. The proof, consisting of two counterexamples, is in Appendix A.
Proposition 7. For the maximin rule and the uncovered set rule, with five candidates,
there are candidacy games without NE.
However, this negative result does not extend to all Condorcet-consistent rules, as
shown in Proposition 8 below (and also in Proposition 9 in the following section).
Proposition 8. For the Top-Cycle rule, with five candidates, every candidacy game has
a Nash equilibrium.
Proof. Let P be a profile over X = {a, b, c, d, e} and without loss of generality, assume
that the tie-breaking priority ranks a above all other candidates. If |T C(P )| ≤ 4 then
consider the restriction P ↓T C(P ) of P to T C(P ). It is a q-candidate profile for q ≤ 4,
therefore by Proposition 5 the corresponding candidacy game has an NE Z ⊆ T C(P ).
Because it is an NE in P ↓T C(P ) , no candidate in T C(P ) has an incentive to deviate.
Now, if a candidate in X \ T C(P ) joins, the outcome does not change, therefore no
candidate outside T C(P ) has an incentive to join. Therefore, Z is an NE for P .

Assume now that T C(P ) = {a, b, c, d, e}; this implies T Ct (P ) = a. Without loss
of generality, assume the majority graph contains a → b → c → d → e → a. For abcde
not to be an NE, a withdrawing agent x has to induce a new top-cycle not containing a.
If this top-cycle is a singleton, then X \ {x} is an NE. Therefore, the top-cycle after the
withdrawal of x must be of size 3: it can only be {c, d, e}, with b withdrawing because
it prefers the most prioritary candidate (let us call it y) among {c, d, e} to a. At this
stage, we know that d → a, c → a, e → a, c → d → e → c, and that the winner in
acde is y. Observe that, irrespective of the tie-breaking winner, a cannot leave because
the winner would remain the same. There are thus three cases to consider:
– Case 1: y = c. Consider acd 7→ c. Since ac 7→ c, cd 7→ c, and acde 7→ c, acd is
not an NE only if b wants to join; but abcd 7→ a, and b prefers c to a: bcd is an NE.
– Case 2: y = e. Consider ace 7→ e. Since ae 7→ e, ce 7→ e, and acde 7→ e, ace is
not an NE only if b wants to join. For this to be possible, we must have b → e, and
then abce 7→ a. But in this case, since abc 7→ a, abe 7→ a, and abcde 7→ a, abce is
an NE. Therefore, either ace or abce is an NE.
– Case 3: y = d. Consider ade 7→ d. Since ad 7→ d, de 7→ d and acde 7→ d, ade is
not an NE only if b wants to join. For this to be possible, it must be that b → d (and
b prefers a over d). Thus abde 7→ a. In this case, since abd 7→ a and abcde 7→ a,
abde is not an NE only if d wants to leave. This is possible only if e → b (and d
prefers e over a). But then abe 7→ e, ae 7→ e, be 7→ e, and abce 7→ e: abde is an
NE. Therefore, either ade or abde is an NE.


5 More candidates
In this section, we present our results for a general number of candidates.
5.1 A positive result: Copeland
We show the existence of NE for Copeland, under deterministic tie-breaking, for any
number of candidates (provided n is odd).
Proposition 9. For Copeland, for any number of candidates and an odd number of
voters, every candidacy game has an NE.
Proof. Let P be a profile and →P its associated majority graph. Let C(x, P ) be the
number of candidates y 6= x such that x →P y. The Copeland cowinners for P are the
candidates maximizing C(·, P ).
Let Cop(P ) be the set of Copeland cowinners for P and let c be the Copeland
winner—i.e., the most prioritary candidate
in Cop(P ). Consider Dom(c) = {c} ∪

{y|c →P y}. Note that C c, P ↓Dom(c) = |Dom(c)| − 1 = q ≥ C(c, P ). Also, since
any y ∈ Dom(c) is beaten by c, we have C(y, P ↓Dom(c) ) ≤ q − 1.
We claim that Dom(c) is an NE. Note that c is a Condorcet winner in the restriction
of P to Dom(c), and a fortiori, in the restriction of P to any subset of Dom(c). Hence,
c is the Copeland winner in Dom(c) and any of its subsets, and no candidate in Dom(c)
has an incentive to leave.


Now, assume there is a candidate z ∈ X \Dom(c) such that r P ↓Dom(c)∪{z} 6= c.
Note that z →P c as z does not belong to Dom(c); so, C(c, P ↓Dom(c)∪{z} ) = q.
For any y ∈ Dom(c) we have C(y, P↓Dom(c)∪{z} ) ≤ (q − 1) + 1 = q =
C(c, P ↓Dom(c)∪{z} ). If C y, P ↓Dom(c)∪{z} < C(c, P ↓Dom(c)∪{z} ), then y is not the


Copeland winner in P ↓Dom(c)∪{z} . If C y, P ↓Dom(c)∪{z} = C c, P ↓Dom(c)∪{z} ,
then C(y, P ) ≥ C(c, P ). That is, either c ∈
/ Cop(P ), a contradiction, or both y, c
are in Cop(P ). The latter implies c ⊲ y; hence, y is not the Copeland winner in
P ↓Dom(c)∪{z} .


Hence, r P ↓Dom(c)∪{z} = z. That is, either (1) C z, P ↓Dom(c)∪{z} > q, or

(2) C z, P ↓Dom(c)∪{z} = q and z ⊲ c. If (1) holds then C(z, P ) > C(c, P ), which
contradicts the fact that c is the Copeland winner in P . If (2) holds then C(z, P ) =
C(c, P )—i.e., both c and z are in Cop(P ), which implies that c ⊲ z, and z cannot win
in P ↓Dom(c)∪{z} . Therefore, the Copeland winner in P ↓Dom(c)∪{z} is c, which implies
that z has no incentive to join Dom(c).

Note that not only the existence of an NE is guaranteed, but also the existence of an
NE where the winner is the same winner as on the original profile (that is, the Copeland
winner of the profile with all candidates running).9
When n is even, the result carries on if no pairwise majority ties occur. In the general
case, however, the result depends on the way ties are taken into account for computing
the Copeland score of a candidate. For the variant Copeland0 where the Copeland score
remains the number of outgoing edges (ties not giving any point), the result still holds.
Whether it holds for other variants is an open question.
5.2 Top Cycle
Proposition 10. For the Top-Cycle rule, with six candidates, every candidacy game has
an NE, and with seven candidates, there are candidacy games without an NE.
Both results have been obtained by computer search. Technically, we first pruned the
domain to reduce the number of majority graphs to consider. Then, for each remaining
graph, we computed the co-winners given by the top-cycle rule, and we launched a
feasibility problem asking the computer to build an instance without equilibrium. This
is similar in spirit to the ones used in previous sections, but including additional decision
variables for the tie-breaking ordering (and making sure that winners are indeed among
the co-winners). For the six candidate case, the infeasibility of the program tells us
that an equilibrium always exists, but we could not extract any readable proof from the
result.10 The counterexample for seven candidates is given in Appendix A.
9

10

Note however that this does not imply that the set of all candidates is an NE. For instance,
let X = {a, b, c, d}, and consider the majority graph a → b, a → c; b → c, b → d; d →
a, d → c, with the tie-breaking priority relation a ⊲ b ⊲ c ⊲ d. The Copeland winner is a (by
tie-breaking). We only need to specify that b : d ≻ a on top of self-supported preferences. X
is not an NE, because it is a profitable deviation for b to leave.
Note that this positive result holds as well for the Banks rule, since Top-Cycle and Banks do
coincide up to six candidates [3].

5.3 More negative results by induction
For all rules that satisfy IBC and for which we have already found a counter-example for
m, we know that counterexamples exist for any number of candidates. As we previously
noted, veto is an example of a rule not satisfying IBC, but an adapted version of Lemma
1 can easily be designed (see Lemma 2 in Appendix). As a corollary of these, and of
Propositions 1, 4, 7, 6 and 10 we get:
Corollary 2. There exists profiles with no NE in the following cases:
– For all Saari scoring rules satisfying IBC (including plurality), as well as for veto,
for all m ≥ 4.
– For plurality with runoff and single transferable vote, for all m ≥ 4.
– For Borda, maximin, and the uncovered set, for all m ≥ 5.
– For TopCycle, and for all m ≥ 7.

6 Strong Equilibria and Link to Control
6.1 Strong Nash Equilibria
We now prove that the lack of guarantee for the existence of strong Nash equlilibria
holds for almost any voting rule and any number of candidates m ≥ 3.
Let r be a voting rule defined for a varying set of candidates Y ⊆ X. We say that r
is majority-extending if for any Y ⊆ X such that |Y | = 2 and if the two candidates in
Y are not tied in P ↓Y then r(P ↓Y ) is the majority winner in P ↓Y (in case of a tie, we
don’t need to specify the outcome).
Proposition 11. There does not exist any majority-extending and IBC rule that guarantees the existence of an SE at every profile.
Proof. Let r be a majority-extending and IBC rule. Consider the following 3-voter,
k + 3-candidate profile (k ≥ 0):
1
a
b
c
x1
..
.
xk

1
b
c
a
x1
..
.
xk

1
c
a
b
x1
..
.
xk

By a repeated application of IBC, for any nonempty Y ⊆ {a, b, c} and any Z ⊆
{x1 , . . . , xk } we have r(P ↓Y ∪Z ) = r(P Y ).
We already know that r(P ↓{a,b,c,x1 ,...,xk } ∈ {a, b, c}. Without loss of generality,
assume that r(P ↓{a,b,c,x1 ,...,xk } ) = a. For any Z ⊆ {x1 , . . . , xk }, by IBC and majorityextension, the resulting choice function must be:
abcZ 7→ a; abZ 7→ a; bcZ 7→ b; acZ 7→ c; aZ 7→ a; bZ 7→ b; cZ 7→ c
But then, given the candidates’ preferences, for any Z ⊆ {x1 , . . . , xk } we have:

–
–
–
–
–
–
–
–

abcZ is not an SE: abcZ 7→ a, b leaves 7→ c
abZ is not an SE: abZ 7→ a, b leaves and c joins 7→ c
acZ is not an SE: acZ 7→ c, a leaves and b joins 7→ b
bcZ is not an SE: bcZ 7→ b, a joins 7→ a
aZ is not an SE: aZ 7→ a, c joins 7→ c
bZ is not an SE: bZ 7→ b, a joins 7→ a
cZ is not an SE: cZ 7→ c, b joins 7→ b
Z is not an SE: any of a, b or c wants to join.



The result applies to most common voting rules.11
6.2 Relation to Control
Bartholdi et al. [2] define constructive control by deleting candidates (CCDC) and constructive control by adding candidates (CCAC): an instance of CCDC consists of a
profile P over set of candidates C, a distinguished candidate c, an integer k, and we ask
whether there is a subset C ′ of C with |C \ C ′ | ≤ k such that c is the unique winner
in C ′ . An instance of CCAC consists of a profile P over set of candidates C1 ∪ C2 , a
distinguished candidate c, and we ask whether there is a subset C ′ of C2 such that the
unique winner in C1 ∪ C ′ is c. Destructive versions of control are defined by Hemaspaandra et al. [11]: destructive control by deleting (DCDC) is similar to CCDC, except
that we ask whether there is a subset C ′ of C \ {c} with |C \ C ′ | ≤ k such that c is not
the unique winner in C \ C ′ ; and destructive control by adding candidates (DCAC) is
similar to CCAC, except that c should not be the unique winner in C ′ . There are also
multimode versions of control [10]: e.g., CC(DC+AC) allows the chair to delete some
candidates and to add some others (subject to some cardinality constraints).
Nash equilibria and strong equilibria in strategic candidacy relate to a slightly more
demanding notion of control, which we can call consenting control, and that we find an
interesting notion per se. In traditional control, candidates have no preferences and no
choice—the chair may add or delete them as he likes. An instance of consenting CCDC
consists of an instance of CCDC plus, for each candidate in C, a preference ranking
over C, and we ask whether there is a subset C ′ of C with |C \ C ′ | ≤ k such that c
is the unique winner in C ′ , and every candidate in C \ C ′ prefers c to the candidate
which would win if all candidates in C were running. An instance of consenting CCAC
consists of an instance of CCAC plus, for each candidate in C2 , a ranking over C1 ∪ C2 ,
and we ask whether there is a subset C ′ of C2 such that c is the unique winner in
C1 ∪C ′ and every candidate in C ′ prefers c to the candidate which would win if only the
candidates in C1 were running. Consenting versions of destructive control are defined
similarly: here the goal is to have a different candidate from the current winner elected.
Clearly, for profile P , (1, . . . , 1) is an SE iff there is no consenting destructive control by removing candidates against the current winner r(X), with the value of k being
fixed to m (the chair has no limit on the number of candidates to be deleted; the limits
come here from the fact that the candidates must consent), and (1, . . . , 1) is an NE iff
11

A noticeable exception is veto; however, we already know that for veto, there exist profiles
without NE, and therefore without SE.

there is no consenting destructive control by removing candidates against the current
winner r(X), with the upper bound of k = 1 on the number of candidates to be deleted.
For candidate sets that are different from the set X of all candidates (as some may
leave and some other may join), we have to resort to consenting destructive control by
removing and adding candidates, as in [10]. Let s be a state and Xs the set of running
candidate in s: s is an SE if there is no consenting destructive control by removing
and adding candidates against the current winner r(Xs ), without any constraint on the
number of candidates to be removed or added. For an NE, this is similar, but with the
bound k = 1 on the number of candidates to be deleted or added.

7 Conclusions
We have explored further the landscape of strategic candidacy in elections by obtaining
several positive results and several negative results which can be summarized on the
following table, where “yes∗ ” means yes under the assumption that n is odd, or more
generally that pairwise ties do not occur.
plurality
veto
pl. runoff
STV
Borda
maximin
UC
TC
Copeland

3
yes
yes
yes
yes
yes
yes
yes
yes
yes

4
no
no
no
no
yes
yes∗
yes∗
yes∗
yes∗

5-6
no
no
no
no
no
no
no
yes∗
yes∗

≥7
no
no
no
no
no
no
no
no
yes∗

An important issue for further research is a characterization of all rules for which
the existence of a pure Nash equilibrium is guaranteed, at least for an odd number
of voters. We know that not only it contains Copeland, as well as the rule defiend by
the sophisticated winner of the successive elimination rule; these two rules do not have
much in common, which suggests that such a characterization could be highly complex.
Another issue is the study of the set of states that can be reached by some (e.g.
best response) dynamics starting from the set or all potential candidates. In some cases,
even when the existence of NE is guaranteed (e.g. for Copeland), we could already
come up with examples such that none is reachable by a sequence of best responses.
But other types of dynamics may be studied. Another issue for further research is the
computational complexity of deciding whether there is an NE or SE.
Finally, a recent line of research, dealing with a setting where not only candidates,
but also voters, are strategic players, has been investigated by Brill and Conitzer [4].

Acknowledgements
We would like to thank Markus Brill, Edith Elkind, Michel Le Breton and Vincent
Merlin for helpful discussions.





level, with the condition that violating however many
formulas at a given level is always more acceptable

Penalty logic, introduced by Pinkas

[17],

than violating only one formula at a strictly higher

as­

sociates to each formula of a knowledge base

level:

the price to pay if this formula is violated .

e.,

z.

Penalties may be used as a criterion for se­

apparently very appealing (besides it has already been

consistent knowledge base, thus inducing a

used several times in the literature) consists in weight­

A pre­

ing formulas with positive numbers called

cise formalization and the main properties
of penalty logic and of its associated non­

since they are

additive:

ties of the rejected formulas. Moreover, inviolable (or
unrejectable) formulas are given an infinite penalty.
The additive combination of penalties leads to an in­

pecially in the infinitesimal case.

terpretation in terms of

itarist,

Introduction
appears when

the available knowledge base - KB for short - (here
a set of propositional formulas) is inconsistent. Most
approaches come up with the inconsistency by select­
ing among the consistent subsets of KB some

preferred

subsets; the selection criterion generally makes use of
uncertainty considerations, sometimes by using explic­
itly uncertainty measures (such as W ilson
ferhat and Smets

[2)),

expressed qualitatively as
back to Rescher

[20] and

priorities

(the idea comes

[3],

Nebel

[16],

Benferhat, Cayrol, Dubois, Lang, Prade

Lehmann

[14]).

Ben­

has been developed by many

authors, among them Brewka

[4],

[2 7 ] ,

or more often using measures

Cayrol

[1]

and

Although these priorities are gener­

ally not given a semantics in terms of uncertainty mea­
sures (however see

[1]

for a comparative study of the

priority-based and possibilistic approaches to inconsis­
tency handling), their intuitive interpretation is clearly
in terms of gradual uncertainty: the least prioritary
formulas

( i.e., the

ones which are most likely to be re­

jected in case of inconsistency) are clearly the ones we
are the least confident in, i.e., the least certain ones.

cost,

thus this criterion is

util­

contrarily to priority-based approaches which

are rather

inconsistency handling

the global penalty for rejecting

a set of formulas is the sum of the elementary penal­

first part. We also show that penalty logic
and Dempster-Shafer theory at·e related, es­

The problem of

penalties.

Contrarily to priorities, penalties are compensatory

monotonic inference relation are given in the

1

non-compensatory,

An alternative approach, more or less empirical but

lecting preferred consistent subsets in an in­
non-monotonic inference relation.

thus these approaches are

levels never interact.

egalitarist.

This additive criterion is very in­

tuitive, since rejecting a formula generally causes some
"additive" trouble with the experts which provided the
f{ B with the formulas, or some real financial cost, or

another kind of additive cost. Note that a degenerate
case of penalties (all penalties being equal to

1) prefers

subsets of maximum cardinality. Moreover, and as we
will see later, these penalties can sometimes be inter­
preted as the "probability of fault" of the source which
provided us with the information (all sources failing in­
dependently), up to a logarithmic transformation. In
any case, these penalties can be viewed as measuring

uncertainty

since, again, the less expensive to reject,

the more uncertain the piece of information.
penalty logic

Thus,

expresses uncertainty in terms of costs.

However a formal connection of penalties with classical
theories of uncertainty has not really been made.
Penalty-based approaches have been already used sev­
eral times in the literature, first by Pinkas

91 [17] (from

whom we borrowed the terminology "penalty") who
uses them for inconsistency handling and for mod­
elling symmetric neural networks behavior, and also

All aforementioned priority-based approaches consist

by Eiter and Gotlob 94 [10] for cost-based abduction,
by Sandewall 92 [21] for cost-based minimization of

the set

Satisfaction Problems. Moreover, penalties associated

in ranking the f{ B in n priority levels (assume that 1
is the highest priority and n the lowest) and maximize

or

the number of formulas satisfied at each

surprises in temporal reasoning and by Freuder and
Wallace

[12]

for tackling inconsistencies in Constraint

Penalty Logic and its Link with Dempster-Shafer Theory

to formulas have also been used for guiding the search
in randomized algorithms dedicated to the satisfiabil­
ity problems, such as GSAT [23, 22].

Lastly, there

should clearly be a link between penalties and utility
theory (the latter has been recently used in AI, espe­
cially in decision-theoretic planning - see e.g. [18]);
however, in this paper we do not investigate this pos­
sible link.

205

Since PK is a multi-set of pairs (and not a. set), it. is
possible for a pair{'{), a:) to appear several times in PI\;

for example, PK = {{a, 1), {a, 1)} is not equivalent to
PK' = {{a, 1}} since using PK, it costs 2 to delete a
'
and using P K , it costs only 1.
However, as we will see in 2.1.4, if a formula'{) appears
several times in PK then we may replace all the occur­
rences of the formula 'P by only one occurrence of 'P

In this paper we revisit penalties by giving a further

formalization of Pinkas' work; we also go further in the

annotated with the sum of the penalties associated to
this formula in the previous base. The new knowledge

theoretical study of penalty-based inconsistency han­

base obtained is equivalent to the initial base.

dling and non-monotonic reasoning.

We briefly give

a formalization in penalty logic of an additive
problem. Lastly, we establish

a

O.R.

link between penalties

and Dempster-Shafer theory; this link is twofold: first,
the penalty function (on interpretations) is equivalent,
up to a log- transformation, to a contour function (i.e.,
the plausibility function restricted to singletons); then
penalty functions on formulas coincide with plausibil­
ity functions of an infinitesimal t'ersion of Dempst.er­
Shafer theory.

2

based on a finite number of propositional variables. T

.2' wi ll be writt e n '{), 1j!, etc.
The set of interpretations attached to .2' will be de­
noted by n, and an interpretation by w. 'P F= 1/! and
Formulas of

'P f=l'lj! will represent logical consequence and logical
equivalence between the formulas

I==

'P and 1/! respectively.

will also be used between an interpretation and a
formula to denote satisfiahility. The set of models of
a formula 'P will be denoted by M ( 'P); the set of for­
mulas of .2' satisfied by w, i.e., {'P I w I== 'P} will be
denoted by [w].

A classical knowledge base 91 is a set of formulas of
.2'. A sub-theory of 91 is a consistent subset of §9. A

§9 is a consistent subset of 91
T, T U { 'P} is inconsistent. Given

maximal sub-theory T of
such that 'if'{) E 91 \

a formula 1/!, T is said 'ljl-consistent iff T U { 1j!} is c o n­
sistent; Tis maximal'lj!-consistent if it is 1/J-consistent

and V'P E §9 \ T, T U { '{), 1/!} is inconsistent. w+ will
be the union of the set of all the strictly positive real
particular, if

{ +oo}, equipped with the usual order
#- +oo then a: < +oo).

a:

(in

A penalty knowledge base PK is a finite multi-set of
pairs {'P;, a:; ) where '{); E .2' and a:; E w+. a; is the
penalty associated to 'Pi; it represents intuitively what
we s hould pay in order to get rid of 'Pi, if we pay the

requested price we do not need any longer to satisfy
'Pi; so the larger

a:;

In particular, if a:;

move

the p en al ti es ex;). Also, in the expressions sub-theory of
PK, subset of PK and PK \A we will refer to the set of

is, the more important 'Pi is.

:::

Cost of an interpretation

Let PK

and .l will represent taut ology and contradiction re­

numbers and

Lastly, we will say that PK E !JlJc is co nsistent if the set
of formulas 'Pi of PK is consistent ( without mentioning

=

{{'{);,a:;},i =

1

.. . n}

be a penalty knowl­

edge base.

following, .2' will be a propositional language

spectively.

violated).

2.1.1

Formal definitions

In the

logic comes down to classical logic (no formula can be

formulas obtained from PK by ignoring the pena.lties.

Penalty logic

2.1

91c will be the set of all the penalty knowledge bases.
Note that when the penalties are all infinite, penalty

+oo then it is forbidden to re­

i.p; from PK ('Pi is inviolable).

Definition 1 (Pinkas 91 [17]) The cost of an in­
w E Q with respect to PK , denoted by
kpK(w ), is equal to the sum of the penalties of the for­

terpretation

mulas zn PK violated by

(with

the

w:

corn,enfion L:1P,E0 a:;= 0)

Definition 2 A PK-preferred interpretation is an in­
terpretation of minimal cost w.r.t. PK, i.e. an inter­
pretation minimizing

kpl(.

As an example, let us consider the following penalty
k n owledge base P K1:

'PI =a
y2 =b v c
y3 = -.b
'P4 = -.c

0:1 = +oo
0:2

= 10
=5
0:4 = 7
0: 3

Here are the corresponding interpretations costs:

kpr<, ({-,a, b, c})
kpr<, ( {...,a, b, .....,c})
kpK,({a ,-,b,--.c})
kpK,({a,b,-.c})
kpK,({a,•b,c})
kPK,({a,b,c})

kpK, ({ •a, •b,c}) = +oo
kpK, ({ •a, •b, •c}) = +oo
10

5
7

5 + 7=

12

If the interpretations are decisions to make (for exam­
ple if the knowledge base is made of constraints con­
cerning the construction of a timetable), then a min­
imum cost interpretation corresponds to the cheapest

206

Dupin de Saint-Cyr, Lang, and Schiex

decision, i.e., the most interesting one. The cheapest
interpretation is generally not unique. Besides, if the
penalties are all equal to 1 then a cheapest interpreta­
tion satisfies a maximum consistent subset of PK w .r. t.
cardinality.
2.1.2

Cost of consistency of a formula

3 The cost of consistency of a formula r.p
with respect to PK, denoted by f{PK(cp), is the mini­
mum cost with respect to PK of an interpretation sat­
isfying r.p:
KpK(C,O) =min kpK(w)

Definition

wi='P

(with the convention min0 kPK(w)

=

+oo)

Example:

f{PK1 (a!\ b)
KpK,(a-+c)
KPK,(-.a)

7
+oo

KpK('f') of a formula r.p, is the minimal price
to pay in order to make PK consistent with cp. For
example, in order to make PK1 consistent with a -+ c,
the least expensive way is to remove r,o4.
+oo and J(PK ( T)

1 J(PK(l..)
minwEn{kPK(w)}

All proofs can be found (in French) in Dupin de Saint­
Cyr, Lang and Schiex 94 [8] and in Dupin de Saint-Cyr
93 [7).

KPK(l_) = +oo is easy to understand, because it is
impossible to have PK consistent with 1... Let us note
that /(pK ( T) is the cost of any PK-preferred inter­
pretation; it is thus the mini mum cost to make PK
consistent.
Property 2

KpK(T)

is inconsistent.

=

+oo

¢}

{cp;

E

PK,a;:::: +oo}

This quantity KPK(T) is important, because it mea­
sures the strength of the inconsistency of PK (i.e., how
expensive it will be to recover the consistency). If the
penalties are all equal to +oo then KpK(T) can only
take two values: 0 if and only if PK is consistent, and
+oo if and only if PK is inconsistent.
Example: J(PK, (T) = 5; the only minimum cost in­
terpretation is {a, b, -.c}. To make PK1 consistent, the
least expensive solution is to take off (or to ignore) the
formula 'f'3·
Property

3 /(pK(T)

=

1.

Property 4 'Vi.p, ¢ E .!f,

(cp f= ¢)

:::::}

KpJ<('P) 2:

'Vr,o, ¢

E

2:

KPK(IO !\ ¢) 2: max(I{pK('P), Kpr<(?/;))

2. KpK(\0

V

¢)

= mi n(KP K ( cp ) ,

KpK(¢ ))

3. f<pK(l..) 2: /{pK(IO) 2: f{pK(T)

Note that, up to its interval of definition and its or­
dering convention w.r.t. Proposition 5 (((0, +oo), ::::)
instead of ((0, 1), S)), /{pK is actually a possibil­
ity measure. Note also that Spohn's ordinal condi­
tional functions x: verify property 2 1. e. x:( A U B) =
min(x:(A), x:(B)) [26).
Cost of a sub-theory

Definition 4 (Pinkas 91 [17J) The cost CPK (A) of
a sub-theory A of PK, is the sum of the penalties of
the formulas of PK that are not in A:

{!f'.,<:>,)EPK\A
For instance, considering the knowledge base PK1,
given A1 = {i.pl,i.p2,'P3} and A2 = {r,o2,i.p4}, we have
CPK1 (Al) = a4 = 7 and CpK1 (A2) = 0:1 + a3 = +oo.
Definition 5

'VA, B � PK,

B 2:PK A (B is preferred to A) ifJCPK(B) S CPK(A).
'VA, B � PK , B >h A if and only if B 2:PK A and
not A 2:PK B.
Definition 6 (Pinkas 91 [17]) A � PK
ferred sub-theory relatively to PK

is

a

pre­

(or 2:PK­
preferred) if and only if A is consistent and ,3 B � PK ,
such that B is consistent and B >f,K A.

Note that there may be several preferred sub-theories
(in the previous example, { cp1, 'P2, 1p4} is the only one

2:PK1-preferred sub-theory).
Property 6

'VPK

E

fflc,

If J<pK(T) ::f +oo, then any 2:PK -preferred sub-theory
is a maximal sub-theory of PK w. r.t. inclusion.
•

0 ¢} PK is consistent.

Indeed, if KpK(T) = 0 then there is no need to delete
any formula in order to make PK consistent, therefore
PK is consistent (and conversely).

KPK(?/;)

Property 5

2.1.3

5

The cost

Property

This property is the monotonicity of K with respect to
classical entailment.

•

Let us notice that when KPK(T) = +oo, every
sub-theory of PK has an infinite cost, therefore
every sub-theory of PK is 2:PK-preferred, but ob­
viously every sub-theory is not necessarily maxi­
mal w.r.t. inclusion.
Besides, if PK is consistent, then I<PK(T) = 0,
and then the only >pK-preferred sub-theory of
PK is PK itself (its Zost is 0).

Example (continued): A3 = {r,ol,'f'2,'P4} is a 2:PK,­
preferred sub-theory and it is maximal w.r.t. inclusion.

207

Penalty Logic and its Link with Dempster-Shafer Theory

But, although {cp2,cp3,cp4} is a maximalsub-t.heory of
PK1 (w.r.t. inclusion), it is not 2:-PK,-preferred (be­
cause its cost is infinite).

If we add the formula

(cps

=

-,a, a5

=

+oo}

to

PK1

Besides, we define a pre-ordering relation <<c
as follows:
Definition 9

then the subset of infinite cost formulas is inconsistent,
therefore every sub-theory has an infi ni t e cost, and
a

every sub-theory is

preferred

PK

interpretation
cost of the sub­

theory of PK composed of all the formulas satisfying

w:

As

PK4

an example,

PK n

7.2 A is a maximal sub-theory of PK
Vw f= A, kpK(w) = CPK(A).
Corollary

7.3 KPK('P) is equal to the
of a 10-consistent sub-theory of PK:

Corollary

of a formula

minim11m cost

cp wit h respect to the

base PK is the cost of a cp-consist.ent

sub-theory of

=>

min
CrK(A)
.
A<;PI<,A '1"-conH•tent

Therefore, the cost

PK.

2:rK-preferred

7.4 VA � PK,

Corollary

A

is

a
¢::>

(cf. corollary

Definition

7.3,

2:PK -preferred sub-theory

KPK(T)

=

with cp =

7 Add(PK, cp)

CpJ<(A).

T).
=

PK U { (<p, +oo)}

10

ta.b}
_ia,-.bl
J-.a, bl
l...., a,...., bl

Therefore, the cost to make the knowledge base consis­
tent with a given formula, can be computed by adding
with

an

infinite penalty and then evalu­

ating the cost of the new knowledge base consistency.

Two

alent

Equivalence between penalty
knowledge bases
k n o w ledge bases are .semantically equiv­
if they i n d u ce the same cost function on 0, i.e.:

penalty

Definition 8 VPK, PK' E !fie,
PK �c PK'

PK:J, PK3
as

.

,

0

10
8
18

and

follows:

b

10

0

10
8

18

the fol­

0

18
18
18

So we have PK2 �c PK3 and PK3 «c
is not equivalent to PK4).

PI\4

(but Pl\3

N.B.: the previous example shows th at it is impos­
sible to transform equivalently a penalty knowledgr

base containing several non-equivalent formulas in a
penalty knowledge base containing the conjunction of
those formulas.

But, if a knowledge base contains se1'eral times the
same form1tla (or an eq11ivalent on e), it is possible to
transform it equi1•alent/y in a knowhdge base contain­
ing this formula only one time with a penalty equal to
the sum of the penalties of this form.ula in the prel•ious
base.
Property 9 VPK, PK' E :JlJc,

PK

2.2

2.1.4

consider

�c

PK'

=>

A{cpiJ�;

E

PK} f=ll\ {'PiliPi

E

PK'}

The con verse is obviously false.

Property 8

this formula

b

3

w

2:-PK·preferred sub-theory with respfCI to
all the sub-theories of PK

=

us

lowing:

<=>

KpK(rp)

let

The cost func t i ons incluceu by those bases are

E 0,

has a minimal cost U.'.r.f. PK

a

[w] is

less expensive than PK ')
$ kpK'

the penalty knowledge bases defined
PK2 :
PKa :
PI-.:4 :
a
5
18
a
8
a 1\

b

w

is

E !Jic,

¢:> kpK

a

Vw

PK' (PK

sub-theory.

Property 7 The cost kpK(w) of an
w E 0 with respect to PK is equal to the

Corollary 7.1

«c

VPK, PK'

on 5!�

(l>K is semantically equivalent to PK ')
{:::>

kpi<

==

kpw.

Inconsistency handling with penalty logic

Using penalties to handle inconsistency is a syntax­
based approach, in the sense of [16], which means that

the way a know ledge base be hav es is dependent on the
syntax of the input (this is justified by the fact that
each formula is considered as an independent piece of

information); for instance, {p,q,....,pY -,q} will not be­
have as {p 1\ q, ....,p Y ....,q}, since in the first. case we ca.n
re

move independently the formulas

{p,

p and q

( {p, q}.

p V -.q} and { q, ....,p Y ....,q} are the maximal sub­
theories), but in the second case we must rem ove or
....,

whole fo rm ula p 1\ q ( {p 1\ q} and { ...,p V -.q}
the maximal sub-theories).

keep the
are

In order to deal with inconsistency, the basic idea de­
veloped with syntax-ba.'led approaches is to define a

208

Dupin de Saint-Cyr, Lang, and Schiex

nonmonotonic inference relation as follows: 1/J can be
deduced nonmonotonicaly from a knowledge base iff
all the maximal sub-theories of this base entails (clas­
sically) 1/;.
2.2.1

Given

Nonmonotonic inference relation
induced by a penalty knowledge base

PK

E

Definition

�c·

10 'r/cp,1/J

E 2',

2.3

In this section, we will see that penalty logic is not
only a tool for inconsistency handling but also a good
way to represent, in a logical language, discrete opti­
mization problems (for instance issued from operation
research), in which minimum cost interpretations cor­
respond to optimum solutions.

We consider an undirected graph

¢}

'v'A � PK, if A is a ?:.PI< -preferred cp-consistent

sub-theory among all the cp-consistent sub-theories of
PK, then AU {cp} f= 1/J.

sub-graph

N.B.: 'r/1/;, ..L
Property

In penalty logic we can represent it like this:
•

1/J.

s

that this vertex

f---�K1/J.

10 'v'cp, 1/J

0, if w f=

to each vertex

sitional variable

•

2',

E

E U, we can associate

s

a

propo­

which truth assignation means

belongs to

the clique we are look­

minimum of vertices: to each vertex we associate
the penalty formula {s, 1).

f-.- �K 1/J

cp

we are searching for a set of vertices which is max­
imum for cardinality, so we have to exclude the

¢}

•

and w is a ?:.PI< -preferred
interpretation satisfying <p, then w f= 1./J.
E

every vertex is connected with every

ing for.

'P

'r/w

then A F=

(i.e.,

other vertex). Finding a maximum cardinality clique
is a classical N P-ha.rd problem in operational research.

In particular, if cp = T, the definition becomes:
f-.- � K1/J {:} if A is a ?:.PK-preferred sub-theory among

PK,

G, i.e., a set of ver­

tices U and a set of edges V connecting those vertices.
A clique of G is a subset of V which define a complete

cp f-.- �K1/J

all the sub-theories of

An application of penalty logic:
maximum clique in a graph

the resulting set

(x, y)

graph

must be a clique so for each pair

of vertices that are not connected in the

G (i.e., (x, y) � V), at least either

x

y

or

This property shows that the nonmonotonic inference

does not belong to the clique. In consequence, we

relation

can associate to each pair

f-.- �K

belongs to the set of relations based on

preferential models in the sense of [15]. As �Pl< is a
complete pre-ordering, we immediately get the follow­
ing result:

Property

Let

f-.- �K

11

relation1.
Property
'P

12 Given

* 1.,

zs

a

comparative

inference

(...,x V -,y, +oo).

formula

PK(G)

=

{(s, l),s

E

(x, y)

� V the penalty

U}U{(...,xV---.y,+oo),(x,y)

�

V}.

13 (see [8]) Every minimum cost inter­
pretation with respect to PI<( G) corresponds to a max­
imum clique of G and conversely.

Property
PK E

�c and cp, 1/J

E 2',

with

Example:

For instance,

let us consider the following penalty

knowledge base

e

( a , l)(b, l}(c, 1}
(d, l)(e, 1}

5),

--+ c

The minimum cost interpretation

1)}

a f-.- �I<

(al\b)

f---�K

is {-.a, b, c, d, -.e}.

This example shows the ability of penalty logic to en­

It can be checked that:

f-.- �I<

c

b

--.c

(a

( •a V •c, +oo)
{---.a V ---.d, +oo)
( •a V •e, +oo}
(-,b V •e, +oo)
( --.c V •e, +oo)

, +oo),

(-,av--.b , 4),
{b--+
2),

•

code discrete optimization problems. One could ar­
gue that, in operation research, algorithms for solv­

c

c

ing classical problems (as maximum clique, minimum
vertex cover... ) do already exist. Those algorithms
are probably more efficient than the one consisting in

•c

comparative inference relation (13] is a rational rela­

tion [15] that also satisfies supraclassicality: if 'P

'Pb--�K'f/;.

d

PK:

{(a V b
( ---.a

1A

a

F '1/1

then

finding the best interpretation
oped in

[7]).

in penalty logic (devel­

However, the logical representation of this

kind of problems presents at least two advantages: the

209

Penalty Logic and its Link with Dempster-Shafer Theory

great power of expression of logi c allows us to spec­
ify many complicated problems which could not easily
be specified within the operational research language;
and the best solution search method is independent of
the given problem.

3

Relating penalties to
Dempster-Shafer theory

In this section we are going to show:

ties are used to induce a preference r el at ion on

•

first, that the cost of an interpretation kpK : rl
[0, +oo) induced by a penalty knowledge base PK
c ons i s t ing of n weighted formulas corresponds ac­
tually to the contour function pl : rl ---+ [0, 1]
induced by Dempster's combination of n simple
support functions (one for each formula rpi);

•

th en , that moreover, the f unc tion Kp){

---+

:

.5f>

-

[0, +oo) corresponds to a plausibility me as ur e in
an infinitesimal version of Depmster-Shafer the­
ory.

3.1

Interpretation costs and contour
functions

Let PK = { (rp;, a;}, i = 1 .. . n} be a penalty kn owl­
edge base. Let us define, for each i, the body of evi­
dence m;:

m;(rp; ) = 1- e-a,
m; (T) = e -a•

00
By convention we take e= 0. S ince a; E [0, +oo],
it can be seen that m;(cpi) E (0, 1) and m;(T) E [0, 1).

note that lim<>,-+co m;(cp;) = 1. m; is
called a simple support functi on [24]. Let m = m1 EfJ
·EBmn be the result of Dempster's combination of the
m; 's (9] without re-normalization. The contour func­
tion pl : n
[0, 1] associated to m i s the restriction

M oreover,
· ·

of

the

-+

plausibility function to sin g le ton s ,

pl(w)
Now,

=

P l ( { w })

=

L

i.e.,

m (rp)

it is well-known [24] that
=

IT Pl;({w})

( II

1).(

IT

i,wl=...,<+>•

II

i,wl=-.cp;

i,wl=cp;

e-

port functions in order to rank interpretations can be

d on e a.lt.erna.ti vely with penalty logic.

This also brings to light. a relation bet.ween penalties
and [25] where each formula 'Pi of the knowledge base is
considered to be given by a distinct source, this source
having the pro bability p; to be faulty (i.e., the infor­
mation it provides us with is not pertinent), and all

so u rces being independent (which gives the simple sup­
port function m;(cpi) = (1- p;) and m;(T) = p,:). So
if the task is only to find the most plausible interpre­
tation (as in [11] which i s the C o ns tr aint Satisfaction
counterpart of [25]), it can thus be done equivalently
with penalti. Ps.

3.2

Formula costs as infinitesimal
plausibilities

Let us consider an infinitesimal version of Dempster­

Shafer theory, where the masses involved are all in­
finitely close to 0 or to 1. Let c be an infinitely small
quantity2•3. Again, let PK = {(cp;,a;},i = 1. .. n}.
Let us define, for each i, the infinitesimal body of evi­
dence m,,;:

i=l

where P l; is the plausibility function induced by m;.
Moreover, Pl;(w) = 1 if w f= 'Pi and Pl;(w) = e-c., if
w f= -,'Pi. Thus,

pl(w)

rl, a.nd

then possibly to select one of the (or all ) cheapest in­
t.erpretat.ion(s). Namely, this is eno ugh for inducing
the inference relation \--- �K, for solving discrete op­
timization proble m s, and also for applying p en alties
to constraint satisfaction problems or abduction. So,
ha ndlin g penalties in su ch a purpose is nothing but
performing Dempster's combination on s impl e sup­
port functions. Reciprocally, combining simple sup­

m,,; (r,o;) = 1 - ca'
m,,;(T) = ca'

n

Pl({w})

Therefore, kpK(w) = -ln(p!(w)): up to a logarithmic
transformation, kPK is a contour function, or mo re pre­
cisely, the process consisting in computing kpr< corre­
sponds to applyin g Dempster's combination without
re-norma.lization on simple support functions. Thi s
equivalence does not extend to an equivalence between
]{pK and a plausibility function (see subsec ti on 3.2}.
but this result is already significant, since in most prac­
t ic al applications of penalty logic, only the contour
function kpK is useful: this is the case when penal­

e-c.,

Lt.�.�t==-.'Pi O'i

e-kPK(w)

e-Ct·)

Let m, = m , 1 tfl· · · ffi m, n be the result of Dempster's
combination �f the m; 's '[9) without re-normalization.
Let us show now that J(PK has the same or d er of mag­
nitude (w.r.t. c ) as ln(P/,), where ln(Pl,) is the plau­
sibility function induced by m,.
Let us note that the set of focal elements of
exactly {"-iEI'Pi, It;::; {1 ... n}}.

m,

is

2More formally, this consists in considering a family of

e's tending towards 0; indeed what we are interested in is
only the limit of the considered
3We recall that ft(e:)

�

f( I!)

when

h(e) iff lim,_o

I!

tends to 0.

};i:j

==

1.

210

Dupin de Saint-Cyr, Lang, and Schiex

4

Now, let us define
R(PK, w)

=

{I � { l .. n}, J\ (<p;)

i\

.

w consistent}

iEI

Now,
II m;(<p;). II m;(T)
i<l/
IER(PK,t/J) iE/

Pl('!j!)

IER(PK,!j;) iEJ

As c: is infinitely small and
.::a•) R:: 1, therefore:
PI(¢)

R::

I

is always finite, f};E1(1-

/ER(PK,t/J)

{J

E

as

R(PK, !J;), La; is minimum}
i<ll

and let r(PK, !J;)
Since

c: is

=

IRminpen(PK, ¢)1.

infinitely small, we have

PI(¢)

R::

!ERm'""'"(PK,,P)

r(PK, '!j!).maxiER(PI<,.;,).::L,er a,
r(PK,

Used to handle inconsistency and perform non­
monotonic inferences, penalty logic has shown to have
interesting properties. Using penalties for selecting
preferred sub-theories of an inconsistent knowledge
base not only allows to distinguish between the degree
of importance of various formulas, as usual priority­
based approaches do, but also to express possible com­
pensations between formulas. The non-monotonic in­
ference relation defined satisfies the usual postulates
[13] and is (logarithmically) related to an infinitesimal
version of Dempster-Shafer theory.
Furthermore, the complexity of the penalty non­
monotonic deduction problem has been considered in
[5] and is ranked as one of the most simple non­
monotonic inference problem (in��).

/ER(PK,!f;) i<tl

Let us now define Rminpen(PK, !/•)

Conclusion

��).c:miniER(PK,�) Z.v a,

Now,

Penalty logic may also been considered as a logical lan­
guage for expressing discrete optimiza tion problems.
The search for a preferred interpretation has been im­
plemented using an A -like variant of Davis and Put­
nam p ro ced u re (6] and has been tested on small ex­
amples. Randomized search algorithms such as GSAT
[23, 22] could also be considered, but they do not guar­
antee that an optimum is actually reached.
•

As shown in [5], solving the problem of searching a
preferred interpretation allows to simply solve the non­
monotonic inference problem, without any restriction
on the language of the formulas expressed4. Any­
way, even the limited ll.� complexity can be consid­
ered as excessive when faced to practical applications.
A reasonable approach would then consist in defining
a gradual inference relation and in trying only to solve
an approximation of the resulting gradual inference
problem.
Among the other possible extensions of penalty logic,

minJER(PK,tiJ)

La;
i<l/

min

BCPK
,BAtjJ
-

c onsistent

min

B�PK,BAtjJ consi•tent

La;

'Pi<lB

CpJ<(B)

one could consider associating many unrelated penal­
ties to a single formula. Partially ordered penalty vec­
tors would then replace penalties. Another possible ex­
tension consists in taking into account not only penal­
ties caused by violations but also profits associated to
satisfactions (which could be expressed using negative
penalties).
Acknowledgements

Therefore,

Note that r(PK, ¢) does not depend on .::, and more­
r(PK, '¢) > 0. So, up to a logarithmic
transformation and a multiplicative constant (in other
terms, if we consider only the orders of magnitude
w. r. t. c::), Kpl( is equivalent to an infinitesimal plausi­
bility function.

We would like to express our thanks to Didier Dubois
and Henri Prade for helpful suggestions concerning
the link between penalties and Dempster-Shafer the­
ory, and Michel Cayrol for having found an error in
a preliminary version. This work has been partially
supported by the ESPRIT BRA project DRUMS-2.

over that

4

Using an ATMS for computing candidates and pre­

ferred sub-theories could also be considered, but the re­
sulting complexity is more important in the general case

[19].

Penalty Logi c and its Link w ith Dempster-Shafer Theory



We view the syntax-based approaches to de­
fault reasoning as a model-based diagnosis
problem, where each source giving a piece of
information is considered as a component. It
is formalized in the ATMS framework (each
source corresponds to an assumption). We
assume then that all sources are indepen­
dent and "fail" with a very small probability.
This leads to a probability assignment on the
set of candidates, or equivalently on the set
of consistent environments. This probability
assignment induces a Dempster-Shafer belief
function which measures the probability that
a proposition can be deduced from the evi­
dence. This belief function can be used in
several different ways to define a nonmono­
tonic consequence relation. We study ans
compare these consequence relations. The
case of prioritized knowledge bases is briefly
considered.

1

Introduction

Syntax-based approaches to inconsistency handling,
default reasoning and belief revision have been pro­
posed and studied in various forms (e.g. [14], [16],
[31], [15], [4], [6], [24], and especially [25] and [1]).
They assume that the input (the knowledge base KB for short) consists of a set of logical sentences,
possibly equipped with a priority ordering; when this
knowledge base is inconsistent, these approaches select
among the consistent sub-bases of the KB some pre­
ferred sub-bases (the selection criterion can be for in­
stance maximality w.r.t. set inclusion1 or cardinality).
A consequence relation is then generally defined by
taking the intersection of the logical closures of these
preferred sub-bases. Each formula of the KB is con­
sidered as a distinct piece of information, which can
1 In this case the preferred sub-bases coincide with the
extensions of default logic [36] restricted to normal defaults
without prerequisites.

be kept in the knowledge base or rejected from it in­
dependently from the others; therefore, it may happen
that two semantically equivalent knowledge bases may
be revised differently and thus lead to different conclu­
sions - this is why they are called syntax-based. Con­
sider for instance K1 = {p, •p, q} and K2 = {pl\q, •p};
q holds in all maximal consistent sub-bases of Kt but
this is not the case for K2. When cardinality is used
to select preferred subbases, even the number of oc­
currences of identical (or logically equivalent) formu­
las in K matters: for instance, {p, -,p} has two consis­
tent sub-bases of maximum cardinality ( {p} and { -,p})
where as {p, •p, -,p} has only one ( { -,p, •p}).
Now, in model-based diagnosis, the consistency-based
approaches (see [37], [13], [35]) proceed in a very sim­
ilar manner, since they look for preferred candidates,
i.e. minimal (w.r.t. a given selection criterion) sets of
faulty components, such that the description of how
the non-faulty components work is consistent with the
observations2. The link between default reasoning and
model-based diagnosis has already been well studied
(e.g. [33], [37], [26], [20]): indeed, the principles be­
hind consistency-based diagnosis and syntax-based ap­
proaches are basically the same: there is a correspon­
dance between a source providing us with a piece of
information and a component of a diagnosis problem;
a faulty component corresponds to an erratic source
which gives a piece of information which is not rele­
vant (by analogy, we will say that the source is faulty).
When the component is working correctly, the formula
describing its normal behaviour must be satisfied, and
analogously, when the source is not faulty, the formula
associated to it must be true in the real world. Then, a
candidate in a diagnosis problem (i.e. a set of compo­
nents consistent with the observations) corresponds to
a candidate in a syntax-based default reasoning prob­
lem (i.e. a set of formulas whose deletion restores the
consistency of the knowledge base).
In the well-known diagnosis system GDE, De Kleer
and Williams [11] propose a probabilistic criterion to
2The principle of minimizing the set of faulty compo­
nents w.r.t. a given criterion is generally called principle
of parsimony (see e.g. [29]).

392

Lang

rank candidates: each component has an initial prob­
ability of fault, and it is assumed that components fail
independently; then, the a posteriori probability that
a given candidate is the real candidate is computed
via Bayes' rule, conditioning by the observations. This
principle of ranking candidates w .r.t. their probability
assumes the initial probabilities of fault are available.
W hen it is not the case, De Kleer [12] proposes to as­
sume that all components have a very small probability
of fault. W hat we propose to do here is to use a similar
assumption for syntax-based default reasoning, which
induces probabilities of the consistent sub-bases of the
KB (which comes down to compute the probabilities
of the candidates - a candidate specifies which pieces
of information have to be rejected and thus which ones
remain in the KB). We will check that, as expected,
the consistent sub-bases of maximal cardinality are the
most probable ones. This probability distribution in­
duces then a Dempster-Shafer belief function, which
evaluates the probability that a formula can be proved
from the available evidence (which consists only in the
KB and the assumptions of independence and small
probabilities of fault). The most original contribution
of this paper is to propose (and to compare) many
different ways to define a syntax-based consequence
relation from this induced belief function. An inter­
esting point is that we will then recover some already
known syntax-based consequence relations (but with a
new justification) and obtain a few new ones. Lastly,
we propose briefly a generalization to the case of pri­
oritized knowledge bases.
2

Inconsistent knowledge bases as
systems to diagnose

From now on, £ denotes a propositional language gen­
erated by a finite number of propositional variables.
Formulas will be denoted by greek letters rp, ¢, etc.
T denotes t autology, F= classical entailment and Cn
logical closure.
A knowledge base (KB) intuitively consists of a set :F of
hard facts which cannot be rejected, and a multiset �
of default formulas which can be rejected if necessary3.
To distinguish each default from the others, we create
a set of assumptions A = {A1, ... ,An} (with as many
assumptions as defaults) and label each default with
a distinct assumption. We define a knowledge base as
in [31] and we then recall well-known definitions of the
ATMS and model-based diagnosis literatures [10], [37],
[11], [13].
Definition 1 A knowledge base K is defined as a
couple K = (:F, Ll) where
3We recall that in a multiset several occurrences of the
same element are distinguished: this obviously has to be
the case for syntax-based approaches where several occur­
rences of the same default constitute several distinct pieces
of information.

•

:F is a finite set of formulas (hard facts)

•

Ll=

{'Pl. .. . , 'Pn} a finite multiset of formulas (de­
faults).

The assumption set A (K) associated to K (denoted
by A when no confusion is possible) is defined by A
= { A1, ... , An} where each assumption is associated to
a default by the mapping 6: Vi= l...n, 8(Ai) ='Pi·
Definition 2 A subset of A is called an environ­
ment. The context of an environment E is defined
by Context( E) = Cn(:F U{ rp; lA; E E} ) 5. An envi­
ronment E is consistent iff Context(E) is consis­
tent. It is irredundant iff no proper superset of E is
consistent6 It is consistent with maximal cardinality
(or, for short, maxcard consistent) iff for any con­
sistent E' we have lEI 2: IE' I·
A nogood is an inconsistent environment. A candi­
date C is the complementary of a consistent environ­
ment. It is minimal iff no proper subset of C is a
candidate; it is a candidate of minimal cardinality (or
mincard for short) iff for any candidate C' we have
ICI � IC'I7·
•

Pursuing the analogy with model-based diagnosis, the
source of information corresponding to the assumption
A; can be viewed as a component; rp; is then the log­
ical description of how the component works. If A; is
true then the source is "non-faulty" and the associated
formula 'Pi is satisfied in the real world; if A; is false
then the source is "faulty" and then we don't know
whether the associated formula is satisfied or not in
the real world {in terms of diagnosis, it corresponds
to the assumption that we don't know how behaves a
faulty component).
As in [13] a nogood {Ait> .. . , Ai,} will also be written logically by -.A; 1 V ... V ..,A; P 8 ; a candidate
{Ah, . .., AJ.} will also be written logically by -,Ail ('­
... I\ -.AJ.· The nogood base, denoted by -.N, ts
the conjunction of all irredundant nogoods; it is well­
known to be equivalent to the conjunction of all mini­
mal nogoods, and as well to the disjunction of all [irre­
dundant] candidates [13]. A detailed example is given
in Section 3 and continued in Section 4.

4Instead of this we could have equivalently generated
the set of ATMS justifications A; ---+ <p;
5Note that Context(A) K.
6This is called an interpretation in [10]
7 Obviously, a minimal (resp. mincard) candidate is the
complementary of an irredundant (resp. maxcard) consis­
tent environment.
8Note that -.A;, corresponds to De Kleer et al.'s [13]
notation AB( c;i) meaning that the component c;1 is faulty.
=

Syntax-based Default Reasoning as Probabilistic Model-based Diagnosis

393

... I\ ;,. �

t:n-k+l.

From syntactical knowledge bases to

3

belief functions
3.1

(

Computing the probability of
environments

As in

[12}

we make the two following basic assump­

tions:
(I) each assumption is independent from the oth­
ers. This means t ha t each default piece of infor­
mation is kept or rejected independently from the
others - which is in accordance with the spirit of
syntax-based approaches to default reasoning.

•

(S) all assumptions are assigned the same initial

•

1\

of more than two C;'s: P r (C; 1
C )
k
Thus, Pr(-.N) = pt:n- + O(e-n-Hl). Now,

probability (the sources have the same prior prob­
ability of fault), and this probability of fault is
very small: Vi, Prob(-.A;) = t:, with£« 1.
This leads to define a probability assignment on the en­
vironment set 2A. Thus, the prior probability of an en­
vironment E of cardinality k is P r(E) = t:Tl-k(l- c)k
(which is approximated by c:Tl-k when c:-+ 0). Pr ( E)
is the prior probability that E is the real environment,
i.e. the environment corresponding to the real world.
Now, this real environment must be consistent; to en­
sure that inconsistent environments are given a zero
probability, the prior probability is conditioned on the
consistent environments (see e.g.

E f=

-.N

�
,n-IEI(t-€ 1EI)
�'
so Pr E I -.N) = P r(-,N} = •"-li+0(€ "-1<+1 ) ; th ere1ore
P
if /EI = k, Pr(EI-.N) = � + O(t:); and if lEI < k,
Pr(EI•N) = O(e-J:-1£1).
Computing the probability of the consistent environ­
ments is exactly the same task as computing the proba­
bilities of candidates in consistency-based model-based
diagnosis ([11], [12], [35]). Proposition 1 tells that the
only consistent environments whose probability does
not tend to

0

when t:

-+

0

are those of maximal car­

dinality. This is in accordance with a version of the
principle of parsimony consisting in considering only
the candidates of minimum cardinality

( [12} , [29]).

It is also interesting to compute the probability of fault

of a single source, namely

Pr(-.Ad-.N):

Proposition 2 As before, assume that there are e:r­
actly p maxcard consistent environments and let k be
their cardinality. Let A; be an assumption.
•

if A; is absent of r �
ronments, then

•

if A; appears in all maxcard consistent environ­
ments, and is absent of r' irredundant consistent

1

maxcard consistent envi­

[22)), i.e.

environments of cardinality k- 1, then

p max­
card consistent environments; let k be their cardinality.
Let E be any consistent environment. Then9

Proposition 1 Assume that there are exactly

•

if /E/ = k then Pr(E/-,N)=

•

if /E�

Proof:

<

l +

p

O(t:)

k then Pr(EI-.N) = O(t:k-IEI)

us prove first prove that Pr( -.N)
Let C1, ... ,Cp be the mincard
candidates; they are the complementary of the max­

k
pen- +

let

O(t:Tl-k+1).

card consistent environments, so their cardinality is
n - k. Let Cp+l, . . . , Cq be the other irredundant can­
didates. P r (-.N ) = Pr(C1 v . . . v Cq) == Pr(Ct) +
... + Pr(Cp) +Pr(Cp+t) + .. . + Pr(Cq)- Li#i Pr(C; 1\

Ci )+ "E.,;'Ii,UI,ifl Pr(C;I\Ci 1\Cf)+ ... . Now, Pr(C1) =
... = Pr(Cp)= cn-k; Vi= p + l...q, Pr(C;) = t:Tl-k+l;
and Vi, j such that i :j:. j, C; 1\ C; contains at most
n - k + 1 l iterals ..,A;'s (if it contained only n - k,
since n - k is the m aximum cardinality of a con­
sistent environment, one of the two candidates C;
and Cj would be contained in the other one, which

would contradict the fact they are irredundant); thus,
Pr( C; 1\ C;) � e-" -k+l. A fortiori, for all conjunctions
9We recall that the notation O(gk) denotes any function

f of

g

such that

.IJ�l

-+c-o

0.

The proof uses the same kind of considerations as the
proof of Proposition 1.

Remark: if A; appears in all irredundant consistent
environments, then r' = 0 and Proposition 1 gi ves

Pr(-,A;/•N) = €. Indeed, in this case, -.A; never
appears in -.N and therefore -.A; and •N are inde­
pendent; thus Pr(-.A;/-,N)= Pr(•A;)::::: €.

Example: F :::: {a} and to contains the following for­
mulas (with their respective Ai 's):
b 1\ e 1\ f

A1

a -+

A.1

e
-.b 1\ ..,c 1\ -.e 1\ g
b 1\ -.c 1\ d 1\ --..e 1\ -,g

A2 a-> c 1\ d
Aa ..,b v -.d
As
As

Here are the irredundant consistent environments,
their probability and their context10:
10We omit the Cn notation in the context culumn, so
for instance it should be read Context({A1,A2,A�})
Cn( {a, b, c, d, e, f}) etc.
=

394

Lang

E

) Pr(E)-.N) l

Context(E)

� + O(e:)
� + O(e:)

b, •d, e, f
--,b, c, d, e
a, •b, --,c, •e, g
a, b, •c, d, -.e, -.g

{At,Aa,A4}
{A2,Aa,A 4}
1A3,Asl
{As}
Here are the

a,

Be lx (t/J )

a,

O(e:)
O(e::t)

Pr( -.A;I•N):

The

maxcard
consistent
environments
{At,A2,A4}, {At,A3,A4} and {A2,A3,A4}.

are

How probabilities of candidates induce a
belief function

We have seen that the knowledge base K induces
a probability assignment of the environment see 2.A.
This probability assignment of the assumption set in­
duces a Dempster-Sha.fer belieffunction (see

f22}, [34],

[27], [9], [38] for a study of this connection between
ATMS and belief functions). As studied in detail by
Smets [38], this belief function represents a probability
of deductibility, i.e. the probability that the evidence is
sufficient to prove the proposition (see also [22], (27]).
This belief function is given by11

Pr(E I · N)
EE2"\"P/IE Context(E)
Proposition 3

Belx ( t/J)

= 1

iff :F

I= t/J

Proof if :F I= 1j; for any environment E, ¢ E
Context(E) and therefore Belx(¢) = 1. Reciprocally,
if Belx(¢) = 1 then consider the environment 0; it
has a non-zero probability and its context is only :F,
therefore :F F= t/J.
Let k..p be the maximum cardinality of
a consistent environment E such that t/J E Context(E)
(if any) and let U!fi be the number of such environ­
ments; as before, let k be the cardinality of a maxcard
consistent environment. Then

Proposition 4

•

if k!/1

=

k then

Be/K(¢)
•

if k!/1

<

u..p

=-

p

+

O(e:)

k then

Belx(¢)

=

O(e:k-k")

11
An equivalent expression of
stance [22])

1

B e I1'. ( ·"'· )

=

Belg(I/J)

=

0

The proof comes immediately from Proposition 1.

Pr(-.A1)-.N) = Pr(-.A2) = Pr(-.Aa) = � + O(e:);
Pr(-.A4)-.N) = (1 + k)e: + O(e:2) = �c + 0(.:2);
Pr(•A5)-.N) = Pr(•A6)-.N) = 1 +O(c);

3.2

if there is no consistent environment E such that
1j; E Conte:ct(E) then

•

is (see for in­

Pr( la b e l ( 1/J) A -.N)
Pr( -.N)

where label( 1/J) is the logical expression of the set of all ir­
redundant consistent env ironments in which 1/J is provable.

Example (continued):
Belx (b V c ) = 1;
Belx(b) = � + O(s);
Be lx(g) = O(s);
Belx(•g) = O(e:2);
Belx(-.f) = 0.

4

Inducing consequence relations

We have seen that, given a knowledge base K, and
assuming small fault probabilities and independence
of the sources, we obtain a belief function Belx on £
induced by K; Be/K (¢) is the probability that ¢ be
deductible from K from the evidence. Now, we can use
this generated belief function to define nonmonotonic
consequence relations (CR) on £. We are going to
investigate several proposals of CRs, many of which
will appear to be well-known. We define the CRs in the
syntax as Pinkas and Loui [30], namely K f'-- ¢ means
that the formula¢ is inferred from the knowledge base

K12.

As in [31] we define a scenario of K = (:F, �) as a
consistent subset S of :F U� containing :F (note that
Cn(S) is the context of a consistent environment). A
scenario is said irredundant (resp. maxcard) iff it is
maximal w.r.t. set inclusion (resp. cardinality).
Definition 3

K h ¢ iff Belx(¢)

Proposition 5

S of K, S f= t/J.

-+

...... o 1

K f'--t 1j; iff for any maxcard scenario

The proof comes easily from the fact that only max­
card consistent environments have a probability which
does not tend to 0. This kind of CR is known as a
strong CR. More precisely, f---1 has been studied in a
more general setting (and with priorities) in (23] and
[1]13. This result gives thus a n ew interpretation of
this well-known inference relation.
12Note that, in spite of the syntax K f"-- 1/J, f"-- is actu­
ally a unary CRs; a binary CR induced by K would be f"-- K
where rp f"--K 1/J means that with respect to the background
knowledge represented by K, if we assume rp then we infer
nonmonotonically 1/J (and the unary case is recovered when
rp = T). For the sake of simplicity, in this paper we define
only the unary restrictions of the CRs; however this restric­
tion is not essential: indeed, syntax-based CRs generally
satisfy tp f"--K 1/J iff f---Add(K,\0') 1/J, where Add(K,rp) = (.F
U{<p}, t:.) (see [1]).
13 As shown in [23] and (1], the binary and prioritized
version a£ f"--1 is a rational inference relation which is fur­
thermore well adapted to the handling of default rules.

Syntax-based Default Reasoning as Probabilistic Model-based Diagnosis

0 such that

395

Proposition 6 K r-2 1/J iff there is a maxcard sce­
nario S such that S f= 1/;.

A sufficient condition for K f---6 ¢ to hold is when
the number of maxcard s ce n ari os entail ing 1/; is greater
than the number of maxcard scenarios ent ailin g -,'1/J.
However this condition is n ot necessary; the exact
characterization is more complex:

Again, the proof comes from the fact that the consis­
tent environments with a non infinitely small belief are
the maxcard ones. This CR is the weak ( existential)
counterpart of f---1.

Proposition 11 Let u(k, '1/J) be the number of sce­
narios of K of cardinality k entailing ¢.
Let
diff ('I/J, -.¢) = Max{k, u(k, 1/!) =/: u(k, •1/J)}. Then
K f-.-7 '1/J iff u(diff(l/J, -.1/J), 1/!) > u(diff('I/J, -.'1/J), -.'1/J).

Definition 4 K

BelK(l/J)

-+-,

..... o

a

r-2

1/J iff 30!

5 K f-.-a 1/J iff3a
and BelK(-.1/J) -+c-o 0.

Definition
a

>

> 0 s.t. BelK(l/J)

Proposition 7 K f---3 1/J iff K f-.-2

-+,

1/; and K J'v2

..... o

-.'1/J.

The proof comes straightforwardly from Propositions
5 and 6. This kind of CR, called argumentative in [2),
is intermediate between weak and strong CRs.

Definition 6 K f-.-4 1/J iff BelK ( 1/J) > 0
Proposition 8 K f-.-4 1/J iff there is a scenario S of
K such that S f= 1/J, or equivalently, iff there JS an
irredundant scenario S of K such that S f= '1/J.
The proof comes from the fact that all consistent en­
vironments have a non-zero probability. This well­
known weak CR corresponds to the provability in at
least one extension of a normal default theory without
prerequisites14.

Definition 7 K
BelK(•I/!) = 0

f---5 1/J iff BelK ('1/J)

>

0 and

Proposition 9 K r-5 '1/J iff there is a scenario of K

entailing '1/J and if there is no scenario of K entailing
-,-rjJ.
This result is a corollary of Propositi on

8.

This CR is

another argumentative CR.

Definition 8 K

f-.-s 1/! iff BelK(1/!)

>

K f---6 -rjJ iff '1/J is provable in the ma­
jority (more than one half) of the maxcard scenarios
of K.

The proof comes directly from the fact that all max­
card consistent environments have all the same proba­
b ility ( namely l) and that the non-maxcard ones have

infinitely

been called

p

small probability. This kind of

majority

CR has

CR in [30].

Definition 9 K f---7 -rjJ iff BelK('IfJ) > BelK(•'I/J)

(

1•
The corresponding strong CR provability in all exten­
sions , which is more interesting and which has received
many improvements in the literature, seems to have no

)

nice characterization in our framework.

y

this case, let

7

k*

be the cardinality of the
maxcard consistent environments, then u(k*, 1/J) = u.p,
u(k*, -,¢) = u-..p and diff('I/J, -.-rjJ) = k*;

u-..p > 0; in

O(ek1) and BelK(-,-rjJ) = O(ek�) with
BelK(-.1/J) = 0; in this case, u(k•­
k1,'1/J) > 0, u(k*- k1,•'1/J) = 0 and diff('I/J,-.'1/J) =
k*- kt;
- BelK(rP) = O(c:k1) and BelK(-.7/J) = O(c:k1) as well;
in this case, we have to develop further the expres­
sion of Pr(EI -.N) in Proposition 1 , which would show

�

BelK(I/!)

=

k2 > k1 � 0, or

that if among the consistent environments of cardinal­
ity k.p(= k...,.p), there are more entailing 1/; than en­
tailing -.1/J, but if there are exactly as many, then it
depends on the number of c onsist ent environments of
cardinality k.p - 1, and so on.

that this CR has a lexi­
indeed, Prop ositi on 11 co uld have
stated equ ivalently by :
It is dear from this proof

co grap hic spirit :

L('I/J)
L(-.¢) = (u(k,-.1/;),k =

(u( k , '1/J), k = n. .. l) and
then K f-.-7 '1/J iff
L(¢) >lex L(-.1/J), where >lex is the lexicographic or­
dering.

Proposition 12 Let

Definition 10 K
BeiK .,.p
BeiK 1/J)

_,.<-+0

O

=

n .. . l)

f-.-s ¢ iff BelK(l/J)

>

0 and

·

Proposition 13 K f-.-a ¢ iff k.p > k-..p, where k.p is
been defined like in Proposition 4, with the convention

�

Proposition 10

an

Here is a s ke t ch of the proof: there are 3 situations
where BelK(l/J L > Be/K(-.7/J):
- BelK(rP) =
and BelK(•I/!) =
where u.p >

kl/i = -oo iff¢
environment.

appears

in the context of no consistent

The proof comes easily from Proposition 4.

Definition 11 K r-9 w iff BelK('l/J) = 1.
Proposition 14 K f---9 '1/J iff :F
This is

a

f= 1/;.

cl one of P ro p osit i on 3 and has thus

already

been proved. This CR is very strong and it is even
monotonic since it accepts only the consequences of
hard facts.

Proposition 15 Let --< be the relation between CR 's
(as in {30}) defined by h--< h iffVK., ¢, K h -rjJ =>

K 1----J 7/J. This relation between our f-.-; 's is depicted
by the graph on Figure 1.

396

Lang

llh

a

bvc
c

b

f

-,d
g

�J

{

..,g

...,f
5

Figure 1: the

-<

relation between l---i's

The proof would be long and tedious but does not
present any particular difficulty. Note that the exam­
ple at the end of the Section gives counterexamples
corresponding to almost all couples of CR.s such that
hi h · Pinkas and Loui [30) define a safe CR as a
CR !--- such that '</K, '</1/J, K J'v 1/J or K J'v -.tjJ. It
can be checked easily that !---2 and l---4 are generally
unsafe while the other ones are safe.
Proposition 16

When K is consistent, all f--; 's ex­
cept f--.-9 collapse to classical entailment, i.e. K r-; tjJ
iff :F UA f= t/J.

Proof" when K is consistent, there is only one maxcard
scenario: K itself. Therefore K !---1 if; iff K f= 1/;, and
a fortiori, all h below in the graph collapse to f=. It
remains to show it for f--.-5, which is straightforward.

This list of CR's is of course not exhaustive and
one could think of giving other definitions, possibly
parametrized by a given a > 0. The interest of such
a list of CR's is to enable the user to use the most
adapted CR to her specific problem, knowing that
whichever CR she chooses, it will have an interpre­
tation in terms of the belief function induced by the
KB and assumptions (I) and (S). While very cautious
CR.s such as r-1 and very adventurous ones such as r-4
or r-s are often considered as too extreme in practice,
the more quantitative CR.s r-s, !---1 (and r-s which is
maybe a bit less quantitative) seem to be good com­
primises inbetween, and furthermore their DS inter­
pretation is appealing.
Example (continued):

Let � = ( b V c V -.e ) 1\ g. In the following table, the sign
x (resp. the sign - ) means that the formula is (resp.
is not) entailed w.r.t. h· There is no column for r-9
(obviously, only a is a r-9-consequence of K).

X
X

-

hlhhhFrlh
X
X
X
X

-

X
X
X

X

-

X
X
X
X
X
X

-

X
X
X

X

X
X
X
X
X

-

-

X
X

X
X

-

-

X

X

X

-

h
X
X
X
X
X
X
X
X
X

-

Extension to the prioritized case

Many syntax-based approaches to default reasoning
assume that the knowledge base is partitioned into
priority levels, namely K = (Kt, . .., Kn) (1 being by
convention the most prioritary level); these levels are
qualitative and generally it is more acceptable to vi­
olate any number of formulas of a lower priority level
then violate one formula of a higher priority level.
A generalization of the maximum cardinality princi­
ple to the prioritized case is defined both in [1] and
in [23]: a sub-base A of a prioritized knowledge base
(K1, ... , Kn) is lexicographically strictly preferred to a
sub-base B iff there exists a i E l..n such that '</j > i,
lA n Sj I = IB n Sj I and lA n Sd > IB n si I; the
same selection criterium has been used in diagnosis
by DeKleer [1 '2]. Now, it is possible to character­
ize lexicographically preferred subtheories in terms of
probabilities of fault; following De Kleer [12], for any
piece of information in Ki we assign an initial proba­
bility of fault of t:; to its source, with the constraint
that '</i and '</j > i, €J � €i (more precisely, that
€j < c{ma:r, where fmax is an upper bound of the
maximum number of formulas of a priority level - we
may take for instance fmax = IKJ). Then it can be
shown that the only consistent environments of K hav­
ing an a posteriori probability which does not tend to
0 when € --+ 0 correspond exactly to the lexicograph­
ically preferred subbases (which generalizes Proposi­
tion 1 ) , and that 1/J is lexicographically deduced from
K iff Belx('I/J) -t-o 1 (which generalizes Proposition
5).

6

Related work and conclusion

We have strengthened the already known connections
between syntax-based default reasoning, model-based
diagnosis and ATMS, and belief functions, by building
on deKleer's infinitesimal probabilities of fault. We
have followed the following steps:
(1) syntax-based nonmonotonic entailment is viewed
as diagno sis, by considering each piece of information
as the description of how a component works, and the
source which provided us with it as the component;
(2) we assume that all sources have very small {and
equal) initial probabilities of fault, and that they are

Syntax-based Default Reasoning as Probabilistic Model-based Diagnosis

independent;

(3)

we compute the probabilities of each candidate,
and then a belief function on the language which can
be interpreted as a probability of provability;

(4) we use this belief function to define syntax-based
nonmonotonic consequence relations;
(5) lastly, we position these definitions in the litera­
ture of syntax-based approaches to nonmonotonic en­
tailment.
Our work integrates various subfields of AI and thus
there are many rel;ated works, more so bacause the
links between these subfliels had already received a lot
of attention in the literature. Many authors assign
prior probabilities to assumptions or components and
compute then posterior probabilities of candidates,
and some of them compute a belief function ([34] [27]

(22], (35])

but generally the initial probabilities are as­
sumed to be given by the user. De Kleer [12) uses the
same basic assumptions as us (2) but he computes then
posterior probabilities of candidates conditioned by a
measurement (in order to find the best measurement
to do next), which diverges from our step (4).
Furthermore,

397

definitions given in Section 4 still make sense in the
case we start with non-infinitesimal user-given proba­
bilities of failure; but the results do not hold any longer
and the characterization of these inference relations is
thus much less interesting.
We would like to emphasize that our contribution does
not really propose a new formalism nor a new way
to perform nonmonotonic reasoning, but rather puts
together the (already known) links between syntax­
based default reasoning on one side, and ATMS, di­
agnosis and belief functions on the other side, and as­
sumes further independence of the pieces of informa­
tion and infinitely small probabilities of failure. Now,
although the theoretical complexity of syntax-based
entailment relations has received recently some atten­
tion [25) [7], up to now, the more practical algorithmic
and implementation issues have been less studied in
the literature of syntax-based default reasoning than
in the literature of ATMS and model-based diagnosis.
Therefore, our conclusion (and our hope) is that that
syntax-based default reasoning should benefit from ex­
isting works on the aforementioned fields, such as the
characterization of tractable subclasses (e.g. [5]), ex­
perimental results etc.

it is worth noticing that the "non­

trivial" (i.e. other than 0 and 1) belief weights we
obtain when £ --> 0 are obtained from a completely
syntactic knowledge base without explicit numbers. A
related work which shares this feature is the Dempster­
Shafer handling of default rules of Benferhat and

Smets [3]: they start from a set of ranked default rules,
where the ranking comes either from the user or from
the ranking procedure of Goldszmidt and Pearl's Sys­
tem Z [28]; they associate then to each def ault of rank
i the mass 1-Ei (with Ei � 1 and Ei+! � ci) and com­
pute then a belief function assuming independence be­

cf

cJ',

tween the defaults. Note that
and
as well as ar­
bitrary products of£; 's, are not comparable. The com­
puted belief function is used to define an inference re­
lation (in the same way as f---I) which solves the prop­
erty inheritance blocking problem. The common point
to their work and ours is the generation of a belief
function from a knowledge base (in their approach, a
ranked set of default rules); but the objective pursued
is different: while they search for a consequence rela­
tion solving the blocking inheritance problem, we want
to characterize consequence relations in terms of prob­
abilities of fault of the sources. Other authors have
used infinitesimal probabilities in nonmonotonic rea­
soning, following Adams' £-semantics (especially Pearl
[27], Goldszmidt et al. [18)); in these approaches the
default rule a _. f3 is translated by Pr(f31a) � 1 - e:

with £ � 1. The main difference with our use of in­
finitesimal probabilities relies in their interpretation
(in the latter approaches they are conditional probabil­
ities qualifying default rules while in ours they qualify
the relevance of a piece of information).
Obviously, steps (3) and (4) can be done without as­
suming infinitely small prior probabilities. Thus, the

Acknowledgements
This work has been supported by the ESPRIT-BRA
Research Project "DRUMS-2" (Def e asible Reasoning
and Uncertainty Management Systems). Thanks to
Salem Benferhat, Didier Dubois and Henri Prade for
helpful discussions and comments on earlier versions,
and to the anonymous reviewers for helpful criticisms.



We investigate the computational complexity of testing dominance and consistency in CP-nets.
Previously, the complexity of dominance has been determined for restricted classes in which the
dependency graph of the CP-net is acyclic. However, there are preferences of interest that define
cyclic dependency graphs; these are modeled with general CP-nets. In our main results, we show
here that both dominance and consistency for general CP-nets are PSPACE-complete. We then
consider the concept of strong dominance, dominance equivalence and dominance incomparability,
and several notions of optimality, and identify the complexity of the corresponding decision problems. The reductions used in the proofs are from STRIPS planning, and thus reinforce the earlier
established connections between both areas.

1. Introduction
The problems of eliciting, representing and computing with preferences over a multi-attribute domain arise in many fields such as planning, design, and group decision making. However, in a
multi-attribute preference domain, such computations may be nontrivial, as we show here for the
CP-net representation. Natural questions that arise in a preference domain are, “Is this item preferred to that one?”, and “Is this set of preferences consistent?” More formally, a set of preferences
is consistent if and only if no item is preferred to itself. We assume that preferences are transitive,
i.e., if α is preferred to β, and β is preferred to γ, then α is preferred to γ.
An explicit representation of a preference ordering of elements, also called outcomes, of such
multi-variable domains is exponentially large in the number of attributes. Therefore, AI researchers
have developed languages for representing preference orderings in a succinct way. The formalism
of CP-nets (Boutilier, Brafman, Hoos, & Poole, 1999) is among the most popular ones. A CP-net
c 2008 AI Access Foundation. All rights reserved.

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

provides a succinct representation of preference ordering on outcomes in terms of local preference
statements of the form p : xi > x j , where xi , x j are values of a variable X and p is a logical condition.
Informally, a preference statement p : xi > x j means that given p, xi is strictly preferred to x j ceteris
paribus, that is, all other things being equal. The meaning of a CP-net is given by a certain ordering relation, called dominance, on the set of outcomes, derived from such reading of preference
statements. If one outcome dominates another, we say that the dominant one is preferred.
Reasoning about the preference ordering (dominance relation) expressed by a CP-net is far from
easy. The key problems include dominance testing and consistency testing. In the first problem,
given a CP-net and two outcomes α and β, we want to decide whether β dominates α. The second
problem asks whether there is a dominance cycle in the dominance ordering defined by an input
CP-net, that is, whether there is an outcome that dominates (is preferred to) itself.
We study the computational complexity of these two problems. The results obtained prior to this
work concerned only restricted classes of CP-nets, all requiring that the graph of variable dependencies implied by preference statements in the CP-net be acyclic. Under certain assumptions, the
dominance-testing problem is in NP and, under some additional assumptions, even in P (Domshlak
& Brafman, 2002; Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004a). We show that the complexity in the general case is PSPACE-complete, and this holds even for the propositional case, by
exhibiting in Section 4 a PSPACE-hardness proof for dominance testing.
We then turn to consistency testing. While acyclic CP-nets are guaranteed to be consistent, this
is not the case with general CP-nets (Domshlak & Brafman, 2002; Brafman & Dimopoulos, 2004).
In Section 5, we show that consistency testing is as hard as dominance testing.
In the following two sections we study decision problems related to dominance and optimality
in CP-nets. First, we consider the complexity of deciding strict dominance, dominance equivalence
and dominance incomparability of outcomes in a CP-net. Then, we study the complexity of deciding
the optimality of outcomes, and the existence of optimal outcomes, for several notions of optimality.
To prove the hardness part of the results, we first establish the PSPACE-hardness of some problems related to propositional STRIPS planning. We then show that these problems can be reduced
to CP-net dominance and consistency testing by exploiting connections between actions in STRIPS
planning and preference statements in CP-nets.
The complexity results in this paper address CP-nets whose dominance relation may contain
cycles. Most earlier work has concentrated on the acyclic model. However, as argued earlier, for
instance by Domshlak and Brafman (2002), acyclic CP-nets are not sufficiently expressive to capture human preferences on even some simple domains.1 Consider, for instance, a diner who has
to choose either red or white wine, and either fish or meat. Given red wine, they prefer meat, and
conversely, given meat they prefer red wine. On the other hand, given white wine, they prefer fish,
and conversely, given fish they prefer white wine. This gives a consistent cyclic CP-net, and there is
no acyclic CP-net giving rise to the same preferences on outcomes. So, such cyclicity of preference
variables does not necessarily lead to a cyclic order on outcomes.

1. We do not mean to say that cyclic CP-nets are sufficient to capture all possible human preferences on simple domains
– this is obviously not true. However, we note that every preference relation extends the preference relation induced
by some CP-net with possibly cyclic dependencies. Not only is this property no longer true when cyclic dependencies
are precluded but, in the case of binary variables, the number of linear orders that extends some acyclic CP-net is
exponentially smaller than the number of all linear orders (Xia, Conitzer, & Lang, 2008).

404

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

We assume some familiarity with the complexity class PSPACE. We refer to Papadimitriou
(1994) for details. In particular, we later use the identities NPSPACE = PSPACE = coPSPACE.
In several places, we will consider versions of decision problem, in which input instances are
assumed to have some additional property. Such problems are usually formulated in the following
way: “Q, given R”2 . We first note that “Q, given R” is not the same problem as “Q and R”. Let
us recall the definition of a decision problem as presented by Ausiello et al. (1999). A decision
problem is a pair P = hIP ,YP i where IP is a set of strings (formally, a subset of Σ∗ , where Σ is a
finite alphabet), The decision problem P = hIP ,YP i reads as follows: given a string x ∈ IP , decide
whether x ∈ YP . A problem hIP ,YP i is in a complexity class C if the language YP ⊆ Σ∗ is in C (this
does not depend on IP ). A problem hIQ ,YQ i is reducible to hIP ,YP i if there is a polynomial-time
function F such that (1) for every x ∈ IQ , F(x) ∈ IP , and (2) for every x ∈ IQ , x ∈ YQ if and only
if F(x) ∈ YP . Thus, if P is the decision problem “Q, given R”, then IP is the set of all strings
satisfying R, while YP is the set of all strings satisfying R ∩ Q. For all such problems, it is granted
that the input belongs to R; to solve them we do not have to check that the input string is indeed
an element of R. Such problems “Q, given R” are widespread in the literature. However, in most
cases, R is a very simple property, that can be checked in polynomial (and often linear) time, such
as “decide whether a graph possesses a Hamiltonian cycle, given that every vertex has a degree at
most 3”. Here, however, we will consider several problems “Q, given R” where R itself is not in the
class P (unless the polynomial hierarchy collapses). However, as we said above, the complexity of
recognizing whether a given string is in R does not matter. In other words, the complexity of “Q,
given R” is the same, whether R can be recognized in unit time or is PSPACE-complete. We will
come back to this when the first such problem appears in the paper (cf. the proof of Proposition 5).
In no case that we consider is the complexity of R greater than the complexity of Q.
A part of this paper (up to Section 5) is an extended version of our earlier conference publication
(Goldsmith, Lang, Truszczyński, & Wilson, 2005). Sections 6 and 7 are entirely new.

2. Generalized Propositional CP-Nets
Let V = {x1 , . . . , xn } be a finite set of variables. For each variable x ∈ V , we assume a finite domain
Dx of values. An outcome is an n-tuple (d1 , . . . , dn ) of Dx1 × · · · × Dxn .
In this paper, we focus on propositional variables: variables with binary domains. Let V be a
finite set of propositional variables. For every x ∈ V , we set Dx = {x, ¬x} (thus, we overload the
notation and write x both for the variable and for one of its values). We refer to x and ¬x as literals.
Given a literal l we write ¬l to denote the dual literal to l. The focus on binary variables makes the
presentation clearer and has no impact on our complexity results.
We also note that in the case of binary domains, we often identify an outcome with the set of
its values (literals). In fact, we also often identify such sets with the conjunctions of their elements.
Sets (conjunctions) of literals corresponding to outcomes are consistent and complete.
A conditional preference rule (sometimes, a preference rule or just a rule) over V is an expression p : l > ¬l, where l is a literal of some atom x ∈ V and p is a propositional formula over V that
does not involve variable x.
2. In the literature one often finds the following formulation: “Q, even if R”, which does not have exactly the same
meaning as “Q, given R”. Specifically, when saying “Q is NP-complete, even if R”, one means “Q is NP-complete,
and Q, given R is NP-complete as well”.

405

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

In the rest of the paper, we need to refer to two different languages: a conditional preference
language where for every (binary) variable x, the conditional preference table for x needs to specify
a preferred value of x for every possible assignment of its parent variables, and a more general
language where the tables may be incomplete (for some values of its parents, the preferred value of
x may not be specified) and/or locally inconsistent (for some values of its parents, the table may both
contain the information that x is preferred and the information that ¬x is preferred). We call these
languages respectively CP-nets and GCP-nets (for “generalized CP-nets”). Note that GCP-nets are
not new, as similar structures have been discussed before (Domshlak, Rossi, Venable, & Walsh,
2003). The reason why we use this terminology (“CP-nets” and “GCP-nets”) is twofold. First, even
if the assumptions of completeness and local consistency for CP-nets are sometimes relaxed, most
papers on CP-nets do make them. Second, we could have used “CP-nets” and “locally consistent,
complete CP-nets” instead of “GCP-nets” and “CP-nets”, but we felt our notation is simpler and
more transparent.
Definition 1 (Generalized CP-net) A generalized CP-net C (for short, a GCP-net) over V is a
set of conditional preference rules. For x ∈ V we define pC+ (x) and pC− (x), usually written just:
p+ (x) and p− (x), as follows: pC+ (x) is equal to the disjunction of all p such that there exists a rule
p : x > ¬x in C; pC− (x) is the disjunction of all p such that there exists a rule p : ¬x > x in C. We
define the associated directed graph GC (the dependency graph) over V to consist of all pairs (y, x)
of variables such that y appears in either p+ (x) or p− (x).
In our complexity results we will also need the following representation of GCP-nets: a GCPnet C is said to be in conjunctive form if C only contains rules p : l > ¬l such that p is a (possibly
empty) conjunction of literals. In this case all formulas p− (x), p+ (x) are in disjunctive normal form,
that is, a disjunction of conjunctions of literals (including ⊤ – the empty conjunction of literals).
GCP-nets determine a transitive relation on outcomes, interpreted in terms of preference. A
preference rule p : l > ¬l represents the statement “given that p holds, l is preferred to ¬l ceteris
paribus”. Its intended meaning is as follows. If outcome β satisfies p and l, then β is preferred to
the outcome α which differs from β only in that it assigns ¬l to variable x. In this situation we say
that there is an improving flip from α to β sanctioned by the rule p : l > ¬l.
Definition 2 If α0 , . . . , αm is a sequence of outcomes with m ≥ 1 and each next outcome in the
sequence is obtained from the previous one by an improving flip, then we say that α0 , . . . , αm is an
improving sequence from α0 to αm for the GCP-net, and that αm dominates α0 , written α0 ≺ αm .
Finally, a GCP-net is consistent if there is no outcome α which is strictly preferred to itself, that
is, such that α ≺ α.
The main objective of the paper is to establish the complexity of the following two problems
concerning the notion of dominance associated with GCP-nets (sometimes under restrictions on the
class of input GCP-nets).
Definition 3
GCP - DOMINANCE : given a GCP-net C and two outcomes α and β, decide whether α ≺ β in C, that
is, whether β dominates α in C.
GCP - CONSISTENCY : given a GCP-net C, decide whether C is consistent.
406

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

GCP-nets extend the notion of CP-nets (Boutilier et al., 1999). There are two properties of
GCP-nets that are essential in linking the two notions.
Definition 4
A GCP-net C over V is locally consistent if for every x ∈ V , the formula pC− (x) ∧ pC+ (x) is unsatisfiable. It is locally complete if for every x ∈ V , the formula pC− (x) ∨ pC+ (x) is a tautology.
Informally, local consistency means that there is no outcome in which both x is preferred over
¬x and ¬x is preferred over x. Local completeness means that, for every variable x, in every outcome
either x is preferred over ¬x or ¬x is preferred over x.
Definition 5 (Propositional CP-net) A CP-net over the set V of (propositional) variables is a locally consistent and locally complete GCP-net over V .
It is not easy to decide whether a GCP-net is actually a CP-net. In fact, the task is coNPcomplete.
Proposition 1 The problem of deciding, given a GCP-net C, whether C is a CP-net is coNPcomplete.
Proof: Deciding whether a GCP-net C is a CP-net consists of checking local consistency and local
completeness. Each of these tasks amounts to n validity tests (one for each variable). It follows that
deciding whether a GCP-net is a CP-net is the intersection of 2n problems from coNP. Hence, it is
in coNP, itself. Hardness comes from the following reduction from UNSAT. To any propositional
formula ϕ we assign the CP-net C(ϕ), defined by its set of variables Var(ϕ)∪{z}, where z 6∈ Var(ϕ),
and the following tables:
−
+
• for any variable x 6= z: pC(ϕ)
(x) = ⊤; pC(ϕ)
(x) = ⊥;
−
+
(z) = ⊥.
(z) = ¬ϕ; pC(ϕ)
• pC(ϕ)
−
−
+
+
(z) = ⊥. There(z) ∧ pC(ϕ)
(x) = ⊥; moreover, pC(ϕ)
(x) ∧ pC(ϕ)
For any variable x 6= z, we have pC(ϕ)
−
+
fore, C(ϕ) is locally consistent. Now, for any variable x 6= z, we have pC(ϕ) (x) ∨ pC(ϕ)
(x) = ⊤.
−
+
Moreover, pC(ϕ) (z) ∨ pC(ϕ) (z) = ¬ϕ. Thus, C(ϕ) is locally complete if and only if ϕ is unsatisfiable.
It follows that C(ϕ) is a CP-net if and only if ϕ is unsatisfiable.


Many works on CP-nets make use of explicit conditional preference tables that list every combination of values of parent variables (variables on which x depends) exactly once, each such combination designating either x or ¬x as preferred.3 Clearly, CP-nets in this restricted sense can be
regarded as CP-nets in our sense that, for every variable x, satisfy the following condition:
if y1 , . . . , yk are all the atoms appearing in p+ (x) and p− (x) then every complete and
consistent conjunction of literals over {y1 , . . . , yn } appears as a disjunct in exactly one
of p+ (x) and p− (x).
3. There are exceptions. Some are discussed for instance by Boutilier et al. (2004a) in Section 6 of their paper.

407

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Under this embedding, the concepts of dominance and consistency we introduced here for GCP-nets
generalize the ones considered for CP-nets as defined by Boutilier et al. (2004a).
Problems CP - DOMINANCE and CP - CONSISTENCY are defined analogously to Definition 3. In
the paper we are interested in the complexity of dominance and consistency problems for both GCPnets and CP-nets. Therefore, the matter of the way in which these nets (especially CP-nets, as for
GCP-nets there are no alternative proposals) are represented is important. Our representation of
CP-nets is often more compact than the one proposed by Boutilier et al. (2004a), as the formulas
p+ (x) and p− (x) implied by the conditional preference tables can often be given equivalent, but
exponentially smaller, disjunctive normal form representations. Thus, when defining a decision
problem, it is critical to specify the way to represent its input instances, as the representation may
affect the complexity of the problem. Unless stated otherwise, we assume that GCP-nets (and thus,
CP-nets) are represented as a set of preference rules, as described in Definition 1. Therefore, the
size of a GCP-net is given by the total size of the formulas p− (x), p+ (x), x ∈ V .
We now note a key property of consistent GCP-nets, which we will use several times later in the
paper.
Proposition 2 If a GCP-net C is consistent then it is locally consistent.
Proof: If C is not locally consistent then there exists a variable x and an outcome α satisfying
pC− (x) ∧ pC+ (x). Then α ≺ α can be shown by flipping x from its current value in α to the dual value
and then flipping it back: since α satisfies pC− (x) ∧ pC+ (x), and since pC− (x) ∧ pC+ (x) does not involve
any occurrences of x, both flips are allowed.

Finally, we conclude this section with an example illustrating the notions discussed above.
Example 1 Consider a GCP-net C on variables V = {x, y} with four rules, defined as follows:
x : y > ¬y; ¬x : ¬y > y; y : ¬x > x; ¬y : x > ¬x. We have p+ (y) = x, p− (y) = ¬x, p+ (x) = ¬y and
p− (x) = y. Therefore C is locally consistent and locally complete, and so is a CP-net.
There is a cycle of dominance between outcomes: x ∧ y ≺ ¬x ∧ y ≺ ¬x ∧ ¬y ≺ x ∧ ¬y ≺ x ∧ y,
and so C is inconsistent. This shows that consistency is a strictly stronger property than local
consistency.

3. Propositional STRIPS Planning
In this section we derive some technical results on propositional STRIPS planning which form the
basis of our complexity results in Sections 4 and 5. We establish the complexity of plan existence
problems for propositional STRIPS planning under restrictions on input instances that make the
problem of use in the studies of dominance and consistency in GCP-nets.
Let V be a finite set of variables. A state over V is a complete and consistent set of literals over
V , which we often view as the conjunction of its members. A state is therefore equivalent to an
outcome, defined in a CP-nets context.
Definition 6 (Propositional STRIPS planning) By a propositional STRIPS instance we mean a
tuple hV, α0 , γ, ACTi, where
1. V is a finite set of propositional variables;
408

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

2. α0 is a state over V , called the initial state;
3. γ is a state called the goal;4
4. ACT is a finite set of actions, where each action a ∈ ACT is described by a consistent conjunction of literals pre(a) (a precondition) and a consistent conjunction of literals post(a) (a
postcondition, or effect).5
An action a is executable in a state α if α |= pre(a). The effect of a in state α, denoted by eff (a, α),
is the state α′ containing the same literals as α for all variables not mentioned in post(a), and
the literals of post(a). We assume that an action can be applied to any state, but that it does not
change the state if its preconditions do not hold: if α 6|= pre(a) (given that states are complete,
this is equivalent to α |= ¬pre(a)) then eff (a, α) = α. This assumption has no influence as far as
complexity results are concerned.
The PROPOSITIONAL STRIPS PLAN EXISTENCE problem, or STRIPS PLAN for short, is to decide whether for a given propositional STRIPS instance hV, α0 , γ, ACTi there is a finite sequence
of actions leading from the initial state α0 to the final state γ. Each such sequence is a plan for
hV, α0 , γ, ACTi. A plan is irreducible if every one of its actions changes the state.
We assume, without loss of generality, that for any action a, no literal in post(a) appears also
in pre(a); otherwise we can omit the literal from post(a) without changing the effect of the action;
if post(a) then becomes an empty conjunction, the action a can be omitted from ACT as it has no
effect.
We have the following result due to Bylander (1994).
Proposition 3 (Bylander, 1994)

STRIPS PLAN

is PSPACE-complete.

Typically, propositional STRIPS instances do not require that goals be states. Instead, goals are
defined as consistent conjunctions of literals that do not need to be complete. In such a setting, a
plan is a sequence of actions that leads from the start state to a state in which the goal holds. We
restrict consideration to complete goals. This restriction has no effect on the complexity of the plan
existence problem: it remains PSPACE-complete under the goal-completeness restriction (Lang,
2004).
3.1 Acyclic STRIPS
Definition 7 (Acyclic sets of actions) A set of actions ACT (we use the same notation as in Definition 6) is acyclic if there is no state α such that hV, α, α, ACTi has a non-empty irreducible plan,
that is to say, if there are no non-trivial directed cycles in the graph on states induced by ACT.
We will now establish the complexity of the following problem:
ACTION - SET ACYCLICITY :

given a set ACT of actions, decide whether ACT is acyclic.

Proposition 4
ACTION - SET ACYCLICITY is PSPACE-complete.
4. Note that in standard STRIPS the goal can be a partial state. This point is discussed just after Proposition 3.
5. We emphasize that we allow negative literals in preconditions and goals. Some definitions of STRIPS do not allow
this. This particular variant of STRIPS is sometimes called PSN (propositional STRIPS with negation) in the literature.

409

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Proof: The argument for the membership in PSPACE is standard; we nevertheless give some details.
We will omit such details for further proofs of membership in PSPACE. The following nondeterministic algorithm decides that ACT has a cycle:
guess α0 ;
α := α0 ;
repeat
guess an action a ∈ ACT ;
α′ := eff (a, α);
α := α′
until α = α0 .
This algorithm works in nondeterministic polynomial space (because we only need to store α0 ,
α and α′ ), which shows that ACTION - SET ACYCLICITY is in NPSPACE, and therefore in PSPACE,
since NPSPACE = PSPACE. Thus, ACTION - SET ACYCLICITY is in coPSPACE, hence in PSPACE,
since coPSPACE = PSPACE.
We will now show that the complement of the ACTION - SET ACYCLICITY problem is PSPACEhard by reducing the ACYCLIC STRIPS PLAN problem to it.
Let PE = hV, α0 , γ, ACTi be an instance of the ACYCLIC STRIPS PLAN problem. In particular,
we have that ACT is acyclic. Let a be a new action defined by pre(a) = γ and post(a) = α0 . It is easy
to see that ACT ∪ {a} is not acyclic if and only if there exists a plan for PE. Thus, the PSPACEhardness of the complement of the ACTION - SET ACYCLICITY problem follows from Proposition
5. Consequently, the ACTION - SET ACYCLICITY problem is coPSPACE-hard. Since PSPACE =
coPSPACE, the ACTION - SET ACYCLICITY problem is PSPACE-hard, as well.

Next, we consider the STRIPS planning problem restricted to instances that have acyclic sets of
actions. Formally, we consider the following problem:
ACYCLIC STRIPS PLAN : Given a propositional STRIPS instance hV, α0 , γ, ACTi such
that ACT is acyclic and α0 6= γ, decide whether there is a plan for hV, α0 , γ, ACTi

This is the first of our problems of the form “Q, given R” that we encounter and it illustrates
well the concerns we discussed at the end of the introduction. Here, R is the set of all propositional
STRIPS instances hV, α0 , γ, ACTi such that ACT is acyclic, and Q is the set of all such instances for
which there is a plan for hV, α0 , γ, ACTi. Checking whether a given propositional STRIPS instance
is actually acyclic is itself PSPACE-complete (this is what Proposition 4 states), but this does not
matter when it comes to solving ACYCLIC STRIPS PLAN: when considering an instance of ACYCLIC
STRIPS PLAN , we already know that it is acyclic (and this is reflected in the reduction below).
Proposition 5
ACYCLIC STRIPS PLAN

is PSPACE-complete.

Proof: The argument for the membership in PSPACE is standard (cf. the proof of Proposition 4). To
prove PSPACE-hardness, we first exhibit a polynomial-time reduction F from STRIPS PLAN. Let
PE = hV, α0 , γ, ACTi be an instance of STRIPS PLAN. The idea behind the reduction is to introduce
a counter, so that each time an action is executed, the counter is incremented. The counter may
count up to 2n , where n = |V |, making use of n additional variables. The counter is initialized to
410

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

0. Once it reaches 2n − 1 it can no longer be incremented and no action can be executed. Hence,
the set of actions in the resulting instance of STRIPS PLAN is acyclic: we are guaranteed to produce
an instance of R. To describe the reduction, we write V as {x1 , . . . , xn }. We define F(PE) = PE′ =
hV ′ , α′0 , γ′ , ACT ′ i as follows:
• V ′ = {x1 , . . . , xn , z1 , . . . , zn }, where zi are new variables we will use to implement the counter;
• α′0 = α0 ∧ ¬z1 ∧ · · · ∧ ¬zn ;
• γ′ = γ ∧ z1 ∧ · · · ∧ zn ;
• for each action a ∈ ACT, we include in ACT ′ n actions ai , 1 ≤ i ≤ n, such that:

pre(ai ) = pre(a) ∧ ¬zi ∧ zi+1 ∧ · · · ∧ zn
– for i ≤ n − 1 :
post(ai ) = post(a) ∧ zi ∧ ¬zi+1 ∧ · · · ∧ ¬zn , and

pre(an ) = pre(a) ∧ ¬zn
– for i = n :
post(an ) = post(a) ∧ zn .
• Furthermore, we include in ACT ′ n actions bi , 1 ≤ i ≤ n, such that:

pre(bi ) = ¬zi ∧ zi+1 ∧ · · · ∧ zn
– for i ≤ n − 1 :
post(bi ) = zi ∧ ¬zi+1 ∧ · · · ∧ ¬zn , and

pre(bn ) = ¬zn
– for i = n :
post(bn ) = zn .
We will denote states over V ′ by pairs (α, k), where α is a state over V and k is an integer, 0 ≤
k ≤ 2n − 1. We view k as a compact representation of a state over variables z1 , . . . , zn : assuming that
the binary representation of k is d1 . . . dn (with dn being the least significant digit), k represents the
state which contains zi if di = 1 and ¬zi , otherwise. For instance, let V = {x1 , x2 , x3 }. Then we have
V ′ = {x1 , x2 , x3 , z1 , z2 , z3 }, and the state ¬x1 ∧ x2 ∧ x3 ∧ z1 ∧ ¬z2 ∧ z3 is denoted by (¬x1 ∧ x2 ∧ x3 , 5).
We note that the effect of ai or bi on state (α, k) is either void, or increments the counter:
eff (ai , (α, k)) =



(eff (a, α), k + 1) if ai is executable in (α, k)
(α, k)
otherwise

eff (bi , (α, k)) =



(α, k + 1) if bi is executable in (α, k)
(α, k)
otherwise

Next, we remark that at most one ai and at most one bi are executable in a given state (α, k).
More precisely,
• if k < 2n − 1, then exactly one bi is executable in (α, k); denote by i(k) the index such that bi(k)
is executable in (α, k) (this index depends only on k). We also have that ai(k) is executable in
(α, k), provided that a is executable in α.
• if k = 2n − 1, then no ai and no bi is executable in (α, k).
411

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Now we show that PE′ is acyclic. Assume π is an irreducible plan for hV ′ , α′ , α′ , ACT ′ i. Let
= (α, k). If k < 2n − 1, then π is empty, since any action in ACT ′ in any state either is nonexecutable or increments the counter, and an irreducible plan contains only actions whose effect is
non-void. If k = 2n − 1, then no action of ACT ′ is executable in α′ and again π is empty. Thus, there
exists no non-empty irreducible plan for hV ′ , α′ , α′ , ACT ′ i, and this holds for all α′ . Therefore PE′
is acyclic.
We now claim that there is a plan for PE if and only if there is a plan for PE′ . First, assume that
there is a plan in PE. Let π be a shortest plan in PE and let m be its length (the number of actions
used). We have m ≤ 2n − 1, since no state along π repeats (otherwise, shorter plans than π for PE
would exist). Let α0 , α1 , . . . , αm = γ be the sequence of states obtained by executing π. Let a be the
action used in the transition from αk to αk+1 . Since k < 2n − 1 (because m ≤ 2n − 1 and k ≤ m − 1),
there is exactly one i, 1 ≤ i ≤ n, such that the action ai applies at the state (α, k) over V ′ . Replacing
a with ai in π yields a plan that when started at (α0 , 0) leads to (αm , m) = (γ, m). Appending that
plan with appropriate actions bi to increment the counter to 2n − 1 yields a plan for PE′ . Conversely,
if τ is a plan for PE′ , the plan obtained from τ by removing all actions of the form b j and replacing
each action ai with a is a plan for PE, since ai has the same effect on V as a does. Thus, the claim
follows.

α′

We emphasize that this reduction F from STRIPS PLAN to ACYCLIC STRIPS PLAN (or, equivalently, to STRIPS PLAN given ACTION - SET ACYCLICITY) works because it satisfies the following
two conditions:
1. for every instance PE of STRIPS PLAN, F(PE) is an instance of ACYCLIC STRIPS PLAN (this
holds because for every PE, F(PE) is acyclic);
2. for every PE of STRIPS PLAN, F(PE) is a positive instance of ACYCLIC
only if PE is a positive instance of STRIPS PLAN.

STRIPS PLAN

if and

3.2 Mapping STRIPS Plans to Single-Effect STRIPS Plans
Versions of the STRIPS PLAN and ACYCLIC STRIPS PLAN problems that are important for us allow only actions with exactly one literal in their postconditions in their input propositional STRIPS
instances. We call such actions single-effect actions.6 We refer to the restricted problems as SE
STRIPS PLAN and ACYCLIC SE STRIPS PLAN , respectively.
To prove PSPACE-hardness of both problems, we describe a mapping from STRIPS instances to
single-effect STRIPS instances.7
Consider an instance PE = hV, α0 , γ, ACTi of the STRIPS PLAN problem, where ACT is not necessarily acyclic. For each action a ∈ ACT we introduce a new variable xa , whose intuitive meaning
is that action a is currently being executed.
V
We set X = a∈ACT ¬xa . That is, X is the conjunction of negative literals of all the additional
V
variables. In addition, for each a ∈ ACT we set Xa = xa ∧ b∈ACT−{a} ¬xb . We now define an
instance PE′ = hV ′ , α′0 , γ′ , S(ACT)i of the SE STRIPS PLAN problem as follows:
6. Such actions are also called “unary” actions in the planning literature. We stick to the terminology “single-effect”
although it is less commonly used, simply because it is more explicit.
7. PSPACE-completeness of propositional STRIPS planning with single-effect actions was proved already by Bylander
(1994). However, to deal with acyclicity we need to give a different reduction than the one used in that paper.

412

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

• Set of variables: V ′ = V ∪ {xa : a ∈ ACT};
• initial state: α′0 = α0 ∧ X;
• goal state: γ′ = γ ∧ X;
• set of actions: S(ACT) = {ai : a ∈ ACT, i = 1, . . . , 2|post(a)| + 1}.
Let a be an action in ACT such that post(a) = l1 ∧ · · · ∧ lq , where l1 , . . . , lq are literals.
– For i = 1, . . . , q, we define an action ai by setting:
pre(ai ) = pre(a) ∧ X ∧ ¬li ; post(ai ) = xa .
The role of ai is to enforce that Xa holds after ai is successfully applied, and in this
way to enable “starting the execution of a”, provided that no action is currently being
executed, that the ith effect of a is not already true, and that the precondition of a is true.
– For i = q + 1, . . . , 2q, we define action ai by setting:
pre(ai ) = Xa ; post(ai ) = li .
The role of ai is to make the ith effect of a true.
– Finally, we define a2q+1 by setting:
pre(a2q+1 ) = Xa ∧ l1 ∧ · · · ∧ lq ; post(a2q+1 ) = ¬xa .
Thus, a2q+1 is designed so that X holds after a2q+1 is successfully applied; that is, a2q+1
“closes” the execution of a, thus allowing for the next action to be executed.
Let π be a sequence of actions in ACT. We define S(π) to be the sequence of actions in S(ACT)
obtained by replacing each action a in π by a1 , . . . , a2q+1 , where q = |post(a)|. Now consider a
sequence τ of actions from S(ACT). Remove from τ every action ai such that i 6= 2|post(a)| + 1,
and replace actions of the form a2|post(a)|+1 by a. We denote the resulting sequence of actions from
ACT by S′ (τ). We note that S′ (S(π)) = π. The following properties then hold.
Lemma 1 With the above definitions,
(i) if π is a plan for PE then S(π) is a plan for PE′ ;
(ii) if τ is an irreducible plan for PE′ then S′ (τ) is an irreducible plan for PE;
(iii) ACT is acyclic if and only if S(ACT) is acyclic.
Proof: (i) Let a ∈ ACT be an action, let α be a state and let β be the state obtained from α by
applying a. Let θ be the V ′ -state obtained by applying the sequence of actions ha1 , . . . , a2q+1 i
(where q = |post(a)|) to the state α ∧ X of PE′ . We will show that θ = β ∧ X.
We note that if for each i = 1, . . . , q, state α ∧ X does not satisfy pre(ai ) then the sequence of
actions ha1 , . . . , a2q+1 i has no effect, so the state is still α ∧ X. For this to happen, either α doesn’t
satisfy pre(a), or all of l1 , . . . , lq already hold in α so post(a) holds in α. In either case, α = β, and
so θ = β ∧ X.
413

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Suppose now that for some i ∈ {1, . . . , q}, α does satisfy pre(ai ). Then the first such action
causes xa and hence Xa to hold. After applying actions aq+1 , . . . , a2q , l1 ∧ · · · ∧ lq holds, and so
post(a) holds. After applying a2q+1 both post(a) and X hold. No other variable in V has changed,
so θ = β ∧ X, as required.
Applying this result iteratively implies that if π is a plan for PE then S(π) is a plan for PE′ .

ai

(ii) Let τ be an irreducible plan for PE′ , so that every action in τ changes the state, which implies
that every action in τ is performed in a state where its precondition is true. We will show that S′ (τ)
/ When τ = 0,
/ S′ (τ) = 0,
/ too, and the assertion follows.
is a plan for PE. We will assume that τ 6= 0.
j
′
Write the first action in τ as a , where a ∈ ACT, and let τ be the maximal initial subsequence of
τ consisting of all actions of the form ai . We must have j ≤ |post(a)|, since X holds in α′0 (by our
assumption above, action a j does apply) and X is inconsistent with the precondition of ai for each
i > |post(a)|. Also, pre(a j ) and ¬l j hold in α′0 and so, in α0 as well. Thus, α0 satisfies pre(a), and
applying a changes the state, since ¬l j holds in α0 and post(a) |= l j . Let us denote by β the state
resulting from applying a to α0 . As we noted, β 6= α0 ,
Let β′ be the state resulting after applying τ′ to α′0 . If β′ is the goal state γ′ then X holds in β′ . If
β′ is not the goal state then τ 6= τ′ . Let bi be the action in τ directly following the last action in τ′ .
By the definition of τ′ , a 6= b. After applying a j , Xa holds, so in β′ either Xa holds or X holds. Thus,
Xb does not hold, as a 6= b. Since bi changes the state, i must be in {1, . . . , |post(b)|}, so X holds in
β′ in this case, too.
Hence the last action in τ′ is a2q+1 , where q = |post(a)|. Since the only variables in V which can
be affected by actions ai are those that appear in the literals in post(a) and since the action a2q+1
can be executed (otherwise it would not belong to τ), it follows that β′ = β ∧ X.
Applying this reasoning repeatedly, we show that applying S′ (τ) to α0 yields γ, and that each
action in S′ (τ) changes the state, so S′ (τ) is an irreducible plan for PE, which is non-empty if and
only if τ is non-empty.
(iii) Suppose ACT is not acyclic, so that there exists state α and a non-empty irreducible plan π for
PEα = hV, α, α, ACTi. Then, by (i), S(π) is a plan for PE′α = hV ′ , α ∧ X, α ∧ X, S(ACT )i. Because
π is non-empty and irreducible, it changes some state, so S(π) also changes some state, and hence
can be reduced to a non-empty irreducible plan for PE′α . Therefore S(ACT) is not acyclic.
Conversely, suppose that S(ACT) is not acyclic. Then there exists a state α′ and a non-empty
irreducible plan τ for hV ′ , α′ , α′ , S(ACT)i. We will first prove that X holds at some state obtained
during the execution of this plan.
/ By
Suppose that X holds at no such state, and let a j be the first action in τ. We note that τ 6= 0.
our assumption, X does not hold either before or after applying a j . Therefore q + 1 ≤ j ≤ 2q, where
q = |post(a)|. Since τ is irreducible, a j changes the state. Thus, ¬l j holds in α′ and l j holds in the
state resulting from α′ after applying a j .
By our assumption, Xa holds before and after applying a j . Thus, the next action, if there is one,
must also be of the form ai for q + 1 ≤ i ≤ 2q. Repeating this argument implies that all actions in
τ are of the form ai where q + 1 ≤ i ≤ 2q. Since the set of literals in post(a) is consistent, l j is
never reset back to ¬l j . Thus, the state resulting from α′ after applying τ is different from α′ , a
contradiction.
Thus, X holds at some state reached during the execution of τ. Let us consider one such state.
It can be written as β ∧ X, for some state β over V . We can cyclically permute τ to generate a
non-empty irreducible plan τ′ for hV ′ , β ∧ X, β ∧ X, S(ACT)i. By part (ii), S′ (τ′ ) is a non-empty
414

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

irreducible plan for hV, β, β, ACTi. Therefore ACT is not acyclic.



Proposition 6
SE STRIPS PLAN

and ACYCLIC SE STRIPS PLAN are PSPACE-complete.

Proof: Again, the argument for the membership in PSPACE is standard. PSPACE-hardness of
ACYCLIC SE STRIPS PLAN is shown by reduction from ACYCLIC STRIPS PLAN . The same construction shows that STRIPS PLAN is reducible to SE STRIPS PLAN, and thus SE STRIPS PLAN is
PSPACE-complete.
Let us consider an instance PE = hV, α0 , γ, ACTi of ACYCLIC STRIPS PLAN. We define PE′ =
′
hV , α′0 , γ′ , S(ACT)i, which by Lemma 1(iii) is an instance of the ACYCLIC SE STRIPS PLAN problem. By Lemma 1(i) and (ii) there exists a plan for PE if and only if there exists a plan for PE′ . This
implies that ACYCLIC SE STRIPS PLAN is PSPACE-hard.


4. Dominance
The goal of this section is to prove that the GCP - DOMINANCE problem is PSPACE-complete, and
that the complexity does not go down even when we restrict the class of inputs to CP-nets. We
use the results on propositional STRIPS planning from Section 3 to prove that the general GCP DOMINANCE problem is PSPACE-complete. We then show that the complexity does not change if
we require the input GCP-net to be locally consistent and locally complete.
The similarities between dominance testing in CP-nets and propositional STRIPS planning were
first noted by Boutilier et al. (1999). They presented a reduction, discussed later in more detail by
Boutilier et al. (2004a), from the dominance problem to the plan existence problem for a class
of propositional STRIPS planning specifications consisting of unary actions (actions with single
effects). We prove our results for the GCP - DOMINANCE and GCP - CONSISTENCY problems by constructing a reduction in the other direction.
This reduction is much more complex than the one used by Boutilier et al. (1999), due to the
fact that CP-nets impose more restrictions than STRIPS planning. Firstly, STRIPS planning allows
multiple effects, but GCP-nets only allow flips x > ¬x or ¬x > x that change the value of one
variable; this is why we constructed the reduction from STRIPS planning to single-effect STRIPS
planning in the last section. Secondly, CP-nets impose two more restrictions, local consistency and
local completeness, which do not have natural counterparts in the context of STRIPS planning.
For all dominance and consistency problems we consider, the membership in PSPACE can be
demonstrated similarly to the membership proof of Proposition 4, namely by considering nondeterministic polynomial space algorithms consisting of repeatedly guessing appropriate improving flips
and making use of the fact that PSPACE = NPSPACE = coPSPACE. Therefore, from now on we
only provide arguments for the PSPACE-hardness of problems we consider.
4.1 Dominance for Generalized CP-Nets
We will prove that the GCP - DOMINANCE problem is PSPACE-complete by a reduction from the
problem SE STRIPS PLAN, which we now know to be PSPACE-complete.
415

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

4.1.1 M APPING S INGLE -E FFECT STRIPS P ROBLEMS
P ROBLEMS

TO

GCP-N ETS D OMINANCE

Let hV, α0 , γ, ACTi be an instance of the SE STRIPS PLAN problem. For every action a ∈ ACT
we denote by la the unique literal in the postcondition of a, that is, post(a) = la . We denote by
pre′ (a) the conjunction of all literals in pre(a) different from ¬la (we recall that by a convention we
adopted earlier, pre′ (a) does not contain la ). We then define ca to be the conditional preference rule
pre′ (a) : la > ¬la and define M(ACT) to be the GCP-net C = {ca : a ∈ ACT}, which is in conjunctive
form.
A sequence of states in a plan corresponds to an improving sequence from α0 to γ, which leads
to the following result.
Lemma 2 With the above notation,
(i) there is a non-empty irreducible plan for hV, α0 , γ, ACTi if and only if γ dominates α0 in
M(ACT);
(ii) ACT is acyclic if and only if M(ACT) is consistent.
Proof: We first note the following equivalence. Let a be an action in ACT, and let α and β be
different outcomes (or, in the STRIPS setting, states). The action a applied to α yields β if and only
if the rule ca sanctions an improving flip from α to β. This is because a applied to α yields β if and
only if α satisfies pre(a) and α and β differ only on literal la , with β satisfying la and α satisfying
¬la . This is if and only if α satisfies pre′ (a) and α and β differ only on literal la , with β satisfying
la , and α satisfying ¬la . This, in turn, is equivalent to say that rule ca sanctions an improving flip
from α to β.
Proof of (i): Suppose first that there exists a non-empty irreducible plan a1 , . . . , am for hV, α0 , γ, ACTi.
Let α0 , α1 , . . . , αm = γ be the corresponding sequence of outcomes, and, for each i = 1, . . . , m, action ai , when applied in state αi−1 , yields different state αi . By the above equivalence, for each
i = 1, . . . , m, cai sanctions an improving flip from αi−1 to αi , which implies that α0 , α1 , . . . , αm is an
improving flipping sequence in M(ACT), and therefore γ dominates α0 in M(ACT).
Conversely, suppose that γ dominates α0 in M(ACT), so that there exists an improving flipping
sequence α0 , α1 , . . . , αm with αm = γ, and m ≥ 1. For each i = 1, . . . , m, let cai be an element of
M(ACT) which sanctions the improving flip from αi−1 to αi . Then, by the above equivalence,
action ai , when applied to state αi−1 yields αi (which is different from αi−1 ), and so a1 , . . . , am is a
non-empty irreducible plan for hV, α0 , γ, ACTi.
Proof of (ii): ACT is not acyclic if and only if there exists a state α and a non-empty irreducible
plan for hV, α, α, ACTi. By (i) this is if and only if there exists an outcome α which dominates itself
in M(ACT), which is if and only if M(ACT) is not consistent.


Theorem 1 The GCP - DOMINANCE problem is PSPACE-complete. Moreover, this remains so under
the restrictions that the GCP-net is consistent and is in conjunctive form.
Proof: PSPACE-hardness is shown by reduction from ACYCLIC SE STRIPS PLAN (Proposition 6).
Let hV, α0 , γ, ACTi be an instance of the ACYCLIC SE STRIPS PLAN problem. By Lemma 2(ii),
M(ACT) is a consistent GCP-net in conjunctive form. Since α0 6= γ (imposed in the definition of
416

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

the problem ACYCLIC SE STRIPS PLAN), there is a plan for hV, α0 , γ, ACTi if and only if there is a
non-empty irreducible plan for hV, α0 , γ, ACTi, which, by Lemma 2(i), is if and only if γ dominates
α0 in C.

Theorem 1 implies the PSPACE-completeness of dominance in the more general conditional
preference language introduced by Wilson (2004b), where the conditional preference rules are written in conjunctive form.
4.2 Dominance in CP-Nets
In this section we show that GCP - DOMINANCE remains PSPACE-complete under the restriction to
locally consistent and locally complete GCP-nets, that is, CP-nets. We refer to this restriction of
GCP - DOMINANCE as CP - DOMINANCE .
Consistency of a GCP-net implies local consistency (Proposition 2). Therefore, the reduction in the proof of Theorem 1 (from ACYCLIC SE STRIPS PLAN to GCP - DOMINANCE restricted
to consistent GCP-nets) is also a reduction to GCP - DOMINANCE restricted to locally consistent
GCP-nets. PSPACE-hardness of ACYCLIC SE STRIPS PLAN (Proposition 6) then implies that GCP DOMINANCE restricted to locally consistent GCP-nets is PSPACE-hard, and, in fact, PSPACEcomplete since membership in PSPACE is easily obtained with the usual line of argumentation.
We will show PSPACE-hardness for CP - DOMINANCE by a reduction from GCP - DOMINANCE
for consistent GCP-nets.
4.2.1 M APPING L OCALLY C ONSISTENT GCP-N ETS

TO

CP-N ETS

Let C be a locally consistent GCP-net. Let V = {x1 , . . . , xn } be the set of variables of C. We define
/ We define a GCP-net C′ over V ′ , which we
V ′ = V ∪ {y1 , . . . , yn }, where {y1 , . . . , yn } ∩ V = 0.
will show is a CP-net. To this end, for every z ∈ V ′ we will define conditional preference rules
q+ (z) : z > ¬z and q− (z) : ¬z > z to be included in C′ by specifying formulas q+ (z) and q− (z).
First, for each variable xi ∈ V , we set
q+ (xi ) = yi and q− (xi ) = ¬yi .
Thus, xi depends only on yi . We also note that the formulas q+ (xi ) and q− (xi ) satisfy local consistency and local completeness requirements.
Next, for each variable yi , 1 ≤ i ≤ n, we define
ei = (x1 ↔ y1 ) ∧ · · · ∧ (xi−1 ↔ yi−1 ) ∧ (xi+1 ↔ yi+1 ) ∧ · · · ∧ (xn ↔ yn ),
fi+ = ei ∧ p+ (xi ) and fi− = ei ∧ p− (xi ).
Finally, we define
q+ (yi ) = fi+ ∨ (¬ fi− ∧ xi )
and
q− (yi ) = fi− ∨ (¬ fi+ ∧ ¬xi ).
Thus, yi depends on every variable in V ′ but itself.
We note that by the local consistency of C, formulas fi+ ∧ fi− , 1 ≤ i ≤ n, are unsatisfiable.
Consequently, formulas q+ (yi ) ∧ q− (yi ), 1 ≤ i ≤ n, are unsatisfiable. Thus, C′ is locally consistent.
417

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Finally, q+ (yi ) ∨ q− (yi ) is equivalent to fi+ ∨ ¬xi ∨ fi− ∨ xi , so is a tautology. Thus, C′ is locally
complete and hence a CP-net over V ′ .
Let α and β be outcomes over {x1 , . . . , xn } and {y1 , . . . , yn }, respectively. By αβ we denote the
outcome over V ′ obtained by concatenating n-tuples α and β. Conversely, every outcome for C′ can
be written in this way.
Let α be an outcome over V . We define α to be the outcome over {y1 , . . . , yn } obtained by
replacing in α every component of the form xi with yi and every component ¬xi with ¬yi . Then for
every i, 1 ≤ i ≤ n, αα |= ei .
Let s be a sequence α0 , . . . , αm of outcomes over V . Define L(s) to be the sequence of V ′ outcomes: α0 α0 , α0 α1 , α1 α1 , α1 α2 , . . . , αm αm . Further, let t be a sequence ε0 , ε1 , . . . , εm of V ′ outcomes with ε0 = αα and εm = ββ. Define L′ (t) to be the sequence obtained from t by projecting
each element in t to V and iteratively removing elements in the sequence which are the same as their
predecessor (until any two consecutive outcomes are different).
Lemma 3 With the above definitions,
(i) if s is an improving sequence for C from α to β then L(s) is an improving sequence for C′ from
αα to ββ;
(ii) if t is an improving sequence from αα to ββ then L′ (t) is an improving sequence from α to β;
(iii) C is consistent if and only if C′ is consistent.
Proof: Let e = ni=1 (xi ↔ yi ). The definitions have been arranged so that the GCP-net C and the
CP-net C′ have the following properties:
(a) If e does not hold in an outcome γ over V ′ , then every improving flip applicable to γ changes the
value of some variable xi or yi so that xi ↔ yi holds after the flip.
Indeed, let us assume that there is an improving flip from γ to some outcome γ′ over V ′ . If the
flip concerns a variable xi , then xi ↔ ¬yi holds in γ. Consequently, xi ↔ yi holds in γ′ .
Thus, let us assume that the flip concerns a variable yi . If ei holds in γ then, since e does not,
xi ↔ ¬yi holds in γ. Thus, xi ↔ yi holds in γ′ . If ei does not hold in γ then neither fi+ nor fi− does.
Thus, if xi (¬xi , respectively) holds in γ, yi (¬yi , respectively) holds in γ′ . Since the flip concerns yi ,
it follows that xi ↔ yi holds in γ′ .
(b) No improving flip from αα changes any variable xi .
Indeed, for any variable xi , since e holds in αα, xi ↔ yi holds in αα, too. Thus, no improving
flip changes xi .
(c) There is an improving flip in C′ that changes variable yi in an outcome αα if and only if there is
an improving flip for the GCP-net C from outcome α that changes variable xi . After applying the
improving flip (changing variable yi ) to αα, there is exactly one improving flip possible. It changes
xi and results in an outcome ββ, where β is the outcome over V resulting from applying to α the
improving flip changing the variable xi .
To prove (c), let us first assume that ¬yi holds in αα and observe that in such case ¬xi holds in
αα, too. It follows that q+ (yi ) holds in αα if and only if p+ (xi ) holds in α. Consequently, changing
yi in αα is an improving flip in C′ if and only if changing xi in α is an improving flip in C. The
argument in the case when yi holds in αα is analogous (but involves q− (yi ) and p− (xi )). Thus, the
first part of (c) follows.
V

418

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

Let β be the outcome obtained by applying an improving flip to xi in α. It follows that the
improving flip changing the value of yi in αα results in the outcome αβ. In this outcome, by (a),
an improving flip must concern x j or y j such that x j ↔ y j holds after the flip. Since for every j 6= i,
x j ↔ y j holds in αβ, the only improving flips in αβ concern either xi or yi . By the local consistency
of C′ , yi cannot be flipped right back. Clearly, changing xi is an improving flip that can be applied
to αβ. By our discussion, it is the only improving flip applicable in αβ and it results in the outcome
ββ. This proves the second part of (c).
Proof of (i): The assertion follows by iterative application of (c).
Proof of (ii): Suppose that t is an improving sequence ε0 , ε1 , . . . , εm of V ′ -outcomes with ε0 = αα
and εm = ββ. Since e holds in ε0 , (b) implies that the first flip changes some variable yi , and (c)
implies that the second flip changes variable xi to make xi ↔ yi hold again. Hence ε2 can be written
as δδ. By (c) there is an improving flip in C from outcome α changing variable xi , that is, leading
from α to δ. Iterating this process shows that L′ (t) is an improving sequence from α to β.
Proof of (iii): Suppose that C is inconsistent. Then there exists some outcome α and an improving
sequence s in C from α to α. By (i), L(s) is an improving sequence from αα to αα, proving that C′
is inconsistent.
Conversely, suppose that C′ is inconsistent, so there exists an improving sequence t for C′ from
some outcome to itself. By (a), any improving flip applied to an outcome in which e does not hold
increases (by one) the number of i such that xi ↔ yi holds. This implies that e must hold in some
outcome in t, because t is not acyclic. Write this outcome as αα. We can cyclically permute t to
form an improving sequence t2 from αα to itself. Part (ii) then implies that L′ (t2 ) is an improving
flipping sequence for C from α to itself, showing that C is inconsistent.


Theorem 2 CP - DOMINANCE is PSPACE-complete. This holds even if we restrict the CP-nets to
being consistent.
Proof: We use a reduction from PSPACE-hardness of the GCP - DOMINANCE problem when the
GCP-nets are restricted to being consistent (Theorem 1). Let C be a consistent, and hence locally
consistent, GCP-net over V , and let α and β be outcomes over V . Consider the CP-net C′ over
variables V ′ constructed above. Lemma 3(i) and (ii) imply that β dominates α in C if and only if ββ
dominates αα in C′ . Moreover, C′ is consistent by Lemma 3(iii). Consequently, the hardness part
of the assertion follows.

Note that PSPACE-hardness obviously remains if we require input outcomes to be different,
because the reduction for Theorem 1 uses a pair of different outcomes.
Notice the huge complexity gap with the problem of deciding whether there exists a nondominated outcome, which is “only” NP-complete (Domshlak et al., 2003, 2006).

5. Consistency of GCP-Nets
In this section we show that the
from Sections 3 and 4.

GCP - CONSISTENCY

419

problem is PSPACE-complete, using results

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Theorem 3
GCP - CONSISTENCY is PSPACE-complete. This holds even under the restriction to GCP-nets in
conjunctive form.
Proof: PSPACE-hardness is shown by reduction from ACTION - SET ACYCLICITY. We apply function S from Section 3.2 followed by M from Section 4.1. This maps instances of ACTION - SET
ACYCLICITY to instances of GCP - CONSISTENCY in conjunctive form. By Lemma 1(iii) and Lemma
2 (ii), an instance of ACTION - SET ACYCLICITY is acyclic if and only if the corresponding instance
of GCP - CONSISTENCY is consistent, proving the result.

We now show that consistency testing remains PSPACE-complete for CP-nets (GCP-nets that
are both locally consistent and locally complete).
Theorem 4

CP - CONSISTENCY

is PSPACE-complete.

Proof: We use a reduction from GCP - CONSISTENCY under the restriction that the GCP-net is in
conjunctive form. Let C be a GCP-net in conjunctive form. We define a CP-net C′ as follows. Because C is in conjunctive form, local consistency can be decided in polynomial time, as it amounts
to checking the consistency of a conjunction of conjunctions of literals. If C is not locally consistent
we set C′ to be a predetermined inconsistent but locally consistent CP-net, such as in the example
in Section 2. Otherwise, C is locally consistent and for C′ we take the CP-net we constructed in
Section 4.2. The mapping from locally consistent GCP-nets to CP-nets, described in Section 4.2,
preserves consistency (Lemma 3 (iii)). Since local inconsistency implies inconsistency (Proposition 2), we have that the GCP-net C is consistent if and only if the CP-net C′ is consistent. Thus,
PSPACE-hardness of the CP - CONSISTENCY problem follows from Theorem 3.


6. Additional Problems Related to Dominance in GCP-Nets
Having proved our main results on consistency of and dominance in GCP-nets, we move on to
additional questions concerning the dominance relation. Before we state them, we introduce more
terminology.
Let α and β be outcomes in a GCP-net C. We say that α and β are dominance-equivalent in C,
written α ≈C β, if α = β, or α ≺C β and β ≺C α. Next, α and β are dominance-incomparable in C
if α 6= β, α⊀C β and β⊀C α. Finally, α strictly dominates β if β ≺C α and α6≺C β.
Definition 8
We define the following decision problems:
SELF - DOMINANCE : given a GCP-net C and an outcome α, decide whether α ≺C α, that is, whether
α dominates itself in C.
STRICT DOMINANCE : given a GCP-net C and outcomes α and β, decide whether α strictly dominates β in C.
DOMINANCE EQUIVALENCE : given a GCP-net C and outcomes α and β, decide whether α and β
are dominance-equivalent in C.
DOMINANCE INCOMPARABILITY : given a GCP-net C and outcomes α and β, decide whether α
and β are dominance-incomparable in C.
420

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

When establishing the complexity of these problems, we will use polynomial-time reductions
from the problem GCP - DOMINANCE. Let H be a GCP-net with the set of variables V = {x1 , . . . , xn },
and let β be an outcome. We define a GCP-net G = Θ1 (H, β) with the set of variables W = V ∪ {y}
by setting the conditions for flips on variables xi , i = 1, . . . , n, and y as follows:
1. if xi ∈ β:
+
p+
G (xi ) = pH (xi ) ∨ ¬y
−
p−
G (xi ) = pH (xi ) ∧ y
2. if ¬xi ∈ β:
+
p+
G (xi ) = pH (xi ) ∧ y
−
p−
G (xi ) = pH (xi ) ∨ ¬y
3. p+
G (y) = β
4. p−
G (y) = ¬β.
The mapping Θ1 can be computed in polynomial time. Moreover, one can check that if H is a
locally consistent GCP-net, Θ1 (H, β) is also locally consistent. Finally, if H is a CP-net, Θ1 (H, β)
is a CP-net, as well.
For every V -outcome γ, we let γ+ = γ ∧ y and γ− = γ ∧ ¬y. We note that every W -outcome is of
the form γ+ or γ− . To explain the structure of the GCP-net G, we point out that there is an improving
flip in G from γ+ into δ+ if and only if there is an improving flip in H from γ to δ (thus, G restricted
to outcomes of the form γ+ forms a copy of the GCP-net H). Moreover, there is an improving flip
in G from γ− into δ− if and only if δ agrees with β on exactly one more variable xi than γ does.
Finally, an improving flip moves between outcomes of different type if and only if it transforms β−
to β+ , or γ+ to γ− for some γ 6= β.
We now formalize some useful properties of the GCP-net G = Θ1 (H, β). We use the notation
introduced above.
Lemma 4 For every V -outcome γ, γ− ≺G β+ and, if γ 6= β, γ+ ≺G β+ (in other words, β+ dominates
every other W -outcome).
Proof: Consider any V -outcome γ 6= β. Then γ ∧ ¬y ≺C β ∧ ¬y since, given ¬y, changing a literal
to the form it has in β is an improving flip. By the definition, we also have β ∧ ¬y ≺C β ∧ y and
γ ∧ y ≺G γ ∧ ¬y (as γ 6= β). It follows that β− ≺G β+ and γ+ ≺G γ− ≺G β+ . Thus, the assertion
follows.


Lemma 5 For arbitrary V -outcome α different from β, the following statements are equivalent:
1. β ≺H α;
2. β+ ≺G α+ ;
3. β+ ≈G α+ .
421

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Proof: By Lemma 4, α+ ≺G β+ . Thus, the conditions (2) and (3) are equivalent.
[(1)⇒(2)] Clearly (recall our discussion about the structure of G), if there is an improving flip from
γ to δ in H, then there is an improving flip from γ+ to δ+ in G. Thus, if there is an improving
sequence in H from β to α, there is an improving sequence in G from β+ to α+ .
[(2)⇒(1)] Let us assume β+ ≺G α+ , and let us consider an improving sequence of minimum length
from β+ to α+ . By the minimality, no internal element in such a sequence is β+ . Thus, no internal
element equals β− either (as the only improving flip from β− leads to β+ ). Since an improving flip
from γ− to γ+ requires that γ = β, all outcomes in the sequence are of the form γ+ . By dropping
y from each outcome in this sequence, we get an improving flipping sequence from α to β in H.
Thus, β ≺H α.

Lemma 6 Let H be consistent and let α and β be different V -outcomes. Then, α+ ≺G α+ if and
only if β ≺H α.
Proof: Suppose there exists an improving sequence from α+ to itself. There must be an outcome
in the sequence of the form γ ∧ ¬y (otherwise, dropping y in every outcome yields an improving
sequence from α to α in H, contradicting the consistency of H). To perform an improving flip from
¬y to y we need β to hold, which implies that β+ appears in the sequence. Thus, β+ ≺G α+ . By
Lemma 5, β ≺H α.
Conversely, let us assume that β ≺H α. Again by Lemma 5, β+ ≺G α+ . By Lemma 4, α+ ≺G β+ .
Thus, α+ ≺G α+ .

The next construction is similar. Let H be a GCP-net on variables V = {x1 , . . . , xn }, and let α
be an outcome. We define a GCP-net F = Θ2 (H, α) as follows. As before, we set W = V ∪ {y} to
be the set of variables of F. We define the conditions for flips on variables xi , i = 1, . . . , n, and y as
follows:
+
1. p+
G (xi ) = pH (xi ) ∧ y
−
2. p−
G (xi ) = pH (xi ) ∧ y

3. p+
G (y) = ¬α
4. p−
G (y) = α.
Informally, outcomes of the form γ+ form in F a copy of H. There are no improving flips between
outcomes of the form γ− . There is an improving flip from α+ to α− and, for every γ 6= α, from γ− to
γ+ . In particular, if F is consistent then Θ2 (H, α) is consistent, The mapping Θ2 can be computed
in polynomial time and we also have the following property.
Lemma 7 Let β be a V -outcome different from α. Then the following conditions are equivalent:
1. β ≺H α
2. α− strictly dominates β− in F
3. α− and β− are not dominance-incomparable in F.
422

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

Proof: If there exists an improving sequence from β− to α− then the first improving flip in the sequence changes β− to β+ . Moreover, there is an improving flip from γ+ to γ− if and only if γ = α.
Thus, β− ≺F α− if and only if β ≺H α. Since α− ⊀F β− all three conditions are equivalent.


Proposition 7 The following problems are PSPACE-complete: SELF - DOMINANCE, STRICT
INANCE , DOMINANCE EQUIVALENCE , and DOMINANCE INCOMPARABILITY .

DOM -

Proof: For all four problems, membership is proven easily as for the problems in earlier sections.
For the PSPACE-hardness proofs, we use the problem CP - DOMINANCE in a version when we
required that the input CP-net be consistent and the two input outcomes different. The problem is
PSPACE-hard by Theorem 2.
Let H be a consistent CP-net on a set V of variables, and let α and β be two different V -outcomes.
By Lemma 5, β ≺H α can be decided by deciding the problem DOMINANCE EQUIVALENCE for α+
and β+ in the GCP-net Θ1 (H, β). Thus, the PSPACE-hardness of DOMINANCE EQUIVALENCE
follows.
Next, the equivalence of Lemma 6, α+ ≺G α+ ⇔ β ≺H α, which holds due to consistency of H,
shows that the problem SELF - DOMINANCE is PSPACE-hard.
Finally, by Lemma 7, β ≺H α can be decided either by deciding the problem STRICT DOMI NANCE for outcomes α− and β− in Θ2 (H, α), or by deciding the complement of the problem DOM INANCE INCOMPARABILITY for α− and β− in the GCP-net Θ2 (H, α). It follows that STRICT DOM INANCE and DOMINANCE INCOMPARABILITY (the latter by the fact that coPSPACE=PSPACE) are
PSPACE-complete.8


Corollary 1 The problems SELF - DOMINANCE and DOMINANCE EQUIVALENCE are PSPACE-complete under the restriction to CP-nets. The problems STRICT DOMINANCE and DOMINANCE IN COMPARABILITY remain PSPACE-complete under the restriction to consistent CP-nets.
Proof: Since in the proof of Proposition 7 we have that H is a CP-net, the claim for the first two
problems follows by our remarks that the mapping Θ1 preserves the property of being a CP-net.
For the last two problems, we observe that since H in the proof of Proposition 7 is assumed to
be consistent, F = Θ2 (H, α) is consistent, too. Thus, it is also locally consistent and the mapping
F to F ′ we used for the proof of Theorem 2 applies. In particular, F ′ is a consistent CP-net and has
the following properties (implied by Lemma 3):
1. α strictly dominates β in F if and only if αα strictly dominates ββ in F ′
2. α and β are dominance-incomparable in F if and only if αα and ββ are dominance-incomparable in F ′ .
Since F ′ is a consistent CP-net, the claim for the last two problems follows, too.



8. For STRICT DOMINANCE, the result could have been also obtained as a simple corollary of Theorem 2, since in
consistent GCP-nets dominance is equivalent to strict dominance.

423

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

7. Problems Concerning Optimality in GCP-Nets
The dominance relation ≺C of a GCP-net C determines a certain order relation, which gives rise to
several notions of optimality. We will introduce them and study the complexity of corresponding
decision problems.
We first observe that the dominance equivalence relation is indeed an equivalence relation (reflexive, symmetric and transitive). Thus, it partitions the set of all outcomes into non-empty equivalence classes, which we call dominance classes. We denote the dominance class of an outcome α
in a GCP-net C by [α]C .
The relation ≺C induces on the set of dominance classes a strict order relation (a relation that is
irreflexive and transitive). Namely, we define [α]C ≺Cdc [β]C if [α]C 6= [β]C (equivalently, α 6≈C β) and
α ≺C β. One can check that the definition of the relation ≺Cdc on dominance classes is independent
of the choice of representatives of the classes.
Definition 9 (Non-dominated class, optimality in GCP-nets) Let C be a GCP-net. A dominance
class [α]C is non-dominated if it is maximal in the strict order ≺Cdc (there is no dominance class
[β]C such that [α]C ≺Cdc [β]C ). A dominance class is dominating if for every dominance class [β]C ,
[α]C = [β]C or [β]C ≺Cdc [α]C .
An outcome α is weakly non-dominated if it belongs to a non-dominated class. If α is weakly
non-dominated and is the only element in its dominance class, then α is non-dominated.
An outcome α is dominating if it belongs to a dominating class. An outcome α is strongly
dominating if it is dominating and non-dominated.
Outcomes that are weakly non-dominated, non-dominated, dominating and strongly dominating
capture some notions of optimality. In the context of CP-nets, weakly non-dominated and nondominated outcomes were proposed and studied before (Brafman & Dimopoulos, 2004). They were
referred to as weakly and strongly optimal there. Similar notions of optimality were also studied
earlier for the problem of defining winners in partial tournaments (Brandt, Fischer, & Harrenstein,
2007). We will study here the complexity of problems to decide whether a given outcome is optimal
and whether optimal outcomes exist.
First, we note the following general properties (simple consequences of properties of finite strict
orders).
Lemma 8 Let C be a GCP-net.
1. There exist non-dominated classes and so, weakly non-dominated outcomes.
2. Dominating outcomes and nondominated outcomes are weakly non-dominated.
3. A strongly dominating outcome is dominating and non-dominated.
4. The following conditions are equivalent:
(a) C has a unique non-dominated class;
(b) C has a dominating outcome;
(c) weakly non-dominated and dominating outcomes in C coincide.
For consistent GCP-nets only two different notions of optimality remain.
424

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

Lemma 9 Let C be a consistent GCP-net. Then:
1. Each dominance class is a singleton, ≺C is a strict order, and ≺C and ≺Cdc coincide (modulo
the one-to-one and onto correspondence α 7→ [α]C )
2. If α is a weakly non-dominated outcome, α is non-dominated (weakly non-dominated and
non-dominated outcomes coincide)
3. If α is a dominating outcome, α is strongly dominating (strongly dominating and dominating
outcomes coincide).
4. Finally, α is a unique (weakly) non-dominated outcome if and only if α is strongly dominating.
Next, we observe that all concepts of optimality we introduced are different. To this end, we will
show GCP-nets with a single non-dominated class that is a singleton, with multiple non-dominated
classes, each being a singleton, with a single non-dominated class that is not a singleton, and with
multiple non-dominated classes, each containing more than one element. We will also show a GCPnet with two non-dominated classes, one of them a singleton and the other one consisting of several
outcomes.
Example 2 Consider the following GCP-net C with two binary variables a and b
: a > ā
: b > b̄
This GCP-net determines a strict preorder on the dominance classes, in which {ab} is the only
maximal class (in fact, all dominance classes are singletons). Thus, ab is both non-dominated and
dominating and so, it is strongly dominating.
Example 3 Consider the following GCP-net C with two binary variables a and b
b : a > ā
b̄ : ā > a
a : b > b̄
ā : b̄ > b
This GCP-net determines a strict preorder, in which {ab} and {āb̄} are two different non-dominated
classes. Thus, ab and āb̄ are non-dominated and there is no dominating outcome.
Example 4 Consider a GCP-net with variables a, b and c, defined as follows:
a : b > b̄
ā : b̄ > b
b̄ : a > ā
b : ā > a
ab : c > c̄

425

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

There are two dominance classes: Sc = {abc, ab̄c, ābc, āb̄c} and Sc̄ = {abc̄, ab̄c̄, ābc̄, āb̄c̄}. Every
outcome in Sc strictly dominates every outcome in Sc̄ , therefore, Sc is the unique non-dominated
class and every outcome in Sc is dominating. Because Sc is not a singleton, there are no nondominated outcomes (and so, no strongly dominating outcome, either).
Example 5 Let us remove from the GCP-net of Example 4 the preference statement ab : c > c̄. Then
Sc and Sc̄ are still the two dominance classes, but now every outcome is Sc is incomparable with
any outcome in Sc̄ . Thus, Sc and Sc̄ are both non-dominated. Since there are two non-dominated
classes, there is no dominating outcome. Since each class has more than one element, there are no
non-dominated outcomes. All outcomes are weakly non-dominated, though.
Example 6 Let us modify the GCP-net of Example 4 by changing the preference statement b̄ : a > ā
into b̄c : a > ā. The dominance relation ≺ of this GCP-net satisfies the following properties: (i)
the four outcomes in Sc dominate each other; (ii) āb̄c̄ ≻ ābc̄ ≻ abc̄ ≻ ab̄c̄; (iii) any outcome in Sc
dominates abc̄ (and, a fortiori, ab̄c̄). One can check that there are five dominance classes: Sc , {abc̄},
{ābc̄}, {ab̄c̄} and {āb̄c̄}. Two of them are non-dominated: Sc and {āb̄c̄}. Since there are two nondominated classes, there is no dominating outcome. On the other hand, {āb̄c̄} is a non-dominated
outcome (a unique one).
We will consider the following decision problems corresponding to the notions of optimality we
introduced.
Definition 10
For a given GCP-net C:
WEAKLY NON - DOMINATED OUTCOME : given an outcome α, decide whether α is weakly nondominated in C
NON - DOMINATED OUTCOME : given an outcome α, decide whether α is non-dominated in C
DOMINATING OUTCOME : given an outcome α, decide whether α is dominating in C
STRONGLY DOMINATING OUTCOME : given an outcome α, decide whether α is strongly dominating in C
EXISTENCE OF A NON - DOMINATED OUTCOME : decide whether C has a non-dominated outcome
EXISTENCE OF A DOMINATING OUTCOME : decide whether C has a dominating outcome
EXISTENCE OF A STRONGLY DOMINATING OUTCOME : decide whether C has a strongly dominating outcome.
In some of the hardness proofs, we will again use the reductions Θ1 and Θ2 , described in the
previous section. We note the following additional useful properties of the GCP-net G = Θ1 (H, β).
Lemma 10 For arbitrary V -outcome α different from β, the following statements are equivalent:
1. β+ ≺G α+
2. α+ is weakly non-dominated in G
3. α+ is a dominating outcome in G.
426

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

Proof: Since β+ is dominating in G (Lemma 4), weakly non-dominated outcomes and dominating
outcomes coincide (Lemma 8). It follows that the conditions (1)-(3) are equivalent to each other. 

Proposition 8 The following problems are PSPACE-complete: WEAKLY NON - DOMINATED OUTCOME and DOMINATING OUTCOME . The result holds also for the problems restricted to CP-nets.
Proof: The membership is easy to prove by techniques similar to those we used earlier.
For the PSPACE-hardness proofs, we use reductions from CP - DOMINANCE for consistent CPnets (in the version where the two input outcomes are different). Let H be a CP-net, and α and
β two different V -outcomes. By Lemmas 5 and 10, β ≺H α can be decided by deciding either of
the problems WEAKLY NON - DOMINATED OUTCOME and DOMINATING OUTCOME for the GCPnet G = Θ1 (H, β) and the outcome α+ . We observed earlier, that if H is a CP-net, then so is
G = Θ1 (H, β). Thus, the second part of the assertion follows.

Next, we will consider the problem STRONGLY DOMINATING OUTCOME. We will exploit the
reduction F = Θ2 (H, α), which we discussed in the previous section. We observe the following
property of F.
Lemma 11 Let H be a GCP-net and F = Θ2 (H, α). Then α− is strongly dominating in F if and
only if α is dominating in H.
Proof: Let us assume that α is dominating in H. From the definition of F, it follows that for every
V -outcome γ 6= α, γ+ ≺F α+ and γ− ≺F γ+ . Since α+ ≺F α− , α− is dominating in F. Since there
is no improving flip leading out of α− , α− is strongly dominating.
Conversely, let us assume that α− is strongly dominating in F and let γ be a V -outcome different from α. Let us consider an improving sequence from γ+ to α− . All outcomes in the sequence
other than the last one, α− , are of the form δ+ . Moreover, the outcome directly preceding α− is
α+ . Dropping y from every outcome in the segment of the sequence between γ+ and α+ yields an
improving sequence from γ to α in H.

We now have the following consequence of this result.
Proposition 9 The problem STRONGLY
stricted to CP-nets.

DOMINATING OUTCOME

is PSPACE-complete, even if re-

Proof: Let H be a CP-net (over the set V of variables) and α an outcome. By Lemma 11, the problem DOMINATING OUTCOME can be decided by deciding the problem STRONGLY DOMINATING
OUTCOME for F = Θ2 (H, α) and α− . Thus, the PSPACE-hardness of STRONGLY DOMINATING
OUTCOME follows by Proposition 8. The membership in PSPACE is, as in other cases, standard and
is omitted.
Since H is a CP-net, it is locally consistent and so, F is locally consistent, too. As in the proof
of Corollary 1 we use the mapping from GCP-net F to CP-net F ′ defined in Section 4.2. By Lemma
3, α is a strongly dominating outcome in F if and only if αα dominates every outcome of the form
γγ, which is if and only if αα is a strongly dominating outcome in F ′ , since any F ′ -outcome is
dominated by an outcome of the form γγ (using the rules q+ (xi ) = yi and q− (xi ) = ¬yi ). Therefore
427

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

for F and α can be decided by deciding
for F ′ and αα. Thus, the second part of the claim follows.

STRONGLY DOMINATING OUTCOME
NATING OUTCOME

STRONGLY DOMI 

The problem NON - DOMINATED OUTCOME is easier. It is known to be in P for CP-nets (Brafman
& Dimopoulos, 2004). The result extends to GCP-nets. Indeed, if H is a GCP-net and α an outcome,
α is non-dominated if and only if there is no improving flip that applies to α. The latter holds if and
only if for every variable x in H, if x (respectively, ¬x) holds in α, then p− (x) (respectively, p+ (x))
does not hold in α. Since the conditions can be checked in polynomial the claim holds and we have
the following result.
Proposition 10 The problem NON - DOMINATED

OUTCOME

for GCP-nets is in P.

Next, we will consider the problems concerning the existence of optimal outcomes. Let H be a
GCP-net on the set of variables V = {x1 , . . . , xn }, and let α and β be two different V -outcomes. For
every i = 1, 2, . . . , n, we define formulas αi as follows. If xi ∈ α, then αi is the conjunction of all
literals in α, except that instead of xi we take ¬xi . Similarly, if ¬xi ∈ α, then αi is the conjunction of
all literals in α, except that instead of ¬xi we take xi . Thus, αi is the outcome that results in α when
the literal in corresponding to xi is flipped into its dual.
We now define a GCP-net E = Θ3 (H, α, β) by taking W = V ∪ {y} as the set of variables of E
and by defining the flipping conditions as follows:
+
1. p+
E (xi ) = (pH (xi ) ∧ y) ∨ (¬y ∧ ¬α ∧ ¬αi )
−
−
pE (xi ) = pH (xi ) ∧ y

2. p+
E (y) = β
3. p−
E (y) = ¬β.
The GCP-net Θ3 (H, α, β) has the following properties. The outcomes of the form γ+ (= γ ∧ y)
form a copy of H. There is no improving flip for the outcome α− (= α ∧ ¬y). Next, there is no
improving flip into α− from an outcome of the form γ− . To see this, let us assume that such a flip
exists and concerns a variable, say, xi . It follows that γ = αi . By the definition of flipping conditions,
an improving flip for γ− that involves xi is impossible, a contradiction. Thus, the only improving
flip that leads to α− originates in α+ .
We also have that for every outcome γ other than α and β, γ− ≺E β− . It follows from the fact
that for every outcome γ other than α and β, γ− has an improving flip. Indeed, for each such γ there
is a variable xi such that (i) xi is false in γ, and (ii) flipping the literal of xi to its dual does not lead to
α (that is, γ is not αi ). (For even if γ = αi for some i, then, because γ, α 6= β, there exists i′ 6= i such
that γ and β differ on xi′ , so that xi′ satisfies (i) and (ii).) Thus, a flip on that variable is improving.
As all improving flips between outcomes containing ¬y result in one more variable xi assigned to
true, thus having the same status as it has in β, γ− ≺E β− follows.
Finally, we have β− ≺E β+ and, for every outcome γ other than β, γ+ ≺E γ− . This leads to the
following property of E = Θ3 (H, α, β).
Lemma 12 Let H be a GCP-net and let α and β be two different outcomes. Then β ≺H α if and
only if Θ3 (H, α, β) has a (strongly) dominating outcome.
428

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

Proof: (Only if) Based on our earlier remarks, α+ ≺E α− . Moreover, since β ≺H α, we have
β+ ≺E α+ . In addition, for every γ different from α and β, γ+ ≺E γ− ≺E β− ≺E β+ . Thus, α− is
both dominating and strongly dominating (the latter follows from the fact that no improving flips
lead out of α− ).
(If) Let us assume that α− is dominating (and so, the argument applies also when α− is strongly
dominating). Then there is an improving sequence from β+ to α− . Let us consider a shortest such
sequence. Clearly, α+ is the outcome just before α− in that sequence (as we pointed out, no improving flip from an outcome of the form γ− to α− is possible). Moreover, by the definition of
Θ3 (H, α, β) and the fact that we are considering a shortest sequence from β+ to α− , every outcome
in the sequence between β+ and α+ is of the form γ+ . By dropping y from each of these outcomes,
we get an improving sequence from β to α.


Proposition 11 The problem EXISTENCE OF DOMINATING OUTCOME and the problem EXISTENCE
OF STRONGLY DOMINATING OUTCOME are PSPACE-complete, even if restricted to CP-nets.
Proof: We show the hardness part only, as the membership part is straightforward. To prove hardness we notice that by Lemma 12, given a consistent CP-net H and two outcomes α and β, β ≺H α
can be decided by deciding either of the problems EXISTENCE OF DOMINATING OUTCOME and
EXISTENCE OF STRONGLY DOMINATING OUTCOME for Θ3 (H, α, β). To prove the second part of
the assertion, we note that if H is consistent, E = Θ3 (H, α, β) is consistent, too and so, the mapping
from locally consistent GCP nets to CP-nets applies. Let us denote the result of applying the mapping to E by E ′ . Then, using the same argument as in the proof of Proposition 9, E has a (strongly)
dominating outcome if and only if E ′ has a strongly dominating outcome. Thus, one can decide
whether β ≺H α in a consistent CP-net H by deciding either of the problems EXISTENCE OF DOM INATING OUTCOME and EXISTENCE OF STRONGLY DOMINATING OUTCOME for E ′ .

We also note that the problem EXISTENCE
standard complexity theory assumptions).

OF NON - DOMINATED OUTCOME

Proposition 12 The problem EXISTENCE OF NON - DOMINATED

OUTCOME

is easier (under

is NP-complete.

Proof: We note that in the case of GCP-nets in conjunctive form the problem is known to be NP-hard
(Domshlak et al., 2003, 2006). Thus, the problem is NP-hard for GCP-nets. The membership in the
class NP follows from Proposition 10.

If we restrict to consistent GCP-nets, the situation simplifies. First, we recall (Lemma 9) that if
a GCP-net is consistent then weakly non-dominated and non-dominated outcomes coincide, and the
same is true for dominating and strongly dominating outcomes. Moreover, for consistent GCP-nets,
non-dominated outcomes exist (and so, the corresponding decision problem is trivially in P). Thus,
for consistent GCP-nets we will only consider problems DOMINATING OUTCOME and EXISTENCE
OF DOMINATING OUTCOME .
Proposition 13 The problems DOMINATING OUTCOME and
COME restricted to consistent GCP-nets are in coNP.
429

EXISTENCE OF DOMINATING OUT-

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Proof: Using Lemmas 8 and 9, α is not a dominating outcome if and only if there exists an outcome
β 6= α which is non-dominated. Similarly, there is no dominating outcome in a consistent GCP-net
if and only if there are at least two non-dominated outcomes. Thus, guessing non-deterministically
an outcome β 6= α, and verifying that β is non-dominated, is a non-deterministic polynomial-time
algorithm deciding the complement of the problem DOMINATING OUTCOME. The argument for the
other problem is similar.

We do not know if the bounds in Proposition 13 are tight, that is, whether these two problems
are coNP-complete. We conjecture they are.

8. Concluding Remarks
We have shown that dominance and consistency testing in CP-nets are both PSPACE-complete. Also
several related problems related to dominance and optimality in CP-nets are PSPACE-complete, too.
The repeated use of reductions from planning problems confirms the importance of the structural similarity between STRIPS planning and reasoning with CP-nets. This suggests that the welldeveloped field of planning algorithms for STRIPS representations, especially for unary operators
(Brafman & Domshlak, 2003), could be useful for implementing algorithms for dominance and
consistency in CP-nets.
Our theorems extend to CP-nets with non-binary domains, and to extensions and variations of
CP-nets, such as TCP-nets (Brafman & Domshlak, 2002; Brafman, Domshlak, & Shimony, 2006)
that allow for explicit priority of some variables over others, and the more general language for
conditional preferences (Wilson, 2004a, 2004b), where the conditional preference rules are written
in conjunctive form.
The complexity result for dominance is also relevant for the following constrained optimisation
problem: given a CP-net and a constraint satisfaction problem (CSP), find an optimal solution (a
solution of the CSP which is not dominated by any other solution of the CSP). This is computationally complex, intuitively because a complete algorithm involves many dominance checks when
the definition of dominance under constraints allows for dominance paths to go through outcomes
violating the constraints (Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004b).9 The problem of
checking whether a given solution of a CSP is non-dominated can be seen to be PSPACE-complete
by a reduction from CP-dominance that uses a CSP that has exactly two solutions.
Our results reinforce the need for work on finding special classes of problems where dominance
and consistency can be tested efficiently (Domshlak & Brafman, 2002; Boutilier et al., 2004a),
and for incomplete methods for checking consistency and constrained optimisation (Wilson, 2004a,
2006).
Several open problems remain. We do not know the complexity of deciding whether the preference relation induced by a CP-net is complete. We do not know whether dominance and consistency
testing remain PSPACE-complete when the number of parents in the dependency graph is bounded
by a constant. We also do not know whether these two problems remain PSPACE-complete for
CP-nets in conjunctive form (the reduction used to prove Theorems 2 and 4 yields CP-nets that are
not in conjunctive form). Two additional open problems are listed at the end of Section 7.
9. With another possible definition, where going through outcomes violating the constraints is not allowed (Prestwich,
Rossi, Venable, & Walsh, 2005), dominance testing is not needed to check whether a given solution is non-dominated.

430

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

Acknowledgments
Jérôme Lang’s new address is: LAMSADE, Université Paris-Dauphine, 75775 Paris Cedex 16,
France. The authors are grateful to the reviewers for their excellent comments, and to Pierre Marquis
for helpful discussions. This work was supported in part by the NSF under Grants ITR-0325063,
IIS-0097278 and KSEF-1036-RDE-008, by the ANR Project ANR–05–BLAN–0384 “Preference
Handling and Aggregation in Combinatorial Domains”, by Science Foundation Ireland under Grants
No. 00/PI.1/C075 and 05/IN/I886, and by Enterprise Ireland Ulysses travel grant FR/2006/36.




A key issue in the handling of temporal
data is the treatment of persistence; in most
approaches it consists in inferring defeasi­
ble conlusions by extrapolating from the ac­
tual knowledge of the history of the world;
we propose here a gradual modelling of per­
sistence, following the idea that persistence
is decreasing (the further we are from the
last time point where a fluent is known to
be true, the less certainly true the fluent
is); it is based on possibility theory, which
has strong relations with other well-known
ordering-based approaches to nonmonotonic
reasoning. We compare our approach with
Dean and Kanazawa's probabilistic projec­
tion. We give a formal modelling of the
decreasing persistence problem. Lastly, we
show how to infer nonmonotonic conclusions
using the principle of decreasing persistence.
1

Introduction

The use of persistence in order to draw nonmonotonic
conclusions has been widely studied. Most approaches
select models having the minimal set of changing flu­
ents. Thus, in these approaches, a propositional fluent
f true at a given time point will tend to remain true
indefinitely, provided that no other proposition being
contradictory with f is observed at a later time point;
this is an extremely adventurous choice, and it may be
often unrealistic, because some fluents have only a lim­
ited tendency to persist (for instance, given that it is
raining at t0, it is not reasonable to infer that it is still
certainly raining one week later). Let us now consider
a second typical case, where a fluent f is known to be
true at time to and known to be false at a later time
point it, nothing being known inbetween (for instance,
it is raining at 10 am, and it is not raining at 6 pm).
In this figure, there must be a time point h in (t0, h)
*Much of this work

was done

iting Linkoping University

while this author was vis­

Jerome Lang

*

IRIT
Universite Paul Sabatier
F-31062 Toulouse Cedex
France
email: lang@irit.fr
when f changes its truth value from true to false (this
is known as the clipping problem). Chronological min­
imization (Shoham 88) and similar approaches prefer
models where fluents change at the latest possible time
point; this has been argued as being often unreason­
able (see (Sandewall 92) for a discussion) and several
other approaches have been proposed which reject the
latter principle, and, cautiously, do not conclude any­
thing about f within (t0, tt). For instance, the logic
for time of action proposed in (Sandewall 92) will con­
clude that the truth value of f is occluded during
(t0, t1). Borillo & Gaume's (90) three-valued extension
of Kowalski & Sergot's event calculus will also give a
cautious result. We argue that these cautious results
assuming complete ignorance within the whole inter­
val are not always realistic, since we are not always
completely ignorant of what happens at time points
being very close to one of the bounds of the interval
(thus, in our example it is rather sure it is still raining
at 10.05 am and rather sure it is not raining at 5.55
pm). The transition model given in (Cordier & Siegel
92) enables to specify explicitely whether fluents tend
to persist or not depending on some applications con­
ditions, and has thus a rich expression power, but how­
ever it cannot express that persistence may decrease
gradually.
The reason why all these approaches cannot model de­
creasing persistence is clearly their lack of graduality;
consider again the first raining example (forward pro­
jection); one is likely to believe that rains is almost
certainly true a short time after 10.00, and not to be­
lieve anything at all after a very long time (say, one
week later); note that in this latter case -,f should not
be believed either; we are too far from a time-point
when the truth value off is known for assuming any­
thing: we are thus in a state of complete ignorance
about the truth value of f. Between these two ex­
treme states of knowledge, there is a lot of intermedi­
ary states, since the further from 10.00, the less cer­
tain we are that it is still raining: as time goes on, the
amount of ignorance increases. This principle will be
called increasing ignorance about persistence, or,
for the sake of brevity, decreasing persistence, al­
though we prefer the former formulation: indeed, what

470

Driankov and Lang

is gradually decreasing is not persistence of truth but
persistence of our belief about truth; see (Asher 93) for
a study of persistence of truth vs. persistence of be­
lief. This graduality in persistence can be expressed in
a qualitative way using ordering relations or in a more
quantitative way using numerical measures of uncer­
tainty.

and also with bounded projection (see Section 3).
After recalling the bases of possibility theory and its
use in nonmonotonic reasoning, we will give a formal
presentation of our approach, and lastly we will show
how to use decreasing persistence in order to infer non­
monotonic conclusions.

To our knowledge, there has been essentially one ap­
proach to modelling persistence in a gradual way,
namely Dean and Kanazawa's probabilistic projection
(Dean & Kanazawa 89a,b) (see also (Haddawy 90) for
a temporal probability logic for reasoning about ac­
tions). They distinguish between 2 kinds of proposi­
tions, namely facts (or fluents) and events; a fact is a
proposition which, once true, tends to persist, i.e. to
remain true for some time without additional effort;
events are instantaneous, and they do not persist, but
they tend to change the truth value of some fluents.
Note that all facts have a starting point and an ending
point (possibly infinite); if a fluent is true, becomes
false and then becomes true again, it must be consid­
ered as two different instances ("tokens") of the same
fact. Dean and Kanazawa propose an elaborate prob­
abilistic model for persistence, taking account for each
fact of its natural tendency to persist, represented by a
survivor function S(8) = p(holds(f, t)iholds(f, t- 8))
(probability that f survives at least for 8 time units),
and of the probabilities of events changing the truth
value of the fluent. Thus probabilistic prediction
comes down to computing the probability of f being
still true at t, or equivalently, the density function of
the clipping point of f, i.e. the time point when it
becomes false.

2

However, probabilistic prediction is not well-suited to
dealing with fluents which may change their value sev­
eral times; besides, a probabilistic modelling of persis­
tence does not express that we become more and more
ignorant about the truth value of a formula when time
goes on. Let us consider the following example, where
we know that it is raining at time t0 (and that we
do not know anything about what will happen after­
wards). Dean and Kanazawa's approach will conclude
that the probability of "raining" at t0 + f is close to
1 iff is close to 0, which is intended; however, it will
also conclude that if we are very far from t0, raining
is false, which is of course not intended. A first idea
for treating this case correctly would be to model per­
sistence with an asymptotic probability (which is ac­
tually the probability a priori that it is raining, inde­
pendently from earlier and later observations); but it
still does not express increasing ignorance, since prob­
ability theory is well-suited to modelling chance, but
can not deal correctly with ignorance (see (Dubois &
Prade.88)); possibility theory (Zadeh 78) is much more
adapted to the representation of states of partial or
complete ignorance.
A last point is that Dean and Kanazawa's probabilistic
projection is only done forwards; our possibilistic ap­
proach also deals with backwards projection problems,

Background on possibilistic logic

Let L be a classical propositional language (where T
and .1. denote tautology and contradiction, respec­
tively) and n be the classical set of interpretations
associated with L. A possibility distribution is a map­
ping 1r from n to [0, 1]. 1r is said to be normalized iff
3w E 0 such that 1r(w) = 1. By convention, 1r rep­
resents some background knowledge about where the
real world is; in particular, 1r( w) = 0 means that w
1 that nothing prevents
is not possible, and 1r(w )
w from being the real world.
When 1r(w ) > 1r(w'),
w is a preferred candidate to w' for being the real
world. A possibility distribution leads to evaluate in­
duces two mappings on L, namely a possibility mea­
sure II(tp) = Supwl=cp1r(w ) which evaluates the extent
to which tp is consistent with the available knowledge
expressed by 1r, and a necessity (or certainty) mea­
sure N(cp) = Infwl=.,cp(1- 1r(w)) = 1- II(-.tp), which
evaluates the extent to which tp is entailed by the
available knowledge. We have Vtp, '1/J, N(<p /1. 'lj;) =
min(N(tp),N('lj;)). Note that while N(cp) = 1 means
that <p is certainly true, N(cp) = 0 means only that
cp is not certain at all.Complete ignorance about <p
is expressed by N (<p) = N (-.tp) = 0. Since pos­
sibility distributions are not required to be normal­
ized, it may be the case that N(.l.) > 0. Note that
we have V<p, min(N(cp), N(-.cp)) = N(.l.). Note that
what is essential in possibility theory is not the pre­
cise value of certainty degrees, but their ordinal na­
ture: indeed certainty degrees can be used to rank
formulas of L. Namely, it is equivalent to work with
necessity measures or with (qualitative) necessity re­
lations (see (Dubois, Prade 91)) defined by ?..N defined
by V<p, '1/J, <p ?..N 'ljJ iff N(<p) ?.. N('lj;), meaning that <p is
at least as certain as 'lj;.
=

A possibilistic knowledge base (Dubois et al. 91a)
is a finite set of necessity-valued formulas K =
{('Pi a;) , i = 1, n} where ai represents a lower bound of
the necessity degree N(<pi)· A possibility distribution
1r on n satisfies K iff Vi, N ( <p;) ?.. a;, where N is the
necessity measure induced by 1r. Logical consequence
is then defined by K F (e {3) iff any possibility dis­
tribution satisfying K satisfies (E {3). The fuzzy set of
models of a possibilistic knowledge base has for mem­
bership function the least specific possibility distribu­
tion satisfying the constraints N (<pi) ?.. a;, i = 1, n.
This possibility distribution 7rK is defined by: Vw E n,
1r:K(w ) = mini=l,n{1 - a;,w F -.cpi} .
Possibilistic
logic allows for partial inconsistency, occuring there
is no normalized possibility distribution satisfying I<,
which means that K F ( .1. {3) for some strictly positive

Possibilistic decreasing persistence

{3. The quantity Max{f3, I< F= ( l. {3)} is called incon­
sistency degree of I<, denoted by I ncons(I<) . It can be
shown that I ncons(I<) = Nk(l.) = 1-Supwen?rf<(w).

persistence consists in extrapolating N(free) in the in­
terval (10.00, +oo); an example of persistence function
is shown on Figure 1.

In (Dubois et al. 91b), possibilistic logic was extended
to a timed version which handles both uncertainty and
time; basically, a timed possibilistic knowledge base
consists in a collection of possibilistic knowledge bases
indexed by time points varying on a given time scale
T; so, instead of considering possibility distributions
(resp. necessity measures), we consider collections of
possibility distributions {?rt, t E T} (resp. collections
of necessity measures { Nt, t E T}).
From a possibilistic knowledge base K, it is possi­
ble to define a nonmonotonic inference relation (see
(Dubois Prade 91)) 1-x by: <p 1-x t/J iff NK (cp __,.
tf;) > Nk(-.cp). Note that in the particular case
where <p = T, we get the following (abbreviating
T I-t tf; in I-t tf;): 1- t/J iff Nk(t/J) > Nk(l.) iff
Nt (tf;) > I ncons( I<). It has been shown that 1-K en­
joys all "desirable" properties that nonmonotonic in­
ference relations "should" satisfy, including rational
monotonicity (Dubois, Prade 91).
3

Possibilistic decreasing persistence:
the extrapolation problem

3.1

Informal presentation of the
extrapolation problem

The general principle of decreasing persistence is,
given a factual temporal knowledge base and some in­
formation about the persistence of some given fluent
f, to derive uncertain information about f in the in­
tervals when the truth value off is unknown. Let us
start with motivating examples.
Example 1 (unbounded forward extrapolation): let us
consider the fluent free of a given parking place which
may or may not be free at any time-point t. Sup­
pose that all we know about free is that it holds up
to to = 10.00 (and we do not anything about it af­
terwards). We would like to extrapolate, using some
knowledge describing how our ignorance about the
persistence of free increases, the following uncertain
facts: the certainty (necessity) degree of free, which
is 1 at 10.00 (since free is known to be true), should
be close to 1 when t is close to 10.00 (we recall that
N(free) expresses to which point free is entailed by
the knowledge of reference; here it is obvious that at
time points close to 10.00, free is entailed, to some
certainty degree close to 1, by both the fact that it
holds at 10.00 and the general principle of decreasing
persistence); then, the further t is from 10.00, the less
certain we are that free is true; and there should also
be a point from which on we are too far from 10.00 to
be even weakly certain that free still holds, i.e. from
which on N(free) = 0 (then we are in a state of com­
plete ignorance about free, i.e. we haveN(-.free) = 0
too). So, in this example the principle of decreasing

471

tO

Figure 1: unbounded forward extrapolation
Example 2 (unbounded backward extrapolation): as­
sume now that free is known to be true from 10.00
on (we do not know anything about it before) and we
have to infer uncertain facts about the past of the flu­
ent (this problem is also called postdiction) . This case
is very similar to forward extrapolation (in a symmet­
ric way), and all previous remarks hold.
Example 3 (bounded extrapolation without change):
now, assume that free is known to be true up to
10.00, and from 10.30 on, nothing is known about f ree
during the interval (10.00, 10.30). Traditional non­
gradual approaches to persistence are too optimistic
since they conclude by default that free holds every­
where in (10.00, 10.30], since nothing tells· us that a
change ocurred. However this is not always realistic,
especially if the considered interval is long (relatively
to the considered fluent). The most intuitive kind of
extrapolation on [10.00, 10.30] tells that the further
from one of the two reference time-points 10.00 and
10.30, the less certain we are that free still holds (see
figure 2). The fact that free holds at the two extrem­
ities of the interval should be a confirmation that free
holds in any arbitrary point of the interval; in other
words, for instance, we should be at least as certain
that free holds at 10.15 in this situation than in the
situation of Example 1. In some cases, the interval
length may be too long for us to be somewhat certain
that the fluent does not change within the interval;
for instance, consider free within [10.00, 18.00]. See
Figure 2.

Nt (f)

Nt (f)
f

Figure 2: bounded extrapolation without change
Example 4 (bounded extrapolation with change): now,
assume free is true up to 10.00, and false from 10.30
on; again, nothing is known during (10.00, 10.30).
Traditional non-gradual approaches are too cautious
since they conclude that free is unknown within

472

Driankov and Lang

(10.00, 10.30); however, a more realistic (and more in­
formative) extrapolation would tell that free is rather
certainly true if we are very close to 10.00 (the closer,
the more certain; but it should nevertheless decrease
faster than in Examples 1 and 3), and rather certainly
false if we are very close to 10.30 (again, the closer,
the more certain). See Figure 3.

base is maintained consistent, or by considering all
contingent formulas as Unknown at inconsistent time­
points.
The partial history H induced by!{ is the logical clo­
sure of !{, i.e. the collection of all Cn( Kt), for t vary­
ing in T. We will denote the belief status (True, False
or Unknown) of <p at to by Ht(<p).
3.2.2

tO

t1

Figure 3: bounded extrapolation with change
3.2

Formalizing possibilistic decreasing
persistence

First, it is primordial to state the distinction be­
tween factual knowledge and knowledge about persis­
tence. The first one expresses what we know about
the world during the time scale of reference and en­
ables us only to draw certain, monotonic conclusions
(for instance "it was raining from 10.00 to 11.00, and
it was not raining at 12.30"), while the second one
expresses what we know about the general behaviour
of fluents (for instance, "raining tends to persist but
usually no more than a couple of hours") and, together
with factual knowledge, enables us to draw uncertain
and defeasible conclusions.
3.2.1

Factual knowledge

Factual knowledge consists in an generally incomplete
knowledge about the the world at every time point.
It will be represented in a traditional way, by reify­
ing time. Let T= (-co, +co) be the time scale of
reference. Let L be a propositional logical language;
atomic propositions which are allowed to vary along
time are called ftuents. A timed knowledge base /{ is a
finite set of timed formulas T : <p, where T is a subset of
T (generally an interval) and <p a well-formed formula
of L. T : <p expresses that <p holds for any time point
t in T. The cut of!{ at t0 is the classical knowledge
base Kt0 = {T : <p E K I to E K }; clearly, a formula
<p is known to be true at t0 iff <p E Cn(Kt0), where
Cn denotes logical closure, and known to be false at
to iff -,<p E Cn(Kt0); if <p is neither True nor False
at t0 then <p is said to be unknown at to. Note that
there is a fourth possible status for <p at to, due to the
possibility that Kt0 be inconsistent (in which case <p is
both True and False); note that the set { True, False,
Unknown, Inconsistent } is the well-known 4-valued
lattice of (Belnap 77). However, for the sake of clarity,
in this paper we will deliberately ignore inconsistent
time-points (i.e. time-points t such that Kt is incon­
sistent), either by assuming that the timed knowledge

Persistence extrapolation problems

Let f be a propositional fluent, and let H be a partial
history on the time scale T. A time-point t will said to
be informative for f iff Ht(/)=True or Ht(f)=False.
The set of all informative time-points off is denoted
by ITP(f). For practical reasons we need to require
that partial histories satisfy the following property: H
is said to be closed iff for any elementary fluent f,
ITP(<p) is a closed subset of T, i.e. a (possibly infi­
nite) union of intervals of T which have one of these
4 forms: [a, b] (possibly a= b), [a, +co), (-co, b] or
(-co, +co). H being a closed partial history, a time­
point tis said to be a reference time-point for f w.r.t.
H iff t is at the leftest or at the rightest extremity of
one of the intervals constituting ITP(!). The com­
plementary of ITP(f), i.e. the set of all time points t
when Ht(/)= Unknown, is a (possibly infinite) union
of airwise disjoint open intervals, called maximal non­
informative intervals off w.r.t. H; if ITP(!) :f. 0,
their form is either (-co, t0) or (tn, +co) or (t;, ti+l),
where all t;'s are reference time points forf w.r.t. H
(it may be the case that t; =t;+1). From now on we
exclude the trivial case ITP(f) = 0 (i.e. the truth
value of f is always unkwown) since it is completely
uninteresting (persistence cannot apply).
A persistence extrapolation problem consists in a closed
history H, an elementary fluent f and a maximal non­
informative interval I for f w.r.t. H. The various
examples presented informally in Section 3.1 suggest
the following classification of persistence extrapolation
problems:
•

•

•

a persistence extrapolation problem (H, f, I) is an
unbounded extrapolation problem iff I= (tn, +co)
(forward extrapolation), or I = (-co, t0) (back­
ward extrapolation).
a persistence extrapolatioa problem (H, f, I) is a
bounded extrapolation problem without change iff
I= (t;, ti+l) and Ht, ( f )= Ht,+1(!).
a persistence extrapolation problem (H, f, I) is a
bounded extrapolation problem with change iff I=
(t;, ti+l) and Ht,(f) :f. Ht,+1(<p).

3.2.3

Decreasing persistence functions and
decreasing persistence schemata for
fluents

Having stated persistence extrapolation problems, we
are now giving a general methodology for solving them.

Possibilistic decreasing persistence

Informally, extrapolation based on decreasing persis­
tence consists in inferring by default a truth-value,
with some certainty degree, to a fluent at time-points
where its truth-value is not definitely known. Of
course, the way to cope with it may depend not only
on the involved fluent, but on the class (backward,
forward, ...) of the extrapolati�m problem and when
it occurs. Let I be a maximal non-informative inter­
val for f w.r.t. H. A persistence function for (!, I)
is a mapping from I to [0, 1) which associates to any
t in I the necessity degree N1(!) of f at t. Thus,
persistence functions extrapolate uncertain knowledge
from factual knowledge by using the general princi­
ple of decreasing persistence. Obviously, the prob­
lem is tractable only if the user can specify persis­
tence functions in a general way (for instance, "in a
forward extrapolation problem starting at to the ne­
cessity degree of free decreases linearly and reaches 0
at t0 + 1.00 if t0 is during the day and at to + 4.00 if
t0 is during the night"). This is a decreasing persis­
tence schema. Once applied to a given partial history,
a persistence schema is "instanciated" to persistence
functions. If H is a partial history and Pers denotes
a set of persistence schemata for a subset of the flu­
ents involved in H, then Apply(Pers, H) denotes the
application of Pers to H. Note that Apply(Pers, H)
is a collection of possibilistic knowledge bases (one for
each t, denoted by Apply(Pers, H)1). In next Sec­
tion we investigate some of the properties that persis­
tence schemata should preferably satisfy in order to be
in accordance with the general principle of decreasing
pereistence, and we propose some examples of persis­
tence schemata.
4

From qualitative to quantitative
axioms for persistence schemata

473

is, Dl should sometimes not be required (for instance,
for periodic or " usually periodic" fluents with a known
period, like "sleep").

j/ull infinite persistence
_.l5 ymptotic persistence
----�

asymptotically

-==-t-� limited persistence
0 L-----"'+-Jo..��---�
limited persistencet
no persistence at all

Figure 4: some forward persistence functions
On Figure 4 we have represented continuous functions
satisfying D1 (except no persistence at al0; note that
any persistence function satisfying Dl and continuity
is of one of the four following types shown on figure 4.
Among other possible requirements, one could require
the persistence function to be strictly decreasing on
[t0, +oo) (which rules out limited persistence func­
tions) or, which is weaker, strictly decreasing in the
right neighbourhood of to.
These requirements can be formulated in very simi­
lar ways for all other classes of extrapolation problems
(for the sake of brevity we will omit doing it).
Backward extrapolation
This is very analogous to the case of forward persis­
tence, except that persistence is "increasing" (but, of
course, still decreasing with respect to the distance to
the nearest reference time point): given a backward
extrapolation problem (H,f, ( -oo, t0):
D2. N1(f) is non-decreasing on ( -oo, t0]

Independently from the exact shape of the persistence
function of a fluent f im an interval I, there are some
very general properties that is may be desirable to im­
pose. We give a first set of very basic axioms which are
completely qualitative (since they do not use the met­
ric nature of T and [0, 1]); we propose then a second
set of more debatable properties, which are qualitative
with respect to necessity degrees but quantitative with
respect to time.

Bounded extrapolation without change
Let (H, f, (to, t1)) be a bounded extrapolation prob­
lem without change (without loss of generality, f be­
ing True at both to and tl).
D3. 3t* E (to, t1] such that N1(!) is is non-increasing
in (to, t*] and non-decreasing in (h, ti).
Strictness in the neighbourhoods of t0 and t1 would
ensure that t* E (to, t1)). Note that the persistence
function needs not to be symmetrical. Some admissi­
ble functions are shown on figure 5.

4.1

When the persistence function is continuous, it is nec­
essarily of one of the 3 following types, shown on figure
5, depending on the minimal value of N1(!) on [to, t1):
full persistence, where "'t E [to, t1), Nt(f) = 1; elastic
persistence, where Min1e[to,t.]N1(!) E (0, 1); and par­
tially elastic persistence, where Min1e[t0,tt]Nt (!) = 0.
Elastic persistence should occur whenever the interval
[t0, tl] is short enough for the fluent to always remain
somewhat certain; if the interval is too long, then we
only have partially elastic persistence, and there are
some time points within the interval when it cannot
be guaranteed that the fluent is still somewhat cer-

Basic axioms for persistence functions

These very basic axioms just ensure that persistence is
well respecting the principle of increasing ignorance.
Forward extrapolation
Let ( H,f,(t0, +oo)) be a forward extrapolation prob­
lem.
Dl. N1(f) is non-increasing on (t0, +oo)
Obviously, Dl does not restrict a lot the possible per­
sistence functions; typical examples of functions satis­
fying Dl are shown in Figure 4. But, however basic it

474

Driankov and Lang

full persistence

f

f

no persistence at all

Figure 5: some functions for bounded extrapolation
without change
tain. Consider for example the fluent free (again the
parking place); if it is known that free holds at 10.00
and at 10.10, nothing being about its truth value in­
between, it is reasonable to consider the case of elas­
tic persistence (for it is almost certain that the place
has remained free for the whole interval); now, if it
is known that free holds January 1st at 10.00 and at
May 1st at 10.00, nothing being known about its truth
value inbetween, then it is of course not reasonable to
assume the same, since for time points far from both
January 1st 10.00 and May 1st 10.00 it should be ab­
solutely not certain that free still holds.
Bounded extrapolation with change
Let (H,f ,(to,ti)) be a bounded extrapolation problem
with change (without loss of generality, f being True
at to and False at t1). If we assume we do not want
to generate partially inconsistent time-points (which
is very reasonable), it must be always the case that
min(N1(f), Nt(-,J)) = 0, thus the following axiom:
D4. 3t', t", with to S t' S t" S t1 such that N1(f) is
non-increasing in [to,t'], N1( f ) = 0 in [t',t1], Nt(_,J) =
0 in [to , t"] and N1( -, f ) is non-decreasing in [t",t1].
4.2

Semi-quantitative axioms for decreasing
persistence

The axioms we have given so far are very weak; in this
subsection we give stronger axioms which do not use
the metric properties of the certainty scale [0, 1] but
which use the metric properties of the temporal scale.
4.2.1

Homogeneity

The main condition for a fluent being homogeneous is
that the way it behaves with respect to decreasing per­
sistence depends only on the class of the extrapolation
problem and the time length of the interval, but not
on when the interval starts. For instance, while the
fluent "ra.ining" may well be considered homogeneous
on a time scale of 24 hours, it cannot be the case for
the free parking place which will more certainly remain
free after some period of time, say, at 10 pm than at 10
am. So, homogeneity should not always be required.
However, in many cases, even if a fluent is definitely
not homogeneous on the whole time scale, it can often

be considered homogeneous on some shorter subinter­
vals. The exact formulation of homogeneity is however
more complex and expresses monotonicity conditions
with respect to interval lengths. Let us now write for­
mally some of the numerous homogeneity conditions.
From now on, f is a homogeneous fluent over the whole
time scale.
Case 1: monotonicity for two bounded extrapolation
problems without change
Let H be a partial history; let (H,f ,(t0,t1)) and
(H,f,(tz, t3)) be two bounded extrapolation problems
without change, the truth value of f at the bounds
of both intervals being identical (say, Tr ue ). Homo­

geneity tells us that the shorter the interval, the more
certain of the persistence of f in the interval. For in­
stance; if free is homogeneous over [8.00, 12.00], and
is known to be true at 9.00, 9.10, 11.00 and 11.20,
free holding at 9.01 should be at least as certain than
free holding at 11.01, and similarly, free holding at
9.09 should be at least as certain than free holding at
11.19, for rather obvious reasons. Assume without loss
of generality that t1- to S t3- tz, and let 8 = t1-t0;
then
Hl.
Vx E [0,8],Nto+x(f) S Nt,+x (f) and Vx E
[0, 8], N t1-x(f) S Nt3-x(f)
As an immediate consequence, if t1-t 0 = t3-t2,then
Vx E [0,8],Nto+x(f) = Nt2+xCf), i.e. the persistence
function is exactly the same within two intervals of the
same length.
·

Case 2: monotonicity between forward extrapolation
and bounded extrapolation without change
Let (H, f, (to,t1)) be a bounded extrapolation prob­
lem without change and (H, f,(t2,+oo)) be a forward
extrapolation problem (!being True at t0,t1 and t2).
Let 8 = t1 -to. Then homogeneity tells that persis­
tence should decrease at least as fast within [t3,+oo)
as in [to, tl] , which writes
H2. Vx E [0, 8],Nto+x(f) 2:: Nt1+x(f).
Case 3: bounded with change/ bounded with change
Suppose we have two bounded extrapolation problems
with change concerning the same fluent f, within the
two intervals (to , t1) and (tz, t3), the truth value off
at to and t2 being the same (say, True). T hen, homo­
geneity tells us that the shorter the interval, the faster
persistence decreases f in the interval (contrarily to
what happens in the case of bounded persistence with­
out change where the shorter the interval, the slower
persistence decreases). Let us assume without loss of
generality that t1 -to S t3 -t2 and let 8 = t1 -to ;
then we get
H3. Vx E [0,8],Nto+x (f) 2:: Nt,+ x ( f )
and Vx E [0,8], Nt1-x ( -, f ) S Nt,-x(-,f ).

For the sake of brevity, we omit writing monotonic­
ity conditions for the other cases (bounded without
change( backward, bounded with change/ bounded
without change, bounded with change/ forward).

Possibilistic decreasing persistence

4.2.2

Other metric axioms

Among the other axioms we may require for some fiu­
ents, we can consider for instance forward/backward
symmetry, which means that the fluent behaves sym­
metrically with respect to forward and backward ex­
trapolation. Note that a lot of fiuents don't (for
instance, consider the well-known fluent alive of
the Yale Shoooting Problem). Assuming both for­
ward/backward symmetry and homogeneity for f im­
plies that backwards and forwards extrapolation func­
tions are symmetric of each other, that functions for
bounded persistence without change are symmetric
relatively to the middle of the considered interval, and
a symmetry property concerning bounded persistence.
A stronger possible requirement (often too strong) is
symmetry with respect to negation: the truth value
"true" of the fluent tends to persist exactly the same
way as the truth value "false". Among other things,
it implies that, for a bounded persistence with change
problem, the increasing functions for f (resp. •f) and
the increasing function for •g (resp. f) are symmetric
of each other.
4.3

Quantitative persistence functions

All the previous requirements do not enforce precise
persistence functions. This last step (necessary for
practical application) has to be done by the user. For
instance, a reasonable choice for a family of persistence
schemata consists in piecewise linear functions.
5

Inferring nonmonotonic conclusions
from decreasing persistence

In Section 2, we have seen how, from a possibilistic
knowledge base, it is possible to define a nonmono­
tonic inference relation. So, since the application of
decreasing persistence principles to a partial history
gives us a possibilistic knowledge base, it is then pos­
sible to draw some non monotonic inferences. More
formally, let H be a partial history on a time scale T,
and let Pers be a set of persistence schemata for a sub­
set of the fluents involved in H. Let App/y(Pers, H)
be the application of Pers to H as defined in Section
3. Now, for any t, let Nt be the necessity measure
obtained by the application of the principle of mini­
mum specificity (as in Section 2) to Apply(Pers, H)t·
Then, for any t E T, we can define the nonmonotonic
inference relation l"'t as in Section 2. Let us now give
a detailed exampl e.
Example

Let us consider two machines A and B which may be
either working or in failure at any time point. Let
A and B be propositional fiuents, A (resp. B) being
true iff A (resp. B) is working. Both machines are
considered equivalent with respect to persistence; fur­
thermore we assume that A and B are homogeneous

475

on T, and the persistence functions of A and •A are
represented on figure 6 (the time unit being the day).

0.2

I
I
I
I
I
I
I

.. 1 .

- - ·----

1
I

tO

t0+10

tO

t0+3

F igure 6:
Let us briefly comment these two persistence func­
tions. The asymptotic value of 0.2 in the forward per­
sistence function of works means that the certainty
degree by default of works is 0.2, i.e. it is somewhat
certain that machine work, independently from persis­
tence considerations. The fastly decreasing persistence
of •works is due to the existence of repairmen (failing
machines tend to be repaired in short delays). Let I<
be the following timed knowledge base: machine A is
known to be working from 0 to 10, machine B is known
to be working from 17 to 30 and we know that at least
one of the two machines is not in a failure state at time
15; formally:
K = {[0, 10]: A; [15]: -,A v ·B; [17, 30]: B}.
Now, consider the fluent A. We have successively
a backward extrapolation problem on ( -co, 0), and
then a forward extrapolation problem on (10, +oo ).
Applying the decreasing persistence schemata, we get
the following certainty degrees at time 15: Ni5(A) =
0.5; Ni5(B) = 0.8 and (without needing persis­
tence schemata) Ni5(•A V ·B) = 1. We have also
Ni5(•A) = min(Ni5(•AV•B), Ni5(B)) = 0.8. More­
over we get Ni5(j_) = min(Ni5(A), Ni5(B), Ni5(•A V
•B)) = 0.5; hence, the knowledge has an inconsistency
degree at time 15.
Since Ni5(....A
., ) = 0.8 > Ni5(j_), we have 1"'15 •A;
similarly we have 1"'15 B, but we do not have 1"'15 A.
or l"'1s •B. This is due to the fact that the closest
time point when B is true is closer to 15 than the clos­
est time point where A is true.
Note also that at t = 35, we have Nj5(B) = 0.5 and
N35(j_) == 0, so we have /"'35 B.
6

Concluding remarks

In this paper we have shown that possibility theory
is well-suited for modelling gradually decreasing per­
sistence, mainly because it is adequate to represent­
ing ;;tates of partial or complete ignorance. More­
over, since necessity orderings and similar construc­
tions have been proved to be well-suited for perform­
ing nonmonotonic deductions, this framework provides
us with a general methodology for inferring uncertain,
defeasible conclusions from a "hard facts" knowledge
base and some persistence schemata describing, for
each fluent, how ignorance increases with respect to

476

Driankov and Lang

its persistence.

J.M Dunn, eds.), 8-37.

We think of pursuing our work in many directions.
First of all, in this paper we considered decreasing per­
sistence schemata only for atomic fluents; this leads to
some problems when only disjunctions of fluents are
known (see (Schrag 92) for a study of problems cre­
ated by disjunction in reasoning about persistence).
For instance, consider the partial history where f V g
is True at t0, nothing else being known. Since both
fluents I and g have the Unknown status at t0, we
can apply persistence schemata to none of them; and
since there is no persistence schema for I V g, we will
get Nto+f(f V g) = 0 \If > 0, i.e. no persistence
at all for I V g. This could be avoided by applying
persistence to non-atomic formulas as well; however,
this leads to many technical problems, because per­
sistence schemata of different formulas sharing fluents
obviously interact. This is a topic left for further re­
search.

Salem Benferhat, Didier Dubois, Henri Prade (1992),
Representing default rules in possibilistic logic, Proc.
KR'92, 673-684.

We could also generalize our study to non­
propositional fluents (i.e. whose domain is not True,
False), which should not cause any trouble; we also
think to incorporate decreasing persistence principles
with non-gradual approaches dealing not only with
persistence but more generally with time and action,
such as in (Sandewall 92). Another easy generalisa­
tion of our work would consist in starting from a timed
knowledge base already pervaded with uncertainty (i.e.
from a possibilistic knowledge base) and to extrapolate
necessity measures in a similar way. Moreover, work of
Section 4 can be extended; in particular, it would be
interesting to make a classification of fluents with re­
spect to how they behave w.r.t decreasing persistence
(adding other properties such as periodicity, ...).
Then, it would be interesting to generalize the prin­
ciple of decreasing persistence to spatial reasoning
(extrapolating the truth value of a fluent at a point
(x, y, z) by considering some close points where its
truth value is known). Integrating both temporal and
spatial "persistence" could enable us to infer defeasible
conclusions from knowledge about time, space and mo­
tion. Next step would be a formal logical study of such
a methodology, which could use notions of distances or
similarity measures between worlds as in (Ruspini 91).
Acknowledgements

We would like to thank Patrick Doherty, Didier Dubois
and Henri Prade for helpful discussions. This work has
been supported by the European ESPRIT Basic Re­
search Action # 6156 entitled "Defeasible Reasoning
and Uncertainty Management Systems (DRUMS-2)".

GROUP ACTIVITY SELECTION PROBLEM

arXiv:1401.8151v1 [cs.GT] 31 Jan 2014

ANDREAS DARMANN1 , EDITH ELKIND2 , SASCHA KURZ3 , JÉRÔME LANG4 , JOACHIM SCHAUER1 ,
AND GERHARD WOEGINGER5

A BSTRACT. We consider a setting where one has to organize one or several group activities for a set of agents. Each agent will participate in at most one activity, and her
preferences over activities depend on the number of participants in the activity. The goal
is to assign agents to activities based on their preferences. We put forward a general model
for this setting, which is a natural generalization of anonymous hedonic games. We then
focus on a special case of our model, where agents’ preferences are binary, i.e., each agent
classifies all pairs of the form ”(activity, group size)” into ones that are acceptable and
ones that are not. We formulate several solution concepts for this scenario, and study them
from the computational point of view, providing hardness results for the general case as
well as efficient algorithms for settings where agents’ preferences satisfy certain natural
constraints.

1. I NTRODUCTION
There are many real-life situations where a group of agents is faced with a choice of
multiple activities, and the members of the group have differing preferences over these
activities. Sometimes it is feasible for the group to split into smaller subgroups, so that
each subgroup can pursue its own activity. Consider, for instance, a workshop whose
organizers would like to arrange one or more social activities for the free afternoon.1 The
available activities include a hike, a bus trip, and a table tennis competition. As they will
take place simultaneously, each attendee can select at most one activity (or choose not to
participate). It is easy enough to elicit the attendees’ preferences over the activities, and
divide the attendees into groups based on their choices. However, the situation becomes
more complicated if one’s preferences may depend on the number of other attendees who
choose the same activity. For instance, the bus trip has a fixed transportation cost that has to
be shared among its participants, which implies that, typically, an attendee i is only willing
to go on the bus trip if the number of other participants of the bus trip exceeds a threshold
ℓi . Similarly, i may only be willing to play table tennis if the number of attendees who
signed up for the tournament does not exceed a threshold ui : as there is only one table, the
more participants, the less time each individual spends playing.
Neglecting to take the number of participants of each activity into account may lead to
highly undesirable outcomes, such as a bus that is shared by two persons, each of them
paying a high cost, and a 48-participant table tennis tournament with one table. Adding
constraints on the number of participants for each activity is a practical, but imperfect
solution, as the agents’ preferences over group sizes may differ: while some attendees
(say, senior faculty) may be willing to go on the bus trip with just 4–5 other participants,
others (say, graduate students) cannot afford it unless the number of participants exceeds
10. A more fine-grained approach is to elicit the agents’ preferences over pairs of the
form “(activity, group size)”, rather than over activities themselves, and allocate agents to
1

Some of the co-authors of this paper had to deal with this problem when co-organizing a Dagstuhl seminar.
1

2ANDREAS DARMANN1 , EDITH ELKIND2 , SASCHA KURZ3 , JÉRÔME LANG4 , JOACHIM SCHAUER1 , AND GERHARD WOEGINGER5

activities based on this information. In general, agents’ preferences can be thought of as
weak orders over all such pairs, including the pair “(do nothing, 1)”, which we will refer to
as the void activity. A simpler model, which will be the main focus of this paper, assumes
that each agents classifies all pairs into ones that are acceptable to him and ones that are not,
and if an agent views his current assignment as unacceptable, he prefers (and is allowed)
to switch to the void activity (so the assignment is unstable unless it is acceptable to all
agents).
The problem of finding a good assignment of agents to activities, which we will refer to as the Group Activity Selection Problem (GASP), may be viewed as a mechanism
design problem (or, more narrowly, a voting problem) or as a coalition formation problem, depending on whether we expect the agents to act strategically when reporting their
preferences. Arguably, in our motivating example the agents are likely to be honest, so
throughout the paper we assume that the central authority knows (or, rather, can reliably
elicit) the agents’ true preferences, and its goal is to find an assignment of players to activities that, informally speaking, is stable and/or maximizes the overall satisfaction. This
model is closely related to that of anonymous hedonic games [3], where, just as in our setting, players have to split into groups and each player has preferences over possible group
sizes. The main difference between anonymous hedonic games and our problem is that,
in our setting, the agents’ preferences depend not only on the group size, but also on the
activity that has been allocated to their group; thus, our model can be seen as a generalization of anonymous hedonic games. On the other hand, we can represent our problem
as a general (i.e., non-anonymous) hedonic game [4, 3], by creating a dummy agent for
each activity and endowing it with suitable preferences (see Section 2.2 for details). However, our setting has useful structural properties that distinguish it from a generic hedonic
game: for instance, it allows for succinct representation of players’ preferences, and, as we
will see, has several natural special cases that admit efficient algorithms for finding good
outcomes.
In this paper, we initiate the formal study of GASP. Our goal is to put forward a model
for this problem that is expressive enough to capture many real-life activity selection scenarios, yet simple enough to admit efficient procedures for finding good assignments of
agents to activities. We describe the basic structure of the problem, and discuss plausible constraints of the number and type of available activities and the structure of agents’
preferences. We show that even under a fairly simple preference model (where agents are
assumed to approve or disapprove each available alternative) finding an assignment that
maximizes the number of satisfied agents is computationally hard; however, we identify
several natural special cases of the problem that admit efficient algorithms. We also briefly
discuss the issue of stability in our setting.
We do not aim to provide a complete analysis of the group activity selection problem;
rather, we view our work as a first step towards understanding the algorithmic and incentive
issues that arise in this setting. We hope that our paper will lead to future research on this
topic; to facilitate this, throughout the paper we highlight several possible extensions of
our model as well as list some problems left open by our work.
2. F ORMAL M ODEL
Definition 2.1. An instance of the Group Activity Selection Problem (GASP) is given by a
set of agents N = {1, . . . , n}, a set of activities A = A∗ ∪{a∅ }, where A∗ = {a1 , . . . , ap },
and a profile P , which consists of n votes (one for each agent): P = (V1 , . . . , Vn ). The
vote of agent i describes his preferences over the set of alternatives X = X ∗ ∪ {a∅ }, where

GROUP ACTIVITY SELECTION PROBLEM

3

X ∗ = A∗ × {1, . . . , n}; alternative (a, k), a ∈ A∗ , is interpreted as “activity a with k
participants”, and a∅ is the void activity.
The vote Vi of an agent i ∈ N is (also denoted by i ) is a weak order over X ∗ ; its
induced strict preference and indifference relations are denoted by ≻i and ∼i , respectively.
We set Si = {(a, k) ∈ X ∗ | (a, k) ≻i a∅ }; we say that voter i approves of all alternatives
in Si , and refer to the set Si as the induced approval vote of voter i.
Throughout the paper we will mostly focus on a special case of our problem where
no agent is indifferent between the void activity and any other alternative (i.e., for any
i ∈ N we have {x ∈ X ∗ | x ∼i a∅ } = ∅), and each agent is indifferent between all the
alternatives in Si . In other words, preferences are trichotomous: the agent partitions X
into three clusters Si , {a∅ } and X \ (Si ∪ {a∅ }), is indifferent between two alternatives of
the same cluster, prefers any (a, k) in Si to a∅ , and a∅ to any (a, k) in X \ (Si ∪ {a∅ });
we denote this special case of our problem by a-GASP.
It will be convenient to distinguish between activities that are unique and ones that exist
in multiple copies. For instance, if there is a single tennis table and two buses, then we
can organize one table tennis tournament, two bus trips (we assume that there is only one
potential destination for the bus trip, so these trips are identical), and an unlimited number
of hikes (again, we assume that there is only one hiking route). This distinction will be
useful for the purposes of complexity analysis: for instance, some of the problems we
consider are easy when we have k copies of one activity, but hard when we have k distinct
activities. Formally, we say that two activities a and b are equivalent if for every agent i
and every j ∈ {1, . . . , n} it holds that (a, j) ∼i (b, j). We say that an activity a ∈ A∗ is
k-copyable if A∗ contains exactly k activities that are equivalent to a (including a itself).
We say that a is simple if it is 1-copyable; if a is k-copyable for k ≥ n, we will say that
it is ∞-copyable (note that we would never need to organize more than n copies of any
activity). If some activities in A∗ are equivalent, A∗ can be represented more succinctly by
listing one representative of each equivalence class, together with the number of available
copies. However, as long as we make the reasonable assumption that each activity exists
in at most n copies, this representation is at most polynomially more succinct.
Our model can be enriched by specifying a set of constraints Γ. One constraint that
arises frequently in practice is a global cardinality constraint, which specifies a bound K
on the number of activities to be organized. More generally, we could also consider more
complex constraints on the set of activities that can be organized simultaneously, which can
be encoded, e.g., by a propositional formula or a set of linear inequalities. We remark that
there can also be external constraints on the number of participants for each activity: for
instance, a bus can fit at most 40 people. However, these constraints can be incorporated
into agents’ preferences, by assuming that all agents view the alternatives that do not satisfy
these constraints as unacceptable.
2.1. Special Cases. We now consider some natural restrictions on agents’ preferences that
may simplify the problem of finding a good assignment. We first need to introduce some
additional notation. Given a vote Vi and an activity a ∈ A∗ , let Si↓a denote the projection
of Si onto {a} × {1, . . . , n}. That is, we set Si↓a = {k | (a, k) ∈ Si }.

Example 2.2. Let A∗ = {a, b} and consider an agent i whose vote Vi is given by
(a, 8) ≻i (a, 7) ∼i (b, 4) ≻i (a, 9) ≻i (b, 3) ≻i (b, 5) ≻i (a, 6) ≻i (b, 6) ≻i a∅ ≻i . . .
Then Si = {a} × [6, 9] ∪ {b} × [3, 6] and Si↓a = {6, 7, 8, 9}.

We are now ready to define two types of restricted preferences for a-GASP that are
directly motivated by our running example, namely, increasing and decreasing preferences.

4ANDREAS DARMANN1 , EDITH ELKIND2 , SASCHA KURZ3 , JÉRÔME LANG4 , JOACHIM SCHAUER1 , AND GERHARD WOEGINGER5

Informally, under increasing preferences an agent prefers to share each activity with as
many other participants as possible (e.g., because each activity has an associated cost,
which has to be split among the participants), and under decreasing preferences an agent
prefers to share each activity with as few other participants as possible (e.g., because each
activity involves sharing a limited resource). Of course, an agent’s preferences may also be
increasing with respect to some activities and decreasing with respect to others, depending
on the nature of each activity. We provide a formal definition for a-GASP only; however,
it can be extended to GASP in a straightforward way.
Definition 2.3. Consider an instance (N, A, P ) of a-GASP. We say that the preferences
of agent i are increasing (INC) with respect to an activity a ∈ A∗ if there exists a threshold
ℓai ∈ {1, . . . , n + 1} such that Si↓a = [ℓai , n] (where we assume that [n + 1, n] = ∅).
Similarly, we say that the preferences of agent i are decreasing (DEC) with respect to an
activity a ∈ A∗ if there exists a threshold uai ∈ {0, . . . , n} such that Si↓a = [1, uai ] (where
we assume that [1, 0] = ∅).
We say that an instance (N, A, P ) of a-GASP is increasing (respectively, decreasing) if
the preferences of each agent i ∈ N are increasing (respectively, decreasing) with respect
to each activity a ∈ A∗ . We say that an instance (N, A, P ) of a-GASP is mixed increasingdecreasing (MIX) if there exists a set A+ ⊆ A∗ such that for each agent i ∈ N his
preferences are increasing with respect to each a ∈ A+ and decreasing with respect to
each a ∈ A− = A∗ \ A+ .
A recently proposed model which can be embedded into GASP with decreasing preferences is the ordinal version of cooperative group buying ([7], Section 6): the model has a
set of buyers and a set of items with volume discounts; buyers rank all pairs (j, pj ) for any
item j and any of its possible discounted prices, where the discounted price is a function
of the number of buyers who are matched to the item.
For some activities, an agent may have both a lower and an upper bound on the acceptable group size: e.g., one may prefer to go on a hike with at least 3 other people, but does
not want the group to be too large (so that it can maintain a good pace). In this case, we
say that an agent has interval (INV) preferences; note that INC/DEC/MIX preferences are
a special case of interval preferences.
Definition 2.4. Consider an instance (N, A, P ) of a-GASP. We say that the preferences
of agent i are interval (INV) if for each a ∈ A∗ there exists a pair of thresholds ℓai , uai ∈
{1, . . . , n} such that Si↓a = [ℓai , uai ] (where we assume that [i, j] = ∅ for i > j).
Other natural constraints on preferences include restricting the size of Si (or, more
liberally, that of Si↓a for each a ∈ A∗ ), or requiring agents to have similar preferences:
for instance, one could limit the number of agent types, i.e., require that the set of agents
can be split into a small number of groups so that the agents in each group have identical
preferences. We will not define such constraints formally, but we will indicate if they are
satisfied by the instances constructed in the hardness proofs in Section 4.1.
2.2. GASP and Hedonic Games. Recall that a hedonic game [3, 4] is given by a set of
agents N , and, for each agent i ∈ N , a weak order ≥i over all coalitions (i.e., subsets of
N ) that include i. That is, in a hedonic game each agent has preferences over coalitions
that he can be a part of. A coalition S, i ∈ S, is said to be unacceptable for player i if
{i} >i S. A hedonic game is said to be anonymous if each agent is indifferent among all
coalitions of the same size that include him, i.e., for every i ∈ N and every S, T ⊆ N \ {i}
such that |S| = |T | it holds that S ∪ {i} ≥i T ∪ {i} and T ∪ {i} ≥i S ∪ {i}.

GROUP ACTIVITY SELECTION PROBLEM

5

At a first glance, it may seem that the GASP formalism is more general than that of
hedonic games, since in GASP the agents care not only about their coalition, but also
about the activity they have been assigned to. However, we will now argue that GASP can
be embedded into the hedonic games framework.
Given an instance of the GASP problem (N, A, P ) with |N | = n, where the i-th agent’s
preferences are given by a weak order i , we construct a hedonic game H(N, A, P ) as
follows. We create n + p players; the first n players correspond to agents in N , and the
last p players correspond to activities in A∗ . The last p players are indifferent among all
coalitions. For each i = 1, . . . , n, player i ranks every non-singleton coalition with no
activity players as unacceptable; similarly, all coalitions with two or more activity players
are ranked as unacceptable. The preferences over coalitions with exactly one activity player
are derived naturally from the votes: if S, T are two coalitions involving player i, x is the
unique activity player in S, and y is the unique activity player in T , then i weakly prefers
S to T in H(N, A, P ) if and only if (x, |S| − 1) i (y, |T | − 1), and i weakly prefers S
to {i} in H(N, A, P ) if and only if (x, |S| − 1) i a∅ . We emphasize that the resulting
hedonic games are not anonymous. Further, while this embedding allows us to apply the
standard solution concepts for hedonic games without redefining them, the intuition behind
these solution concepts is not always preserved (e.g., because activity players never want
to deviate). Therefore, in Section 3, we will provide formal definitions of the relevant
hedonic games solution concepts adapted to the setting of a-GASP.
We remark that when A∗ consists of a single ∞-copyable activity (i.e., there are n activities in A∗ , all of them equivalent to each other), GASP become equivalent to anonymous
hedonic games. Such games have been studied in detail by Ballester [2], who provides a
number of complexity results for them. In particular, he shows that finding an outcome
that is core stable, Nash stable or individually stable (see Section 3 for the definitions of
some of these concepts in the context of a-GASP) is NP-hard. Clearly, all these complexity
results also hold for GASP. However, they do not directly imply similar hardness results
for a-GASP.
3. S OLUTION C ONCEPTS
Having discussed the basic model of GASP, as well as a few of its extensions and special
cases, we are ready to define what constitutes a solution to this problem.
Definition 3.1. An assignment for an instance (N, A, P ) of GASP is a mapping π : N →
A; π(i) = a∅ means that agent i does not participate in any activity. Each assignment
naturally partitions the agents into at most |A| groups: we set π 0 = {i | π(i) = a∅ } and
π j = {i | π(i) = aj } for j = 1, . . . , p. Given an assignment π, the coalition structure
CS π induced by π is the coalition structure over N defined as follows:


CS π = π j | j = 1, . . . , p, π j 6= ∅ ∪ {i} | i ∈ π 0 .
Clearly, not all assignments are equally desirable. As a minimum requirement, no agent
should be assigned to a coalition that he deems unacceptable. More generally, we prefer
an assignment to be stable, i.e., no agent (or group of agents) should have an incentive
to change its activity. Thus, we will now define several solution concepts, i.e., classes of
desirable assignments. We will state our definitions for a-GASP only, though all of them
can be extended to the more general case of GASP in a natural way. Given the connection
to hedonic games pointed out in Section 2.2, we will proceed by adapting the standard
hedonic game solution concepts to our setting; however, this has to be done carefully to
preserve intuition that is specific to our model.

6ANDREAS DARMANN1 , EDITH ELKIND2 , SASCHA KURZ3 , JÉRÔME LANG4 , JOACHIM SCHAUER1 , AND GERHARD WOEGINGER5

The first solution concept that we will consider is individual rationality.
Definition 3.2. Given an instance (N, A, P ) of a-GASP, an assignment π : N → A is
said to be individually rational if for every j > 0 and every agent i ∈ π j it holds that
(aj , |π j |) ∈ Si .
Clearly, if an assignment is not individually rational, there exists an agent that can benefit from abandoning his coalition in favor of the void activity. Further, an individually
rational assignment always exists: for instance, we can set π(i) = a∅ for all i ∈ N . However, a benevolent central authority would usually want to maximize the number of agents
that are assigned to non-void activities. Formally, let #(π) = |{i | π(i) 6= a∅ }| denote the
number of agents assigned to a non-void activity. We say that π is maximum individually
rational if π is individually rational and #(π) ≥ #(π ′ ) for every individually rational
assignment π ′ . Further, we say that π is perfect2 if #(π) = n. We denote the size of a
maximum individually rational assignment for an instance (N, A, P ) by #(N, A, P ). In
Section 4, we study the complexity of computing a perfect or maximum individually rational assignment for a-GASP, both for the general model and for the special cases defined in
Section 2.1.
Besides individual rationality, there are a number of solution concepts for hedonic
games that aim to capture stability against individual or group deviations, such as Nash
stability, individual stability, contractual individual stability, and (weak and strong) core
stability (see, e.g., [5]). In what follows, due to lack of space, we only provide the formal definition (and some results) for Nash stability. We briefly discuss how to adapt other
notions of stability to our setting, but we leave the detailed study of their algorithmic properties as a topic for future work.
Definition 3.3. Given an instance (N, A, P ) of a-GASP, an assignment π : N → A is
said to be Nash stable if it is individually rational and for every agent i ∈ N such that
π(i) = a∅ and every aj ∈ A∗ it holds that (aj , |π j | + 1) 6∈ Si .
If π is not Nash stable, then there is an agent assigned to the void activity who wants to
join a group that is engaged in a non-void activity, i.e., he would have approved of the size
of this group and its activity choice if he was one of them. Note that a perfect assignment is
Nash stable. The reader can verify that our definition is a direct adaptation of the notion of
Nash stability in hedonic games: if an assignment is individually rational, the only agents
who can profitably deviate are the ones assigned to the void activity. The requirement of
Nash stability is much stronger than that of individual rationality, and there are cases where
a Nash stable assignment does not exist (the proof is omitted due to space limits).
Proposition 3.4. For each n ≥ 2, there exists an instance (N, A, P ) of a-GASP with
|N | = n that does not admit a Nash stable assignment. This holds even if |A∗ | = 1 and all
agents have interval preferences.
In Definition 3.3 an agent is allowed to join a coalition even if the members of this
coalition are opposed to this. In contrast, the notion of individual stability only allows a
player to join a group if none of the existing group members objects. We remark that if all
agents have increasing preferences, individual stability is equivalent to Nash stability: no
group of players would object to having new members join.
2The terminological similarity with the notion of perfect partition in a hedonic game [1] is not a coincidence;

there a perfect partition assigns each agent to her preferred coalition; here a perfect assignment assigns each
agent to one of her equally preferred alternatives.

GROUP ACTIVITY SELECTION PROBLEM

7

A related hedonic games solution concept is contractual individual stability: under this
concept, an agent is only allowed to move from one coalition to another if neither the
members of his new coalition nor the members of his old coalition object to the move.
However, for a-GASP contractual individual stability is equivalent to individual stability.
Indeed, in our model no agent assigned to a non-void activity has an incentive to deviate,
so we only need to consider deviations from singleton coalitions.
The solution concepts discussed so far deal with individual deviations; resistance to
group deviations is captured by the notion of the core. One typically distinguishes between
strong group deviations, which are beneficial for each member of the deviating group, and
weak group deviations, where the deviation should be beneficial for at least one member
of the deviating group and non-harmful for others; these notions of deviation correspond
to, respectively, weak and strong core. We note that in the context of a-GASP strong group
deviations amount to players in π 0 forming a coalition in order to engage in a non-void
activity. This observation immediately implies that every instance of a-GASP has a nonempty weak core, and an outcome in the weak core can be constructed by a natural greedy
algorithm; we omit the details due to space constraints.
4. C OMPUTING G OOD O UTCOMES
In this section, we consider the computational complexity of finding a “good” assignment for a-GASP. We mostly focus on finding perfect or maximum individually rational
assignments; towards the end of the section, we also consider Nash stability. Besides the
general case of our problem, we consider special cases obtained by combining constraints
on the number and type of activities (e.g., unlimited number of simple activities, a constant
number of copyable activities, etc.) and constraints on voters’ preferences (INC, DEC,
INV, etc.). Note that if we can find a maximum individually rational assignment, we can
easily check if a perfect assignment exists, by looking at the size of our maximum individually rational assignment. Thus, we will state our hardness results for the “easier” perfect
assignment problem and phrase our polynomial-time algorithms in terms of the “harder”
problem of finding a maximum individually rational assignment.
4.1. Individual Rationality: Hardness Results. We start by presenting four NP-completeness
results, which show that finding a perfect assignment is hard even under fairly strong constraints on preferences and activities. We remark that this problem is obviously in NP, so
in what follows we will only provide the hardness proofs.
Our first hardness result applies when all activities are simple and the agents’ preferences are increasing.
Theorem 4.1. It is NP-complete to decide whether a-GASP admits a perfect assignment,
even when all activities in A∗ are simple and all agents have increasing preferences.
sketch. We provide a reduction from E XACT C OVER BY 3-S ETS (X3C). Recall that an
instance of X3C is a pair hX, Yi, where X = {1, . . . , 3q} and Y = {Y1 , . . . , Yp } is
a collection of 3-element subsets of X; it is a “yes”-instance if X can be covered by
exactly q sets from Y, and a “no”-instance otherwise. Given an instance hX, Yi of X3C,
we construct an instance of a-GASP as follows. We set N = {1, . . . , 3q} and A∗ =
{a1 , . . . , ap }. For each agent i, we define his vote Vi so that the induced approval vote Si
is given by Si = {(aj , k) | i ∈ Yj , k ≥ 3}, and let P = (V1 , . . . , Vn ). Clearly, (N, A, P )
is an instance of a-GASP with increasing preferences. It is not hard to check that hX, Yi
is a “yes”-instance of X3C if and only if (N, A, P ) admits a perfect assignment.  

8ANDREAS DARMANN1 , EDITH ELKIND2 , SASCHA KURZ3 , JÉRÔME LANG4 , JOACHIM SCHAUER1 , AND GERHARD WOEGINGER5

Our second hardness result applies to simple activities and decreasing preferences, and
holds even if each agent is willing to share each activity with at most one other agent.
Theorem 4.2. It is NP-complete to decide whether a-GASP admits a perfect assignment,
even when all activities in A∗ are simple, all agents have decreasing preferences, and,
moreover, for every agent i ∈ N and every alternative a ∈ A∗ we have Si↓a ⊆ {1, 2}.
sketch. Consider the following restricted variant of the problem of scheduling on unrelated
machines. There are n jobs and p machines. An instance of the problem is given by a
collection of numbers {pij | i = 1, . . . , n, j = 1, . . . , p}, where pij is the running time of
job i on machine j, and pij ∈ {1, 2, +∞} for every i = 1, . . . , n and every j = 1, . . . , p.
It is a “yes”-instance if there is a mapping ρ : {1, . . . , n} → {1, . . . , p} assigning jobs
to machines so that the makespan is at most 2, i.e., for each j = 1, . . . , p it holds that
P
i:ρ(i)=j pij ≤ 2. This problem is known to be NP-hard (see the proof of Theorem 5
in [6]).
Given an instance {pij | i = 1, . . . , n, j = 1, . . . , p} of this problem, we construct an
instance of a-GASP as follows. We set N = {1, . . . , n}, A∗ = {a1 , . . . , ap }. Further,
for each agent i ∈ N we construct a vote Vi so that the induced approval vote Si satisfies
↓a
↓a
↓a
Si j = {1} if pij = 2, Si j = {1, 2} if pij = 1, and Si j = ∅ if pij = +∞. Clearly,
these preferences satisfy the constraints in the statement of the theorem, and it can be
shown that a perfect assignment for (N, A, P ) corresponds to a schedule with makespan
of at most 2, and vice versa.


Our third hardness result also concerns simple activities and decreasing preferences.
However, unlike Theorem 4.2, it holds even if each agent approves of at most 3 activities.
The proof proceeds by a reduction from M ONOTONE 3-SAT.
Theorem 4.3. It is NP-complete to decide whether a-GASP admits a perfect assignment,
even when all activities in A∗ are simple, all agents have decreasing preferences, and,
moreover, for every agent i ∈ N it holds that |{a | Si↓a 6= ∅}| ≤ 3.
Our fourth hardness result applies even when there is only one activity, which is ∞copyable, and every agent approves at most two alternatives; however, the agents’ preferences constructed in our proof do not satisfy any of the structural constraints defined in
Section 2.1. The proof proceeds by a reduction from X3C.
Theorem 4.4. It is NP-complete to decide whether a-GASP admits a perfect assignment,
even when all activities in A∗ are equivalent (i.e., A∗ consists of a single ∞-copyable
activity a) and for every i ∈ N we have |Si↓a | ≤ 2.
4.2. Individual Rationality: Easiness Results. The hardness results in Section 4.1 imply that if A∗ contains an unbounded number of distinct activities, finding a maximum
individually rational assignment is computationally hard, even under strong restrictions on
agents’ preferences (such as INC or DEC). Thus, we can only hope to develop an efficient
algorithm for this problem if we assume that the total number of activities is small (i.e.,
bounded by a constant) or, more liberally, that the number of pairwise non-equivalent activities is small, and the agents’ preferences satisfy additional constraints. We will now
consider both of these settings, starting with the case where p = |A∗ | is bounded by a
constant.
Theorem 4.5. There exist an algorithm that given an instance of a-GASP finds a maximum
individually rational assignment and runs in time (n + 1)p poly(n).

GROUP ACTIVITY SELECTION PROBLEM

9

Proof. We will check, for each r = 0, . . . , n, if there is an individually rational assignment
π with #(π) = r, and output the maximum value of r for which this is the case. Fix an
r ∈ {0, . . . , n}. For every vector (n1 , . . . , np ) ∈ {0, . . . , n}p that satisfies n1 + · · · + np =
r we will check if there exists an assignment of agents to activities such that for each
j = 1, . . . , p exactly nj agents are assigned to activity aj (with the remaining agents being
assigned to the void activity), and each agent approves of the resulting assignment. Each
check will take poly(n) steps, and there are at most (n + 1)p vectors to be checked; this
implies our bound on the running time of our algorithm.
For a fixed vector (n1 , . . . , np ), we construct an instance of the network flow problem
as follows. Our network has a source s, a sink t, a node i for each player i = 1, . . . , n, and
a node aj for each aj ∈ A∗ . There is an arc of unit capacity from s to each agent, and an
arc of capacity nj from node aj to the sink. Further, there is an arc of unit capacity from
i to aj if and only if (aj , nj ) ∈ Si . It is not hard to see that an integral flow F of size r
in this network corresponds to an individually rational assignment of size r. It remains to
observe that it can be checked in polynomial time whether a given network admits a flow
of a given size.


Moreover, when A∗ consists of a single simple activity a, a maximum individually
rational assignment can be found by a straightforward greedy algorithm.
Proposition 4.6. Given an instance (N, A, P ) of a-GASP with A∗ = {a}, we can find
a maximum individually rational assignment for (N, A, P ) in time O(s log s), where s =
P
i∈N |Si |.
Proof. Clearly, (N, A, P ) admits an individually rational assignment π with #(π) = k if
and only if | {i | (a, k) ∈ Si } | ≥ k. Let R = {(i, k) | (a, k) ∈ Si }; note that |R| = s.
We can sort the elements of R in descending order with respect to their second coordinate
in time O(s log s). Now we can scan R left to right in order to find the largest value of k
such that R contains at least k pairs that have k as their second coordinate; this requires a
single pass through the sorted list.


Now, suppose that A∗ contains many activities, but most of them are equivalent to each
other; for instance, A∗ may consist of a single k-copyable activity, for a large value of
k. Then the algorithm described in the proof of Theorem 4.5 is no longer efficient, but
this setting still appears to be more tractable than the one with many distinct activities.
Of course, by Theorem 4.4, in the absence of any restrictions on the agents’ preferences,
finding a maximum individually rational assignment is hard even for a single ∞-copyable
activity. However, we will now show that this problem becomes easy if we additionally
assume that the agents’ preferences are increasing or decreasing.
Observe first that for increasing preferences having multiple copies of the same activity
is not useful: if there is an individually rational assignment where agents are assigned to
multiple copies of an activity, we can reassign these agents to a single copy of this activity
without violating individual rationality. Thus, we obtain the following easy corollary to
Theorem 4.5.
Corollary 4.7. Let (N, A, P ) be an instance of a-GASP with increasing preferences where
A∗ contains at most K activities that are not pairwise equivalent. Then we can find a
maximum individually rational assignment for (N, A, P ) in time nK poly(n).
If all preferences are decreasing, we can simply eliminate all ∞-copyable activities.
Indeed, consider an instance (N, A, P ) of a-GASP where some activity a ∈ A∗ is ∞copyable. Then we can assign each agent i ∈ N such that (a, 1) ∈ Si to his own copy

10
ANDREAS DARMANN1 , EDITH ELKIND2 , SASCHA KURZ3 , JÉRÔME LANG4 , JOACHIM SCHAUER1 , AND GERHARD WOEGINGER5

of a; clearly, this will only simplify the problem of assigning the remaining agents to the
activities.
It remains to consider the case where the agents’ preferences are decreasing, there is
a limited number of copies of each activity, and the number of distinct activities is small.
While we do not have a complete solution for this case, we can show that in the case of
a single k-copyable activity a natural greedy algorithm succeeds in finding a maximum
individually rational assignment.
Theorem 4.8. Given a decreasing instance (N, A, P ) of a-GASP where A∗ consists of a
single k-copyable activity (i.e., A∗ = {a1 , . . . , ak }, and all activities in A∗ are pairwise
equivalent), we can find a maximum individually rational assignment in time O(n log n).
Proof. Since all activities in A∗ are pairwise equivalent, we can associate each agent i ∈ N
with a single number ui ∈ {0, . . . , n}, which is the maximum size of a coalition assigned
to a non-void activity that he is willing to be a part of. We will show that our problem can
be solved by a simple greedy algorithm. Specifically, we sort the agents in non-increasing
order of ui s. From now on, we will assume without loss of generality that u1 ≥ · · · ≥ un .
To form the first group, we find the largest value of i such that ui ≥ i, and assign agents
1, . . . , i to the first copy of the activity. In other words, we continue adding agents to the
group as long as the agents are happy to join. We repeat this procedure with the remaining
agents until either k groups have been formed or all agents have been assigned to one of
the groups, whichever happens earlier.
Clearly, the sorting step is the bottleneck of this procedure, so the running time of
our algorithm is O(n log n). It remains to argue that it produces a maximum individually
rational assignment. To show this, we start with an arbitrary maximum individually rational
assignment π and transform it into the one produced by our algorithm without lowering the
number of agents that have been assigned to a non-void activity. We will assume without
loss of generality that π assigns all k copies of the activity (even though this is is not
necessarily the case for the greedy algorithm).
First, suppose that π(i) = a∅ , π(j) = aℓ for some i < j and some ℓ ∈ {1, . . . , k}.
Then we can modify π by setting π(i) = aℓ , π(j) = a∅ . Since i < j implies ui ≥ uj ,
the modified assignment is individually rational. By applying this operation repeatedly, we
can assume that the set of agents assigned to a non-void activity forms a contiguous prefix
of 1, . . . , n.
Next, we will ensure that for each ℓ = 1, . . . , k the group of agents that are assigned to
aℓ forms a contiguous subsequence of 1, . . . , n. To this end, let us sort the coalitions in π
according to their size, from the largest to the smallest, breaking ties arbitrarily. That is,
we reassign the k copies of our activity to coalitions in π so that ℓ < r implies |π ℓ | ≥ |π r |.
Now, suppose that there exist a pair of players i, j such that i < j, π(i) = aℓ , π(j) = ar ,
and ℓ > r (and hence |π ℓ | ≤ |π r |). We have uj ≥ |π r | ≥ |π ℓ |, ui ≥ uj ≥ |π r |, so if we
swap i and j (i.e., modify π by setting π(j) = aℓ , π(i) = ar ), the resulting assignment
remains individually rational. Observe that every such swap increases the quantity Σ =
Pk P
t=1
s∈π t (s · t) by at least 1: prior to the swap, the contribution of i and j to Σ is
iℓ + jr, ans after the swap it is ir + jℓ > iℓ + jr. Since for any assignment we have
Σ ≤ kn(n + 1)/2, eventually we arrive to an assignment where no such pair (i, j) exists.
At this point, each π ℓ , ℓ = 1, . . . , k, forms a contiguous subsequence of 1, . . . , n, and,
moreover, ℓ < r implies i ≤ j for all i ∈ π ℓ , j ∈ π r .
Now, consider the smallest value of ℓ such that π ℓ differs from the ℓ-th coalition constructed by the greedy algorithm (let us denote it by γ ℓ ), and let i be the first agent in π ℓ+1 .
The description of the greedy algorithm implies that π ℓ is a strict subset of γ ℓ and agent

GROUP ACTIVITY SELECTION PROBLEM

11

i belongs to γ ℓ . Thus, if we modify π by moving agent i to π ℓ , the resulting allocation
remains individually rational (since i is happy in γ ℓ ). By repeating this step, we will gradually transform π into the output of the greedy algorithm (possibly discarding some copies
of the activity). This completes the proof.


The algorithm described in the proof of Theorem 4.8 can be extended to the case where
we have one k-copyable activity a and one simple activity b, and the agents have decreasing
preferences over both activities. For each s = 1, . . . , n we will look for the best solution
in which s players are assigned to b; we will then pick the best of these n solutions. For
a fixed s let Ns = {i ∈ N | (b, s) ∈ Si }. If |Ns | < s, no solution for this value of s
exists. Otherwise, we have to decide which size-s subset of Ns to assign to b. It is not hard
to see that we should simply pick the agents in Ns that have the lowest level of tolerance
for a, i.e., we order the agents in Ns by the values of uai from the smallest to the largest,
and pick the first s agents. We then assign the remaining agents to copies of a using the
algorithm from the proof of Theorem 4.8. Indeed, any assignment can be transformed into
one of this form by swapping agents so that the individual rationality constraints are not
broken. It would be interesting to see if this idea can be extended to the case where instead
of a single simple activity b we have a constant number of simple activities or a single
k ′ -copyable activity.
√
We conclude this section by giving an O( n)-approximation algorithm for finding a
maximum individually rational assignment in a-GASP with a single ∞-copyable activity.
Theorem 4.9. There exists a polynomial-time algorithm that given an instance (N, A, P )
of a-GASP where A∗ consists of a single ∞-copyable activity a, outputs an individually
rational assignment π with #(π) = Θ( √1n )#(N, A, P ).
Proof. We say that an agent i is active in π if π(i) 6= a∅ ; a coalition of agents is said
to be active if it is assigned to a single copy of a. We construct an individually rational
assignment π iteratively, starting from the assignment where no agent is active. Let N ∗ =
{i | π(i) = a∅ } be the current set of inactive agents (initially, we set N ∗ = N ). At
each step, we find the largest subset of N ∗ that can be assigned to a single fresh copy of
a without breaking the individual rationality constraints, and append this assignment to π.
We repeat this step until the inactive agents cannot form another coalition.
Now we compare the number of active agents in π with the number of active agents
in a maximum individually rational assignment π ∗ . To this end, let √
us denote the active
coalitions of π by B1 , . . . , Bs , where |B1 | ≥ . . . ≥ |Bs |. If |B1 | ≥ n, we are done, so
assume√that this is not the case. Note that since B1 was chosen greedily, this implies that
|C| ≤ n for every active coalition C in π ∗ .
Let C be the set of active coalitions in π ∗ . We partition C into s groups by setting
1
C = {C ∈ C | C ∩ B1 6= ∅} and C i = {C ∈ C | C ∩ Bi 6= ∅, C 6∈ C j for j < i}
for i = 2, . . . , s. Note that every active coalition C ∈ π ∗ intersects some coalition in π:
otherwise we could add C to π. Therefore, each active coalition in π ∗ belongs to one of the
sets C 1 , . . . , C s . Also, by construction, the sets C 1 , . . . , C s are pairwise disjoint. Further,
since the coalitions in C i are pairwise disjoint and each of them intersects Bi , we have
|C i | ≤ |Bi | for each i = 1, . . . , s. Thus, we obtain
X X
X X √
#(π ∗ ) =
|C| ≤
n
i=1,...,s C∈C i

≤

X
i=1,...,s

i=1,...,s C∈C i

X
√
√
√
|C | n ≤
|Bi | n ≤ #(π) n.
i

i=1,...,s



12
ANDREAS DARMANN1 , EDITH ELKIND2 , SASCHA KURZ3 , JÉRÔME LANG4 , JOACHIM SCHAUER1 , AND GERHARD WOEGINGER5


4.3. Nash Stability. We have shown that a-GASP does not not always admit a Nash stable
assignment (Proposition 3.4). In fact, it is difficult to determine whether a Nash stable
assignment exists. The proofs of the next two results are omitted due to space constraints.
Theorem 4.10. It is NP-complete to decide whether a-GASP admits a Nash stable assignment.
However, if agents’ preferences satisfy INC, DEC, or MIX, a Nash stable assignment
always exists and can be computed efficiently.
Theorem 4.11. If (N, A, P ) is an instance of a-GASP that is increasing, decreasing, or
mixed increasing-decreasing, a Nash stable assignment always exists and can be found in
polynomial time.
Moreover, the problem of finding a Nash stable assignment that maximizes the number
of agents assigned to a non-void activity admits an efficient algorithm if A∗ consists of a
single simple activity.
Theorem 4.12. There exist a polynomial-time algorithm that given an instance (N, A, P )
of a-GASP with A∗ = {a} finds a Nash stable assignment maximizing the number of
agents assigned to a non-void activity, or decides that no Nash stable assignment exists.
Proof. For each k = n, . . . , 0, we will check if there exists a Nash stable assignment π
with #(π) = k, and output the largest value of k for which this is the case.
For each i ∈ N , let Si′ = Si↓a . For k = n a Nash stable assignment π with #(π) =
n exists if and only if n ∈ Si′ for each i ∈ N . Assigning every agent to a∅ is Nash
stable if and only if 1 ∈
/ Si′ for each i ∈ N . Now we assume 1 ≤ k ≤ n − 1 and set
U1 = {i ∈ N | k ∈ Si′ , k + 1 ∈
/ Si′ }, U2 = {i ∈ N | k ∈
/ Si′ , k + 1 ∈ Si′ }, and
U3 = {i ∈ N | k ∈ Si′ , k + 1 ∈ Si′ }. If |U1 | + |U3 | < k, there does not exist an
individually rational assignment π with #(π) = k. If U2 6= ∅, no Nash stable assignment
π with #(π) = k can exist, since each agent from U2 would want to switch. If |U3 | > k,
no Nash stable assignment π with #(π) = k can exist, since at least one agent in U3 would
not be assigned to a and thus would be unhappy. Finally, if |U1 | + |U3 | ≥ k, |U3 | ≤ k,
U2 = ∅, we can construct a Nash stable assignment π by assigning all agents from U3 and
k − |U3 | agents from U1 to a. Since we have π(i) = a∅ for all i with k 6∈ Si′ and π(i) 6= a∅
for all i with k + 1 ∈ Si′ , no agent is unhappy.


5. C ONCLUSIONS

AND

F UTURE W ORK

We have defined a new model for the selection of a number of group activities, discussed
its connections with hedonic games, defined several stability notions, and, for two of them,
we have obtained several complexity results. A number of our results are positive: finding
desirable assignments proves to be tractable for several restrictions of the problem that
are meaningful in practice. Interesting directions for future work include exploring the
complexity of computing other solution concepts for a-GASP and extending our results to
the more general setting of GASP.
Acknowledgments This research was supported by National Research Foundation (Singapore) under Research Fellowship NRF2009-08, by the project ComSoc (ANR-09-BLAN0305-01), and by the Austrian Science Fund (P23724-G11 and P23829-N13). This project
was initiated during the Dagstuhl seminar 12101 “Computation and Incentives in Social

GROUP ACTIVITY SELECTION PROBLEM

13

Choice”, and the authors are very grateful to Dagstuhl for providing a great research environment and inspiration for this work. We thank Craig Boutilier and Michel Le Breton
for helpful comments. Part of this work was done when the second author was visiting
Université Paris-Dauphine.



While plausible reasoning has been applied to a vari­

This article deals with plausible reasoning

about spatial information. On the other hand, it has

ety of domains, it has rarely been applied to reasoning
been applied to reasoning about

from incomplete knowledge about large-scale

tial information.

consisting of a set of pointwise observations,

fluents1 do not change and therefore that their value

belief functions to represent the influence of

persist from one time point to the subsequent one, un­

the knowledge at a given point to another

less the contrary is known (from an observation, for

point; the quantitative strength of this in­

instance) or inferred; this implies some minimization

fluence decreases when the distance between

of change. Now, the latter persistence paradigm can

These influences are

be transposed from temporal to spatial reasoning. In

aggregated using a variant of Dempster's rule

the very same line of reasoning, when reasoning about

of combination taking into account the rela­

properties in space, it is (often) intuitively satisfactory

tive dependence between observations.

to assume that, knowing from an observation that a
given property r.p holds at a given point

Introduction

as well at points "close enough" to

This article aims at handling knowledge about large­
scale spatial properties (e.g.

soil type, weather), in

contexts where this knowledge is only partial; i.e. some
piece of information is known only at some given lo­

cations of space. We have investigated some means to
perform plausible reasoning on this kind of informa­
tion at any point in the considered space.
Several studies can be related to the question of
usually consider the question of representing incom­
plete knowledge about the location of spatial ob­
jects (using relational theories, more or less related
to the seminal work of [Randell

et al., 1992], or us­
2000]), or about vague re­
1996], rather than about static

ing fuzzy locations [Bloch,
gions [Cohn and Gotts,

properties and their distribution over a given space.

et al., 2000]

apply revision strategies to in­

consistency removing in geographical information sys­
tems.

A completely different line of work, in the

robotics literature, deals with map building using oc­
cupancy grids (see e.g.

[Iyengar and Elfes,

will be briefly discussed in Section

5.2.

x,

then it holds

x.

What we precisely mean by "close enough" depends
on the nature of the region as well as on the property
r.p involved. Moreover, it is clear that the belief that
r.p "persists" from point

x

to point y is gradually de­

creasing: the closer y to

x,

the more likely r.p observed

at

x

is still true at y. This graduality can be modelled

by order relations or by quantitative measures such as
probability. However, as we explain in Section 3, pure

imprecise knowledge in spatial databases, but they

[Wiirbel

Plausible reasoning about systems

that evolve over time usually consists in assuming that

is extrapolated to neighbour points. We use

both points increases.

temporal information,

which gives some hints about how to do it for spa­

spatial properties. The available information,

1

France

1991]);

it

probabilistic reasoning is not well-suited to this kind of

reasoning, unless very specific assumptions are made.
We therefore model persistence with the help of the

belief function theory,

also known as the Dempster­

Shafer theory. Belief functions (and their duals, plau­
sibility functions) generalize probability measures and
enable a clear distinction between randomness and ig­
norance that probability measures fail to do.
After giving some background on belief functions, we
show how to infer plausible conclusions, weighted by
belief degrees, from spatial observations.

Then, we

relate computational experiments, evoke information­
theoretic and decision-theoretic issues, and conclude.
1A

fluent is

a

proposition

which

evolves over time.

LANG & MULLER

286

Background on belief functions

2

UAI2001

well-suited to the combination of information from dif­
ferent sources. The

The

Dempster�Shafer

[Dempster,

1967]

theory

[Shafer,

1976]

of

evidence

is a generalization of

Dempster combination m1 ffi m2 of

two (normalized) mass functions
defined by

m1

probability theory enabling an explicit distinction
between randomness and ignorance.
Let

S

mt

ffi m2(A) =

be a finite set of possible states of the world

(taken to be the set for possible values for a given vari­
able, for the sake of simplicity),

one of which corre­

L
X,Y�S,XnY=A

and

m2

on S is

m1(X)m2(Y)
R(m1, m2)

where

sponds to the real world. A (normalized)

mass assign­
m(0) = 0
and LACS m(A) = 1. The condition that m(0) = 0 is
sometimes omitted (see [Smets and Kennes, 1994]): if
m(0) > 0 then we say that m is an unnormalized mass
assignment. The int erest of having a mass assignment
ment

is a mapping

m: 25

-t [0,

1]

such that

unnormalized is the ability to keep track of a degree
of conflict.
The subsets of S with a nonempty mass are called the

focal elements of m. m

simple support function iff
it there is a nonempty subset A of S and a a E [0, 1]
such that m(A) =a and m (S) = 1-a (by convention,
when specifying

is a

ssignmen t we omit subsets

a ma.ss a

with an empty mass).
A mass assignment

Plm

Plm(B)

from 25 to [0,

=

Belrn (B)

m

induces two set functions

Belm
1]: the belief function Belm
and the plausibility function Plm are defined respec­
tively by: '</B � S, Belm(B) = L ACB m (A) and
and

LAnB;t.0 m(A).

When

m is

normalized,

represents the probability of existence of at

least one true piece of evidence for A, while

Plm(B)

represents the probability of existence of at least one
true piece of evidence which does not contradict A.
When all focal elements are singletons,

m

can be

viewed as a probability distribution on S; in this case

X,Y<::;S,XnY=0

Importantly, this operation is associative, which en­

m1 ffi m2 ffi . .. ffi
of mass assignments.

ables its extension to the combination

mn of an

arbi t r ary number n

When unnormalization is allowed, we define the t.m ­

normalized Dempster combination
or not) mass assignments

m1

and

of two (normalized

m2

on

S

by

X,Y<;:S,XnY=A

The resulting

m1 ffiu m2 (0)
m1 and m2.

measures the degree of

conflict between

Lastly, in some cases it is needed to transform a mass
assignment into a probability distribution. This is the
case for instance when performing decision-theoretic
tasks.
place

Importantly, this transformation should take

after combination has been performed

and not

before, as argued in [Smets and Kennes, 1994] who in­
troduce the

pignistic transform T(m)

of a normalized

m, being the probability distribution
by: Vs E S, T(m)(s) :::: L A<;:S,•EA
���)

mass assignment
on S defined

·

Alternatives to the pignistic transform for decision

Belm (A) = Plm(A) = LsEA m(s), hence, Belm and
Plm coincide and are identical to the probability mea­

making using belief functions are given in [Strat, 1994].

sure induced by

3

m.

Therefore Dempster-Shafer theory

Extrapolation from observations

generalizes probability theory on finite universes.
The Dempster-Shafer theory of evidence enables an
explicit distinction between randomness and ignorance

that probability theory cannot2. Another crucial ad­
vantage of the theory of belief functions is that it is
2This is clear from the following two mass functions:

mi{head,tails} = 1; m2({head}) = m2({tails}) = %·
m2 represents a true random phenomenon such as toss­

ing a regular coin, while m, would correspond to a case
where it is not reasonable to define prior probabilities on
imagine for instance that you were just

{head, tails} -

given a parrot with the only knowledge that the two words
knows are ''head" and "tails": there is absolutely no
reason to postulate that it says "heads" and "tails" ran­
domly with a probability
(nor with any other probabil­

it

i ty ) ; it may
"head".

%

well be the case, for instance, that it always say
This state of complete ignorance about the out­

come of the event is well represented by the neutral mass

3.1

Observations

From now on we consider a space E, i.e., a set of
"spatial points" (which could be seen as either Eu­

clidean points or atomic regions). E is equipped with
a distance3

d.

We are interested in reasoning on the evolution "in
space" of some properties. For the sake of simplicity,
the property of interest merely consists of the value of
function
1.
3Recall that a distance is a mapping
E2 -t JR+
such as (i)
= 0 if
and only if
(ii)
and (iii)
+
z)::;
z). However we do
not really require the triangular inequality (iii); hence our
formal framework only requires d to be a pseudo-distance
but these technical details will not be discussed further.

m(S) =

d(y, x)

d(x, y)
d(x, y)

d(y,

d:
x = y;
d(x,

d(x, y) =

UAI 2001

LANG & MULLER

a given variable, whose domain is a finite set S. S is

furthermore assumed to be purely qualitative, i.e., S is

not a discretized set of numerical values. S may be for
instance a set of possible soil types, or a set of weather
types. The simplest case is when S may is binary, i.e.,

the property of interest is a propositional variable the

truth value of which we are interested in -for instance
S=

{rain,-,rain}.

An

observation function 0

is

a

mapping

from

Dom(O) � E to the set of nonempty subsets of S. 0

intuitively consists of a set of pointwise observations
(x, O(x)) where x E E and O(x) is a nonempty subset

of S; such a pointwise observation means that it has
been observed that the state of the world at point

longs to

x

be­

O(x) . 0 is said to be complete at x ifO(x) is a

singleton and

trivial at x ifO(x) =

S. The

range R(O)

of 0 is the set of points where a nontrivial observation
has been performed, i.e.,
3.2

R(O)

=

{x!O(x) f. S}.

degree which is all the higher

y is close to x. In

O(y) has a maximal (and absolute) impact on

while,

x

when y gets too far from x, this impact becomes null.

By default (and like to [Dean and Kanazawa, 1989] for

temporal persistence ) we will use exponential decay

functions

f(obs, a )

= exp(-

>.(;bs))

where

is a

J..(obs)

real strictly positive number expressing the "persis­
tence power" of the observation

obs

(such a function is

called an exponential decay function ) . This deserves
further comments.

We first consider the case of complete observations,

i.e.,

obs

is a singleton

{v}. J..({v}),

written

J..(v)

with­

out any risk of misunderstanding, characterize the per­

sistence degree of the value

J..( v ) ,

the lower

v:

stronger the spatial persistence of the property V

The two limit cases for

The question is now how to extrapolate from an ob­
servation function 0.

as

particular, if x = y (thus d(x, y) = 0) then O(x) =

•

Spatial persistence

287

J..(v)

is

As explained in the introduc­

=

exp (- >.

0;

(v))

J..( v)

are:

the

=

v.

by passage to the limit we write

= 0 and therefore the property V

non-persistent:

::::: v

as soon as d(x, y) > 0, the fact

that V = v holds at point y does not support

tion, the spatial persistence principle stipulates that

the belief that V

=

v

should hold at

x

too. As

as long as nothing contradicts it, a property observed

an example, consider the property "the 5th dec­

with a quantity of belief decreasing with the distance

this property is non-persistent (provided that the

at a given point is believed to hold at points nearby,

imal of the temperature at x is even".

to the observation. This principle is now formally en­
coded in the framework of belief functions.
Let x be a given point of E, called the

focus point.

What we are interested in is to infer some new (plau­
sible) beliefs about what holds at x. For this we con­

sider a set of mass assignments

{my y:z: , y

E

R(O)}

where each myYx is the simple support function de­
fined by

{ my<-+x(O(y))
myyx(S)

where

f IS

a mapping from

X

JR+ to [0, 1] s.t.

1. f is non-increasing in its second argument,
a� f3 implies f(X,a):::; f(obs,{3);
2. f(obs, a )
3.

f

f(obs, a )

=

1 if and only if

a=

i.e.,

decay function.

modelling decreasing beliefs over

used in [Dean and Kanazawa, 1989].

have first been

The intuitive reading of the mass assignment

= +oo

is

>.tv))

=

:

by passage to the limit we write

1 and

therefore the property V

strongly persistent:

= v

as soon as it is true some­

where in space, it is true everywhere in E.

How J..( v ) is determined depends on the variable V and
the value

v

involved. It may be determined by expe­

relevant persistence

of

V = v from y to x (which may sometimes be under­

stood as the probability of

continuous persistence from

x to y - this will be discussed later), according to
the formula above, is exp(-

d l (V = v)

t(�)) ) .

In particular, if

is the "half persistence" of V =

tence is equal to

Decay functions for

time

J..( v)

exp(-

v,

i.e., the

dfstance for which the probability of "relevant" persis­

0;4

-+a-Hoo 0

will be called a

•

to hold, the probability of the

f(O(y), d(x, y))

(25 \ 0)

granularity of space is coarse enough);

rience. Considering a point x where V = v is known

= f(O(y), d(x, y))
= 1-

Clearly,

�, then

we have J..( v) =

t·:f).

Now, when V is not a singleton, the persistence decay

function of

V

will be taken to be the persistence func­

tion of the most weakly persistent element of

v,

The critical point is the reference to

persis­

J..(V) = minvEV J..(v).

my<-+"

is the following: the fact that O(y) is observed at y

supports the belief that O(y) holds at x as well, to a
4 as noticed by a referee, there are intuitive cases where
this condition could be weakened.

relevant

tence rather than with simple persistence.

i.e.,

Assume

that we try to build an approximately valid weather
map and that the property rain

=

true observed at

point x. Clearly, this property being known to have a

288

LANG & MULLER

UAI2001

�

significant spatial persistence, this piece of knowledge

explanation of this value

is a strong evidence to believe that it is also raining at

pieces of evidence that it is raining at y and not rain­

a very close pointy, such as, say,

ing at

d(:r, y) = 1 k m.

This

is not at all an evidence to believe that is raining at

x and are in conflict.

y and the
z both can be considered as informa­
the first one telling that it is raining at x

absence of rain at

may well be the case that it is raining at :r; but in this

and the second one that it is not, the reliability of the

z

d(x, z) = 8000km,

hence, the impact of

have a strong impact on

An analogy with information merging from multiple

x on
This does not mean
that the probability of raining at z is (almost) zero. It

z

where

z

is the following: the two

regarding rain is (almost ) zero.

z is ( almost certainly )
unrelated to the fact that it is raining at x, because, for

case, the fact that it is raining at

sources is worthwhile: the rain observed at
tion sources,

sources being function of the distance between them
and the focus point

In the absence of a reason to

x.

instance, the air masses and the pressure at these two

believe more one source than the other one, the prob­

points

ability that it is raining at

pact

do with the prior probability of p ersi st enc e: had this

( at the same time) are independent. The im­
/(rain, d(x, z)) =true of x on z regarding rain

can be interpreted as the probability that, knowing

prior been

that it is raining at

would still have been

x,

it is also raining at

z and

two points are in the same "raining region".

these

Hence

the terminology "relevant persistence", which may also
be interpreted as "continuous persistence" (i.e., persis­
tence along a continuous path) if we assume moreover
that a raining region is self-connected5.

0.25,

x is �.

This has nothing to

the probability that it is raining at

x

�·

w as the focus point. w being very far
y and z, their impact is almost zero and the prob­
ability of rain at w is (extremely close to) the prior

Consider now
from

probability of rain, i.e.,
and comes from

�·

ignorance

This value of

� is a

prior

rather than with conflict.

This is where the difference between pure probability

Therefore, probability cannot distinguish from what

and be li e f

happens at

ability

tween

functions (recall that they generalize prob­
theory ) is the most significant: in a pure prob­

abilistic framework, this impact degree, or probability

x and

at

w,

i.e., it cannot distinguish be­

confiictual information and lack of information.

Belief functions, on the other hand, would do this dis­

of relevant persistence, cannot be distinguished from

tinction: while the belief of raining at

a usual probability degree. If we like to express prob­

been close to

abilities of persistence in a pure probabilistic frame­

the belief of not raining at

[0, 1] s.t.
Prob(H olds(x, rain)IH olds(y, r ain ))= 9rain(d(:c, y)).
This mapping g is different from f. More precisely,

to

work, we need a mapping

9rain

:

E2

--+

g 2: f holds, and g and f are closer and closer to f

d(x, y) is

as

d(x,y) becomes
large ( with respect to the persistence degree of rain),
the impact g tends to 0 while g tends to the prior prob­
ability of raining at x. From this we draw the follow­
ing conclusion: a pure probabilistic modelling of spatial
persistence needs not only some knowledge about how
properties persist over space but also a prior probabil­
ity that the property holds at each point of space; the
latter, which may be hard to obtain, is not needed with
the belief function modelling of persistence.

0.

�,

the belief of raining at
w,

x would have
w, as well as

would have been dose

Hence the second conclusion:

a pure probabilis­
tic modelling of spatial persistence does not allow for a
distinction between confiictual information and lack of
information, while the belief function modelling does.

smaller and smaller; when

3.3

Combination

Once each observation is translated into a simple sup­
port function

my<-+x,

the bel i ef about the value of the

variable V is computed by combining all mass assign­
ments my<-+x for

y

E

R(O).

A first way of combining them consists in applying
mere Dempster combination, i.e.,

The second drawback of a pure probabilistic modelling
of spatial persistence is the lack of distinguishability

between ignorance and conflict. Suppose ( without loss

of generality ) that the
persistence is

where

x is

both, and

�·

prior probability of

Consider the four points

very close to

w

(uniform )
x and y

is very far from

x.

z.

Suppose that it has

y

and that it is

The probability, as well

lief, that it is raining at

:r,

y, z

and half way between

been observed that it is raining at
not raining at

w, x,

as

are very close to

the be­

�.

The

5and, in a stronger way, by "linearly continuous per­
sistence" if we assume that a raining region is not only
self-connected but also convex.

If one wishes to keep explicitly track of the measure
of conflict then one may use unnormalized Dempster
combination instead. However, a naive use of Demp­
ster combination has a severe drawback. Consider the

== {x,y,z,w} where d(x,y) = 1;
d(x, w) = d(y, w) = 10; d(z, w ) = 10; d(x, z) =
d(y, z) = 19 and the observation function 0 concern­
ing rain: O(x) = O(y) = true; O(z) = false. The

following space E

focus point is w.We take an exponential decay func­
tion with a uniform >.

mx<-tw, my'-+w

= 30.

The

mass

assignments

and mx<-+w are the following:

UA12001

LANG & MULLER

X � E and for any xE E \X,
J.l(xiX) = min( 1, J1. (X U {x})- J-t.(X)) where J.l.( 0) = 0 ,
J.l(X) = 1 if lXI = 1 and for any X of cardinality
n � 2,
.
-�
2
J.l(X) = 2- n L{y,z}�X,y;tz e ). where ). IS a pos-

X

•---- • .lP..
w
w
z
\·------- - ---------+-------------.:')
10
?
y

itive real number.

mx<-+w ({true})
mx<-+w ( {true, false})

�

= exp(- ) �

m<-+w

=

�

0.5

= 1- exp(- )

my<-tw({true})
mx<-+w ({true, false})
mz<-+w({false})
mx<-+w ({true, false})
The combination

mx<-+w

�
�
�
�
Ef)

�

In particular we have J.l.(xl0) = 1 and Ji.(xi{Y}) = 1d(.r,y)
.
e- -----r- . Takmg ). = 10, on the exampie of figure 1 we
have J.l.({yl{x}}) � 0.095 and J-t. ( z l {x} ) � 0.85 .

0.5

Now,

0.5
0.5
0.5
0.5

R( 0)

�

�

1. sort the points in

x,

and at

y

x

and y

2.

by increasing order of

i.e., let

mx<-tw

=

1 to n do
Yi I{Yl , Yi-d ) ;
J.l(
- J.li f_1et m� · m�(o(ill = 1- ( 1- f(O(i), d(x, y;))�·
,
mHS)
= ( 1- f( O(i), d(x , y;))�'
for

i

f-

•

·I

are clearly not inde­

pendent, and thus the mass assignments

R(O)

Lo(x) be the ordered
(Yt,-··,Yn)} where R(O)
{Yt,···,Yn} and
d(x, yl) ::; ... ::; d(x, Yn);

being close to each other, the pieces of information
z

the focus point and

list

0.6
0.2
0. 2

Clearly, this is not what we expect, because
that it is raining at

x be

the points where a nontrivial observation has

been performed.

my'-+w Ef) mz<-t w

�

mass assignments

n

with respect to J1. is done by

the following algorithm. Let

the distance to

m<-+w ( {true})
m<-+w({false})
mx<-tw ({true, false})

and

. . .

should not be combined as if they were inde­

pendent. On the other hand, on the following figures,

mx<-tw, mx<-tw and mx'-+w are identical to those
above but x is no longer close to y, the above result
m<-t w = mx<-tw $my<-tw EBmz<-tw is intuitively correct.
where

To remedy this problem, we introduce a

factor

the aggregation of the

my'-+x, y E R( 0) \ {x},

yields

my<-tw

289

discounting

when combining mass assignments.

The dis­

count grows with the dependence between the sources,
i.e., with the proximity between the points where ob­
servations have been made.

=

ffiio::l ..n mi

This way of combining by first reranking and then us­
ing interaction factors is reminiscent of the aggrega­
tion operator known in multi-criteria decision theory
called

Choquet integral.

Formal analogies will not be

discussed further here.
In practice, it is often the case that each pointwise

We use here a method inspired from multi-criteria
decision making (where positive or negative interac­
tions between criteria have to be taken into account
when aggregating scores associated to the different cri­

Assuming that E is fin ite, for X � E and
xE E \X, we introduce a conditional importance de­
gree J-t.(xiX) E [0, 1] expressing the importance of the
knowledge gathered at point x once the points in X
have been taken into account. The quantity 1-J-t.(xiX)
is therefore a discount due to the dependence with the
teria) .

information at x and the information already gath­
ered.Intuitively, it is desirable that "the further

x from

X", the higher J.l(xiX). When xis sufficiently far from
X, there is no discount and J.l.(xiX) is taken to be 1.
Several possible choices are possible for

3. compute mx

J.l·

In the im­

plementation we chose the following function6: for any

6lts intuitive justification, which is based on

an

anal-

observation is precise, i.e.,
y; E

R(O).

O (yi )

=

{v;}

for each

In this case, the above combination op­

eration can be written in a much simpler way: the
mass of a value

{v}

can be expressed as follows, given

Vm;, ::J!j, Vj E V/ a:; =
m;({vj}) f. 0; Vi E [l..p],P; = {k E (l..n]/mk({v;}) f.
0}; Vi E [l..p],P; = {k E [l..n]/mk({v;}) = 0}. In
a few preliminary notations :

that case, it is easy to show that combination without
discount yields:

m(v;)

=

( 1- (0kEP, (1- a:�c))) * (0kEP, ( 1- a:�c )) .

Whereas combination with discount yields:

m(v;) = ( 1- (0kEP; ( 1- o:�c )�k )) * (0xEP, ( 1- a�c)�k ).
ogy with fuzzy measures and interaction indexes in multi­
criteria decision making, would be rather long and compli­
cated to explain without introducing further several defi­
nitions. We omit it because this is not the main scope of
the paper.

LANG & MULLER

290

Experiments

4

UAI2001

reveals no information, and a purple one would reveal
conflicting values.

Since color is not possible in this

We recall that what we focus on is the plausible ex­

article we will show figures in shades of gray.

trapolation of information: given a set of observations

observation point will be in black or white, and the

Each

on E, what is the likelihood of the truth of a formula

shade of gray for each interpolation will be a difference

on a point outside of the set of observations ? For the

between the combined mass of the two values (normal­

experiments, we used a binary value domain, namely

S

=

{white, black}.

likely a point is to have a value close to a black obser­

We compute the overall mass assignment for each lo­
cation

x

in the space E, by combining the mass as­

signment induced by every point y in the observation
set

R(O).

We have two courses of action from here.

Either we make a plain Dempster combination of all
the simple support functions
ther we make

a

mx

=

EByER(O) my<-+x,

ei­

correction based on a Choquet integral

applied to the exponents (as explained at the end of
Section

3.3),

ized). In order to see the observations points, the more

to lower the influence of close concurring

observations (for which the independance hypothesis
cannot hold). After this combination is performed, we
can decide whether to normalize the results (by as­
signing the mass of the null set to the other possible
sets) or to keep a non-zero mass for contradictory in­
formation. Keeping un-normalized resulting mass as­
signments helps visualizing the conflictual regions.

vation, the more white it is, and conversely. A middle
gray will indicate similar levels of both values.

For

instance, figure 4 shows the result for three close con­
curring "black" observations next to a single "white"
observation. In one case the information is corrected to
take into account the fact that close points are related
and do not express independent sources. In the other
one we have made a plain Dempster combination. We
can see that the three black points combined have an
influence similar to a single point.

In the limit case

where the three points are exactly identical we would
have exactly the same result as with only one point
(illustrating this would not be very spectacular). Fig­
ure 2 nonetheless shows different levels of interpolation
varying with the distance between concurring observa­
tions, with or without the Choquet-like correction.

We chose the following experimental framework: we
consider a space of pixels E, ordered along two axes,
and for which a distance relation is the Euclidean dis­
tance. The distance unit is then one and the factors

>..(white), >..(black)

are uniformly fixed at

took the same value of

3 ()

3,

and we

used for the coefficient of

interaction between observations

7.

The best way to

Figure

2:

Corrected

normalized

(left)

and

non­

corrected normalized (right) interpolation, with vary­
ing distances between observations with identical val­
ues

Figure

1:

Corrected(left) and non-corrected (right) in­

terpolation, with conflicting values and three concur­

5

decision-theoretic issues

ring, close observations
illustrate our results would be to assign a color to each
pixel, assigning a red intensity to one value, a blue in­
tensity to the other (and eventually a green intensity
to the belief in the empty set, if one want to keep track
of the level of contradiction). This way a black pixel

7This settings proved empirically to give visual results
that illustrates well the principled we use here. Obviously,
these factors should be tailored for specific spatial proper­
ties with respect to the scale of the actual observed space.
Moreover, other distances could be considered where the
interaction and persistence of relevance would take into
account other factors.

Information·theoretic and

Plausible information can be very useful in the context
of decision-making, when decisions have to be made on
the basis of uncertain information.
5.1

Information intensity maps

Our framework can be used to measure the variations
of the quantity of information over space.

In order

to do so, we may compute a probability distribution
on S at each point of E, using for instance the pig­

nistic transform, and the information level at each

point can then be computed using usual information-

UAI2001

LANG & MULLER

theoretic measures such as entropy8.
build a map where each point

x

Hence we can

as a set of observations on a larger space, what lo­

is associated to the

cations are the most informative when one want to

entropy of its final probability distribution. Entropy
increases as information decreases; in other words, the
quantity 1of

p.

H (p)

291

measure the quantity of information

Minimal entropy is obtained at points at which

at a complete observation has been made.

Maximal

entropy is obtained at points associated with a uni­
form probability distribution (if any). Note that this
uniform probability distribution may come either from
conflictual observations or from a lack of information:
as explained in Section 3.2, once the combined mass
assignment has been transformed into a probability
distribution, there is no longer a way to distinguish

switch to a finer-grained representation?
An information intensity map already gives some hints
about where it should be interesting points to make
new measures: measures seem more useful in regions
in which the information quantity is low.

However,

picking the point of E with the lowest amount of in­
formation is not sufficient in general.

Especially, it

is relevant to make a difference between points where
nothing is known because the observations are too far,
and the ones where there is conflict between observa­
tions at points nearby.

conflict from lack of knowledge.

If one is interested in choosing

This is true independently of the number of values

classical heuristics is the maximum expected entropy
loss9. This, however, works well if (1) only one more

we consider for a spatial fluent, but to illustrate the
process, we show on figure 3 the level of information
using as before the 2-valued set S

=

{white, black}.

In this case, the quantity of information 1 -

H(p)

- H Information is minimal
when p(white) = p(black) = � and maximal when
p(white) = 1,p(black) = 0 or p(white) = O,p(black) =
1. The shade of gray is proportional to IP(white)-� 1grows with IP( white)

This way, a black point corresponds to a low amount
of information and a white point to a high one. Again
we show the results both with and without correction.

one

measurement, a

measurement has to be made; (2) the measurements
have uniform costs; (3) the utility of a gain of infor­
mation does not depend on the value observed nor
on the location of the measurement.

The more gen­

eral problem of determining an optimal measurement
policy over a given number of steps can be cast in
' the framework of Partially Observable Markov De­
cision Processes.

This requires the specification not

only of measurement costs but also a utility function
which grows with the global amount of information
(and which possibly takes account of the relative im­
portance of some values or of some regions). This point
is left for further research, and should be positioned to
the recent work of [D. Kortenkamp and Murphy, 1997]
extending the idea of occupancy grids with the use of
MDP.
Once a series of measurements has been done, one may
decide either to stop the measurements, or, if the quan­
tity information is considered high enough (relatively
to the expected cost of new measurements), we can
then easily compute a "plausible map" from the re­

Figure

3:

Corrected

normalized

(left)

and

non­

corrected normalized (right) level of information

sult of the combination step, by assigning each point
of the space a value with the highest probability, in
order to represent the most likely distribution of the
spatial property considered. Figure

4

shows the result

on a sample observation set, with two different levels
5.2

Decision-theoretic

map

construction

We are now interested in the following problem: given
a set of observations 0, where (and what) is it worth­
while to measure next? This problem, already consid­
ered in the field of robotics (where it has received a
pure probabilistic treatment), is relevant not only for
exploring geographical data but also for the question of
granularity dependent representations. Indeed, given a
coarse-grain representation of spatial information seen

8We recall that the entropy of a probability distribution
L:.ES -p(s) lnp( s )

p over a finite setS is defined as H(p)

=

of gray for each value. One can again observe that the
correction decreases the likeliness of a value near con­
curring measures.

In practise, it would probably be

better to decide of a threshold under which the belief
in a value is irrelevant before pignistic transformation.
If we know indeed that the belief in value 1 is 0.05,
and belief in value 2 is 0.04, (thus the belief in the
set {1,2} is 0.91), we don't want to assume it is more
likely that value 1 holds and thus we would like the
map to remain undetermined at this point.

9This heuristics is widely used in model-based diagnosis
when choosing the next test to perform.

LANG & MULLER

29 2

UAI 2001




A semantics is given to possibilistic logic, a
logic that handles weighted classical logic
formulae, and where weights are interpreted as
lower bounds on degrees of certainty or
possibility, in the sense of Zadeh's possibility
theory. The proposed semantics is based on fuzzy
sets of interpretations. It is tolerant to partial
inconsistency. Satisfiability is extended from
interpretations to fuzzy sets of interpretations,
each fuzzy set representing a possibility
distribution describing what is known about the
state of the world. A possibilistic knowledge base
is then viewed as a set of possibility distributions
that satisfy it. The refutation method of automated
deduction in possibilistic logic, based on
previously introduced generalized resolution
principle is proved to be sound and complete with
respect to the proposed semantics, including the
case of partial inconsistency.
1

INTRODUCTION

Possibilistic logic is a logic of uncertainty tailored for
reasoning under incomplete information. At the syntactic
level, it handles formulas of propositional or first-order­
logic to which lower bounds of degrees of necessity (i.e.
certainty) or possibility are attached. The degrees of
possibility follows the rules of possibility theory (Zadeh,
1978 ; Dubois and Prade, 1988) and the degrees of
necessity are defined from degrees of possibility through a
classical duality relationship. A possibilistic knowledge
base can thus be viewed as a stratified (or layered) classical
knowledge base, where some formulae are more certain, or
more possible than others. Resolution rules have been
derived in accordance with the axioms of possibility theory
(Dubois and Prade, 1987, 1990a) and a refutation technique
has been implemented for necessity-valued formulas
(Dubois,Prade and Lang, 1987) further on extended to both
possibility and necessity-valued formulas (Lang, 1991).
The main ideas behind possibilistic logic are: i) the degree
attached to a proof path in a possibilistic knowledge-base
is the least degree attached to a formula in this proof path,
and the degree attached to a consequence of a possibilistic

knowledge base is the greatest degree attached to proof­
paths yielding this consequence ; ii) when two
antagonistic propositions p and --.p can be derived, the one
with the highest degree inhibits the other one. The latter
point indicates that possibilistic logic can handle partial
inconsistencies. Moreover possibilistic logic proposes a
way of handling uncertainty based on the idea of ordering
rather than counting, contrary to probabilistic logic.
This paper presents a semantics for possibilistic logic in a
fairly general situation, i.e. possibility or necessity-valued
clauses, and the presence of partial inconsistency, are
allowed. It extends a previous semantics dedicated to
necessity-valued propositional clauses only (Dubois et a!.,
1989). This semantics is based on an extension of the
satisfiability notion from sets of interpretations to fuzzy
sets of interpretations. The idea of a fuzzy set of
interpretations is that some interpretations are preferred to
others and enable non-trivial inferences that could not be
made if interpretations were equally considered. In this
sense, possibilistic logic belongs to the family of non­
monotonic logics based on preferential models, whose
general setting has been devised by Shoham (1988); see
Dubois and Prade (1991) on this point. Possibility
distributions are viewed here as a convenient way of
encoding a preference relation by attaching a weight to
each interpretation of a set of formulas. Possibilistic logic
completely contrasts with Ruspini (1991)'s so-called
"fuzzy logic" where the semantics relies on the idea of
similarity rather than ordering. Ruspini's logic is one of
graded indiscernibility between worlds (in the spirit of
Pawlak (1982)'s rough sets) while possibilistic logic is a
logic of preference between interpretations.
Possibilistic logic is closely related to Shackle (1961)'s
degrees of potential surprize, and Spohn (1988)'s ordinal
conditional functions. See Dubois and Prade (1990b) on
this latter point. Possibility measures can also be viewed
as consonant belief functions (Shafer, 1976). However,
possibilistic logic is not a truth-functional many-valued
logic and is not a logic of vagueness (as is fuzzy logic)
because it primarily pertains to non-fuzzy propositions the
truth of which is uncertain due to incomplete information.
In the next section, a language and a semantics are
presented for possibilistic logic, a logic of necessity and

A Logic of Graded Possibility and Certainty Coping with Partial Inconsistency

possibility-valued (classical) formulas. A version of the
semantics, in terms of a possibility distribution on a set
of interpretations for the case of consistent knowledge
bases is first presented, where consistency refers to the
proper assignment of the possibility and necessity degrees
(with respect to the axioms of possibility and necessity
measures). A generalized semantics, where an extra­
element representing the absurd interpretation is added to
the referential of the possibility distribution, is then
introduced in order to allow for inconsistencies. Section 3
describes an automated deduction procedure based on
extended resolution and refutation. Completeness of the
deduction procedure holds, with respect to the proposed
semantics.
2
2.1

POSSIBILISTIC LOGIC :
LANGUAGE AND SEMANTICS
LANGUAGE

A possibi/istic formula is either a pair (q> (N a)) where q>
is a classical first-order formula and aE (0,1], (a should
be StriCtly positive) or a pair (q> (fl�)) where�E [0,1].
(<p (N a)) expresses that <p is certain at least to the degree
a, i.e. N(<p) � a , and (<p err �)) expresses that <p is
possible at least to the degree �.i.e. IT(cp) ��.where rr
and N are dual measures of possibility and necessity
modelling our incomplete state of knowledge (Zadeh,
1978 ; Dubois and Prade, 1988). The right part of a
possibilistic formula, i.e. (N a) or err�). is called the
valuation of the formula, and is denoted val(<p).
The basic axiom of a possibility measure IT is fl(<p v <p') =
max (IT(<p ),IT( cp')) (on a finite language ;£,- on which
formulas are defined). Informally, fl(<p) =0 means that <p
is impossible while IT(<p) = I means that <p is consistent
with current knowledge. Particularly fl(<p) =0 when <p is a
contradiction. The necessity measure N is defined as N(<p)=
1 - ITC�cp), and is such that N(<p 1\ <p') =min(N(<p),N(cp')).
N(<p) 1 means that <p is sure ; for instance N(<p) =1
when cp is a tautology. Since V <p, N(<p v �cp) =1, we
only have N(<p v cp') � max(N(<p),N(<p')); indeed, for <p' =
�cp, we may have N(cp) N(�<p) =0 (i.e. IT(cp) IT(�cp) =
1). It can be shown that N(<p) � IT(cp), generally. More
specifically, IT(cp) = 1 as soon as N(<p) > 1. This is due to
the axioms that force IT(cp v �cp) =1 =max(IT(<p),IT(�cp)).
When fl(<p) IT(�cp) =1, we capture a state of ignorance
about <p. Hence since we use lower bounds on possibility
or necessity measures, various cases of relative ignorance
can be captured ranging from the case where we know that
we do not know (IT(<p) rrc�cp) =1) to the case where we
do not know if we know errCcp) � 0, TI(-,<p) � 0). Let CJ,f
be the set of all possible valuations of possibilistic
formulas. Since N(<p) > 0 entails TI(cp) = 1, and the
valuations act as lower bounds, (<p (N a)) is stronger than
(<p err�)) for any a > 0,� � 0 ; this leads us to define the
following ordering among valuations :
(N a)� (N�) iff a �� ; err a)� err�) iff a�� ;
(IT a)� (N�) Va, V� > 0.
Hence the maximal and minimal elements of o/ are
respectively (N 1) (expressing that a formula is completely
=

=

=

=

=

certain) and en 0) (corresponding to the strongest form of
ignorance, since fl(<p) � 0 only). A possibilistic
knowledge base is then defined as a finite set (a
conjunction) of possibilistic formulae. ff"* will denote
the set of classical formulae obtained from a set of
possibilistic formulae fF, by ignoring the weights. A
possibilistic formula whose valuation is of the form (N a)
(resp. err a)) will be called a necessity-valued (resp.
possibility-valued) formula. Let LP 1 (resp. LP2) denote
the language consisting of only necessity-valued formulae
(resp. where possibility-valued formulae are also allowed).
2.2

SEMANTICS

UNDER

CONSISTENCY

Let ;£,- be a classical language associated with the set ff"*
of classical formulae obtained from a set fF of
possibilistic formulae, and let Q be the set of (classical)
interpretations for ;£,- . Let ;£,- ' be the set of closed
formulae of ;£,- .
Then we define a possibility distribution 1t as a mapping
from Q to [0,1] such that 3 ro E Q, n(ro ) = 1
(normalization). This possibility distribution represents
the description of an incomplete state of knowledge, such
that n(ro) = 0 means that ro is forbidden while n(ro') >
n(ro) means that ro' is an interpretation preferred to ro.
The normalization constraint expresses the natural
requirement that there should exist at least one fully
possible interpretation in Q with respect to a consistent
(possibly incomplete) state of knowledge. The possibility
measure IT. induced (in the sense of Zadeh (1978)) by the
possibility distribution 1t is the function from ;£,-' to [0,1]
defined by V cpE ;£,- ', IT(cp) =Sup(n(ro), ro F= <p} 1 where
ro F= <p means "ro is a model of cp". The dual necessity
measure N induced by 1t is defined by V <pE ;£,- ', N(cp) =
1 - Il(-,cp) =Inf (1 - n(ro), ro F= -,cp} 1. Then, it can be
seen that expressing constraints of the form N(<p) �a or
Il(cp) � � is equivalent to specify a set of possibility
distributions over Q which are compatible with the
corresponding possibilistic formulae. A possibility
distribution 1t on Q is said to satisfy the possibilistic
formula (<p (N a)), iff N(<p) �a, where N is the necessity
measure induced by n. We shall then use the notation 1t F=
(<p (N a)). In the same manner, we write 1t F= (<p err�)) iff
Il(cp) ��.where IT is the possibility measure induced by
l . .. n} be a set of possibilistic
n. Then, let fF =(<Pi , i
=

formulae <l>i =(<p i vi ) where <p iE ;£,-' and ViE o/; a
possibility distribution 1t is said to satisfy ff", i.e. 1t F= ff",
iff V i = 1, ... ,n, 1t satisfies <l>i . Then, a possibilistic
formula <l> is said to be a logical consequence of the set of
possibilistic formulae fF iff any possibility distribution
satisfying fF also satisfies <l>, i.e. V 1t, (7t F= ff) ==>
(1t F= <l>).
Example: let fF ((p (N 0.7)), (-,pv q (n 0.8))}.
=

1 Sup {) and Inf {) denote the least upper bound and
greatest lower bound respectively of the subset of real
numbers defined between {)

189

190

Lang, Dubois, and Itade

1t 1= ff

iff N(p) � 0.7 and fl(-,p v q) � 0.8
iffinf{1 - 1t(CO), co 1= -,p) � 0.7 and
Sup{1t(ro), co 1= -,p v q) � 0.8.
Let [p, q], [-,p, q], [p, -,q] and [-,p, -,q] be the 4 different
interpretations for the propositional language generated by
{p, q) (where [p, q] gives the value True to p and q, etc.).
Then, it comes down to
1t I= ff iff 1t ([-,p, ql):::; 0.3, 1t ([-,p, -,q]):::; 0.3,
1t ([p, ql) � 0.8, max (1t ([p, q]), 1t ([p, -,q]) ) = 1.
Indeed fl(-,p):::; 0.3 and fl(-,p v q) � 0.8
¢'> max(1t(-,p" q), 1t(-,p" -,q)):::; 0.3,
max(1t(p " q), 1t(-,p" q), 1t(-,p" -,q)) � 0.8,
max(1t(p" q), 1t(-,p" q), 1t(p"-,q), 1t(-,p "-,q)) =1
¢'> 1t(-,p 1\ q) :::; 0.3, 1t(-,p 1\ -,q) :::; 0.3,
1t(p 1\ q) � 0.8, max(1t(p" q), 1t(p" -,q)) = 1.
It is then obvious that ff 1= (q (Il 0.8)). Indeed, any
possibility distribution 1t satisfying ff is such that
1t ([p, ql) � 0.8, and thus verifies fl(q) = max(1t ([p, q]),
1t ([-,p, ql)) � 0.8 ; hence 1t satisfies (q (Il 0.8)).
•
It is worth noticing that in LP1 there is an equivalence
between the consistency of the classical set of formulae
ff* and the existence of a greatest normalized possibility
distribution 1t satisfying ff, as shown in (Dubois et al.,
1989). Indeed if 1t is normalized it can be easily checked
that 'v'<p, min(N(<p),N(-,<p)) = 0 where N is defined from 1t;
in other words it is impossible that there exists <p such
that both <p and -,<p have a strictly positive lower bound
for their necessity degrees (i.e. that both <p and -,<p appear
in the deductive closure of ff*).
Our semantics is similar to Nilsson's (1986) probabilistic
logic semantics. Indeed this author considers a set of
probability distributions on the set of interpretations n,
defining probability measures on the set of closed
formulas � ' , which are compatible with bounds
constraining the probability of formulae in the knowledge
base. The notions of logical consequences are similar in
both approaches.
2. 3

EXTENDING THE SEMANTICS T O
PARTIAL INCONSISTENCIES

Let us first take an example
let '()
{(-,p v r (N 0.6)), (...., q v ...., r (N 0.9)), (p (N 0.8)),
(q (N 0.3)). It can be checked that 1t 1= y iff
1t ([p, q, r]):::; 0.1;
1t ([p, q, ....,r]):::; 0. 4;
1t ([p, -,q, r]):::; 0.7 ;
1t ([p, -,q, -,r]):::; 0.4;
1t ([-,p, q, r]):::; 0.1;
1t ([-,p, q, -,r]):::; 0.2;
1t ([-,p, -,q, r]):::; 0.2;
1t ([-,p, -,q, -,r]):::; 0.2;
Sup{1t(ro), co E Q) = I.
This set of constraints being unsatisfiable (because of the
normalization constraint), there is no possibility
distribution over n satisfying '() , which comes down to
say that y is inconsistent. As a consequence, any
possibilistic formula is a logical consequence of y .
However, it would not be fully satisfactory to define a
logic which handles degrees of uncertainty without
allowing for degrees of (partial) inconsistency. Indeed, if
we consider the above example where we suppose that p, q

and r respectively express "the hostages will be freed" (p);
"Peter is going to be the victim of an affair" (q) ; "Peter
will be elected" (r) respectively. Then the formulas
contained in ff express that it is moderate! y certain that if
the hostages are freed then Peter will be elected, that it is
almost certain that if Peter is victim of an affair then he
will not be elected, that it is rather certain that the
hostages are going to be freed and that it is weakly certain
that Peter will be the victim of an affair. The
inconsistency comes from the beliefs of the experts who
gave the information stored in the knowledge base.
However, the expert who gave the last formula was only
weakly certain of what he said, so that the inconsistency
should be relativized.Since the first three formula of'() are
strictly more certain than the last one, we would like our
logic to behave as if the set of formulas were only
partially inconsistent, its inconsistency degree being the
valuation of the weakest formula involved in the
contradiction ; then, the deduction of a formula with a
valuation strictly greater than this inconsistency degree
should still be permitted ; since this deduction would
involve only a consistent part of the knowledge base made
here of the most certain pieces of information in the
example, we should still be able to deduce (r (N 0.6)) non­
trivially; this is done inSection 3. However a conclusion
deduced from a partially inconsistent knowledge base
should be regarded as more brittle than what is derived
from a consistent one.
We are now going to give a semantics which handles such
partial inconsistencies. The problem with the first
semantics is that according to the definition of possibility
and necessity measures we have (if .l denotes the
contradiction): fl(.l) = Sup(1t(ro), OJ 1= .l} =Sup 0 = 0
and N(.l) = Inf{l - 1t(CO), co I= -,.l) = 1 - Sup(1t(ro),
co E Q) = 0. Hence the solution requires that non-zero
values for fl(.l) and N(.l) be allowed.
The solution we propose consists in adding to the set of
interpretations Q an extra-element, noted OJ .l in which
any formula is "true", i.e. V <p E �',co .Li= <p which
corresponds to the idea of an "absurd interpretation"
discussed by Stalnaker (1968)2 Let Q.l = Q u {OJ.Ll· A
possibility distribution on n .l is a mapping ii from n .l
to [0,1] such that :1 CO E Q .l, ii(CO) = I (normalization
over n.L)· Then we define two functions from �'to [0,1]
,..
induced by 1t: fl(<p) = Sup{1t(CO), (!) E n.l, (!)I= <p);
N"(<p) = Inf{l - n(ro), co E Q .l• co FF <p). Note that N"(<p)
does not take ii(OJ_L) into account, while n(<p) does ;
A

A

2The idea of adding an extra-element to the
referential of a possibility distribution has been already used
for dealing with the case of an attribute which does not apply
to an item of a data base. However the extensions of the
possibility and necessity measures which are used for the
evaluations of queries in incomplete information databases
differ from the extensions defined here ; see chapter 6 of
Dubois and Prade (1988).

A Logic of Graded Possibility and Certainty Coping wifu Partial Inconsistency

particularly �(<p) = inf(l- it(ro), ro E Q, ro F= -,cp}, and
�(.l) = 1- sup(it(ro), ro E Q} ;:;: 0 ; note also that
ro Fj= <p is no longer equivalent to ro F= -,cp, since ro_1_ F=
<p and ro.l F= -,cp .

As it can be easily seen, we have
'd <p E ;t.', n(<p) = maxm(.l), I - �(-,<p)]
Note that n and � are not possibility and necessity
measures with respect to Q, but only with respect to Q.l·

We now give the inconsistency-tolerant semantics of
possibilistic logic. Each possibilistic formula (<p (Il a))
or (<p (N a)), is now considered as meaning n(<p) <::a
(respectively �(<p) <:: a), i.e. we take into account the
absurd interpretation in our understanding of expert
statement. For instance, (<p (IT a)) expresses that "it is
possible at least to the degree a that either <p is true or we
are in an absurd situation". This leads us to the following
definitions :
s a tisfaction : it � (<p (I1 a)) iff n (<p);:;: a ; it �
(<p (N a)) iff �(<p);:;: a, where nand � are the extended
possibility and necessity measures induced by it ; it �
fF iff it satisfies all formulae of fF ;
- logical consequence : fF � <l> iff '<lit, it� fF implies
it � <l>.
The inconsistency-tolerant semantics is more general than
the first one we introduced. In the case of a consistent
possibilistic knowledge base fF (i.e., there exists a
possibility distribution 1t over Q satisfying fF according
to the first semantics), then the two logical consequence
relations F= and � are equivalent. This is no longer true if
fF is inconsistent (this is the property we wished). For
instance, let us consider again l'J = ((-,p v r (N 0.6)),
(-,q v -,r (N 0.9)), (p (N 0.8)), (q (N 0.3)} which is
inconsistent according to the first semantics ; then,
according to the inconsistency-tolerant semantics, l'J is
consistent since we can find a possibility distribution on
Q _1_ satisfying l'J . For example the possibility
distribution,

fio defined by

it o ([p, q, r]) O.l ;
ito ([p, -,q, r]) = 0.7 ;
=

it ([-,p, q, r1) = 0.1 ;
0
ito ([-,p, -,q, r]) = 0.2 ;
it0 (roj_) = 1,

it0 ([p, q, -,r]) = 0.4 ;

going to show it, we can distinguish between two different
types of partial inconsistencies.
Let fF be a set of possibilistic formulae ; considering the
possibility distributions on Q _1_ satisfying fF , three
situations may occur :
3 it � fF such that it(ro_]_) = 0 : in this case, fF is
(i)

(ii)

consistent in both semantics ; fF is then said to be
completely consistent.
V it � fF, it(roj_) > 0 but 3 it � fF such that

I : then, for any it
satisfying fF , we have n(_l_) = it(OO_j_) > 0 and
�(_!_) = 1 - Sup (it(ro), ro * ro_1_) = o. Thus fF
S u p ( it(ro ), ro

possibility distributions it on Q_!_ satisfying fF
gives the inconsistency

degree of fF . Let

a= Inf( n(_l_), it � fF) ; then Incons(fF) = (I1 a).
(iii) V it � fF, Sup(it (ro), ro * roj_} < 1 (which entails
that V it � fF, neroj_) = 1). In this case, for any it
satisfying fF , we have n(_l_) = it(OO_j_) = 1 and
�(.l) = 1 - Sup(it(ro), ro * OO_j_} > o. Thus fF

induces a "(somewhat) necessary inconsistency" ; the
minimal value of � (_!_) among the possibility
distributions it on Q_!_ satisfying fF will give us the
inconsistency degree of fF . Let a = Inf(�(.l),
it � fF) ; then Incons(fF) = (N a).
fF is thus characterized by its inconsistency degree which
is a valuation of the form (I1 a) or (N a) ; if fF is
completely consistent then Incons(fF ) = (IT 0). If
V it � fF, Sup(it(ro), ro * ro_]_} = 0 then Incons(fF) =

(N 1) and fF is completely inconsistent. If Incons(fF) =
(I1 a) with a > 0 or Incons(fF) = (N �) with � < I then
fF is partially inconsistent.
The following scale shows
inconsistencies: (see Figure 1)

(N 1)

ito ([-,p, q, -,r]) = 0.2;

satisfies lJ . Moreover, since y is not inconsistent
according to the inconsistency-tolerant semantics, any
formula can no longer be derived from y contrary to what
happened with the first semantics. For example we have
lJ � (r (N 0.6)) but we do not have g � (r (N 0.7)) ;
indeed it o � lJ but we do not have no � (r (N 0.7)).
Hence the new semantics is definitely more tolerant to
inconsistencies than the former one. When a set of
possibilistic formulae fF is inconsistent in the sense of
the first semantics but not in the sense of the second, then
we shall say that fF is partially inconsistent. As we are

roj_) =

induces a "possible inconsistency" (contradiction
being possible to a strictly positive degree). The
minimal value of n(_l_) = it(roj_) among the

ito ([p, -,q, -,r]) = 0.4 ;

ito ([-,p, -,q, .....,r]) = 0.2 ;

*

the

hierarchy

of

complete inconsistency

(Na)
Incons(S" )

partial
inconsistency

(Il l)

(I1 a)
(IT 0)

Figure

complete consistency

1

The knowledge base y gives an example of a degree of
inconsistency equal to (N 0.3). An example of a
knowledge base with a degree of inconsistency of the form
(I1 a) is given by� = ((p (IT 0.7)), (-,p (N 0.6))).
Clearly n satisfies� ¢=> Il(p) <::0.7 and N(-,p) <::0.6 ¢=)
Il(p) <:: 0.7 and Il(p) :<;; 0.4, a contradiction in the first
semantics. Using the inconsistency-tolerant semantics,

191

192

Lang, Dubois, and frade

we get for W "#- <0_1_, 'd WI= p, n (<O) ::;; 0.4 and 3 WI=
--,p, it(w)= 1; it(w_j_) = 0.7. Hence Incons(�)= (TI 0.7).

� = inf it(w_j_)
under the constraints
N(<pi);:,: ai, i = 1,m
n
max( (wJ.). TI(<pj));:,: �j· j = m + 1,. . . , n
Since � > 0, 'd 7t � ff', 3 k such that TI(<pk ) < �k ·
and Incons(ff')= �k for some �k· In order to minimize
this value, let us maximize it over Q, so as to make
the set (j I TI(<pj) < �jl as small as possible. Let it be
defined by n(w) = min{1 - ai , w I= •<fl i· w "'<OJ } .
.
Clearly, it 1= {(<p i (N ai)), i = l ,m}, 3 wE Q, it(w)
= 1 (since there is no inconsistency among the
N-valued formulas), and 'dn' , it' � {(<p i (N ai )),
i = 1,m} ==} 'd wE Q, it'(w)::;; it(w). The only
parameter le ft is it ( w _1_ ). Let � k =
max{�j I I1(<flj) < �j} where I1 is based on it. Note that
the maximality of it over Q minimizes the number of
(<flj (I1 �j)) with I1(<flj) < �j·

The examples indicate that the inconsistency degree of a
possibilistic knowledge base ff is the valuation of the
least formula (in the sense of the ordering in 9f) involved
in the strongest contradiction in ff. Let wE 9f such that
I n c o n s ( ff ) = w. It is easy to see that 'd <l> E ff ,
Incons(ff - {<I>}) ::;; w. Let ff' � ff such that Incons(ff') =
Incons(ff) and 'd <I> E ff', Incons(ff' - {<l>}) < Incons(ff').
ff' is called a smallest maximally inconsistent subset of
ff. Then the following result holds :

Proposition I : The inconsistency of a possibilistic
knowledge base ff is the smallest weight of possibilistic
formulas in any smallest maximally inconsistent subset
ff• of ff. More precisely, if Incons(ff) = (N a) then there
exists at least one formula (<p (N a )) E ff' and
'd (<p' w)E ff', w ;:,: (N a). If Incons(ff) = (I1 �) then
there is a unique possibility-valued formula in ff' of the
form (<p (I1 �)).
Proof:
i) Incons ( fF) = (N a). Assume ff• = {(<p i (N a i )),
i = 1,m} u {(<fl j (I1 � j), j = m + 1, . . . ,n}. The
inconsistency degree is
a= 1 - SUPw"#W_j_ n(w)

under the constraints
� (<fl ) 2': a , i = 1,m
i
i
n (<flj) 2': �j· j = m + 1, . . . , n
Since a> 0, n(w_1_) = 1 and the constraints n (<flj) 2':
� j are ever satisfied. Hence Incons(ff ') =
Incons{(<fli (N ai)), i = l ,m}. The minimality of ff' is
thus contradictory with the presence of possibility­
valued formulas in ff '. Thus ff ' is of the form
{(<fli (N ai)), i = 1,n}. By assumption any possibility
distribution it satisfying ff' is such that n(w)::;; 1 -a
for all w * w_1_. Assume a1 = mini= 1,m ai . Let us
prove that a1 = a. 7t satisfies ff' if and only if 'd i,
n(w)::;; 1 -ai, 'd w I= •<fl i· w * w_j_ ; in other words,
'dit, it� ff implies 'd w I= •<fl1 v '<fl2··· v •<fln•
it ( w ) ::;; max 1 - a = 1 - a . Hence, since
i
1
i
• <fl 1 v •<fl 2 ··· v •<fl n = T, where T denotes the
tautology (otherwise ff' would not be inconsistent),
'd wE Q, n(w)::;; 1 - a1 is due ton � ff '. Hence
the inequalitya 2':a1· Now let 1t be defined by
it(w) = 1 -a1 if w 1= <fl 2" <fl3··· "<fl n· w "'<OJ.,
n(w)::;; 1 - ai if w I= •<fli· w "'w_!_·
Because <fl 2 "<fl3··· " <fln ;o'_l_, 3w, it(w) = 1- a1.
and it� ff.Hencea=a1 .
ii) lncons(fF) = ([J /3). It is obvious that ff' contains at
least one possibility valued formula. Let us show that
it is unique. The inconsistency degree is now of the
form :

For simplicity assume � k = � m+1· Let us put it(w_j_) =
� m + 1 . Then clearly, it � ff ', since 'd j ,
m a x (� m + 1 • I1(<fl j)) 2': � j by construction. Thus
Incons(ff')::;; � m +1· Now, 'd<flj such that TI(<pj) 2': �j·
Incons(ff' - {(<p (I1 �j)}) = Incons(ff') ; the same thing is
true for all <flj such that I1(<flj) < �j < � m +1· If there is
another formula (<fli (I1 �i)) such that �i = �m+1• dropping
one of these formulas still requires it (<O_j_) = �m+ 1 for
ensuring it � ff'. Hence, if ff • is really minimal it
contains only one possibility-valued formula, i.e. (<flm+ l
•
(I1 �m+1)) and Incons(ff') = (I1 �m+1 )·
Incons(ff) acts as a threshold inhibiting all deductions of
ff with a valuation::;; Incons(ff). Indeed, deductions such
as ff � (<p w) where w ::;; Incons(ff) are trivial since
ff � (<p w) comes directly from ff � (J. w) and the
inequalities n (<p) 2': n(J.) . �(<p) 2': �(_!_) (it easy to check
that if for any classical formulae <p and 1jf, if <p 1= 1jl then
n(<p) 2': n(1j!), �(<p) 2': � (1j!)). On the contrary, deductions
with a valuation strictly greater than Incons(ff) are not
caused by the partial inconsistency ; these deductions are
called non-trivial deductions.
Lastly, the following results are easy to prove (Lang,
1991) : If ff is a set of possibilistic formulae and w a
valuation of 9f, let us note ff w = {(<p v), v 2': w} and
ff w = {(<p v), v> w} ; then
(i) ff�(<pw) iff ffw�(<pw)
(ii) If Incons(ff) = w, ff is�-equivalent to ff w and to
ffw u ((_!_ w)}.
3

AUTOMATED DEDUCTION IN
POSSIBILISTIC LOGIC

Two well-known automated deduction methods have been
generalized to possibilistic logic : i) resolution (Dubois

A Logic of Graded Possibility and Certainty Coping with Partial Inconsistency

and Prade, 1990a) and ii) the Davis and Putnam semantic
evaluation procedure for propositional logic (Lang, 1990).
Here we focus only on resolution for which we give
soundness and completeness results.

where R(q ,c2) is a classical resolvent of q and c2, and *
is defined by
(N a) * (N �) = (N min(a.�)) ;
en�) if a+�> 1 ;
(N a) * (IT r:t) {
f-' - err 0) if a + � � 1.
err a) * en�) = en 0).
_

3.1

CLAUSAL FORM

In order to extend resolution to possibilistic logic, a
clausal form is first defined. A possibilistic clause is a
possibilistic formula (c w) where c is a first-order or
propositional clause and w is a valuation of 'V'. A
possibilistic clausal form is a conjunction of possibilistic
clauses. If a possibilistic formula fF contains only
necessity-valued classical formulae, then there exists a
clausal form G of fF such that Incons(G) = Incons(ff),
which generalizes the result holding in classical logic
about the equivalence between the inconsistency of a set of
formulae and the inconsistency of its clausal form. Indeed
possibilistic clausal form G of ff can be obtained by the
following method: if ff = ((ljli (N ai)), i= 1... n}, then
put each IPi into clausal form, i.e. IPi = (V)"j(Ci j) where
C ij is a universally-quantified classical clause ; then
(V)"i, j((C ij (N a i ))} is the possibilistic clausal form
equivalent to fF 3 . If fF contains also possibility-valued
formulae, then generally we cannot compute from fF a
clausal form having the same inconsistency degree as fF,
even in propositional possibilistic logic. For instance, the
closest clausal form we can compute from ff =
((p " q (IT a )), (-,p v -,q (N 1))} (a > 0) is C =
( (p (TI a)), (q (TI a)), (-,p v -,q (N 1))}, but it can be
checked that Incons(ff) =ena) whereas Incons(G) =
(IT 0). This negative result comes from the non­
compositionnality of possibility measures for conjunction.
Indeed (p "q ena)) is much stronger than (pena))"
(q en a)), since (p 1\ q en a)) means ncr 1\ q) � a, i.e.
3 co E Q.l such that co 1= p" q and ii(co) �a, whereas
(p en a)) 1\ (q en a)), means :leo, co' E Q.l SUCh that
co 1= p, co' 1= q and ii(co) �a, ii(co') �a. This problem,
also appears in modal logics (Farinas and Herzig, I988)
and can be similarly solved in our framework by
"coloring" the "IT" valuations. We denote respectively by
CLPI (resp. CLP2) the language consisting in necessity­
valued clauses only (resp. necessity- and possibility-valued
clauses).
3.2

POSSIBILISTIC RESOLUTION RULES

The following possibilistic resolution rule, between two
possibilistic clauses (q W I ) and (c2 w2), has been
established by Dubois and Prade (1987, 1990):
(CJ w1) (C2 w2)
(R)

3 Indeed, N(r,i(Cij)) 2: a is equivalent to min;[N(Cij))
2: a and thus to "'j[N(c;j) 2: a]; fF is then equivalent to

"'i("'j{(cij (N a;))]]. i.e. "ij{(Cij (N a;))].

The similarity between (R) and resolution patterns existing
in modal logics has been pointed out ; see (Dubois and
Prade, 1990). The following result can be easily checked
Proposition 2 (soundness of rule (R)) : let G be a set of
possibilistic clauses, and C a possibilistic clause obtained
by a finite number of successive applications of (R) to C ;
then C � C.
Proof:
(i) If C = (q (N a)), C' = (c2 (N �)), the application of
rule R yields C" (R(c l ,c2) (N min(a,�)). Then Vrc
satisfying C"C' we have l'l(c I ) �a and N(c2) � �.
=

and then l'l(cJ"c2) = min(N(q),l'l(c2)) �min(a,�)

and finally N(R(q,c2)) � 1\l(ci" c2) � min(a,�).
Thus rule R is sound in this case.
(ii) If C = (Cj (N a)), C' = (c2 en�)), rule R yields C" =
(R(q,c2) en(a * �)) ; if a+� � 1, a * � = 0 and
then trivially C, C' � C". If a + � > 1, Vii
satisfying C" C' we have l'l(q) �a and D(c2) �� ;
but ncc2) = max[ii(co_L), Il(c2)], then
- either ii(co.L) � � and then D(R(ci ,c2)) �� and
finally ii � C" ;
- or ii(co.L) <�. then ncc2) = Il(c2) ; in this case
Il(c2) = max[Il(-,cl"c2), Il(q"c2)l;

but l'l(q) �a entails Il(-,q) � I - a <�. then
Il(q"c2) �� and DCR(ci ,c2)) � Il(R(c l ,c2)) �
Il(q"c2) ��.and finally ii � C".

Then rule (R) is sound.
3.3

•

REFUTATION BY RESOLUTION

In this section we consider a set ff of possibilistic
formulae (the knowledge base) and a formula ljl ; we want
to know the maximal valuation with which ff entails <p,
i.e. Val(ff,<p) =Sup (wE 9f, ff � (<p w)).
This request can be answered by using refutation by
resolution, which is extended to possibilistic logic as
follows :
Refutation by resolution :
1. Put ff in clausal form C ;
2 . Put ljl in clausal form ; let CJ, ... , C
m be the
obtained clauses ;
3. C' � C u ((q (N I)), ..., (en (N 1))}
4. Search for a proof of (.l w) with w maximal , by
repeatedly applying the resolution rule (R) from C';
5. Val(fJ,<p) = w

193

194

Lang, Dubois, and B-ade

When the knowledge base consists of both necessity­
valued and possibility-valued formulae, then since the
transformation into clausal form is not complete (it does
not preserve the inconsistency degree), we shall suppose
that 5F is a set of possibilistic clauses ; in this case, C =
ff and step 1 is omitted. Soundness and completeness
results hold for possibilistic resolution. Let ff be a set of
possibilistic clauses, <p a classical formula, C' the set of
possibilistic clauses obtained as explained precedently.
Then we have the following results:
Proposition 3 Soundness and completeness of refutation in
clausal possibilistic logic :

ff � ( <p w) <=> Incons(ff1\ (---,<p (N 1))) �w
or equivalently: Incons(ff 1\ (-,<p (N 1))) = Val(ff,<p). See
the proof in Annex.

This result allows us to compute Val(ff,<p) by proving the
inconsistency of ff 1\ (-,<p (N 1)).

Note that in Proposition 3 we are not making use of
resolution. The two following propositions relate the
resolution procedure to the computation of the degree of
inconsistency.
Proposition 4 Soundness and completeness of refutation
by resolution in LP1 (Dubois, Lang and Prade, 1989) : let
ff be a set of necessity-valued first-order formulae and C
the set of necessity-valued clauses obtained from ff ; then
the valuation of the optimal refutation by resolution from
C (i.e. the greatest valuation of the obtained empty clause)
is the inconsistency degree of ff.

Corollary : let <p be a classical formula and C' the set of
possibilistic clauses obtained from ff u {(-,<p (N 1))) ;
then the valuation of the optimal refutation by resolution
from C' is Val(ff,<p). This corollary derives immediately
from Propositions 3 and 4.

Prwosition 5 Soundness and completeness of refutation

by resolution in propositional CLP2 : if C is a set of
propositional necessity- or possibility-valued clauses, then

the valuation of the optimal refutation by resolution from
C is the inconsistency degree of ff.

Corollary : let <p be a classical formula and C' the set of
possibilistic clauses obtained from C u {(-,<p (N 1))) ;
then the valuation of the optimal refutation by resolution
from C' is Val(C,<p).
Proposition 5 is a consequence of Propositions 3 and 1
together with the expression of the resolution rule.
N.B. : Proposition 5 does not hold for first-order
possibilistic clauses; for instance, if C = {(p(x) (Il a))), x
being a (universally quantified) variable and a> 0, and <p =
p(a) A p(b), then there is no (Il a)-refutation by resolution
from C A {(-,p(a) v -,p(b) (N 1))), whereas C �
(p(a) 1\ p(b) (I1 a)). It does not hold either for possibilistic
general formulas, since the tranlation into clausal form
does not preserve the inconsistency degree if the knowledge
base contains possibility-valued formulas. Completeness
can be recovered by indexing the "IT" symbols in the

(Il a)-valuations, in the same spirit as in modal logics
(Farinas and HeiZig, 1988)).
3.4

ILLUSTRATIVE EXAMPLE

We now give an illustrative example. Let C be the
following knowledge base, concerning an election whose
two candidates are Mary and Peter :
(Elected(Peter) vElected(Mary) (N 1))
C1
(---,Elected(Peter) v-,Elected(Mary) (N 1))
C2
(-,Former-president(x) v Elected(x) (N 0.5))
C3
C4
(Former-president(Mary) (N I))
(-,Supports(John,x) v Elected(x) (N 0.6))
C5
(Supports(John, Mary) (I1 0.8))
C6
C7
(-,Victim-of-an-affair(x) v-,Elected(x) (N 0.9))
We cannot find any refutation from C ; hence, C is
consistent, i.e. Incons(C) = (Il 0). Let us now find the best
possibility or necessity degree of the formula
"Elected(Mary)". Let C'= C u {(-,Elected(Mary) (N 1)));
then there exist two distinct refutations by resolution from
C', which are:
(-,Elected (Mary) (N 1)) C3

------

(...,Former-president (Mary) (N 0.5))

4

(_1_ (N 0.5))
I OPTIMAL !
(-,Elected (Mary) (N 1)) C5

-----�C
6

(-,Sup

(_1_ (I1 0.8))
NON-OPTIMAL
Hence we conclude that C � (Elected(Mary) (N 0.5)), i.e.
it is moderately certain that Mary will be elected ; this
degree (N 0.5) is maximal, i.e. Val (C, Elected(Mary)) =
(N 0.5). Then, we learn that Mary is being the victim of
an affair (which is a completely certain information). This
leads us to update the knowledge base by adding to C the
possibilistic clause C 8 : (Victim-of-an-affair(Mary) (N !)).
Let C 1 be the new knowledge base, C1 = C u {C 8} . Then,
we can find a (N 0.5)-refutation from cl :
C8
C3
C4
C7

-------

(-,Elected (Mary) (N 0.9))

------

(Elected (Mary) (N 0.5))

-----(_1_ (N 0.5))

Hence ff1 is partially inconsistent, with Incons (CJ) =
(N 0.5).
The refutation which had given N (Elected(Mary) � 0.5 can
always be obtained from ff 1 but since its valuation is not
greater than Incons(ff J). it has become a trivial deduction.

A Logic of Graded Possibility and Certainty Coping with Partial Inconsistency

On the contrary, adding to fF 1 the possibilistic clause
(Elected(Mary) (N 1)), we find this time a (N 0.9)­
refutation. And, since (N 0.9) > Incons(fF1), we have the
non-trivial deduction fF1 � (-,Elected(Mary) (N 0.9)), and
it could be shown that we also have fF1 � (Elected(Peter)
(N 0.9)).
CONCLUSION

Possibilistic logic drastically differs from probabilistic
logic since the former is based on the ideas of ordering and
preference (only the ordering of numbers is used) while the
latter is b�sed on the ideas of measure and counting.
_ a logic of incomplete information
Possibiiistlc logic Is
_ more robust than classical logic, because it is
that Is
tolerant to inconsistency. Besides, as advocated elsewhere
possibilistic logic is in full accordance with current
theories of belief revision based on epistemic entrenchment
(Dubois and Prade, 1990b), and with the principles of non­
monotonic reasoning (Dubois and Prade, 1991). One of the
strength of possibilistic logic is that the proof methods in
�lassical logic still apply, even in the presence of partial
mconsistency, and keep all their power, as indicated by the
completeness results of this paper. This is would not be
the case with a similar probabilistic extension of logic.
Moreover efficient strategies for refutation methods have
also been implemented (Dubois et a!., 1987). Current
applications of possibilistic logic include hypothetical
reasoning (Dubois, Lang and Prade, 1990), logic
programming (Dubois, Lang and Prade, 1991), the
automated resolution of combinatorial optimization
problems with bottleneck-like objective functions (Lang,
1991) and belief revision.
Among topics for further research is the study of the links
between the semantics presented here and the Kripke-like
sem�ntics previously proposed for necessity and
possibility measures by Dubois, Prade and Testemale
(1988). Another issue is to bridge the gap between
possibilistic logic (especially the handling of possibility
degrees (Il a) ) and the semantics proposed by Yager
(1987) in default logic for defaults such as "if p is certain
and q is possible then r ". It would require to allow for
disjunctions of weighted formulas in the language.
Acknowledgements

This work is partially supported by the DRUMS project
(Defeasible Reasoning and Uncertainty Management
Systems): funded by the Commission of the European
Commumues under the ESPRIT Basic Research Action
Number 3085.



We propose an integration of possibility the­
ory into non-classical logics. We obtain many
formal results that generalize the case where
possibility and necessity functions are based
on classical logic. We show how useful such
an approach is by applying it to reasoning un­
der uncertain and inconsistent information.
1

IRIT
Paul Sabatier
118 route de Narbonne
3 1062 Toulouse Cedex
France

U niversite

Now, possibility theory brings in something more that
should be fruitfully exploited as complementary to
such aspects of reasoning. Hence, we study how to
integrate possibility theory with non-classical logics.
Our work comes from the following two facts:
•

even when the involved uncertainty has a possi­
bilistic nature, "classical" possibility theory may
not be well-suited to the addressed problem, due
to shortcomings, not of possibility theory itself
but of classical logic, on which possibility theory
is defined. For example, some problems require a
formalization with a local view of inconsistency:
this is impossible with classical possibility theory
(we need a paraconsistent approach, cfSection 3).

•

on the ot.her hand, non-standard logics su ch as
intuitionistic logic, paraconsistent logics,. . . are
not expressive enough to express uncertainty in
a gradual way.

Introduction

Possibility theory has been widely used in Artificial In­
telligence to represent uncertain knowledge in a more
qualitative way than, for example, probability theory:
indeed, it is equivalent to work with "quantitative"
possibility theory (which means using possibility and
necessity measures and possibility distributions, which
map formulas or worlds to [0, 1]) or with its qualitative
counterpart (where qualitative necessity and possibil­
ity relations are preorders on the logical language and
qualitative possibility distributions are just preorders
on the set of worlds). Besides, its connection to vari­
ous qualitative formalisms in logic and Artificial Intel­
ligence has been established, notably with epistemic
entrenchment relations in [DP 9la], conditional logics
in [Bou 92] [F HL 94], System Z in [BDP 92]. The use of
possibility theory in Artificial Intelligence covers non­
monotonic reasoning [DP 91b], belief revision, incon­
sistency handling, inheritance and default rules han­
dling, temporal reasoning, constraint satisfaction, . . .
In Knowledge Representation, many non-classical log­
ics have been used (note that in this paper we consider
only non-classical logics sharing the same language as
classical logic). Each of them was intended for some
particular focus, a specific aspect of reasoning: E.g.
paraconsistent logics have been used to deal with con­
tradictory knowledge bases. Or, intuitionistic logic has
been used to take into account some subtle distinctions
between statements involving double negation for ex­
ample. Or, Kleene's 3-valued logic {and other many­
valued logics) has been used to cope with statements
for which neither truth nor falsity make sense.

These arguments show that it is generally valuable to
integrate non-classical logics with a numerical theory
of uncertainty. Now, the reason why we focus in this
paper on possibility theory rather than another theory
of uncertainty, is its qualitative nature (as it amounts
to a "numerical account" of preordering relations over
formulas or worlds), which should make it a priori sim­
pler to generalize than more quantitative approaches
such as probability theory or belief functions.
The methodology we follow in this paper consists of
going from the general case to the particular case:
•

in Section 2, we investigate whether, and under
which conditions, important properties of possi­
bility theory remain valid when generalized. We
state the results in the most general case to make
the study "reusable", though the applications de­
veloped in Section 3 focus on paraconsistency.

•

in Section 3, we take a case study, that is, we
choose a paraconsistent logic (namely Ct) and dis­
cuss more practical applications to reasoning with
uncertain and inconsistent information.

*Research supported by CNRS in proj ect "Gestion de
l'evolutif et l'incertain dans une ba.$e de connaissances".

Besnard and Lang

70

Non-classical necessity and

2

possibility functions
2.1

Necessity /possibility functions

The natural presentation of necessity and possibility
functions (see [Zad 78] for instance) shows that pos­
sibility theory consists in meta-level definitions over
classical logic, which respect completely the structure
of classical logic.
This suggests that similar functions could be defined
on other logics than classical logic; so, replacing (.C,I-)
by (.C, f---L) where L is a given non-classical logic, we can
look for a definition of possibility/necessity functions
on the logic L. We deal with classical propositional1
languages, built from a list of propositional variables
- sometimes required to be finite -, and the connec­
tives -., 1\, V, �, <-> (where 1-L 9 <--> t/; is a shorthand
for 1-L 9 -+ t/; and 1-L t/; -+ ¥') . The only vary­
ing parameter is then the consequence relation f-L.
We now give a generic definition of non-classical ne­
cessity /possibility functions, of which the usual ne­
cessity /possibility functions correspond to the special
case where L is classical logic (Section 3 deals with the
special case where L is the paraconsistent logic Cr).

Definition: let .C be a classical propositional language
and 1-L a consequence relation, L being a given (maybe
non-classical) logic. A L-necessity function is a map­
ping N from .C to [0, 1] satisfying the following axioms2
(Taut) if

f---L 9

N (9)

then

=

1

The dual functions of necessity functions are called
possibility functions. They can be defined by 3 axioms
about contradiction, equivalence and disjunction:

Definition: A L-possibility
from C to [0, 1] such that

function is a mapping II

(Contr) if 1-L •({) then II(¥=')= 0
(Eqn) if l- L 9 +-+ t/; then II(If') = II(t/;)
(Disj) II(9 V ¢) = max(II(If'), II(t/;))
Whatever the logic L, the next property entails (Eq n):
(Domn) iff-L

9--+

t/; then II('P)::; II(t/;)

Proposition 2: (Domrr) is entailed by (Eqrr) and
(Disj) on condition that f- L satisfies:
1-L

2.2

(/)-+

Some properties of non-classical
necessity /possibility functions

W hen L is classical logic, (L-)possibility functions can
be defined from (L-)necessity functions by means of
\lip E £, ll(lf') = 1- N(...,r.p) and (L-)necessity func­
tions can be defined from (L-)possibility functions by
V'(J E .C,N(¥') = 1-II(-.¥')· That is, "classical" neces­
sity and possibility functions enjoy the (double) dual­
ity property:
(Dl} II is a possibility function iff d n : £ -+ [0, 1]
defined by drr (r.p) 1 -II( -,'P) is a necessity func­
tion.
(D2) N is a necessity function iff dN : C -+ [0, 1] de­
fined by dN(9) = 1- N(-.9) is a possibility func­
tion.
=

(Eq) if 1-L 9 <--> t/; then N('P) = N(t/;)
(Conj) N(¥' 1\ t/;) = min(N(¥'), N(t/;))
When L is classical logic, we recover the classical ne­
cessity functions. Whatever the logic L is, the follow­
ing property always entails (Eq):
(Dom) if f---L 'P-+ t/; then N('P)::; N (t/;)

Some questions we may ask are: how can (D1) and
(D2) carry over to L-necessity and L-possibility func­
tions? When are (Dl) and (D2) equivalent?

Proposition 1: (Dom) is entailed by (Eq) and (Conj)

Proposition 3: if 1-L

on condition that l-L satisfies:

Proposition 4: if L satisfies

f-L\;'�1/J
Hence, for all logics

L

fulfilling the latter condition, a
as a func­
tion N: .C----> [0, 1] satisfying (Taut), (Conj), (Dom).

necessity function can then be characterized

1 For

the sake of simplicity, we

consid er

( <p)

tra axiom (Contr) if f- •<p then N
for example, in
the quantity

0 but not all:
N{) > 0, reflects
=

a degree of (partial) inconsistency.
Note that requiring
(Contr) or not -and the same for (Taut)- does not make
much difference since (Dam) ensures that contradictions
(resp. tautologies) have anyway the lowest (resp. highest)
necessity degree. Now, the reason why we require (Taut)
and not (Contr) concerns the characterization of necessity
functions in terms of possibility distributions.

-.-.r.p

<-->¥' then (D1)

{::}

(D2).

1. 1-L r.p +-+ ...,-,'(J
2. 1- L -.(91\ t/;) � ( -.9 V -.'ljJ)
3 . f-L (tp V '1/J) � (-.r.p 1\ -,.,p)
-.

and the following inference rules

1-L(/)

only the propo­

sitional level throughout the paper.
2
Many definitions of necessity functions include the ex­

[DLP 94]

'1/J

1-Llp-+tj;
'1/J

j- L

f---L({)--"1/J
1-L -.'ljJ -+ -.r.p

then (D1) and (D2) hold.
Note that among non-classical logics admitting (1)-(3)
and the above two inference rules (modus ponens and
contraposition), there are various relevant logics such
as the logic E [AB 75]. Let us now have a look on
necessary conditions for having (D1) (or (D2)).

Proposition 5: if there exists 9 such that f-L r.p and
r.p then (Dl) does not hold.
IfL
-.-.

Possibility and Necessity Functions over Non-Classical Logics

Proposition

and lfL

6: if there exists I{) such that rL
(D2) does not hold.

1p then

--,---,1{)

Next, we investigate a few issues related to the con­
dition under which a function from C to [0, 1] can be
both a necessity and a possibility function.
a truth-functional valuation is a fun c­
tion f from C to [0, 1] such that there exist two non­

Definition:

decreasing operators EB and® from (0, 1]2 to (0, 1] such
that 'V1p, t/J, f('P V t/J) = f(cp) ffi f(t/J) and /('P 1\ t/J) =
f(cp) 0 f(,P).
Definition: a logic L is said to admit trivialisation
of truth-functional valuations iff any truth-functional
valuation f satisfying (Dom), i.e. f-L 1p -+ t/J implies
f( 1p) � f( t/J) (we will also say that f is monotonic
w.r.t. 1-L) is a classical valuation, i.e. there are two
values O" and 1* such that Vip,/(IP) E {o•,l*} and
f(-.IP) f= f(IP)It is well-know n that trivialisation of truth-functional
va luations holds in the case of classical propositional
logic ([Wes 87] (DP 88] - see also [DP 94] for a discus­
sion on the implications of this result). To study the
condition under which this property also holds in the
case of non-classical logics, Je t us consider the follow­
ing assumptions:
1. 'r-Lip-+ipVt/J
2.

f-.LI{)I\1/J-1{)

3.

f-L

'P

1\

2.3

Semantics of L-necessity /possibility
functions

With the assumption that C is built from a finite
number of propositional variables, "classic al " neces­
sity /possibility functions can be semantically defined
by means of possibility distributions: a possibility dis­
tribution 7r is simply a fun cti on from the set n of all in­

terpretations for L to (0, 1]. The necessity function in­
duced by 1r is defined by N ( 'P) = inf{1-7r(w) /w f= ''P}
(with the convention inf 0 = 1 th at we take in all the
paper as well as sup 0 = 0). It can then be proved
that N is a necessity measure, and that any necessity
measure is induced by a possibility distribution.
We now turn to the general case of a logic L f or which
the class of L-m ode ls is wri tten nL .
a L-possibility distribution is a mapping
from �h to [0, 1 ] . It is said to be normalized iff
sup v E: i1L 7r(v) = 1.
Definition:
1r

In classical logic, due to the equivalence between v li: 'P
-.cp, the two following defini ti ons for inducing
a C-necessity function from a C-possibility distribution
a re e qui valent:

and v f=

N(cp)
N(cp)

V cp +->I{)

5. 'rL

'P

1\ '1j;

+-+

'1j; 1\ 'P

6. f-. L

cp V 1/J

+->

t/J V cp

II(cp)
ll(cp)

let L be a logic satisfying (1) to (8)
and f a truth-functional valuation mon otonic w .r .t.
f-L. Then we have ffi = max and ® = min.

Proposition 7:

8: let L be a logic satisfying (1) to (8)
and excluded middle, and f a truth-functional valua­
tion on L mo notonic w.r.t. f-.L· Then, Vcp,f(<p) = 1*
or f(-,cp) = 1•, where 1• = sup{ /('P) , cp E C}.
Proposition

Proposition 9: let L be a logic satisfying (1)-(8) and
non-contradiction and f a truth-functional valuation
monotonic w.r.t. 1-£. Then Vcp,/(cp) = 0* or f(-,IP) =
o• where 0* = inf{f(cp),ip E £}.
Corollary 10: any logic satisfying (1) to {8), excluded
middle and non-contradi c tion admits trivialisation of
truth-functional valuations.

=

sup{7r(v)/v � 'P}
sup{7r(v)/v f= ''P}

JI{1r), /2{1r), /a(7r), /4(1r) are the map­
pings from ,C to (0, 1] induced from 1r by:

Definition:

7. 'r-L (cpl\t/J)I\ � +-+cpi\(1/J/\0
8. 'rL('P Vt/J)Y�+-+cp V(t/JY�)
9. f-.L cp V -.cp (exc luded middle)
10. f-.L -.(cp/\-.cp) (non-contradiction)
Again, an example of a logic satisfying these properties
is the logic E [AB 75]. On the other hand, intuitionistic
logic and paraconsistent logics do not.

1- sup{1r(v)/v li: cp}
1- sup{7r(v)/v F ''P}

Analogously, for p ossibitity functions:

'P +->I{)

4. 'r-L I{)

71

ft(7r)(cp)
f2(7r)(cp)
/a(7r)('P)
/4(7r)(cp)

=

1- sup{7r(v)/v
1- sup{7r(v)lv
sup{1r(v)/v FL
::: sup { 1r( v ) I v � L

�L cp}
FL •'P}
cp}
-.cp}

It is straightforward from these definitions that the
following duality properties hold:
•
•

/4 ( 7r)('P) = 1- ft(7r)(-,cp)
f2(7r) {'P) = 1- fa(7r)(•cp)

Proposition 11: if L is such that v !i=L cp =? v FL
-.cp (or equivalent1y, v �L ''P =? v f= L 'P )3 then
/2(1r)(cp) � fl(7r)(cp), and /4(1r)(cp) � /3(1r)(cp).
Proposition 12: ft is a L-necessity function, pro­
vided that the following conditions hold:
•

if

•

V

•

V

then v FL cp for all v (Soundness)
FL 'P +-+ t/J iff ( V F L 'P) {::> ( V F tj;)
F L 'P 1\ 1/J iff V FL I{) and V F L 1/J
f-L cp

3Either (v �L cp =? v I=L -.cp) or (v �L •cp =? v FL cp)
basically amounts to the validity of cp V •cp in the logic L.

72

Besnard and Lang

Proposition 13: h is a 1-necessity function, pro­
vided that the following conditions hold:

rp then v �L -.rp for all v
v FL rp <c-t 1/; iff (v FL -.rp) <:? (v FL -.'lj;)
• v FL -.( rp 1\ '1/J) i ff v FL -.rp or v FL -.tf
Proposition 14: h is a 1-possibility function,
•

if I-L

•

pro­

vided that the following conditions hold:
•
•
•

v �L -.rp for all v
v FL rp <c-t 1/; iff (v FL 'P) <:? (v FL '1/J)
v F=L rp V '1/J iff v F= L cp or v F= L tP
if I- L cp then

Proposition 15: J4 is a 1-possibility function, pro­
vided that the following conditions hold:
•
•
•

f= L 'P for all v (Soundness)
v FL 'P <c-t 1/; iff (v FL -.'P) <:? (v FL -,'lj;)
v FL --.(cp V tf) iff v FL ''P and v FL •1/;
if I-L

2.4

rp

then

v

L-necessity orderings

It has been shown [Dub 86] that necessity and possi­
bility functions can be equivalently expressed in purely
qualitative terms, with preordering relations.
We
briefly give a generalization of this result, for the case
of necessities (the case for possibilities is similar).
Definition: A 1-necessity ordering is a relation on .C
satisfying the following properties:

rp 2:: 1/;

1/; 2:: � then rp 2:: � (transitivity)
1/; 2:: rp (dominance)
or rp 1\ tjJ � '1/J (conjunctiveness)

•

if

•

if I- L 'P -+ '1/J then

and

•

rp 1\ tP

� rp

[Dub 86]: a relation 2:: on C is said to
agree strictly with a mapping f from C to [0, 1] iff
Vrp, 1/; E .C, we have 'P 2:: tP <:? !(rp) 2:: f('1/J ).
Definition

Proposition 16 (correspondence between 1-necessity
functions and 1-necessity orderings): the only map­
pings from .C to [0, 1] agreeing strictly with 1-necessity
orderings and also satisfying (Taut) are 1-necessity
functions.

3

Application to reasoning with
uncertain and inconsistent
information

3.1

Motivations

Possibility theory, as well as its qualitative counter­
parts such as epistemic entrenchment relations [GM
88], ranked knowledge bases [Pea 90] or rational clo­
sure [1eh 89] provide a relativized treatment of incon­
sistency, since the latter becomes a gradual notion.
I.e., a possibilistic knowledge base [D1P 94] consists
of a set of constraints KB = {(cp; ai),i = l..n}, where
(cp; a;) is a syntactic notation for the semantical con­
straint N(rp;) 2:: a;.

A possibilistic knowledge base is partially inconsis­
tent if it leads to enforce N(.l) > 0; stated oth­
erwise, the inconsistency degree of K B is defined
by Incons(KB) = maxs£;KB,S�l_ min(<p;a,)es a; =
min{N(.l), N satisfies KB}. Any formula below this
level, i.e. any rp; where a;:::; Incons(KB), is then in­
hibited (it is "drown" by the inconsistency [BCD1P
93]). This shows that the notion of inconsistency
in possibilistic logic and its qualitative counterpart is
gradual but global. The inconsistency level measures
to what extent the knowledge base is inconsistent, but
do not locate the inconsistency. The aforementioned
"drowning effect" is a consequence of this global treat­
ment of inconsistency. One way to cope with it is
to consider the knowledge base syntactically [Bre 89]
[Neb 91] [BCD1P 93], by selecting among maximal
sub-bases of KB using a criterion involving the a;'s.
However, these syntactical approaches do not have
(yet) any semantics in terms of uncertainty measures.
Now, using paraconsistent logics for handling incon­
sistent knowledge bases enables a local treatment of
inconsistency, by locating the inconsistency on some
formulas. Yet, these paraconsistent approaches do not
allow for any graduality in the inconsistency, which im­
plies some loss of information if the initial knowledge
was pertained with uncertainty.
While possibilistic logic allows for a gradual but global
treatment of inconsistency, where conflicts are solved
only by comparing the uncertainty level of the pieces of
information with the inconsistency level of the knowl­
edge base, the pure paraconsistent approach localizes
inconsistency, but conflicts cannot be ranked accord­
ing to uncertainty, importance, priority, normality as
done in rank-based systems. Thus paraconsistency is
not able to "solve" the conflicts. What we propose
here is to apply the results of Section 2 to a given
paraconsistent logic, namely C1 [daC 74], to handle
both uncertain and inconsistent knowledge, and with
a local treatment of inconsistency. We now give two
motivating examples, one about fusion of uncertain
information (multi-source reasoning) and one about
reasoning with default rules.
Example 1 (multi�source reasoning)
This example is borrowed from [Cho 94].
Two witnesses report their observations about a mur­
derer. Witness 1 (noted W1) is certain that the mur­
derer was a woman with blond hair, and believes (with
some uncertainty) that she was wearing a Chanel suit,
glasses, and was driving a BMW. Witness 2 (noted
W2) is certain that the murderer was a woman with
brown hair and that she was not wearing glasses, and
believes (with some uncertainty) that she was driving
a Fiat.

W1 female (sure), blond-hair (sure), drives-BMW
(unsure), wear-glasses (unsure), wear-Chanel­
sui t (unsure)
W2 female (sure), brown-hair (sure), drives-Fiat
(unsure), •wear-glasses (sure)

Possibility and Necessity Functions over Non-Classical Logics

What would we like to conclude about the following
statements?
•

Both witnesses agree that the murderer was fe­
male and are completely sure; so we want to con­
clude the murderer was female.

•

No contradiction either about wear-Chanel-suit
since witness 2 does not know anything.

•

Strong contradiction about the colour of the mur­
derer's hair; we wish to conclude neither blond
nor brown but we want to keep in mind that
these literals are "strongly subject to inconsis­
tency" (knowing the constraint •(blond-hair 1\
brown-hair)).

•

•

Contradiction about wear-glasses: the contradic­
tion is weaker than the one above since witness 1
is unsure; moreover, since witness 2's information
is prioritary to witness 1 's we would like to solve
the conflict (by concluding •wear-glasses).
Weak contradiction again, about the car; however,
since both witnesses are equally certain, we do not
want to conclude anything.

Example 2

(drowning effect)
Here, applying Pearl's ranking procedure of default
rules to
.6.

=

{penguin ......,. bird, penguin
bird fly, b ird ___. wings}

---->

•fly,

___.

3.2

A case study: C1-necessity functions

3.2.1

The paraconsistent logic C1

C1 [daC 7 4] is a paraconsistent logic, that is, a logic
in which a contradiction <p 1\ -,IP fails to entail other
arbitrary contradictions 1/J 1\ -,'ljJ cl retains all infer­
ence patterns of classical logic that are not based on
negation. For instance,
,

IP

1/J

<pi\¢
is valid in C1. By contrast, some inference patterns
of classical logic that do appeal to negation are not
preserved. For instance,
•1/J
'IP
-.(<p V 'I/J)
is not valid in C1. The idea is that positive informa­
tion is fundamental: positive formulas and inferences
contribute to state what the facts are whereas negative
formulas and inferences are merely constraints (in the
sense of integrity constraints for databases). Accord­
ingly, cl allows us to elicit all and only the formulas
responsible for a given contradiction ([CL 92] (BL 941).
A valuation-based semantics for C1 (Alv 84] is given
in Section 3.2.3 as we now reproduce the original ax­
iomatic presentation of C1 that consists of the next
ten axioms
1. <p---+(1/J----><p)
2. (<p----> 1/J)----> [(10---+ (1/J--->

g1ves
.6. 1

=

.6.0

=

{penguin ......,. bird, penguin ---> •fly} ;
{bird ---. fly, bird ---+ wings}.

Adding the fact penguin to .6. enables us to infer •fly
but wings is not deduced (it is "drown" by the incon­
sistency appearing at rank 1). This particular case of
the drowning effect is known as the property of "in­
heritance blocking".
Considering .6. as a set of formulas for the logic C1, we
obtain
AU

{penguin} f-c, {fly, •fly, wings}.

Thus, we avoid the drowning effect but we do not take
into account priorities (induced by specificity) such as
penguin ......,. •fly over bird ......,. fly and we conclude
that fly is not well-behaved.
What we would like is to take advantage of the lo­
calisation of inconsistency, as done by paraconsistent
entailment, and the priority between formulas, which
would lead us to infer {fly, wings} but not •fly.
Note that prioritized syntax-based approaches based
on the selection of maximal consistent subsets of the
knowledge base guided by the priorities solve the
drowning effect but do not tell anything about where
the contradictions are localized; so, for instance, the
conclusion •wear-glasses is not relativised by the
fact that it is (weakly) subject to inconsistency.

73

u

))

---->

(10---+ u)]

3.
4.

\0

5.

<p-->(1/J----><p/\tf;)
<p ---> <p V 7./J
<p---->1/JV<p
(IP----> CT)--> [(1/J----> 0')......,. (<p V tf;---+ 0')]

6.

7.

8.

1\ 1/J ......,.

\0 1\

'P

1/J -1/J

9. 'P v --,'P
10. --,--,1{)-+<p

together with the single inference rule

'f r..!f

C1 has the following basic features.

First, the con­
nectives are not interdefinable. For instance, <p V 7./J
cannot be defined as • ( •<p 1\ •7./J). Second, the re­
placement of equivalent formulas does not hold. For
instance, (<p v 7./J) +--+ [(<p ---+ 1jJ) ......,. 7./J] is valid in C1 but
•(<p V 1/J) ......, -.[('P--> 1/J) ---+ 1/J] is not. Third , neither
modus tollens
•<p
nor disjunctive syllogism
\0

are valid in C1.

--,\0

v 1/J
1/J

Regarding notation, we use <p0 as an abbreviation for
--, (<p 1\ •<p) . In the next two sections, we also use # to
denote any of 1\, V, ---+.

74

Besnard and Lang

3.2.2

C1 Mnecessity functions: definition and

basic properties
Definition: like for L-necessity functions, replacing
1--L by 1--c,.
Some properties enjoyed by C1-necessity functions are:
Dam: If

1--c, t.p -+

(P1) N(t.p)

=

.,P then N(t.p) � N(.,P)

N(•t.p0) or N(•t.p)

=

3.3

N(• t.p0 )

(P2) N(.,P);::: min(N(t.p), N(t.p-+ .,P))

3.3.1

::::} N(1/J) ;::: min;=l..n N('Pi)
(P4) N(-.t.p);::: min(N(t.p0), N(t.p--+ '1/J), N(t.p- + •if))
(P5) N(t.p v '1/J);::: max(N(t.p), N(.,P))
(P6) N(-,-,t.p) = N('P)

(P3) 'Pl,... , 'Pn 1--c, 1/J

(P7) N{t.p00) = 1
(P8) N(('P# 1/J)0) � min(N(t.p0), N(.,P0))
(P9) N is a classical necessity function if and only if
N(t.p0) = 1 for all t.p
min(N('P) ,N(-.t.p)) is the necessity of t.p
N(-,t.p0)
"behaving badly"; it can be seen as a measure of the
inconsistency inherent in t.p. C1-necessity functions en­
able us to rank the formulas not only with respect to
their certainty, but also with respect to their inherent
inconsistency: N( ''Po) gives a notion of inconsistency
which is both local and gradual. We recover of course
as particular cases:
=

•

•

Classical necessity functions, so that N (''Po) =
N(.l) for all t.p. The notion of inconsistency is
still gradual but global.
Classical C1-valuations, which verify N( -.t.p0) = 0
or N(...,t.p") = 1, for all t.p. The notion of inconsis­
tency is still local but not gradual.

3.2.3

C1-necessity functions: semantics

At first, a (paraconsistent) Ct-valuation [Alv 84] is a
mapping from .C to {0, 1} such that:
•
•
•
•
•
•
•

0::::} v(..,IP) 1
v(-.-,'P) = 1 {:} v(t.p) = 1
v('l/!0) = v(t.p---+ '1/J) = v(tp- + •1/J) = I::::} v(IP)
v(lf' -+ '1/J) = 1 {:} v(lf') = 0 or v(.,P) = 1
v(t.p 1\ '1/!) = 1 {::} v(tp) = 1 and v('I/J) ::::= 1
v(tpV.,P) = 1 {:} v(lf') = 1 or v('!j!) = 1
v(tp0) = v('l/!0) = 1::::} v((!f'#'l/!)0) = 1
v(t.p)

=

=

=

0

from the set of all C1-valuations to [0, 1].

Due to Proposition 12, the function fi (1r) defined

fl(7r)(1;?)

=

1- sup{11'(v)\v(1;?)

=

Reasoning with C1 Mnecessity functions
Generalizing the principle of minimum
specificity

The principle of minimum specificity [DP 86] or equiv­
alently,minimum compact ranking [Pea 90] and ratio­
nal closure [Leh 8 9] (all these being equivalent, up to
the language on which they are defined) induces, from
a possibilistic knowledge base, a particular necessity
function i.e. the smallest among all necessity functions
satisfying the knowledge base. Thanks to the prop­
erty (P3), we are able to generalize the principle of
minimum specificity to C1-necessity functions:

Definition: a C1-possibilistic knowledge base is a fi­
nite set KB = {(tp; a; ) , 1 � i � n} where if'; E .C and
a; E [0, l]. A C1-necessity function N is said to satisfy
KB iff Vi
l..n, N(lf'i) ;::: a;.
=

Definition: the minimum specificity closure NKB of a

C1-possibilistic knowledge base KB is the C1-necessity
function defined by

Vtj;
where KB13

E

=

.C, Nxs (,P)
{lf';\(!f'; ai)

=

E

sup{,BIKB11I--c1 '1/J}

KB and a;;:=: ,8}.

Proposition 17 (principle of minimum specificity for
C1-necessities): For any Ct-necessity function N, N
satisfies KB iff N;::: NxsMore generally, the minimum specificity closure could
be extended to any logic L satisfying the property
(P3). Applying the principle of minimum specificity
enables us to draw conclusions that taking into account
the uncertainty and the inconsistency of the knowledge
base. We propose the following definition of a conse­
quence relation:

Definition: KB f--- '1/J iff Nxs ( .,P)

>

Nxs(-.'1/!0).

Proposition 18: KB f--- 'rP iff Nxs(t/;)

Definition: a C1-possibility distribution is a mapping
1r

We could have also defined C1-possibility functions,
C1-necessity and possibility orderings, that we do not
discuss for the sake of brevity. C1-necessity functions
are sufficient to deal with the next section, devoted to
the application to reasoning with uncertain and incon­
sistent knowledge.

as

0}

is a Ct-necessity function (since Ct obeys the condi­
tion stated in Proposition 12 - the soundness of the
semantics coming from the soundness and complete­
ness of C1 established in [Alv 84]).

>

Nxs(-,'!j!).

Intuitively, we deduce '1/J from KB iff the certainty of
'1/J is higher than the inconsistency inherent to '1/J, or
equivalently, iff the certainty of 'lj; is higher than the
certainty of •¢. The binary version of f--- would be
defined by if' f'--KB '1/J iff Nxs(t.p -+ ¢) > Nxs(l;? -+
•if0), or equivalently iff Nxs(t.p--+ ¢) > Nxs(IP -+
-,'CjJ). Note that f-- is nonmonotonic; a more complete
study of the properties of f--- a Ia Kraus, Lehmann
and Magidor [KLM 90], is possible with respect to the
(monotonic) logic cl instead of classical logic.
Note that when N collapses to a classical necessity
measure, we haveVt/;Nx8(-.,P0) = N(..L) and f--- is the
classi cal possibilistic consequence relation [DP 91 b].

Possibility and Necessity Functions over Non-Classical Logics

(multi-source reasoning): let us return to
the example of Section 3.1. Taking some a E (0, 1 ) :

Example

•

•

W1 (witness 1):
N(female) = 1; N(brown) = 1; N(BMW) = a;
N(Chanel) = a ; N(glasses) = u:.
W2 (witness 2):
N(female) = 1; N(-.brown) = 1; N(-.BMW) =a;
N(-. glasses)= 1.

The fusion K B of these two knowledge bases gives the
following minimum specificity closure:
•

NKB(female) = 1; NKB(-.female) = 0;
NxB(-.female0) = 0;

•

NxB(brown) = 1; NKs(-.brown)= 1;
NxB(-.brown°) = 1;
NxB(BMW) u:; NxB(-.BMW) =a;
NxB(Chanel) =a; NKB(•Chanel) = 0;
NxB(•Chanel0) = 0;
NxB(glasses) = a; NKB(-.glasses)
1;
NxB(-.glasses0) = a.

•
•

•

=

=

Therefore, we have K B f--- female, K B f--- Chanel,
KB f--- -.glasses; however, KB lt- BMW, KB lt- •BMW,
K B lt- brown, K B lt- -,brown.

75

Therefore, we have
K B f--- •fly (which is intended);
K B f--- -,wings (which is intended);
f--- avoids the drowning effect, contrarily to
the classical minimum specificity closure,
System Z, and similar systems.
but also
K B f--- •live-in-Antarctica

which is not intended! (Due to NKB(fly) = /3, the
rule fly--+ •live-in-Antarctica applies).
Here is a revised definition, more suited to handling
default rules:
Definition: Let K B = FULl, where F is a set of
facts and Ll = {'Pi --+ 1/;i, i = l..n} a set of default
rules, where each rule is assigned a necessity degree
corresponding to its Z-ranking. We define

G0(Ll) =FuLl
and Vk 2': 0,

ck+l(Ll)
F u {.:p;--+ 1/;; E Gk(Ll) I NGk(f!.)('Pi) > NGk(f!.)(•.:pi)}
F u {'Pi--+ 1/;; E Gk{Ll) I Gk(Ll ) r- <:;';}.
k(Ll). Then Ll f---• 1/; iff
Lastly, let G00(Ll) = n >oG
kG00(Ll ) r- 1/;.
=

=

3.3.2

Handling default rules

Example:

Consider the fact penguin and the rules

� = {penguin---+ bird, penguin---+ •fly,
bird ---+ fly, bird ---+ wings,
fly--+ -.live-in-Antarctica}.
Applying the Z ranking procedure to Ll (written with
the possibilistic ranking convention) gives the ranking:
(for any a:, j3 such that 0 < j3 < a < 1)
{penguin--+ bird, penguin---+ --,fly,
fly---+ -.live-in-Antarctica};
�f3 = {bird ---+ fly, bird---+ wings}.

Lla

=

Then, taking the C1-minimum specificity closure of
K B = {penguin} U � leads to
•
•

•

NxB(penguin) = 1;
NxB(bird) u:;
NxB(•fly) =a;
NKB(fly--+ •live-in-Antarctica) =a;
NxB(fly) = /3;
NxB(•fly0) = /3;
NxB(wings) j3;
NxB(-.live-in-Antarctica) = /3;
NKB(-.bird)= 0;
NxB(-.bird0) = 0;
NxB(-.penguin) = 0;
NxB(--,penguin°) = 0;
NxB(-.wings) 0;
NxB(•wings0) = 0;
NxB(live-in-Antarctica)= 0;
NKB(--,live-in-Antarctica0) = 0.
=

=

•

=

Example:

We apply the usual ranking procedure:

� = {bird --+ fly, bird ---+ wings,
penguin ---+ bird, penguin ---+ -.fly,
fly---+ •live-in-Antarctica}.

G 1(Ll) = {penguin, bird---+ fly, bird--+ wings,
penguin ---+ bird, penguin --+ --,fly}.
Clearly, G00(Ll) = G1(6.). Therefore, Ll f---• •fly.
Also, Ll r-• bird and 6. f---1 wings. Contrastedly,
Ll �· •live-in-Antarctica.
4

Conclusion

We have given some basic results describing what re­
mains and what changes when switching from classi­
cal possibility theory to possibility theory over a non­
classical logic. We have then focused on a case study,
namely the paraconsistent logic C1, and showed how to
use it to reason with inconsistent and uncertain infor­
mation. W hat has been left aside in this paper is the
other possible applications of possibility theory over
non-classical logics: first, one could think of applying
the general results of Section 2 to other non-classical
logics: for instance, introducing possibility and ne­
cessity valuations into intuitionistic logic could model
gradual strengths of proofs; or, introducing them to
Kleene's logic (or more generally to a multi-valued
logic) would enable us to handle both uncertainty and
partial truth.

76

Besnard and Lang

Another topic for further research would be a parallel
study for other numerical theories of uncertainty. For
instance, paraconsistent probabilities would lead to a
more quantitative framework for reasoning with un­
certain and conflictual information; in this framework,
noticing that Prob( <p) + Prob( -.�.p) = Pro b( <p v -,<p) +
Prob( <pi\ -.�.p) = 1 + Prob( -.�.p0),relaxing the constraint
Prob( -.�.p0) = 0 would make P r ob( <p) + Prob( -.�.p) > 1
possible for some formulas; then one could think of
searching for the "least inconsistent" probability dis­
tribution satisfying a set of constraints, which could be
useful for instance when rectifying a set of inconsistent
probabilistic data.
5


