
We apply decision theoretic techniques to construct nonplayer characters that are able to assist a human player in collaborative games. The method is based on solving Markov
decision processes, which can be difficult when the game
state is described by many variables. To scale to more complex games, the method allows decomposition of a game task
into subtasks, each of which can be modelled by a Markov
decision process. Intention recognition is used to infer the
subtask that the human is currently performing, allowing the
helper to assist the human in performing the correct task. Experiments show that the method can be effective, giving nearhuman level performance in helping a human in a collaborative game.

Introduction
Traditionally, the behaviour of Non-Player Characters
(NPCs) in games is hand-crafted by programmers using
techniques such as Hierarchical Finite State Machines (HFSMs) and Behavior Trees (Champandard 2007). These techniques sometimes suffer from poor behavior in scenarios
that have not been anticipated by the programmer during
game construction. In contrast, techniques such as Hierarchical Task Networks (HTNs) or Goal-Oriented Action
Planner (GOAP) (Orkin 2004) specify goals for the NPCs
and use planning techniques to search for appropriate actions, alleviating some of the difficulties of having to anticipate all possible scenarios.
In this paper, we study the problem of creating NPCs that
are able to help players play collaborative games. The main
difficulties in creating NPC helpers are to understand the intention of the human player and to work out how to assist
the player. Given the successes of planning approaches to
simplifying game creation, we examine the application of
planning techniques to the collaborative NPC creation problem. In particular, we extend a decision-theoretic framework
Copyright c 2011, Association for the Advancement of Artificial
Intelligence (www.aaai.org). All rights reserved.

for assistance used in (Fern and Tadepalli 2010) to make it
appropriate for game construction.
The framework in (Fern and Tadepalli 2010) assumes that
the computer agent needs to help the human complete an unknown task, where the task is modeled as a Markov decision
process (MDP) (Bellman 1957). The use of MDPs provide
several advantages such as the ability to model noisy human
actions and stochastic environments. Furthermore, it allows
the human player to be modelled as a noisy utility maximization agent where the player is more likely to select actions
that has high utility for successfully completing the task. Finally, the formulation allows the use of Bayesian inference
for intention recognition and expected utility maximization
in order to select the best assistive action.
Unfortunately, direct application of this approach to
games is limited by the size of the MDP model, which grows
exponentially with the number of characters in a game. To
deal with this problem, we extend the framework to allow
decomposition of a task into subtasks, where each subtask
has manageable complexity. Instead of inferring the task
that the human is trying to achieve, we use intention recognition to infer the current subtask and track the playerâ€™s intention as the intended subtask changes through time.
For games that can be decomposed into sufficiently small
subtasks, the resulting system can be run very efficiently in
real time. We perform experiments on a simple collaborative
game and demonstrate that the technique gives competitive
performance compared to an expert human playing as the
assistant.

Scalable Decision Theoretic Framework
We will use the following simple game as a running example, as well as for the experiments on the effectiveness of
the framework. In this game, called Collaborative Ghostbuster, the assistant (illustrated as a dog) has to help the
human kill several ghosts in a maze-like environment. A
ghost will run away from the human or assistant when they
are within its vision limit, otherwise it will move randomly.
Since ghosts can only be shot by the human player, the dogâ€™s

role is strictly to round them up. The game is shown in Figure 1. Note that collaboration is often truly required in this
game - without surrounding a ghost with both players in order to cut off its escape paths, ghost capturing can be quite
difficult.

This algorithm is guaranteed to converge to the optimal
value function V âˆ— (s), which gives the expected cumulative
reward of running the optimal policy from state s.
The optimal value function V âˆ— can be used to construct
the optimal actionsPby taking action aâˆ— in state s such that
aâˆ— = argmaxa { s0 Ta (s, s0 )V âˆ— (s0 )}. The optimal Qfunction is constructed from V âˆ— as follows:
X
Qâˆ— (s, a) =
Ta (s, s0 )(Ra (s, s0 ) + Î³V âˆ— (s0 )).
s0

The function Qâˆ— (s, a) denotes the maximum expected longterm reward of an action a when executed in state s instead
of just telling how valuable a state is, as does V âˆ— .

Figure 1: A typical level of Collaborative Ghostbuster. The
protagonists, Shepherd and Dog in the bottom right corner,
need to kill all three ghosts to pass the level.

Markov Decision Processes
We first describe a Markov decision process and illustrate
it with a Collaborative Ghostbuster game that has a single
ghost.
A Markov decision process is described by a tuple
(S, A, T, R) in which
â€¢ S is a finite set of game states. In single ghost Collaborative Ghostbuster, the state consists of the positions of the
human player, the assistant and the ghost.
â€¢ A is a finite set of actions available to the players; each
action a âˆˆ A could be a compound action of both players.
If each of the human player and the assistant has 4 moves
(north, south, east and west), A would consist of the 16
possible combination of both playersâ€™ moves.
â€¢ Ta (s, s0 ) = P (st+1 = s0 |st = s, at = a) is the probability that action a in state s at time t will lead to state s0
at time t + 1. The human and assistant move deterministically in Collaborative Ghostbuster but the ghost may
move to a random position if there are no agents near it.
â€¢ Ra (s, s0 ) is the immediate reward received after the state
transition from s to s0 triggered by action a. In Collaborative Ghostbuster, a non-zero reward is given only if the
ghost is killed in that move.
The aim of solving an MDP is to obtain a policy
maximizes the expected cumulative reward
PâˆžÏ€ that
t
t=0 Î³ RÏ€(st ) (st , st+1 ) where 0 < Î³ < 1 is the discount
factor.
Value Iteration. An MDP can be effectively solved using a simple algorithm proposed by Bellman in 1957 (Bellman 1957). The algorithm maintains a value function V (s),
where s is a state, and iteratively updates the value function
using the equation
!
X
0
0
0
Vt+1 (s) = max
Ta (s, s )(Ra (s, s ) + Î³Vt (s )) .
a

s0

Intractability. One key issue that hinders MDPs from being widely used in real-life planning tasks is the large state
space size (usually exponential in the number of state variables) that is often required to model realistic problems.
Typically in game domains, a state needs to capture all essential aspects of the current configuration and may contain
a large number of state variables. For instance, in a Collaborative Ghostbuster game with a maze of size m (number
of valid positions) consisting of a player, an assistant and n
ghosts, the set of states is of size O(mn+2 ), which grows
exponentially with the number of ghosts.

Subtasks
To handle the exponentially large state space, we decompose
a task into smaller subtasks and use intention recognition to
track the current subtask that the player is trying to complete.

Figure 2: Task decomposition in Collaborative Ghostbuster.
In Collaborative Ghostbuster, each subtask is the task of
catching a single ghost, as shown in Figure 2. The MDP for
a subtask consists of only two players and a ghost and hence
has manageable complexity.

Human Model of Action Selection In order to assist effectively, the AI agent must know how the human is going to
act. Without this knowledge, it is almost impossible for the
AI to provide any help. We assume that the human is mostly
rational and use the Q-function to model the likely human
actions.
Specifically, we assume
maxaAI Qâˆ—
i (si ,ahuman ,aAI )

P (ahuman |wi , si ) = Î±.e
(1)
where Î± is the normalizing constant, wi represents subtask i
and si is the state in subtask i. Note that we assume that the
human player knows the best response from the AI sidekick
and plays his part in choosing the action that matches the
most valued action pair. However, the human action selection can be noisy, as modelled by Equation (1).

Intention Recognition and Tracking
We use a probabilistic state machine to model the subtasks
for intention recognition and tracking. At each time instance, the player is likely to continue on the subtask that
he or she is currently pursuing. However, there is a small
probability that the player may decide to switch subtasks.
This is illustrated in Figure 3, where we model a human
player who tends to stick to his chosen sub-goal, choosing
to solve the current subtask 80% of the times and switching
to other sub-tasks 20% of the times. The transition probability distributions of the nodes need not be homogeneous, as
the human player could be more interested in solving some
specific subtask right after another subtask. For example, if
the ghosts need to be captured in a particular order, this constraint can be encoded in the state machine. The model also
allows the human to switch back and forth from one subtask
to another during the course of the game, modelling change
of mind.

where T (wj â†’ wi ) is the switching probability from subtask j to subtask i.
Next, we compute the posterior belief distribution using
Bayesian update, after observing the human action a and
subtask state si,t at time t, as follows:
Bt (wi |at = a, st , Î¸tâˆ’1 ) = Î±.Bt (wi |Î¸tâˆ’1 ).P (at = a|wi , si,t )
(3)
where Î± is a normalizing constant. Absorbing current human action a and current state into Î¸tâˆ’1 gives us the game
history Î¸t at time t.
Complexity This component is run in real time, and thus
its complexity dictates how responsive our AI is. We are
going to show that it is at most O(k 2 ), with k being the
number of subtasks.
The first update step as depicted in Equation 2 is executed
for all subtasks, thus of complexity O(k 2 ).
The second update step as of Equation 3 requires the computation of P (at = a|wi , si ) (Equation 1), which takes
O(|A|) with A being the set of compound actions. Since
Equation 3 is applied for all subtasks, that sums up to
O(k|A|) for this second step.
In total, the complexity of our real-time Intention Recognition component is O(k 2 + k|A|), which will be dominated
by the first term O(k 2 ) if the action set is fixed.

Decision-theoretic Action Selection
Given a belief distribution on the players targeted subtasks
as well as knowledge to act collaboratively optimally on
each of the subtasks, the agent chooses the action that maximizes its expected reward.
(
)
X
i
âˆ—
Bt (wi |Î¸t )Qi (st , a)
a = argmaxa
i

CAPIR: Collaborative Action Planner with
Intention Recognition
We implement the scalable decision theoretic framework
as a toolkit for implementing collaborative games, called
Collaborative Action Planner with Intention Recognition
(CAPIR).
Figure 3: A probabilistic state machine, modeling the transitions between subtasks.
Belief Representation and Update The belief at time t,
denoted Bt (wi |Î¸t ), where Î¸t is the game history, is the conditional probability of that the human is performing subtask
i. The belief update operator takes Btâˆ’1 (wi |Î¸tâˆ’1 ) as input
and carries out two updating steps.
First, we obtain the next subtask belief distribution, taking into account the probabilistic state machine model for
subtask transition T (wk â†’ wi )
X
Bt (wi |Î¸tâˆ’1 ) =
T (wj â†’ wi )Btâˆ’1 (wj |Î¸tâˆ’1 )
(2)
j

CAPIRâ€™s Architecture
Each game level in CAPIR is represented by a GameWorld
object, which consists of two Players and multiple SubWorld
objects, each of which contains only the elements required
for a subtask (Figure 4). The game objective is typically to
interact with these NPCs in such a way that gives the players the most points in the shortest given time. The players
are given points in major events such as successfully killing
a monster-type NPC or saving a civilian-type NPC â€“ these
typically form the subtasks.
Each character in the game, be it the NPC or the protagonist, is defined in a class of its own, capable of executing
multiple actions and possessing none or many properties.
Besides movable NPCs, immobile items, such as doors or

Figure 4: GameWorldâ€™s components.
shovels, are specified by the class SpecialLocation. GameWorld maintains and updates an internal game state that captures the properties of all objects.
At the planning stage, for each SubWorld, an MDP is generated and a collaboratively optimal action policy is accordingly computed (Figure 5). These policies are used by the AI
assistant at runtime to determine the most appropriate action
to carry out, from a decision-theoretic viewpoint.







   
  

   

   





  
   

 

   

!  "#

$ $     

"#   

(
'


%

&

Figure 5: CAPIRâ€™s action planning process. (a) Offline subtask Planning, (b) in-game action selection using Intention
Recognition.

busters. We chose five levels (see Appendix) with roughly
increasing state space size and game play complexity to assess how the technique can scale with respect to these dimensions.
The participants were requested to play five levels of the
game as Shepherd twice, each time with a helping Dog controlled by either AI or a member of our team, the so-called
human expert in playing the game. The identity of the dogâ€™s
controller was randomized and hidden from the participants.
After each level, the participants were asked to compare
the assistantâ€™s performance between two trials in terms of
usefulness, without knowing who controlled the assistant at
which turn.
In this set of experiments, the playerâ€™s aim is to kill three
ghosts in a maze, with the help of the assistant dog. The
ghosts stochastically1 run away from any protagonists if they
are 4 steps away. At any point of time, the protagonists could
move to an adjacent free grid square or shoot; however, the
ghosts only take damage from the ghost-buster if he is 3
steps away. This condition forces the players to collaborate
in order to win the game. In fact, when we try the game with
non-collaborative dog models such as random movement,
the result purely relies on chance and could go on until the
time limit (300 steps) runs out, as the human player hopelessly chases ghosts around obstacles while the dog is doing
some nonsense at a corner. Oftentimes the game ends when
ghosts walk themselves into dead-end corners.
The twenty participants are all graduate students at our
school, seven of whom rarely play games, ten once to twice
a week, and three more often.
When we match the answers back to respective controllers, the comparison results take on one of three possible
values, being AI assistant performing â€œbetterâ€, â€œworseâ€ or
â€œindistinguishableâ€ to the human counterpart. The AI assistant is given a score of 1 for a â€œbetterâ€, 0 for an â€œindistinguishableâ€ and -1 for a â€œworseâ€ evaluation.
Qualitative evaluation For simpler levels 1, 2 and 3, our
AI was rated to be better or equally good more than 50%
the times. For level 4, our AI rarely got the rating of being
indistinguishable, though still managed to get a fairly competitive performance. Subsequently, we realized that in this
particular level, the map layout is confusing for the dog to
infer the humanâ€™s intention; there is a trajectory along which
the human playerâ€™s movement could appear to aim at any
one of three ghosts. In that case, the dogâ€™s initial subtask belief plays a crucial role in determining which ghost it thinks
the human is targeting. Since the dogâ€™s belief is always initialized to a uniform distribution, that causes the confusion.
If the human player decides to move on a different path, the
AI dog is able to efficiently assist him, thus getting good ratings instead. In level 5, our AI gets good ratings only for
less than one third of the times, but if we count â€œindistinguishableâ€ ratings as satisfactory, the overall percentage of
positive ratings exceeds 50%.

Experiment and Analysis
In order to evaluate the performance of our AI system, we
conducted a human experiment using Collaborative Ghost-

1
The ghosts run away 90% of the times and perform some random actions in the remaining 10%.

12	
 Â 
10	
 Â 
8	
 Â 
-Â­â€1	
 Â 

6	
 Â 

0	
 Â 
1	
 Â 

4	
 Â 
2	
 Â 
0	
 Â 
1	
 Â 

2	
 Â 

3	
 Â 

4	
 Â 

5	
 Â 

Figure 6: Qualitative comparison between CAPIRâ€™s AI assistant and human expert. The y-axis denotes the number of
ratings.
120	
 Â 
100	
 Â 
80	
 Â 

AI	
 Â 

60	
 Â 

Human	
 Â 

40	
 Â 
20	
 Â 
0	
 Â 
1	
 Â 

2	
 Â 

3	
 Â 

4	
 Â 

5	
 Â 

Figure 7: Average time, with standard error of the mean as
error bars, taken to finish each level when the partner is AI
or human. The y-axis denotes the number of game turns.
Quantitative evaluation Besides qualitative evaluation,
we also recorded the time taken for participants to finish
each level (Figure 7). Intuitively, a well-cooperative pair
of players should be able to complete Collaborative Ghostbusterâ€™s levels in shorter time.
Similar to our qualitative result, in levels 1, 2 and 3, the
AI controlled dog is able to perform at near-human levels in
terms of game completion time. Level 4, which takes the
AI dog and human player more time on average and with
higher fluctuation, is known to cause confusion to the AI
assistantâ€™s initial inference of the humanâ€™s intention and it
takes a number of game turns before the AI realizes the true
target, whereas our human expert is quicker in closing down
on the intended ghost. Level 5, larger and with more escape
points for the ghosts but less ambiguous, takes the protagonist pair (AI, human) only 4.3% more on average completion
time.

Related Work
Since plan recognition was identified as a problem on its
own right in 1978 (Schmidt, Sridharan, and Goodson 1978),
there have been various efforts to solve its variant in different domains. In the context of modern game AI research,
Bayesian-based plan recognition has been inspected using

different techniques such as Input Output Hidden Markov
Models (Gold 2010), Plan Networks (Orkin and Roy 2007),
text pattern-matching (Mateas and Stern 2007), n-gram and
Bayesian networks (Mott, Lee, and Lester 2006) and dynamic Bayesian networks (Albrecht, Zukerman, and Nicholson 1998). As far as we know, our work is the first to use
a combination of precomputed MDP action policies and online Bayesian belief update to solve the same problem in a
collaborative game setting.
Related to our work in the collaborative setting is the work
reported by Fern and Tadepalli (Fern and Tadepalli 2010)
who proposed a decision-theoretic framework of assistance.
There are however several fundamental differences between
their targeted problem and ours. Firstly, they assume the task
can be finished by the main subject without any help from
the AI assistant. This is not the case in our game, which
presents many scenarios in which the effort from one lone
player would amount to nothing and a good collaboration
is necessary to close down on the enemies. Secondly, they
assume a stationary human intention model, i.e. the human
only has one goal in mind from the start to the end of one
episode, and it is the assistantâ€™s task to identify this sole intention. In contrary, our engine allows for a more dynamic
human intention model and does not impose a restriction on
the freedom of the human player to change his mind mid
way through the game. This helps ensure our AIâ€™s robustness when inferring the human partnerâ€™s intention.
In a separate effort that also uses MDP as the game AI
backbone, Tan and Cheng (Tan and Cheng 2010) model the
game experience as an abstracted MDP - POMDP couple.
The MDP models the game worldâ€™s dynamics; its solution
establishes the optimal action policy that is used as the AI
agentâ€™s base behaviors. The POMDP models the human play
style; its solution provides the best abstract action policy
given the human play style. The actions resulting from the
two components are then merged; reinforcement learning is
applied to choose an integrated action that has performed
best thus far. This approach attempts to adapt to different
human play styles to improve the AI agentâ€™s performance. In
contrast, our work introduces the multi-subtask model with
intention recognition to directly tackle the intractability issue of the game worldâ€™s dynamics.

Conclusions
We describe a scalable decision theoretic approach for constructing collaborative games, using MDPs as subtasks and
intention recognition to infer the subtask that the player is
targeting at any time. Experiments show that the method is
effective, giving near human-level performance.
In the future, we also plan to evaluate the system in more
familiar commercial settings, using state-of-the-art game
platforms such as UDK or Unity. These full-fledged systems offer development of more realistic games but at the
same time introduce game environments that are much more
complex to plan. While experimenting with Collaborative
Ghostbuster, we have observed that even though Value Iteration is a simple naive approach, in most cases, it suffices,
converging in reasonable time. The more serious issue is the

state space size, as tabular representation of the states, reward and transition matrices takes much longer to construct.
We plan to tackle this limitation in future by using function
approximators in place of tabular representation.

Appendix
Game levels used for our experiments.

Acknowledgments
This work was supported in part by MDA GAMBIT grant R252-000-398-490 and AcRF grant T1-251RES0920 in Singapore. The authors would like to thank Qiao Li (NUS),
Shari Haynes and Shawn Conrad (MIT) for their valuable
feedbacks in improving the CAPIR engine, and the reviewers for their constructive criticism on the paper.





This paper outlines a methodology for
analyzing the representational support
for
knowledge-based
decision-modeling
in a broad domain. A relevant set of inference
patterns and knowledge types are identified.
By comparing the analysis results to existÂ­
ing representations, some insights are gained
into a design approach for integrating cateÂ­
gorical and uncertain knowledge in a contextÂ­
sensitive manner.
1

Introduction

Research in knowledge-based decision systems
(KBDS) combines artificial intelligence and decision
analysis techniques to solve problems involving choice
and uncertainty. The dynamic decision-modeling apÂ­
proach in KBDS advocates that the decision modÂ­
els for different problems should be dynamically conÂ­
structed from a knowledge base [Breese, 1989, WellÂ­
man, 1990a]. This approach facilitates scalability and
reusability of the knowledge bases. Moreover, the reÂ­
sulting decision models are context-sensitive and inÂ­
clude only the relevant information specific to the
problems. To date, however, while much progress has
been made in improving the algorithms for manipulatÂ­
ing decision models, the automated model construcÂ­
tion process remains to be formalized.
This paper characterizes the knowledge for supporting
dynamic decision-modeling in medicine. CharacterÂ­
izing such knowledge illuminates the representational
and computational requirements for automating deciÂ­
sion analysis in a broad domain. Unlike previous efÂ­
forts, instead of concentrating on the structural comÂ­
ponents of the decision model such as nodes, condiÂ­
tional probabilities, and influences, we focus on the
ontological features of the decision problem such as
contexts, classes of observed events, classes of available
actions, classes of possible outcomes, temporal preceÂ­
dence, and probabilistic and contextual dependencies.

By gaining insights into the nature of decisions, this
exercise serves as a step toward developing a formal
methodology for requirement analysis and realizing a
uniform representation framework for supporting dyÂ­
namic decision-modeling in KBDS.
The following discussions are based on the general sysÂ­
tem architecture depicted in Figure 1. Given a probÂ­
lem description, the planner or decision-maker conÂ­
structs a decision model by accessing information conÂ­
tained in the knowledge base. The domain and the
decision-analytic components of the knowledge base
are integrated by the knowledge-base manager, which
also serves as an interface to the planner.
The decision models considered are qualitative probÂ­
abilistic networks (QPNs) [Wellman, 1990b). Since
QPNs are the qualitative variants of influence diaÂ­
grams, and since each influence diagram can be transÂ­
formed into a decision tree, our results are expected to
be generalizable to other decision models.

M Domain
a
KB
n
a
g
e Decisionanalytic
r
KB
Figure 1: A Knowledge-Based Decision System
In the subsequent sections, we present a medical deÂ­
cision problem and examine the reasoning and repÂ­
resentational issues involved in the decision analysis
process. Some ideas on integrating context-sensitive
categorical and uncertain knowledge will be explored
and compared to relevant representation frameworks.

Representation Requirements for Supporting Decision Model furmulation

2

An Example

Table 1: Characterized Background Information

A simplified medical decision roblem ( Beck and
Pauker, 1981, Tsevat et al., 1989 is shown below:

r

Category

Concepts

General history
Signs and Symptoms
Laboratory findings
Diseases
Alternatives
Com pli cation s

80 year old, female
Fainting, arrythmia

The patient is an 80 year-old woman. She complained
of fainting and was found to have irregular heartbeats,
or arrythmia. A diagnosis of cardiomyopathy, i.e., disÂ­
order of the heart muscles was made. Such a disorder
usually leads to embolism, or formation of blood clots
in the patient's body. The problem is to determine if
anticoagulant therapy should be administered to reduce
the chance of embolism, given the high risk of bleeding
complications in the elderly.
Each relevant event in the decision problem can be reÂ­
garded as a concept, e.g., SO-year-old, cardiomyopathy,
anticoagulant-therapy, etc. A concept is an event or a
random variable in the probabilistic sense; it denotes
an abstract description of an object, an attribute, a
state of being or a process, depending on the circumÂ­
stances.
3

The Decision Making Process

Given a set of input concepts, the goal for the proposed
KBDS is to construct a decision model such as the one
shown in Figure 2, and then evaluate the feasibility of
the alternatives with respect to some criteria,e.g., lifeÂ­
expectancy, expected monetary value, etc.
More formally, the decision-analytic approach to deÂ­
cision making can be viewed as a five-step process:
1) Background characterization; 2) context establishÂ­
ment; 3) problem formulation; 4) model construction;
and 5) Model evaluation.
3.1

Background Information
Characterization

The process begins by classifying the input concepts
into the variables concerned, the actions available, and
the possible outcomes involved in a decision problem.
In the clinical setting, the input concepts can usually
be divided into six categories, as shown in Table 1 for
our example.
The planner can characterize each input concept by
asking questions like:
â€¢
â€¢

Is fainting a kind of sign or symptom?
Is cardiomyopathy a kind of disease?

To answer the above queries, the knowledge-base must
support categorizations of the relevant domain conÂ­
cepts. A categorization is a grouping of concepts with
similar descriptions in a particular dimension. ExÂ­
amples of such groupings include those induced by
the specialization (AKO) relation, the decomposition
(PARTOF) relation, etc.

Cardiomyopathy
Anticoagulant-therapy
Embolism, bleeding

The characterized background information, however,
is insufficient for formulating a decision model. For
instance, in our example, the relationships among the
input concepts are not explicitly stated, the two relÂ­
evant kinds of embolism being considered, systemic
and pulmonary embolisms, are not specified, and the
evaluation criteria are not mentioned. The missing inÂ­
formation, which may be related to the domain or the
decision-analytic methodology, must be derived when
necessary.
3.2

Domain Context Establishment

Establishing the context 1 means defining the task enÂ­
vironment in which the problem is to be solved. This
enables different problem situations to be considered
and sets limits on the possible operations that can be
applied to a given problem [Kassirer and Kopelman,
1987). The context is selected with only a few clues
[ Kassirer and Garry, 1978). In the clinical setting, a
context is usually indicated by a suspected disease, a
syndrome, i.e., a set of signs and symptoms that conÂ­
vey special meanings, or a general diagnostic category,
e.g., an acute respiratory disorder [ Kassirer and KopelÂ­
man, 1987).
In our example, the clinical context is "cardiomyopaÂ­
thy in old-age." This context is established by idenÂ­
tifying the suspected diseases and any conditions that
might significantly affect their nature.
Given the characterized background information, idenÂ­
tifying the suspected diseases simply involves looking
them up in the set of input concepts. For now, we asÂ­
sume that other significant conditions, e.g., old-age in
our example, are specified by an oracle. Recognizing
these conditions automatically requires a very sophisÂ­
ticated planner, and the issues involved are outside the
scope of this paper.
The main purpose of establishing a context is to al1 This

1989,

[

is different from the decision context Breese,
Holtzman,
which refers to all the assumptions,

1989]

constraints, variables, and alternatives considered in the
decision problem.

213

214

Leong

Figure 2: A QPN For The Example
low access to the context-sensitive information. For
instance, in older patients, cardiomyopathy may have
different manifestations and more severe complications
than in younger patients, or in the presence of other
diseases. Therefore, such context-sensitive knowledge
must be expressible in the knowledge base.
3.3

Decision Problem Formulation

Guided by the characterized background information,
a decision problem is formulated within the domain
context by identifying:
â€¢

â€¢
â€¢

â€¢
â€¢

â€¢

all or the most important diseases/hypotheses
that may be involved;
the relative significance of all these concepts;
all
or
the
most
important
possible
outcomes/ complications of these concepts;
all or the most important actions available;
the effects of the actions on the concepts and their
outcomes and possible complications; and
the evaluation criteria.

Table 2 shows all the relevant concepts in our examÂ­
ple. "Pulmonary embolism" and "systemic embolism"
are among the values of the corresponding "embolism"
node in Figure 2.

Table 2: Concepts Involved in Decision Problem
Old-age
Cardiomyopathy
Fainting
Arrythmia
Embolism
Pulmonary-embolism
Systemic-embolism

Anticoagulant-therapy
Bleeding
Long-term-morbidity
Short-term-morbidity
Mortality
Quality-adjustedlife-expectancy

These concepts are derived by asking questions like:
â€¢

What are the most common embolisms caused by
cardiomyopathy?

â€¢

What are the other (if any) complications of
anticoagulant-therapy?

To answer the above queries, the knowledge base
must, in addition to supporting categorizations of
the domain concepts, allow expression of the interÂ­
actions, i.e., the correlational/influential/causal relaÂ­
tions, among these concepts. The varying degrees
of significance for all these relations in different con-

Representation Requirements for Supporting Decision Model furmulation

texts must also be expressible in the knowledge base.
This, together with the varying degrees of temporal
and probabilistic dependencies among the interactions,
would facilitate derivation of the most relevant inforÂ­
mation for the problem at hand.
3.4

Decision Model Construction

As mentioned, a decision model for our example is
shown in Figure 2.
To construct such a decision model, its structure, e.g.,
nodes and links in a QPN, and its preference model,
e.g., evaluation criteria such as morbidity, mortality,
and monetary costs associated with utilities, must be
inferrable from the knowledge base. The temporal conÂ­
straints on the decision model structure, i.e., the orÂ­
der in which the concepts and their consequences are
to be considered, should also be inferrable from the
interactions of the underlying concepts. Hence, the
construction involves asking questions like:
â€¢

â€¢

How are the observable effects of the alternatives
relate to the chance events?
What are the outcomes that affect the evaluation
criteria?

To support these queries, the relevant interactions
among the concepts must be expressible in the knowlÂ­
edge base. These interactions involve both domain
concepts and decision-analytic concepts, e.g., "presÂ­
ence of disease positively-influences morbidity."
3.5

Decision Model Evaluation

Upon completion, the decision model is evaluated by
some procedure with respect to the evaluation criteria.
Here, evaluation of a decision model refers to solving
the model with procedures such as folding back of a
decision tree, or graph reduction of a QPN. The evalÂ­
uation criterion assumed in our example is qualityÂ­
adjusted life expectancy, i.e., a measure of time reÂ­
maining in a patient's life, taking into account the inÂ­
conveniences caused by the illness (morbidity). Given
a well-formed decision model, only procedural knowlÂ­
edge is needed in this step.
Summary of Inference Patterns and

4

Representation Requirements

The above analysis shows that four types of general
inference patterns are involved in the automated deciÂ­
sion analysis process:
â€¢
â€¢

â€¢

(Ql) Does concept A related to concept B in 0
(Q2) What are the concepts related to concept A
in 0?
(Q3) Does concept A relate to concept B by i?

â€¢

(Q4) What are the concepts related to concept A
by i?

where 0 is a categorization and i is an interaction.
Three types of knowledge are required to support these
inferences: categorical knowledge, uncertain knowlÂ­
edge, and a notion of "context."
4.1

Categorical Knowledge

The categorical knowledge captures the definitional or
structural relations of the concepts, allowing expresÂ­
sion of facts such as: "cardiomyopathy is a kind of
disease" and "pulmonary embolism is a kind of emÂ­
bolism." This type of knowledge should provide the
system with the power of abstraction and inheritance.
In other words, knowing a class of concepts would alÂ­
low the planner to derive its subclasses, and vice versa.
Furthermore, the generic description for a class of conÂ­
cepts can be specified at an appropriate level of abÂ­
straction; portions of this description can be inheritaÂ­
ble by its subclasses or superclasses.
4.2

Uncertain Knowledge

The uncertain knowledge captures the interactions,
i.e., the correlational, influential, or causal relations
among the concepts, allowing expression of facts such
as: "presence of anticoagulant-therapy negativelyÂ­
influences presence of embolism" and "cardiomyopaÂ­
thy causes arrythmia." This type of knowledge should
provide the system with the power of differentiation
by accommodating a spectrum of temporal and probÂ­
abilistic dependencies among the concepts. By comÂ­
paring the relational strengths, the planner would be
able to deduce the certainty and usefulness of the inÂ­
formation derived from the knowledge base.
4.3

A Contextual Notion

In addition to the categorical and uncertain knowlÂ­
edge, a notion of "context" should be included in the
knowledge base. This contextual notion has the folÂ­
lowing properties:
1. It sets a boundary on the relevant categorical and
uncertain knowledge, and can be regarded as a
focusing mechanism. This enables the planner
to look for different information in different sitÂ­
uations. For instance, the old-age of a patient
would lead to the focus on a particular set of comÂ­
plications for cardiomyopathy and anticoagulantÂ­
therapy.
2. It allows differentiation of the relational signifiÂ­
cance, both categorical and interactional, among
a set of concepts; the relative relevance and imÂ­
portance of the information can thus be disÂ­
tinguished in different situations. For example,

215

216

Leong

bleeding is the most important complication of
anticoagulant-therapy in the context of cardiomyÂ­
opathy in old-age.
3. It is compositional and can be defined hierarchiÂ­
cally. In other words, multiple, interacting conÂ­
texts may coexist and a context can be defined
within another context. For example, "cardiomyÂ­
opathy" and "old-age" combine to form the conÂ­
text of "cardiomyopathy in old-age"; the latter,
in turn, is a subcontext of "disease in old-age."
5

A Representation Design

We now propose a representation design that would
meet the requirements for supporting the inferences
Ql-Q4 in a context-sensitive manner.
5.1

Representation of Concepts

In our framework, a concept is an intensional descripÂ­
tion of the relational interpretation of an object, a
state, a process, or an attribute of these phenomÂ­
ena. In other words, a concept reflects the salient
features of the underlying phenomenon through a
set of interactions with other concepts. These relÂ­
evant concepts are called the properties of the conÂ­
cept being described. For example, the description
of the concept disease2 includes properties such as
severity, manifestation, and treatment, as well
as interactions such as "presence-of-disease causes
and
presence-of-manifestation-of-disease"
''presence-of-treatment-of-disease
negativelyÂ­
influences severity-of-disease."
5.1.1

Properties of Concepts

The properties of a concept include its inherent qualÂ­
ities, characteristics, and other relevant concepts that
constitute its description e.g., size (of a tumor)
and treatment (of a disease). Each property is a
concept3 itself. Each property of a concept has a list
of values, which are also concepts themselves.
To incorporate context-dependent information, a
new concept can be derived from each propÂ­
erty of a concept.
For example, the concept
treatment-of-cardiomyopathy is derived from the
property treatment of cardiomyopathy. This new
derived-concept has a description constrained by
the concept it is derived from; the two concepts
are related by the context (CXT) relation to be
described below.
Compositions of the CXT reÂ­
lation enable "chaining" of the derived-concepts,
e.g., duration-of-treatment-of-cardiomyopathy,
2 All

concepts

defined in our framework

will

enced in typevri ter type style.
3 Referred

to

as

property-concept from now on.

be

referÂ­

presence-of-complications-of-Â­
treatment-of-cardiomyopathy, etc.

formable in this way.

, are concepts

The properties of a concept in this framework are
analogous to the roles in term subsumption languages
and the slots in frame-based languages. The difÂ­
ference is that the properties alone do not comÂ­
pletely describe a concept; they serve only as inÂ­
dices to the interactions that constitute the meanÂ­
ing of a concept. These interactions are expressed
in terms of the corresponding derived-concepts,
e.g., "duration-of-treatment-of-cardiomyopathy
negatively-influences severity-of-cardiomyopathy
is an interaction in the description of cardiomyopathy.
5.1.2

Interactions of Concepts

Each interaction between two concepts has two comÂ­
ponents: temporal precedence, with "known" or "unÂ­
known" as values, and qualitative probabilistic influÂ­
ence [Wellman, 1990b], with "positive," "negative,"
and "unknown" as values. The interactions can thus
be expressed as four types of links in a network inÂ­
terpretation of our framework: associational links,
which denote probabilistic correlation with an unÂ­
known type of influence and unknown temporal preceÂ­
dence; precedence links, which denote temporal preceÂ­
dence with unknown type of probabilistic influence; inÂ­
fluential links, which denote conditional probabilistic
dependencies; and causal/inhibitive links, which deÂ­
note known temporal precedence in addition to known
type of probabilistic influences.
5.2

Categorization of Concepts

The description of a concept can be constrained by a
set of categorizers. A categorizer is a categorical or
class relationship; it is a binary relation that speciÂ­
fies the properties and the interactions of a concept in
terms of those of another concept. By imposing a parÂ­
tial order on the related concepts, a categorizer estabÂ­
lishes a unique perspective for describing each concept.
For example, a concept can be described as "a kind of'
another concept or "a part of' another concept. Some
common categorizers include the specialization (AKO)
relation, the decomposition (PARTOF) relation, and the
equivalence (EQV) relation.
All the concepts related by a categorizer are said to be
in a categorization; some categorizations have hierarÂ­
chical interpretations, while others are more naturally
seen as networks. By knowing the position of a parÂ­
ticular concept with respect to another concept in a
categorization, the description of the former can be
inferred from the latter. This descriptive inference in
a categorization is called inheritance.
For instance, the specialization relation can be defined
as follows:

Representation Requirements for S\lpporting Decision Model Furmulation

Let C be the set of
all concepts. Let 0 be the set of categorizers. Let Ow ï¿½
C be the set of concepts in a categorization related by
categorizer w E 0. For all a,bE C, and for AKOE 0
where AKO <; C x C:
Definition .1 (Specialization)

1.

AKO dï¿½ {(a, b)la C b, i.e., Vo:, a: E a
b} .

2.

Let ako: C--+ Z: be a function defined on AKO:
ako(a)

=

=> a:

E

{bl(a, b)E AKO}.

Two major properties are observed for the AKO cateÂ­
gorizer:

1. a E 0AKO <==> 3b,(a,b) E AKO or (b, a) E
AKO.
2. The AKO relation is irreflexive, 88ymmetric, and
transitive.
3. The properties and interactions of the concepts
are downward inheritable in the specialization hiÂ­
erarchy.
5.3

Context-Dependent Representation

The categorizers establish some general perspecÂ­
For example, a
tives for describing a concept.
pulmonary-embolism is a kind of embolism in general.
The description of a concept in these general perspecÂ­
tives is further constrained by a set of contexts.
A context (CXT) relation can be thought of 88 a
"meta-categorizer;" it is a binary relation that specÂ­
ifies the properties and the interactions of, and
hence also the categorizers on a concept in acÂ­
cordance with those of another concept.
For
example, treatment-of-cardiomyopathy is speciÂ­
fied 88 a kind of treatment-of-disease because
treatment-of-cardiomyopathy is defined in the conÂ­
text of cardiomyopathy, and cardiomyopathy is a
kind of disease. All concepts are described in some
contexts; the descriptions that are valid in general are
in the universal context. Therefore, the (CXT) relation
facilitates representation of context-sensitive informaÂ­
tion, 88 mentioned earlier, by allowing chaining of
derived-concepts and constraining their descriptions.
The partial-ordering imposed by this relation forms a
context-hierarchy of all the concepts in the knowledge
b88e.
6

Supporting General Inferences

B88ed on the above representation framework, we shall
now discuss how the knowledge base of the proposed
KBDS would provide answers for the inferences QlÂ­
Q4. In the following discussions:

1. Let C be the set of all concepts.

2. Let 0 = {AKO,...}=the set of all categorizers.
3. Let :Fo = {fw lfw is a function defined on w, VwE
0} = {ako,...} 88 defined in Section 5.2.
4. Let
I
=
{association,
precedence, positive-influence, negative-influence,
cause, inhibitor }=the set of all interaction types.
5. ViE I, let :Fz = {/;If ; is a function defined on i}
6. Vf; E Fz, i E I,a,bE C, f;(a) = {bl(a,b)V(b, a)E
i}.
â€¢

Ql: Does concept A relate to concept B by
<categorizer>?

To find out if two concepts A and B are related in an
categorization, let Wo E 0 be the categorizer in quesÂ­
tion.
Answerql =

{ yes
no

if (A,B) E w0
otherwise.

An example of the Ql query is: Does cardiomyopathy
related to disease by specialization? The answer is:
yes.
â€¢

Q2: What are the concepts related to concept A
by <categorizer>?

To find out the concepts related to a concept A in an
categorization, again let Wo E 0 be the categorizer in
question.
Answerq2 = fw.(A).
An example of the Ql query is: What are the conÂ­
cepts that are related to embolism by specializaÂ­
tion? The answers are: pumonary-embolism and
systemic-embolism.
â€¢

Q3: What are the concepts that relate to concept
A by <interaction>?

To find out the concepts that directly interact with a
concept A in an interaction, let i0 E I be the interacÂ­
tion in question.
Answerqa = /;0(A).
An example of the Q3 query is: What are the concepts
that relate to complication-of-anticoagulant-Â­
therapy by positive-influence?
The answer is:
presence-of-old-age.
â€¢

Q4: Does concept A relate to concept B by
<interaction>?

To find out whether two concepts A and tt B are inÂ­
volved in an interaction, again let io E I be the interÂ­
action in question.

217

218

Leong

Answerq4

=

{ yes
no

if (A, B) E io
otherwise.

An example Q4 query is: Does cardioJDyopathy relate
to fainting by cause? (Read: Does cardioJDyopathy
cause fainting? ) The answer is: yes.
For simplicity, all the answers to the above inferences
assume a closed world assumption, i.e., a negative
answer will be returned if a relation is not explicÂ­
itly derivable from the knowledge base. The contextÂ­
sensitivity of the answers, though not very obvious, is
actually inherent from the underlying representation.
7

Related Work

The major shortcomings of the static decisionÂ­
modeling approach, i.e., treating pre-enumerated deÂ­
cision models or templates as knowledge bases, result
from the rigidity of the knowledge bases. Constrained
by the structure of the decision models, e.g., nodes and
links of a decision tree, such knowledge bases do not
reflect the nature of the domain knowledge.
The different representations used in existing KBDS
with the dynamic decision-modeling approach are not
very satisfactory, either. The first order logic-like
representations, such as those employed by Breese
[1987, 1989], and Goldman and Charniak [1990], have
no explicit hierarchical dimensions. In these frameÂ­
works, multi-level decision models are created by acÂ­
tivation of a set of rules; limited contextual informaÂ­
tion is captured as conditional probabilities matrices
in these rules.
In Wellman's [1990a] SUDO-PLANNER system, doÂ­
main descriptions can be expressed in multiple levels of
precision in this framework, thus facilitating decisionÂ­
modeling in multiple levels of abstraction. The terÂ­
minological component of this framework, however, is
subjected to the limited expressiveness of most term
subsumption languages. Moreover, the purely probaÂ­
bilistic nature of the effects or influences does not reÂ­
flect the varying degrees of significance among the conÂ­
cepts with respect to the problem at hand. Although
some contextual effects on the influences can be exÂ­
pressed in the qualitative synergies defined in QPN,
there is no general mechanism for capturing contexÂ­
tual information in the whole framework.
Other relevant representation formalisms include those
that incorporate an uncertainty model to a hierarchical
representation framework. Most hierarchical represenÂ­
tations are designed to support derivation of absolute
or categorical answers. To support approximate reaÂ­
soning, i.e., finding out facts that are not absolutely
true or false, but believed to a certain degree, some
efforts attempt to accommodate an uncertainty model
by re-interpreting the semantics of a categorical repreÂ­
sentation, while others try to couple the two to form

a coherent framework.
For instance, in the network representation developed
by Lin and Goebel [1990], both subsumption and
causal relationships are expressible. Probabilistic inÂ­
terpretations are given to parts of the causal network,
called the scenarios. These scenarios can be considÂ­
ered as contexts with different probability distribuÂ­
tions. Although the scenarios are not hierarchically
arranged, their probabilistic rankings are preserved
across the subsumption relationships. Nevertheless,
this network formalism does not allow the properties,
and hence the nature of each node or concept to be
explicitly represented.
Yen and Bonissone's [1990] work attempts to generalÂ­
ize the semantics of term subsumption languages with
an approximate reasoning model, such as fuzzy logic
or possibility theory, to support plausible inferences.
Non-definitional relations among the concepts, howÂ­
ever, are not expressible in these frameworks. There
is also no general notion of context-dependent definiÂ­
tions.
Saffiotti's [1990] hybrid framework, on the other hand,
integrates a component that deals with absolute or catÂ­
egorical knowledge and another with the uncertainty of
this knowledge. Any formal representation formalism
and uncertainty model may constitute the two comÂ­
ponents in the framework, e.g., first-order logic with
Dempster-Shafer theory, term subsumption language
with probability theory, etc. We believe this work is an
important step toward the theoretical foundations of
integrating categorical and uncertain know ledge. The
expressiveness and hence the usefulness of the frameÂ­
work, however, depend solely on the component forÂ­
malisms.
8

Discussion and Conclusion

To support dynamic decision-modeling, the structure
of the knowledge base must reflect the nature of both
the decision problem and the domain knowledge. In
particular, the underlying representation must neither
be restricted by the structural components of the deÂ­
cision models, e.g., nodes and links of an influence diÂ­
agram, nor their evaluation mechanisms, e.g., folding
back of a decision tree. By focusing on the ontology
of a decision problem, we have identified a set of inferÂ­
ence patterns and knowledge types for supporting auÂ­
tomated construction of decision models in medicine.
The brief survey on existing representations has shed
some light on a design approach for integrating cateÂ­
gorical and uncertain knowledge in a context-sensitive
manner. We believe such an integration calls for a
framework with a terminological component, an asserÂ­
tional component, and a network interpretation. By
capturing the context notion via partitioning the netÂ­
work, this framework would allow us to establish tax-

Representation Requirements for Supporting Decision Model furmulation

onomies of structured concepts, state the facts, i.e., the
interactions among the concepts, and answer questions
about these relations.
We have sketched a design outline of such a repreÂ­
sentation in this paper; a more detailed exposition is
described elsewhere [Leong, 1991]. Many important
issues, however, are yet to be explored. In particÂ­
ular, the notion of "context" needs to be more forÂ­
mally defined, many interesting problems arise in the
context-sensitive inheritance patterns of the categorÂ­
ical relations, and the context-sensitive probabilistic
semantics of the interactions needs to be generalized.
Careful examination of these issues, we believe, will
lead to the formalization of both the automated deÂ­
cision model formulation process and the domain and
decision-analytic knowledge involved.
Acknowledgments

The author would like to thank Peter Szolovits for adÂ­
vice on the project, Mike Wellman for many helpful
discussions, Jon Doyle for comments on the mathematÂ­
ical definitions and U.TE]Xformatting, and the anonyÂ­
mous referees for suggestions on the presentation of
this paper.
This research was supported by the National Institutes
of Health grant no. 5 R01 LM04493 from the National
Library of Medicine.



A" hierarchy, and the conditional dependency graph of a
probabilistic network. In other words, current frameworks

Automated decision making is often complicated

only allow us to express context-sensitive knowledge eiÂ­

by the complexity of tlle knowledge involved.

ther in absolute terms or probabilistically, but not both

Much of tllis complexity arises from tlle contextÂ­

(Leong 1991b).

sensitive variations of the underlying phenomÂ­
ena. We propose a framework for representing
descriptive,

context-sensitive

knowledge.

In (Leong 1991b), we have identified the different types of
information required for supporting dynamic, knowledgeÂ­

Our

approach attempts to integrate categorical and

based formulation of decision models in a broad domain.

uncertain knowledge in a network formalism.

Given a decision problem, dynamic decision modeling inÂ­

This paper outlines the basic representation conÂ­

volves selecting a subset of concepts and relations from a

structs, examines tlleir expressiveness and effiÂ­

knowledge base, and assembling them into a closed-world
decision model, e.g

ciency, and discusses tlle potential applications of

.â€¢

an influence diagram (Breese, GoldÂ­

man and Wellman 1991). Our analysis indicated that an

the framework.

appropriate knowledge base representation would be a netÂ­

1

work

INTRODUCTION

We live in a world which is full of variations and excepÂ­
tions. Decision making in our daily lives involves skillfully
manipulating the myriad of phenomena and carefully anaÂ­
lyzing the consequences of each relevant variation or
exception. For instance, in the clinical setting, tlle choice of

formalism

of other complications, tlle regimen of other medications
being prescribed, etc. Hence, to automate the decision
making process, tllere must be a general way to represent
the context-sensitive variations of the relevant information.

categorical

or

absolute

manner.
We propose such a representation design in this paper. The
following information, for example, is expressible in our

framework:

treatment prescription for a particular disease depends on
the general condition of the patient, the presence or absence

integrating

knowledge and uncertain knowledge in a context-sensitive

The Royal Elephant Example

Elephants are gray in color. Royal elephants are a
kind of

elephants. Royal elephants in Thailand

are white in color. Presence of people usually
scares away the elephants. But royal elephants
are nwre likely to be found when there are people

Research in path-based inheritance in hierarchical systems

around. In particular, the King ofThailand always

(Touretzky 1987) and uncertain reasoning with belief netÂ­

demands the royal elephants in Thailand to follow

works

him everywhere.

(Pearl

1988)

has

shed

some

light

on

tlle

characteristics and the complexities of a general frameÂ­
work for reasoning with context-sensitive knowledge. In
particular, network or graph representations are found to be

very effective in expressing the variations and exceptions
involved.
There have been many efforts at integrating categorical or
hierarchical knowledge with uncertain knowledge (Lin and
Goebel 1990)(Saffiotti 1990)(Yen and Bonissone 1990).
No existing framework, however, captures the essence of
both, say, tlle inheritance graph of a specialization or "IS-

While this piece of (fictitious) information may not seem

immediately interesting from the decision making point fo
view, it illustrates some important representation requireÂ­
ments that our framework attempts to capture.

First, the different relevant phenomena must be explicitly
distinguishable, describable, and capable of supporting reaÂ­
soning, e.g., elephant, royal elephant, color of elephant,
gray, white, Thailand, King of Thailand, etc. These descripÂ­

tions would constitute the basic building blocks of the

Representing Context-Sensitive Knowledge

representation framework.
Second, the different categorical or structural relations
among the phenomena must be expressible. Such relations
include the specialization or "a kind of' relation, e.g., royal
elephant is a kind of elephant, and the decomposition or
"part of' relation, the equivalence relation, etc.
Similarly, the different uncertain or behavioral relations
among the phenomena must be expressible. Instances of
such relations, as illustrated in the above example, include
those captured in the English phrases: "usually scares
away", "more likely to be found", and "always follow."

Royal
Elephant I
ThaRand

Lastly, there should be a construct that would capture the
context-dependent notions indicated in the Royal Elephant
Example: Only the royal elephants in Thailand are white in
color, and they can always be found when the King is
around. These facts or descriptions are not applicable to
royal elephants in general.

Figure I: Partial Network Representation of the Royal
Elephant Example

Due to its simplicity, we shall refer to the Royal Elephant

Example throughout this paper to illustrate the major repÂ­
resentation constructs in our framework. Comments on
how these constructs are actually being employed will be
made whenever appropriate.
In the following sections, we shall describe the components

of the proposed framework, and examine some of the moÂ­
tivations behind our design choices. We shall also briefly
d iscus s the typical inferences in automated decision makÂ­
ing supported by the framework, and informally assess its
potential expressiveness, efficiency, and effectiveness.

2

3

REPRESENTATION OF CONCEPTS

In our framework, a concept is an intensional description of
the relational interpretation of an object, a state, a process,
or an attribute of these phenomena. In other words, a conÂ­
cept reflects the salient features of the underlying
phenomenon through a set of interactions, i.e., correlationÂ­
al, influential, or causal relations with other concepts. For
example, the concept royal elephant might comprise the
following relations 1:

A PARTIAL NETWORK
â€¢

Figure 1 depicts some relevant parts of the network repreÂ­
sentation for the Royal Elephant Example in our
framework. In the figure, the nodes represent the phenomÂ­
ena or concepts being described, while the links represent
the relations among the concepts. Only one type of categorÂ­
ical or structural relations is displayed: specialization
(AKO). Three types of uncertain or behavioral relations are
displayed: cause (c), positive-influence (+), and negativeÂ­
influence (-). A third type of relations, the context (CXT)
relation, induces a hypergraph on the network; the transiÂ­
tive-closure of the context relation of a concept constitutes
its description. The (#) and (#*) signs in the figure should
be read as: "of', e.g., "King of Thailand", "Presence of
King of Thailand"; the(#*) sign is simply an abbreviation
of an imp licit chain of the(#) signs.
In contrast to early semantic networks with ad-hoc relaÂ­
tions, to term-subsumption languages with only
subsumption (IS-A) relations, and to belief networks with
only probabilistic relations, our representation design acÂ­
commodates a spectrum of different relations with wellÂ­
defined, though not necessarily formal semantics. We shall
now look at the different components in more details.

â€¢

"aie ofroyalelephantpositively-influences

lenï¿½th ofteeth ofroyalelephant".
"aen!lerofroyalelephant associates-with
sizeofroyalelephant", etc.

In these relations, concepts such as aaeofroyal elephant,
teeth ofroyal elephant aenderofroyal elephant and ï¿½
ofroyalelephants are related to royalelephant via the conÂ­
teX! or CXT relation; they are called the properties of royal
elephant, and in tum may have their own properties, e.g.,
lenï¿½th of teeth of royal elephant is a property of teeth of

royalelephant.
The description of a concept, i.e., its properties and the inÂ­
teractions among them, may be constrained by a set of
categorizers. A categorizer is a categorical or class relaÂ­
tionship which establishes a unique perspective for
describing one concept in terms of another. For example,
asserting the relation: "royalelephant is a kind of elephant"
in the description of royal elephant implies that its properÂ­
ties and their corresponding interactions may have been

1Â· Relations such as: "color of royal elephant is white" are speÂ­
cial case to
ilar way.

this characterization, and can be handled in a simÂ­

167

168

Leong

inherited, in a particular manner, from those of elephant. A

partial network representation of the concept royal eleÂ­
l2ha!!l is shown in Figure 2.

â€¢

"abnonnal" or ''non-general" situations. For instance, in
the decision problem above, if a second disease, say AcÂ­
quired Immune-deficiency Syndrome (AIDS) is present,
the decision maker should consider some subtypes of pneuÂ­
monia which are different from those being considered in
the absence of AIDS.
J.l

â€¢

â€¢

Figure 2: Partial Description of the Royal Elephant
Concept
The rationale behind our design is discussed in detail in
(Leong 199la). In essence, the different relations defined
reflect the characteristics of the knowledge involved in supÂ­
porting dynamic decision modeling.
The interactions capture behavioral relations with varying
degrees of certainty among the concepts; these relations
support the task of identifying infonnation with varying deÂ­
grees of significance in a particular situation. For instance,
in deciding a treatment plan for a disease, the decision makÂ­
er might wish to consider other events or conditions that
affect or are affected by the disease, e.g., its potential causÂ­
es, its symptoms, its complications, etc. The relevance of
these related events is discriminated according to the cerÂ­
tainty or "strength" of their interactions with the disease.
The categorizers capture structural relations among !he
concepts; !hese relations support the task of reasoning at
multiple levels of details in decision modeling. For inÂ­
stance, given !he presence of a disease, say pneumonia, a
decision maker might wish to prescribe treatment after deÂ­
ciding which particular subtype of pneumonia is actually
present. The possible subtypes of pneumonia can be found
by tracing the concepts related to pneumonia via the speÂ­
cialization (AKO) relation.
One important component of our representation design is
the context (CXT) relation. This unique relation is neither
behavioral nor structural, instead, it can be regarded as a
higher-order relation that constrains the interpretations of
all other relation types in the framework. Explicit encoding
of the CXT relations provides a general mechanism to deÂ­
scribe the concepts, in tenns of their other types of relations
among each other, in a context-sensitive rnanner.Such inÂ­
fonnation is crucial for supporting decision modeling in

THE CONTEXT RELATION

Intuitively, the context or CXT relation delimits the
"scope" of the description of a concept in a network. All
concepts in our framework are denoted in tenns of the CXT
relation.
In general, all concepts reachable from a particular conÂ­
cept, say C. via the CXT relations in the network are in the
description of C. A concept directly related to C via the
CXT relation is a property of C, denoted as (P#C), e.g.,
(King#Thailand), read: King of Thailand, and (Royal ElÂ­
ephant # Thailand),
read: Royal Elephant ofThailand.
The properties of a concept include its inherent qualities,
characteristics, and other relevant concepts that constitute
its description.
It follows that every concept is defined in some context. In

other words, all concepts can be expressed in the form of
(a # b). In this tuple notation, 9-is the "basic identity" of
the concept, and .b. is the "context" in which the concept is
defined; both entries are concepts themselves. The basic
identify of a concept is the most accurate general descripÂ­
tion of the concept. The context specifies the condition in
which the description of the denoted concept is valid, and
allows this description to vary, if necessary, from the basic
identity. There is a special concept, denoted as T, which is
defined to be itself; any concept defined in the context of T
is in the universal context, i.e., valid in general. For examÂ­
ple, the concepts !nl.man, elephant. mya1 elephant. etc., are
actually denoted as (Human# T), (Elephant#T), (Royal
Elephant # T}, and so forth. For simplicity, we shall omit
the universal context in our notations in this paper.
The tuple notation allows concepts to be "chained" to
form a new concept, analogous to the "role chaining"
notion in KL-ONE (Brachman and Schmolze 1985). For
instance, ((Color#Royal Elephant)#Thailand) is a conÂ­
cept. The chaining expression is associative, and the
embedded parentheses are usually omitted.
The CXT relation, therefore, induces a "context tree"
among all the concepts defined in the knowledge base, with
the universal concept T as the root. This context hierarchy
serves two purposes: First, as we shall see below, it allows
expression of context-sensitive description of a concept in
tenns of its categorical and uncertain relations with other
concepts. Second, it serves as a focusing mechanism beÂ­
cause, as we have noted earlier, every subtree in the
hierarchy contains all the relevant concepts in the descripÂ­
tion of the particular concept at the root of the subtree.

Representing Context-Sensitive Knowledge

interactions among a set of concepts. For example,

3â€¢2 BEHAVIORAL RELATIONS: INTERACTIONS
An interaction is a "behavioral" relationship between two

or more concepts. In the decision modeling context, the inÂ­

teractions can be described in tenus of English words such
as "causes," "alleviates," "indicates,"

etc., in one extreme;

they can also be expressed as numeric conditional probabilÂ­

ities between two or more concepts in another extreme. To
balance between intuitive expressiveness and semantic preÂ­

cision, our definitions integrate a temporal ordering notion
and a qualitative probabilistic interpretation.

Each interaction in our framework has two components:

temporal precedence, with "known" or "unknown" as valÂ­
ues, and qualitative probabilistic influence
(Wellman

1 990b), with "positive", "negative", or "unÂ­

known" as values. Different additive combinations of these

values allow us to express the behavioral relationships

if conÂ­
A precedes concept ]!, either by direct or indirect
interaction, it is not allowed to assert an influence from .B.
to A.
cept

In the above definitions, interpreting causation/inhibition

as positive/negative probabilistic influences with known

temporal precedence is consistent with the standard definiÂ­
tion of probabilistic causality with temporal ordering, as
proposed by Suppes (Suppes
With reference to Figure

straightforward. The qualitative probabilistic influence valÂ­

ues, in a nutshell, are defined as follows: if a concept

Cl
positively/negatively influence another concept.c2, then 1)
for binary conceptS Cl and C2. the presence of Cl increasÂ­
es/decreases the probability of the presence of C2. with all
other things being unchanged; and 2) for continuous conÂ­
cepts Cl and C2. higher values of a increase/decrease the
probability of higher values of C2. again with all other
things being unchanged. The detailed definitions can be

1, in the Royal Elephant Example,

the statements: "presence of people usually scares away the

elephants", "royal elephants are more likely to be found

when there are people around", and "the King of Thailand

always demands the royal elephants in Thailand to follow
him everywhere" can be expressed as the following interÂ­
actions:
â€¢

across a spectrum of uncertainty.

The interpretations for the temporal precedence values are

1970).

â€¢
_

â€¢

Presence ofhuman negatively-influences
presenceofelephant
Presenceofhuman positively-influences
presenceofroyal elephant
PresenceofKin2ofThailand causes
presenceofroyal elephantofThailand

3-3 STRUCTURAL RELATIONS: CATEGORIZAÂ­
TIONS
A categorizer is a binary relation that groups concepts, acÂ­
cording to their descriptions, into a categorization. By

knowing the position of a particular concept with respect to

in (Leong 1991a) and (Wellman 1990b). Table 1 deÂ­

another concept in a categorization, we can infer the deÂ­

concepts d and !;.2: association, precedence, influence, and

interactions of the former from the latter in a particular

found

picts the four types of interactions defined between any two

cause/inhibition.

Table

scription,

i.e.,

the properties

and their corresponding

manner. Examples of categorizers, as defined in our frameÂ­
work, include

the specialization or "a kind of' (AKO)
(PARTOF) relaÂ­

relation, the decomposition or "part of'

1: Types of Interactions

tion, the equivalence (EQV) relation, and the structuralÂ­

copy (SC) relation. In the Royal Elephant Example, the relÂ­

Qualitative
Interaction

Network

Temporal

Probabilistic

Type

Representation

Precedence

Influence

Association

PreÂ«dence

ï¿½
ï¿½

c
ï¿½
Cause/Inhibition ï¿½
Influence

Unknown

Unknown

Known

Unknown

evant categorical relationships are:
â€¢

royal elephant

â€¢ ï¿½ is a kind of lJ.wwm

â€¢

Unknown

Positive/Negative

Royal elephant is a kind of elephant

â€¢ Royal elephantofThailand is a kind of

Kin2 ofThailand is a kind of.Jtiili

A concept can be involved in multiple categorizations, e.g.,

teeth ofroyalelephant is part of royalelephant, and also is
a kind of ori'anofanimal. A set of conventions, based on
subgraphs copying and references updating, are defined for

each categorizer for proper inheritance of concept descripÂ­

Known

Positive/Negative

Interactions with known temporal ordering can only be

used to describe concepts that represent "events" in the
world. T he temporal ordering also constrains the possible

tions. It is currently assumed that the descriptions inherited
in different categorizations of the concept are consistent2.

The specialization, decomposition, and equivalence rela2Â· As

we shall discuss in !he potential application of the frameÂ­

work, !his assumption is quite reasonable.

169

170

Leong

tions defined in our framework are in accordance with the

straints or situations, e.g., in Thailand. These extra

resentation literature. We shall not repeat the definitions

of the concepts involved.

conventional or common definitions in the knowledge repÂ­

here. The context sensitive nature of our framework, howÂ­

ever, calls for the fonnalization of a new categorical
relation, structural-copy (SC). The SC relation can be

viewed as a unidirectional "reference" relation. This relaÂ­

tion is not explicitly demonstrated in the Royal Elephant

Example, but we could easily extend the scenario as folÂ­
lows:

The Royal Elephant Example (cont.)

constraints or situations are captured in the CXT relations

4

STRUCTURE OF KNOWLEDGE BASE

So far we have outline the basic representation constructs

in our framework. By adopting a descriptive approach to
concept definition, we have developed a set of categoriclll

relations and a set of uncertain relations among the conÂ­

cepts. These relations are further constrained by the CXT
relation to capture context-sensitive information in a uniÂ­

As mentioned earlier; the royal elephants in ThaiÂ­

fonn way.

land are present whenever the King of Thailand

From the network perspective, each type of relations deÂ­

makes a publi c appearance. Those royal eleÂ­
phants with pink tails in Thailand are always

fined in our framewmk imposes a set o f multiply connected

directed graphs on the concepts. In particular, the CXT reÂ­

lation hierarchy fonns a single directed tree on all the

selected as the King's rides.
In this case, we shall define a concept pink-taU royal eleÂ­

phant of Thailand, which is kind of royal elephant of
Thailand. There is also a need to define another concept
called ride of Kinï¿½ ofThailand, with which we associate
the description for a typical ride for a king, e.g., the type of

concepts in the knowledge base. This imposed regularity on

the knowledge base, we believe, would facilitate the effiÂ­
ciency of the inferences supported.

A major assumption that allows us to take advantage of the

network interpretation of the framework for supporting inÂ­

saddle mounted, decorations, etc. But the ride of Kinï¿½,: of
Thailand is also a pink-tail royal elephant of Thailand. in

ferences is that all the relation links in concept descriptions,

used to describe the fanner. Note that this is not a specialÂ­

cept descriptions are ''pre-compiled". and no "run-time"

the sense that the description of the latter can be directly
ization relation, i. e. , the ride of Kinï¿½ of Thailand is not a

kind of pink- tail royal elenhant ofThailand; the two conÂ­

cepts are actually descriptions of the same object under

different circumstances3 Therefore, it is much more natural

to define ride ofKinï¿½,: ofThailand as
pink-tailroyal elephant ofThailand

a structural-copy of

including those that are inherited, are fully established
when the concepts are defined. In other words, all the conÂ­

definition is allowed. This strong assumption has simplified
the representation design process, but will likely to be elimÂ­
inated as we progress to explore more complicated issues

and improve our design in the future.

As mentioned earlier, a subtree in the context hierarchy is

built for each concept defined., with its properties in tum as

In general, if a concept A is a structural copy of another

the branches or subtrees of this subtree. Given that all the

scription of A. In other words, the properties and their

glance, the possible "chaining" of the CXT relation would

concept B.. then the description of li is visible in the deÂ­
corresponding interactions of B. may be directly used in the
description of A. with the appropriate updated references.

For instance, the property teethofrideofKinï¿½ ofThailand

is directly copied from the corresponding property ï¿½

pink-tailroyal elephant ofThailand. In the

planned impleÂ­

mentation of the framework, we do not have to specify this

description in the definition of ride ofKinï¿½,: ofThailand; as

long as the SC relation between the two concepts is assertÂ­

ed, the corresponding structure should be automatically

copied when the knowledge base is constructed.

The SC relation is irreftexive, antisymmetric, and transiÂ­

tive. Intuitively, the SC relation provides a means for
different concepts to share description under different con3Â· Another

more realistic example is the concept: cornoljcation

2f..All2S, which is usually another disease, say

carjnjjpneymonja!PCP>

fneumocystis

this case,
used to describe the concept, in

or a physiological state. In

the description of 11:Â£ can be

addition to its description of being a complication.

relation links are fully established for each concept, at first

lead to an exponential explosion in he number of definable
or derivable concepts.

Indeed, the number of distinct concepts that can be formed
from an initial set of n context-free concepts, i.e., concepts

defined in the universal concept T, are of O(n!) or O(n11).

The actual bound for the knowledge is actually infinite if

we allow a concept to appear more than once in a CXT

chain, e.g., (child# child# child#....# King# Thailand).

The space needed for the knowledge base could possibly be
huge. We believe, however, the situation is not that serious
because, in general, many of the CXT chaining combinaÂ­

tions do not make sense; the CXT hierarchy is usually
sparse.

5

INFERENCES SUPPORTED

Two classes of powerful inferences, inheritance and recogÂ­

nition, are usually supported in hierarchical knowledge

representation systems of the semantic networks family.

Representing Context-Sensitive Knowledge

The presence of conflicting concept descriptions gives rise

Table

to the exceptions and multiple inheritance problems in inÂ­

" Â® " operator is for combining intemction chains and the

heritance, and the partial matching problem in recognition
(Shastri 1989). Since we assume our knowledge base is a
fully established network of concept descriptions, we do
not anticipate most of the difficulties that research in inherÂ­

itance theory or default reasoning (Touretzky, Harty and

Thomason 1987) encounters. As compared to these sysÂ­

tems for supporting commonsense reasoning, however,
only a restricted set of inferences are provided in our
framework.

2 defines the indirect effects of the interactions. The

" $ " opemtor is for combining parallel intemctions. The
definitions are consistent with the opemtors for combining

influence chains and parallel i'!fluences in qualitative probÂ­
abilistic networks (QPNs). The corresponding operations

are commutative, associative, and distributive, just like orÂ­

dinary multiplication and addition (Wellman 1990b). The
tables are indexed from intemction entries in "row" then
"column", and the net interaction is read from their intersection. For example,

All the knowledge in our knowledge base is currently asÂ­

- Â®i

= +; +

E9

c

= c.

Table 2: Indirect Effects of Interactions

s umed to be pre-compiled; any conflicts or inconsistencies

would have been resolved, either by the conventions specÂ­
ified in the relational semantics or by consulting the user,
when the network is constructed. The multiple inheritance
problem in our framework is therefore addressed when the
knowledge base is constructed; the exceptions

are handled

by explicitly specifying the CXT relations in a unifonn
way. There is no run-time support for inheritance inferencÂ­

â‚¬)

a
a
a
a
a
a
a

a
p

+
c

es.

a
p
a
a
p
p

+
a
a
+

-

+

-

a
a
-

+
+

c
a
p
+

-

c

i
a
p
-

+

i
c

e
a
p

+

c

a
a
p
a
a
p
p

+

p
p
p
p
p

p

a
p
+
a
c
p

a
p
a

c
p
p
c

p
i

c
p

-

p

p
p
p
i
p
i

On the other hand, our framework is equipped to handle a
restricted class of the recognition problem; these problems
can be reduced to the simpler problem of finding a path in
a particular network imposed by a relation type, and then
interpreting the indirect relation between the concepts at
the beginning and the end of the path.

5â€¢1

INDIRECT INTERACTIONS

There are two forms of indirections for interactions: interÂ­

5â€¢2

Detennining the relationship between two concepts in a
particular categorization is straightforward, involving simÂ­
ply checking whether one concept is in the transitive
closure of the other. The context-sensitive nature of our
framework further allows, for example, the following types
of inferences to be dmwn on the categorizations:

action chains and parallel interactions. An example of the

â€¢

former scenario is as follows:
â€¢

â€¢

Presenceofhuman negatively-influences
presence ofelephant
Presence ofelephantpositively-influences
presence ofmouse

A relevant query would be: W hat is the interaction between

preseoce ofhuman and presenceofmouseÂ±?
Similarly, an example of the latter scenario is as follows:
â€¢

â€¢

â€¢

Presence ofKiniofThailand causes
presence ofroyalelephantofThailand
Presence ofKini ofThailand

INDIRECT CATEGORIZATIONS

â€¢

Elephant is a kind of animal

:w:tb. is a kind of llii.3lJ

We can conclude that:
â€¢

Teeth of elephant is a kind of organ of animal

The detailed definition of such inferences is again docuÂ­
mented in (Leong 1991a). In the specialization hierarchy,
this definition is analogous to the idea of derivative subÂ­

classification in OWL (Hawkinson 1975). The inferences
supported in our fmmework are generalized to all other catÂ­
egorical relations defined as well.

6

SUPPORTING DECISION MAKING
in the Royal ElÂ­
can be adequately captured in our

positively-influences

We have seen how the relevant information

presenceofcatofThailand
Presence ofroyalelel)hant ofThailand

ephant Example

positively-influences

Dresence ofmouse ofThailand
â€¢ Presence ofcat ofThailand
negatively-influences

Dresence ofmouseofThaj!and
A relevant query would be: W hat is the net interaction beÂ­
tween Kini ofThaUand and

mouseofTbaj!and?

representation framework. We shall now examine how the
represented knowledge can be used to support dynamic forÂ­
mulation of a decision model.
The decision-analytic approach to decision making

can be

viewed as a five-step process: 1) Background information
characterization;

2) domain context establishment; 3) deciÂ­

sion problem fonnulation; 4) decision model construction;
and

5) decision model evaluation.

171

172

Leong

To sup(X)rt the above decision making process, the followÂ­
ing general types of queries are involved (Leong 1991b),
with the parameters in the angular brackets denoting the reÂ­
lations defined in our framework:
â€¢

â€¢

â€¢

â€¢

(Ql) Does concept.Arelate to concept .B. by
<categorizer>?
(Q2) W hat are the concepts related to concept A
by <categorizer>?
(Q3) Does concept A relate to concept .!l by
<interaction>?
(Q4) What are the concepts related to concept A
by <interaction>?

For example, consider the following scenario:
The Tourist's Decision Problem

A tourist in Thailand had a very expensive camÂ­
era. One day very early in the nwming, He heard
from the radio that an elephant was spotted in a
nearby shopping mall. He would really like to take
a picture of a Royal Elephant, but the radio report
did not mention what type of elephant it was. The
decision is whether or not the tourist should bring
his camera to the shopping nwll, given a substanÂ­

tial chance that the camera could be stolen.

A target decision model for the Tourist's Decision Problem
is shown in Figure 3.

Figure 3: A QPN for the Tourist's Decision Problem
Given the problem specification, and a knowledge base
containing all the relevant information about elephants and
a tourist's life in Thailand, the decision maker could formuÂ­
Late the above decision model by (X)Sing a series of queries
to the knowledge base. Some examples of these queries, are
as follows:
â€¢

â€¢

W hat are the concepts related to Elephant by
specialization?
W hat are the concepts that positively-influence

chance of stolen camera?

â€¢

etc.

To evaluate the decision model, the decision maker would
in tum (X)se a series of queries to the constructed decision
model as follows:
â€¢

â€¢

â€¢

Does brinï¿½-camern? relate toï¿½ by
(X)Sitive-influence?
Does brinï¿½-camern? relate toï¿½ by
negative-influence?
etc.

All these queries are of the general forms Ql to Q4 as deÂ­
fined above. As illustrated in the previous section, these
queries are sup(X)rted by the inferences (direct or indirect
interactions and categorizations) provided in our frameÂ­
work.
The built-in context-sensitive nature of the representation
provides the decision maker with a general way of accessÂ­
ing variations in the domain information. For example, if
the Tourist's Decision Problem is (X)sed in a country other
than Thailand, the resulting target decision model might be
different because the royal elephants there, if present,
might be scared of people. The same set of queries, howevÂ­
er, would be used by the decision maker to construct this
new decision model

7

DISCUSSION AND CONCLUSION

In this paper, we have briefly discussed the motivation and
the design approach for a representation framework that inÂ­
tegrates categorical knowledge and uncertain knowledge in
a context-sensitive manner. Our design is based on a netÂ­
work formalism which facilitates the interpretation and the
manipulation of the inheritance problem in the various reÂ­
lations being modelled. By examining how the information
in the Royal Elephant Example can be represented, we
have demonstrated the expressiveness of our framework.
We have also argued that this expressiveness is adequate
for capturing many interesting phenomena essential for
sup(X)rting automated decision making.
Efficiency, i.e., how easily can the knowledge be accessed
in the framework, is demonstrated through a set of indirect
inference definitions. With these inferences, a restricted
class of the recognition problem can be reduced to a pathÂ­
finding problem. We (X)Stulate that instead of the NP-comÂ­
plete classification mechanism being sup(X)rted in most
existing term-subsumption languages or representation
systems, simple path-finding graph algorithms of (X)lynoÂ­
mial time complexity are adequate for our puf(X)se. More
rigorous analysis, however, needs to be done to substantiate
this claim.
We would like to conclude the informal evaluation of our
framework by examining its effectiveness, i.e., how well it
sup(X)rts the applications it is designed for. In this case, the
intended application is for sup(X)rting dynamic formulation
of decision models in automated decision analysis. We

Representing Context-Sensitive Knowledge

have briefly sketched how the framework supports the proÂ­

J. S. Breese, R. Goldman and M. P. Wellman (1991).

cess with the Tourist's Decision Problem example. In

Knowledge-Based Construction of Probabilistic and DeciÂ­

practice, we have also briefly examined this issue by handÂ­

sion Models: An Overview. In Proceedings of the AAA!

building and hand-evaluating a small test knowledge base

Workshop on Knowledge-Based Construction of Decision
Models, 1-17.

in the domain of opportunistic pulmonary infections with
suspected AIDS (Leong 1991a); the results are promising.
Unfonunately, a rigorous evaluation is impossible until we

have an implemented system , which is planned for the near
future.

We believe our representation framework is applicable in
some other problem solving tasks as well. The restricted set
of inferences provided, however, renders it unsuitable for
supporting more general recognition problems. Moreover,

L. B. Hawkinson (1975). The Representation of Concepts
in OWL. In Proceedings of the International Joint ConferÂ­

ence on Artificial Intelligence.
T.-Y. Leong (1 99 1a) . Knowledge Representation for SupÂ­

porting

Decision

Model

Formulation

in Medicine.

Massachusetts Institute of Technology.MIT-LCS-TR 504.
T.-Y. Leong (199lb). Representation Requirements for

we have only dealt with concept types and relation types in

Supporting Decision Model Formulation. In Proceedings

our framework; concept instances and relation instances
are not currently handled. Therefore, any inferences inÂ­

of the Seventh Conference on Uncertainty in Artificial InÂ­
telligence, 212-219.

volving instances are not currently addressed, e.g., we

D. Lin and R. Goebel (1990). Integrating Probabilistic,

would not know what to do with a concept .C.U:W:.. which is

Taxonomic and Causal Knowledge in Abductive DiagnoÂ­

an instance of royal elephant

sis. In Proceedings of the Sixth Conference on Uncertainty

Given the pre-compiled nature of the knowledge base, one

in Artificial Intelligence, 40-45.

might also wonder how easily new information or changes

J. P earl (1 988). Probabilistic Reasoning in Intelligent SysÂ­

can be incorporated into the intricate network structure.
This problem might be alleviated by the appropriate use of
delayed evaluation or selective expansion techniques, but
we have yet to consider the options carefully to substantiate
the claim. This would be a major component to be worked
out and considered in evaluating the effectiveness of the

tems: Networks of Plausible Inference. San Mateo, CA:
Morgan Kaufmann.
A. Saffiotti (1990). A Hybrid Framework for Representing
Uncertain Knowledge. In Proceedings of the Eighth NaÂ­

tional Conference on Artificial Intelligence, 653-658.

implemented framework in future.

L. Shastri

In conclusion, while there is definitely much more to be acÂ­

works: A Formalization of Recognition and Inheritance.

complished in this project, we believe we have established

(1989). Default Reasoning in Semantic NetÂ­

Artificial Intelligence, 39(3): 283-355.

the essential componems of the proposed representation

P. Suppes (1970). A Probabilistic Theory of Causation.

framework. We have also demonstrated its potentials in faÂ­

Amsterdam: North-Holland.

cilitating automated decision making under uncertainty.
Future agenda for this work include: 1) Implementation of
the representation system; 2) formal evaluation of the
framework in actual use; 3) refining the relational definiÂ­
tions in the framework; 4) extending the framework to
handle concept and relation instances, and 5) development

D. S. Touretzky, J. F. Harty and R. H. Thomason (1987). A
Clash of Intuitions: The Current State of Nonmonotonic
Multiple Inheritance Systems. In Proceedings of the InterÂ­

national Joint Conference on Artificial Intelligence, 476482.

of a set of techniques for efficient incorporation of changes

M.P. Wellman (1990b). Fundamental Concepts of QualitaÂ­

into the knowledge base.

tive P robabilistic Networks. Artificial Intelligence, 44(3):

257-304.
Acknowledgments

J. Yen and P. P. Bonissone (1990). Extending Term SubÂ­

The author wishes to thank P eter Szolovit and Mike WellÂ­

sumption

man for many helpful discussions and comments on the

Proceedings of the Sixth Conference on Uncertainty in ArÂ­
tificial Intelligence, 468-437.

content of this paper, and the anonymous referees for sugÂ­
gestions on the presentation of this paper. This research
was supported by the National Institutes of Health grant no.
5 ROl LM04493 from the National Library of Medicine.



We propose a framework for building graphÂ­
ical causal model that is based on the conÂ­
cept of causal mechanisms. Causal models
are intuitive for human users and, more imÂ­
portantly, support the prediction of the efÂ­
fect of manipulation. We describe an impleÂ­
mentation of the proposed framework as an
interactive model construction module, ImaÂ­
GeNie, in SMILE (Structural Modeling, InÂ­
ference, and Learning Engine) and in GeNie
(SMILE's Windows user interface).

1

INTRODUCTION

Graphical probabilistic models, such as Bayesian netÂ­
works and influence diagrams, have become popular
modeling tools for supporting decision making under
uncertainty. The normative character of the graphiÂ­
cal decision models guarantees the correctness of the
inference procedure. Consequently, the quality of the
advice suggested by the models depends directly on
the requisiteness of the models. A model is requisite if
it contains everything that is essential for solving the
problem and no new insights about the problem will
emerge by elaborating on it (Philips 1982). To build
a requisite model requires human intuition and creÂ­
ativity since the notion of requisiteness is subjective.
Construction of graphical models, therefore, is laboÂ­
rious and demanding in terms of domain expertise.
While support for obtaining model parameters, such
as prior and conditional probability distribution, has
received much attention in behavioral decision theory
literature (see von Winterfeldt and Edwards (1988) for
a review) and in artificial intelligence (Druzdzel & van
der Gaag 2000), relatively little work has been done on
composing model structure. At the same time, there
are strong indications that the quality of advice is more
sensitive to the model structure than to the precision

Tze Yun Leong
Medical Computing Laboratory
Department of Computer Science
School of Computing
National University of Singapore
Singapore 119260
leongty@comp. nus. edu. sg
of its numerical parameters (Pradhan et al. 1996).
There are essentially four approaches to aid model
building. The first approach focuses on providing more
expressive building tools. The Noisy-OR model (Pearl
1988; Henrion 1989) and its generalizations (Dlez 1993;
Srinivas 1993) simplify the representation and eliciÂ­
tation of independence interactions among multiple
causes. Beckerman (1990) developed the similarity
network and partition as tools for representing subset
independence to facilitate the structure construction
and probability elicitation. The second approach, usuÂ­
ally referred to knowledge-based model construction
(KBMC), emphasizes aiding model building by autoÂ­
mated generation of decision models from a domain
knowledge-base guided by the problem description and
observed information (see a special issue at the journal
IEEE Transactions on Systems, Man and Cybernetics
on the topic of KBMC (Breese, Goldman, & Wellman
1994)). The third approach focuses on algorithms that
can learn the model structure and parameters from a
database of observations (Cooper & Herskovits 1991;
Pearl & Verma 1991; Spirtes, Glymour, & Scheines
1993). Although model construction from data can
reduce the knowledge engineering effort, the learning
approach faces other problems such as small data sets,
unmeasured variables, missing data, selection bias, and
the flexibility of model granularity.
While we acknowledge that in the future it may be
possible to build powerful computer systems that will
model human creativity, sense for relevance, and simÂ­
plicity, we believe that these tasks are and will long be
performed better by humans. Our view is that model
building, a task that relies on all these capacities, is
best implemented as an interactive process. The fourth
approach on aiding model construction that is most reÂ­
lated to our work is to apply system engineering and
knowledge engineering techniques for aiding the proÂ­
cess of building Bayesian networks. Laskey and MaÂ­
honey (1996; 1997) address the issues of modularizaÂ­
tion, object-orientation, knowledge-base, and evalua-

354

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

tion in a spiral model of development cycle. Koller
and Pfeffer (1997; 1999) developed Object-Oriented
Bayesian Networks (OOBN) that use objects as orgaÂ­
nizational units to reduce the complexity of modeling
and increase the speed of inference.
Our approach on aiding model construction is based
on the concept of causal mechanisms. Causal mechaÂ­
nisms, which are local interactions among domain variÂ­
ables, are building blocks that determine the causal
structure of a model. As they encode our understandÂ­
ing of local interactions and are fairly model indeÂ­
pendent, causal mechanisms can be easily reused in
various models. When the algebraic form of the inÂ­
teraction is known, causal mechanisms are captured
by so called structural equations. When less informaÂ­
tion is available about the interaction, it can be specÂ­
ified in a probabilistic format. As shown by Druzdzel
and Simon (1993), conditional probability tables in
Bayesian networks that model causal relations among
their variables can be also viewed as descriptions of
causal mechanisms. Similarly to object-hierarchy abÂ­
straction, causal mechanism can be organized hierarÂ­
chically in nearly decomposable system (Iwasaki & SiÂ­
mon 1994). At the same time they provide a valuÂ­
able heuristic for acquiring and managing knowledge:
causality.
In our framework, we encode causal mechanisms as
functional relations among variables and, wherever
causal mechanisms are asymmetric, the direction of
causal influence among variables. We extend Simon's
causal ordering algorithm (Simon 1953) to develop a
modeling process that uses the output graph of this
algorithm in the interaction with users. We assist the
model building process by helping user (1) to identify
a set of mechanisms related to the current model and
to bring them into model workspace (2) to integrate
the newly added mechanisms with the model under
construction (3) to specify the variables that can be
manipulated, and (4) to extract reusable causal mechÂ­
anisms from existing models into the knowledge base.
The final model structures generated by our modeling
process are guaranteed to be causal if the underlying
structural equations reflect causal mechanisms of the
modeled problem.
In addition to being intuitive for human users and facilÂ­
itating crucial user interface functions such as explanaÂ­
tion, causal models support prediction of the effect of
manipulation, i.e., changes in structure (Simon 1953;
Spirtes, Glymour, & Scheines 1993; Pearl 1995). The
users of such models (and that includes autonomous
robots) can ask questions like "What will happen if
I perform action A?" Manipulation is especially imÂ­
portant in strategic planning, where it is important to
derive creative decision options and not only evaluate

existing decision options. In the process of creating a
model, a user may want to explore the possibility of
manipulating its different elements. Supporting this
manipulation is not straightforward, as some mechaÂ­
nisms may be reversible, i.e., acting in reverse direcÂ­
tion. For example, when driving up the hill, car engine
causes the wheels to turn; but when driving down the
hill in a low gear, the model should be able to predict
that the wheels will cause the engine to slow down.
Our approach supports causal modeling that includes
reversible causal mechanisms and offers an integrated
framework for building and using causal models.
The remainder of this paper is structured as follows.
Section 2 gives an overview of structural equation modÂ­
els, causal mechanisms, and how these support changes
in structure. Section 3 discusses the process of interÂ­
active model construction, including issues related to
the representation of causal mechanism, assistant inÂ­
terface, and the extension of causal ordering algorithm.
Section 4 presents an example of user interaction with
our system, ImaGeN/e. F inally, we discuss the impliÂ­
cations of our approach and outline the direction for
our future work.
2

STRUCTURAL EQUATION
MODELS

When scientists study phenomena or problems, they
normally focus on systems, pieces of the real world
that can reasonably be studied in isolation. ScienÂ­
tists identify the relevant variables, the ranges of the
variables' values, and the relations among variables to
form abstractions of these systems, known as modÂ­
els. One way of representing models is by systems
of structural equations where each structural equaÂ­
tion describes a conceptually distinct causal mechaÂ­
nism active in the system. Such systems are known as
Structural Equation Models (SEMs) (Haavelmo 1943;
Simon 1953). A structural equation describing a causal
mechanism M is often encoded as an implicit function

where f is some algebraic function and its arguments
V; are variables that directly participate in the mechÂ­

anism M.
A variable in a SEM is exogenous if it summarizes
an outside influence on the system, i.e., its value is
determined outside of the model. An exogenous variÂ­
able is truly exogenous if it represents a variable in the
real world system that we cannot manipulate without
changing the boundaries of the system. An exogenous
variable is a policy variable if it represents a variable
that we can manipulate, i.e., set its value. For examÂ­
ple, we normally model outside temperature as a truly

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

exogenous variable in an agricultural model, but we
can model the temperature as a policy variable in a
model of a greenhouse. For each exogenous variable,
there is a value assignment structural equation to desÂ­
ignate the observed value ( or a probability distribution
over observed values) for the truly exogenous variable
or the chosen value for the policy variable. A variable
in a SEM is endogenous if its value is derived by substiÂ­
tuting the values of exogenous variables into the core
structural equations that depict the relations among
modeled variables in the system and by solving these
equations in SEM .
A SEM S with m causal mechanisms and n variables
is represented as
m
S

=

U fM,(Vl, V2, V3, ... , Vn).
i=l

Since the knowledge of which variables participate in
which mechanisms is sufficient to determine the diÂ­
rection of causation, 1 in the remainder of this paper
we will only use structure matrix (Druzdzel & Simon
1993), a qualitative representation of a SEM.
Definition 1 (structure matrix) A structure maÂ­
trix A of a SEM S = U:1 fM,(Vl, V2, V3, . .., Vn) = 0
is a m x n matrix with element a;j = x if Vj participates
in f M;, where x is a marker, and a;j = 0 otherwise.
Let Amxn be the structure matrix of a SEM S with m
equations and n variables. S is non-over-constrained
if following property holds.
Definition 2 (non-over-constrained system) A
system of m structural equations S is non-overÂ­
constrained if in any subset of k ::; m equations of
S at least k different variables appear with nonzero coÂ­
efficients.
A non-over-constrained Amxn is self-contained if m =
n. A non-over-constrained Amxn is under-constrained
if m < n. Amxn is over-constrained if it violates nonÂ­
over-constrained property.
Example:

The University Performance Budget Planning
Model (UPBPM) (Simon, Kalagnanam, & Druzdzel 2000)
is comprised of 38 core equations that describe interactions
among 88 variables in the university strategic budget planÂ­
ning context. The model has been adopted by the Office
for Planning and Budget at Carnegie Mellon University for
the purpose of strategic planning of university operations.

The following simple model, StudentFacultyRatio model,
extracted from UPBPM, consists of one core equations and
two value assignment equations and describes the interacÂ­
tion among three variables: StudentFacultyRatio (SFR),
NumberOJStudents (NS), and NumberOfFaculty (NF).

1 Only when calculating the strength of the influences,
we need the exact form of equations.

355

The corresponding structure matrix for this self-contained
model is shown at the right hand side.

{"

/2:
h:

2.1

NS
NF
SFR

=
=
=

22102
3006
NSjNF

NS
h
h
h

X

0

X

NF
0
X
X

SFR
0
0
X

0

Causal Ordering

As shown by Simon (1953), a self-contained SEM exÂ­
hibits asymmetries that can be represented by a diÂ­
rected acyclic graph and interpreted causally. Simon
developed a causal ordering algorithm that takes a selfÂ­
contained structure matrix A as input and outputs
a causal graph G = {N(G), A(G)}, where the nodes,
N(G), are sets of variables and the arcs, A (G), describe
causal relations among them.
Let B be a subset of equations in a non-overÂ­
constrained SEM and Cpxq be the structure matrix
of B. We say that B is a self-contained subset if
p = q; B is a under-constrained subset if p < q. A
self-contained subset is minimal if it does not contain
any self-contained ( proper) subsets itself. A minimal
self-contained subset is a strongly coupled component
if it contains more than one equation, which usually
represents a feedback system in the real world.
The causal ordering algorithm starts with identifying
the minimal self-contained subsets in input A. These
identified minimal self-contained subsets are called
complete subsets of 0-th order and a node is created
for each subset. Next, the algorithm removes the equaÂ­
tions of the complete subsets of 0-th order from A as
solving the values of variables. Then it removes all
variables that occur in the complete subsets of 0-th orÂ­
der from the remaining equations in A as substituting
the values of solved variables into remaining equations.
The remaining set of equations is called the derived
system of first order, a self-contained structure. The
algorithm repeats the process of identifying, solving,
and substituting on the derived system of k-th order
until it is empty. In addition, whenever a node m is
created for a minimal self-contained subset M, the alÂ­
gorithm refers the set of equations EM of M back to
the original set of equations OEM in A and adds arcs
from the nodes representing variables in OVM \ VM to
m, where VM is the set of variables participating in
EM and OVM is the set of variables participating in
OEMÂ·

Example:
The UPBPM (Simon, Kalagnanam, &
Druzdzel 2000) implements Simon (1953) causal ordering
algorithm that given an assignment of values to 50 exogeÂ­
nous variables, derives the structure of the model.
When applying the causal ordering algorithm to the strucÂ­
ture matrix of StudentFacultyRatio model, we first identify

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

356

h and h as the complete subset of 0-th order. After
solving and substituting of NS and NF, we then identify

NS

fï¿½ as the complete subset of 1-st order. The structure maÂ­

X

trix and the corresponding causal graph are shown below.

NS

NF

SFR

0

0

X

0
0

X

X

X

NF

SFR

0

0

X

X

X

0

0

X

()liL-D NF

~

In the revised system, the causal ordering shows that NF
has become an endogenous variable affected by NS and
SFR. Now, changing the number of students will affect

X

the number of faculty. Manipulation has lead to a change
in structure.

D

Given the causal graph, we can read off the causal relaÂ­
tions among the nodes by focusing on the node of interest
and its parents. For example, SFR directly depends on
D

NF and NS.

Notice that the causality that we read off causal graphs
is defined within models and causal asymmetries arise
when mechanisms are placed in context. If the context
has changed, it may result in changes in structure.
2.2

Changes in Structure

The main value of structural equation models is that
they support prediction of the effects of changes in
structure, i.e., external manipulations that intervene
in the mechanisms captured by the original system of
equations. Such changes are modeled by modifying
the equations that describe the affected mechanisms
and leaving those equations that correspond to unafÂ­
fected mechanisms unmodified. The causal ordering
algorithm applied to the modified SEMs derives the
new causal structure of the system.
Normally, the effect of external manipulation is loÂ­
cal and, when related back to the graph, amounts to
arc cutting (Pearl 1995; Spirtes, Glymour, & Scheines
1993). The assumption underlying the arc-cutting opÂ­
eration is that imposing a value on a variable by an
external intervention makes that variable independent
of its direct causes. This assumption is valid for mechÂ­
anisms with strong asymmetric relationship between
a variable and its causes; for example, wearing sunÂ­
glasses protects our eyes from the sun but it does
not make the sun go away. However, when a model
contains reversible causal mechanisms (Simon 1953;
Druzdzel & van Leijen 2000), manipulation can have
a drastic effect on the graph.
Example: From the causal graph of StudentFacultyRaÂ­
tio model in previous example, we k now that changing NS
will affect SFR but not NF. Now, consider that the budget
planning officer would lik e to set the StudentFacultyRaÂ­
tio to advertise their faculty availability. If needed, she
is willing to adjust the NumberOfFaculty (e. g. , hire more
faculty) . According to the revised modeling context, she
needs to designate the variable SFR as exogenous, e. g. ,
j4 : SFR = 10, and release h : NF
3, 006. The resultÂ­
ing structure matrix and corresponding causal graph are:
=

Figure 1: Interactive and Iterative Model Construction
System Architecture. The arcs show the direction of
the information flow.

3

INTERACTIVE MODEL
CON STRUCTION

We have developed an interactive and iterative model
construction environment, ImaGeNie, that assists
users in building graphical decision model in causal
form. We use the causal ordering algorithm to genÂ­
erate the causal model structures which can later be
associated with different node types and parameters
and transformed into Bayesian networks or influence
diagrams. Figure 1 shows the architecture of ImaGeÂ­
N/e. It includes three knowledge structures: mechÂ­
anism knowledge bases, which hold domain knowlÂ­
edge expressed as causal mechanisms, model buildÂ­
ing workspace, which serve as a blackboard for model
composition, and models. The domain knowledge
can be maintained either by the equation authoring
interface, where model builders can compose strucÂ­
tural equations directly, or by the mechanism exÂ­
traction operation that enables model builders to exÂ­
tract reusable causal mechanisms from existing modÂ­
els. Model builders can use hierarchy navigation inÂ­
terface to locate the mechanisms of interest and select

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

them into the model building workspace with assisÂ­
tance of the mechanism selection operation. In adÂ­
dition to mechanism selection and traditional model
authoring operations, model builders can manipulate
variables and merge mechanisms as model building
process evolves. The underlying causal ordering modÂ­
ule will restructure the models according to the user
actions.
3.1

Knowledge Representation

In ImaGeNie, the fundamental knowledge representaÂ­
tion units are causal mechanisms, which are encoded as
structural equations. For example, we can specify the
student faculty ratio as h (S F R, NS, N F ). Users may
optionally provide explicit functions for causal mechÂ­
anisms such as algebraic functions, conditional probÂ­
ability tables, truth tables, value/utility tables, and
choice tables.
While most mechanisms will be described in one, perÂ­
haps their only, mode of operation, some mechanisms
are reversible in the sense of being flexible as to the
direction of causality that they imply when they are
embedded in different contexts. We define the manipÂ­
ulativeness and observability for each variable in our
domain knowledge base to express the characteristics
of the variable that may aid in the process of model
building. Along with the manipulativeness characterÂ­
istic, a variable can be truly exogenous, manipulatable,
or truly endogenous. For the sun and sunglasses examÂ­
ple, we may use two structural equations !5(S, G) and
f6(S) to describe causal relation between S and G and
assign S as a truly exogenous variable to express the
fact that it is impossible to manipulate the sun in the
current modeling domain. We may assign G as manipÂ­
ulatable to designate it as a potential policy variable.
A variable is truly endogenous if its value has to be deÂ­
rived from embedded mechanisms. The observability
is important in deciding whether adding this variable
(observable or unobservable) will be of benefit to the
model. In the diagnostic domain, it may be desired to
develop the cost model that can associate manipulation
cost/ observation cost with manipulatable/observable
variables.
Our domain knowledge base is organized as a hierarÂ­
chical system that consists of subsystems and causal
mechanisms as its fundamental building elements. The
hierarchical approach not only helps domain experts to
express their domain knowledge in cognitively meanÂ­
ingful units but also helps knowledge engineers to
access stored mechanisms easily. Our approach is
similar to type-hierarchy in (Koller & Pfeffer 1997;
Laskey & Mahoney 1997) but without imposing the
inheritance constraint since knowledge can be posÂ­
sibly organized hierarchically from different perspec-

357

tives. More details on the syntax of our knowledge
representation language can be found in (Lu 1999).
3.2

Extending Causal Ordering to
Under-constrained Model

In ImaGeNie, the model construction process is a reÂ­
flection of our problem solving. The under-constrained
models evolved in such process reveal different problem
recognition stages. In an under-constrained model, the
mechanisms are our observations of how the problem
should be described so far. Model building process is
strongly related to causal manipulation. The exogeÂ­
nous variables are those outside influences that have
been committed. An under-constrained model canÂ­
not be drawn as a directed acyclic graph, as the diÂ­
rection of causal interactions is not completely deterÂ­
mined until the model is self-contained. However, it
is desired to have a graphical representation of underÂ­
constrained models during the whole process of model
construction, since the graphical representation may
help model builder identify her focus and change her
commitments of the outside influences. We extend SiÂ­
mon's causal ordering algorithm to explicate the causal
ordering that has been identified in under-constrained
models. We also propose a graphical representation
to depict the causal ordering results in an informative
graphical form that aims to help user in model buildÂ­
ing.
In order to formalize our extensions, we need to reÂ­
state the theorem that was originally proved by Simon
(1953).

Theorem 1 Let A and B be two minimal selfÂ­
contained subsets of equations of a non-overÂ­
constrained SEM, S. Then the structural equations
of A and B, and likewise the variables in A and B are
disjunct.
Consider any subset B of the equations of a non-overÂ­
constrained SEM. We will denote the number of equaÂ­
tions in Bas ne8, and the number of variables appearÂ­
ing in B as nvB.

Theorem 2 Let S be a non-over-constrained system
and D be the derived system of structural equations
from S by applying identification, solving, and subÂ­
stitution. If D is not empty, then D is non-overÂ­
constrained.
Proof:

In the process of identification, let M be the
union of all the minimal self-contained subsets, M = M 1 U
M2 U ... U Mk, and the remainder R. We k now R is not
empty since V is not empty.
Suppose that V violates the non-over-constrained property.

Then there exists a subset Â£' of V such that net:' >

nvt:'Â·

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

358

Let & be the subset of R that &' derives from. We know

M U &.
The equations of M and & are disjunct because M and R
that

neÂ£

=

Now, consider the subset :F

neÂ£1Â·

are disjunct and &

neM + neÂ£1.

ï¿½ R. Therefore,

ne;:

=

=

neM + neÂ£

=

Since &' derives from & by substitution, the

variables appearing in & are either in

M

or in &'.

sequently, the variables in :F are either in
Moreover, the variables in

M

M

ConÂ­

or in &'.

and &' are disjunct because

M.
Therefore, nv;: = nvM + nVÂ£1. Since the equations of M ,
i
and likewise the variables in M , are disjunct by TheoÂ­
i
&' derives from & by substituting out the variables in

nVM = L;nvM, and neM = L;neM;Â·
nVM = neM. Therefore, ne;: = neM + neÂ£ =
neM + neÂ£1 > neM + nVÂ£1 = nvM + nVÂ£1 = nv;:, i.e., the
rem 1, we have
Hence

Procedure ExtendedCausalOrdering
Input:
A structure
constrained SEM.

V0

Definition 3 (strictly under-constrained subÂ­
sets) The strictly under-constrained subsets of a nonÂ­
over-constrained SEM are those under-constrained
subsets that do not contain any self-contained subsets.
Theorem 3 A SEM, S, is under-constrained if and
only if there exists a derived strictly under-constrained
subset inS.
Proof (sketch):

We can prove => by construction and

Â¢:: by contradiction given Theorem
the formal proof.

2.

See (Lu

1999)

Mi

(a) Create nodes

vMâ€¢. Â·
J

non-over-

Vi,

Mi
Vi

is
is

Nj for all variables in

(b) Add arcs from the nodes represent

OVMJ'. \ VMJ'. to nodes in Nj, where
OVMJ'. is the set of the variables

D

Given Theorem 2, we can keep applying identificaÂ­
tion, solving, and substitution operations on derived
non-over-constrained system until either V is empty
or there are no more minimal self-contained subsets
that can be identified. If V is empty, we know that S
is self-contained. If V is not empty and no more selfÂ­
contained subsets can be identified, we know that S
is under-constrained and we call V the derived strictly
under-constrained subsets.

a

1. for each minimal self-contained subset
Mj E Mi, where 1:::; j:::; IMil

2 contradicting the fact that S is non-over-constrained.

V must be non-over-constrained.

of

Let i := 0 and
:= A
while there exists
c
where
the complete subset of i:th order and
the derived structure of i-th order.

variables of :F. In other words, the set :F violates DefiniÂ­
We conclude that

A

Output: A graph G = {V, A( G)}, where V are
the variables in A and A( G) is a set of directed, hiÂ­
directed, or undirected arcs.

number of equations of :F is greater than the number of
tion

matrix

in

OEM'.,
J

equations
(c) if

INJI

the original equations of

EM'.
J

>

1,

of

Mj

in A.

add pair-wise hiÂ­

directed arcs among elements of

Nj.

Mi from Vi to deriveR; (solvÂ­
Mi from
Ri to derive V (substituting).
3. Let i := i + 1 and Vi : = V.
if vi is not empty
2.

Remove

ing) and remove variables of

for each remaining equation
where 1:::; k:::;

vi,
1.

ek in

IV'I
Create nodes Nek for the
of variables, v.k' in ek.

set

2.

Add arcs from nodes repreÂ­
senting
to

3.

Add pair-wise undirected arcs
between nodes

OV.k \ Vek

N.k.

N.k.

Figure 2: Extended Causal Ordering Algorithm

for
D

Figure 2 outlines our extended causal ordering algoÂ­
rithm that is based on Theorem 3. The input of the
algorithm is a non-over-constrained structure matrix
A. The output is a graph G = {V, A(G)}, where the
nodes V are variables and A(G) is a set of directed,
hi-directed, or undirected arcs. The algorithm essenÂ­
tially follows the steps of identification, solving, and
substitution as Simon's causal ordering algorithm unÂ­
til there are no more self-contained subsets that can be
identified from the derived system. The algorithm will
explicitly depict the causal relations and relevant relaÂ­
tions encoded in the strictly under-constrained subset,
if there remains one.
The graph generated by our extended causal ordering
algorithm is specifically designed to aid the process of

model construction. Unlike the original causal orderÂ­
ing algorithm, each variable in the system is repreÂ­
sented as a separate node so that the model builder
can access and manipulate it directly. Directed arcs
depict the causal relations among variables. In addiÂ­
tion to these, our algorithm explicates the causal reÂ­
lations encoded in the under-constrained system. BiÂ­
directed arcs denote feedback mechanisms in stronglyÂ­
coupled subsets. User can visualize the effect of breakÂ­
ing the feedback system by manipulating one of variÂ­
ables connected by the hi-directed arc. Undirected arcs
visually express relevant but undetermined causal relaÂ­
tions among variables so that model builder can focus
on clarifying the mechanisms governing these variables
and complete the model.
Example: Suppose the budget planning officer wants to

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

extend the StudentFacultyRatio model to take the average
class size into account. She adds the structural equations
h : CS = (NS * CL)/(NF * TL) and Is : CL = 15 to
describe the relations among ClassSize ( CS), ClassLoad
( CL), TeachingLoad ( TL), NS and NF. The structure maÂ­
trix of the extended model is as follows.

NS
/1
h
h

h

Is

X

NF
0

0

X

X

X

X

X

0

0

SFR
0
0

cs

0
0

X

X

0
0
0

CL
0
0
0

TL
0
0
0

0

X

0

X

X

After applying the extended causal ordering algorithm to
the system, she obtains the following under-constrained
causal graph.

359

nipulatable variables as exogenous helps in obtaining
a self-contained system, i.e., orienting all arcs in the
model graph. If the user assigns a potential policy
variable, a manipulatable variable that is endogenous
in a self-contained system, as exogenous, the whole
model becomes over-constrained, because the numÂ­
ber of equations is greater than the number of variÂ­
ables. We allow a model to be under-constrained or
self-contained at any stage of the model development
in ImaGeNie, but we disallow a model to be overÂ­
constrained. W hen a model becomes over-constrained,
the system pops up a list of mechanisms that are
currently in the model and asks users to release one
of them in order to change the system into a selfÂ­
contained or an under-constrained system.

CL
4

SESSION

TL
From the under-constrained causal graph, she can read
off the current stage of problem formulation as follows:

StudentFacultyRatio is determined by NumberOIStudents
NumberOfFaculty; currently both ClassSize and
TeachingLoad depend on NumberOfStudents, NumÂ­
berOfFaculty, and ClassLoad, but the relation between
ClassSize and TeachingLoad is not yet determined, which

and

is the consequence of the fact that the system is still
under-constrained.
3.3

EXAMPLE MODEL BUILDING

D

We continue on extending our simple model to demonÂ­
strate how to interact with ImaGeNie to build a simÂ­
plified university budget model from U P B PM knowlÂ­
edge base encoded in ImaGeN/e. Suppose the officer
has designated TL variable as exogenous with equaÂ­
tion fg : TL 6. Figure 3 shows ImaGeNie interface
with the navigation tree of the knowledge base and the
model we have built so far in the workspace.
=

'f GeNie GeNie1

PIï¿½

Modeling Process

The modeling process starts with an initial focus,
which is normally, in the spirit of value-focused thinkÂ­
ing (Keeney 1994), the value variable. Users can also
start with other focus variables, for example decision,
observation, and whatever else is relevant or imporÂ­
tant a-priori. W ith the assistant interface, users can
interactively browse the mechanisms related to their
focus variables, select those that best depict the probÂ­
lem at hand, merge them, or specify exogenous variÂ­
ables to set the boundary of the system. However, we
suggest the users to focus on one variable and add relÂ­
evant mechanisms one at a time as the model evolves,
since it resembles the action of focusing on a variable
of interest, explaining or observing it in terms of its
underlying mechanism. The user repeats the process
iteratively until the model is requisite. In other words,
users make decisions on the level of granularity and
when to stop with the model building process. The
system only plays the passive role of an assistant: sugÂ­
gesting mechanisms to choose from, indicating the posÂ­
sible mechanisms to merge, and denoting the manipuÂ­
latable variables.
Normally a model evolves from an under-constrained
system to a self-contained system. Designating rna-

Urï¿½ver:sity_Mecharum_ï¿½
Smple Unversity ï¿½
UnivetsityCore
ClassSï¿½te

Figure 3: ImaGeNie Interface: Navigation Tree and
the Graphical Model Including Equations: JI, ]2, h ,
h, fs, and fg.
Suppose she would like to plan the expenses related to
faculty salary. She may use the navigation tree to loÂ­
cate mechanisms for faculty salary. Suppose she identiÂ­
fies the mechanism f10: FS =(OJ +TA*NS)j(NF*
( 1 + 0)) that describes the interactions among variÂ­
ables: FacultySalary (FS), Otherlncome (OJ), TuÂ­
itionAmount (TA), Overhead (0), NS and N F . She
drags it into the workspace. In order to maintain the
unique variable identifiers in the model, ImaGeNie auÂ­
tomatically renames the NS and N F into NSO and

360

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS

NF O. The extended causal ordering algorithm generÂ­
ates the graph shown in Figure 4.
IJGeNiel

1!!11!1Â£1

Figure 4: Model builder selects and drags !Io into
workspace; the extended causal ordering algorithm
generates a corresponding graph.
She can then integrate the added mechanism with the
model by merging NS to NSO and NF to NFO. ( See
Figure 5).
iii! GeNiel

2000

that describes the dependence relations among those
variables of interests ( See Figure 6 top). She can now
read off the following dependency relations from the
complete model:
â€¢

Faculty salary is determined by the number of stuÂ­
dents, the number of faculty, tuition amount, other
income, and overhead.

â€¢

Student-faculty ratio is determined by the number of
students and the number of faculty.

â€¢

Class size is determined by the number of students,
the number of faculty, class load, and teaching load.

After inspecting the current self-contained model, she
would like to analyze the model under the condition
that the average class size is fixed at 15 students per
class. She makes the variable CS exogenous by specÂ­
ifying a value assignment equation as fi4 : CS = 15.
Consequently the original self-contained model will beÂ­
come over-constrained. ImaGeNie will ask her to reÂ­
lease one of the equations ( Figure 6 top). Suppose that
she chooses to release the value assignment equation
for the variable T L. The resulting graph generated by
the causal ordering is shown in Figure 6 bottom.

IIIII!JE'l

CS â€¢INS "Cl.)/(NF"TLJ
.,e;;:___..c;;:__-jï¿½ï¿½:(ï¿½JtJA"NS)I(NFâ€¢(1 +0))
CL â€¢ 15
NF â€¢ 3006
01

ill GeNiel

â€¢

30000000

I!II(!J Â£l

Figure 5: Model builder performs the merge operaÂ­
tions for NS (top). The causal ordering generates the
corresponding graph (bottom).

Figure 6: A change in structure on a self-contained
model. The user manipulates CS by setting JI4 :
CS = 15 and releasing f9: TL = 6 (top). The causal
ordering generates the corresponding graph (bottom).

She then makes TA , 0, and OJ exogenous by assigning
equations: fn : TA = 1, 200, !I2 : 0 = 0.48, and
JI3 : OJ= 30,000,000 and obtains a complete model

Now, she can read off the local effect of her change
on the system from the causal graph: teaching load is

361

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

determined by the number of students, the number of
faculty, class load, and class size.

ImaGeNie also supports model builder in extractÂ­
ing reusable mechanisms from the workspace into the
knowledge base. Model builder simply selects the
nodes of interest and drags them into the destination
branch in the navigation tree. Due to space limitaÂ­
tions, we are omitting this example.
5

DISCUSSION A N D FUTURE
WORK

Support for building model structure is one of the
best ways of improving the quality of advice based on
decision-theoretic models. While existing approaches
focus on automatic model construction either from
knowledge base or directly from data, our approach
favors a closely-coupled loop between the system and
its user. This is based on our belief that human judgeÂ­
ment with respect to relevance, model size, completeÂ­
ness, and granularity is more reliable. Built on the
assumption that under-constrained models reflect our
problem recognition stages, ImaGeNie assists users in
encoding their conceptual problem framing in a causal
graph generated by the extended causal ordering alÂ­
gorithm. Furthermore, ImaGeNie provides users with
the flexibility to choose building blocks from knowlÂ­
edge base to extend the model, to manipulate the
variables in order to observe the effect of intervention
(structure changes), and to extract reusable mechaÂ­
nisms from existing models to knowledge bases. The
concept of causal mechanisms, on which ImaGeNie reÂ­
lies, provides a general mean to accommodate different
forms of knowledge description and makes knowledge
acquisition task easier.
Recent research in applying the object-oriented frameÂ­
work to extend Bayesian networks for modeling comÂ­
plex domains (Koller & Pfeffer 1997; Laskey & MaÂ­
honey 1997; Pfeffer et al. 1999) is closely related to
our work. Each of these approaches organizes doÂ­
main knowledge into a hierarchical system. In ObjectÂ­
Oriented Bayesian Network ( O O B N), the domain
knowledge is structured explicitly as class-hierarchy
for the type system and as object-hierarchy for the
real model. In our framework, we do not impose any
constraint on how users should organize their domain
knowledge in the knowledge base. In the future, we
would like to explore the semantics for combining type
system with causal mechanisms so that our knowledge
base can efficiently store the domain knowledge and be
effectively used by users. As for the constructed modÂ­
els, ImaGeNie provides submodels to group nodes into
a graphical organization unit for the sake of succinct
presentation, but there is no special semantic meaning

attached to submodels in terms of inference. We plan
to impose d-sepset (Xiang, Poole, & Beddoes 1993)
constraint on submodels composition such that each
submodel has well defined 1/0 sets to resemble object
hierarchy in O O B N.
Once the model structures generated from our frameÂ­
work are associated with variable ranges and their nuÂ­
merical parameters such as explicit equations or conÂ­
ditional probability tables ( CP Ts), manipulation on
the model may invalidate these numerical parameters.
Druzdzel and van Leijen (2000) have shown the special
conditions under which the CP Ts in Bayesian networks
can be reversed under manipulation. As for the exÂ­
plicit equations, ImaGeNie tries to solve the manipuÂ­
lated system symbolically if there exists a solution. We
would like to further explore conditions under which
we can derive the numerical parameters from the mixÂ­
ture models after manipulation.

ImaGeNie provides a flexible interactive model buildÂ­
ing environment for users to build models in causal
form with as much system assistance as possible but
without giving up their control over the model buildÂ­
ing process. We believe our efforts in incorporating
causality as a heuristic in aiding model building and
knowledge acquisition is an important extension to the
existing approaches.
Acknowledgments
This research was supported by the Air Force Office of SciÂ­
entific Research, grants F49620-97-1-0225 and F4962000-1-0112,

by the National Science Foundation under

Faculty Early Career Development (CAREER) Program,
grant IRI-9624629 , and by a strategic research grant numÂ­
ber RP960351 from the National Science and Technology
Board and the Ministry of Education in Singapore. We
thank anonymous reviewers for suggestions improving the
clarity of the paper.

SMILE and GeNie are available at

http://www2.sis.pitt.edu/ï¿½genie.


. We consider the problem of using a heuristic policy to improve the value approximation by the Upper Confidence Bound applied
in Trees (UCT) algorithm in non-adversarial settings such as planning
with large-state space Markov Decision Processes. Current improvements
to UCT focus on either changing the action selection formula at the internal nodes or the rollout policy at the leaf nodes of the search tree. In
this work, we propose to add an auxiliary arm to each of the internal
nodes, and always use the heuristic policy to roll out simulations at the
auxiliary arms. The method aims to get fast convergence to optimal values at states where the heuristic policy is optimal, while retaining similar
approximation as the original UCT in other states. We show that bootstrapping with the proposed method in the new algorithm, UCT-Aux,
performs better compared to the original UCT algorithm and its variants in two benchmark experiment settings. We also examine conditions
under which UCT-Aux works well.

1

Introduction

Monte Carlo Tree Search (MCTS) [1], or more specifically Upper Confidence
Bound applied in Trees (UCT) [2], is a state-of-the-art approach to solving large
state-space planning problems. Example applications of the UCT algorithm in
the games domain include Go [1,3,4], General Game Playing [5], Real-Time
Strategy Game [6], etc.
The algorithm estimates the value of a state by building a search tree using
simulated episodes, or rollouts, via interactions with the simulator. Instead of
sampling every branch equally, the goal is to focus samplings in tree branches
that are more promising. In particular, UCT achieves that by choosing the action, or arm if its parent node is regarded as a multi-armed bandit, with the
highest estimated upper bound to simulate at every internal node, and randomly
selects actions after leaving the tree to finish the rollout.
Because UCT uses random sampling to discover nodes with good return,
it could take a long time to achieve good performance. To address this problem, many enhancements have been used to improve the search control of the
algorithm by either (1) tweaking the action selection formula at the internal
nodes [7,3,5,4,8], or/and (2) designing better-informed rollout policies in place
of random sampling at the leaf nodes [3,4].

We consider the problem of using a heuristic function to improve the approximated value function computed by UCT. Taking the approaches above, the first
method is to initialize new tree nodes with heuristic values and the second is to
use the chosen heuristic to roll out simulations at the leaf nodes. As intended,
these two methods could greatly influence the search control by guiding it into
more promising regions that are determined by the heuristic. However, when
the heuristic function does not accurately reflect the prospect of the states, it
could feed the algorithm with false information, thereby leading the search into
regions that should be kept unexplored otherwise.
In this work, we propose a novel yet simple enhancement method. Given a
heuristic in the form of an imperfect policy Ï€, the method adds an additional
arm at every internal node of the search tree. This special arm is labeled by
the action suggested by Ï€ and once selected, rolls out the rest of the sampling
episode using Ï€. If the policy Ï€ works well at a state, we expect it to quickly
give a good estimate of the value of the state without relying too much on the
other arms. The method aims to get fast convergence to optimal values at states
where the heuristic policy is optimal, while retaining similar approximation as
the original UCT in other states.
We compared this method with two aforementioned techniques in two domains, namely Obstructed Sailing, an extension of the original Sailing problem
previously used to measure UCTâ€™s performance in [2], and Sheep Savior, a large
state-space MDP that characterizes a generic two-player collaborative puzzle
game. The results showed that UCT-Aux the new algorithm (Aux for auxiliary
arms) significantly outperforms its competitors when coupled with reasonable
heuristics.
One nice property of this method is that it does not affect the implementation of other bootstrapping techniques: No modification of the action selection
formula nor the rollout policy at any leaf nodes except for the added arms is required. This allows different sources of bootstrapping knowledge to be combined
into one algorithm for more performance boost.
The rest of the paper is structured as follows. We first give a brief overview
of MDP, UCT and its popular enhancements before presenting UCT-Aux. Next,
we describe two experimental setups for comparing the agentsâ€™ performance and
analyze the results. We also identify the common properties of the heuristics
used in two experimental domains and provide some insights on why UCTAux works well in those cases. Finally, we conclude the paper by discussing the
possible usage of UCT-Aux.

2
2.1

Background
Markov Decision Process

A Markov Decision Process characterizes a planning problem with tuple (S, A, T, R),
in which
â€“ S is the set of all states,

â€“ A is the set of all available actions,
â€“ Ta (s, s0 ) = P (st+1 = s0 |st = s, at = a) is the probability that action a âˆˆ A
in state s âˆˆ S at time t will lead to state s0 âˆˆ S at time t + 1.
â€“ Ra (s, s0 ) is the immediate reward received after the state transition from s
to s0 triggered by action a.
An action policy Ï€ is a function, possibly stochastic, that returns an action
Ï€(s) for every state s âˆˆ S. In infinite-horizon discounted MDPs, the objective is
to choose an action policy Ï€ âˆ— that maximizes some cumulative
of the
Pâˆž function
t
âˆ—
received rewards, typically the expected discounted sum
t=0 Î³ Ra (st , st+1 )
with 0 â‰¤ Î³ < 1 being the discount factor. An MDP can be effectively solved
using different methods, one of which is the value iteration algorithm based
on the Bellmanâ€™s equation [9]. The algorithm maintains a value function V (s),
where s is a state, and iteratively updates the value function using the equation
!
X
0
0
0
Vt+1 (s) = max
Ta (s, s )(Ra (s, s ) + Î³Vt (s )) .
a

s0

This value iteration algorithm is guaranteed to converge to the optimal value
function V âˆ— (s), which gives the optimal expected cumulative reward of running
the optimal policy from state s.
The optimal value function V âˆ— can be used to construct
the optimal policy
P
by taking action aâˆ— in state s such that aâˆ— = argmaxa { s0 Ta (s, s0 )V âˆ— (s0 )}. The
optimal Q-function is constructed from V âˆ— as follows:
X
Ta (s, s0 )(Ra (s, s0 ) + Î³V âˆ— (s0 )).
Qâˆ— (s, a) =
s0

Qâˆ— (s, a) denotes the maximum expected long-term reward of an action a when
executed in state s.
One key issue that hinders MDPs and Value Iteration from being widely used
in real-life planning tasks is the large state space size (usually exponential in the
number of state variables) that is often required to model realistic problems.
2.2

Upper Confidence Bound Applied to Trees (UCT)

UCT [2] is an anytime algorithm that approximates the state-action value in real
time using Monte Carlo simulations. It was inspired by Sparse Sampling [10],
the first near-optimal policy whose runtime does not depend on the size of the
state space. The approach is particularly suitable for solving planning problems
with very large or possibly infinite state spaces.
The algorithm searches forward from a given starting state, building up a
tree whose nodes alternate between reachable future states and state-action pairs
(Figure 1). State nodes are called internal if their child state-action pairs have
been expanded and leaf otherwise. Starting with a root state, the algorithm
iteratively rolls out simulations from this root node; each time an internal node
is encountered, it is regarded as a multi-armed bandit and UCB1 [11] is used to

a0

S0	
 Â 

S0,a0	
 Â 

a0

S1	
 Â 

a1

a1
S0,a1	
 Â 

S2	
 Â 

S3	
 Â 
a0

a1

S1,a0	
 Â 

S1,a1	
 Â 

S3,a0	
 Â 

S3,a1	
 Â 

S4	
 Â 

S5	
 Â 

S6	
 Â 

S7	
 Â 

Fig. 1: A sample UCT search tree with two valid actions a0 and a1 at any state.
Circles are state nodes and rectangles are state-action nodes; solid state nodes
are internal while dotted are leafs.

determine the action or arm to sample, i.e., the edge to traverse. In particular,
at an internal node s, the algorithm selects an action according to
s
)
(
log n(s)
,
(1)
Ï€U CT (s) = argmax QU CT (s, a) + 2Cp
n(s, a)
a
in which
â€“ QU CT (s, a) is the estimated value of state-action pair (s, a), taken to be the
weighted average of its childrenâ€™s values.
â€“ Cp > 0 is a suitable hand-picked constant.
â€“ n(s) is the total number of rollouts starting from s.
â€“ n(s, a) is the number of rollouts that execute a at s.
At the chosen child state-action node, the simulator is randomly sampled for
a next state with accompanying reward; new states automatically become leaf
nodes. From the leaf nodes, rollouts are continued using random sampling until a
termination condition is satisfied, such as reaching terminal states or simulation
length limit. Once finished, the returned reward propagates up the tree, with the
value at each parent node being the weighted average of its child nodesâ€™ values;
suppose the rollout executes action a at state s and accumulates reward R(s, a)
in the end.
â€“ at state-action nodes, n(s, i) = n(s, i) + 1 and QU CT (s, a) = QU CT (s, a) +
1
n(s,a) (R(s, a) âˆ’ QU CT (s, a))
â€“ at state nodes, n(s) = n(s) + 1.
Typically one leaf node is converted to internal per rollout, upon which its child
state-action nodes are generated. When the algorithm is terminated, the rootâ€™s
arm with highest QU CT (s, a) is returned1 .
1

In practice, returning the arm with highest n(s, a) is also a common choice.

When used for infinite-horizon discounted MDPs, the search can be cut off at
an 0 -horizon. Given any  > 0, with 0 small enough, the algorithm is proven to
converge to the arm whose value is within the -vicinity of the optimal arm [2].
2.3

Enhancement methods

In vanilla UCT, new state-action nodes are initialized with uninformed default
values and random sampling is used to finish the rollout when leaving the tree.
Given a source of prior knowledge, Gelly and Silver [3] proposed two directions
to bootstrap UCT:
1. Initialize new action-state nodes with n(s, a) = nprior (s, a) and QU CT (s, a) =
Qprior (s, a), and
2. Replace random sampling by better-informed exploration guided by Ï€prior .
We refer to these two algorithms as UCT-I (UCT with new nodes initialized
to heuristic values) and UCT-S (UCT with simulations guided by Ï€prior ); UCTIS is the combination of both methods. UCT-I and UCT-S can be further tuned
using domain knowledge to mitigate the flaw of a bad heuristic and amplify the
influence of a good one by adjusting the dependence of the search control on the
heuristic at internal nodes. In this work, we do not investigate the effect of such
tuning to ensure a fair comparison between techniques when employed as is.
In the same publication [3], the authors proposed another bootstrapping technique, namely Rapid Action Value Estimation (RAVE), which we do not examine
in this work. The technique is specifically designed for domains in which an action from a state s has similar effect regardless of when it is executed, either at s
or after many moves. RAVE uses the All-Moves-As-First (AMAF) heuristic [12]
instead of QU CT (s, a) in Equation 1 to select actions. Many board games such as
Go or Breakthrough [5] have this desired property. In our experiment domains,
RAVE is not applicable, because the actions are mostly directional movements,
e.g., {N, E, S, W }, thus tied closely to the state they are performed at.

3

UCT-Aux: Algorithm

Given an added policy Ï€, we propose a new algorithm UCT-Aux that follows
the same search control as UCT except for two differences.
1. At every internal node s, besides |A(s)| normal arms with A(s) being the
set of valid actions at state s, an additional arm labeled by the action Ï€(s)
is created (Figure 2).
2. When this arm is selected by Equation 1, it stops expanding the branch but
rolls out a simulation using Ï€; value update is carried out from the auxiliary
arm up to the root as per normal.
The method aims to better manage mixed-quality heuristics. If the heuristic
Ï€â€™s value estimation at a state is good, we expect the added arm to dominate

S0	
 Â 

a0
S0,a0	
 Â 

a1

Ï€(s0)

S0,a1	
 Â 

S0, Ï€(s0)	
 Â 
	
 Â 

a0
S1,a0	
 Â 

S1	
 Â 
a1
S1,a1	
 Â 

Ï€(s1)

S2	
 Â 

S1, Ï€(s1)	
 Â 

S3	
 Â 
a0

a1

Ï€(s3)

S3,a0	
 Â 

S3,a1	
 Â 

S3, Ï€(s3)	
 Â 
	
 Â 

	
 Â 

S4	
 Â 

S5	
 Â 

S6	
 Â 

S7	
 Â 

Fig. 2: Sample search tree of UCT-Aux.

the distribution of rollouts and quickly give a good estimate of the stateâ€™s value
without the need to inspect other arms. Otherwise, the search control will focus
rollouts in ordinary arms, thus retaining similar approximation as vanilla UCT.
For stochastic heuristic policies, at every internal node, not one but Îº auxiliary arms are added, with Îº being the number of actions aÏ€ such that P (Ï€(s) =
aÏ€ ) > 0. As such, the number of arms at internal nodes is bounded by 2|A| since
Îº â‰¤ |A|.
Convergence Analysis
We will show that regardless of the added policyâ€™s quality, UCT-Aux converges in
finite-horizon MDPs2 . The proof follows closely that of UCT analysis by treating
the auxiliary arms as any other ordinary arms. As a recap, UCT convergence
analysis revolves around the analysis of non-stationary multi-armed bandits with
reward sequences satisfying some drift conditions, which is proven to be the
case for UCTâ€™s internal nodes with appropriate choice of bias sequence Cp 3 . In
particular, the drift conditions imposed on the payoff sequences go as follows:
Pn
â€“ The expected values of the averages X in = n1 t=1 Xit must converge for
all arms i with n being the number of pulls and Xit the payoff of pull t. Let
Âµin = E[X in ] and Âµi = limnâ†’âˆž Âµin .
â€“ Cp > 0 can be chosen such that the tail inequalities P (X i,n(i) â‰¥ Âµi +ct,n(i) ) â‰¤
q
ln t
tâˆ’4 and P (X i,n(i) â‰¤ Âµi âˆ’ ct,n(i) ) â‰¤ tâˆ’4 are satisfied for ct,n(i) = 2Cp n(i)
with n(i) being the number of times arm i is pulled up to time t.
Firstly, we will show that all internal nodes of UCT-Aux have arms yielding
rewards satisfying the drift conditions. Suppose the horizon of the MDP is D, the
number of actions per state is K and the heuristic policy is deterministic (Îº = 1);
2

3

As mentioned in [2], for use with discounted infinite-horizon MDPs, the search tree
can be cut off at the effective 0 -horizon with 0 being the desired accuracy at root.
Empirically, Cp is often chosen to be an upper bound of the accumulated reward
starting from the current state.

this can be proven using induction on D. Note that i.i.d. payoff sequences satisfy
the drift conditions trivially due to Hoeffdingâ€™s inequality.
â€“ D = 1: Suppose the root has already been expanded, i.e., become internal.
It has K + 1 arms, which either lead to leaf nodes (ordinary arms) or return
i.i.d. payoffs (auxiliary arm). Since leaf nodes have i.i.d. payoffs, all arms
satisfy drift conditions.
â€“ D > 1: Assume that all internal state nodes under the root have arms
satisfying the drift conditions, e.g., s1 and s3 in Figure 2. Consider any
ordinary arm of the root node (the added armâ€™s payoff sequence is already
i.i.d.), for instance, (s0 , a1 ). Its payoff average is the weighted sum of payoff
sequences in all leafs and state-action nodes on the next two levels of the
subtree, i.e., leaf s2 , arms (s3 , a0 ), (s3 , a1 ) and (s3 , Ï€(s3 )), all of which satisfy
drift conditions due to either the inductive hypothesis or producing i.i.d.
payoffs. Theorem 4 in [2] posits that the weighted sum of payoff sequences
conforming to drift conditions also satisfies drift conditions; therefore, all
arms originating from the root node satisfy drift conditions.
As a result, the theorems on non-stationary bandits in [2] hold for UCTAuxâ€™s internal nodes as well. Therefore, we can obtain similar results to Theorem
6 of [2], with the difference being statistical measures related to the auxiliary
arms such as Âµaux and âˆ†aux , i.e., the new algorithmâ€™s probability of selecting a
suboptimal arm converges to zero as the number of rollouts tends to infinity.

4

Experiments

We compare the performance of UCT-Aux against UCT, UCT-I, UCT-S and
UCT-IS in two domains: Obstructed Sailing and Sheep Savior. Obstructed Sailing extends the benchmark Sailing domain by placing random blockage in the
map; the task is to quickly move a boat from one point to a destination on a
map, disturbed by changing wind, while avoiding obstacles. Sheep Savior features a two-player maze game in which the players need to herd a sheep into its
pen while protecting it from being killed by two ghosts in the same environment.

5

Obstructed Sailing

The Sailing domain, originally used to evaluate the performance of UCT [2],
features a control problem in which the planner is tasked to move a boat from a
starting point to a destination under certain disturbing wind conditions. In our
version, there are several obstacles placed randomly in the map (see Figure 3a).
In this domain, the state is characterized by tuple hx, y, b, wprev , wcurr i with
(x, y) being the current boat position, b the current boat posture or direction,
wprev the previous wind direction and wcurr the current wind direction. Directions take values in {N, NE, E, SE, S, SW, W, NW}, i.e. clockwise starting from
North. The controllerâ€™s valid action set includes all but the directions against

(a) Obstructed Sailing sample map

(b) SailTowardsGoal

Fig. 3: Obstructed Sailing domain; (a) a randomized starting configuration,
(b) SailTowardsGoal heuristic produces near-optimal estimates/policies in good
cases but misleads the search control in others.

wcurr , out of the map or into an obstacle. After each time step, the wind has
roughly equal probability to remain unchanged, switch to its left or its right [13].
Depending on the relative angle between the action taken and wcurr , a cost
from 1 to 4 minutes is incurred. Additionally, changing from a port to a starboard
tack or vice versa causes a tack delay of 3 minutes. In total, an action can cost
anywhere from 1 to 7 minutes, i.e., Cmin = 1 and Cmax = 7 [13]. We model the
problem as an infinite-horizon discounted MDP with discount factor Î³ = 0.99.
5.1

Choice of heuristic policies

A simple heuristic for this domain is to select a valid action that is closest to the
direction towards goal position regardless of the cost, thereafter referred to as
SailTowardsGoal. For instance, in the top subfigure of Figure 3b, at the starting
state marked by â€œSâ€, if current wind is not SW, SailTowardsGoal will move the
boat in the NE direction; otherwise, it will execute either N or E.
This heuristic is used in UCT-I and UCT-IS by initializing new state-action
nodes with values
nST G (s, a) â† 1
0

1 âˆ’ Î³ d(s ,g)+1
QST G (s, a) â† C(s, a) + Cmin
1âˆ’Î³
with C(s, a) being the cost of executing action a at state s and d(s0 , g) the
minimum distance between next state s0 and goal position g. The initialized

value can be seen as the minimum cost incurred when all future wind directions
are favorable for desired movement. For UCT-S, the random rollouts are replaced
by Ï€(s) = argmaxa QST G (s, a).
Heuristic quality. This heuristic works particularly well for empty spaces,
producing near-optimal plans if there are no obstacles. However, it could be
counterproductive when encountering obstacles. In the bottom subfigure of Figure 3b, if a rollout from the starting position is guided by SailTowardsGoal, it
could be stuck oscillating among the starred tiles, thus giving inaccurate estimation of the optimal cost.
5.2

Setup and results

The trial map size is 30 by 30, with fixed starting and goal positions at respectively (2, 2) and (27, 27) (Figure 3a). We generated 100 randomized instances of
the map, where obstacles are shuffled by giving each grid tile p = 0.4 chance
to be blocked 4 . Each instance is tried five times, each of which with different
starting boat postures and wind directions.

Fig. 4: Performance comparison of UCT, UCT-S, UCT-I, UCT-IS and UCT-Aux
when coupled with the heuristic SailTowardsGoal; y-axis is the reward average
with error bars being the standard errors of the means.

All UCT variants (UCT, UCT-I, UCT-S, UCT-IS and UCT-Aux) use the
same Cp = Cmax /(1 âˆ’ Î³) = 700 and the search horizon5 is set to be 300; an
4

5

We tried with different values of p âˆˆ {0.05, 0.1, 0.2, 0.3, 0.5} and they all yield similar
results as Figure 4; the detailed charts are not presented due to space constraint.
The search horizon is chosen to be long enough so that the cost accumulated after
the horizon has small effect to the total cost.

optimal path should not be very far from 60 steps as most actions move the boat
closer to the goal. The exact optimal policy is obtained using Value Iteration.
Note that the performance of Optimal agent varies because of the randomization
of starting states (initial boat and wind direction) and map configurations.
Given the same number of samplings, UCT-Aux outperforms all competing
UCT variants, despite the mixed quality of the added policy SailTowardsGoal
when dealing with obstacles (Figure 4). Note that without parameter tuning,
both UCT-I and UCT-S are inferior to vanilla UCT, but between UCT-I and
UCT-S, UCT-I shows faster performance improvement when the number of samplings increases. The reason is because when SailTowardsGoal produces inaccurate heuristic values, UCT-I only suffers at early stage while UCT-S endures
misleading guidance until the search reaches states where the policy yields more
accurate heuristic values. The heuristicâ€™s impact is stronger in UCT-S than UCTI: UCT-ISâ€™s behavior is closer to UCT-S than UCT-I.

6

Sheep Savior

This domain is an extension of the Collaborative Ghostbuster game introduced
in [14] as the testbed for their assistance framework for collaborative games.
The game features two players (a shepherd and a dog) whose task is to herd
a sheep into its pen while avoiding it to be killed by two ghosts in a maze-like
environment. All non-player characters (NPCs) run away from the players within
a certain distance, otherwise the ghosts chase the sheep and the sheep runs away
from ghosts. Since ghosts can only be shot by the Shepherd, the dogâ€™s role is
strictly to gather the NPCs (Figure 5).
Both protagonists have 5 movement actions (no move, N, S, E and W) while
Shepherd has an additional action to inflict damage on a nearby ghost, hence a
total of 30 compound actions. The two players are given rewards for successfully
killing ghosts (5 points) or herding sheep into its pen (10 points). If the sheep
is killed, the game is terminated with penalty -10. The discount factor in this
domain is set to be 0.99.
6.1

Choice of heuristic policies

The game can be seen as having three subtasks, each of which is the task of
catching a single ghost or herding a single sheep, as shown in Figure 5. Each of
these subtasks consists of only two players and one NPC, hence has manageable
complexity and can be solved exactly offline using Value Iteration.
A heuristic Q-value can be obtained by taking the average of all individual
subworldsâ€™, or subtasksâ€™, Q-values, as an estimate for one state-action pairâ€™s
value. Specifically, at state s the policy, GoalAveraging, yields
nGA (s, a) â† 1
m

QGA (s, a) =

1 X
Qi (si , a)
m i=1

Fig. 5: Task decomposition in Sheep Savior.

in which si is the projection of s in subtask i, m is the number of subtasks,
i.e. three in this case, and Qi (si , a) are subtasksâ€™ Q-values. The corresponding
heuristic policy can be constructed as Ï€GA (s) = argmaxa QGA (s, a).
Heuristic quality. GoalAveraging works well in cases when the sheep is
well-separated from ghosts. However, when these creatures are close to each
other, the policyâ€™s action estimation is no longer valid and could yield deadly
results. The under-performance is due to the fact that the heuristic is oblivious
to the interactivity between subtasks, in this case, ghost-killing-sheep scenarios.
6.2

Setup and results

The map shown in Figure 5 is tried 200 times, each of which with a different randomized starting configurations. We compare the means of discounted rewards
produced by the following agents: Random, GoalAveraging, UCT, UCT-I, UCTS, and UCT-Aux. The optimal policy in this domain is not computed due to the
prohibitively large state space, i.e., 1045 âˆ— 32 â‰ˆ 1011 since each ghost has at
most two health points. All UCT variants have a fixed planning depth of 300.
In our setup, one second of planning yields roughly 200 rollouts on average, so
we do not run simulations with higher numbers of rollouts than 10000 due to
time constraint. Moreover, in this game-related domain, the region of interest is
in the vicinity of 200 to 500 rollouts for practical use.
As shown in Figure 6, UCT-Aux outperforms the other variants, especially
early on with small numbers of rollouts. UCT-S takes advantage of GA better
than UCT-I, which yields even worse performance than vanilla UCT. Observing
the improvement rate of UCT-S we expect it to approach UCT-Aux much sooner
than others, although asymptotically all of them will converge to the same optimal value when enough samplings are given and the search tree is sufficiently
expanded; the time taken could be prohibitively long though.

Fig. 6: Performance comparison of Random, GoalAveraging, UCT, UCT-S,
UCT-I, and UCT-Aux when coupled with Goal Averaging.

7

Discussions

Although UCT-Aux shows superior performances in the experiments above, we
observe that the chosen heuristic policies share a common property that is crucial
for UCT-Auxâ€™s success: they show behaviors of â€œmake it or break itâ€. In other
words, at most states s, their action value estimate QÏ€ (s, a) is either near-optimal
or as low as that of a random policy Qrand (s, a).
Specifically, in Obstructed Sailing, if following SailTowardsGoal can bring
the boat from a starting state to goal position, e.g., when the line of sight
connecting source and destination points lies entirely in free space, the resultant
course of actions does not deviate much from the optimal action sequences.
However when the policy fails to reach the goal, it could be stuck fruitlessly. For
instance, Figure 3b depicts one such case; once the boat has reached either one
of three starred tiles underneath the goal position, unless at least three to five
wind directions in a row are E, SailTowardsGoal results in oscillating the boat
among these starred tiles. The resultant cost is therefore very far from optimal
and could be as low as the cost incurred by random movement.
In contrast, an example for heuristics that are milder in nature is the policy StochasticOptimal.0.2 which issues optimal actions with probability 0.2 and
random actions for the rest. This policy is also suboptimal but almost always
yields better estimation than random movement; it is not as â€œextremeâ€ as SailTowardsGoal. Figure 7, which charts the performance histograms of StochasticOptimal.0.2 alongside with SailTowardsGoal, shows that a majority of runs with
SailTowardsGoal yield costs that are either optimal or worse than Randomâ€™s.
Similarly, GoalAveraging in Sheep Savior is also extreme: By ignoring the
danger of Ghosts when around Sheep, it is able to quickly herd the Sheep in the
Pen or kill nearby Ghosts (good), or end the game prematurely by forcing the

Fig. 7: Performance histograms of heuristics in Obstructed Sailing. The returned
costs of a heuristic are allocated relatively into bins that equally divide the cost
difference between Random and Optimal agents; x-axis denotes the bin number
and y-axis the frequency.

Sheep into Ghostsâ€™ zones (bad). We hypothesize that one way to obtain extreme
heuristics is by taking near-optimal policies of the relaxed version of the original planning problem, in which aspects of the environment that cause negative
effects to the accumulated reward are removed. For instance, SailTowardsGoal
is in spirit the same as the optimal policy for maps with no obstacle, while
GoalAveraging should work well if the ghosts do not attack sheep.
As UCT-Aux is coupled with heuristic policies with this â€œextremeâ€ characteristic, rollouts are centralized at auxiliary arms of states where Ï€(s) is nearoptimal, and distributed to ordinary arms otherwise. Consequently, the value
estimation falls back to the default random sampling where Ï€ produces inaccurate estimates instead of relying entirely on Ï€ as does UCT-S.
7.1

When does UCT-Aux not work?

Figure 8 charts the worst-case behavior of UCT-Aux when the coupled heuristicâ€™s
estimate is mostly better than random sampling but much worse than that of the
optimal policy, e.g. the heuristic StochasticOptimal.0.2 in Obstructed Sailing.
The reason behind UCT-Auxâ€™s flop is the same as that of UCT, i.e., due
to the overly â€œoptimismâ€ of UCB1, as described in [8]. At each internal node,
samplings are directed into suboptimal arms that appear to perform the best so
far, exponentially more than the rest (Theorem 1 [2]) when convergence has not
started. Even though each arm is guaranteed to be sampled an infinite number
of times when the number of samplings goes to infinity (Theorem 3 [2]), the subpolynomial rate means only a tiny fraction of samplings are spent on attempting
bad-looking arms. As a result, in a specially designed binary tree search case,
UCT takes at least â„¦(exp(exp(...exp(2)...))) samplings before the optimal node
is discovered; the term is a composition of D âˆ’ 1 exponential functions with D
being the number of actions in the optimal sequence.

Fig. 8: Bad case of UCT-Aux when coupled with StochasticOptimal.0.2.
Samplings
UCT
UCT-S
UCT-I
UCT-IS
UCT-Aux

500
268.4
268.9
279.2
278.6
159.2

1000
555.4
558.6
583
586
256.7

2000
1134.6
1157.3
1200.7
1209.2
447.8

5000
2694.5
2733.2
2805
2834.8
889.5

10000
5395.7
5424.7
5620
5657.1
1341.7

20000
11041.7
11212.7
11519.4
11704.4
1981.3

50000
27107.4
27851.2
28123.8
28872.5
3117.9

100000
53235.9
54382.2
55393.7
56401.2
4317.1

200000
107107
109308
111418
113682
5970.11

Table 1: The average number of tree nodes for UCT variants in Obstructed
Sailing when coupled with StochasticOptimal.0.2.

UCT-Aux falls into this situation when coupled with suboptimal policies
whose estimates are better than random sampling: At every internal node, it
artificially creates an arm that is suboptimal but produces preferable reward
sequences when compared to other arms with random sampling. As a result,
the auxiliary arms are sampled exponentially more often while not necessarily
prescribing a good move. Table 1 shows some evidence of this behavior: Given the
same number of samplings, UCT-Aux constructs a search tree with significantly
less nodes than other variants (up to 20 times). That means many samplings
have ended up in non-expansive auxiliary arms because they were preferred.
7.2

Combination of UCT-Aux, UCT-I and UCT-S

UCT-Aux bootstraps UCT in an orthogonal manner to UCT-I and UCT-S, thus
allowing combination with these common techniques for further performance
boost when many heuristics are available. Figure 9 charts the performance of

such combinations in Obstructed Sailing. UCT-Aux variants use SailTowardsGoal at the auxiliary arms while UCT-I/S variants use StochasticOptimal.0.2
at the ordinary arms. UCT-Aux-S outperforms both UCT-Aux and UCT-S at
earlier stage, and matches the better performer among the two, i.e. UCT-Aux,
in a long run.

Fig. 9: Combination of UCT-Aux with UCT-I/S/IS in Obstructed Sailing.

8

Conclusion

In this work, we have introduced a novel yet simple technique to bootstrap UCT
with an imperfect heuristic policy in a popular non-adversarial domain, i.e.,
planning in large-state space MDPs. It is shown to be able to leverage on the
well-performing region while avoiding the bad regions of the policy, empirically
outperforming other state-of-the-art bootstrapping methods when coupled with
the right policy, i.e, the â€œextremeâ€ kind. Our conclusion is that if such property is
known before hand about a certain heuristic, UCT-Aux can be expected to give
a real boost over the original UCT, especially in cases with scarce computational
resource; otherwise, it would be safer to employ the currently prevalent methods
of bootstrapping. As such, a different mentality can be employed when designing
heuristics specifically for UCT-Aux: instead of safe heuristics that try to avoid
as many flaws as possible, the designer should go for greedier and â€œriskierâ€ ones.
Lastly, since UCT-Aux is orthogonal to other commonly known enhancements,
it is a flexible tool that can be combined with others, facilitating more options

when incorporating domain knowledge into the vanilla MCTS algorithm. In the
future, we plan to examine how to adapt the method to adversarial domains.

9

Acknowledgments

This research is partially supported by a GAMBIT grant â€Tools for Creating
Intelligent Game Agentsâ€, no. R-252-000-398-490 from the Media Development
Authority and an Academic Research Grant no. T1 251RES1005 from the Ministry of Education in Singapore.


