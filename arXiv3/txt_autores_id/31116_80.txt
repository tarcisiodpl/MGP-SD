
We formulate in this paper the mini-bucket
algorithm for approximate inference in terms
of exact inference on an approximate model
produced by splitting nodes in a Bayesian
network. The new formulation leads to
a number of theoretical and practical implications. First, we show that branchand-bound search algorithms that use minibucket bounds may operate in a drastically
reduced search space. Second, we show that
the proposed formulation inspires new minibucket heuristics and allows us to analyze existing heuristics from a new perspective. Finally, we show that this new formulation allows mini-bucket approximations to benefit
from recent advances in exact inference, allowing one to significantly increase the reach
of these approximations.

1

INTRODUCTION

Probabilistic reasoning tasks in Bayesian networks are
typically NP–hard, and approximation algorithms are
often sought to address this apparent intractability.
One approach to approximate inference is based on
mini-buckets, a scheme that has been successfully employed by branch-and-bound algorithms for computing
MPEs (Most Probable Explanations) (Dechter & Rish,
2003; Marinescu, Kask, & Dechter, 2003). Roughly
speaking, mini-buckets is a greedy approach to approximate inference that applies the variable elimination algorithm to a problem, but only as long as computational resources allow it. When time and space
constraints keep us from progressing, a mini-buckets
approach will heuristically ignore certain problem dependencies, permitting the process of variable elimination to continue (Zhang & Poole, 1996; Dechter,
1996). Mini-buckets will therefore give rise to a family

of approximations that, in particular, are guaranteed
to produce upper bounds on the value we seek, and
further whose quality depends on the heuristic used to
ignore dependencies.
In this paper, we make explicit in the most fundamental terms the dependencies that mini-bucket approximations ignore. In particular, we reformulate the
mini-bucket approximation using exact inference on an
approximate model, produced by removing dependencies from the original model. We refer to this process
of removing dependencies as node splitting, and show
that any mini-bucket heuristic can be formulated as a
node splitting heuristic.
This perspective on mini-buckets has a number of
implications, both theoretical and practical. First,
it shows how one can significantly reduce the search
space of brand-and-bound algorithms that make use
of mini-bucket approximations for generating upper
bounds. Second, it provides a new basis for designing
mini-bucket heuristics, a process which is now reduced
to specifying an approximate model that results from
node splitting. We will indeed propose a new heuristic and compare it to an existing heuristic, which we
reformulate in terms of node splitting. Third, it allows one to embed the mini-bucket approximation in
the context of any exact inference algorithm—for example, ones that exploits local structure (Chavira &
Darwiche, 2006)—which could speed up the process of
generating mini-bucket bounds, without affecting the
quality of the approximation. We will illustrate this
ability in some of the experiments we present later.
This paper is organized as follows. In Section 2, we
review the MPE task, as well as algorithms for finding
MPEs. In Section 3, we define node splitting operations for Bayesian networks, and show in Section 4
how mini-bucket elimination is subsumed by splitting
nodes. In Section 5, we examine mini-buckets as a
node splitting strategy, and introduce a new strategy
based on jointrees. In Section 6, we consider branchand-bound search for finding MPEs, and show how

58

CHOI ET AL.

we can exploit node splitting to improve the efficiency
of search. In Section 7, we provide empirical support
for the claims in Section 6, and conclude in Section 8.
Proofs and other results appear in the Appendix.

2

MOST PROBABLE
EXPLANATION

We will ground our discussions in this paper using the
problem of computing MPEs, which we define formally
next. Let N be a Bayesian network with variables X,
inducing distribution Pr . The most probable explanation (MPE) for evidence e is then defined as:
MPE (N, e)

def

=

arg max Pr (x),
x∼e

where x ∼ e means that instantiations x and e are
compatible: they agree on every common variable.
Note that the MPE solution may not be unique, in
which case MPE (N, e) denotes a set of MPEs. One
can also define the MPE probability:
MPE p (N, e)

def

=

max Pr (x).
x∼e

A number of approaches have been proposed to tackle
the MPE problem, when a Bayesian network has a
high treewidth. These include methods based on local search (Park, 2002; Hutter, Hoos, & Stützle, 2005)
and max-product belief propagation (e.g., Pearl, 1988;
Weiss, 2000), including generalizations (e.g., Yedidia,
Freeman, & Weiss, 2005; Dechter, Kask, & Mateescu,
2002) and related methods (Wainwright, Jaakkola, &
Willsky, 2005; Kolmogorov & Wainwright., 2005). Although these approaches have been successful themselves, and can provide high-quality approximations,
they are in general non-optimal.
An approach based on systematic search can be used to
identify provably optimal MPE solutions, although the
efficiency of a search depends heavily on the problem
formulation as well as the accompanying heuristics.
In particular, it is quite common also to use branchand-bound search algorithms for computing MPEs and
their probability (e.g., Marinescu et al., 2003; Marinescu & Dechter, 2005). The use of these search algorithms, however, requires the computation of an upper
bound on the MPE probability to help in pruning the
search space. The mini-buckets method is the state of
the art for computing such bounds (Dechter & Rish,
2003). In fact, the success of mini-buckets is most apparent in this context of computing MPEs, which is
the reason we will use this application to drive our
theoretical analysis and empirical results.

X

X

Figure 1: When we split a variable X (left), we create
a clone X̂ that inherits some of the children (right).

3

SPLITTING NODES

We will define in this section a method for approximating Bayesian networks by splitting nodes: An operation that creates a clone X̂ of some node X, where the
clone inherits some of the children of X; see Figure 1.
Definition 1 Let X be a node in a Bayesian network N with children Y. We say that node X is
split according to children Z ⊆ Y when it results in
a network that is obtained from N as follows:
• The edges outgoing from node X to its children Z
are removed.
• A new root node X̂ with a uniform prior is added
to the network with nodes Z as its children.
A special case of node splitting is edge deletion, where
a node is split according to a single child (i.e., splitting also generalizes edge deletion as defined in Choi
& Darwiche, 2006a, 2006b).
Definition 2 Let X → Y be an edge in a Bayesian
network N . We say that node X is split along an edge
X → Y when the node X is split according to child Y .
The following case of node splitting will be the basis of
a splitting strategy that yields a special class of minibucket approximations with implications in search.
Definition 3 Let X be a node in a Bayesian network
N . We say that node X is fully split when X is split
along every outgoing edge X → Y .
Thus, when we fully split a node X, we create one clone
for each of its outgoing edges. Figure 2 illustrates an
example of a network where two nodes have been split.
Node C has been split according to children {D, E},
and Node A has been split along the edge A → D.
A network N 0 which results from splitting nodes in
network N has some interesting properties. To explicate these properties, however, we need to introduce
a function which, given an instantiation x of variables
in network N , gives us an instantiation of clones in N 0
that agrees with the values given to variables in x.

CHOI ET AL.

59

Algorithm 1 ve(N, e): returns MPE p (N, e).
1: i ← 0
2: S ← {f e | f e is a CPT (incorporating e) of N }
3: while S contains variables do
4:
i←i+1
5:
X ← a variable appearing in S
6:
Si ← all factors
Y in S that contain X
7:
fi ← max
f
X

Figure 2: A Bayesian network N (left) and an approximation N 0 (right) found by splitting C according to
{D, E}, and splitting A according to D.
Definition 4 Let N be a Bayesian network, and let
N 0 be the result of splitting nodes in N . If x is an
→
instantiation of variables in N , then let −
x be the compatible instantiation of the corresponding clones in N 0 .
For example, in the split network in Figure 2, an instantiation x = {A = a1 , B = b1 , C = c2 , D = d3 , E = e1 }
→
is compatible with instantiation −
x = {Â = a1 , Ĉ = c2 }.
Moreover, x is not compatible with {Â = a1 , Ĉ = c1 }.
To see the effect that splitting a node can have on a
network, consider a simple two-node network A → B
with binary variables, where θa1 = .2, θb1 |a1 = .1, and
θb1 |a2 = .7. After splitting A according to B, we have:
x
a1 b 1
a1 b 2
a2 b 1
a2 b 2

0

Pr (x)
0.02
0.18
0.56
0.24

x
a1 â1 b1
a1 â1 b2
a1 â2 b1
a1 â2 b2
a2 â1 b1
a2 â1 b2
a2 â2 b1
a2 â2 b2

0

0

0

Pr (x )
0.01
0.09
0.07
0.03
0.04
0.36
0.28
0.12

x
a1 â1 b1
a1 â1 b2
a1 â2 b1
a1 â2 b2
a2 â1 b1
a2 â1 b2
a2 â2 b1
a2 â2 b2

0

0

βPr (x )
0.02
0.18
0.14
0.06
0.08
0.72
0.56
0.24

where β = |A1 | = 2. We see that whenever A1 and its
clone Â1 are set to the same value, we can recover the
original probabilities Pr (x) after splitting, by using
βPr 0 (x0 ). This includes the value of the MPE in N ,
which may no longer be the largest value of βPr 0 (x0 ).
This intuition yields the key property of split networks.
Theorem 1 Let N be a Bayesian network, and let N 0
be the result of splitting nodes in N . We then have
→
MPE (N, e) ≤ βMPE (N 0 , e, −
e ).
Q

Here, β =
network N 0 .

p

C∈C

p

|C|, where C is the set of clones in

That is, the MPE probability with respect to a split
network provides an upper bound on the MPE probability with respect to the original network. We note
that the probability of evidence is also upper bounded
in the split network; see Theorem 3 in the Appendix.

f ∈Si

8:
S ← S − Si ∪ {fi }
9: return product of factors in S

Algorithm 2 mbe(N, e): returns an upper bound on
MPE p (N, e).
{ Identical to Algorithm 1, except for Line 6: }
6:
Si ← some factors in S that contain X

The following corollary shows that splitting degrades
the quality of approximations monotonically.
Corollary 1 Let network N2 be obtained by splitting
nodes in network N1 , which is obtained by splitting
nodes in network N0 . We then have
MPE p (N0 , e)

→
≤ β1 MPE p (N1 , e, −
e1 )
−
→
≤ β MPE (N , e, e ),
2

p

2

2

−
→
where β1 , β2 and →
e1 , −
e2 are as defined by Theorem 1.

4

MINI-BUCKET ELIMINATION

We discuss in this section the relationship between the
approximations returned by split networks and those
computed by the mini-buckets algorithms (Dechter &
Rish, 2003). In particular, we show that every minibuckets heuristic corresponds precisely to a node splitting strategy, where exact inference on the resulting
split network yields the approximations computed by
mini-buckets. Our discussion here will be restricted to
computing MPEs, yet the correspondence extends to
probability of evidence as well.
We start first by a review of the mini-buckets method,
which is a relaxed version of the variable elimination
method given in Algorithm 1 (Zhang & Poole, 1996;
Dechter, 1996). According to this algorithm, variable
elimination starts with a set of factors corresponding
to the CPTs of a given Bayesian network. It then
iterates over the variables appearing in factors, eliminating them one at a time. In particular, to eliminate a variable X, the method multiplies all factors
that contain X and then max-out X from the result.
The bottleneck of this algorithm is the step where the
factors containing X are multiplied, as the resulting

60

CHOI ET AL.
Θ Θ

Θ

Θ Θ

Θ
Θ

Θ
Θ
Θ

∅

∅ ∅

Figure 3: An execution trace of ve on N (left) and
mbe on N (right). The network is defined in Figure 2.

factor may be too big for the computational resources
available. The mini-bucket method deals with this difficulty by making a simple change to the variable elimination algorithm (also known as the bucket elimination
algorithm).1 This change concerns Line 6 in which all
factors containing variable X are selected. In minibuckets, given in Algorithm 2 (Dechter & Rish, 2003),
one chooses only a subset of these factors in order to
control the size of their product. Which particular set
of factors is chosen depends on the specific heuristic
used. Yet, regardless of the heuristic used, the answer
obtained by the mini-buckets method is guaranteed to
be an upper bound on the correct answer.2 One should
note here that the simple change from all to some on
Line 6 implies the following. The number of iterations
performed by Algorithm 1 is exactly the number of
network variables, since each iteration will eliminate
a network variable. However, Algorithm 2 may only
partially eliminate a variable in a given iteration, and
may take multiple iterations to eliminate it completely.
To help us visualize the computations performed by
Algorithms 1 and 2, consider their execution trace.
Definition 5 Given an instance of ve or mbe run
on a given network N , we define its execution trace T
as a labeled DAG which adds, for each iteration i,
• a node i, labeled by the factor set Si , and
• directed edges j → i, for all factors fj ∈ Si , each
labeled by the corresponding factor fj .
1

More precisely, bucket elimination is a particular implementation of variable elimination in which one uses a list
of buckets to manage the set of factors during the elimination process. Although the use of such buckets is important
for the complexity of the algorithm, we ignore them here
as the use of buckets is orthogonal to our discussion.
2
This is also true for versions of the algorithm that compute the probability of evidence.

Figure 3 depicts traces of both algorithms on the network in Figure 2 (left). Variable elimination, whose
trace is shown on the left, eliminates variables from A
to E, and performs five iterations corresponding to the
network variables. Mini-buckets, however, performs
seven iterations in this case, as it takes two iterations
to eliminate variable A and two iterations to eliminate
variable C. Note that an execution trace becomes a
rooted tree after reversing the direction of all edges.
Given an execution trace T , we can visually identify
all of the network CPTs used to construct any factor
in Algorithms 1 and 2. For mini-buckets, we also want
to identify a subtrace of T , but one that covers only
those network CPTs that are relevant to a particular
attempt at eliminating variable X at iteration i. A
CPT is not relevant to iteration i if X is eliminated
from it in a later iteration, or if X has already been
eliminated from it in some previous iteration.
Given a trace T , we thus define the subtrace Ti relevant
to an iteration i as the nodes and edges of T that are
reachable from node i (including itself), but only by
walking up edges j → i, and only those edges labeled
with factors fj mentioning variable X. For example,
in Figure 3 (right), the subtrace Ti for iteration i = 7 is
the chain 4 → 6 → 7. In the same trace, the subtrace
Ti for iteration i = 5 is the chain 1 → 3 → 5.
Given a subtrace Ti , we can identify only those CPTs
that are relevant to a partial elimination of X, but
further, the set of variables those CPTs belong to.
Definition 6 Let i be an iteration of mbe where we
eliminate variable X, and let Ti be the subtrace of T
that is relevant to iteration i. The basis B of an iteration i is a set of variables where Y ∈ B iff:
• ΘY |U ∈ Sj for some node j of Ti , and
• X ∈ {Y } ∪ U,
where ΘY |U are CPTs in N .
For example, in Figure 3 (right), the basis of iteration
i = 4 is {D, E}, since C is eliminated from the CPTs
of D and E at iteration 4.
Given this notion, we can show how to construct a network with split nodes, that corresponds to a particular
execution of the mini-bucket method. In particular,
exact variable elimination in N 0 will be able to mimic
mini-bucket elimination in N , with the same computational complexity. This is given in Algorithm 3 which
returns both a network N 0 and an ordering π 0 of the
variables in N 0 (this includes the variables in original
network N and their clones in N 0 ). Figure 4 shows a
trace corresponding to a split network, and the associated variable order.

CHOI ET AL.
Algorithm 3 split-mbe(N, e): returns a split network N 0 and variable ordering π 0 , corresponding to a
run of mbe(N, e).
1: N 0 ← N
2: for each iteration i of mbe(N, e) do
3:
X ← as chosen on Line 5 of mbe
4:
Si ← as chosen on Line 6 of mbe
5:
B ← basis of iteration i
6:
if X ∈ B then
7:
π 0 (i) ← X
8:
else
9:
split node X in N 0 according to children B
10:
π 0 (i) ← clone X̂ of X resulting from split
11: return network N 0 and ordering π 0
Θ Θ

Θ Θ
Θ

Θ

Θ
Θ

5

61

NODE-SPLITTING STRATEGIES

Given the correspondences in the previous section,
every mini-bucket heuristic can now be interpreted as
a node splitting strategy. Consider for example the
mini-bucket heuristic given in (Dechter & Rish, 2003),
which is a greedy strategy for bounding the size of
the factors created by mbe. This heuristic works as
follows, given a bound on the size of the largest factor:
• A particular variable order is chosen and followed
by the heuristic.
• When processing variable X, the heuristic will
pick a maximal set of factors Si whose product
will be a factor of size within the given bound.
• The above process is repeated in consecutive iterations and for the same variable X until variable
X is eliminated from all factors.
• Once X is completely eliminated, the heuristic
picks up the next variable in the order and the
process continues.

∅ ∅

∅ ∅

Figure 4: An execution trace of mbe on N (left) and
ve on N 0 (right). For simplicity, we ignore the priors of
clone variables in N 0 . Networks are defined in Figure 2.

We now have our basic correspondence between minibuckets and node splitting.
Theorem 2 Let N be a Bayesian network, e be
some evidence, and let N 0 and π 0 be the results of
split-mbe(N, e). We then have:
→
mbe(N, e) = βMPE (N 0 , e, −
e ),
Q

p

where β = C∈C |C| and C are the clone variables
in N 0 . Moreover, variable elimination on network N 0
using the variable order π 0 has the same time and space
complexity of the corresponding run mbe(N, e).
Note that the ordering π 0 returned by Algorithm 3 may
not be the most efficient ordering to use when running
exact variable elimination in a split network: there
→
may be another variable order where ve(N 0 , e, −
e ) produces smaller intermediate factors than mbe(N, e). Indeed, we need not restrict ourselves to variable elimination when performing inference on the split network,
as any exact algorithm suffices for this purpose. This
property can have significant practical implications, a
point we highlight in Section 7 where we exploit recent
advances in exact inference algorithms.

This heuristic tries then to minimize the number of
instances where a proper subset of factors is selected
in Line 6 of Algorithm 2, and can be interpreted as a
heuristic to minimize the number of clones introduced
into an approximation N 0 . In particular, the heuristic
does not try to minimize the number of split variables.
We now introduce a new node splitting strategy based
on fully splitting nodes, where a variable is split along
every outgoing edge. The strategy is also a greedy algorithm, which attempts to fully split the variable that
contributes most to the difficulty of running a jointree algorithm in the approximate network N 0 . This
process is repeated until the network is sufficiently simplified. In particular, the method starts by building a
jointree of the original network. It then picks a variable whose removal from the jointree will introduce the
largest reduction in the sizes of the cluster and separator tables. Once a variable is chosen, it is fully split.
One can obtain a jointree for the split network by simply modifying the existing jointree, which can then be
used to choose the next variable to split on.3 In our
empirical evaluation, we go further and construct a
new jointree for the simpler network, and choose the
next variable to split from it. This process is repeated
until the largest jointree cluster is within our bound.
We now have two strategies for splitting nodes in a network. The first is based on the classical mini-bucket
heuristic that tries to minimize the number of clones,
3
In particular, one can simply adjust the separators and
clusters without changing the structure of the jointree.

62

CHOI ET AL.

Algorithm 4 split-bnb: z and q ? are global variables.
→
1: q ← βMPE p (N 0 , z, −
z)
?
2: if q > q then
3:
if z is a complete instantiation then
4:
q? ← q
5:
else
6:
pick some X ∈
/Z
7:
for each value x of variable X do
8:
z ← z ∪ {X = x}
9:
split-bnb()
10:
z ← z − {X = x}

and the second one is based on reducing the size of
jointree tables and tries to minimize the number of
split variables. Recall that Corollary 1 tells us that
the quality of the MPE bound given by a split network degrades monotonically with further splits. As
we shall see in Section 6, and empirically in Section 7,
it may sometimes be more important to minimize the
number of split variables, rather than the number of
clones, in the context of branch-and-bound search.

6

SEARCHING FOR MPE’S

When computing the MPE is too difficult for traditional inference algorithms, we can employ systematic
search methods to identify provably optimal solutions.
Suppose now that we are given network N and evidence e, and that we want to compute MPE p (N, e)
using depth-first branch-and-bound search. We want
then to select some network N 0 using a node-splitting
heuristic from the previous section to allow for exact
inference in N 0 (say, by the jointree algorithm). Theorem 1 gives us the upper bound
→
MPE p (N, e) ≤ βMPE p (N 0 , e, −
e ).
Moreover, one can easily show that if z is a complete
variable instantiation x of N , we then have
→
MPE p (N, x) = βMPE p (N 0 , x, −
x );
see Lemma 1. These two properties form the basis of
our proposed search algorithm, split-bnb, which is
summarized in Algorithm 4.
Throughout the search, we keep track of two global
variables. First, z is a partial assignment of variables
in the original network that may be extended to produce an MPE solution in MPE (N, e). Second, q ? is a
lower bound on the MPE probability that is the largest
probability of a complete instantiation so far encountered. The search is initiated after setting z to e and
q ? to 0.0: we use evidence e as the base instantiation,

and 0.0 as a trivial lower bound. Upon completion
of the search, we have the optimal MPE probability
q ? = MPE p (N, e).
At each search node, we compute a bound on the best
completion of z by performing exact inference in the
approximate network N 0 . If the resulting upper bound
q is greater than the current lower bound q ? , then we
must continue the search, since it is possible that z
can provide us with a better solution than what we
have already found. In this case, if z is already a complete instantiation, it is easy to show that q is equal
to Pr (z) (by Lemma 1, in the Appendix) and that we
have found a new best candidate solution q ? . If z is
not a complete instantiation, we select some variable
X that has not been instantiated. For each value x
of X, we add the assignment {X = x} to z and call
split-bnb recursively with the new value of z and our
candidate solution q ? . Upon returning from the recursive call, we retract the assignment {X = x}, and
continue to the next value of X.
6.1

REDUCING THE SEARCH SPACE

Consider now the following critical observation.
Proposition 1 Let N be a Bayesian network, and let
N 0 be the result of splitting nodes in N . If Z contains
all variables that were split in N to produce N 0 , then
→
MPE p (N, z) = βMPE p (N 0 , z, −
z ),
where β =

Q

C∈C

|C| and C are all the clones in N 0 .

According to this proposition, once we have instantiated in z all variables that were cloned, the resulting
approximation is exact. This tells us that during our
search, we need not instantiate every one of our network variables X. We need only instantiate variables
in a smaller set of variables Z ⊆ X containing precisely
the variables that were split in N to produce N 0 . Once
the bound on the MPE probability becomes exact, we
know that we will not find a better solution by instantiating further variables, so we can stop and backtrack.
This observation allows us to work in a reduced search
space: rather than searching in a space whose size is
exponential in the number of network variables X, we
search in a space whose size is exponential only in the
number of split variables!
Moreover, if our variable splitting strategy seeks to
minimize the number of split variables, rather than
the number of clones introduced, we can potentially
realize dramatic reductions in the size of the resulting
search space. As we shall see in the following section,
this can have a drastic effect on the efficiency of search.

CHOI ET AL.

In our experiments, we compared the splitting strategy based on a jointree (JT) with the strategy based
on a greedy mini-bucket elimination (MB), both described in Section 5. In particular, we asserted limits
on the maximum cluster size for JT, and equivalently,
the size of the largest factor for MB. We then compared the two strategies across a range of cluster and
factor size limits from 0 to 12, where 0 corresponds to
a fully disconnected network and 12 corresponds to exact inference (no splits). In all of our experiments, to
emphasize the difference between splitting strategies,
we make neutral decisions in the choice of a search seed
(we use a trivial seed, 0.0), variable ordering (random)
and value ordering (as defined by the model).
First, consider Figure 5, which compares the effectiveness of node splitting strategies in minimizing the
number of variables split and the number of clones.
Recall that the heuristic based on jointrees (JT) seeks
to minimize the number of split variables, while the
greedy mini-bucket (MB) strategy would seek to minimize the number of clones. We see that in Figure 5, on
4

In particular, each network is associated with its own
piece of evidence corresponding to a codeword received via
transmission through a (simulated) noisy Gaussian channel, with standard deviations ranging from σ = 0.2 to
σ = 0.8 in steps of 0.1.

JT
MB

10
5
0
0

80

JT
MB

60
40
20
0
0

5
10
log2(max cluster size)

5
10
log2(max cluster size)

Figure 5: Comparing splitting heuristics.

10

10

10

JT
MB

4

2

0

0

5
10
log (max cluster size)
2

search nodes

We begin with experiments on networks for decoding
error-correcting codes (see, e.g., Frey & MacKay, 1997;
Rish, Kask, & Dechter, 1998). We first consider simpler networks, that correspond to codes containing 16
information bits and 24 redundant bits. Each of our
plot points is an average of 42 randomly generated networks: 6 networks for each of 7 levels of noise.4 Here,
an MPE solution would recover the most likely word
encoded prior to transmission. Our method for exact
inference in the approximate model is based on compiling Bayesian networks (Chavira & Darwiche, 2007),
an approach that has already been demonstrated to be
effective in branch-and-bound search for MAP explanations (Huang, Chavira, & Darwiche, 2006).

# of vars split

We present empirical results in this section to highlight the trade-offs in the efficiency of search based on
the quality of the bound resulting from different node
splitting strategies, and the size of the resulting search
space. We further illustrate how our framework allows
for significant practical gains with relatively little effort, by employing state-of-the-art algorithms for exact inference in the approximate, node-split network.
Thus, our goal here is, not to evaluate a completely
specified system for MPE search, but to illustrate the
benefits that our node-splitting perspective can bring
to existing systems.

15

# of clones created

EMPIRICAL OBSERVATIONS

search space size

7

63

10

10

5

0

0

5
10
log (max cluster size)
2

Figure 6: Evaluating the efficiency of search. On the
right, the top pair searches in the full space, and the
bottom pair searches in the reduced space.

the left, our jointree (JT) method can split nearly half
of the variables that the mini-bucket (MB) strategy
splits. On the other hand, we see that on the right, the
mini-bucket (MB) strategy is introducing fewer clones.
Note that on both extremes (no splits and all split),
MB and JT are identical.
To see the impact that reducing the number of split
variables has on the efficiency of search, consider Figure 6. On the left, we see that JT can get an order
of magnitude savings over MB in the size of the reduced search space, which is exponential only in the
number of split variables (see again Figure 5). Consider now, on the right, the number of nodes visited
while performing split-bnb search. The top pair plots
the efficiency of search using the full search space (JTF and MB-F), while the bottom pair plots the efficiency of using the reduced search space (JT-R and
MB-R). We see that both JT-R and MB-R experience
several orders of magnitude improvement when using
the reduced-search space versus the full search space.
When we compare JT-F and MB-F (top pair), we see
that MB-F is in fact more efficient in terms of the
number of nodes visited. In this setting, where both
methods are searching in the same space, we see that
the number of clones introduced appears to be the
dominant factor in the efficiency of search. This is
expected, as we expect that the upper bounds on the
MPE probability should be tighter when fewer clones
are introduced. When we now compare JT-R and
MB-R (bottom pair), we see that the situation has

64

CHOI ET AL.
JT
MB

# of clones created

# of vars split

30
20
10

0

10
20
log (max cluster size)

JT
MB

80
60
40
20
0

10
20
log (max cluster size)
2

2

JT
MB

search nodes

search space size

Figure 7: Comparing splitting heuristics.

5

10

0

4

10

2

10

10
20
log2(max cluster size)

0

10
20
log2(max cluster size)

Figure 8: Evaluating the efficiency of search.

Table 1: Compilation versus Variable Elimination
Network
90-20-1
90-20-2
90-20-3
90-20-4
90-20-5
90-20-6
90-20-7
90-20-8
90-20-9
90-20-10

Search
Nodes
14985
137783
3065
4545
29343
5065
2987
6213
5121
8419

AC
Time (s)
18
111
4
3
38
3
2
6
5
10

VE
Time (s)
2417
15953
1271
988
6579
630
1155
812
2367
2343

Imp.
135
144
334
355
173
227
485
146
480
235

reversed, and that JT-R is now outperforming MB-R.
Here, each method is performing search in their own
reduced search spaces. A strategy based on reducing
the number of split variables reduces the size of the
search space, and this reduction now dominates the
quality of the bound.
Figures 7 and 8 depict similar results but for larger
coding networks, in which we have a rate 21 code with
32 information bits and 32 redundant bits. Note that
only the reduced space was used for search here.
Our approach based on node splitting has another major advantage, which we have only briefly mentioned
thus far. By formulating mini-buckets as exact inference in an approximate network, the evaluation of the
mini-bucket approximation need not rely on any specific exact inference algorithm. We mention here that

the arithmetic circuit (AC) approach we have been
using to compute the bound indeed has a key advantage over mainstream algorithms, in that it is able
to effectively exploit certain types of local structure
(Chavira & Darwiche, 2006). To highlight the extent
to which using a different algorithm can be significant,
we constructed another set of experiments. In each, we
used a different grid network, first introduced in (Sang,
Beame, & Kautz, 2005), and constructed a single MPE
query. Each grid network has treewidth in the low
thirties, just out of reach for traditional algorithms for
exact inference. We ran our search twice, each time using a different algorithm to compute the mini-bucket
bound: the first using AC and the second using standard variable elimination (that does not exploit local
structure). Table 1 shows the results for each network,
including the number of search nodes visited and, for
each algorithm, the total search time. For each network, we performed two identical searches for each algorithm: the only difference being in how the bound
was computed. Consequently, the dramatic differences
we observe reflect the ability of the AC approach to
exploit local structure, showing how advances in exact
inference can be easily utilized to extend the reach of
mini-bucket approximations.

8

CONCLUSION

We presented in this paper a new perspective on minibucket approximations, formulating it in terms of exact inference in an approximate network, but one
found by splitting nodes. This perspective has led to a
number of theoretical and practical insights. For one,
it becomes apparent that a branch-and-bound search
using a mini-bucket bound may operate in a drastically reduced search space. This suggests a heuristic for identifying a mini-bucket approximation that
is explicitly based on minimizing this search space,
rather than the quality of the resulting bound. Empirically, we observe that a reduced search space can have
more impact than a better bound, in terms of the efficiency of branch-and-bound search. Moreover, as our
approach is independent of the algorithm used for exact inference in the resulting approximate network, we
can effortlessly employ state-of-the-art algorithms for
exact inference, including those that can exploit compilation and local structure.

A

PROOFS

Lemma 1 Let N be a Bayesian network, and let N 0
be the result of splitting nodes in N . We then have
→
Pr (x) = βPr 0 (x, −
x ).

CHOI ET AL.
Q
Here β = C∈C |C|, where C is the set of clones in
network N 0 .
→
Proof of Lemma 1 Note first that −
x is an instantiation of only root variables, and that all clones have
uniform priors, i.e., θc = |C|−1 . We then have that
Y
Y
→
Pr 0 (−
x) =
θc =
|C|−1 = β −1 .
−
c∼→
x

C∈C

→
Since instantiation x is compatible with −
x , where a
variable and its clones are set to the same value, we
→
find in Pr 0 (x | −
x ) that clone variables act as selectors
for the CPT values composing Pr (x). Thus
→
→
→
Pr (x, −
x ) = Pr 0 (x | −
x )Pr 0 (−
x ) = Pr (x)β −1
0

→
and we have Pr (x) = βPr 0 (x, −
x ), as desired.



Proof of Theorem 1 Suppose for contradiction that
there exists an instantiation z ∈ MPE (N, e) such that
→
Pr (z) > βMPE p (N 0 , e, −
e ). By Lemma 1, the instan→
−
tiation z gives us
→
→
Pr (z) = βPr 0 (z, −
z ) > βMPE p (N 0 , e, −
e ),
→
contradicting the optimality of MPE p (N 0 , e, −
e ).



Proposition 1 is in fact a generalization of Lemma 1
from a complete instantiation x to a partial instantiation z where Z contains all nodes that have been split
in N 0 . Note that splitting a node X when the value
of X has already been fixed corresponds to a common preprocessing rule for Bayesian networks given
evidence. In particular, when a given piece of evidence
z fixes the value of variable Z, any edge Z → Y can be
pruned and a selector node Ẑ can be made a parent of
Y . Node Ẑ is then set to the value that instantiation
z assigns to Z. This pruning process yields a simpler
network which corresponds exactly to the original network for any query of the form {α, z}.
Proof of Proposition 1 From the correspondence
to pruning edges outgoing instantiated variables, we
know that queries of the form {α, z}, including complete instantiations {x, z}, are equivalent in N condi→
tioned on z and N 0 conditioned on {z, −
z }. Thus the
MPEs of each network must also be the same.

Proof of Theorem 2 Given the trace of an instance
of mbe(N, e), algorithm split-mbe(N, e) returns a
network N 0 and an ordering π 0 of variables in N 0 .
We show, by induction, that each iteration of ve
on N 0 mimics each iteration of mbe on N . We can
then conclude that the product of factors returned by
both must be the same, and further, that they are of
the same time and space complexity. In particular,

65

→
we show how ve(N, e, −
e ) mimics mbe(N, e) first on
Line 2, and then Lines 5, 6 and 7, in Algorithms 1 and
2. For simplicity, we ignore the constant factor β that
the clone CPTs contribute to the MPE value of N 0 .
On Line 2 (iteration i = 0), by construction, the CPTs
in N are the same as the CPTs in N 0 , after relabeling.
For iterations i > 0, assume for induction that the
factors available to both ve and mbe are the same.
On Line 5, if mbe picked variable X on Line 5, then
algorithm ve picks variable X 0 = π 0 (i), which is either
X or a clone X̂, by construction (Lines 7 and 10 of
Algorithm 3).
On Line 6, each factor in the set Si is either 1) a CPT
mentioning X, or 2) a factor that is composed of a
CPT mentioning X. The variables that these CPTs
belong to are the variable set B, the basis of iteration
i. Algorithm 3 decides to split (or not split), so that
each variable in B will have a CPT in N 0 that mentions
X 0 = π 0 (i). We know by induction, that all factors f
selected by mbe are available for selection by ve in N 0 .
Since Algorithm 3 ensures that each of these factors
f now mention X 0 , and since ve picks all factors
mentioning X 0 , we know ve picks the same factors
mbe picked.
On Line 7, consider any variable Z mentioned in Si .
Let j ≥ i be the iteration where Z is eliminated in
mbe. The relevant CPTs mentioning Z at iteration i
are among the relevant CPTs of the basis at iteration
j. Thus, Algorithm 3 ensures that they all mention the
same instance of Z in N 0 . Thus, the resulting product
of factors fi must be the same after relabeling.

A node-split network also upper bounds Pr (e). The
following theorem corresponds to a mini-bucket bound
on the probability of evidence (Dechter & Rish, 2003).
Theorem 3 Let N be a Bayesian network, and let N 0
be the result of splitting nodes in N . We then have
→
Pr (e) ≤ βPr 0 (e, −
e ).
Q
Here, β = C∈C |C|, where C is the set of clones in
network N 0 .
Proof of Theorem 3 By Lemma 1, we know that
→
Pr (x) = βPr 0 (x, −
x ). Therefore:
X
X
→
Pr (e) =
Pr (x) = β
Pr 0 (x, −
x)
x∼e

≤β

X

x∼e

→
Pr (x ) = βPr 0 (e, −
e)
0

0

−
x0 ∼e,→
e

where x0 is an instantiation of variables in N 0 , but
where the values of the original network variables are
not necessarily compatible with the values of the clone
→
variables (as they are in x and −
x ).


66

CHOI ET AL.

B

LOOP-CUTSET CONDITIONING

The loop-cutset conditioning algorithm and split-bnb
search are closely related when our splitting strategy
performs only full splits (see Definition 3). This correspondence reveals the difficulty of answering the following decision problem:
D-FS: Given k and ω, does there exist a set
Z of size ≤ k such that fully splitting nodes
Z in network N results in an approximate
network N 0 with treewidth ≤ ω?
We now state the following negative result.
Theorem 4 Decision problem D-FS is NP–complete.
Hardness can be shown by reduction from the loopcutset problem, which is NP–complete (Suermondt
& Cooper, 1990). In particular, when we fully split
enough variables Z to render N 0 a polytree, then Z
also constitutes a loop-cutset of N .
0

If N is rendered a polytree, and we ignore the bound
during split-bnb search and further employ the reduced search space over split variables Z, then splitbnb reduces to loop-cutset conditioning. More generally, when we split enough variables Z so that network
N 0 has treewidth ω, split-bnb reduces to ω–cutset
conditioning (Bidyuk & Dechter 2004).
0

Assuming that for exact inference in N , we use an
algorithm that is exponential in the treewidth ω of
N 0 , this correspondence tells us that the worst-case
time and space complexity of split-bnb search is precisely that of ω–cutset conditioning. In particular, say
that n is the number of variables in N , value m is the
number of variables cloned in N 0 , and value ω is the
treewidth of network N 0 . The worst-case time complexity of split-bnb search is thus
O(n exp{ω} · exp{m}) = O(n exp{ω + m}),
since we spend O(n exp{ω}) time at each of at most
exp{m} search nodes. Note that the space complexity
of split-bnb search is only O(n exp{ω} + m).

Choi, A., & Darwiche, A. (2006b). A variational approach
for approximating Bayesian networks by edge deletion. In UAI, pp. 80–89.
Dechter, R. (1996). Bucket elimination: A unifying framework for probabilistic inference. In UAI, pp. 211–219.
Dechter, R., Kask, K., & Mateescu, R. (2002). Iterative
join-graph propagation. In UAI, pp. 128–136.
Dechter, R., & Rish, I. (2003). Mini-buckets: A general
scheme for bounded inference. J. ACM, 50 (2), 107–
153.
Frey, B. J., & MacKay, D. J. C. (1997). A revolution:
Belief propagation in graphs with cycles. In NIPS,
pp. 479–485.
Huang, J., Chavira, M., & Darwiche, A. (2006). Solving
map exactly by searching on compiled arithmetic circuits. In AAAI, pp. 143–148.
Hutter, F., Hoos, H. H., & Stützle, T. (2005). Efficient
stochastic local search for MPE solving. In IJCAI,
pp. 169–174.
Kolmogorov, V., & Wainwright., M. J. (2005). On the
optimality of tree-reweighted max-product message
passing. In UAI.
Marinescu, R., & Dechter, R. (2005). AND/OR branchand-bound for graphical models. In IJCAI, pp. 224–
229.
Marinescu, R., Kask, K., & Dechter, R. (2003). Systematic
vs. non-systematic algorithms for solving the MPE
task. In UAI, pp. 394–402.
Park, J. D. (2002). Using weighted max-sat engines to solve
MPE. In AAAI/IAAI, pp. 682–687.
Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann Publishers, Inc., San Mateo, California.
Rish, I., Kask, K., & Dechter, R. (1998). Empirical evaluation of approximation algorithms for probabilistic
decoding. In UAI, pp. 455–463.
Sang, T., Beame, P., & Kautz, H. (2005). Solving Bayesian
networks by weighted model counting. In AAAI,
Vol. 1, pp. 475–482. AAAI Press.
Suermondt, H. J., & Cooper, G. F. (1990). Probabilistic
inference in multiply connected networks using loop
cutsets. IJAR, 4, 283–306.
Wainwright, M. J., Jaakkola, T., & Willsky, A. S. (2005).
Map estimation via agreement on trees: messagepassing and linear programming. IEEE Transactions
on Information Theory, 51 (11), 3697–3717.



We consider in this paper the formulation of
approximate inference in Bayesian networks
as a problem of exact inference on an approximate network that results from deleting edges
(to reduce treewidth). We have shown in earlier work that deleting edges calls for introducing auxiliary network parameters to compensate for lost dependencies, and proposed
intuitive conditions for determining these parameters. We have also shown that our earlier method corresponds to Iterative Belief
Propagation (IBP) when enough edges are
deleted to yield a polytree, and corresponds
to some generalizations of IBP when fewer
edges are deleted. In this paper, we propose a different criteria for determining auxiliary parameters based on optimizing the KL–
divergence between the original and approximate networks. We discuss the relationship
between the two methods for selecting parameters, shedding new light on IBP and its
generalizations. We also discuss the application of our new method to approximating
inference problems which are exponential in
constrained treewidth, including MAP and
nonmyopic value of information.

1

INTRODUCTION

The complexity of algorithms for exact inference on
Bayesian networks is generally exponential in the network treewidth (Jensen, Lauritzen, & Olesen, 1990;
Lauritzen & Spiegelhalter, 1988; Zhang & Poole, 1996;
Dechter, 1996; Darwiche, 2001). Therefore, networks
with high treewidth (and no local structure, Chavira &
Darwiche, 2005) can be inaccessible to these methods,
necessitating the use of approximate algorithms. Iterative Belief Propagation (IBP), also known as Loopy

Belief Propagation (Pearl, 1988; Murphy, Weiss, &
Jordan, 1999), is one such algorithm that has been critical for enabling certain classes of applications, which
have been intractable for exact algorithms (e.g., Frey
& MacKay, 1997). We have proposed in previous work
a new perspective on this influential algorithm, viewing it as an exact inference algorithm on a polytree approximation of the original network (Choi & Darwiche,
2006; Choi, Chan, & Darwiche, 2005). The approximate polytree results from deleting edges from the
original network, where the loss of each edge is offset
by introducing new parameters into the approximate
network. We have shown that the iterations of IBP can
be understood as searching for specific values of these
parameters that satisfy intuitive conditions that we
characterized formally (Choi & Darwiche, 2006). This
has led to a number of implications. On the theoretical
side, it provided a new, network–specific, characterization of the fixed points of IBP. On the practical side, it
has led to a concrete framework for improving approximations returned by IBP by deleting fewer edges than
those necessary to yield a polytree; that is, we delete
enough edges to obtain a multiply connected network
which is still tractable for exact inference.
In this paper, we consider another criterion for determining the auxiliary parameters introduced by deleting edges, which is based on minimizing the KL–
divergence between the original and approximate network. This proposal leads to a number of interesting
results. First, we provide intuitive, yet necessary and
sufficient, conditions that characterize the stationary
points of this optimization problem. These conditions
suggest an iterative procedure for finding parameters
that satisfy these conditions, leading to a new approximate inference method that parallels IBP and its generalizations. Second, the sufficiency of these conditions
lead to new results on IBP and its generalizations,
characterizing situations under which these algorithms
will indeed be optimizing the KL–divergence.
We seek to optimize the form of the KL–divergence

U

U

SE(U)

S’

PM(U’)

U’

X

X

Figure 1: Deleting edge U → X by adding a clone U 0
of U and a binary evidence variable S 0 .
that uses weights from the original distribution, and as
it turns out, the update equations for our new method
are more expensive than those for IBP and its generalizations, requiring the availability of true node marginals in the original network. This means that the
method as described is, in general, applicable only to
networks whose treewidth is manageable, but whose
constrained treewidth is not.1 That is, this approximation will typically be useful for problems which remain
hard even if treewidth is manageable. This includes
MAP (Park & Darwiche, 2004), inference in credal
networks (Cozman, de Campos, Ide, & da Rocha,
2004), and the computation of nonmyopic value of information (Krause & Guestrin, 2005). In complexity theoretic terms, computing node marginals is PP–
complete, while computing MAP is NPPP –complete.
Hence, our proposed method can be used to approximate NPPP –complete problems, while IBP and its generalizations approximate PP–complete problems.
This paper is structured as follows. Section 2 reviews the framework of approximating networks by
edge deletion. Section 3 treats the characterization of
auxiliary parameters introduced by deleting edges, discussing the new characterization proposed in this paper, and comparing it to the one corresponding to IBP
and its generalizations. Section 4 considers the problem of selecting which edges to delete in order to optimize the quality of approximations. Section 5 presents
empirical results, Section 6 discusses related work, and
Section 7 closes with some concluding remarks. Proofs
of theorems are sketched in Appendix A.

2

DELETING AN EDGE

Let U → X be an edge in a Bayesian network, and
suppose that we wish to delete this edge to make the
network more amenable to exact inference algorithms.
This deletion will introduce two problems. First, variable X will lose its direct dependence on parent U .
1

Networks may admit elimination orders with manageable treewidths, but certain queries may constrain these
orders, leading to constrained treewidths.

Second, variable U may lose evidential information received through its child X. To address these problems, we propose to add two auxiliary variables for
each deleted edge U → X as given in Figure 1. The
first is a variable U 0 which is made a parent of X,
therefore acting as a clone of the lost parent U . The
second is an instantiated variable S 0 which is made a
child of U , meant to provide evidence on U in lieu of
the lost evidence.2 Note that the states u0 of auxiliary
variable U 0 are the same as the states u of variable U ,
since U 0 is a clone of U . Moreover, auxiliary variable
S 0 is binary as it represents evidence.
The deletion of an edge U → X will then lead to introducing new parameters into the network, as we must
now provide conditional probability tables (CPTs) for
the new variables U 0 and S 0 . Variable U 0 , a root node
in the network, needs parameters θu0 representing the
prior marginal on variable U 0 . We will use PM (U 0 ) to
denote these parameters, where PM (u0 ) = θu0 . Variable S 0 , a leaf node in the network, needs parameters θs0 |u representing the conditional probability of
s0 given U . We will use SE (U ) to denote these parameters, where SE (u) = θs0 |u . Moreover, we will
collectively refer to PM (U 0 ) and SE (U ) as edge parameters. Figure 2 depicts a simple network with a
deleted edge, together with one possible assignment of
the corresponding edge parameters.
We have a number of observations about our proposal
for deleting edges:
• The extent to which this proposal is successful
will depend on the specific values used for the parameters introduced by deleting edges. This is a
topic which we address in the following section.
• If the deleted edge U → X splits the network into
two disconnected networks, one can always find
edge parameters which are guaranteed to lead to
exact computation of variable marginals in both
subnetworks (Choi & Darwiche, 2006).
• The auxiliary variable S 0 can be viewed as injecting a soft evidence on variable U , whose strength
is defined by the parameters SE (U ). Note that for
queries that are conditioned on evidence s0 , only
the relative ratios of parameters SE (U ) matter,
not their absolute values (Pearl, 1988; Chan &
Darwiche, 2005).
Our goal now is to answer the following two questions.
First, how do we parametrize deleted edges? Second,
which edges do we delete?
2
Our proposal for deleting an edge is an extension of
the proposal given by (Choi et al., 2005), who proposed
the addition of a clone variable U 0 but missed the addition
of evidence variable S 0 .

A

A
Θs0 |A
θs0 |a
θs0 |ā

S’
A’

B

C

B

C

D

ΘA0
θa0
θā0

SE (A)
0.3437
0.6562
PM (A0 )
0.8262
0.1737

D

Figure 2: A network N (left), an approximate network N 0 found after deleting A → B (center), along with
parameters for auxiliary evidence variable S 0 and clone A0 (right).

3

PARAMETRIZING EDGES

Finally, these update equations lead to fixed points
characterized by the following conditions:

Given a network N and evidence e, our proposal is
then to approximate this network with another N 0 that
results from deleting some edges U → X as given earlier. Moreover, when performing inference on network
N 0 , we will condition on the augmented evidence e0 ,
composed of the original evidence e and all auxiliary
evidence s0 introduced when deleting edges. More formally, if Pr and Pr 0 are the distributions induced by
networks N and N 0 , respectively, we will use Pr 0 (X|e0 )
to approximate Pr (X|e) where X is a set of variables
in the original network N .
To completely specify our approximate network N 0 ,
we need to specify parameters PM (u0 ) and SE (u) for
each edge that we delete. We have proposed in (Choi
& Darwiche, 2006) an iterative procedure that uses the
following update equations to parametrize edges:
PM (u0 ) = α
SE (u) = α

∂Pr 0 (e0 )
∂θs0 |u
∂Pr 0 (e0 )
,
∂θu0

(1)

where α is a normalizing constant.3 This procedure,
which we call ed-bp, starts with some arbitrary values for PM (U 0 ) and SE (U ), leading to an initial approximate network N 0 . This network can then be
used to compute new values for these parameters according to the update equations in (1). The process
is then repeated until convergence to a fixed point
(if at all). We have also shown that when deleting
enough edges to yield a polytree, the parametrizations
PM (U 0 ) and SE (U ) computed in each iteration correspond precisely to the messages passed by IBP. Moreover, if the edges deleted do not yield a polytree, edbp corresponds to a generalization of IBP (simulated
by a particular choice of a joingraph; see also Aji &
McEliece, 2001; Dechter, Kask, & Mateescu, 2002).
3
This is an alternative, but equivalent, formulation of
the update equations given by (Choi & Darwiche, 2006).

Pr 0 (u|e0 )
Pr 0 (u|e0 \ s0 )

= Pr 0 (u0 |e0 ),
= Pr 0 (u0 ).

(2)

The first condition says that variables U 0 and U should
have the same posterior marginals. The second condition, in light of the first, says that the impact of
evidence s0 on variable U is equivalent to the impact
of all evidence on its clone U 0 . Indeed, these conditions
correspond to the intuitions that motivated ed-bp.
3.1

A VARIATIONAL APPROACH

We propose now a variational approach to parametrizing deleted edges, based on the KL–divergence:
Pr (w|e)
def X
,
KL(Pr (.|e), Pr 0 (.|e0 )) =
Pr (w|e) log
Pr 0 (w|e0 )
w
where w is a world, denoting an instantiation over
all variables. Note that the KL–divergence is not
symmetric: the divergence KL(Pr (.|e), Pr 0 (.|e0 )) is
weighted by the true distribution while the divergence
KL(Pr 0 (.|e0 ), Pr (.|e)) is weighted by the approximate
one. Common practice weighs the KL–divergence using the approximate distribution, which is typically
more accessible computationally (e.g., Yedidia, Freeman, & Weiss, 2005). In contrast, we will weigh by
the true distribution in what follows.
Before we proceed to optimize the KL–divergence, we
must ensure that the domains of the distributions
Pr (.|e) and Pr 0 (.|e0 ) coincide. One way to ensure this
is to use the following construction, demonstrated in
Figure 3. Given a Bayesian network N ? , we can replace each edge U → X to be deleted with a chain
U → U 0 → X, where the equivalence edge U → U 0
denotes an equivalence constraint: θu0 |u = 1 iff u0 = u.
The resulting augmented network N will then satisfy
three important properties. First, it is equivalent to
the original network N ? over common variables. Second, it has the same treewidth as N ? . Finally, when

U

U

U

SE(U)

S’
U’

X

For the remainder of this paper, we will only be dealing with augmented networks N , leaving the original
network N ? implicit.
PM(U’)

U’

X

3.2

Figure 3: The edge U → X in N ? is replaced with a
chain U → U 0 → X in N . We delete the equivalence
edge U → U 0 in N to get N 0 .
we delete equivalence edges U → U 0 from N , we get
an approximate network N 0 that does not require the
introduction of clone variables U 0 as they are already
present in N 0 .4 We can therefore compute the KL–
divergence between the augmented network N and its
approximation N 0 .

Lemma 1 Let N be an (augmented) Bayesian network and N 0 be the network that results from deleting
equivalence edges U → U 0 . Then:

U →U 0 u=u0

Pr 0 (e0 )
1
.
+ log
θu0 θs0 |u
Pr (e)

Since Pr 0 (e0 ) is a function of our edge parameters, the
KL–divergence is thus also a function of our edge parameters. This result will be used later to derive update
equations for our variational method, and to develop
a heuristic for choosing edges to delete.
Before we proceed though, we observe the following. Let X be the variables of the original network N ? and U0 be the clone variables introduced
via the equivalence edges U → U 0 in N . The KL–
divergence of Lemma 1 is then over the variables
XU0 . One would normally prefer to optimize the
KL–divergence KL(Pr (X|e), Pr 0 (X|e0 )) over the original variables X, but our method will seek to optimize KL(Pr (XU0 |e), Pr 0 (XU0 |e0 )) instead. In fact,
the properties of the KL–divergence tell us that
KL(Pr (X|e), Pr 0 (X|e0 ))
≤ KL(Pr (XU0 |e), Pr 0 (XU0 |e0 )).

(3)

In our experimental results in Section 5, we will report
results on both versions of the KL–divergence, referring to KL(Pr (X|e), Pr 0 (X|e0 )) as the exact KL, and
to KL(Pr (XU0 |e), Pr 0 (XU0 |e0 )) as the KL bound.
We still need to add a new child S 0 for each U however. Since variables S 0 are observed, they do not prohibit
us from computing the KL–divergence between N and N 0
even though they are not present in network N .
4

We have the KL–divergence KL(Pr (.|e), Pr 0 (.|e0 )) as
a function of our edge parameters PM (u0 ) = θu0 and
SE (u) = θs0 |u . If we set to zero the partial derivatives of the KL–divergence with respect to each edge
parameter, we get the following.
Theorem 1 Let N be a Bayesian network and N 0 be
the network that results from deleting equivalence edges
U → U 0 . The edge parameters of N 0 are a stationary
point of KL(Pr (.|e), Pr 0 (.|e0 )) if and only if
Pr 0 (u|e0 ) = Pr 0 (u0 |e0 ) = Pr (u|e),

(4)

for all deleted edges U → U 0 .

We can now state the following key result:

KL(Pr (.|e), Pr 0 (.|e0 ))
X X
Pr (uu0 |e) log
=

THE APPROXIMATE NETWORK

X

That is, if we delete the edge U → U 0 , then the marginals on both U and U 0 must be exact in the approximate network N 0 . Note, however, that this does not
imply that other node marginals must be exact in N 0 :
only those corresponding to deleted edges need be.
Theorem 1 has a number of implications. First, the
necessity of Condition (4) will be exploited in the following section to provide an iterative method that
searches for parameters that are a stationary point for
the KL–divergence. Second, the sufficiency of Condition (4) implies that any method that searches for
edge parameters, regardless of the criteria chosen, will
yield parameters that are a stationary point for the
KL–divergence, if the parameters give rise to exact
marginals for variables corresponding to deleted edges.
For example, if we search for parameters using ed-bp
(Choi & Darwiche, 2006), and the parameters found
lead to exact marginals, then these parameters will
indeed be a stationary point for the KL–divergence.
Before we show how to identify parameters satisfying Condition (4), we note that parameters satisfying
Condition (2) do not necessarily satisfy Condition (4)
and, hence, are not necessarily a stationary point for
KL(Pr (.|e), Pr 0 (.|e0 )). We provide a simple network
with four nodes in Appendix B demonstrating this
point. Recall that Condition (2) characterizes IBP and
some of its generalizations (Choi & Darwiche, 2006).
3.3

SEARCHING FOR PARAMETERS

Having characterized stationary points of the KL–
divergence, we now proceed to develop an iterative
procedure for finding a stationary point. Our method
is based on the following result.

Theorem 2 Let N be a Bayesian network and N 0 be
the network that results from deleting equivalence edges
U → U 0 . The edge parameters of N 0 are a stationary
point of KL(Pr (.|e), Pr 0 (.|e0 )) if and only if:


∂Pr 0 (e0 )
0
0 0
, (5)
PM (u ) = Pr (u|e) Pr (e )/
∂θu0


∂Pr 0 (e0 )
SE (u) = Pr (u|e) Pr 0 (e0 )/
. (6)
∂θs0 |u
We have a number of observations about this theorem. First, if we have access to the true marginals Pr (u|e), then this theorem suggests an iterative
method that starts with some arbitrary values of parameters PM (u0 ) and SE (u), leading to some initial
approximate network N 0 . Using this network, we can
0
0
(e0 )
(e0 )
and ∂Pr
compute the quantities Pr 0 (e0 ), ∂Pr
∂θu0
∂θs0 |u ,
which can then be used to compute new values for
the parameters PM (u0 ) and SE (u), one set at a time.
The process can then be repeated until convergence
(if at all). We will refer to this method as ed-kl, to
be contrasted with ed-bp given earlier (Choi & Darwiche, 2006). Note that since the KL–divergence is
non-negative, there exists a set of edge parameters that
are globally minimal. However, a stationary point of
the KL–divergence is not necessarily a global minima.
Second, the availability of the true marginals Pr (u|e)
typically implies that the network treewidth is small
enough to permit the computation of these marginals.
Hence, ed-kl is in general applicable to situations
where the treewidth is manageable, but where the constrained treewidth is not. In these situations, the goal
of deleting edges is to reduce the network constrained
treewidth, making it amenable to algorithms that are
exponential in constrained treewidth, such as MAP
(Park & Darwiche, 2004), inference in credal networks
(Cozman et al., 2004), and the computation of nonmyopic value of information (Krause & Guestrin, 2005).
Third, we have the following result which is critical for
the practical application of ed-kl:
Theorem 3 Let N be a Bayesian network and N 0 be
the network that results from deleting a single equivalence edge U → U 0 . We then have
Pr 0 (e0 ) =

∂Pr (e)
,
∂θu0 |u

X

θs0 |u θu0

=

X

θs0 |u

=

X

θu0

uu0

which implies:
∂Pr 0 (e0 )
∂θu0
∂Pr 0 (e0 )
∂θs0 |u

u

u0

∂Pr (e)
,
∂θu0 |u

∂Pr (e)
.
∂θu0 |u

The main observation here is that ∂Pr (e)/∂θu0 |u is a
function of the original network and, therefore, is independent of the parameters θu0 and θs0 |u —this is why
the second and third equations above follow immediately from the first. Given the above equations, we can
apply ed-kl to a single deleted edge, without the need
for inference. That is, assuming that we have computed ∂Pr (e)/∂θu0 |u , we can use the above equations
to compute updated values for edge parameters from
the old values in constant time. This result will have
implications in the following section, as we present a
heuristic for deciding which edges to delete.

4

CHOOSING EDGES TO DELETE

Our method for deciding which edges to delete is based
on scoring each network edge in isolation, leading to a
total order on network edges, and then deleting edges
according to the resulting order. For example, if we
want to delete k edges, we simply delete the first k
edges in the order.
The score for edge U → U 0 is based on the KL–
divergence between the original network N and an approximate network N 0 which results from deleting the
single edge U → U 0 . The KL–divergence is computed
using Lemma 1. This lemma requires some quantities
from the original network N , which can be computed
since the network is assumed to have a manageable
treewidth. The lemma also requires that we have the
parameters θu0 and θs0 |u for the deleted edge U → U 0 ,
and the corresponding probability Pr 0 (e0 ). These can
be computed relatively easily using Theorem 3, assuming that we have computed ∂Pr (e)/∂θu0 |u as explained
in the previous section. Given these observations, all
edge parameters, together with the corresponding KL
scores, can be computed simultaneously for all edges
using a single evaluation of the original network. Moreover, the computed parameters have another use beyond scoring edges: when used as initial values for
ed-kl, they tend to lead to better convergence rates.
We indeed employ this observation in our experiments.

5

EMPIRICAL ANALYSIS

We present experimental results in this section on a
number of Bayesian networks, to illustrate a number
of points on the relative performance of ed-kl and edbp. We start with Figure 4 which depicts the quality
of computed approximations according to the exact
KL–divergence5 ; see Equation 3. For each approximation scheme, we consider two methods for deleting
edges. For ed-kl, we delete edges randomly (ed-kl5
To compute the exact KL–divergence, see, for example,
(Choi et al., 2005).

alarm

win95pts

1.6

0.16
ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

3.5
avg KL−divergence (exact)

1.8
avg KL−divergence (exact)

emdec

4
ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

1.4
1.2
1
0.8
0.6

3

0.14
avg KL−divergence (exact)

2

2.5
2
1.5
1

0.12

ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

0.1
0.08
0.06
0.04

0.4
0.5

0.2
10

20
30
edges deleted

0.02

0
0

40

20

40

tcc

0
0

100

1

0.2

0.15

0.1

0.05

50

100
edges deleted

100
150
edges deleted

20

0.8

0.6

0.4

0
0

150

200

250

25

ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

15

10

5

0.2

0
0

50

chain

1.2
ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

avg KL−divergence (exact)

avg KL−divergence (exact)

80

grid

0.3

0.25

60
edges deleted

avg KL−divergence (exact)

0
0

10

20

30
40
50
edges deleted

60

70

0
0

80

5

10

15
20
25
edges deleted

30

35

40

Figure 4: Comparing ed-kl and ed-bp using the exact KL, with two methods for edge deletion.
alarm

win95pts

7

16
avg KL−divergence (bound)

avg KL−divergence (bound)

8

emdec

18
ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

6
5
4
3
2

14

3
ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

2.5
avg KL−divergence (bound)

9

12
10
8
6
4

2

1.5

1

0.5
1
0
0

2
10

20
30
edges deleted

0
0

40

20

40

60
edges deleted

80

0
0

100

50

100
150
edges deleted

200

250

Figure 5: Comparing ed-kl and ed-bp using the KL bound, with two methods for edge deletion.
alarm

win95pts

70

160

120
ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

100

140

40
30

100
80

60

40

60

20

ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

80

120

iterations

iterations

50

180

iterations

60

emdec

200
ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

40

20

10
20
0
0

10

20
30
edges deleted

40

0
0

20

40

60
edges deleted

80

100

0
0

50

100
150
edges deleted

Figure 6: Comparing ed-kl and ed-bp according to number of iterations to converge.

200

250

tcc

0.95

0.99

0.9

0.85

0.8

0.75

0.7
0

ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided
20

40

80

0.97

0.96

0.94
0

100

0.9

0.98

0.95

60
edges deleted

grid
1

relative difference

1

relative difference

relative difference

win95pts
1

ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided
50

0.8
0.7
0.6
0.5
0.4

100
edges deleted

150

0

ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided
50

100

150
200
edges deleted

250

300

350

Figure 7: Approximating MAP using ed-kl and ed-bp.
win95pts

tcc

30

25
ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

20

15

15

10

15

10

5

10

5
0

ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

20
constrained treewidth

constrained treewidth

25
constrained treewidth

grid

20
ED−BP−Rand
ED−BP−MI
ED−KL−Rand
ED−KL−Guided
ED−BP−Guided

20

40

60
edges deleted

80

100

5
0

0
50

100
edges deleted

150

0

50

100

150
200
edges deleted

250

300

350

Figure 8: Reducing constrained treewidth by deleting edges. The horizontal line denotes network treewidth, as
approximated using a min-fill heuristic.
rand) and according to the heuristic of Section 4 (edkl-guided). For ed-bp, we delete edges randomly
(ed-bp-rand) and according to a heuristic based on
mutual information (ed-bp-mi) given in (Choi & Darwiche, 2006). As is clear from the figures, ed-kl is
overwhelmingly superior as far as minimizing the KL–
divergence, sometimes even using random deletion of
edges.
Figure 5 depicts sample results for the quality of approximations according to the KL–divergence bound;
see Equation 3. As mentioned earlier, ed-kl searches
for stationary points of this bound instead of stationary points of the exact KL–divergence, yet empirically
one does not see much difference between the two on
these networks.
Figures 4 and 5 depict another approximation scheme,
ed-bp-guided, which deletes edges based on the
heuristic of Section 4, but then uses ed-bp to search
for parameters instead of ed-kl. This is a hypothetical method since the mentioned heuristic assumes that
the network treewidth is manageable, a situation under which one would want to apply ed-kl instead of
ed-bp. Yet, our results show that ed-bp is consistently very close to ed-kl in this case as far as minimizing the KL–divergence. This observation is critical

as it highlights the great importance of heuristics for
deleting edges. In particular, these results show that
ed-bp can do quite well in terms of minimizing the
KL–divergence if the right edges are deleted!
Figure 6 depicts sample results on the speed of convergence for both ed-kl and ed-bp, again using the
different methods for edge deletion. In two of these
networks, ed-kl consistently converges faster than edbp. In the three omitted figures, due to space limitations, ed-kl is also superior to ed-bp.
We consider also sample results from using approximations identified by ed-kl to approximate MAP. Figure 7 depicts the relative difference p/q, where p is the
value of the MAP solution found in the approximate
network N 0 and q is the value of a MAP solution in
the original network N . It is clear from the figure that
ed-kl-guided produces the superior approximations,
and can provide accurate solutions even when many
edges are deleted. Again, based on the hypothetical
method ed-bp-guided, we see that it is possible for
ed-bp to produce good MAP approximations as well
if the right edges are deleted.
Figure 8 highlights how effective deleting edges is in
reducing the constrained treewidth (approximated using a min-fill heuristic), and thus how effective deleting

edges is in reducing the complexity of computing MAP.
We see that good approximations can be maintained
even when the constrained treewidth is reduced to the
network treewidth. When we further delete every network edge, we have a fully factorized approximation of
MAP, where the constrained (and network) treewidth
corresponds to the size of the largest network CPT.

ture from ed-kl and can lead to much worse behavior
for less likely evidence. That is, these approaches approximate a network once for all queries, while ed-kl
can approximate a network for each specific query.

The plots given in this section correspond to averages
of at least 50 instances per data point, where each
instance correspond to evidence over all leaf nodes
drawn from the network joint. We have also experimented with evidence drawn randomly (not from the
joint), leading to similar results. Networks tcc and
emdec are courtesy of HRL Labs, LLC. The grid and
chain networks are synthetic and available from the authors. Networks alarm and win95pts are available at
http://www.cs.huji.ac.il/labs/compbio/Repository.

We proposed a method, ed-kl, for approximating
Bayesian networks by deleting edges from the original network and then finding stationary points for the
KL–divergence between the original and approximate
networks (while weighing the divergence by the true
distribution). We also proposed an efficient heuristic
for deciding which edges to delete from a network, with
the aim of choosing network substructures that lead to
high quality approximations.

6

RELATED WORK

Many variational methods pose the problem of approximate inference as exact inference in some approximate model, often seeking to minimize the KL–
divergence, but weighing it by the approximate distribution (e.g., Jordan, Ghahramani, Jaakkola, & Saul,
1999; Jaakkola, 2000; Wiegerinck, 2000; Geiger &
Meek, 2005). One example is the mean–field method,
where we seek to approximate a network N by a
fully disconnected N 0 (Haft, Hofmann, & Tresp, 1999).
If we delete all edges from the network and try to
parametrize edges using ed-kl, we would be solving
the same problem solved by mean–field, except that
our KL–divergence is weighted by the true distribution, leading to more expensive update equations.
Other variational approaches typically assume particular structures in their approximate models, such as
chains (Ghahramani & Jordan, 1997), trees (Frey, Patrascu, Jaakkola, & Moran, 2000; Minka & Qi, 2003),
or disconnected subnetworks (Saul & Jordan, 1995;
Xing, Jordan, & Russell, 2003). In contrast, ed-kl
works for any network structure which is a subset of
the original. In fact, the efficient edge deletion heuristic of Section 4 tries to select the most promising
subnetworks and is quite effective as illustrated earlier. Again, most of these approaches weigh the KL–
divergence by the approximate distribution for computational reasons, with the notable exceptions of (Frey
et al., 2000; Minka & Qi, 2003).
Other methods of edge deletion have been proposed
for Bayesian networks (Suermondt, 1992; Kjærulff,
1994; van Engelen, 1997), some of which can be rephrased using a variational perspective. All of these
approaches, however, approximate a network independent of the given evidence, which is a dramatic depar-

7

CONCLUSION

The update equations of ed-kl require exact posteriors from the original network. This means that edkl is, in general, applicable to problems that remain
hard even when treewidth is manageable, including
MAP, nonmyopic value of information, and inference
in credal networks. This is to be contrasted with our
earlier method ed-bp, which updates parameters differently, coinciding with IBP and some of its generalizations.
Our empirical results provide good evidence to the
quality of approximations returned by ed-kl, especially when compared to the approximations returned
by ed-bp. Moreover, our results, both theoretical
and empirical, shed new and interesting light on edbp (and, hence, IBP and some of its generalizations),
showing that it can also produce high quality approximations (from a KL–divergence viewpoint), when
deleting the right set of network edges.
Acknowledgments
This work has been partially supported by Air Force
grant #FA9550-05-1-0075-P00002 and by JPL/NASA
grant #1272258.

A

Proof Sketches

Note that u ∼ w signifies that u and w are compatible
instantiations.
Proof of Lemma 1 Deleting edges U → U 0 , we have:
KL(Pr (.|e), Pr 0 (.|e0 )) =

X
w

Pr (w|e) log

Pr (w|e)
Pr 0 (w|e0 )

Pr 0 (e0 )
Pr (w, e)
+ log
=
Pr (w|e) log
0
0
Pr (w, e )
Pr (e)
w
X
Y θu0 |u
Pr 0 (e0 )
+ log
=
Pr (w|e) log
θu0 θs0 |u
Pr (e)
0
w
X

uu ∼w

=

X X

Pr (w|e) log

w uu0 ∼w

=

X X X

θu0 |u
Pr 0 (e0 )
+ log
θu0 θs0 |u
Pr (e)

Pr (w|e) log

U →U 0 uu0 w|=uu0

=

X X

Pr (uu0 |e) log

U →U 0 uu0

=

θu0 |u
Pr 0 (e0 )
+ log
θu0 θs0 |u
Pr (e)

1
Pr 0 (e0 )
Pr (uu0 |e) log
.
+ log
θu0 θs0 |u
Pr (e)
0

U →U 0 u=u

The last equation follows, since when u does not agree
with u0 , we have that Pr (uu0 |e) log θu0 |u = 0 log 0,
which we assume is equal to zero, by convention. 
Proof of Theorem 1 Note that when u = u0 , we
have Pr (uu0 |e) = Pr (u|e) = Pr (u0 |e).
First direction of theorem. Let f be the KL–divergence
as given in Lemma 1. Setting ∂f /∂θu0 to zero, we get:
0

Pr 0 (u0 , e0 )
θu0 ∂Pr 0 (e0 )
=
= Pr 0 (u0 |e0 )
0
0
Pr (e ) ∂θu0
Pr 0 (e0 )

Similarly, to show Pr (u|e) = Pr 0 (u|e0 ). Note that
constraints such as normalization are inactive here.
Second direction of theorem. Given a network N 0
where marginals on U and U 0 are exact, we want to
verify that the edge parameters are stationary points.
If we take the partial derivative with respect to θu0 :


∂f
θu0 ∂Pr 0 (e0 )
1
−Pr (u|e) +
=
∂θu0
θu0
Pr 0 (e0 ) ∂θu0


1
Pr 0 (u0 , e0 )
=
−Pr (u|e) +
θu0
Pr 0 (e0 )
1
(−Pr (u|e) + Pr 0 (u0 |e0 )) .
=
θu0
We are given Pr 0 (u0 |e0 ) = Pr (u|e), thus ∂f /∂θu0 = 0.
Similarly, to show ∂f /∂θs0 |u = 0.

Proof of Theorem 2 Equation 5 follows easily from
Equation 7. Equation 6 follows from ∂f /∂θs0 |u .

Proof of Theorem 3 First, we have:
X
Pr 0 (e0 ) =
Pr 0 (uu0 , e0 )
uu0

uu0

θs0 |u θu0

X2

U2

X2

S’

U’1

X1

X
∂Pr 0 (u, e)
∂ 2 Pr 0 (e0 )
=
.
θs0 |u θu0
∂θs0 |u ∂θu0
∂θu0
0
uu

Note that the distribution induced by a network where
a single edge U → U 0 has been deleted is equivalent to

U2

Figure 9: An example network N (left) where deleting
a single edge (right) may have infinitely many ed-bp
fixed points.

the distribution induced by another network N 0 that
is identical in structure to N , except that θu0 |u = θu0
for all u. We then have:

(7)

where u agrees with u0 . We then have

=

U1

Pr 0 (e0 ) =

0

Pr (u|e)
1
∂Pr (e )
∂f
=−
+
= 0,
∂θu0
θu0
Pr 0 (e0 ) ∂θu0

X

X1

θu0 |u
Pr 0 (e0 )
+ log
θu0 θs0 |u
Pr (e)

X X

Pr (u|e) =

U1

X

θs0 |u θu0

uu0

∂Pr 0 (e) X
∂Pr (e)
=
.
θs0 |u θu0
∂θu0 |u
∂θu0 |u
0

The other relations follow easily.

B

uu



Example

We demonstrate here an example where ed-bp fixed
points are not necessarily stationary points of the
KL–divergence. This example also shows that even
if we delete a single edge, ed-bp can have infinitely
many parametrizations satisfying Condition (2), even
though there exists an ed-bp (and ed-kl) fixed point
minimizing the KL bound, KL(Pr (.|e), Pr 0 (.|e0 )) (as
well as minimizing the exact KL). This example also
corresponds to an instance of IBP (with a particular
message passing schedule), since edge deletion renders
the network a polytree (Choi & Darwiche, 2006).
Our example is depicted in Figure 9. Variables Ui
have parameters θui = θūi = 0.5. Variables Xj are
fixed to states xj , and assert the equivalence of U1
and U2 : θxj |u1 u2 = 1 iff u1 = u2 . Conditioning on evidence e = x1 x2 , we have Pr (u1 |e) = Pr (u2 |e) = 0.5.
If we delete the edge U1 → X1 (implicitly, we delete
an edge U1 → U10 ), then any non-zero parameterization of our edge parameters satisfies the ed-bp fixed
point conditions given by Condition (2). For example,
when θs0 |u1 = θs0 |ū1 = 0.5, and θu01 = θū01 = 0.5, the
KL–divergence is zero and thus minimized, yielding
parent and clone marginals that are exact. By Theorem 1, edges parameters are then a stationary point
of the KL–divergence. However, when θu01 6= 0.5, the
parent and clone marginals are not exact, and thus
edges parameters are not a stationary point of the KL–
divergence, again by Theorem 1.




We propose an approach for approximating
the partition function which is based on two
steps: (1) computing the partition function of
a simplified model which is obtained by deleting model edges, and (2) rectifying the result
by applying an edge-by-edge correction. The
approach leads to an intuitive framework in
which one can trade-off the quality of an approximation with the complexity of computing it. It also includes the Bethe free energy
approximation as a degenerate case. We develop the approach theoretically in this paper and provide a number of empirical results
that reveal its practical utility.

1

INTRODUCTION

We presented in prior work an approach to approximate inference which is based on performing exact
inference on a simplified model (Choi & Darwiche,
2006a, 2006b). We proposed obtaining the simplified model by deleting enough edges to render its
treewidth manageable under the current computational resources. Interestingly enough, the approach
subsumes iterative belief propagation (IBP) as a degenerate case, and provides an intuitive framework
for capturing a class of Generalized Belief Propagation (GBP) approximations (Choi & Darwiche, 2006a;
Yedidia, Freeman, & Weiss, 2005).
We show in this paper that the simplified models can
also be used to approximate the partition function if
one applies a correction for each deleted edge. We
propose two edge-correction schemes, each of which
is capable of perfectly correcting the partition function when a single edge has been deleted. The first
scheme will have this property only when a particular condition holds in the simplified model, and gives

rise to the Bethe free energy approximation when applied to a tree-structured approximation (see Yedidia
et al., 2005, for more on the Bethe approximation and
its relationship to IBP). The second correction scheme
does not require such a condition and is shown empirically to lead to more accurate approximations. Both
schemes can be applied to the whole spectrum of simplified models and can therefore be used to trade-off
the quality of obtained approximations with the complexity of computing them.
This new edge-correction perspective on approximating the partition function has a number of consequences. First, it provides a new perspective on the
Bethe free energy approximation, and may serve as a
tool to help identify situations when Bethe approximations may be exact or accurate in practice. Next, it
suggests that we do not necessarily need to seek good
approximations, but instead seek approximations that
are accurately correctable. To this end, we propose a
heuristic for finding simplified models that is specific
to the task of correction. Finally, it provides the opportunity to improve on edge-deletion approximations
(and certain GBP approximations), with only a modest amount of computational effort. In particular, we
show empirically how it is possible to correct only for
a small number of edges that have the most impact on
an approximation.
Proofs of results appear in the Appendix.

2

EDGE DELETION

We first review our edge deletion framework in probabilistic graphical models. For simplicity, we consider
pairwise Markov random fields, although our framework can easily be extended to general Markov networks as well as to factor graphs. For an application
to directed models, see (Choi & Darwiche, 2006a).
Let a pairwise Markov random field (MRF) M have
a graph (E, V) with edges (i, j) ∈ E and nodes i ∈ V,

function will be denoted by Z 0 (Θ) and its distribution
will be denoted by Pr 0 (.; Θ). When choosing a particular value for edge parameters Θ, we will drop reference
to Θ, using only M0 , Z 0 and Pr 0 (.).

Figure 1: An MRF (left); after edge deletion (right).

ψ(Xi , X j )

i

φ(Xi , Xk )

i

j

ψ(Xk , X j )
k

ψ(Xk , X j )

i

k

θ(Xi )

θ(Xk )

j
j

Figure 2: To delete edge (i, j) (top), we introduce auxiliary node k (middle), and delete equivalence edge
(i, k), adding edge parameters (bottom).
where each node i of the graph is associated with a
variable Xi taking on values xi . Edges (i, j) are associated with edge potentials ψ(xi , xj ) and nodes i with
node potentials ψ(xi ). The (strictly positive) distribution Pr induced by M is defined as follows:
Pr (x)

def

=

Y
1 Y
ψ(xi , xj )
ψ(xi ),
Z
(i,j)∈E

i∈V

where x is an instantiation x1 , . . . , xn of network variables, and where Z is the partition function:
Z

def

=

X Y
x (i,j)∈E

ψ(xi , xj )

Y

ψ(xi ).

i∈V

The basic idea behind our framework is to delete
enough edges from the pairwise MRF to render it
tractable for exact inference.
Definition 1 Let M be a pairwise MRF. To delete
edge (i, j) from M we remove the edge (i, j) from M
and then introduce the auxiliary potentials θ(Xi ) and
θ(Xj ) for variables Xi and Xj .

Note that while the distribution Pr (.) and partition
function Z of the original pairwise MRF M may be
hard to compute, the distribution Pr 0 (.; Θ) and partition function Z 0 (Θ) of M0 (Θ) should be easily computable due to edge deletion. Note also that before
we can use Pr 0 (.; Θ) and Z 0 (Θ) to approximate Pr (.)
and Z, we must first specify the edge parameters Θ. In
fact, it is the values of these parameters which will control the quality of approximations Pr 0 (.; Θ) and Z 0 (Θ).
Without loss of generality, we will assume that we are
only deleting equivalence edges (i, j), which connect
two variables Xi and Xj with the same domain, and
have a potential φ(xi , xj ) that denotes an equivalence
constraint: φ(xi , xj ) = 1 if xi = xj , and φ(xi , xj ) = 0
otherwise. The deletion of any edge in an MRF can
be formulated as the deletion of an equivalence edge.1
As for the values of the edge parameters, we proposed
(and justified) in (Choi & Darwiche, 2006a) the following conditions on θ(xi ) and θ(xj ):
θ(xi ) = α

and

θ(xj ) = α

∂Z 0
∂θ(xi )

(1)

where α is a normalizing constant. Note that the partial derivatives of Equation 1 can be computed efficiently in traditional inference frameworks (Darwiche,
2003; Park & Darwiche, 2004).
Equation 1 can also be viewed as update equations,
suggesting an iterative method that searches for edge
parameters, which we called ed-bp (Choi & Darwiche,
2006a). Starting with an initial approximation M00 at
iteration t = 0 (say, with uniform parameters), we
can compute edge parameters θt (xi ) and θt (xj ) for an
iteration t > 0 by performing exact inference in the
approximate network M0t−1 . We repeat this process
until we observe that all parameters converge to a fixed
point satisfying Equation 1 (if ever).
Note that Equation 1 does not specify a unique value
of edge parameters, due to the constants α. That is,
each value of these constants will lead to a different
set of edge parameters. Yet, independent of which
constants we use, the resulting pairwise MRF M0 will
1

Figure 1 provides an example of deleting an edge.
When deleting multiple edges, note that we may introduce multiple, yet distinct, potentials θ(Xi ) for the
same node Xi . We shall refer to auxiliary potentials
θ(Xi ) and θ(Xj ) as edge parameters and use Θ to denote the set of all edges parameters. The resulting
pairwise MRF will be denoted by M0 (Θ), its partition

∂Z 0
∂θ(xj )

To delete an MRF edge (i, j) that is not an equivalence
edge, we use the technique illustrated in Figure 2: we introduce an auxiliary node k between i and j; introduce an
equivalence constraint on the edge (i, k); copy the original
potential of edge (i, j) to (k, j); and delete the equivalence
edge (i, k). Note that the original model and the extended
one will: (1) have the same treewidth, (2) agree on the
distribution over their common variables, and (3) have the
same partition function values.

have an invariant distribution Pr 0 (.) that satisfies the
following properties. First,
Pr 0 (xi ) = Pr 0 (xj ) =

1
· θ(xi )θ(xj ),
zij

(2)

P
where zij = xi =xj θ(xi )θ(xj ). Next, if the pairwise
MRF M0 has a tree structure, the node and edge
marginals of distribution Pr 0 (.) will correspond precisely to the marginals obtained by running IBP on
the original model M. Moreover, if the pairwise MRF
M0 has loops, the node marginals of distribution Pr 0
will correspond to node marginals obtained by running
generalized belief propagation (GBP) using a particular joingraph for the original model M (Yedidia et al.,
2005; Choi & Darwiche, 2006a).

3

EDGE CORRECTION

the exact partition function Z. Moreover, the result
of this correction is invariant to the constants α used
in Equation 1.
From now on, we will use MI (Xi ; Xj ) to denote the
mutual information between two variables Xi and Xj ,
computed in the simplified MRF M0 . Moreover, when
MI (Xi ; Xj ) = 0, we will say that the deleted edge
(i, j) is a zero-MI edge. Note that while an edge may
be zero-MI in M0 , the mutual information between Xi
and Xj in the original MRF M may still be high.
Let us now consider the more realistic situation where
we delete multiple edges, say E ? , from M to yield the
model M0 . We propose to accumulate the above correction for each of the deleted edges, leading to a corrected partition function Z 0 · z1 , where
z=

Y
(i,j)∈E ?

While the edge parameters specified by Equation 1 are
guaranteed to yield an invariant distribution Pr 0 (.),
they are not guaranteed to yield an invariant partition
function Z 0 as this function is sensitive to the choice of
constants α. Hence, while these edge parameters will
yield an interesting approximation of node marginals,
they do not yield a meaningful approximation of the
partition function.
We will show in this section, however, that one can apply an edge-by-edge correction to the partition function Z 0 , leading to a corrected partition function that
is invariant to the choice of constants α. This seemingly subtle approach leads to two important consequences. First, it results in a semantics for the Bethe
free energy approximation as a corrected partition
function. Second, it allows for an improved class of
approximations based on improved corrections.
3.1

ZERO EDGE-CORRECTION

We will now propose a correction to the partition function Z 0 , which gives rise to the Bethe free energy and
some of its generalizations.
Proposition 1 Let M0 be the result of deleting a single equivalence edge (i, j) from a pairwise MRF M. If
the parameters of edge (i, j) satisfy Equation 1, and if
the mutual information between Xi and Xj in M0 is
zero, then:
Z = Z0 ·

1
,
zij

where

zij =

X

θ(xi )θ(xj ).

xi =xj

That is, if we delete a single edge (i, j) and find that Xi
and Xj are independent in the resulting model M0 , we
can correct the partition function Z 0 by zij and recover

zij =

Y

X

(i,j)∈E ?

xi =xj

θ(xi )θ(xj ).

(3)

We will refer to this correction as a zero-MI edge correction, or ec-z. This correction is no longer guaranteed to recover the exact partition function Z, even if
each of the deleted edges is a zero-MI edge. Yet, if the
pairwise MRF M0 has a tree structure, applying this
correction to the partition function Z 0 gives rise to the
Bethe free energy approximation.
To review, the Bethe free energy Fβ , is an approximation of the true free energy F of a pairwise MRF M,
and is exact when M has a tree structure (Yedidia
et al., 2005). In this case, F = − log Z, so we can
in principle use Fβ as an approximation of the partition function Z, even when M does not have a tree
structure, i.e., we can use Zβ = exp{−Fβ }.
Theorem 1 Let M0 be the result of deleting equivalence edges from a pairwise MRF M. If M0 has a
tree structure and its edge parameters are as given by
Equation 1, we have Zβ = Z 0 · z1 .
Hence, the Bethe approximation of Z is a degenerate
case of the ec-z correction. Thus, IBP and the closely
related Bethe approximation, which are exact when an
MRF M is a tree, are naturally characterized by treestructured ed-bp approximations M0 . In particular,
exact inference in the simplified network M0 yields:
(1) node and edge marginals that are precisely the approximate marginals given by IBP (Choi & Darwiche,
2006a), and now (2) a rectified partition function that
is precisely the Bethe approximation; cf. (Wainwright,
Jaakkola, & Willsky, 2003).2
2
Wainwright et al. proposed tree-based reparametrization (TRP), an algorithm that iteratively reparameterizes
the node and edge potentials of a pairwise MRF. At convergence, the node and edge potentials of a tree (any tree)

Since the ec-z correction is specified purely in quantities available in the model M0 , it will be easily computable as long as the model M0 is sparse enough (i.e.,
it has a treewidth that is manageable under the given
computational resources). Hence, this correction can
be practically applicable even if M0 does not have a
tree structure. In such a case, the correction will lead
to an approximation of the partition function which is
superior to the one obtained by the Bethe free energy.
We will illustrate this point empirically in Section 6.
3.2

GENERAL EDGE-CORRECTION

Proposition 1 gives us a condition that allows us to
correct the partition function exactly, but under the
assumption that the single edge deleted is zero-MI.
The following result allows us, in fact, to correct the
partition function when deleting any single edge.
Proposition 2 Let M0 be the result of deleting a single equivalence edge (i, j) from a pairwise MRF M. If
the parameters of edge (i, j) satisfy Equation 1, then:
Z = Z0 ·

yij
,
zij

where

yij =

X

Pr 0 (xi | xj ).

xi =xj

Note that when the deleted edge (i, j) happens to be
zero-MI, factor yij is 1, and thus Proposition 2 reduces
to Proposition 1.
We can also use this proposition as a basis for correcting the partition function when multiple edges are
deleted, just as we did in Equation 3. In particular,
we now propose using the correction Z 0 · yz , where z is
the same factor given in Equation 3, and
Y X
Y
Pr 0 (xi | xj ), (4)
yij =
y=
(i,j)∈E ?

(i,j)∈E ? xi =xj

which we refer to as a general edge correction, or ec-g.
We note that when every edge is deleted in an ed-bp
network M0 , every deleted edge becomes a zero-MI
edge. Thus, in this case, ec-g reduces to ec-z, and
both yield the Bethe free energy, as in Theorem 1. As
we recover more edges, we may expect ec-g to offer
embedded in the reparametrized MRF induces a distribution whose exact node and edge marginals are consistent
with the corresponding marginals given by IBP. In contrast
to ed-bp, TRP’s embedded-tree distributions are already
normalized, i.e., their partition function is 1. Moreover,
generalizations of TRP appeal to auxiliary representations,
via reparametrization in joingraphs and hypergraphs. In
contrast, the semantics of ed-bp suggest that we simply
delete fewer edges. As we shall see in Section 5, the semantics of edge correction further suggest intuitive edge
recovery heuristics for choosing more structured approximations.

θ (X1)

1

θ (X
(X'1)

2

1

1'

2

3

3

Figure 3: An MRF (left); after deleting edge (1, 2), as
in Figure 2 (right).
improved approximations over ec-z, as it relaxes the
zero-MI assumption for deleted edges. Accordingly, we
may want to delete different edges for ec-g than we
would for ec-z.

4

AN EXAMPLE

We provide here an illustrative example of our edge
correction techniques. Consider a network of three
nodes X1 , X2 and X3 that form a clique, with the following edge potentials:
Xi
xi
xi
x̄i
x̄i

Xj
xj
x̄j
xj
x̄j

ψ(X1 , X2 )
.9
.1
.1
.9

ψ(X1 , X3 )
.1
.9
.9
.1

ψ(X2 , X3 )
.081
.810
.090
.900

Suppose now that we delete the edge (1, 2) by replacing (1, 2) with a chain {(1, 10 ), (10 , 2)} and deleting the
equivalence edge (1, 10 ); see Figure 3. Using ed-bp to
parameterize this deleted edge, we have (to 4 digits):
Xi
xi
x̄i

θ(X1 )
.4789
.5211

θ(X10 )
.8273
.1727

and we compute Z 0 ≈ 0.4447. In this example, edge
(1, 10 ) happens to be a zero-MI edge, so yij = 1 and
zij ≈ 0.4862. Further, we know that both Propositions 1 and 2 allow us to recover the true partition
function Z = Z 0 · z1ij ≈ 0.9146.
Now, suppose that we replace the potential on edge
(2, 3) with 1 − ψ(X2 , X3 ). In this case, ed-bp gives us
edge parameters (to 4 digits):
Xi
xi
x̄i

θ(X1 )
.5196
.4804

θ(X10 )
.1951
.8049

and we compute Z 0 ≈ 0.5053. In this case, edge (1, 10 )
is not a zero-MI edge. Here, we find that yij ≈ 1.0484
and zij ≈ 0.4880. Since we only delete a single edge,
Proposition 2 recovers the true partition function Z =
yij
= 1.08542 whereas Proposition 1 gives only an
Z 0 · zij
approximation Z 0 · z1ij ≈ 1.0353.

5

EDGE RECOVERY

noisy−or: EC−Z
0.12 k=11−20

Suppose we already have a tree-structured approximation M0 of the original model M, but are afforded
more computational resources. We can then improve
the approximation by recovering some of the deleted
edges. However, which edge’s recovery would have the
most impact on the quality of the approximation?
Edge Recovery for EC-Z. Since ec-z is exact for
a single deleted edge when MI (Xi ; Xj ) = 0, one may
want to recover those edges (i, j) with the highest mutual information MI (Xi ; Xj ). In fact, this is the same
heuristic proposed by (Choi & Darwiche, 2006a) for
improving marginal approximations. We will indeed
show the promise of this heuristic for ec-z corrections,
in Section 6. On the other hand, we also show that it
turns out to be a poor heuristic for ec-g corrections.
Edge Recovery for EC-G. Consider the situation
when two equivalence edges are deleted, (i, j) and
(s, t). In this case, we use the approximate correction:
Z0 ·

yij yst
y
= Z0 ·
,
z
zij zst

y

ij
where zij
is the single-edge correction for edge (i, j)
yst
and zst is the single-edge correction for edge (s, t).

The question now is: When is this double-edge correction exact? Intuitively, we want to identify a situation
where each edge can be corrected, independently of the
other. Consider then the case where variables Xi , Xj
are independent of variables Xs , Xt in M0 .
0

Proposition 3 Let M be the result of deleting two
equivalence edges, (i, j) and (s, t), from a pairwise
MRF M. If the edge parameters of M0 satisfy Equation 1, and if MI (Xi Xj ; Xs Xt ) = 0 in M0 , then:
Z = Z0 ·

yij yst
.
zij zst

This suggests a new edge recovery heuristic for ec-g
approximations to the partition function. Initially, we
start with a tree-structured network M0 . We assign
each deleted edge (i, j) a score:
X
MI (Xi Xj ; Xs Xt ).
(s,t)∈E ? \(i,j)

We then prefer to recover the top k edges with the
highest mutual information scores.

6

EXPERIMENTS

Our goal here is to highlight different aspects of edgecorrection, edge-recovery, and further a notion of partial correction. Starting from a random spanning tree

relative error

0.1 k=6−10
0.08
0.06
0.04 k=1−5
0.02
0

k=0−0

0

39

edges recovered

79 80

Figure 4: Edge correction in noisy-or networks.
(dropping instances where ed-bp and hence IBP, do
not converge), we rank each deleted edge, and recover
edges k at a time until all edges are recovered. At
each point, we evaluate the quality of the approximab − Z|/Z, where
tion by the average relative error |Z
b
Z denotes the designated approximation. Remember
that in a tree-structured approximation, when no edge
is recovered, ec-z corresponds to the Bethe approximation. Likewise, when every edge is recovered, both
ec-z and ec-g are exact. Although, for simplicity, we
presented our edge-correction framework in the context of pairwise MRFs, some of our experiments are
run on Bayesian networks, to which all of our results
also apply.3 In these cases, observations are generated
from the joint distribution over all leaves, unless otherwise specified.
Noisy-or. We consider first random two-layer noisyor networks. Deleting an edge in this network effectively disconnects a cause variable C from an effect
variable E, where a clone Ĉ replaces C as a a cause
of E.4 In this situation, we may use edge-correction
to reason how well ec-z and the Bethe approximation
may perform. With no positive findings, for example,
we know that all causes are pairwise mutually independent, including a cause C and its clone Ĉ in a noisy-or
network where edges have been deleted. Starting from
a tree-structured approximation, corresponding to the
Bethe approximation, every recoverable edge is zeroMI and will remain zero-MI up to the point where all
edges are recovered. Thus we may infer ec-z to be
exact throughout, and thus also that the Bethe approximation is exact.
Consider now Figure 4, which compares the quality of
ec-z corrections as edges are recovered randomly. We
generated over 400 random noisy-or networks,5 where
3

Most of the Bayesian networks used here are available
at http://www.cs.huji.ac.il/labs/compbio/Repository.
4
As in Section 2, we replace edge C → E with a chain
C → Ĉ → E, and delete the equivalence edge C → Ĉ.
5
Each network was given 20 roots and 20 sinks, where

for each network, we randomly chose k of 20 effect
variables as positive findings and the remaining effect
variables as negative findings. We have 4 cases here
measuring the quality of the ec-z approximation, each
an average over a range of positive findings: 0, 1–5,
6–10, 11–20. As predicted, the ec-z and Bethe approximations are exact with 0 positive findings. Given
this, we expect, and observe, that with more positive
findings, and fewer zero-MI edges, the ec-z and Bethe
approximations tend to be less accurate.
Edge recovery. Consider now Figure 5, where we
compare ec-z corrections to ec-g corrections, but also
the impact that different edge recovery heuristics can
have on an approximation. Here, plots are averages of
over 50 instances. In the first plot, we took random
6×6 grid networks, where pairwise couplings were randomly given parameters in [0.0, 0.1) or (0.9, 1.0]. First,
when we compare ec-z and ec-g by random edge recovery, we see that ec-g is a notable improvement
over ec-z, even when no edges are recovered. When
we use the mutual information heuristic (MI) designed
for ec-z, the ec-z approximations also improve considerably. However, ec-g approximations are worse than
when we randomly recovered edges! Although ec-g
approximations still dominate the ec-z ones, this example illustrates that ec-z approximations (based on
the Bethe approximation) and ec-g approximations
(based on exact corrections for a single edge) are of a
different nature, and suggest that an alternative approach to recovery may be needed. Indeed, when we
use the mutual information heuristic (MI2) designed
for ec-g, we find that ec-g easily dominates the first
four approximations. We see similar results in the
win95pts and water networks.
Partial corrections. Although the individual edgecorrections for ec-z are trivial to compute, the corrections for ec-g require joint marginals. In the case
where we need to correct for many deleted edges, the
ec-g corrections of Equation 4 may become expensive
to compute. We may then ask: Can we effectively
improve an approximation, by correcting for only a
subset of the edges?
Consider then Figure 6, where we plot how the quality of our approximation evolves over time (averaged
over 50 instances), over two steps: (1) the ed-bp
parametrization algorithm, and after convergence (2)
ec-g edge correction. On the first half of each plot,
we start with a tree-structured approximate network,
and compute the ec-z approximation as ed-bp (and
equivalently, IBP, in this case) runs for a fixed number
of iterations. Eventually, the edge-corrected partition
function converges (to the Bethe approximation), at
sinks are given 4 random parents. Network parameters
were also chosen randomly.

which point we want to compute the edge corrections
for ec-g. We can compute the corrections for an edge,
one-by-one, applying them to the ec-z approximation
as they are computed. Since edge corrections are invariant to the order in which they are computed, we
can then examine a notion of a partial ec-g approximation that accumulates only the correction factors
for a given subset of deleted edges.
On the right half of each plot, we compute the error
in a partial ec-g approximation given two separate
orderings of deleted edges. The first ordering, which
we consider to be “optimal”, pre-computes corrections
for all edges and sorts them from largest to smallest.
In the win95pts network, we find that in fact, most
of the edges have very little impact on the final ec-g
approximation! Moreover, the time it took to compute the most important corrections required only as
much time as it took ed-bp (IBP) to converge. This
suggests that it is possible to improve on the Bethe approximation, with only a modest amount of additional
computation (in the time to compute corrections for
the important edges).
Of course, such an approach would require a way to
identify the most important corrections, without actually computing them. In (Choi & Darwiche, 2008), we
proposed a soft extension of d-separation in polytree
Bayesian networks that was shown to be effective in
ranking edges for the process of edge recovery (as in
ec-z). Applying it here to the task of ranking edgecorrections, we find that it is also effective at identifying important edges for correction. For example, in the
win95pts network, soft d-separation (sd-sep) is nearly
as competitive with the “optimal” at producing partial ec-g approximations. Moreover, soft d-separation
is much more efficient, requiring only node and edge
marginals to rank all deleted edges.
We see a similar story in the pigs and mildew network. In the mildew network, where many deleted
edges have an impact on the approximation, the quality of the approximation tends to improve monotonically (on average), so we may still desire to perform as
many individual corrections as resources allow.

7

EDGE CORRECTIONS AND
FREE ENERGIES

As the Bethe free energy is an edge-corrected partition
function, ec-z and ec-g approximations can be viewed
also from the perspective of free energies.
When the model M0 is a tree, ec-z yields the influential Bethe free energy approximation (Yedidia et al.,
2005). When the model M0 has cycles, it can be
shown that ec-z corresponds more generally to jo-

0.05

EC−Z,rand
EC−G,rand
EC−Z,MI
EC−G,MI
EC−G,MI2

0.3
relative error

relative error

0.06

water

win95pts

0.4

EC−Z,rand
EC−G,rand
EC−Z,MI
EC−G,MI
EC−G,MI2

0.04
0.03
0.02

0.025

0.2

0.02
0.015
0.01

0.1

0.005

0.01
0
0

EC−Z,rand
EC−G,rand
EC−Z,MI
EC−G,MI
EC−G,MI2

0.03

relative error

6x6 grid
0.07

edges recovered

0
0

25

edges recovered

0

37

edges recovered

35

Figure 5: ec-z versus ec-g, and edge recovery.
win95pts

0.6
0.4
0.2
0
0

mildew
ED−BP
EC−G,opt
EC−G,sd−sep

0.8
relative error

relative error

0.8

pigs

1

ED−BP
EC−G,opt
EC−G,sd−sep

0.6
0.4

100

0
0

150

0.3

0.2

0.1

0.2

50

ED−BP
EC−G,opt
EC−G,sd−sep

0.4

relative error

1

500

1000

time (ms)

1500 2000
time (ms)

2500

3000

0
0

5000

10000
time (ms)

15000

Figure 6: Time to parametrize by ed-bp, and compute ec-g corrections.
ingraph free energy approximations (Aji & McEliece,
2001; Dechter, Kask, & Mateescu, 2002); see (Choi &
Darwiche, 2006a) for the connection to iterative joingraph propagation.
The ec-g correction can also take the form of another
free energy approximation. Note first that when multiple equivalence edges are deleted, we can compute the
0
partition function Zij
of a model M0ij where the single
edge (i, j) has been recovered (keeping edge parameyij
0
. Therefore,
ters for all other edges fixed): Zij
= Z 0 · zij
we have that:
0
Y yij
Y Zij
y
.
= Z0 ·
Z0 · = Z0 ·
z
zij
Z0
?
?
(i,j)∈E

(i,j)∈E

0 y
This yields a (dual)
P energy of0 the form − log(Z · z ) =
0
(n−1) log Z − (i,j)∈E ? log Zij , where n is the number
of equivalence edges (i, j) deleted. Whereas we fixed,
somewhat arbitrarily, our edge parameters to satisfy
Equation 1, we could in principle seek edge parameters optimizing the above free energy directly, giving
rise to EP and GBP free energy approximations with
higher-order structure (Welling, Minka, & Teh, 2005).
On the other hand, edge recovery heuristics for ec-g
could possibly serve as a heuristic for identifying improved EP and GBP free energies, directly. This is a
perspective that is currently being investigated.

While we are concerned mostly with IBP and the
closely related Bethe free energy approximation, we
expect that an edge-correction perspective may be use-

ful in improving other reasoning algorithms, particularly those that can be formulated as exact inference
in simplified models. These include, as we have shown
here, IBP and some of its generalizations (Yedidia
et al., 2005), but also numerous variational methods (Jordan, Ghahramani, Jaakkola, & Saul, 1999;
Wiegerinck, 2000; Geiger, Meek, & Wexler, 2006) and
their corresponding free energy approximations. Also
related, is tree-reweighted belief propagation (TRW)
(Wainwright, Jaakkola, & Willsky, 2005), which provides upper bounds on the log partition function, and
can be thought of as a convexified form of the Bethe
free energy. Mean field methods and its generalizations are another well-known class of approximations
that provide lower bounds on the partition function
(e.g., Saul & Jordan, 1995; Jaakkola, 2001). Although
the latter have been found to be useful, others have
found that the Bethe free energy can often provide better quality approximations, (e.g., Weiss, 2001). Similarly, comparing ec-z approximations and mean-field
bounds derived from approximations with the same
structure, we find that ec-z, which does not guarantee bounds, offers better approximations.

8

CONCLUSION

We proposed an approach for approximating the partition function which is based on two steps: (1) computing the partition function of a simplified model which
is obtained by deleting model edges, and (2) rectifying

the result by applying an edge-by-edge correction. The
approach leads to an intuitive framework in which one
can trade-off the quality of an approximation with the
complexity of computing it through a simple process
of edge recovery. We provided two concrete instantiations of the proposed framework by proposing two
edge correction schemes with corresponding heuristics
for edge recovery. The first of these instantiations captures the well known Bethe free energy approximation
as a degenerate case. The second instantiation has
been shown to lead to more accurate approximations,
more so when edge recovery is targeted towards accurate correction. We further highlighted, in our experiments, how edge correction could be used as a conceptual tool to help identify situations where the Bethe
approximation may be exact, or accurate. Finally, we
suggested a notion of partial correction, that can improve on the Bethe approximation with only a modest
amount of computational effort.

This work has been partially supported by Air Force
grant #FA9550-05-1-0075 and by NSF grant #IIS0713166.

PROOFS

Note that Proposition 1 follows from Proposition 2.
Proof of Theorem 1 When a given model is a tree,
the Bethe free energy is exact. We then consider
the exact energy of a tree-structured M0 where F 0 =
− log Z 0 . Our goal then is to show that Zβ = Z 0 · z1 ,
or equivalently, F 0 = Fβ − log z.
Let E[ . ] denote expectations and H (.) denote entropies with respect to IBP beliefs, and equivalently,
ed-bp marginals in M0 (Choi & Darwiche, 2006a).
First, note that Fβ = Uβ − Hβ where Uβ is the Bethe
average energy
X
X
Uβ = −
E[ log ψ(Xi , Xj ) ] −
E[ log ψ(Xi ) ]
i∈V

(i,j)∈E

and where Hβ is the Bethe approximate entropy
Hβ =

X
(i,j)∈E

H (Xi , Xj ) −

The average energy U 0 and the entropy H 0 for M0 is
X

U0 = −

E[ log ψ(Xi , Xj ) ] −

X

−

X

H =

X

(ni − 1)H (Xi )

i∈V

where ni is the number of neighbors of node i in M
(for details, see Yedidia et al., 2005).
It will be convenient to start with the case where every
edge (i, j) in the unextended model is replaced with a
chain {(i, i0 ), (i0 , j 0 ), (j 0 , j)}. We then delete all equivalence edges (i, i0 ), (j 0 , j) ∈ E ? . Note that the resulting

E[ log ψ(Xi ) ]

E[ log θ(Xi )θ(Xi0 ) ]

(i,i0 )∈E ?
0

X
i∈V

(i0 ,j 0 )∈E

H (Xi , Xj ) +

X

H (Xi ).

i∈V

(i0 ,j 0 )∈E ?

Since θ(xi )θ(xj ) = zij Pr (xi ) (see Equation 2), we have
E[ log θ(Xi )θ(Xi0 ) ] = log zij − H (Xi ).

(5)

We can show through further manipulations that
X

E[ log θ(Xi )θ(Xi0 ) ] = log z −

X

ni H (Xi ).

i∈V

(i,i0 )∈E ?

Acknowledgments

A

network M0 has n + 2m nodes: n nodes i ∈ V, and 2
clone nodes i0 , j 0 for each of the m edges (i0 , j 0 ) ∈ E.

After substituting into Uβ0 , and some rearrangement:
F 0 = U 0 − H 0 = Uβ − Hβ − log z = Fβ − log z
as desired. To show this correspondence continues to
hold for any tree-structured M0 , we note first that
IBP beliefs continue to be node and edge marginals for
any tree-structured ed-bp approximation M0 . Next,
when we recover an edge into a tree approximation
that yields another tree approximation, we lose an
expectation over edge parameters (Equation 5). The
corresponding node entropy H (Xi ) that is lost in the
average energy U 0 is canceled out by a node entropy
gained in the entropy H 0 . Finally, the term log zij
that is lost is no longer needed in the correction factor z after recovery. Thus, we can recover edges into
our fully disconnected approximation, and conclude
that F 0 = Fβ − log z continues to hold for any treestructured approximation M0 .

Proof of Proposition 2 In an extended network M
with equivalence edge (i, j) and potential φ(xi , xj ):
Z=

X
xi =xj

X
∂2Z 0
∂Z
=
∂φ(xi , xj ) x =x ∂θ(xi )∂θ(xj )
i

j

X Z 0 Pr 0 (xi , xj )
X Z 0 Pr 0 (xi , xj )
=
=
θ(xi )θ(xj )
zij Pr 0 (xj )
x =x
x =x
i

j

0

=

Z
zij

X

i

j

Pr 0 (xi | xj )

xi =xj
y

ij
which is simply Z 0 · zij
. Note that the fourth equality
follows from Equation 2.


Proof of Proposition 3 In an extended network M
with equivalence edges (i, j) and (s, t) and edge potentials φ(xi , xj ) and φ(xs , xt ):
X
∂2Z
Z=
xi =xj ∂φ(xi , xj )∂φ(xs , xt )
xs =xt

=

X
xi =xj
xs =xt

=

∂4Z 0
∂θ(xi )∂θ(xj )∂θ(xs )∂θ(xt )

X Z 0 Pr 0 (xi , xj , xs , xt )
xi =xj θ(xi )θ(xj )θ(xs )θ(xt )
X Z 0 Pr 0 (xi , xj , xs , xt )
0
0
xi =xj zij Pr (xj )zst Pr (xt )

Saul, L. K., & Jordan, M. I. (1995). Exploiting
tractable substructures in intractable networks. In
Advances in Neural Information Processing Systems
(NIPS), pp. 486–492.

by Eq. 2

xs =xt

=

Wainwright, M. J., Jaakkola, T., & Willsky, A. S.
(2003). Tree-based reparameterization framework
for analysis of sum-product and related algorithms.
IEEE Transactions on Information Theory, 49 (5),
1120–1146.

Z 0 X Pr 0 (xi , xj )Pr 0 (xs , xt )
zij zst xi =xj
Pr 0 (xj )Pr 0 (xt )
xs =xt

X
Z0 X
Pr 0 (xs |xt )
Pr 0 (xi |xj )
=
zij zst x =x
x =x
i

j

0

yij yst
zij zst .

which is simply Z ·

s

Jordan, M. I., Ghahramani, Z., Jaakkola, T., & Saul,
L. K. (1999). An introduction to variational methods for graphical models. Machine Learning, 37 (2),
183–233.
Park, J., & Darwiche, A. (2004). A differential semantics for jointree algorithms. Artificial Intelligence,
156, 197–216.

xs =xt

=

Jaakkola, T. (2001). Tutorial on variational approximation methods. In Saad, D., & Opper, M. (Eds.),
Advanced Mean Field Methods. MIT Press.

t






optimal solution, by simply reasoning about the behavior of its underlying inference method.

We propose a method called EDML for learning MAP parameters in binary Bayesian networks under incomplete data. The method
assumes Beta priors and can be used to learn
maximum likelihood parameters when the
priors are uninformative. EDML exhibits
interesting behaviors, especially when compared to EM. We introduce EDML, explain
its origin, and study some of its properties
both analytically and empirically.

Even though EDML originates in a rather involved approximate inference scheme, its update equations can
be intuitively justified independently. We therefore
present EDML initially in Section 3 before delving into
the details of how it was originally derived in Section 5.

INTRODUCTION

We consider in this paper the problem of learning
Bayesian network parameters given incomplete data,
while assuming that all network variables are binary.
We propose a specific method, EDML,1 which has
a similar structure and complexity to the EM algorithm (Dempster, Laird, & Rubin, 1977; Lauritzen,
1995). EDML assumes Beta priors on network parameters, allowing one to compute MAP parameters.
When using uninformative priors, EDML reduces to
computing maximum likelihood (ML) parameters.
EDML originated from applying an approximate inference algorithm (Choi & Darwiche, 2006) to a meta
network in which parameters are explicated as variables, and on which data is asserted as evidence. The
update equations of EDML resemble the ones for EM,
yet EDML appears to have different convergence properties which stem from its being an inference method
as opposed to a local search method. For example, we
will identify a class of incomplete datasets on which
EDML is guaranteed to converge immediately to an
1

EDML stands for Edge-Deletion MAP-Learning or
Edge-Deletion Maximum-Likelihood as it is based on an
edge-deletion approximate inference algorithm that can
compute MAP or maximum likelihood parameters.

Intuitively, EDML can be thought of as relying on two
key concepts. The first concept is that of estimating
the parameters of a single random variable given soft
observations, i.e., observations that provide soft evidence on the values of a random variable. The second
key concept behind EDML is that of interpreting the
examples of an incomplete data set as providing soft
observations on the random variables of a Bayesian
network. As to the first concept, we also show that
MAP and ML parameter estimates are unique in this
case, therefore, generalizing the fundamental result
which says that these estimates are unique for hard
observations. This result is interesting and fundamental enough that we treat it separately in Section 4 before we move on and discuss the origin of EDML in
Section 5.
We discuss some theoretical properties of EDML in
Section 6, where we identify situations in which it is
guaranteed to converge immediately to optimal estimates. We present some preliminary empirical results
in Section 7 that corroborate some of the convergence
behaviors predicted. In Section 8, we close with some
concluding remarks on related and future work. We
note that while we focus on binary variables here, our
approach generalizes to multivalued variables as well.
We will comment later on this and the reason we restricted our focus here.

2

TECHNICAL PRELIMINARIES

We use upper case letters (X) to denote variables and
lower case letters (x) to denote their values. Variable

sets are denoted by bold-face upper case letters (X)
and their instantiations by bold-face lower case letters
(x). Since our focus is on binary variables, we use
x (positive) and x̄ (negative) to denote the two values of binary variable X. Generally, we will use X to
denote a variable in a Bayesian network and U to denote its parents. A network parameter will therefore
have the general form θx|u , representing the probability Pr (X = x|U = u).
Note that variable X can be thought of as inducing a
number of conditional random variables, denoted Xu ,
where the values of variable Xu are drawn based on
the conditional distribution Pr (X|u). In fact, parameter estimation in Bayesian networks can be thought
of as a process of estimating the distributions of these
conditional random variables. Since we assume binary
variables, each of these distributions can be characterized by the single parameter θx|u , since θx̄|u = 1−θx|u .
We will use θ to denote the set of all network parameters. Given a network structure G in which all variables are binary, our goal is to learn its parameters
from an incomplete dataset, such as:
example
1
2
3

X
x
?
x̄

Y
ȳ
ȳ
?

Z
?
?
z

We use D to denote a dataset, and di to denote an
example. The dataset above has three examples, with
d3 being the instantiation X = x̄, Z = z.
A commonly used measure for the quality of parameter
estimates θ is their likelihood, defined as:
QN
L(θ|D) = i=1 Pr θ (di ),
where Pr θ is the distribution induced by network
structure G and parameters θ. In the case of complete
data (each example fixes the value of each variable),
the ML parameters are unique. Learning ML parameters is harder when the data is incomplete, where EM
is typically employed. EM starts with some initial parameters θ0 , called a seed, and successively improves
on them via iteration. EM uses the update equation:
PN
P rθk (xu|di )
k+1
θx|u = Pi=1
,
N
i=1 P rθ k (u|di )
which requires inference on a Bayesian network parameterized by θk , in order to compute P rθk (xu|di ) and
P rθk (u|di ). In fact, one run of the jointree algorithm
on each distinct example is sufficient to implement an
iteration of EM, which is guaranteed to never decrease
the likelihood of its estimates across iterations. EM
also converges to every local maxima, given that it
starts with an appropriate seed. It is common to run

EM with multiple seeds, keeping the best local maxima it finds. See (Darwiche, 2009; Koller & Friedman,
2009) for recent treatments on parameter learning in
Bayesian networks via EM and related methods.
EM can also be used to find MAP parameters, assuming one has some priors on network parameters.
The Beta distribution is commonly used as a prior on
the probability of a binary random variable. In particular, the Beta for random variable Xu is specified
by two exponents, αXu and βXu , leading to a density
∝ [θx|u ]αXu −1 [1 − θx|u ]βXu −1 . It is common to assume
that exponents are > 1 (the density is then unimodal).
For MAP parameters, EM uses the update equation
(see, e.g., (Darwiche, 2009)):
PN
αXu − 1 + i=1 Pr θk (xu|di )
k+1
.
θx|u
=
PN
αXu + βXu − 2 + i=1 Pr θk (u|di )
When αXu = βXu = 1 (uninformative prior), the
equation reduces to the one for computing ML parameters. When computing ML parameters, using
αXu = βXu = 2 leads to what is usually known as
Laplace smoothing. This is a common technique to
deal with the problem of insufficient counts (i.e., instantiations that never appear in the dataset, leading
to zero probabilities and division by zero). We will
indeed use Laplace smoothing in our experiments.
Our method for learning MAP and ML parameters
makes heavy use of two notions: (1) the odds of an
event, which is the probability of the event over the
probability of its negation, and (2) the Bayes factor (Good, 1950), which is the relative change in
the odds of one event, say, X = x, due to observing some other event, say, η. In this case, we have
the odds O(x) and O(x|η), where the Bayes factor is
κ = O(x|η)/O(x), which is viewed as quantifying the
strength of soft evidence η on X = x. It is known that
κ = Pr (η|x)/Pr (η|x̄) and κ ∈ [0, ∞]. When κ = 0,
the soft evidence reduces to hard evidence asserting
X = x̄. When κ = ∞, the soft evidence reduces to
hard evidence asserting X = x. When κ = 1, the soft
evidence is neutral and bears no information on X = x.
A detailed discussion on the use of Bayes factors for
soft evidence is given in (Chan & Darwiche, 2005).

3

AN OVERVIEW OF EDML

Consider Algorithm 1, which provides pseudocode for
EM. EM typically starts with some initial parameters
estimates, called a seed, and then iterates to monotonically improve on these estimates. Each iteration
consists of two steps. The first step, Line 3, computes
marginals over the families of a Bayesian network that
is parameterized by the current estimates. The second step, Line 4, uses the computed probabilities to

Algorithm 1 EM

Algorithm 2 EDML

input:
G:
A Bayesian network structure
D:
An incomplete dataset d1 , . . . , dN
θ:
An initial parameterization of structure G
αXu , βXu : Beta prior for each random variable Xu
1: while not converged do
2:
Pr ← distribution induced by θ and G
3:
Compute probabilities:

input:
G:
A Bayesian network structure
D:
An incomplete dataset d1 , . . . , dN
θ:
An initial parameterization of structure G
αXu , βXu : Beta prior for each random variable Xu
1: while not converged do
2:
Pr ← distribution induced by θ and G
3:
Compute Bayes factors:

Pr (xu|di )

4:

and

for each family instantiation xu and example di
Update parameters:
θx|u ←

αXu − 1 +
αXu + βXu

κix|u ←

Pr (u|di )

Pr (xu|di )/Pr (x|u) − Pr (u|di ) + 1
Pr (x̄u|di )/Pr (x̄|u) − Pr (u|di ) + 1

for each family instantiation xu and example di
Update parameters:

4:

PN

Pr (xu|di )
PN
− 2 + i=1 Pr (u|di )
i=1

5: return parameterization θ

(1)

θx|u ← argmax [p]αXu −1 [1 − p]βXu −1
p

N
Y

[κix|u · p − p + 1]

i=1

(2)
5: return parameterization θ

update the network parameters. The process continues until some convergence criterion is met. The main
point here is that the computation on Line 3 can be
implemented by a single run of the jointree algorithm,
while the update on Line 4 is immediate.

random variable X are unique in this case and characterized by θx = Nx /N . If one further assumes a Beta
prior with exponents α and β that are ≥ 1, it is also
known that the MAP parameter estimates are unique
x +α−1
and characterized by θx = NN+α+β−2
.

Consider now Algorithm 2, which provides pseudocode
for EDML, to be contrasted with the one for EM. The
two algorithms clearly have the same overall structure.
That is, EDML also starts with some initial parameters estimates, called a seed, and then iterates to update these estimates. Each iteration consists of two
steps. The first step, Line 3, computes Bayes factors
using a Bayesian network that is parameterized by the
current estimates. The second step, Line 4, uses the
computed Bayes factors to update network parameters. The process continues until some convergence
criterion is met. Much like EM, the computation on
Line 3 can be implemented by a single run of the jointree algorithm. Unlike EM, however, the update on
Line 4 is not immediate as it involves solving an optimization problem, albeit a simple one. Aside from
this optimization task, EM and EDML have the same
computational complexity.

Consider now a more general problem in which the
observations are soft in that they only provide soft
evidence on the values of random variable X. That
is, each soft observation ηi is associated with a Bayes
factor κix = O(x|ηi )/O(x) which quantifies the evidence that ηi provides on having observed the value
x of variable X. We will show later that the ML estimates remain unique in this more general case, if at
least one of the soft observations is not trivial (i.e.,
with Bayes factor κix 6= 1). Moreover, we will show
that the MAP estimates are also unique assuming a
Beta prior with exponents ≥ 1. In particular, we will
show that the unique MAP estimates are characterized by Equation 2 of Algorithm 2. Further, we will
show that the unique ML estimates are characterized
by the same equation while using a Beta prior with
exponents = 1. This is the first key concept that underlies our proposed algorithm for estimating ML and
MAP parameters in a binary Bayesian network.

We next explain the two concepts underlying EDML
and how they lead to the equations of Algorithm 2.

3.2
3.1

ESTIMATION FROM SOFT
OBSERVATIONS

Consider a random variable X with values x and x̄, and
suppose that we have N > 0 independent observations
of X, with Nx as the number of positive observations.
It is well known that the ML parameter estimates for

EXAMPLES AS SOFT
OBSERVATIONS

The second key concept underlying EDML is to interpret each example di in a dataset as providing a soft
observation on each random variable Xu . As mentioned earlier, soft observations are specified by Bayes
factors and, hence, one needs to specify the Bayes factor κix|u that example di induces on random variable

x
X1

X2

…

XN

Figure 1: Estimation given independent observations.

Xu . EDML uses Equation 1 for this purpose, which
will be derived in Section 5. We next consider a few
special cases of this equation to highlight its behavior.
Consider first the case in which example di implies
parent instantiation u (i.e., the parents U of variable
X are instantiated to u in example di ). In this case,
i)
Equation 1 reduces to κix|u = O(x|u,d
O(x|u) , which is the
relative change in the odds of x given u due to conditioning on example di . Note that for root variables X,
which have no parents U, Equation 1 further reduces
i)
to κix = O(x|d
O(x) .
The second case we consider is when example di is
inconsistent with parent instantiation u. In this case,
Equation 1 reduces to κix|u = 1, which amounts to
neutral evidence. Hence, example di is irrelevant to
estimating the distribution of variable Xu in this case,
and will be ignored by EDML.
The last special case of Equation 1 we shall consider
is when the example di is complete; that is, it fixes
the value of each variable. In this case, one can verify
that κix|u ∈ {0, 1, ∞} and, hence, the example can be
viewed as providing either neutral or hard evidence
on each random variable Xu . Thus, an example will
provide soft observations on variables only when it is
incomplete (i.e., missing some values). Otherwise, it
is either irrelevant to, or provides a hard observation
on, each variable Xu .
In the next section, we prove Equation 2 of Algorithm 2. In Section 5, we discuss the origin of EDML,
where we go on and derive Equation 1 of Algorithm 2.

4

ESTIMATION FROM SOFT
OBSERVATIONS

Consider a binary variable X. Figure 1 depicts a network where θx is a parameter representing Pr (X = x)
and X 1 , . . . , X N are independent observations of X.
Suppose further that we have a Beta prior on parameter θx with exponents α ≥ 1 and β ≥ 1. A standard
estimation problem is to assume that we know the values of these observations and then estimate the parameter θx . We now consider a variant on this problem, in
which we only have soft evidence ηi about each obser-

vation, whose strength is quantified by a Bayes factor
κix = O(x|ηi )/O(x). Here, κix represents the change
in odds that the i-th observation is positive due to evidence ηi . We will refer to ηi as a soft observation on
variable X, and our goal in this section is to compute
(and optimize) the posterior density on parameter θx
given these soft observations η1 , . . . , ηN .
We first consider the likelihood:
QN
Pr (η1 , . . . , ηN |θx ) = i=1 Pr (ηi |θx )
QN
= i=1 [Pr (ηi |x, θx )Pr (x|θx ) + Pr (ηi |x̄, θx )Pr (x̄|θx )]
QN
= i=1 [Pr (ηi |x)θx + Pr (ηi |x̄)(1 − θx )]
QN
∝ i=1 [κix · θx − θx + 1].
The last step follows because κix = O(x|ηi )/O(x) =
Pr (ηi |x)/Pr (ηi |x̄). The posterior density is then:
ρ(θx |η1 , . . . , ηN ) ∝ ρ(θx )Pr (η1 , . . . , ηN |θx )
QN
∝ [θx ]α−1 [1 − θx ]β−1 i=1 [κix · θx − θx + 1].
This is exactly Equation 2 of Algorithm 2 assuming
we replace the random variable X with the conditional
random variable Xu .2
The second derivative of the log posterior is
X  (κi − 1) 2
β−1
α−1
x
−
−
−
i − 1)θ + 1
[θx ]2
[1 − θx ]2
(κ
x
x
i
which is strictly negative when κix 6= 1 for at least one
i. This remains true when α = β = 1. Hence, both
the likelihood function and the posterior density are
strictly log-concave and therefore have unique modes.
This means that both ML and MAP parameter estimates are unique in the case of soft, independent observations, which generalizes the uniqueness result for
hard, independent observations on a variable X.

5

THE ORIGIN OF EDML

This section reveals the technical origin of EDML,
showing how Equation 1 of Algorithm 2 is derived, and
providing the basis for the overall structure of EDML
as spelled out in Algorithm 2.
EDML originated from an approximation algorithm
for computing MAP parameters in a meta network.
Figure 2 depicts an example meta network in which
2
The case of κix = ∞ needs to be handled carefully
in Equation 2. First note that κix = ∞ iff Pr (ηi |x̄) = 0
in the derivation of this equation. In this case, the term
Pr (ηi |x)θx +Pr (ηi |x̄)(1−θx ) equals c·θx for some constant
c ∈ (0, 1]. Since the value of Equation 2 does not depend
on constant c, we will assume c = 1. Hence, when κix = ∞,
the term [κix · θx − θx + 1] evaluates to θx by convention.

h
H1

S1

H2

E1

s|h

S2

H3

E2

s|h

e|h

S3

E3

e|h

Figure 2: A meta network induced from a base network
S←−H−→E. The CPTs here are based on standard
semantics; see, e.g., (Darwiche, 2009, Ch. 18).

parameters are represented explicitly as nodes (Darwiche, 2009). In particular, for each conditional random variable Xu in the original Bayesian network,
called the base network, we have a node θx|u in the
meta network which represents a parameter that characterizes the distribution of this random variable.
Moreover, the meta network includes enough instances
of the base network to allow the assertion of each example di as evidence on one of these instances. Assuming that θ is an instantiation of all parameter variables,
and D is a dataset, MAP estimates are then:
θ? = argmax ρ(θ|D),
θ

where ρ is the density induced by the meta network.
Computing MAP estimates exactly is usually prohibitive due to the structure of the meta network. We
therefore use the technique of edge deletion (Choi &
Darwiche, 2006), which formulates approximate inference as exact inference on a simplified network that is
obtained by deleting edges from the original network.
The technique compensates for these deletions by introducing auxiliary parameters whose values must be
chosen carefully (and usually iteratively) in order to
improve the quality of approximations obtained from
the simplified network. EDML is the result of making
a few specific choices for deleting edges and for choosing values for the auxiliary parameters introduced,
which we explain next.
5.1

INTRODUCING GENERATORS

Let X i denote the instance of variable X in the base
network corresponding to example di . The first choice

3

H3

H3

E3

E3

3

3

Eh:

3

Eh:

3

3

Eh

Eh

Eh

Eh

e|h

e|h

e|h

e|h

(a) Adding generators

(b) Deleting copy edges

Figure 3: Introducing generators into a meta network
and then deleting copy edges from the resulting meta
network, which leads to introducing clones.

of EDML is that for each edge θx|u −→X i in the meta
network, we introduce a generator variable Xui , leading
to the pair of edges θx|u −→Xui −→X i . Figure 3(a)
depicts a fragment of the meta network in Figure 2, in
which we introduced two generator variables for edges
θe|h −→E 3 and θe|h̄ −→E 3 , leading to θe|h −→Eh3 −→E 3
and θe|h̄ −→Eh̄3 −→E 3 .
Variable Xui is meant to generate values of variable X i
according to the distribution specified by parameter
θx|u . Hence, the conditional distribution of a generator
Xui is such that Pr (xiu |θx|u ) = θx|u . Moreover, the
CPT of variable X i is set to ensure that variable X i
copies the value of generator Xui if and only if the
parents of X i take on the value u. That is, the CPT of
variable X i acts as a selector that chooses a particular
generator Xui to copy from, depending on the values
of its parents U. For example, in Figure 3(a), when
parent H 3 takes on its positive value h, variable E 3
copies the value of generator Eh3 . When parent H 3
takes on its negative value h̄, variable E 3 copies the
value of generator Eh̄3 .
Adding generator variables does not change the meta
network as it continues to have the same density over
the original variables. Yet, generators are essential
to the derivation of EDML as they will be used for
interpreting data examples as soft observations.
5.2

DELETING COPY EDGES

The second choice made by EDML is that we only
delete edges of the form Xui −→X i from the augmented
meta network, which we shall call copy edges. Figure 3(b) depicts an example in which we have deleted

h

the root and generators Xui as children. When soft
evidence is asserted on these generators, we get the
estimation problem we treated in Section 4.

H2:
H1
S1

H3

H2
E1

S3

S2

E2

S2h:

E2h:

E3

EDML can now be fully described by specifying (1)
the soft evidence on each generator Xui in a paramei
ter island, and (2) the CPT of each clone Xu:
in an
example island. These specifications are given next.
5.4

S1h

S2h

s|h

S3h

S2h:

s|h

e|h

E2h:

e|h

Figure 4: An edge-deleted network obtained from the
meta network in Figure 2 found by: (1) adding generator variables, (2) deleting copy edges, and (3) adding
cloned generators. The figure highlights the island for
example d2 , and the island for parameter θs|h .

the two copy edges from Figure 3(a).
Note here the addition of another auxiliary variable
i
Xu:
, called a clone, for each generator Xui . The addition of clones is mandated by the edge deletion framei
is chosen
work. Moreover, if the CPT of clone Xu:
carefully, it can compensate for the parent-to-child information lost when deleting edge Xui −→X i . We will
later see how EDML sets these CPTs. The other aspect of compensating for a deleted edge is to specify
soft evidence on each generator Xui . This is also mandated by the edge deletion framework, and is meant
to compensate for the child-to-parent information lost
when deleting edge Xui −→X i . We will later see how
EDML sets this soft evidence as well, which effectively
completes the specification of the algorithm. We prelude this specification, however, by making some further observations about the structure of the meta network after edge deletion.
5.3

PARAMETER & EXAMPLE ISLANDS

Consider the network in Figure 4, which is obtained
from the meta network in Figure 2 according to the
edge-deletion process indicated earlier.
The edge-deleted network contains a set of disconnected structures, called islands. Each island belongs
to one of two classes: a parameter island for each network parameter θx|u and an example island for each
example di in the dataset. Figure 4 provides the full
details for one example island and one parameter island. Note that each parameter island corresponds
to a Naive Bayes structure, with parameter θx|u as

CHILD-TO-PARENT
COMPENSATION

The edge deletion approach suggests the following soft
evidence on generators Xui , specified as Bayes factors:
κix|u =

O(xiu: |di )
P ri (di |xiu: )
=
,
O(xiu: )
P ri (di |x̄iu: )

(3)

where P ri is the distribution induced by the island
of example di . We will now show that this equation
simplifies to Equation 1 of Algorithm 2.
i
from the
Suppose that we marginalize all clones Xu:
island of example di , leading to a network that induces
a distribution Pr . The new network has the following
properties. First, it has the same structure as the base
network. Second, Pr (x|u) = P ri (xiu: ), which means
that the CPTs of clones in example islands correspond
to parameters in the base network. Finally, if we use
u to denote the disjunction of all parent instantiations
excluding u, we get:

κix|u

=
=
=

P ri (di |xiu: )
P ri (di |x̄iu: )
Pr (di |xu)Pr (u) + Pr (di |u)Pr (u)
Pr (di |x̄u)Pr (u) + Pr (di |u)Pr (u)
Pr (xu|di )/Pr (x|u) − Pr (u|di ) + 1
.
Pr (x̄u|di )/Pr (x̄|u) − Pr (u|di ) + 1

This is exactly Equation 1 of Algorithm 2. Hence, we
can evaluate Equation 3 by evaluating Equation 1 on
the base network, as long as we seed the base network
with parameters that correspond to the CPTs of clones
in an example island.
5.5

PARENT-TO-CHILD
COMPENSATION

We now complete the derivation of EDML by showing
how it specifies the CPTs of clones in example islands,
which are needed for computing soft evidence as in the
previous section.
In a nutshell, EDML assumes an initial value of these
CPTs, typically chosen randomly. Given these CPTs,
example islands will be fully specified and EDML will
compute soft evidence as given by Equation 3. The

h
H1

S1

H2

E1

s|h

S2

s|h

H3

E2

e|h

S3

E3

e|h

Figure 5: A pruning of the meta network in Figure 2
given H 1 = h̄, H 2 = h and H 3 = h̄.

computed soft evidence is then injected on the generators of parameter islands, leading to a full specification
of these islands. EDML will then estimate parameters
by solving an exact optimization problem on each parameter island as shown in Section 4. The estimated
parameters are then used as the new values of CPTs
for clones in example islands. This process repeats
until convergence.
We have shown in the previous section that the CPTs
of clones are in one-to-one correspondence with the parameters of the base network. We have also shown that
soft evidence, as given by Equation 3, can be computed
by evaluating Equation 1 of Algorithm 2 (with parameters θ corresponding to the CPTs of clones in an
example island). EDML takes advantage of this correspondence, leading to the simplified statement spelled
out in Algorithm 2.

6

SOME PROPERTIES OF EDML

Being an approximate inference method, one can
sometimes identify good behaviors of EDML by identifying situations under which the underlying inference
algorithm will produce high quality approximations.
We provide a result in this section that illustrates this
point in the extreme, where EDML is guaranteed to return optimal estimates and in only one iteration. Our
result relies on the following observation about parameter estimation via inference on a meta network.
When the parents U of a variable X are observed to
u in an example di , all edges θx|u? −→X i in the meta
network become superfluous and can be pruned, except for the one edge that satisfies u? = u. Moreover,

edges outgoing from observed nodes can also be pruned
from a meta network. Suppose now that the parents of
each variable are observed in a dataset. After pruning
edges as indicated earlier, each parameter variable θx|u
will end up being the root of an isolated naive Bayes
structure that has some variables X i as its children
(those whose parents are instantiated to u in example
di ). Figure 5 depicts the result of such pruning in the
meta network of Figure 2, given a dataset with H 1 = h̄,
H 2 = h and H 3 = h̄.
The above observation implies that when the parents
of each variable are observed in a dataset, parameters
can be estimated independently. This leads to the following well known result.
Proposition 1 When the dataset is complete, the ML
estimate for parameter θx|u is unique and given by
D#(xu)/D#(u), where D#(xu) is the number of examples containing xu and D#(u) is the number of examples containing u.
It is well known that EM returns such estimates and
in only one iteration (i.e., independently of its seed).
The following more general result is also implied by
our earlier observation.
Proposition 2 When only leaf variables have missing values in a dataset, the ML estimate for each parameter θx|u is unique and given by D#(xu)/D+ #(u).
Here, D+ #(u) is the number of examples containing
u and in which X is observed.
We can now prove the following property of EDML,
which is not satisfied by EM, as we show next.
Theorem 1 When only leaf variables have missing
values in a dataset, EDML returns the unique ML estimates given by Proposition 2 and in only one iteration.
Proof Consider an example di that fixes the values
of parents U for variable X and consider Equation 1.
First, κix|u = 1 iff example di is inconsistent with u
or does not set the value of X. Next, κix|u = 0 iff example di contains x̄u. Finally, κix|u = ∞ iff example
di contains xu. Moreover, these values are independent of the EDML seed so the algorithm converges in
one iteration. Given these values of the Bayes factors,
Equation 2 leads to the estimate of Proposition 2. 
We have a number of observations about this result.
First, since Proposition 1 is implied by Proposition 2,
EDML returns the unique ML estimates in only one
iteration when the dataset is complete (just like EM).
Next, when only the values of leaf variables are missing
in a dataset, Proposition 2 says that there is a unique
ML estimate for each network parameter. Moreover,

Theorem 1 says that EDML returns these unique estimates and in only one iteration. Finally, Theorem 1
does not hold for EM. In particular, one can show that
under the conditions of this theorem, an EM iteration
will update its current parameter estimates θ and return the following estimates for θx|u :
−

D#(xu) + D #(u)Pr (x|u)
.
D#(u)
Here, D− #(u) is the number of examples that contain
u and in which the value of X is missing. This next
estimate clearly depends on the current parameter estimates. As a result, the behavior of EM will depend
on its initial seed, unlike EDML.
When only the values of leaf variables are missing,
there is a unique optimal solution as shown by Proposition 2. Since EM is known to converge to a local optimum, it will eventually return the optimal estimates
as well, but possibly after some number of iterations.
In this case, the difference between EM and EDML is
simply in the speed of convergence.
Theorem 1 clearly suggests better convergence behavior of EDML over EM in some situations. We next
present initial experiments supporting this suggestion.

7

MORE ON CONVERGENCE

We highlight now a few empirical properties of EDML.
In particular, we show how EDML can sometimes find
higher quality estimates than EM, in fewer iterations
and also in less time.
We highlight different types of relative convergence behavior in Figure 6, which depicts example runs on a
selection of networks: spect, win95pts, emdec6g, and
tcc4e. Network spect is a naive Bayes network induced from a dataset in the UCI ML repository, with
1 class variable and 22 attributes. Network win95pts
(76 variables) is an expert system for printer troubleshooting in Windows 95. Networks emdec6g (168
variables) and tcc4e (98 variables) are noisy-or networks for diagnosis (courtesy of HRL Laboratories).
We simulated datasets of size 2k , using the original
CPT parameters of the respective networks, and then
used EDML and EM to learn new parameters for a
network with the same structure. We assumed that
certain variables were hidden (latent); in Figure 6, we
randomly chose 14 of the variables to be hidden. Hidden nodes are of particular interest to EM, because it
has been observed that local extrema and convergence
rates can be problematic for EM here; see, for example
(Elidan & Friedman, 2005; Salakhutdinov, Roweis, &
Ghahramani, 2003).

0EDML
1
2
3
4
5
6 1EM
10
1e2
0.0EDML

spect

102

iteration

103

spect
EDML

0
1
2
3
4
5
62
4
10 10

win95pts

0.0

EM 3
10
1e2

0.2

0.2

0.4

0.4

0.6

0.6

0.8 EM
101
1e2
0.0EDML
0.2
0.4
0.6
0.8
1.0
1.2
1.4 EM
1.6 1
10
1e2
0.0EDML
0.5
1.0
1.5
2.0
2.5
3.0
3.5 EM
4.0 1
10

102

iteration

103

104

0.8
103

104

1e2
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
1.6 3
10

104

tcc4e

102

iteration

103

emdec6g

102

iteration

103

EDML

EM

time

104

105

win95pts

104

105

106

105

106

emdec6g
1e2
EDML
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
EM
4.0 3
104
105
10

106

EDML

time

tcc4e

EM
104

time

time

Figure 6: Quality of parameter estimates over iterations (left column) and time (right column). Going
right on the x-axis, we have increasing iterations and
time. Going up on the y-axis, we have increasing quality of parameter estimates. EDML is depicted with a
solid red line, and EM with a dashed black line.
In Figure 6, each plot represents a simulated data set
of size 210 , where EDML and EM have been initialized with the same random parameter seeds. Both
algorithms were run for a fixed number of iterations,
1024 in this case, and we observed the quality of the
parameter estimates found, with respect to the log posterior probability (which has been normalized so that
the maximum log probability observed is 0.0). We assumed a Beta prior with exponents 2. EDML damped
its parameter updates by a factor of 21 , which is typical
for (loopy) belief propagation algorithms.3
3
The simple bisection method suffices for the optimization sub-problem in EDML for binary Bayesian networks.
In our current implementation, we used the conjugate gradient method, with a convergence threshold of 10−8 .

In the left column of Figure 6, we evaluated the quality of estimates over iterations of EDML and EM. In
these examples, EDML (represented by a solid red
line) tended to have better quality estimates from iteration to iteration (curves that are higher are better), and further managed to find them in fewer iterations (curves to the left are faster).4 This is most
dramatic in network spect, where EDML appears to
have converged almost immediately, whereas EM spent
a significant number of iterations to reach estimates of
comparable quality. As most nodes hidden in network
spect were leaf nodes, this may be expected due to
the considerations from the previous section.
In the right column of Figure 6, we evaluated the
quality of estimates, now in terms of time. We remark again that procedurally, EDML and EM are very
similar, and each algorithm needs only one evaluation
of the jointree algorithm per distinct example in the
data set (per iteration). EDML solves an optimization problem per distinct example, whereas EM has a
closed-form update equation in the corresponding step
(Line 4 in Algorithms 1 and 2). Although this optimization problem is a simple one, EDML does require
more time per iteration than EM. The right column
of Figure 6 suggests that EDML can still find better
estimates faster, especially in the cases where EDML
has converged in significantly fewer iterations. In network emdec6g, we find that although EDML appeared
to converge in fewer iterations, EM was able to find
better estimates in less time. We anticipate in larger
networks with higher treewidth, the time spent in the
simple optimization sub-problem will be dominated by
the time to perform jointree propagation.
We also performed experiments on networks learned
from binary haplotype data (Elidan & Gould, 2008),
which are networks with bounded treewidth. Here, we
simulated data sets of size 210 , where we again randomly selected 41 of the variables to be hidden. We
further ran EDML and EM for a fixed number of iterations (512, here). For each of the 74 networks available, we ran EDML and EM with 3 random seeds, for
a total of 222 cases. In Figure 7, we highlight a selection of the runs we performed, to illustrate examples of
relative convergence behaviors. Again, in the first row,
we see a case where EDML identifies better estimates
in fewer iterations and less time. In the next two rows,
we highlight two cases where EDML appears to converge to a superior fixed point than the one that EM
appears to converge to. In the last row, we highlight
an instance where EM instead converges to a superior
estimate. In Figure 8, we compare the estimates of
4

We omit the results of the first 10 iterations as initial
parameter estimates are relatively poor, which make the
plots difficult to read.

1e2
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4 1
10

greedy.15.1
EDML
EM

1e3
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4 1
10

bounded.u.20.5
EDML

1e3
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4 1
10

bounded.u.25.5
EDML

1e2

greedy.1.1
EM
EDML

0

1

102

iteration

greedy.15.1

103

1e2
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4 4
10

bounded.u.20.5

103

1e3
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4 4
10

bounded.u.25.5

103

1e3
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4 4
10
1e2

greedy.1.1
EM
EDML

EM

102

iteration

EM

102

iteration

0

1

2

2

3

3

4
101

102

iteration

4
103 103

EDML
EM

105

106

time

EDML
EM

105

106

time

EDML
EM

105

time

104

time

105

106

106

Figure 7: Quality of parameter estimates over iterations (left column) and time (right column). Going
right on the x-axis, we have increasing iterations and
time. Going up the y-axis, we have increasing quality of parameter estimates. EDML is depicted with a
solid red line, and EM with a dashed black line.
EDML and EM at each iteration, computing the percentage of the 74 × 3 = 222 cases considered, where
EDML had estimates no worse than those found by
EM. In this set of experiments, the estimates identified by EDML are clearly superior (or at least, no
worse in most cases), when compared to EM.
We remark however, that when both algorithms are
given enough iterations to converge, we have observed
that the quality of the estimates found by both algorithms are often comparable. This is evident in Figure 6, for example. The analysis from the previous
section indicates however that there are (very specialized) situations where EDML would be clearly preferred over EM. One subject of future study is the identification of situations and applications where EDML

100 % of 222 cases, EDML favored
80
60
40
20
0
101

iteration

102

Figure 8: Quality of EDML estimates over 74 networks (3 cases each) induced from binary haplotype
data. Going right on the x-axis, we have increasing
iterations. Going up the y-axis, we have an increasing
percentage of instances where EDML’s estimates were
no worse than those given by EM.

izes to multivalued variables since edge deletion does
not require a restriction to binary variables and the
key result of Section 4 also generalizes to multivalued
variables. The resulting formulation is less transparent
though when compared to the binary case since Bayes
factors no longer apply directly and one must appeal to
a more complex method for quantifying soft evidence;
see (Chan & Darwiche, 2005). We expect our future
work to focus on a more comprehensive empirical evaluation of EDML, in the context of an implementation
that uses multivalued variables. Moreover, we seek to
identify additional properties of EDML that go beyond
convergence.


We consider the problem of deleting edges
from a Bayesian network for the purpose of
simplifying models in probabilistic inference.
In particular, we propose a new method for
deleting network edges, which is based on the
evidence at hand. We provide some interesting bounds on the KL-divergence between
original and approximate networks, which
highlight the impact of given evidence on the
quality of approximation and shed some light
on good and bad candidates for edge deletion. We finally demonstrate empirically the
promise of the proposed edge deletion technique as a basis for approximate inference.

1

INTRODUCTION

Classical algorithms for exact probabilistic inference
have a complexity which is parameterized by the network topology [Jensen et al., 1990; Lauritzen and
Spiegelhalter, 1988; Zhang and Poole, 1996; Dechter,
1996; Darwiche, 2001]. In particular, it is well known
that exact inference can be performed exponential only
in the treewidth of a given network, where treewidth
is a graph theoretic parameter that measures network
connectivity. When the treewidth is high, one may
then consider simplifying the network by deleting some
edges to reduce its treewidth and then run exact inference on the simplified network. This approach would
then lead to a class of approximate inference algorithms, which result from applying exact inference to
an approximate network.
Clearly, the quality of approximate inference in this
case would depend on the quality of approximate networks one constructs as a result of edge deletion. In
previous work on edge deletion, most results focused
on the quality of approximation between the prior distributions induced by the original and approximate

networks, typically by considering the KL–divergence
between the two [Cover and Thomas, 1991]. However,
it is known that the KL–divergence may be small between two distributions, yet blow up when conditioning on a particular evidence [Koller, 1996]. Therefore, bounding the KL–divergence would not necessarily provide guarantees on conditional queries.
In this paper, we propose an edge deletion method
which is sensitive to the available evidence. The
method was motivated by the following observations.
First, by deleting an edge Y → X from a network,
we are in essence changing the conditional probability
table (CPT) of variable X, since X will have one less
parent in the new network. Moreover, it is known that
if the current evidence e fixes the value of variable Y ,
then the edge Y → X can be deleted and the CPT for
X can be modified, while yielding a simpler network
which corresponds exactly to the original network for
any query of the form α, e. The question now is: what
if the current evidence does not fix the value of Y , but
the probability of Y is extreme given evidence e? Can
we in this case delete Y → X and still expect to get a
good approximate network? In particular, would the
approximate results converge to the exact ones as the
posterior of Y given e converges to an extreme distribution? We will indeed provide a bound and analysis
that give some interesting insights on this matter.
We also empirically evaluate the edge deletion methods
as a basis for approximate inference, by running exact
inference on the approximated network. This method
of approximate inference is interesting as it provides
a tradeoff between efficiency and quality of approximation, through control over the deleted edges. It is
therefore in the same spirit as generalized belief propagation [Yedidia et al., 2000], except that it is independent of the specific method used for exact inference.
As we shall see, the formulation based on edge deletion
appears to provide new grounds for analysis.
This paper is structured as follows. In Section 2, we
define the semantics of edge deletion. In Section 3,

we introduce some interesting bounds on the KL–
divergence between the original and approximate networks, for both deleting a single edge, and deleting
multiple edges. In Section 4 we address one of the
key subtleties relating to our edge deletion method,
and in Section 5 we present empirical results on an
approximate inference method based on edge deletion.
Section 6 discusses previous work in edge deletion, and
Section 7 closes with some concluding remarks. Proofs
of Theorems are included in the Appendix.

2

DELETING EDGES

Deleting an edge Y → X from a network entails more
than simply removing an edge from the graph; one
must also have a way of updating the CPT of variable
X, which has one less parent after deletion. Other notions of edge deletion studied in the past, which we will
review in Section 6, motivated their deletion by asserting, in a particular sense, a conditional independence
between Y and X. However, as these methods did not
specifically take evidence into account, an approximation may look good before conditioning on evidence,
but could potentially be a bad one afterwards.
Consider a variable Y in a network N and some evidence e that fixed the value of Y . We can then delete
each outgoing edge of Y , and assume the fixed value of
Y in the CPT of each of its children X. This method
will give a network with exact results for queries of the
form α, e. But what if the value of a variable is almost
determined by evidence e? Then perhaps we can try
to weight the CPT for X by the posterior probability
distribution of the parent Y .
Assume that we have a network N in which node X
has parents Y and U, where U may be empty. We
want to approximate this network by another, say N 0 ,
which results from removing the edge Y → X. This
approximation will be done given a piece of evidence e,
by replacing the CPT ΘX|Y U of variable X in network
N by the CPT Θ0X|U as defined below.
Definition 1 (Edge Deletion) Let N be a Bayesian
network with node X having parents Y and U. The
network N 0 which results from deleting edge Y → X
from N given evidence e is defined as follows:
• N 0 has the same structure as N except that edge
Y → X is removed.
• The CPT for variable X in N 0 is given by:
X
def
0
θx|yu Pr (y|e).
θx|u
=
y

• The CPTs for variables other than X in N 0 are
the same as those in N .

Note that this approximation assumes that we have
the posteriors Pr (Y |e) in the original network N . This
probability is typically not available, as the network
N must already be difficult, for us to be interested
in deleting some of its edges. We will indeed address
this point in Section 4, but for now we will pretend
that we have this posterior probability. Note also that
the probabilities Pr 0 (Y |e) in the approximate network
may not equal the original probabilities Pr (Y |e) when
the edge Y → X is cut as given above.
Intuitively, this edge deletion method is equivalent to
creating an auxiliary root node Y 0 whose CPT ΘY 0
is Pr (Y |e) and then replacing the original parent Y
with the new node Y 0 . This can be shown by eliminating variable Y 0 from the new network, which leads
to replacing the CPT of X by the one proposed in
Definition 1.

3

QUALITY OF APPROXIMATION

We consider in this section the quality of networks
generated by the proposed edge deletion method.
In particular, we provide bounds on the KL–divergence between the conditional distributions Pr (.|e)
and Pr 0 (.|e) induced by the original and approximate
networks N and N 0 , where KL is defined as follows
[Cover and Thomas, 1991]:
KL(Pr , Pr 0 )

X

def

=

Pr (w) log

w

3.1

Pr (w)
.
Pr 0 (w)

DELETING A SINGLE EDGE

Our intuition suggests that deleting an edge out of a
variable whose value is almost determined given the
evidence may yield a reasonable approximation. The
following bound lends some support to that intuition:
Theorem 1 Let N and N 0 be two Bayesian networks
as given in Definition 1. We then have:
KL(Pr (.|e), Pr 0 (.|e)) ≤ log

Pr 0 (e)
+ ENT (Y |e),
Pr (e)

where ENT (Y |e) is the entropy of Y given e, and is
defined as follows:
ENT (Y |e)

def

=

−

X

Pr (y|e) log Pr (y|e).

y

Note that the ENT (Y |e) = 0 if and only if Pr (y|e) = 1
for some y; that is, the entropy of Y given e is zero if
and only if the value of Y is determined. Now consider
the following condition in which our bound becomes an
equality:

Theorem 2 Let N and N 0 be two Bayesian networks
as given in Definition 1. If the CPT for variable X is
deterministic:
θx|yu ∈ {0, 1}
(1)
and
θx|yu = θx|y0 u = 1 only if y = y 0

(2)

then
KL(Pr (.|e), Pr 0 (.|e)) = log

Pr 0 (e)
+ ENT (Y |e).
Pr (e)

Note that Condition 2 is satisfied when the CPT for
X has no context–specific independence. Moreover,
both conditions are satisfied if X is a parity function
of its parents, as one typically finds, for example, in
networks for error-correcting codes [Frey and MacKay,
1997].
The more certain we are of the value of Y given e, the
more extreme Pr (Y |e) is, and the lower ENT (Y |e) is.
This suggests that if the value of Y is almost determined, then the ENT (Y |e) term in the bound on the
KL–divergence is negligible, and we may get a good
approximation. Moreover, the log Pr 0 (e)/Pr (e) term
may be negative, and the entropy term need not be
small for us to get a good approximation. However, as
we demonstrate in Appendix B, there are particular
situations where ENT (Y |e) can be arbitrarily close to
zero, but where log Pr 0 (e)/Pr (e) can be unbounded.
3.2

DELETING MULTIPLE EDGES

We can extend the bound given in Theorem 1 about a
single edge deletion, to a bound on multiple deletions,
where the entropy term is additive:
Theorem 3 Let N 0 be a network obtained from network N by deleting multiple edges Y → X as given by
Definition 1, deleting at most one incoming edge per
node X. Then
X
Pr 0 (e)
ENT (Y |e).
+
KL(Pr (.|e), Pr 0 (.|e)) ≤ log
Pr (e)
Y →X

Moreover, if the CPTs for each X satisfy Conditions 1
and 2, then
X
Pr 0 (e)
+
KL(Pr (.|e), Pr 0 (.|e)) = log
ENT (Y |e).
Pr (e)
Y →X

4

FIXED POINTS

Deleting edges Y → X by Definition 1 assumes that
we know the distribution on Y given e. If we are interested in approximating our network N , then computing Pr (Y |e) is itself likely to be difficult computationally. In the approximated network, however, computing the posteriors of Y is likely to be easy. We will

therefore use the approximate network to approximate
Pr (Y |e) using an iterative method as discussed below.
b is the network that we obtain by deletSuppose that N
c t=0 (Y |e) is
ing edges. We first assume that each Pr
uniform, and then cut edges Y → X by setting the
b as follows:
CPT for variable X in N
X
0
c t=0 (y|e).
θx|u
=
θx|yu Pr
y

We then apply exact inference to the approximate netc t (Y |e) are the posteriors of Y at iteration
work. If Pr
t in the approximate network, then the CPT for X is
updated as follows:
X
0
c t (y|e).
θx|yu Pr
θx|u
=
y

We repeat this process until we find that for all edges
c t (Y |e) = Pr
c t+1 (Y |e), or that
that we delete, all Pr
they are within some threshold  from one iteration to
the next. At this point, we say that we have converged,
c (Y |e) are a fixed point for N
b.
and that Pr

We will compare in the following section the quality of
our approximations when computed based on the true
posteriors Pr (Y |e) and the one obtained by the above
iterative method, showing that the fixed point method
tends to work quite well on the given benchmarks.

5

EMPIRICAL ANALYSIS

We discuss here experimental results on edge deletion.
In particular, we compare iterative belief propagation
[Pearl, 1988; Murphy et al., 1999] as an approximate
inference algorithm, with exact inference on a network
with deleted edges. Moreover, we compare the deletion of edges Y → X based on the true probabilites
c (Y |e).
Pr (Y |e) and the fixed point probabilites Pr

We use the jointree algorithm to perform exact inference on the network with deleted edges. Moreover, we
make the following choices in our experiments.
Cost of computation: We use the largest cluster size
in the jointree to measure the difficulty of exact inference. For belief propagation, we assume that difficulty
depends on the number of loops to observe convergence, where the complexity of each loop depends on
the number and sizes of the network CPT’s, and in
particular, the size of the largest CPT.
Deleted edges: For each network we consider, we cut
different sets of edges to control the size of the largest
cluster in the corresponding jointree. We do this by
fixing a variable order that induces a jointree.1 We
1

We use min-fill/min-size heuristics, or by using orders
found otherwise. For example, orders are available for networks in Aalborg DSS’s repository.

Evidence: For each of a given number of trials (typically 50 to 200 trials), we set evidence on all leaves by
sampling based on the prior probabilities of each individual variable, to approximately simulate evidence
that we may likely observe.
Convergence: For each piece of evidence, we approximate inference by belief propagation and by edge deletion for a given set of thresholds on the largest cluster size. When appropriate, we decide on convergence
when the marginal of every variable of an iteration is
within 10−8 of the previous iteration, trying at most
100 iterations. If we do not observe convergence within
this many iterations, we evaluate the instance based on
the state of the network in its last iteration.

son, the iterative version of edge deletion always converged within 100 iterations for all trials, and took
16 iterations on average for this network. When
we use a threshold on the maximum cluster size of
log2 40, 320 = 15.30 or smaller, the largest tables computed during belief propagation and edge deletion are
of comparable sizes, but edge deletion still needs only
21 iterations on average to converge.
barley : average KL(Pr(X|e),Pr’(X|e’))
0.2

average KL(Pr(X|e),Pr’(X|e’))

then delete edges to find an approximated network
which has a jointree whose largest cluster is smaller
than given thresholds, using the same variable ordering. We decide on edges to delete based on a heuristic based on reducing bucket sizes to satisfy a given
threshold in a bucket elimination procedure [Dechter,
1996].

edge deletion
iterative deletion
belief prop.
0.15

0.1

0.05

0
10

12

14

16
18
max cluster size

20

22

barley : average number of iterations
100

Figure 2: Quality of approximation in barley network

average number of iterations

iterative deletion
belief prop.
80

60

40

20

0
10

12

14

16
18
max cluster size

20

22

Figure 1: Loops until convergence in barley network
First consider the barley network, which has a jointree with a normalized maximum cluster size of about
22.79, which is the log2 of the number of entries in the
largest table of a cluster. The barley network also has
a large CPT containing 40, 320 entries. Although the
largest cluster in the jointree still has 180 times more
entries then the largest CPT in the network, if belief
propagation takes many iterations to converge, we get
an approximation of posterior marginals, but with less
attractive benefits in time savings.
Consider Figure 1, which compares the average number of loops required until convergence. In 70 trials,
belief propagation converges in less than half the instances when given 100 iterations to converge, taking 86 iterations on average overall. In compari-

We judge the quality of approximation with two measures. One measure is in terms of the average number
of flips observed in a trial. We say that a flip occurs
when the most likely state of an individual variable
with respect to the original posterior distribution is
no longer the most likely state in the approximated
one. The other measure is in terms of the average KL–
divergence between the true and approximated conditional probabilities of non-evidence variables. Note
that in our figures, curves are not always smooth, since
different thresholds yield different sets of edges deleted,
and smaller sets of edges deleted do not necessarily
yield more accurate approximations.
Consider first Figure 2, which compares the quality of
the approximation given by edge deletion and belief
propagation in the barley network, based on the KL–
divergence. We see in this case, both methods of edge
deletion compare favorably to belief propagation for
all given thresholds on the cluster size. At a threshold
of 22, we find that the largest cluster size of the approximation is 20.47, and so the number of entries in
that cluster table is 20% the size of that in the original
network. With a threshold of 20, the largest table is
3.54% the size; with a threshold of 10, it is 7.72·10−3 %
the size.
Figures 3 and 4 compare the quality of approximations
in the munin1 and munin3 networks. We observe that
the quality of approximation tends to degrade with a
stricter threshold on the largest cluster size. Note that

munin3 : average number of flips

munin3 : average KL(Pr(X|e),Pr’(X|e’))

25

0.12

average KL(Pr(X|e),Pr’(X|e’))

average number of flips

edge deletion
iterative deletion
belief prop.
20

15

10

5
10

11

12

13
14
max cluster size

15

16

0.1

0.08

0.06

0.04

0.02
10

17

edge deletion
iterative deletion
belief prop.

11

12

13
14
max cluster size

15

16

17

Figure 3: Quality of approximation in munin3 network.
munin1 : average number of flips

munin1 : average KL(Pr(X|e),Pr’(X|e’))

20

0.25

average KL(Pr(X|e),Pr’(X|e’))

average number of flips

edge deletion
iterative deletion
belief prop.
15

10

5

0
10

15

20

25

max cluster size

edge deletion
iterative deletion
belief prop.

0.2

0.15

0.1

0.05

0
10

15

20

25

max cluster size

Figure 4: Quality of approximation in munin1 network.
we are deciding on which edges to delete without regard to the particular instantiation of evidence, and we
see that our approximation schemes compare favorably
to belief propagation to a point, with varying degrees
of computational savings. In munin3, both methods of
edge deletion compare favorably against belief propagation, in both measures, up until a threshold of 11.
The largest normalized cluster size in the original network is 17.26 compared to 10.97 in the approximated
network at that threshold. Thus, the largest table in
the jointree for the approximated network is 1.28% of
that of the original network.
In most of our experiments, we tend to observe that
the iterative version of edge deletion is very close to
the version that uses the true probabilities Pr (Y |e) for
larger thresholds, and typically fewer edges deleted,
and become less comparable for smaller and smaller
thresholds. In munin3, they perform similarly over
most of the given thresholds. In munin1, we see that
both versions of edge deletion are comparable up to a

point, where the iterative method tends to fare worse
for smaller thresholds.
Figure 5 provides a summary of the comparisons between our methods of approximation. In these tables,
we measure how belief propagation performs in terms
of the average percentage of flips observed, and by
average KL(Pr (X|e), Pr 0 (X|e)) over all non-evidence
variables. We then find the threshold on the maximum
cluster size in which edge deletion using true probabilities Pr (Y |e) compares favorably to belief propagation, and report the savings in cluster size with respect to the cluster size of the original network. We
also report the quality of approximation for the iterative version of edge deletion that uses fixed point
c (Y |e), for the same threshold. We find
probabilities Pr
that both versions of edge deletion compare well with
belief propagation, and can do so with substantial degrees of computational savings in terms of reduction of
the largest cluster size. Further, we see that when deletion with true probabilities Pr (Y |e) does well, deletion

network
munin1
munin2
munin3
munin4
barley
pigs

cluster
% size
7.31%
16.65%
1.28%
37.55%
3.52%
11.08%

average % flips
BP
ED
ID
5.19%
4.90%
5.32%
0.56%
0.39%
0.35%
2.14%
1.72%
1.98%
1.47%
0.87%
0.82%
24.28% 17.21% 19.89%
1.86%
1.11%
1.00%

network
munin1
munin2
munin3
munin4
barley
pigs

cluster
% size
1.17%
16.65%
1.28%
37.55%
0.01%
11.08%

BP
0.0888
0.0134
0.0926
0.0416
0.1879
0.0042

average KL
ED
ID
0.0652 0.0556
0.0116 0.0112
0.0682 0.0702
0.0261 0.0247
0.1197 0.1693
0.0020 0.0020

Figure 5: Savings in maximum cluster size (% size) at the point where edge deletion (ED) outperforms belief
propagation (BP), in terms of flips and average KL–divergence. KL for iterative version of edge deletion (ID)
also shown. In barley, ED compares favorably in terms of the KL to BP for all thresholds down to our limit of
10.
with fixed point probabilties also tends to do well.

6

putations. Further, approximations may not be good
after conditioning on unlikely evidence.

PREVIOUS WORK
7

Prior work in approximating Bayesian networks by
edge deletion focused primarily on the effects of deletion on the prior distribution. In [Kjærulff, 1994],
edges are deleted, not in the model itself, but on the
moralized independence graph induced by the network, and its simplifications are specific to jointree
based algorithms. Weak dependencies are sought between pairs of variables within particular cliques of the
jointree, and a conditional independence is asserted
based on the variables that appear in the clique. The
author showed that the KL–divergence between the
original distribution and the one where a conditional
independence is asserted is equal to the conditional
mutual information [Cover and Thomas, 1991] of the
variables involved. He further showed that the KL–
divergence is additive, and that for each conditional independence asserted, the divergence is computable locally. It is possible to recover a model from the approximated jointree, but the structure may not be unique,
and the parameterization for it may not be easily determined. The divergence is for prior distributions,
and a form for the posterior distribution was cited as
future work. More recently, [Paskin, 2003] effectively
employed this simplification in a Gaussian graphical
model for simultaneous localization and mapping for
mobile robotics.
In [van Engelen, 1997], edges are deleted in the model,
as we did here. For a node X with parents Y U, we
can cut edge Y → X by replacing each θx|yu with
0
θx|u
= Pr (x|u); essentially, we are asserting that X
and Y are conditionally independent given U. The
KL–divergence between the prior distributions is again
the conditional mutual information, and is additive if
we delete at most a single incoming edge per node.
However, to make this approximation, one must be
able to compute the quantities Pr (x|u). Although
these are local quantities, they may require global com-

CONCLUSION

We proposed a method for deleting edges from a
Bayesian network, which is sensitive to the evidence
at hand. We provided some bounds on the KL–
divergence between the original and approximated network, given evidence. The bounds shed light on when
this method is expected to provide good approximations. We also evaluated empirically an approximate
inference algorithm which is based on deleting edges
against belief propagation, and showed that the edge
deletion method holds good promise. The method
we used to decide on which edges to delete is a bit
primitive, as it is based on a fixed variable order and
does not exploit the given evidence for making its
choices. We are currently working on a more sophisticated scheme for this purpose, which may significantly
improve the quality of approximations obtained by the
proposed method of edge deletion.
Acknowledgments
This work has been partially supported by Air Force
grant FA9550-05-1-0075 and MURI grant N00014-001-0617.

