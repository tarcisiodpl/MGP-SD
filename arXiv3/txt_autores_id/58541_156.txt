
The Factored Frontier (FF) algorithm is a
simple approximate inference algorithm for
Dynamic Bayesian Networks (DBNs). It is
very similar to the fully factorized version
of the Boyen-Koller (BK) algorithm, but in­
stead of doing an exact update at every
step followed by marginalisation (projection),
it always works with factored distributions.
Hence it can be applied to models for which
the exact update step is intractable. We show
that FF is equivalent to (one iteration of)
loopy belief propagation (LBP) on the origi­
nal DBN, and that BK is equivalent (to one
iteration of) LBP on a DBN where we clus­
ter some of the nodes. We then show em­
pirically that by iterating more than once,
LBP can improve on the accuracy of both
FF and BK. We compare these algorithms on
two real-world DBNs: the first is a model of
a water treatment plant, and the second is a
coupled HMM, used to model freeway traffic.
1

Introduction

Dynamic Bayesian Networks (DBNs) are directed
graphical models of stochastic processes. They gener­
alise hidden Markov models (HMMs) by representing
the hidden (and observed) state in terms of state vari­
ables, which can have complex interdependencies. The
graphical structure provides an easy way to specify
these conditional independencies, and hence to pro­
vide a compact parameterization of the modeL See
Figure 1 for some examples.
In this paper, we will be concerned with the task of
offline probabilistic inference in DBNs, i.e., computing
P(Xfly1,r) fort= 1, . . . , T and i 1, . . . ,N, where
Xi is the i'th hidden node at timet, and Yt is evidence
vector at time t; this is often called "smoothing". We
=

will assume that all the hidden nodes are discrete and
each has Q possible values. The observed nodes can
be discrete or continuous.
The simplest way to perform exact inference in a
DBN is to convert the model to an HMM and ap­
ply the forwards-backwards algorithm [18]. This takes
O(TQ2N) time. By exploiting the conditional inde­
pendencies within a slice, it is possible to reduce this
to fl(TNQN+F) time, where F is the maximum fan-in
of any node. Unfortunately, this is still exponential in
N. In fact, this is nearly always the case (assuming
the graph is connected), because even if there is no
direct connection between two nodes in the same or
neighboring "time slices," they will become correlated
over time by virtue of sharing common influences in
the past. Hence, unlike the case for static networks,
we need to use approximations even for "sparse" mod­
els.
In Section 3.1, we present a new approximation, called
the "factored frontier" (FF) algorithm, which repre­
sents the belief state as a product of marginals. The
FF algorithm is thus very similar to the fully fac­
torized version of the Boyen-Koller (BK) algorithm,
which we summarise in Section 3.2. FF, however, is a
more aggressive approximation, and can therefore be
applied when even BK is intractable: FF will always
take O(TNQF+l) time, whereas BK can take more,
depending on the graph.
In Section 4, we show how both FF and BK are related
to loopy belief propagation (LBP) [15, 21, 20, 6, 7, 13],
which is the method of applying Pearl's message pass­
ing algorithm [16] to a Bayes net even if it contains
(undirected) cycles or loops. In Section 5, we exper­
imentally compare all four algorithms - exact, FF,
BK , and LBP - on a number of problems, and in
Section 7, we conclude.

UAI 2001

MURPHY &

WEISS

2.2

379

The frontier algorithm

If Xt is a vector of N hidden nodes, each with Q pos­
sible values, then X can be in S QN possible states,
so the FB algorithm becomes intractable. The fron­
tier algorithm [23] is a way of computing a1 from O:'t-l
(and similarly for the {31's) without needing to form
the QN x QN transition matrix, yet alone multiply by
it.
=

a
Figure 1: Some
chains and T

b
DBNs. (a) A coupled HMM with

N

=

5

3 timeslices. Clear nodes are hidden,
shaded nodes are observed. In the freeway traffic appli­
cation in Section 5, Xl represents the hidden traffic sta­
tus (free-flowing or congested) at location i on the free­
way at time t; this is assumed to generate a local noisy
measurement of traffic speed, Yt', and to depend on its
previous state and the previous state of its upstream and
downstream neighbors. (b) A DBN designed to monitor
a waste water treatement plant. This model is originally
from [9], and was modified by [2] to include (discrete) evi­
dence nodes.
=

2

Exact inference

We start by reviewing the forwards-backwards (FB)
algorithm [18] for HMMs, and then the frontier algo­
rithm [23] for DBNs, since this will form the basis of
our generalisation.

The basic idea is to "sweep" a Markov blanket across
the DBN, first forwards and then backwards. We shall
call the nodes in the Markov blanket the "frontier set",
and denote it by :F; the nodes to the left and right of
the frontier will be denoted by £ and 'R. At every
step of the algorithm, :F d-separates [, and 'R. We
will maintain a joint distribution over the nodes in :F.
We can advance the frontier from slice t - 1 to t as
follows. We move a node from R to :F as soon as all
its parents are in :F. To keep the frontier as small
as possible, we move a node from :F to £ as soon
as all its children are in :F. Adding a node entails
multiplying its conditional probability table (CPT)
P (Xf iPa(Xf )) onto the frontier, and removing a node
entails marginalising it out of the frontier.
This is best explained by example (see Figure 2). Con­
sider the coupled HMM (CHMM) shown in Figure 1.
The frontier initially contains all the nodes in slice t-1:
Ft,o �r O:'t-1 = P(Xl.:..'YIY1:t-1)· We then advance the
frontier by moving Xl from R to :F. To do this, we
multiply in its CPT P(XllXl_1, Xf-1):

Ft,l

=

P(Xf, Xf:_lfiYu-d = P(XfiXf-1, Xf_1) x Ft,o

Next we add in
2.1

Ft,2 = P(Xf'2, X[!'fiYl:t-d
P(X[txf_,,x[_1,Xf_1)

The forwards backwards algorithm

The basic idea of the FB algorithm is to compute
d f
def P(X
t = t.1 Y1:t) .m the £orwards pass, ,Bit =e
ati =
P(Yt+l:rlXt = i) in the backwards pass, and then
to combine them to produce the final answer: 'Yt def
=
P(Xt i\Yl:T) ex a�f3�- Let M(i,j) � P(Xt+l =
j[Xt = i) be the transition matrix, and Wt(i,i) �f
P(yt[Xt = i) be a diagonal matrix containing the con­
ditional likelihood of the evidence at time t. The
algorithm is just repated matrix-vector multiplica­
tion. Specifically, in the forwards pass we compute
at ex WtMT O:'t- , and in the backwards pass we com­
1
pute f3t ex MWt+1.8t+l; the constants of proportional­
ity are simply the normalizing constants. The bound­
ary conditions are a1 = W17l" and f3r = 1, where
7l"; d�,f P(X1 = i) is the prior. If X can be inS possible
states, the FB algorithm clearly takes O(S2T) time.
·

=

Xf:
x

Ft,l

Now all of the nodes that depend on Xl_1 are in the
frontier, so we can marginalize Xl_1 out (move it from
:F to £):
F.t,3=

'2 X2'
P(x1t'
L...., Ft,2
t-1NIY l:t-1 ) - """

The process continues in this way until we compute

Finally, we weight this factor by the likelihood:

O:t = P(Xf'NIYl:t) oc P(yt\Xf'N)

x

Ft,N

It is clear that in this example, exact inference takes
O(TNQN+2) time and space, since the frontier never

380

MURPHY &

WEISS

UA/ 2001

0 0
00

0 0

0 0

0 0

0 0

0 0

00

0 0

add Xl(t)

0 0

0 0
add X2(t)

0 0

0 0

0 0

removeXl(t-1)

0 0

remove

add XJ(I)

X2(t-1)

0 0

Figure 2: The frontier algorithm applied to a CHMM; observed leaves are omitted for clarity. Nodes inside the
box are in the frontier. The node being operated on is shown shaded; only connections with its parents and
children are shown; other arcs are omitted for clarity. See text for details
.

contains more than N + 2 nodes, and it takes O(N)
steps to sweep the frontier from t 1 to t. In general,
the running time of the frontier algorithm is exponen­
tial in the size of the largest frontier; this quantity
is also known as the induced width of the underlying
or moral graph. We would therefore like to keep the
frontiers as small as possible. Unfortunately, comput­
ing an order in which to add and remove nodes so as
to minimize the sum of the frontier sizes is equivalent
to finding an optimal elimination ordering, which is
known to be NP-hard. Nevertheless, heuristics meth­
ods, such as greedy search [10], often perform as well
as exhaustive search using branch and bound [23].
-

A special case of the frontier algorithm, applied to fac­
torial HMMs, was published in Appendix B of [8]. (In
an FHMM, there are no cross links between the hidden
nodes, so there are no constraints on the order in which
nodes are added to or removed from the frontier.) For
regular1 DBNs, the frontier algorithm is equivalent to
the junction tree algorithm [3, 11, 19] applied to the
"unrolled" DEN. In particular, the frontier sets cor­
respond to the maximal cliques in the moralized, tri­
angulated graph; in the junction tree, these cliques
are connected together in a chain, possibly with some
smaller cliques "hanging off the backbone" to accomo­
date the non-persistent observed leaves. Despite this
equivalence to junction tree, the frontier algorithm is
1 A regular DBN has certain restrictions on its topol­
ogy. Let Ht denote all the hidden nodes in time-slice t,
and 01 all the observed nodes. A regular DBN can have
connections from H1 to 01 and to Ht+!, but to nowhere
else. In particular, there cannot be any intra-slice connec­
tions within the H1 nodes. Furthermore, we assume each
node in Ht connects to one or more nodes in Ht+l (i.e., is
persistent). All the DENs in this paper are regular.
The frontier algorithm works for non-regular DBNs, but
it may be less efficient that junction tree in this case. The
factored frontier and loopy belief propagation algorithms
also work for non-regular DENs.

appealingly simple, and will form the basis of the ap­
proximation algorithm discussed in the next section.
3
3.1

Approximate inference
The factored frontier algorithm

The problem with the frontier and junction tree algo­
rithms is that they need exponential space just to rep­
resent the belief states, and hence need at least that
much time to compute them. The idea of the fac­
tored frontier (FF) algorithm is to approximate the
belief state with a product of marginals: P(Xt IYu) �
f1�1 P(XfiYt:t). (The backward messages f3t are ap­
proximated in a similar way.)
The algorithm proceeds as follows: when we add a
node to the frontier, we multiply its CPT by the prod­
uct of the factors corresponding to its parents; this
creates a joint distribution for this family. We then
immediately marginalize out the parent nodes. The
backwards pass is analogous. This is like the frontier
algorithm except that we always maintain the joint dis­
tribution over the frontier nodes in factored form. This
algorithm clearly takes O(TNQF+l) time, no matter
what the topology.
3.2

The Boyen-Koller algorithm

The Boyen-Koller algorithm [2] represents the belief
state, O:t = P(Xt!Yt:t), as a product of marginals over
C "clusters", P(Xt IYI:t) � TI�=l P( XfiYl:t), whe re Xf
is a subset of the variables {Xi}. (The clusters do not
need to be disjoint.) Given a factored prior, O:t-1, we
do one step of exact Bayesian updating to compute
the posterior, Ot. In general, Ot will not be factored
as above, so we need to project to the space of factored
distributions by computing the marginal on each clus-

MURPHY &

UAI 2001

WEISS

381

0·-,

.
.

:

.
.
.

-�oi�
\..�·o�-<l�·
:a:
.

'

.

.

.
.
'-•

(a)

Figure 3: Illustration of the clustering process. (a) This is a modified version of a CHMM with 4 chains. The big
"mega no?es" con� ain the joint distribution on the whole slice. We have omitted the observed leaves for clarity.
LBP apphed to th1s graph is equivalent to BK. (b) This is like (a), except we have created overlapping clusters
of size 2, for additional accuracy.
ter. The product of these marginals then gives the ap­
proximate posterior, Ext. We can use a similar method
for computing the backward messages in an efficient
manner [1]. Boyen and Koller prove, roughly speak­
ing, that if the error introduced by the projection step
isn't much greater than the error incurred by using
an approximate prior, both errors relative to the true
(uncomputable) distribution, then the overall error is
bounded.

the previous slice (but not on its neighbors within a
slice) - the largest clique has size n, and hence the
running time of BK is O(T NQYN), even in the fully
factorized case.

The accuracy of the BK algorithm depends on the size
of the clusters that we use to approximate the belief
state. Exact inference corresponds to using a single
cluster, containing all the hidden variables in a time­
slice. The most aggressive approximation corresponds
to using N clusters, one per variable; we call this the
"fully factorized" approximation.

Pearl's belief propagation algorithm [16] is a way of
computing exact marginal posterior probabilities in
graphs with no undirected cycles (loops). Essentially it
generalises the forwards-backwards algorithm to trees.
W hen applied to a graph with loops, the algorithm
is sometimes called "loopy belief propagation" (LBP);
in this case, the resulting "posteriors" may not be cor­
rect, and can even oscillate. Nevertheless, the out­
standing empirical success of turbo decoding, which
has be shown to be equivalent to LBP [ 13], has cre­
ated great interest in the algorithm.

It is clear that the fully factorized version of BK is
very similar to the FF algorithm, but there is one im­
portant difference: BK assumes that we update the
factored prior exactly (using, say, junction tree) be­
fore computing the marginals, whereas FF computes
the (approximate) marginals directly. BK is obviously
more accurate than FF, but sometimes it cannot be
used, because even one step of exact updating is too
expensive.

-;

The cost of using BK is determined by the size of the
maximal cliques of the moralized, triangulated ver­
sion of the two-slice DBN. (Unrolling the DBN for
many slices induces long-distance correlations, and re­
sults in cliques that span the whole time-slice, as we
saw above.) For the coupled HMM (CHMM) model
in Figure 1, the cliques just correspond to the fami­
lies (nodes and their parents), so the algorithm takes
O(T NQF+l) time, the same as FF. But for the wa­
ter model (see Figure 1), we also get extra "non-local"
cliques due to triangulation. For more complex mod­
els, such as the 2D generalisation of a CHMM- where
each time slice is now an N = n x n lattice, and each
cell depends on all the nodes in its "receptive field" in

4

BK and FF as special cases of loopy
belief propagation

LBP has been empirically shown to work well on sev­
eral kinds of Bayesian networks which are quite differ­
ent from turbo codes [15, 7]. In addition, a number of
theoretical results have now been proved for networks
in which all nodes are Gaussian [21], for networks in
which there is only a single loop [20], and for general
networks but using the max-product (Viterbi) version
instead of the sum-product (forwards-backwards) ver­
sion of the algorithm [6].
The key assumption in LBP is that the messages com­
ing into a node are independent. But this is exactly the
same assumption that we make in the FF algorithm!
Indeed, we can show that both algorithms are equiv­
alent if we use a specific order in which to send mes­
sages. Normally we implement LBP using a decentral­
ized message passing protocol, in which, at each step,
every node computes its own ..\ and 7!' in parallel (based
on the incoming message at the previous step), and
then sends out ..\ and 7l' messages to all its neighbors.
However, we can also imagine a forwards-backwards

MURPHY & WEISS

382

(FB) protocol, in which each node first sends 1r (a)
messages from left to right, and then sends >. (,B) mes­
sages from right to left. A single pass of this FB pro­
tocol is equivalent to FF.2
The fixed points of LBP are the same, no matter what
protocol is used. If there is not a unique fixed point,
the algorithms may end up at different answers. They
can also have different behavior in the short term. In
particular, if the D BN is in fact an HMM, then a single
FB iteration (2TN message computations) will result
in the exact posteriors, whereas it requires T iterations
of the decentralized protocol (each iteration comput­
ing 2TN messages in parallel) to reach the same result;
hence the centralized algorithm is more efficient [17].
For loopy graphs, it is not clear which protocol is bet­
ter; it depends on whether local or global information
is more important for computing the posteriors. In
this paper, we use the centralized (FB) protocol.
It is also easy to see that the fully-factorized version
of BK is equivalent to a single FB pass of LBP applied
to a modified DBN, as shown in Figure 3. Fo r each
slice, we create two "mega nodes" that contains all
the (hidden) nodes in that slice. The messages corn­
ing into the first mega node are assumed independent;
they are then multiplied together to form the (approx­
imate) prior3; a single message is then sent to the sec­
ond mega node, corresponding to an exact update step
using the QN x QN transition matrix; finally, the indi­
vidual marginals are computed, and the process is re­
peated. Of course, BK does not actually construct the
mega nodes, and does the exact update using junction
tree, but the two algorithms are functionally equiva­
lent. To simulate BK when the clusters contain more
than one node, we simply create new clustered nodes,
in addition to the mega-nodes, and run LBP on the
new graph, as illustrated in Figure 3.
Since FF and BK are equivalent to one iteration of
LBP, on the regular and clustered graphs respectively,
we can improve on both of these algorithms by iter­
ating more than once. This gives the algorithm the
opportunity to "recover" from its incorrect indepen­
dence assumptions. We will see in the Section 5 that
even a small number of iterations can help dramati­
cally.
2

In the case of noisy-or nodes, there are efficient ways to
1r messages without having to do work

compute the>. and

which is exponential in the number of parents [16]. This
reduces the overall complexity of FF from

O(TNFQ).
3For

a

O(TNQF+l)

directe d graph, naive Pearl would take

to

O(QN)

time to compute 1r for the mega-node, but we can do this in
tim e by exploiting the fact that the CPT factorizes.

O(QN)

,

Alternatively, we can use an undirected graph in which
the computation of messages always takes time linear in

the number

of neighbors.

4.1

A free

UAI2001

energy for iterated

BK

BK and a single iteration of
on the clustered graph allows us to utilize the re­
cent result of Yedidia et al [22] to obtain a free energy
for "iterated" BK. We define the "iterated" BK algo­
rithm as running LBP on the clustered graph using a
FB schedule until convergence. The first iteration of
iterated BK is equivalent to BK but in subsequent it­
erations, the a and (3 messages interact to improve the
quality of approximation. The analysis of [22] shows
that iterated BK can only converge to zero gradient
points of the Bethe free energy.
The equivalence between
LBP

This sheds light over the relationship between iterated
BK and the mean field (MF) approximation. The MF
free energy is the same as the iterated BK free en­
ergy when joint distributions over pairs of nodes are
replaced by a product of marginal beliefs over individ­
ual nodes: iterated BK captures dependencies between
nodes in subsequent slices while MF does not. While
this result only holds for iterated BK, ordinary BK can
be thought of as a first approximation to iterated BK.
5

Experimental results

In this section, we compare the BK algorithm with
k iterations of LBP on the original graph, using the
FB protocol (k = 1 iteration corresponds to FF).
We used a CHMM model with 10 chains trained on
some real freeway traffic data using exact EM [12].
.
Q
N Ls=l
We define the Lt error as Dot
Li=t
JP(X; =
sJYt:T)- F(Xf = s!Yt:r)J, where P(·) is the exact pos­
terior and F(-) is the approximate posterior. In Fig­
ure 4, we plot this against t for 1-4 iterations of LBP.
Clearly, the posteriors are oscillating, and this hap­
pens on many sequences with this model. We there­
fore used the damping trick described in [15]. In this
case, each new message is defined to be a convex com­
bination of the usual expression and the old messsage,
with weight J.L given to the old message. Hence J.L = 0
corresponds to undamped propagation, and J.L = 1 cor­
responds to not updating the messages at all, i.e., only
using local evidence. It is easy to show that any fixed
points reached using this algorithm are fixed points of
the original set of (undamped) equations. It is clear
from Figure 5 that damping helps considerably. The
results are summarised in F igure 6, where we see that
after a small number of iterations, LBP with J.L = 0.1
is doing better than BK. Other sequences give similar
behavior.
=

To check that these results are not specific to this
model/ data set, we also compared the algorithms on
the water DBN shown in Figure 1. We generated ob­
servation sequences of length 100 from this model us-

MURPHY & WEISS

UAI2001

6

x10-4

g4
Q)

:i

00

.I

l

200

Jl

1 iter

400

x10....

6

m

383

I

00

600

6

2

.._

6

x10....

i
200

H

400

�.

2 iter

600

g4
Q)

:i

00

600

3 iter

2

600

4 iter

Figure 4: £1 error on marginal posteriors vs. timeslice after iterations 1-4 of undamped
traffic

CHMM.

LBP

applied to the

The £1 error oscillates with a period of 2 (as seen by the similarity between the graphs for

iterations 1/3 and 2/4); this implies that the underlying marginals are oscillating with the same period.

6

6

6

x10"""

1 iter

6

Q)

:i

2

00
Figure
traffic

5: iterations
CHMM.

1

-4

2 iter

g4

g4

---i

X

Q)

:i

I

I

200

1, 2, and 18 of

18 iter

LBP

400

d

l

600

2

00

200

BK

400

600

with damping factor f.l = 0.1, and after using 1 iteration of BK, on the

384

MURPHY & WEISS

0.08

- - 0.1

I I
-- !

0.07

�

10
12x

-- . 0.6
,

0.06

0.05

10

�0.04

9

...

e
Q; 8
:::i

0.03

7

0.02

'·.

0.01

6

00

5
6:

iterations

error incurred by LBP using damping factor J.L = 0;

0.8.

=

0.1 and the high­

1.5

1

Results of applying LBP to the traffic

the lowest curve corresponds to J.L

·-

4

CHMM with 10 chains. The lower solid horizontal line

=

._\

5

is the error incurred by BK. The oscillating line is the

est to f..L

-3

11

'

::;

Figure

UAI2001

2

2.5

3

iterations

Figure 7: Same as Figure

6,

4

3.5

4.5

5

but for the water network.

The do tted lines, from top to bottom , represent f..l = 0,
f..L = 0.1 and f..L = 0.2. The solid line represents BK.

The upper horizontal line corresponds

to not updating the messages at all

(J.L =

1), and gives

an indication of performance based on local evidence
alone.
0.5

,.------,
o

·

...,._

0.45

jtree

number of iterations and damping factor.

we see that there is no oscillation, and that as few as

-�

ing random parameters and binary nodes, and then
compared the marginal posteriors as a function of

The results
for a typical sequence are shown in Figure 7. This time
two iterations of LBP can outperform BK.

how the algorithms compare in terms of speed.

We

therefore generated random data from CHMMs with
=

1, 3, . ..

, 11 chains, and computed the posteri­

ors using the different methods.
are shown in Figure

8.

The running times

It is clear that both BK and

FF /LBP have a running time which is linear in

: ..

·

!!.

-�

- .

0.3

Cij

a; 0.25

�<I)

0.

In addition to accuracy, it is also interesting to see

N

+·

0

bk

loopy 1
� 0.4 -+ loopy 2
!:
-+- loo
py 3
0
�0.35 + loopy4
·

0.2

�0.15

�

/

0.

,·

..

,·

.�·
. '

.·

.

. ..

_.+
--+

0.1

+

0.05

N (for

the CHMM model), but the constant factors of BK

11

are much higher, due to the complexity of the algo­
rithm, and in particular, the need to perform repeated
marginalisations. This is also why BK is slower than
exact inference for N < 11, even though it is asymp­
totically more efficient.4

Figure

8:

Running time on CHMMs as a function of

the number of chains.

The vertical axis is the total

running time divided by the length of the sequence.
The horizontal axis is the number of chains. The dot­
ted curve is junction tree, the steep straight line is
BK, and the shallow straight lines are LBP; "loopy k"

4 All algorithms were implemented in Matlab and are in­
cluded in the Bayes Net Toolbox, which can be downloaded
from YY'Il. cs. berkeley. edu/ ""murphyk/Bayes/bnt. html.

means k iterations of LBP.

UAI 2001

6

MURPHY &

Related work

WEISS

[8]

F. V. Jensen, U. Kjaerulff, K. G. Olesen, and J. Ped­
ersen. An expert system for control of waste water
treatment - a pilot project. Technical report, Univ.
Aalborg, Judex Datasystemer, 1989. In Danish.

[9]

U. Kjaerulff. Triangulation of graphs - algorithms
giving small total state space. Technical Report R90-09, Dept. of Math. and Comp. Sci., Aalborg Univ.,
Denmark, 1990.

[10]

U. Kjaerulff. A computational scheme for reasoning
in dynamic probabilistic networks. In UAI�B, 1992.

[11]

J. Kwon and K. Murphy.

We have already discussed in detail the connections
between LBP, BK and FF. However, there are several
other approximate inference algorithms with a very
similar "flavor".

Perhaps the closest is the expecta­

tion propagation algorithm [ 14] . This is also an itera­

tive message passing algorithm, but now the messages
encode moments of the variables computed with re­
spect to some approximating distribution. The mini­

bucket algorithm [4] also approximates joint distribu­

tions over collections of nodes as a product of smaller

hence cannot correct for erroneous independence as­

nia, Berkeley,

[ 1 2]

2000.

R. J. McEliece, D. J. C. MacKay, and J. F. Cheng.
Turbo decoding as an instance of Pearl's 'belief prop­
agation' algorithm.

7

Comm.,

Conclusions

[13]

tions.

J. Pearl.
mann,

[16]

U AI

reviewers for their

[17]

N00014-00-l-0637 and NSF IIS-9988642.

[18]

[2]

X. Boyen and D. Koller. Tractable inference for com­
plex stochastic processes. In U AI, 1998.

[3]

R. G. Cowell, A. P. Dawid, S. L. Lauritzen, and D. J.
Spiegelhalter. Probabilistic Networks and Expert Sys­

[5]

[6]
[7]

1999.

R. Dechter. Mini-buckets: a general scheme of ap­
proximating approximations in automated reasoning.
IJCAI,

Artifi�

77(2):257-286, 1989.

P. Smyth, D. Beckerman, and M. I. Jordan. Prob­
abilistic independence networks for hidden Markov
Neural Computation,

9(2):227-

269, 1997.

X. Boyen and D. Koller. Approximate learning of dy­
namic models. In NIPS-11, 1998.

In

Fusion and propagation

L. R. Rabiner. A tutorial on Hidden Markov Models
and selected applications in speech recognition. Proc.

probability models.



Latent topic models have been successfully
applied as an unsupervised topic discovery technique in large document collections.
With the proliferation of hypertext document
collection such as the Internet, there has
also been great interest in extending these
approaches to hypertext [6, 9]. These approaches typically model links in an analogous fashion to how they model words - the
document-link co-occurrence matrix is modeled in the same way that the document-word
co-occurrence matrix is modeled in standard
topic models.
In this paper we present a probabilistic generative model for hypertext document collections that explicitly models the generation of
links. Specifically, links from a word w to
a document d depend directly on how frequent the topic of w is in d, in addition to
the in-degree of d. We show how to perform
EM learning on this model efficiently. By not
modeling links as analogous to words, we end
up using far fewer free parameters and obtain
better link prediction results.

1

Introduction

The need to automatically infer the different topics
discussed in a corpus arises in many applications ranging from search engines to summarization software. A
prominent approach is modeling the corpus with a latent topic model where each document is viewed as
a mixture of latent topics or factors, and the factors,
shared by the whole corpus, are related to the terms
or words appearing in the documents.
Many of the topic models share the “bag of words”
assumption where each document is represented as a

Yair Weiss
School of CS and Eng.
The Hebrew University
Jerusalem 91904 Israel
yweiss@cs.huji.ac.il

histogram of terms, ignoring the order of terms and the
internal structure of the documents. The entire corpus is represented as a document-term co-occurrence
matrix. Semantic analysis is done by projecting the
document-term co-occurrence matrix onto a lower dimensional factor space. In algebraic methods such as
Latent Semantic Analysis [7] it is projected onto a linear factor space using SVD. In statistical methods such
as Probabilistic LSA [13], Latent Dirichlet Allocation
[3] or the somewhat more general formalism, Discrete
PCA [4] the document-term co-occurrence matrix is
projected onto a simplex by maximizing the observations likelihood. In recent years these latent topic
models have been extended in various ways. In particular, correlation between topics [2] and their dynamics
over time [1] have been directly modeled. The use of
additional information provided in the corpus such as
authorship information has been studied [18]. In addition, novel models that depart from the bag of words
assumption and do consider the internal ordering of
the words in sentences within a document have been
developed. These models combine local dependencies
in various ways; for example, combining n-grams with
a hierarchical topic model [19], modeling syntax [10]
and modeling the continuous drift from one topic to
another within a document [12]
In this paper, we address the question of how to enrich
the model by considering links between documents,
such as hyperlinks in hypertext or citations in scientific papers. With the emergence and rapid growth of
the World Wide Web, hypertext documents containing
links to other documents have become ubiquitous. The
connectivity between documents has proven to play an
important role in determining the importance and relevance of a document for information retrieval or the
interest of a certain user in it [17, 5, 14]. In particular,
Dietz at al. [8] have recently proposed a generative
topic model for the prediction of citation influences,
called the citation influence model. It models the particular structure of paper citations where the citations
graph can be described by a directed acyclic graph

(DAG); a setting that does not hold in the case of the
World Wide Web and other hypertext corpora.
There are few previous works that extend topic models to include link information. Cohn and Hofmann [6]
introduce a joint probabilistic model for content and
connectivity. The model is based on the assumption
that similar decomposition of the document term cooccurrence matrix can be applied to the cite-document
co-occurrence matrix in which each entry is a count of
appearances of a linked-document (or citation) in a
source document. In this approach, links are viewed
as additional observations and are analogous to additional words in the vocabulary, but with different
weight when estimating the topic mixture of the document. Erosheva et al. [9] also makes use of a decomposition of term-document and citation-document cooccurrence matrices by extending the LDA model to
include a generative step for citations. Note that these
models only learn from the co-occurrence matrix of citations without exploiting the information conveyed
by the cited documents text. Thus, if the citationdocument co-occurrences matrix is very sparse, the
generalization power of the models is very limited.
In this paper, we suggest a novel generative model
for hypertext document collection that we name the
latent topic hypertext model (LTHM). Our approach
includes direct modeling of real-world complex hypertext collections in which links from every document to
every document may exist, including a self-reference
(a document linking to itself). We model a link as an
entity originating from a specific word (or collection
of words) and pointing to a certain document. The
probability to generate a link from a source document
d to a target document d′ depends on the topic of the
word from which the link is originating, on the importance of the target document d′ (estimated roughly by
the in-degree) and on the topic mixture of the target
document d′ . In this way, an observed link directly
affects the topic mixture estimation in the target document as well as the source document. Moreover, the
non-existence of a link between two documents is an
observation that serves as evidence for the difference
between the topic mixtures of the documents.
We introduce the LTHM and related models in Section
2 and describe the approximate inference algorithm in
Section 3. Experimental results obtained by learning
two datasets are provided in Section 4. Finally, we
discuss the results in Section 5.

bitrary accordingly. By no means can we assume it
forms a DAG. Therefore, we would like to allow each
document to link to any other document, allowing for
loops, i.e. directed cycles of links originating in a certain document and ending in the same document. In
particular, we would like to allow for self loops with
links where a document links to itself. The solution
is a generative model that consists of two stages. In
the first stage, the document content (the words) is
created. After the text of all the documents has been
created, the second stage of creating links takes place.
The contribution of this paper is in modeling link generation and suggesting an approximate inference algorithm for studying it. The text in the documents can
be generated using several of the various models mentioned in section 1. For simplicity, we describe text
generation (and inference, accordingly) using LDA [3].
In the following section, we first briefly review the LDA
model (2.1). Second, we describe the second stage of
link generation (2.2). Finally, we discuss related models (in section 2.3).
2.1

Document generation (LDA)

According to the LDA model, a collection of documents is generated from a set of K latent factors or
topics. One of the main assumptions in the model is
that for each topic there is a single multinomial random variable β that defines the probability for a word
given a topic for all documents in the collection. Each
document is characterized by a particular mixture of
topic distribution defined by the random variable θ.
The generation of the Nd words of each document d
in a corpus contains two stages: first, a hidden topic z
is selected from a multinomial distribution defined by
θ. Second, given the topic z, a word w is drawn from
the multinomial distribution with parameters βz . Figure 2.1a illustrates the generative model.
Formally, the model can be described as:

1. For each topic z = 1, ..., K choose W dimensional
βz ∼ Dirichlet(η)
2.

For each document d = 1, ..., D
Choose K dimensional θ ∼ Dirichlet(α)
For each word wi , indexed by i = 1, ..Nd
Choose a topic ziW ∼ Multinomial(θd )

2

The latent topic hypertext model

The topology of the World Wide Web is complicated
and unknown. The corpus we work with is a subset
of the World Wide Web and its topology can be ar-

Choose a word wi ∼ Multinomial(βziW )

(a)

(b)

(c)

(d)

Figure 1: a. The LDA model. b The link-LDA model. c. The LTHM model in a scenario of generating links
from document d′ to document d. d. The LTHM model in a scenario of generating links from document d′ to
any other document in the collection of D documents.
2.2

Link generation

We assume that links originate from a word, and each
word can have at most one link associated with it1 .
For simplicity, we restrict the discussion to the case
where a link is anchored to a single word. The generalization to the case where the link is anchored to
a sequence of words can be carried out by forcing the
topics of these words to be identical, as proposed in
[12]. The generation of links is carried out by iterating over all the words in the document and for each
word determining whether to create a link and if so,
what is the target document.
Let us limit the discussion first to the case where the
corpus contains two documents, d and d′ , and links are
generated from words in document d′ to document d.
When iterating over the words in d′ , at the ith word,
we need to decide whether to create a link from wi to
d or not. This decision contains two steps (at most,
as sometimes the first step is sufficient to determine
that no link needs to be created). The first step is
drawing at random a variable τi from a multinomial
λ. In general, τi can take values from 0 to D, and
in this degenerated example it can take two values: 0
indicates no link and d indicates a link to document
d. Only if τi = d do we consider adding a link to
document d and then proceed to the next step, which
is randomly drawing the topic of the link, z L . The
topic assignment z L is drawn from θd , the mixture of
topics of the document d. A link is created iff ziW = z L ,
Figure 2.1c illustrates the full generative model for this
degenerated example.
The generalization to the (still degenerate) case of
generating links from a single document d′ to any
other document in a collection of D documents is illustrated in Figure 2.1d. In this case, the generation
of links from words in document d′ starts by select1
If a link is anchored to an image, for example, we could
substitute a fictitious word for that link.

ing τi ∈ {1 . . . D, ∅} for every word i = 1..Nd′ of the
document d′ . τ is drawn at random from λ ∈ RD+1 ,
a multinomial distribution indicating the probability
of considering a link to each one of the D documents
or not having a link at all. It is a measure of the importance (or in-degree) of the documents in the corpus. λ itself is drawn from the hyperparameter γ. The
Dirichlet prior γ ∈ RD+1 is not symmetric and favors
not creating links, as most words do not have an associated link: γi ≪ γ∅ for i = 1 . . . D. Also, note
that links from a document to itself are allowed in this
model (as well as in real life).
The most general case, in which every document can
contain words linked to any other document, is generated by sequentially going through all words and all
documents and drawing at random the corresponding
τ s and z L s in the way described above.
Formally, the generative process is:

1.

Choose D + 1 dimensional λ ∼ Dirichlet(γ)

2.

For each document d = 1, ..., D
For each word wi , indexed by i = 1, ..Nd
Choose τi ∈ {1 . . . D, ∅} ∼ Multinomial(λ)
If τi 6= ∅ choose a topic zL ∼ Multinomial(θτi )
If z L = ziW create a link Li = τi from
word i to document τi

2.3

Related Models

Both models of [6] and [9] – that we refer to as
link-PLSA and link-LDA, respectively, following [16]’s
suggestion – are make of the citation-document cooccurrence matrix in a similar manner. We focus on

the link-LDA model that is somewhat closer to our
model. According to this approach two types of observed variables are modeled: words in documents and
citation in documents. The generation of these variables is carried out by first selecting a mixture of topics for each of the documents and then for each of
the words and citations on the document generating a
hidden topic from which the observation is selected at
random from the βz in the case of words and from Ωz
in the case of citations; Here z = 1, ..., K. The model
is illustrated in Figure 2.1b.
Formally, the model can be described as:

For each document d = 1, ..., D
Choose K dimensional θ ∼ Dirichlet(α)
For each word wi , indexed by i = 1, ..Nd
Choose a topic zi ∼ Multinomial(θd )
Choose a word wi ∼ Multinomial(βzi )
For each citation d′i , indexed by i = 1, ..Ld
Choose a topic zi ∼ Multinomial(θd )
Choose a citation d′i ∼ Multinomial(Ωzi )

Note that in the LTHM, the probability to create a
link given topic is Pr(link = d|z) = λd θd (z W ). There
are only D additional parameters λ1 . . . λD to denote
the document importance for link creation, whereas in
the link-LDA model there are DK additional parameters, Ωd,z = Pr(d′ = d|z). Also, in LTHM, the very
existence or non-existence of a link is an observation,
while this is not explicitly modeled by the link-LDA.
Moreover, according to the LTHM, a link shares the
same topic with the word it originates from and at
the same time affects the topic mixture in the cited
document.

3

Approximate Inference

Exact inference in hierarchical models such as LDA
and PLSA is intractable due to the coupling of the latent topics and the mixing vectors β, θ. The hypertext
model presented in this paper shares this coupling and
adds a unique coupling between topic mixing vectors;
hence, exact inference is intractable in it as well. In
recent years, several alternatives for approximate inference in such models have been suggested: EM [13] or
variational EM [3], Expectation propagation (EP) [15]
and Monte-Carlo sampling [18, 11]. Unlike other hypertext topic models, in LTHM not only the identities

of the ends of a link are observations, but also the link’s
very existence (or non-existence). Taking into account
the non-existence of links in sampling-based inference
necessitates further approximations. We therefore perform inference using EM.
EM deviates from fully Bayesian methods by distinguishing between latent variables and parameters of
the model. The latent variables are the latent topic
of a word, z W , the latent topic involved in link generation, z L , and the variable τ . The parameters of the
model are the topic mixing vectors θd , the word mixing
vectors βz and the document link importance parameter λd . The Dirichlet hyperparameters α, η and γ are
fixed.
In the link generation process, unless a link is created, the value of τ is unknown. It might have not
been created because τ = ∅ or because of topic mismatch between the source document and any other
document. For this reason, we need to consider all
possible options with their probability during inference: for each source document d and each word in
it from which there is no outgoing link, we need to
consider all D possible z L variables. P
The number of
the potential latent variables z L is D d N d which is
quadratic in the number of documents. It is therefore
infeasible to compute explicitly the posterior distribution of each one of these latent variables. However, in
the M-step, only aggregations of these posterior distributions are needed. The required aggregations can
be computed efficiently (in time linear in the size of
the corpus) by taking advantage of symmetries in the
model as described in section 3.2 and in the appendix.
We begin with the M-step equations, detailing what
are the required expectations. Then we describe how
the required posteriors and aggregations are computed
in the E-step.
3.1

M-step

In the M-step, MAP estimators for the parameters of
the model, θd , βz and λ are found. Let Gz,w denote the
number of occurrences of a word w with topic z W = z.
The update rule for βz,w is identical to that in standard
LDA:
βz,w

∝ E(Gz,w ) + ηw − 1

(1)

The MAP estimator for θd takes into account topics of
words and links that were drawn from θd . The word
topics, z W , are drawn from θd for each of the words
in document d. The link topics are the topics zdL′ ,i,d
drawn from θd when considering a link from any other
document d′ to d. These are the cases where τd′ ,i = d
for any d′ , i regardless of whether the link has been
created or not. For the purpose of inference, we count

the topics zdL′ ,i,d separately for links and for non-links.
Let Fd,z denote the number of occurrences of a topic
z associated with any word in document d. Let Vd,z
be the number of occurrences of a topic z associated
with any incoming link of document d. Let Ud,z be
the number of times τd′ ,i = d but the topic generated
for the link by document d, zdL′ ,i,d , does not match the
topic of the ith word in the the document d′ , zdW′ ,i and
therefore a link has not been created.
θd,z

∝ E(Fd,z ) + E(Vd,z ) + E(Ud,z ) + αz − 1(2)

Note that in the standard LDA model, we would have
just the first term (the expected number of times topic
z appears in document d) and the Dirichlet prior. In
the LTHM, we add two more terms which model the
influence of links (or non-links) on the topic distribution.
The computation of E(Vd,z ) and E(Ud,z ) is described
in section 3.2.
The MAP estimator for λ is
λd
λ∅

∝ E(Td ) + γd − 1
X
X
∝
Nd −
E(Td ) + γ∅ − 1
d

(3)
(4)

d

Where Td is the number of times that τd′ ,i = d for any
d′ and any word i in it (this includes the case of d′ = d
where
a self link is considered). Notice that Td =
P
(V
d,z +Ud,z ). The normalization factor in equations
z
3 and 4 includes the term λ∅ , the most frequent case
that there is no link at all.
3.2

a link) as observations.
W
W
Pr(zd,i
= z|w̄, L̄) ∝ θd (z) Pr(Ld,i |zd,i
= z)φz (wd,i )
(7)
W
where Pr(Ld,i |zd,i
= z), the probability of a link observation is

W
Pr(link(d, i) → d′ |zd,i
= z; P ) = λd′ θd′ (z) ∝ θd′ (z)

if a there is a link from word i in document d to document d′ , and
X
W
Pr(no − link(d, i)|zd,i
= z; P ) = 1 −
λd′ θd′ (z)
d′

if there is no link associated with word i in document
d.
Naı̈ve computation of E(Vd,z ) and (E(Ud,z ) would require estimating the posterior distributions of τd′ ,i and
zdL′ ,i,d for all triplets (d′ , i, d). As mentioned before,
explicit computation of these posteriors is infeasible
due to large number of these variables. Rather than
computing this posterior distribution explicitly over
z L and τ , only the aggregations E(Vd,z ), E(Ud,z ) are
computed.
E(Vd,z ) is the expected number of occurrences of links
incoming to document d with topic z. In the case
where a link exists, the posterior distributions of z L
and the corresponding z W are equal; hence, Vd,z can be
computed by summing posterior probabilities of z W :
X
E(Vd,z ) =
Pr(zdL′ ,i,d = z|O, P ) (8)
(d′ ,i)∈Ad

E-step

In the E-step, expectations required for the M-step are
computed with respect to the posterior distribution
of the latent variables. The expectations required for
the M-step are E(Gd,z ), E(Fz,w ), E(Vd,z ), E(Ud,z ) and
E(Td ).
E(Gd,z ) is the expected number of occurrences of a
topic z in document d as a topic of word and E(Fz,w )
is the expected number of occurrences of a word w
with topic z:
E(Gd,z ) =

Nd
X

W
Pr(zd,i
= z|w̄, L̄)

(5)

i=1

E(Fk,z ) =

Nd
D X
X

W
Pr(zd,i
= z, wd,i = w|w̄, L̄) (6)

d=1 i=1

where w̄ = w1 . . . wNd and L̄ = L1 . . . LNd . The posterior distribution of z W is explicitly computed, taking
into account words and links (or the non-existence of

X

=

Pr(zdW′ ,i = z|O, P )

(d′ ,i)∈Ad

where Ad = {(d′ , i) : link(d′ , i) → d}, O is the set of
all observations and P is the model parameters.
E(Ud,z ) is the expected number of times τd′ ,i = d for
any d′ , i in the corpus, but zdL′ ,i,d 6= zdW′ ,i . The basic
idea in the computation of E(Ud,z ) is that it factors
into topic dependent terms and document-topic dependent terms. The topic dependent terms can be computed in a single linear pass over the corpus (in each
iteration). The document-topic dependent terms are
specific to each Ud,z . Combining them with the topic
dependent terms to compute Ud,z is done in a constant
number of operations (for each d, z). The computation
is detailed in the appendix.
Finally, after E(Vd,z ) and E(Ud,z ) have been computed,
X
E(Td ) =
[E(Vd,z ) + E(Ud,z )]
(9)
z

Despite the quadratic number of latent variables, the
runtime of both E and M steps is linear in the size of
the corpus times the number of topics.
There are a number of extensions to the LDA model
that can be considered here, as the approximate inference algorithm described above can be easily adapted
for many of the alternatives mentioned in section
1. For example, suppose one wishes to model the
text with the HTMM [12], the difference would be
in the computation of the posterior of word topics,
Pr(z W |w1 . . . wNd , L1 . . . LNd ). In HTMM, this posterior would be computed using the forward-backward
algorithm, considering both words and links as the
topic emission probabilities. Alternatively, if one
wishes to make use of authorship information by applying the Author-Topic model [18], it would require to
consider an additional latent variable x for the authorship of each word and compute posterior probabilities
Pr(x, z W |w1 . . . wNd , L1 . . . LNd ) and modify the definition of θd . Yet, the modeling of links stays very
similar; in addition to latent topic of the link, z L , only
a latent author to the link needs to be selected, xL .

4

Experiments

In this section, we explore the relations between links
and topics discovered by LTHM and evaluate its predictive power with respect to links. We compare
LTHM’s link prediction with previous approaches for
combining links: link-PLSA[6] and link-LDA[9]. We
also compare to link prediction by a non-topic method,
based only on the frequency a web page is linked, ignoring the contents of the text in the corpus. For this
comparison, we use two datasets of web pages: the webkb dataset (8282 documents with 12911 links) and a
small dataset of Wikipedia web pages (105 documents
with 799 links).
We begin with an example of the strong relationships
between topics and links in the Wikipedia dataset
learned by LTHM. The Wikipedia dataset is a collection of 105 web pages with 799 links between
the pages in the dataset. We downloaded these
web pages from Wikipedia by crawling within the
Wikipedia domain, starting from the NIPS2 Wikipedia
page. We have made the data set available online
at: http://www.cs.huji.ac.il/∼amitg/lthm.html. We
used a vocabulary of 2247 words and trained LTHM
with 20 hidden aspects. Figure 4 shows four of the
hidden topics found by the model in the Wikipedia
dataset. For each topic we show the ten most probable words and two most probable links. Topic 1
discusses neural networks, and the two most related
links to it (links with high probability to be generated
2

At the time being, there is no UAI Wikipedia page.

from the topic). Similarly, topic 2 is about speech
and pattern recognition. Topic 3 is about cities (Denver and Vancouver, the current and previous venues
of the nips conference). topic 4 is about cognitive science and neuroscience. All these topics have related
links. Due to lack of space, we show only four example topics, but all 20 topics have clear interpretation
and relevant suggested links. A complete list of the
topics with top words and top links can be found at
http://www.cs.huji.ac.il/∼amitg/lthm.html.
We found that the LDA topics on this dataset were
of comparable quality, but the assignment of topics to
documents can be different in LDA and LTHM, especially for short documents. Table 1 shows a comparison of the document topic vector θd for two short
Wikipedia documents, “Journal of Machine Learning”
and “Random Forests”, in LDA and LTHM. All topics with θd > 0.05 are shown. Since LTHM uses the
link information, it assigns more weight to the relevant
topics.
For quantitative evaluation, we compare LTHM vs.
the topic models link-PLSA [6] and link-LDA [9] and a
frequency-based method in the task of link prediction.
The frequency-based method ranks the documents in
the corpus according to the number of time they were
linked to from other documents. This ranking serves
as the link prediction for all the documents. This prediction is the same for all the documents in the corpus
and does not depend on the topics of the source document.
For these experiments we use the Wikipedia dataset
and the webkb dataset. The webkb dataset (available
online at: http://www.cs.cmu.edu/∼webkb) consists
of 8282 html pages. For this dataset, we used a dictionary of 2304 words (built according to their frequency
in the data and removing stop words). We extracted
12911 links where both ends of the links belong to the
webkb corpus. We split each data set into a train set
consisting of 90% of the documents and a test set of
the remaining 10%. During training, the text of all
the documents is provided to all the algorithms, but
only the links originating from the documents in the
train set are visible during training. Both dataset are
learned with 20 hidden aspects. During test, for each
test document d we sort all documents d′ in the corpus according to the probability of having a link from
d (outgoing from any word in d) to d′ .
Figures 3 and 5 show several measures of the performance of the different algorithms. The first measure is
the percentage of documents in the test set for which
at least one link prediction among the top N is a true
link. The motivation for this measure is the following
question: Suppose we want to suggest to an author of

Figure 2: Four example topics learned by LTHM and the links related to them. For each topic, the ten most
probable words are shown along with the two links most probable to be generated from that topic. Next to each
word and each link is its probability to be generated from the given topic.

topic prob
0.1504
0.0798
0.0652
0.0594
0.0533

topic prob
0.1416
0.1194
0.0757
0.0542
0.0527
0.0527

Journal Of Machine Learning Research.html
LDA
LTHM
top words
topic prob
top words
”search”,”article”,”navigation”
0.4136
”learning”,”machine”,”engineering”
”press”,”university”,”new”
0.0943
”card”,”conference”,”credit”
”learning”,”machine”,”algorithms”
”fixes”,”skins”,”import”
”model”,”regression”,”reasoning”
Random Forests.html
LDA
top words
topic prob
”probability”,”distribution”,”variables”
0.2076
”data”,”mining”,”predictive”
0.1921
”learning”,”machine”,”algorithms”
0.1178
fixes”,”skins”,”import”
0.0547
stock”,”market”,”price”
0.0524
search”,”article”,”navigation”

LTHM
top words
”linear”,”function”,”training”
”fuzzy”,”regression”, ”model”
”bayesian”, ”model”, ”network”
”carlo”,”monte”,”genetic”
”learning”,”machine”,”engineering”

Table 1: A comparison of the document topic vector θd for two short Wikipedia documents “Journal of Machine
Learning” and “Random Forests” in LDA and LTHM. All topics with θd > 0.05 are shown. Since LTHM uses
the link information, it assigns more weight to the relevant topics.

a web page other documents to link to. If we show this
author N suggestions for links, will s/he use at least
one of them? The other measures we use are precision
(Among the top N predictions, what is the percentage
of true links?) and recall (What percentage of the true
links are included in the top N predictions?).
Figure 3 shows that LTHM outperforms all three other
methods with respect to all three performance measures. Both link-PLSA and link-LDA do worse than
the frequency-based method. This result may seem
surprising at first, as these methods are more general
than the frequency-based method. In particular, they
could fit the relative frequency of each document as
its probability to be drawn from any topic. In this
case, they would predict the same as the frequencybased method. When we inspect the performance of
these methods on the train set (figure 4), we see linkPLSA and link-LDA fit better than the frequencybased method. This suggests that link-PLSA and linkLDA overfit due to the large number of free parameters
(KD) these models have for modeling links. LTHM,
on the other hand, has only D additional parameters
for modeling links. Moreover, link generation probabilities depend on the topic mixtures of the documents
at both ends of the link. Unlike link-PLSA and linkLDA, no values of the link parameters λ can cancel
this dependency.
Figure 5 shows the performance of the four methods on
the webkb test set. Once again, LTHM outperforms
the other methods. The frequency-based method outperforms link-PLSA and link-LDA.
As mentioned in section 3, thanks to the symmetries in
LTHM, each EM iteration is computed in time linear in
the size of copus times the number of topics. Training
on the webkb dataset with 20 topics took 17 hours for
600 EM iterations. Training on the smaller Wikipedia
dataset with 20 topcis took 30 minutes for 300 EM
iterations.

5

Discussion

In this work we have presented LTHM, a novel topic
model for hypertext documents. In LTHM, the generation of hyperlinks depends on the topics of the
source word and the target document of the link, as
well as the relative importance of the target document.
Compared to previous approaches, LTHM introduces
a much smaller number of additional link parameters.
As a result, LTHM achieves good generalization results in cases where other models overfit and fail to
generalize.

Acknowledgements
Support from the Israeli Science Foundation is gratefully acknowledged.




algorithms have been proposed (see. e.g [13, 18] for
recent reviews).

Finding the most probable assignment
(MAP) in a general graphical model is known
to be NP hard but good approximations have
been attained with max-product belief propagation (BP) and its variants. In particular,
it is known that using BP on a single-cycle
graph or tree reweighted BP on an arbitrary
graph will give the MAP solution if the beliefs have no ties.

Linear Programming (LP) Relaxations are a standard
method for approximating combinatorial optimization
problems in computer science [1]. They have been
used for approximating the MAP problem in a general
graphical model by Santos [15]. More recently, LP relaxations have been used for error-correcting codes [3]
and for protein folding [9]. LP relaxations have an
advantage over other approximate inference schemes
in that they come with an optimality guarantee – if
the solution to the linear program is integer, then it
is guaranteed to give the global optimum of the MAP
problem.

In this paper we extend the setting under
which BP can be used to provably extract
the MAP. We define Convex BP as BP algorithms based on a convex free energy approximation and show that this class includes ordinary BP with single-cycle, tree reweighted
BP and many other BP variants. We show
that when there are no ties, fixed-points of
convex max-product BP will provably give
the MAP solution. We also show that convex
sum-product BP at sufficiently small temperatures can be used to solve linear programs
that arise from relaxing the MAP problem.
Finally, we derive a novel condition that allows us to derive the MAP solution even if
some of the convex BP beliefs have ties. In
experiments, we show that our theorems allow us to find the MAP in many real-world
instances of graphical models where exact inference using junction-tree is impossible.

1

Introduction

The task of finding the maximum aposteriori assignment (or MAP) in a graphical model comes up in
a wide range of applications including image understanding [19], error correcting codes [3] and protein
folding [27]. For an arbitrary graph, this problem is
known to be NP hard [16] and various approximation

The research described here is based on a remarkable recent set of results by Wainwright, Jaakkola
and Willsky [21, 22] who discussed a variant of belief propagation called “tree reweighted belief propagation (TRBP)”. They showed that when the TRBP
output satisfied certain easy-to-check conditions, one
could provably extract the MAP assignment from the
TRBP output. Furthermore, they showed an intriguing connection between TRBP and LP relaxation.
In related work, we have used TRBP on a number of
real world applications [26] and our experience with it
raised a number of questions. First, TRBP is based
on a distribution over spanning trees of the original
graph. We wanted to know whether the properties of
TRBP also hold for other BP variants that are not
based on spanning trees. Second, in some applications
the sufficient conditions given by Wainwright et al. [22]
for extracting the MAP do not hold. We wanted to
know whether one could extend these conditions.
In this paper, we show that the answer to both questions is affirmative. We define a family of algorithms
called convex BP which refer to belief propagation with
a convex free energy approximation. We show that
tree reweighted BP suggested by Wainwright and colleagues [21] is a special case of convex BP but there are

WEISS ET AL.
many convex free energies that cannot be represented
as a tree reweighted free energy. This result has theoretical implications since it shows that the property
of solving the LP is distinct from the property of providing a rigorous bound on the free energy, as well as
practical implications since it provides an expanded
family of possible LP algorithms.
We also discuss the max-product version of convex
BP and show that when convex BP has beliefs without ties, the max-product assignment is guaranteed to
be the MAP assignment. This gives a unified proof
for previous results on ordinary BP with a single cycle [4, 20, 23] and tree reweighted BP [21]. Finally, we
give a new theoretical condition that allows us to provably extract the MAP from convex BP beliefs, even
if they have ties. We illustrate the power of these
theorems on graphical models with hundreds of variables arising from computational biology and errorcorrecting codes.
1.1

MAP and LP relaxation

Given an observation vector y, we wish to perform
inference on Pr(x|y) which is assumed to factorize into
a product of potential functions:
1
1 Y
ψα (xα ) = e−
Pr(x|y) =
Z α
Z

αEα (xα )

where α is the domain of the potential ψα (the set of
all variables that participate in the potential) and we
define the “energy” Eα (xα ) as the negative logarithm
of the potential.
The MAP is the vector x∗ which maximizes the posterior probability:
Y
X
x∗ = arg max
ψα (xα ) = arg min
Eα (xα )
x

x

α

α

To define the LP relaxation, we first reformulate the
MAP problem as one of integer programming. We introduce indicator variables qi (xi ) for each individual
variable and additional indicator variables qα (xα ) for
all the potential domains. Using these indicator variables we define the integer program:
Minimize:

XX
α

qα (xα )Eα (xα )

xα

Subject to:
∀α, xα
∀α

qα (xα ) ∈ {0, 1}
X
qα (xα ) = 1
xα

∀i, xi , α : i ∈ α

X

xα\i

qα (xα ) = qi (xi )

417

where the last equation, enforces the consistency of
indicator variables for different potential domains.
This integer program is completely equivalent to the
original MAP problem, and is hence computationally
intractable. We can obtain the linear programming relaxation by allowing the indicator variables to take on
non-integer values. That is, we replace the constraint
qα (xα ) ∈ {0, 1}. with qα (xα ) ∈ [0, 1]. This problem
can now be solved efficiently, and if the solutions to
the LP happen to be integer, we have provably found
the MAP.
1.2

Belief Propagation and its variants

As shown by Yedidia et al. [28], there exist a large
number of free energy approximations that are based
on a set of “double counting numbers”. These double
counting numbers are used to approximate the entropy
of x, denoted H̃, by means of a linear combination of
entropies over individual variables i, Hi , and variables
that participate in a factor α, Hα :
X
X
H̃ =
cα Hα +
ci Hi
α

i

Given a set of double counting numbers cα , ci we define the approximate free energy functional. This is
a functional that takes as input a set of approximate
marginals bα (xα ), bi (xi ) and uses them to define the
average energy and the approximate entropy. The approximate free energy at temperature T is simply:
F (bα , bi ) = U (bα ) − T H̃(bα , bi )

(1)

where the average energy, U (bα ), and the approximate
entropy, H̃(bα , bi ), are given by:
XX
U (bα ) =
bα (xα )Eα (xα )
α

H̃(bα , bi )

=

xα

X

cα

X

ci

α

+

i

X

bα (xα ) ln bα (xα )

xα

X

bi (xi ) ln bi (xi )

xi

A special case of approximate free energies is when
ci = 1 − di , cα = 1, where di is the number of factors
that node i participates in (or equivalently, the degree
of node i in the factor graph). In this case the approximate free energy is called the Bethe free energy.
Given an approximate free energy, there are many possible algorithms that try to minimize it. For concreteness we give here one possible algorithm, the two-way
GBP algorithm [28], but we should emphasize that
all our results hold for any algorithm that converges
to stationary points of the approximate free energy
(e.g. [21, 24, 25]). Assuming cα = 1 for all factors,

418

WEISS ET AL.

the two-way algorithm is similar to ordinary BP on
a factor graph, but with an additional “reweighting”
step. As in ordinary BP, we denote the messages sent
from factor node α to variable node i by mαi (xi ) and
the message from variable node i to factor node α by
miα (xi ). The messages are updated as follows:
X
Y
m0αi (xi ) =
ψα1/T (xα )
mjα (xj )
xα\i

m0iα (xi )

=

Y

In summary, we have defined the MAP problem, the
LP relaxation and a family of belief propagation algorithms. The natural questions that arise are:
• When can BP algorithms be used to solve the LP
relaxation?
• How are the max-product and sum-product algorithms related?

j6=i

mβi (xi )

• When can BP algorithms be used to provably extract the MAP assignment?

β6=α

mαi (xi )

←

miα (xi )

←

deg(i)
1−ci .

γi −1
γi
m0αi (xi )
m0iα (xi )
γi −1
γi
m0iα (xi )
m0αi (xi )

2

The max-product belief-propagation
with γi =
algorithm is the same, but with the sum replaced with
a max. Note that when γi = 1 (or, equivalently,
ci = 1 − deg(i)) the above update equations reduce
to ordinary-BP. From the messages we calculate the
beliefs:
Y
bi (xi ) ∝
mαi (xi )
α

bα (xα ) ∝ ψα1/T (xα )

Y

miα (xi )

(2)

i

Observation: A set of beliefs bα , bi are stationary
points of an approximate free energy with double
counting numbers cα , ci and temperature T if and only
if they satisfy:
• Admissibility: for all x:
Y
Y
(Pr(x))1/T ∝
bcαα (xα )
bci i (xi )

(3)

i

• Marginalization: The beliefs are positive, sum
to one and satisfy:
X
∀i, α : i ∈ α
bα (xα ) = bi (xi )
(4)
xα\i

Similarly, it can be shown that a set of beliefs
are fixed-points of the max-product algorithm with
double counting numbers cα , ci if and only if they
satisfy the above admissibility condition and maxmarginalization condition:
∀i, α : i ∈ α

max bα (xα ) = bi (xi )
xα\i

As we will show subsequently, a key property in analyzing approximate free energies is their convexity over
the set of constraints.1 Heskes [6, 7] has derived sufficient conditions for an entropy approximation to be
convex over the set of constraints. In our setting, we
can rewrite these conditions as follows:
Definition: An approximate entropy term of the
form:
X
X
H=
cα Hα +
ci Hi
(6)
α

We emphasize again that this is just one possible algorithm to find stationary points of the approximate free
energy. In order to deal with any algorithm, we use
the following characterization of approximate free energy stationary points. This characterization follows
directly from differentiating the Lagrangian of the approximate free energy and was used by [8, 21, 29].

α

Convex Free energies

(5)

i

is said to be provably convex if there exist non-negative
numbers ciα , dα , di such that:
H=

X

i,α:i∈α

2.1

ciα (Hα − Hi ) +

X

d α Hα +

α

X

d i Hi

i

Tree Reweighted Free Energies

Wainwright and colleagues have introduced an important subclass of belief propagation algorithms: tree
reweighted BP. These are algorithms whose free energy is a linear combination of free energies defined on
spanning trees of the graph. They have shown that
tree reweighted BP (1) can be used to obtain a rigorous bound on the free energy and (2) gives rise to a
convex free energy approximation. A natural question
that arises is whether these two properties of TRBP
are equivalent – do all BP algorithms that arise from
convex free energies also give a rigorous bound on the
free energy. In this section we show that the answer is
negative. In fact tree reweighted BP algorithms represent a small fraction of convex free energy belief propagation algorithms.
1
Convexity over the set of constraints means the function is convex as a function of any beliefs that satisfy the
marginalization constraints. This is a weaker assumption
from convexity over any beliefs. Henceforth we refer to this
weaker assumption as convexity of the entropy approximation.

WEISS ET AL.
Tree-reweighted free energies [21] use entropy terms of
the form:
X
HT RBP (µ) =
µT HT
(7)

419
T =5

T =2

T = 0.1

T

where T is a spanning tree in the graph, µT defines a
distribution over spanning trees and HT is the entropy
of that tree. Since HT is convex, so is HT RBP . But not
every convex free energy can be written in this way.
To see this, note that any tree reweighted entropy can
be rewritten:
X
X
X
HT RBP (µ) =
ρij Hij +
(1 −
ρij )Hi
<ij>

i

j

where ρij is the edge appearance probability defined
by µ. In comparing this to the general entropy approximation (equation 6) we see that tree reweighted
entropies are missing a degree of freedom (with ci ).
In fact, for any TRBP entropy we can add an infinite number of possibile positive combination of single node entropies and still maintain convexity. Thus,
TRBP entropies are a measure zero set of all convex
entropies.
In some cases, we can even subtract single node entropies from a TRBP entropy and still maintain convexity. For example, the Bethe free energy for a single cycle can be shown to be convex but it cannot be
represented as tree-reweighted free energy [21]. In particular, it does not give rise to a bound on the free
energy.
This shows that the family of BP algorithms that provide a bound on the free energy is a strict subset of
the family of convex BP algorithms.

3

When does sum-product BP solve
the LP relaxation?

Claim: Convex BP=LP Let bα , bi be fixed-point
beliefs from running belief propagation with a convex
entropy approximation at temperature T . As T → 0
these beliefs approach the solution to the linear program.
Proof: We know that the BP beliefs are constrained
stationary points of the free energy (equation 1). The
minimization of F is done subject to the following constraints:
bα (xα )

∈

[0, 1]

X

bα (xα )

=

1

X

bα (xα )

=

bi (xi )

xα

xα\i

The energy term is exactly the LP problem. As we
decrease the temperature, the approximate free energy

Figure 1: Contour plots of the Bethe free energy (top)
and a convex free energy (bottom) for a 2D Ising model
with uniform external field at different temperatures.
The stars indicate local stationary points. Both free
energies approach the LP as temperature is decreased,
but for the Bethe free energy, a local minimum is
present even for arbitrarily small temperatures.
approaches the LP cost (note that the entropy term
is bounded). If we assume the entropy function to
be convex then the approximate free energy is convex
and hence any fixed-point corresponds to the global
minimum.
Note that for any BP algorithm, it is true that the
approximate free energy minimization problem approaches the LP problem. In particular, this is true for
ordinary BP which minimizes the Bethe free energy.
However, when the entropy function is non-convex,
there is no guarantee that fixed-points will correspond
to the global optimum.
Figure 1 illustrates the difference. We consider a
graphical model corresponding to a toroidal grid. The
nodes are binary and all the pairwise potentials are of
the form:


3 1
Ψ=
1 2
These potentials correspond to an Ising model with a
uniform external field – nodes prefer to be similar to
their neighbors and there is a preference for one state
over the other. In order to visualize the approximate
free energies, we consider beliefs that are symmetric
and identical for all pairs of nodes:


x
y
bα =
y 1 − (x + 2y)
Note that the MAP (and the optimum of the LP) occur at x = 1, y = 0 in which case all nodes are in their
preferred state. Figure 1 shows the Bethe free energy
(top) and a convex free energy (bottom) for this problem for different temperatures. The stars indicate local
stationary points. Both free energies approach the LP

420

WEISS ET AL.

as temperature is decreased, but for the Bethe free energy, a local minimum is present even for arbitrarily
small temperatures.

4

How are max-product BP and
sum-product BP related?

Although we have shown that one can use sum-product
convex BP to solve the linear program, one needs to be
able to run the sum-product algorithm at sufficiently
small temperatures and this may cause serious numerical problems. We now show that in certain cases,
one can solve the linear program by running the maxproduct algorithm at any temperature. This follows
from the interpertation of the max-product algorithm
as the zero temperature limit of sum-product.
Zero
temperature
lemma:
Suppose
{bα (xα ), bi (xi )} are fixed-points of the sumproduct algorithm at temperature T .
Define
b̂α (xα ) ∝ bTα (xα ) and b̂i (xi ) ∝ bTi (xi ). Then for any
T → 0, {b̂α (xα ), b̂i (xi )} approach the conditions for
fixed-points of the max-product BP algorithm at
temperature T = 1.
Proof: Recall that a set of beliefs are fixed-points of
the sum-product algorithm if and only if they satisfy
the admissibility constraint (equation 3) and the marginalization constraint (equation 4) and they are fixedpoints of the max-product algorithm if and only if
they satisfy the admissibility constraint and the maxmarginalization constraint (equation 5).
For any T , if {bα (xα ), bi (xi )} satisfy the admissibility constraint at temperature T then b̂α (xα ) ∝ bTα (xα )
and b̂i (xi ) ∝ bTi (xi ) must satisfy the admissibility constraint at temperature 1. We just need to show that
b̂α , b̂i also satisfy the max-marginalization constraint
as T → 0. Since {bα (xα ), bi (xi )} are fixed-points of
the sum-product algorithm, they must satisfy summarginalization, and substituting in the definition of
{b̂α (xα ), b̂i (xi )} we obtain:
X

1/T

b̂1/T
α (xα ) = b̂i

(xi )

xα\i



X

xα\i

Example: Consider a graphical model with two nodes
x1 , x2 and a pairwise factor:


1 1
ψ12 (x1 , x2 ) =
.
1 0
Consider the Bethe approximation for this graph
(c12 = 1, c1 = c2 = 0). This entropy approximation is
trivially convex. It is easy to show that for any temperature T , the fixed-points of sum-product BP are:


1 1
b12 = 13
, b1 = b2 = 13 (2, 1).
1 0
And, again, for any temperature T , the fixed-points of
max-product BP are:


1 1
b12 =
, b1 = b2 = (1, 1).
1 0
In other words, when we run max-product BP we will
get uniform beliefs in both nodes and no matter how
small we set T , raising the beliefs to the power 1/T will
still give uniform beliefs. However, the sum-product
beliefs are non-uniform for any temperature. Note,
however, that the counterexample still satisfies the
zero temperature lemma — raising the sum-product
beliefs to the power T indeed approaches the maxproduct beliefs as T → 0.
The counterexample shows the problem with going
from max-product beliefs to sum-product beliefs at
T → 0 (which are equivalent to the LP solution)
– the max-product beliefs retain the information on
the maximum belief, but have lost the information regarding the number of configurations that attained the
maximal value. This motivates the following sufficient
conditions for going from max-product beliefs to sumproduct beliefs.
Given a set of beliefs, b̂α , b̂i we define the sharpened
beliefs as follows:

This can be rewritten:


we could use the beliefs to find fixed-points of maxproduct BP at temperature T = 1. But to use maxproduct BP to solve the LP we want to go in the opposite direction, i.e. use max-product BP to define fixedpoints of sum-product BP at small temperatures. It
turns out that this direction does not always work, as
the following counterexample shows.

T

 = b̂i (xi )
b̂1/T
α (xα )

and as T → 0 this approaches the max-marginalization
constraint.
The zero temperature lemma suggests that if we could
run sum-product BP at arbitrarily small temperatures,

qα (xα )
qi (xi )

∝ δ(b̂α (xα ) − max b̂α (xα ))
xα

∝ δ(b̂i (xi ) − max b̂i (xi ))
xi

To illustrate this definition, a belief vector (0.6, 0.4)
would be sharpened to (1, 0) and a belief vector
(0.4, 0.4, 0.2) would be sharpened to (0.5, 0.5, 0).
Using this definition it can be shown:

Ȍ14

1
1
a

a
a
1

1
a
a

Ȍ12
1

WEISS ET AL.

a
1
1
Ȍ13

4

Ȍ34

a
1

2

1
a

3

Ȍ23, Ȍ24

1
a

a
1

a
1
a

1
a
1

Figure 2: A simple problem for which max-product
convex BP will converge in a single iteration but the
beliefs cannot be used to solve the linear program. a
is a real number smaller than 1.
Corollary: Max-Product Convex BP=LP Let
b̂α , b̂i be max-product beliefs at T = 1 for a convex
BP algorithm. If the sharpened max-product beliefs
are sum-marginalizable then they are a solution to the
LP problem.

421

exists an assignment x∗ such that bα (x∗α ) maximizes
bα (xα ) and bi (x∗i ) maximizes bi (xi ) then x∗ is the
MAP.
Proof: Since we have fixed-points of max-product BP
they are admissible (equation 3). Using the fact that
the entropy is provably convex, we can rewrite this as:
Y  bα (xα ) ciα Y
Y
Pr(x) ∝
bdαα (xα )
bdi i (xi ) (8)
b
(x
)
i
i
α
i,α
i
We have rewritten Pr(x) as a product of functions on
xα , xi . We want to show that x∗α , x∗i maximize all of
these functions. We know that x∗α maximizes bα (xα )
and x∗i maximizes bi (xi ). Therefore, we just need to
worry about the quotients:
riα (xα ) ≡

bα (xα )
bi (xi )

In the simple two node example, the sharpened maxproduct beliefs are simply the original beliefs, so they
are not a solution to the LP problem. In this case,
however, it is easy to “fix” the beliefs by defining b1 , b2
as the sum marginals of b12 . Figure 2 shows a simple
problem for which the problem is much harder to fix.
Max-product convex BP will converge in a single iteration to beliefs that are proportional to the potentials, but the sharpened beliefs will not be sum marginalizeable. Hence they cannot be used to solve the
linear program. However, sum-product convex BP at
T = 0.0001 gave a solution to the LP.

Lemma: Suppose we have a set of beliefs bα , bi that
are max-marginalizable and there exists x∗ such that
bα (x∗α ) maximizes bα (xα ) and bi (x∗i ) maximizes bi (xi ).
Then x∗ also maximizes bα (xα )/bi (xi ).

To summarize, our analysis (as well as that by Kolmogorov and Wainwright [10,11]) shows that the relation between LP relaxation and max-product convex
BP is subtle – although we can always verify posthoc whether we have obtained the LP solution, and a
fixed-point corresponding to the LP solution is guaranteed to exist, we are not guaranteed to find that
fixed-point. On the other hand, for sum-product convex BP the connection to LP is much more direct –
at sufficiently small temperatures the BP beliefs will
approach the LP solution.

Corollary Convex BP = MAP without ties Let
bα , bi be fixed-points of max-product BP with a provably convex entropy function. If there are no ties in
these beliefs – for every i the maximum of bi (xi ) is
attained at a unique value x∗i – then x∗ is the MAP.

5

When can we extract the MAP
from max-product convex BP?

Whereas the previous section focused on using the
max-product algorithm to avoid the numerical instabilities associated with sum-product at small temperatures, here we show how to use max-product BP directly to obtain a solution to the MAP problem.
Theorem 1: Convex-BP = MAP without frustrations: Let bα , bi be fixed-points of max-product
BP with a provably convex entropy function. If there

This lemma was proved for the case of pairwise factors
in [20] and the generalization for arbitrary factors is
straightforward.
Using the Lemma we see that x∗ maximizes all the
terms in the decomposition (equation 8), since each
term is either bi (xi ), bα (xα ) or riα (xi , xα\i ), raised by
the power of a non-negative number.

Proof: Since the beliefs are max-marginalizable the
fact that there are no ties in the node beliefs implies
there are no ties in the factor beliefs. It follows that x∗α
maximizes bα (xα ) for each α and hence the previous
theorem holds.
Both the previous theorem and the corollary were
proven for the case of TRBP by [21]. Our proof extends these results for arbitrary convex BP algorithms.
5.1

Dealing with frustrations

There are many cases in which it is impossible to find
an assignment x∗ that maximizes all the factor beliefs.
This happens whenever the beliefs define a frustrated
cycle (see figure 3).
Our final theorem shows that it is possible to extract
the MAP from convex BP beliefs even if there are frustrated cycles.

422

WEISS ET AL.
BP
1
2
1

a

2
3
2

Default
CBP

TRBP
1
2
1

0
1
0

1
2
1

0
1
0

1

3
2

1

3
2

2

3
2

1

3
2

1

Trivial
CBP
0
0
0

0
0
0

0
0
0

Figure 4: Negative double counting numbers −ci for
four different free energy approximations on a 3 × 3
grid used to illustrate the different algorithms.

b

Figure 3: An illustration of a frustrated cycle. The
tables show pairwise beliefs obtained by a convex BP
algorithm. For the four nodes in (a), it is possible to
find an assignment x∗ that maximizes the pairwise and
singleton beliefs. Theorem 1 proves that this means
that x∗ is the global optimum. For the four nodes in
(b) it is impossible to find such an assignment.
Theorem 2: Convex-BP = MAP with frustrations: Let bα , bi be fixed-points of max-product BP
with a provably convex entropy function. Let N T be
the set of non-tied variables and T be the set of tied
variables. We denote the set of tied nodes that have
non-tied neighbors as ∂T . Define x∗N T by maximizing
the local beliefs (the maximum here is unique since
these are non-tied nodes). Define:
Y
Y
Y
ciα
bT (xT ) =
riα
(xα )
bdαα (xα )
bdi i (xi )

maximize bi (xi ) (otherwise this would contradict maxmarginalizability). Hence we can use the lemma again
to show that x∗α must maximize riα (xα ).
Corollary: For pairwise factors, if all nodes on the
boundary of the tied nodes, ∂T , have uniform beliefs,
then the non-tied beliefs are optimal (that is, x∗N T =
AP
xM
N T ).
This is because for uniform beliefs on the boundary, any assignment xT maximizes the beliefs on the
boundary. The fact that factors are pairwise means
that it also maximizes all factors that include the
boundary nodes. This generalizes a result of Kolmogorov and Wainwright [11] for binary nodes.

6

An illustrative example

If there exists x∗T that maximizes bT (xT ) and for
all regions α that contain both tied and non-tied
nodes bα (x∗α ) maximizes bα (xα ) then the assignment
(x∗T , x∗N T ) is the MAP assignment.

To illustrate the relationship between linear programming (LP), ordinary belief propagation (BP), tree
reweighted belief propagation (TRBP) and convex belief propagation (CBP), we conducted simulations with
a small grid graphical model – 9 nodes, arranged in a
3 × 3 grid.

Proof: Using the decomposition equation (equation 8) we can write:
Y
Y
Y
ciα
riα
Pr(x) ∝
(xα )
bdαα (xα )
bdi i (xi )

One of the difficulties in comparing these different variants of belief propagation comes from the fact that
there are many ways to construct TRBP or convex
BP approximations. We define the default convex BP
approximation based on the following observation.

i,α:

α⊂T

i∈T \∂T

i∈T \∂T

α

i,α

= bT (xT ) ·

Y

i

ciα
riα
(xα )

Y

α6⊂T

bdαα (xα )

Y

i∈T
/

ciα
riα
(xα )

i,α:i∈∂T

i,α:i∈T
/

·

Y

bdi i (xi )

Y

bdi i (xi )

i∈∂T

We want to show that x∗ maximizes all the terms
in the decomposition. By construction x∗T maximizes
bT (xT ). By the previous lemma, for all regions α 6⊂ T ,
x∗α maximizes riα (xα ). Also, for all i ∈
/ T and α 6⊂ T ,
bi (xi ) and bα (xα ) are maximized by x∗N T . For i ∈ ∂T ,
x∗T maximizes bi (xi ) due to the assumption that x∗
maximizes the boundary factors . The only thing to
worry about are terms of the sort riα (xα ), where i
is a boundary node. But since the beliefs bα , bi are
max-marginalizable for boundary nodes as well and
bα (x∗α ) maximizes bα (xα ) by assumption, bi (x∗i ) must

Observation: For any factor graph, the free
P energy
approximation given by cα = 1 and ci = − α:i∈α d1α
is convex.
This follows from the convexity decomposition in section 2 with ciα = dα1 ) , di = 0 and dα = 0, where dα is
the number of nodes that participate in the factor α.
We consider 4 different approximate free energies
which give the double counting numbers ci in figure 4.
In all of them, all the factors have the same double
counting number cα = 1 but they differ in the double
counting numbers ci for the nodes. In ordinary BP,
ci = 1 − di . For TRBP we considered two spanning
forests – one for the horizontal edges of the grid, and
one for the vertical edges. We used the uniform distribution over these two spanning forests so that the

WEISS ET AL.
edge appearance probability was 0.5 for all edges. To
facilitate comparison with the other approximations,
we multiplied the entropy approximation by two, so
that cα = 1 for all edges and ci = 2 − deg(i) for
all nodes. We also considered two convex BP approximations. The default CBP approximation gives
ci = −di /2 (since all the factors are pairwise). Finally
the trivial approximation ci = 0 is trivially convex
since it only sums up positive entropies. For all these
free energy approximations we ran the max-product
algorithm with a-synchronous updates and a “dampening” factor of 0.5.
We generated 100 samples of these 3 × 3 “spin
P glasses”
–P the energy was given by E(x) =
i Jii xi +
J
x
x
.
J
and
J
were
sampled
from
zero
ii
ij
<ij> ij i j
mean Gaussians with standard deviations 0.4 and 1.0.
We found that the problems could be subdivided into
three classes based on the behavior of the linear programming relaxation. In the easy regime the linear
programming solution is all integer and hence solving
the LP gives the MAP (this happened in 53% of our
runs). All the convex approximations converged to
beliefs without ties. Consistent with the Max-Product
Convex BP=LP corollary, the assignments obtained
by all the approximations were indeed the MAP. Additionally, in all the simulations in the easy regime, ordinary BP gave the correct answer. However, whereas
the convex algorithms come with a MAP certificate,
ordinary BP comes with no such theoretical guarantee. While all algorithms found the right answer in this
easy regime, the number of iterations to convergence
was different. Ordinary BP converged faster (median
number of iterations 48), then the default CBP (112
iterations), then TRBP (176 iterations) and finally the
trivial CBP (225 iterations).
In the hard regime the LP solution is all fractional
(this happened in 36% of the runs). Consistent with
the Max-Product Convex BP=LP corollary, all the
convex BP algorithms converged in this case to beliefs where all the nodes were tied. For this regime,
ordinary BP never converged. Although the zerotemperature lemma guarantees that a fixed-point with
ties exists for ordinary BP as well, this fixed-point
was never found. In this regime, TRBP converged
the fastest among the convex BP algorithms (median
number of iterations 185), followed by the trivial CBP
(295 iterations) and finally the default CBP (316 iterations). However, in terms of finding the MAP, all
convex algorithms were equally useless.
In the intermediate regime the LP solution is partially integer and partially fractional (this happened
in 11% of the runs). Again, all the convex BP algorithms converged to the same solution where part

423

of the beliefs are tied and others are not (tied beliefs
corresponded to fractional solutions to the LP). The
default CBP was fastest (144 iterations) followed by
TRBP (197 iterations) and then trivial CBP (372). In
the majority of these cases (8 out of 11), ordinary BP
did not converge.
To summarize, convex BP algorithms have the greatest practical advantage over ordinary BP in the intermediate regime where the LP is partially fractional
- they converge better and allow to provably extract
the MAP. All convex BP algorithms are equivalent in
terms of finding the MAP but convergence rate can
vary drastically.

7

Real World Experiments

The experiments reported here were designed to see
how often convex BP will allow us to solve real-world
instances of the MAP problem. Checking the conditions of theorems 1 and 2 requires finding the MAP in
a reduced graphical model defined over the tied nodes.
We use the junction tree algorithm to solve this task
so this becomes infeasible when the subgraph of tied
nodes has large induced width.
Our first two datasets are based on real-world graphical models coming from computational biology. We
briefly summarize the construction of these datasets
(see [26] for more details).
Proteins are chains of residues, each containing one of
20 possible amino acids. All amino acids are connected
together by a common backbone structure, onto which
amino-specific side-chains are attached. The problem of predicting the residue side-chain conformations
given a backbone structure is considered of central importance in protein-folding and molecular design and
has been tackled extensively using a wide variety of
methods (for a recent review, see [2]). The typical
way to predict side-chain configurations is to define
an energy function and a discrete set of possible sidechain conformations, and then search for the minimal
energy configuration. Even when the energy function
contains only pairwise interactions, the configuration
space grows exponentially and it can be shown that
the prediction problem is NP-complete [5].
As a dataset we used 370 X-ray crystal structures with
resolution better than or equal to 2Å, R factor below 20% and mutual sequence identity less than 50%.
Each protein consist of a single chain and up to 1,000
residues. Protein structures were acquired from the
Protein Data Bank site (http://www.rcsb.org/pdb).
For each protein, we have built a graphical model using the ROSETTA energy function [12]. The nodes
of this model correspond to residues, and there are

Task
Side-Chain
Design

WEISS ET AL.
LP=IP
1.35%
0%

Thm 1
83.78%
2.1%

Thm 2
6.76%
0%

Failed
8.1%
97.9%

Table 1: The percentage of real-world instances solved
by the different theorems presented in this paper.
LP=IP means that the solution of the LP was integer.
For the easier problem of side-chain prediction (top)
we could find the global optimum for about 92% of the
cases. For the harder task of protein design, there are
so many tied nodes that checking the conditions of the
theorems becomes infeasible.
edges between any two residues that interact [27]; the
potentials are inversely related to the energy.
The protein design problem is the inverse of the protein folding problem. Given a particular 3D shape,
we wish to find a sequence of amino-acids that will
be as stable as possible in that 3D shape. Typically
this is done by finding a set of (1) amino-acids and (2)
rotamer configurations that minimize an approximate
energy [17]. While the protein design problem is quite
different from side-chain prediction it can be solved
using the same graph structure. The only difference is
that now the nodes do not just denote rotamers but
also the identity of the amino-acid at that location.
Thus, the state-space here is significantly larger than
in the side-chain prediction problem. We, again, used
the ROSETTA energy function to define the pairwise
and local potentials. As a dataset we used 96 X-ray
crystal structures, 40-180 amino acids long. For each
of these proteins, we allowed all residues to assume
any rotamer of any amino acid. There are, therefore,
hundreds of possible states for each node.
We found that convergence was not an issue – in all
the experiments convex BP converged in reasonable
time but the number of ties determines the success
of the algorithm. Table 1 shows a breakdown of the
success rate for the two problems. In the harder problem of protein design, the number of ties is so large
that checking the conditions of theorems 1 and 2 is
infeasible. But in the side-chain problem, even though
exact inference is NP hard and the search space can
be as large as 10600 (largest clique in junction tree –
1060 ), the number of ties is quite manageable – in over
90% of the instances we can find the global optimum.
For this data set, ordinary BP also converged 85.14%
of the times, and whenever it converged it found the
global optimum.
Our third dataset was based on a low density parity
check code taken from David Mackay’s encyclopedia
of sparse graph codes (http://www.inference.phy.
cam.ac.uk/mackay/codes/data.html). We used the
204.33.484 code which has 204 bits and 102 parity

BP

LP

CBP + ties

100
MAP found [%]

424

80
60
40
20
0

10

1.6

1.4

1.2

10
10
10
BSC crossover probability

1.0

Figure 5: A comparison of success rates as a function
of crossover probability for a LDPC code on a binary
symmetric channel.
checks. We simulated sending a codeword over a binary symmetric channel. Each received word defines
the local factors in a factor graph, and we used trivial
convex BP to find the MAP in this graphical model.
We repeated this experiment for different signal to
noise ratios (SNR).
Figure 5 shows our results. For high SNR, the problem is easy and the LP solution is almost always integer (success of LP corresponds to a fully integer LP
solution or, equivalently, max-product convex BP having no ties). However, as the SNR decreases, the LP
solution is almost always partially fractional but using theorem 1 allows us to find the MAP decoding in
all cases. Thus even though the search space here is
of size 2204 and the maximal clique in the junctiontree includes 134 bits, convex BP allows us to find the
global optimum in a matter of minutes.

8

Discussion

Belief Propgation and its variants have shown excellent
performance as approximate inference algorithms. In
this paper we have focused on conditions under which
the MAP can be provably extracted from BP beliefs.
We have shown that previous results – BP on a single
cycle and TRBP on arbitrary graphs – are special cases
of a wider result on BP with a convex free energy. We
have also shown that BP with a convex free energy can
be used to solve LP relaxations of the MAP problem.
Finally, we have proven a novel result that allows us
to extract the MAP from convex BP beliefs even when
there are frustrated cycles.
From a theoretical perspective, one intriguing result
arising from our work is the close connection between
LP relaxations and a large class of belief propagation variants (including ordinary BP). Given the large
amount of literature on the tightness of LP relaxations
for combinatorial problems, this connection may enable proving correctness of BP variants on a larger
class of problems.

WEISS ET AL.
From a practical perspective, our theorems proven in
section 5 allow us to go beyond the LP relaxation and
provably find the MAP even when the LP relaxation
is partially fractional. Our experiments on side chain
prediction and error correcting code show that using
these theorems it is possible to find the MAP on real
world instances of very large graphical models where
techniques such as junction tree are intractable. Similarly, in our work reported in [14] we have used these
theorems to find the global optimum on a number of
stereo vision problems. Until our results, only local
optima for these problems were known. We believe
similar results are possible in a wide range of applications.
Acknowledgements
Supported by the Israeli Science Foundation. We
thank Amir Globerson for comments on a previous
version of this manuscript.



Linear Programming (LP) relaxations have
become powerful tools for finding the most
probable (MAP) configuration in graphical
models. These relaxations can be solved
efficiently using message-passing algorithms
such as belief propagation and, when the relaxation is tight, provably find the MAP configuration. The standard LP relaxation is
not tight enough in many real-world problems, however, and this has lead to the use
of higher order cluster-based LP relaxations.
The computational cost increases exponentially with the size of the clusters and limits the number and type of clusters we can
use. We propose to solve the cluster selection problem monotonically in the dual LP,
iteratively selecting clusters with guaranteed
improvement, and quickly re-solving with the
added clusters by reusing the existing solution. Our dual message-passing algorithm
finds the MAP configuration in protein sidechain placement, protein design, and stereo
problems, in cases where the standard LP relaxation fails.

1

Introduction

The task of finding the maximum aposteriori assignment (or MAP) in a graphical model comes up in a
wide range of applications. For an arbitrary graph,
this problem is known to be NP hard [11] and various
approximation algorithms have been proposed.
Linear Programming (LP) relaxations are commonly
used to solve combinatorial optimization problems in
computer science, and have a long history of being
used to approximate the MAP problem in general
graphical models (e.g., see [9]). LP relaxations have an
advantage over other approximate inference schemes in

Tommi Jaakkola
CSAIL, MIT
Cambridge, MA

Yair Weiss
Hebrew University
Jerusalem, Israel

that they come with an optimality guarantee – if the
solution to the linear program is integral, then it is
guaranteed to give the global optimum of the MAP
problem.
An additional attractive quality of LP relaxations is
that they can be solved efficiently using messagepassing algorithms such as belief propagation and its
generalizations [3, 13, 15]. In particular, by using
message-passing algorithms, we can now use LP relaxations for large-scale problems where standard, offthe-shelf LP solvers could not be used [18].
Despite the success of LP relaxations, there are many
real-world problems for which the basic LP relaxation
is of limited utility in solving the MAP problem. For
example, in a database of 97 protein design problems
studied in [18], the standard LP relaxation allowed
finding the MAP in only 2 cases.
One way to obtain tighter relaxations is to use clusterbased LP relaxations, where local consistency is enforced between cluster marginals. As the size of the
clusters grow, this leads to tighter and tighter relaxations. Furthermore, message-passing algorithms can
still be used to solve these cluster-based relaxations,
with messages now being sent between clusters and not
individual nodes. Unfortunately, the computational
cost increases exponentially with the size of the clusters, and for many real-world problems this severely
limits the number of large clusters that can be feasibly
incorporated into the approximation. For example, in
the protein design database studied in [18], each node
has around 100 states, so even a cluster of only 3 variables would have 106 states. Clearly we cannot use too
many such clusters in our approximation.
In this paper we propose a cluster-pursuit method
where clusters are incrementally added to the relaxation, and where we only add clusters that are guaranteed to improve the approximation. Similar to the
work of [16] who worked on region-pursuit for sumproduct generalized belief propagation [19], we show

how to use the messages from a given cluster-based
approximation to decide which cluster to add next. In
addition, by working with a message-passing algorithm
based on dual coordinate descent, we monotonically
decrease an upper bound on the MAP value.

2

MAP and its LP Relaxation

We consider functions over n discrete variables x =
{x1 , . . . , xn } defined as follows. Given a graph G =
(V, E) with n vertices, and potentials θij (xi , xj ) for all
edges ij ∈ E, define the function
f (x; θ) =

X

θij (xi , xj ) +

ij∈E

X

θi (xi ) .

(1)

i∈V

Our goal is to find the MAP assignment, xM , that
maximizes the function f (x; θ).
The MAP problem can be formulated as a linear program as follows. Let µ be a vector of marginal probabilities that includes {µij (xi , xj )}ij∈E over variables
corresponding to edges and {µi (xi )}i∈V associated
with the nodes. The set of µ that arise from some joint
distribution is known as the marginal polytope [14],

M(G) =

µ | ∃p(x) s.t.

p(xi , xj ) = µij (xi , xj )
p(xi ) = µi (xi )


.

The MAP problem can then be shown to be equivalent
to the following LP,
max f (x, θ) = max µ · θ ,
x

(2)

µ∈M(G)

refer to the P
marginal of τc (xc ) for the edge (i, j), i.e.
τc (xi , xj ) = xc\i,j τc (xc ). Define MC (G) as




µij (xi , xj ) = µi (xi )

τP
c (xi , xj ) = µij (xi , xj ) ∀c, (i, j) ⊆ c

xc τc (xc ) = 1
P

∃τ ≥ 0
 µ≥0

xj

It is easy to see that MC (G) is an outer bound on
M(G), namely MC (G) ⊇ M(G). As we add more
clusters to C the relaxation of the marginal polytope
becomes tighter. Note that similar constraints should
be imposed on the cluster marginals, i.e., they themselves should arise as marginals from some joint distribution. To exactly represent the marginal polytope,
such a hierarchy of auxiliary clusters would require
clusters of size equal to the treewidth of the graph.
For the purposes of this paper, we will not generate
such a hierarchy but instead use the clusters to constrain only the associated edge marginals.
2.1

Choosing Clusters in the LP Relaxation

Adding a cluster to the relaxation MC (G) requires
computations that scale with the number of possible
cluster states. The choice of clusters should therefore
be guided by both how much we are able to constrain
the marginal polytope, as well as the computational
cost of handling larger clusters. We will consider a
specific scenario where the clusters are selected from
a pre-defined set of possible clusters C0 such as triplet
clusters. However, we will ideally not want to use all
of the clusters in C0 , but instead add them gradually
based on some ranking criterion.

P
P
where µ · θ =
ij∈E
xi ,xj θij (xi , xj )µij (xi , xj ) +
P P
µ
(x
)θ
(x
).
There
always exists a maximizi
i
i
i
i
xi
ing µ that is integral – a vertex of the marginal polytope – and which corresponds to xM . Although the
number of variables in this LP is only O(|E|+|V |), the
difficulty comes from an exponential number of linear
inequalities typically required to describe the marginal
polytope M(G).

The best ranking of clusters is problem dependent. In
other words, we would like to choose the subset of clusters which will give us the best possible approximation
to a particular MAP problem. We seek to iteratively
improve the approximation, using our current beliefs
to guide which clusters to add. The advantage of iteratively selecting the clusters is that we add them only
up to the point that the relaxed LP has an integral
solution.

The idea in LP relaxations is to relax the difficult
global constraint that the marginals in µ arise from
some common joint distribution. Instead, we enforce
this only over some subsets of variables that we refer
to as clusters. More precisely, we introduce auxiliary
distributions over clusters of variables and constrain
the edge distributions µij (xi , xj ) associated with each
cluster to arise as marginals from the cluster distribution.1 Let C be a set of clusters such that each c ∈ C is
a subset of {1, . . . , n}, and let τc (xc ) be any distribution over the variables in c. We also use τc (xi , xj ) to

Recently, Sontag and Jaakkola [12] suggested an approach for incrementally adding constraints to the
marginal polytope using a cutting-plane algorithm. A
similar approach may in principle be applied to adding
clusters to the primal problem. One shortcoming of
this approach is that it requires solving the primal LP
after every cluster added, and even solving the primal LP once is infeasible for large problems involving
hundreds of variables and large state spaces.

1

Each edge may participate in multiple clusters.

In the next section we present a method that incrementally adds clusters, but which works exclusively
within the dual LP. The key idea is that the dual LP

provides an upper bound on the MAP value, and we
seek to choose clusters to most effectively minimize
this bound. Note that an analogous bound minimization strategy is problematic in the primal where we
would have to assess how much less the maximum
is due to including additional constraints. In other
words, obtaining a certificate for improvement is difficult in the primal. Moreover, unlike the dual, the
primal algorithm might not give an upper bound on
the MAP prior to convergence.
Finally, we can “warm start” our optimization scheme
after each cluster addition in order to avoid re-solving
the dual LP. We do this by reusing the dual variables calculated in the previous iterations which did
not have the new clusters.

3

Dual LP Relaxation

The obstacles to working in the primal LP lead us
to consider the dual of the LP relaxation. Different
formulations of the primal LP have lead to different
dual LPs, each with efficient message-passing algorithms for solving them [3, 6, 13, 15]. In this paper
we focus on a particular dual formulation by Globerson and Jaakkola [3] which has the advantage that the
message-passing algorithm corresponds to performing
coordinate-descent in the dual LP. Our dual algorithm
will address many of the problems that were inherent
in the primal approaches, giving us:

we show in our experiments that MAP assignments
can be found for nearly all of the problems we consider.
We next describe the generalized MPLP algorithm for
the special case of clusters comprised of three nodes.
Although the algorithm applies to general clusters, we
focus on triplets for simplicity, and because these are
the clusters used in the current paper.
MPLP passes the following types of messages:
• Edge to Node: For every edge e ∈ E (e denotes
two indices in V ) and every node i ∈ e, we have a
message λe→i (xi ).
• Edge to Edge: For every edge e ∈ E, we have
a message λe→e (xe ) (where xe is shorthand for
xi , xj , and i and j are the nodes in the edge).
• Triplet to Edge: For every triplet cluster c ∈ C,
and every edge e ∈ c, we have a message λc→e (xe ).
The updates for these messages are given in Figure
1. To guarantee that the dual objective decreases, all
messages from a given edge must be sent simultaneously, as well as all messages from a triplet to its three
edges.
The dual objective that is decreased in every iteration
is given by


X
X
g(λ) =
max θi (xi ) +
λki→i (xi )
i∈V

3. Simple “warm start” of tighter relaxation.
4. An efficient algorithm that scales to very large
problems.
3.1

The Generalized MPLP Algorithm

The generalized Max-Product LP (MPLP) messagepassing algorithm, introduced in [3], decreases the dual
objective of the cluster-based LP relaxation at every
iteration. This monotone property makes it ideal for
adding clusters since we can initialize the new messages such that the dual value is monotonically decreased.
Another key advantage of working in the dual is that
the dual objective gives us a certificate of optimality.
Namely, if we find an assignment x such that f (x; θ) is
equal to the dual objective, we are guaranteed that x
is the MAP assignment (since the dual objective upper
bounds the MAP value). Indeed, using this property

k∈N (i)

#

"

1. Monotonically decreasing upper bound on MAP.
2. Choosing clusters which give a guaranteed bound
improvement.

xi

+

X
e∈E

max λe→e (xe ) +
xe

X

λc→e (xe )

c:e∈c

It should be noted, however, that not all λ are dual
feasible. Rather, λ needs to result from a reparameterization of the underlying potentials (see [3]). However,
it turns out that after updating all the MPLP messages
once, all subsequent λ will be dual feasible, regardless
of how λ is initialized.2
By LP duality, there exists a value of λ such that g(λ)
is equal to the optimum of the corresponding primal
LP. Although the MPLP updates decrease the objective at every iteration, they may converge to a λ that
is not dual optimal, as discussed in [3]. However, as
we will show in the experiments, our procedure often finds the exact MAP solution, and therefore also
achieves the primal optimum in these cases.
3.2

Choosing Clusters in the Dual LP
Relaxation

In this section we provide a very simple procedure that
allows adding clusters to MPLP, while satisfying the
2

In our experiments, we initialize all messages to zero.

• Edge to Node: For every edge ij ∈ E and node i (or j) in the edge:
λij→i (xi )← −

 1
hX
i
2  −j
λi (xi ) + θi (xi ) + max
λc→ij (xi , xj ) + λ−i
(x
)
+
θ
(x
,
x
)
+
θ
(x
)
j
ij
i
j
j
j
j
3
3 xj c:ij∈c

−j
where
λ−j
i (xi ) is the sum of edge-to-node messages into i that are not from edge ij, namely: λi (xi ) =
P
k∈N (i)\j λik→i (xi ).

• Edge to Edge: For every edge ij ∈ E:
λij→ij (xi , xj )← −

i
1h
2 X
−j
(x
)
+
λ
(x
)
+
θ
(x
,
x
)
+
θ
(x
)
+
θ
(x
)
λc→ij (xi , xj ) + λ−i
j
i
ij
i
j
i i
j
j
i
3 c:ij∈c
3 j

• Triplet to Edge: For every triplet c ∈ C and every edge e ∈ c:
λc→e (xe ) ←

−

 1
h X 
X
2
λe→e (xe ) +
λc0 →e (xe ) + max
λe0 →e0 (xe0 ) +
3
3 xc\e 0
0
e ∈c\e

c =
6 c
e ∈ c0

X

i
λc0 →e0 (xe0 )

c0 =
6 c
e0 ∈ c0

Figure 1: The generalized MPLP updates for an LP relaxation with three node clusters.
algorithmic properties in the beginning of Section 3.
Assume we have a set of triplet clusters C and now
wish to add a new triplet. Denote the messages before
adding the new triplet by λt . Two questions naturally
arise. The first is: assuming we decide to add a given
triplet, how do we set λt+1 such that the dual objective
retains its previous value g(λt ). The second question
is how to choose the new triplet to add.
The initialization problem is straightforward. Simply
set λt+1 to equal λt for all messages from triplets and
edges in the previous run, and set λt+1 for the messages from the new triplet to its edges to zero.3 This
clearly results in g(λt+1 ) = g(λt ).
In order to choose a good triplet, one strategy would be
to add different triplets and run MPLP until convergence to find the one that decreases the objective the
most. However, this may be computationally costly
and, as we show in the experiments, is not necessary.
Instead, the criterion we use is to consider the decrease
in value that results from just sending messages from
the triplet c to its edges (while keeping all other messages fixed).
The decrease in g(λ) resulting from such an update
has a simple form, as we show next. Assume we are
considering adding a triplet c. For every edge e ∈ c,
define be (xe ) to be
X
be (xe ) = λe→e (xe ) +
λc0 →e (xe ) ,
(3)
c0 :e∈c0
3

It is straightforward to show that λt+1 is dual feasible.

where the summation over clusters c0 does not include
c (those messages are initially zero). The decrease in
g(λ) corresponding to updating only messages from c
to the edges e ∈ c can be shown to be
"
d(c) =

X
e∈c

max be (xe ) − max
xe

xc

#
X

be (xe )

.

(4)

e∈c

The above corresponds to the difference between independently maximizing each edge and jointly maximizing over the three edges. Thus d(c) is a lower bound
on the improvement in the dual objective if we were
to add triplet c. Our algorithm will therefore add the
triplet c that maximizes d(c).
3.3

The Dual Algorithm

We now present the complete algorithm for adding
clusters and optimizing over them. Let C0 be the
predefined set of triplet clusters that we will consider
adding to our relaxation, and let CL be the initial relaxation consisting of only edge clusters (pairwise local
consistency).
1. Run MPLP until convergence using the CL clusters.
2. Find an integral solution x by locally maximizing
the
P single node beliefs bi (xi ), where bi (xi ) = θi (xi ) +
k∈N (i) λki→i (xi ). Ties are broken arbitrarily.
3. If the dual objective g(λt ) is sufficiently close to
the primal objective f (x; θ), terminate (since x is approximately the MAP).

4. Add the cluster c ∈ C0 with the largest guaranteed
bound improvement, d(c), to the relaxation.
5. Construct “warm start” messages λt+1 from λt .
6. Run MPLP for N iterations, and return to 2.
Note that we obtain (at least) the promised bound improvement d(c) within the first iteration of step 6. By
allowing MPLP to run for N iterations, the effect of
adding the cluster will be propagated throughout the
model, obtaining an additional decrease in the bound.
Since the MPLP updates correspond to coordinatedescent in the dual LP, every step of the algorithm
decreases the upper bound on the MAP. The monotonicity property holds even if MPLP does not converge in step 6, giving us the flexibility to choose the
number of iterations N . In Section 5 we show results
corresponding to two different choices of N .
In the case where we run MPLP to convergence before
choosing the next cluster, we can show that the greedy
bound minimization corresponds to a cutting-plane algorithm, as stated below.
Theorem 1. Given a dual optimal solution, if we find
a cluster for which we can guarantee a bound decrease,
all primal optimal solutions were inconsistent with respect to this cluster.
Proof. By duality both the dual optimum and the primal optimum will decrease. Suppose for contradiction
that in the previous iteration there was a primal feasible point that was cluster consistent and achieved the
LP optimum. Since we are maximizing the LP, after
adding the cluster consistency constraint, this point is
still feasible and the optimal value of the primal LP
will not change, giving our contradiction.
This theorem does not tell us how much the given
cluster consistency constraint was violated, and the
distinction remains that a typical cutting-plane algorithm would attempt to find the constraint which is
most violated.

4

Related Work

Since MPLP is closely related to the max-product generalized belief propagation (GBP) algorithm, our work
can be thought of as a region-pursuit method for GBP.
This is closely related to the work of Welling [16] who
suggested a region-pursuit method for sum-product
GBP. Similar to our work, he suggested greedily
adding from a candidate set of possible clusters. At
each iteration, the cluster that results in the largest
change in the GBP free energy is added. He showed
excellent results for 2D grids, but on fully connected
graphs the performance actually started deteriorating

with additional clusters. In [17], a heuristic related to
maxent normality [19] was used as a stopping criterion for region-pursuit to avoid this behavior. In our
work, in contrast, since we are working with the dual
function of the LP, we can guarantee monotonic improvement throughout the running of the algorithm.
Our work is also similar to Welling’s in that we focus
on criteria for determining the utility of adding a cluster, not on finding these clusters efficiently. We found
in our experiments that a simple enumeration over
small clusters proved extremely effective. For problems where triplet clusters alone would not suffice to
find the MAP, we could triangulate the graph and consider larger clusters. This approach is reminiscent of
the bounded join-graphs described in [1].
There is a large body of recent work describing the
relationship between message-passing algorithms such
as belief propagation, and LP relaxations [7, 15, 18].
Although we have focused here on using one particular message-passing algorithm, MPLP, we emphasize
that similar region-pursuit algorithms can be derived
for other message-passing algorithms as well. In particular, for all the convex max-product BP algorithms
described in [15], it is easy to design region-pursuit
methods. The main advantage of using MPLP is its
guaranteed decrease of the dual value at each iteration,
a guarantee that does not exist for general convex BP
algorithms.
Region-pursuit algorithms are also conceptually related to the question of message scheduling in BP, as
in the work of Elidan et al. [2]. One way to think
of region-pursuit is to consider a graph where all the
clusters are present all the time, but send and receive
non-informative messages. The question of which cluster to add to an approximation, is thus analogous to
the question of which message to update next.

5

Experiments

Due to the scalable nature of our message-passing algorithm, we can apply it to cases where standard LP
solvers cannot be applied to the primal LP (see also
[18]). Here we report applications to problems in computational biology and machine vision.4
We use the algorithm from Section 3.3 for all of our experiments. We first run MPLP with edge clusters until
convergence or for at most 1000 iterations, whichever
comes first. All of our experiments, except those intended to show the difference between schedules, use
N = 20 for the number of MPLP iterations run after
adding a cluster. While running MPLP we use the
messages to decode an integral solution, and compare
4

Graphical models for these are given in [18].

!1063.5
!1064

Objective

!1064.5
!1065
!1065.5
!1066

MPLP for 20 iterations
MPLP until convergence
MAP

!1066.5
!1067
!1067.5
1000

1500
2000
MPLP iterations

2500

Figure 2: Comparison of different schedules for adding
clusters to relaxation on a side-chain prediction problem.

the dual objective to the value of the integral solution.
If these are equal, we have found the MAP solution.5
Otherwise, we keep adding triplets.
Our results will show that we often find the MAP solution to these hard problems by using only a small number of triplet clusters. This indicates both that triplets
are sufficient for characterizing M(G) near the MAP
solution of these problems, and that our algorithm can
efficiently find the informative triplets.
5.1

Side-Chain Prediction

The side-chain prediction problem involves finding the
three-dimensional configuration of rotamers given the
backbone structure of a protein [18]. This problem
can be posed as finding the MAP configuration of a
pairwise model, and in [18] the TRBP algorithm [13]
was used to find the MAP solution for most of the
models studied. However, for 30 of the models, TRBP
could not find the MAP solution.
In earlier work [12] we used a cutting-plane algorithm
to solve these side-chain problems and found the MAP
solution for all 30 models. Here, we applied our dual
algorithm to the same 30 models and found that it also
results in the MAP solution for all of them (up to a
10−4 integrality gap). This required adding between
1 and 27 triplets per model. The running time was
between 1 minute and 1 hour to solve each problem,
with over half solved in under 9 minutes. On average
we added only 7 triplets (median was 4.5), another
indication of the relative ease with which these techniques can solve the side-chain prediction problem.
5
In practice, we terminate when the dual objective is
within 10−4 of the decoded assignment, so these are approximate MAP solutions. Note that the objective values
are significantly larger than this threshold.

We also used these models to study different update
schedules. One schedule (which gave the results in
the previous paragraph) was to first run a pairwise
model for 1000 iterations, and then alternate between
adding triplets and running MPLP for 20 more iterations. In the second schedule, we run MPLP to convergence after adding each triplet. Figure 2 shows the two
schedules for the side-chain protein ‘1gsk’, one of the
side-chain proteins which took us the longest to solve
(30 minutes). Running MPLP to convergence results
in a much larger number of overall MPLP iterations
compared to using only 20 iterations. This highlights
one of the advantages of our method: adding a new
cluster does not require solving the earlier problem to
convergence.
5.2

Protein Design

The protein design problem is the inverse of the protein
folding problem. Given a particular 3D shape, we wish
to find a sequence of amino-acids that will be as stable
as possible in that 3D shape. Typically this is done by
finding a set of amino-acids and rotamer configurations
that minimizes an approximate energy.
While the problem is quite different from side-chain
prediction, it can be solved using the same graph structure, as shown in [18]. The only difference is that now
the nodes do not just denote rotamers, but also the
identity of the amino-acid at that location. Thus, the
state-space here is significantly larger than in the sidechain prediction problem (up to 180 states per variable
for most variables).
In contrast to the side-chain prediction problems,
which are often easily solved by general purpose integer linear programming packages such as CPLEX’s
branch-and-cut algorithm [5], the sheer size of the
protein design problems immediately limits the techniques by which we can attempt to solve them. Algorithms such as our earlier cutting-plane algorithm [12]
or CPLEX’s branch-and-cut algorithm require solving
the primal LP relaxation at least once, but solving the
primal LP on all but the smallest of the design problems is intractable [18]. Branch and bound schemes
have been recently used in conjunction with a message passing algorithm [4] and applied to similar protein design problems, although not the ones we solve
here.
We applied our method to the 97 protein design problems described in [18], adding 5 triplets at a time to
the relaxation. The key striking result of these experiments is that our method found the exact MAP
configuration for all but one of the proteins6 (up to a
precision of 10−4 in the integrality gap). This is es6

We could not solve ‘1fpo’, the largest protein.

pecially impressive since, as reported in [18], only 2
of these problems were solvable using TRBP, and the
primal problem was too big for commercial LP solvers
such as CPLEX. For the problem where we did not
find the MAP, we did not reach a point where all the
triplets in the graph were included, since we ran out
of memory beforehand.
Among the problems that were solved exactly, the
mean running time was 9.7 hours with a maximum
of 11 days and a minimum of a few minutes. We
note again that most of these problems could not be
solved using LP solvers, and when LP solvers could
be used, they were typically at least 10 times slower
than message-passing algorithms similar to ours (see
[18] for detailed timing comparisons).
Note that the main computational burden in the algorithm is processing triplet messages. Since each variable has roughly 100 states, passing a triplet message
requires 106 operations. Thus the number of triplets
added is the key algorithmic complexity issue. For the
models that were solved exactly, the median number
of triplets added was 145 (min: 5, max: 735). As
mentioned earlier, for the unsolved model this number
grew until the machine’s memory was exhausted. We
believe however, that by optimizing our code for speed
and memory we will be able to accommodate a larger
number of triplets, and possibly solve the remaining
model as well. Our current code is written mostly in
Matlab, so significant optimization may be possible.
5.3

Stereo Vision

Given a stereo pair of images, the stereo problem is to
find the disparity of each pixel in a reference image.
This disparity can be straightforwardly translated into
depth from the camera. The best algorithms currently
known for the stereo problem are those that minimize
a global energy function [10], which is equivalent to
finding a MAP configuration in a pairwise model.
For our experiments we use the pairwise model described in [18], and apply our procedure to the
“Tsukuba” sequence from the standard Middlebury
stereo benchmark set [10], reduced in size to contain
116x154 pixels.
Since there are no connected triplets in the grid graph,
we use our method with square clusters. We calculate
the bound decrease using square clusters, but rather
than add them directly, we triangulate the cycle and
add two triplet clusters. This results in an equivalent
relaxation, but has the consequence that we may have
to wait until MPLP convergence to achieve the guaranteed bound improvement.
In the first experiment, we varied the parameters of the

5

9.237

x 10

9.236
9.235
9.234

Objective
Integer solution

9.233
9.232
9.231
9.23
9.229
1000

1050

1100

1150

1200

1250

1300

MPLP iterations

Figure 3: Dual objective and value of decoded integer
solution for one of the reduced “Tsukuba” stereo models,
as a function of MPLP iterations. It can be seen that both
curves converge to the same value, indicating that the MAP
solution was found.

energy function to create several different instances.
We tried to find the MAP using TRBP, resolving ties
using the methods proposed in [8]. In 4 out of 10
cases those methods failed. Using our algorithm, we
managed to find the MAP for all 4 cases.7
Figure 3 shows the dual objective and the decoded
integer solution after each MPLP iteration, for one set
of parameters.
In the results above, we added 20 squares at a time to
the relaxation. We next contrasted it with two strategies: one where we pick 20 random squares (not using our bound improvement criterion) and one where
we pick the single best square according to the bound
criterion. Figure 4 shows the resulting bound per iteration for one of the models. It can be seen that the
random method is much slower than the bound criterion based one, and that adding 20 squares at a time is
better than just one. We ended up adding 1060 squares
when adding 20 at a time, and 83 squares when adding
just one. Overall, adding 20 squares at a time turned
out to be faster.
We also tried running MPLP with all of the square
clusters.
Although fewer MPLP iterations were
needed, the cost of using all squares resulted in an
overall running time of about four times longer.

7

For one of these models, a few single node beliefs at
convergence were tied, and we used the junction tree algorithm to decode the tied nodes (see [8]).




Message-passing algorithms have emerged as
powerful techniques for approximate inference in graphical models. When these algorithms converge, they can be shown to
find local (or sometimes even global) optima
of variational formulations to the inference
problem. But many of the most popular
algorithms are not guaranteed to converge.
This has lead to recent interest in convergent
message-passing algorithms.
In this paper, we present a unified view of
convergent message-passing algorithms. We
present a simple derivation of an abstract
algorithm, tree-consistency bound optimization (TCBO) that is provably convergent in
both its sum and max product forms. We
then show that many of the existing convergent algorithms are instances of our TCBO
algorithm, and obtain novel convergent algorithms “for free” by exchanging maximizations and summations in existing algorithms.
In particular, we show that Wainwright’s
non-convergent sum-product algorithm for
tree based variational bounds, is actually
convergent with the right update order for
the case where trees are monotonic chains.

1

Introduction

Probabilistic inference in graphical models is a key
component in learning and using these models in practice. The two key inference problems are calculating
the marginals of a model and calculating its most likely
assignment (sometimes referred to as the MAP problem).
One approach to these generally intractable problems
is to use a variational formulation, where approximate

inference is cast as an optimization problem. For the
marginals case this usually corresponds to minimization of a free energy functional, and for the MAP problem it corresponds to solving a linear programming
(LP) relaxation [10].
A key challenge in both the MAP and marginals case
is to devise simple and scalable algorithms for solving the variational optimization problem. In recent
years numerous algorithms have been introduced for
both tasks. These algorithms typically have a “message passing like” structure.
Perhaps the most widely used message-passing algorithms are “belief propagation” and its generalizations [5, 8, 12, 14]. These algorithms typically have two
variants: sum-product which is used to approximate
the marginals, and max-product which is used to approximate the MAP. Fixed-points of these algorithms
can be shown to be local (or sometimes even global)
optima of the corresponding variational formulation.
Yet despite the spectacular empirical success of these
algorithms in real-world applications, they are not
guaranteed to converge, and variants of “dampening”
are often used to improve their convergence [8, 12, 14].
There has therefore been much recent work on convergent message passing algorithms [2, 5, 7, 13]. These algorithms are often very similar in structure to the nonconvergent algorithms and often include local maxproduct or sum-product operations. However, for each
of these specific algorithms it has been possible to
prove that the value of the variational problem (or its
dual) improves at each iteration. Perhaps the most intriguing example of this is Kolmogorov’s TRW-S algorithm [7] which is simply Wainwright’s tree-reweighted
max-product algorithm [11] with a different update
schedule.
Here we introduce a unifying framework which encompasses both marginals and MAP approximations,
by exploiting the mathematical similarities between
these approximations. Specifically, we provide an up-

394

MELTZER ET AL.

per bound on the optimum of the variational approximations, and give sufficient conditions that algorithms
need to satisfy in order to decrease this bound in a
monotone fashion. Any algorithm which satisfies these
conditions is guaranteed to decrease the upper bound
at every iteration. This property in turn guarantees
that such algorithms converge to a global optimum of
the variational problem in the marginals case and to a
local optimum in the MAP LP approximation case.
Our framework involves updating a subset of regions
which form a tree in the region graph. A related approach was recently suggested by Sontag et al. [9]
in the context of solving the MAP approximation.
Their work gives an explicit algorithm for optimizing
all edges corresponding to a tree in the original graph,
such that an upper bound on the LP optimum is decreased at every iteration. Our formalism does not give
an explicit update but rather conditions that guarantee an update to decrease the objective. However,
we show that these conditions are satisfied by several
known algorithms. Furthermore, since the condition
is similar in the marginals and MAP case (specifically
a condition of sum and max consistency respectively)
it is easy to obtain algorithms for both these cases simultaneously, and to use results in one problem for
obtaining algorithms for the other.
For instance, we consider the tree-reweighted (TRW)
free energy minimization problem [12]. Recently two
works have provided convergent algorithms for this
problem [1, 3], but these were more involved than standard message passing algorithms. Here we show the
surprising result that in fact the original algorithm
provided for TRW by Wainwright et al. is convergent, if run with an appropriate schedule of message
updates.

2

Bounds for MAP and Log-Partition

We consider a graphical model where the joint probability over variables p(x) factors
Q into a product over
clique potentials p(x) = Z1 α Ψα (xα ) or equivalently, the energy function
is a sum over clique enP
1
ergies p(x)
=
θ
(xα )). We also denote
exp(
α
α
Z
P
θ(x) = α θα (xα ).
The problem of calculating marginals and approximation of the partition function Z can be recast as the
following maximization problem of the function F (q)
(the negative of the free energy):
log Z = max F (q) = max (hθ(x)iq + H(q))
q

q

(1)

where q is the set of probability distributions over x,
hθ(x)iq is the average energy with respect to q and
H(q) is the entropy function. The maximizing argu-

UAI 2009

ment is then the distribution p(x).
This maximization is in general intractable, so approximate free energies are often used. A class of approximate free energies, discussed in [14], is based on the
concept of a region graph G whose nodes α are regions
of the original graph, and whose edges represent subregion relationships (i.e. an edge between α in β exists
only if β ⊂ α). The approximation replaces the joint
entropy H(q) with a linear combination of local region
entropies Hα (qα ) where each local entropy is weighted
by a “double-counting” number cα :
H̃G,c (q) =

X

cα Hα (qα ) ,

(2)

α

where the subscript G, c indicates the dependence of
the approximation on the region graph G and the
counting numbers cα .
With this approximation of H(q) the free energy now
only depends on local distributions, since the average energyPis a simple function of the qα , namely
hθ(x)iq =
α hθα (xα )iqα . To optimize only over local distributions qα , we need to consider only distributions such that there exists a q(x) that has these as
marginals. This set (called the marginal polytope [10])
cannot be expressed in a compact form, and is typically approximated. One popular approximation is the
local polytope of the region graph L(G) defined as the
set of local distributions that agree on the marginals
for any two regions in the region graph that are subsets
of each other:1
P
)
(
∀β ⊂ α, xβ
qα (xα ) = qβ (xβ )
xα \xβ
L(G) = q ≥ 0
P
∀α,
xα qα (xα ) = 1
Take together, this results in the following standard
variational approximation [10]:
X
max F̃ (q) = max
hθα (xα )iqα + H̃G,c (q) (3)
q∈L(G)

q∈L(G)

α

Similarly the MAP problem is approximated via
X
max F̃ (q) = max
hθα (xα )iqα
q∈L(G)

q∈L(G)

(4)

α

To obtain a unified formalism for MAP and marginals,
we use a temperature parameter T where T = 1 for
marginals and T = 0 for MAP and the optimization
is:
X
max F̃ (q) = max
hθα (xα )iqα + T H̃G,c (q) (5)
q∈L(G)

q∈L(G)

α

1
Note that this is the local polytope of the region graph
not the local polytope of the original graph

UAI 2009
2.1

MELTZER ET AL.

Positive Counting Numbers

The entropy approximation H̃G,c (q) in Eq. 2 is generally not a concave function of the local distributions q.
Thus maximization of F̃ (q) may result in local optima.
To avoid this undesirable property, several works (e.g.,
[5]) have focused on entropies which are obtained by
considering only concave H̃G,c (q) functions. We focus on approximations where all the double counting
numbers are non-negative. This is a strong restriction
but since we are working with a region graph formulation, many approximate free energies which have negative double counting numbers can be transformed into
ones with positive double counting numbers on a region graph. Perhaps the most important example are
tree-reweighted free energies inPwhich the entropy is
approximated as HT RBP (q) = τ ρτ Hτ (q) with ρτ a
probability distribution over trees in the graph and
Hτ (q) is the entropy of the distribution on τ with
marginals given by q (more precisely, the projection
of q on the tree τ ). If we consider a region graph
with trees and their intersection (Fig. 5) the double
counting numbers are non-negative.
ButP
HT RBP can
P
also be rewritten
H
=
ρ
H
+
T RBP
ij ij ij
i ci Hi with
P
ci = 1 − j ρij and ρij is the edge appearance probability of the edge ij under the distribution ρ. In this
case, the double-counting number for the singletons
ci may be negative. However, we will show that it is
sometimes advantageous to work in the representation
that uses a non-negative mixture of trees, since nonnegativity of the counting numbers allows a simpler
derivation of algorithms.
2.2

Optimization and Reparameterization

The vast majority of methods for solving the variational approximation are based on two classes of
constraints that local optima should satisfy. It is
easy to show using Lagrange multipliers, that local optima of F̃ should satisfy two types of constraints [5, 6, 12, 14, 15]
• Reparametrization Q
(or admissibility, or “e constraints”). P (x) ∝ α qα (xα )cα , for every x.

• sum-consistency
(or
“m
constraints”),
P
xα \xβ qα (xα ) = qβ (xβ ) for all β ⊂ α and
xβ .

By enforcing each of these constraints iteratively one
obtains many of the popular sum-product algorithms.
Replacing the sum-consistency constraint with maxconsistency gives many of the popular max-product
algorithms. A simple example is ordinary BP, which
maintains admissiblity at each iteration and a message
from i to j enforces consistency between bij and bj .

395

In general, simply iteratively enforcing constraints is
not guaranteed to give convergent algorithms. However, as we show in this paper, by iterating through
the constraints in a particular order, we obtain monotonically convergent algorithms.
2.3

Bound minimization and
reparameterizations

We begin by providing an upper bound on the logpartition function whose minimization is equivalent to
the maximization in Eq. 5.
We consider marginals bα of the exponential form:
bα (xα ; θ̃α ) =



1
exp θ̃α (xα )/cα
Zθ̃α

(6)

and require that these marginals will be admissible
(maintain the “e constraints”). We obtain admissibility by requiring that the variables θ̃ will satisfy the
following for each x:
X
X
θα (xα ) =
θ̃α (xα )
(7)
α

α

The algorithms we propose will optimize over the variables θ̃ while keeping the constraint in Eq. 7 satisfied
at all times. Moreover, they will monotonically decrease an upper bound on the optimum of Eq. 5. In
the following two lemmas we provide this bound for
the sum and max cases.
Lemma 1 The approximation to the log partition
function is bounded above by:
X
boundsum (θ̃) =
(8)
cα ln Zθ̃α
α

for any reparameterization θ̃ (i.e., any θ̃ satisfying
Eq. 7).
Minimizing boundsum (θ̃) over the set of reparameterizations θ̃ would give the approximated log-partition
function:
min boundsum (θ̃) = max F̃ (q)
θ̃

q∈L(G)

(9)

This is the optimum of Eq. 5 with T = 1.
Proof: Kolmogorov [7] showed that if θ̃ is a reparameterization (i.e. keeping the constraint in Eq. 7), it also
holds that hθ̃iq = hθiq for any q ∈ L(G). Using this
property, we can see that the log-partition function is
constant under reparameterization: F̃ (q; θ) = F̃ (q; θ̃)
for any q ∈ L(G), and in particular the maximum value

396

MELTZER ET AL.

will remain the same. Now, using the new variables θ̃
we have a trivial bound on the log-partition:

X
hθ̃α iqα + cα Hα (qα )
max F̃ (q; θ̃) = max
q∈L(G)

q∈L(G)

≤

X
α

Algorithm 1 The tree consistency bound optimization (TCBO) algorithm
Iterate over sub-graphs T of the region graph that have
a tree structure:

α

1. Choose a tree T



max hθ̃α iqα + cα Hα (qα )
qα

2. Update the values of θ̃αt+1 for all α ∈ T such that:

Since the counting numbers cα are non-negative, the
marginals defined in Eq. 6 maximize each local functional Fα (qα ; θ̃α , cα ) = hθ̃α iqα + cα Hα (qα ), and the
optimal value is cα ln Zθ̃α . Thus,
max F̃ (q; θ̃) ≤

q∈L(G)

X

cα ln Zθ̃α

• re-parameterization is maintained:
X
X
θ̃αt+1 (xα ) +
θ(x) =
θ̃αt (xα )
• tree-consistency is enforced:
Define the beliefs

(10)

α

t+1
bt+1
α (xα ; θ̃α ) =

or optimize the bound to the MAP by enforcing max-consistency:

q∈L(G)

t+1
t+1
t+1
max bt+1
α (xα ; θ̃α ) = bβ (xβ ; θ̃β )
xα\β

xα

Minimizing boundmax (θ̃) over the set of reparameterizations θ̃ would give the optimal value for the regiongraph LP relaxation of the MAP:
X
min boundmax (θ̃) = max
(12)
hθα (xα )iqα
α

This is the optimum of Eq. 5 with T = 0.
Proof: The bound follows directly P
from the admissiblity constraint so that maxx α θ̃α (xα ) ≤
P
α maxxα θ̃α (xα ). The fact that the tightest bound
coincides with the LP relaxation was proven in [13].
We note that the above two lemmas may also be
viewed as an outcome of convex duality. In other
words, the original variational maximization problem
and the equivalent bound minimization problem are
convex duals of each other.
In the following sections we provide a framework for
deriving minimization algorithms for the above two
bounds.

Zαt+1



exp θ̃αt+1 (xα )/cα

xα\β

Lemma 2 The value of the MAP is bounded above by:
X
boundmax (θ̃) =
(11)
max θ̃α (xα )
for any reparameterization θ̃ (i.e., any θ̃ satisfying
Eq. 7).

1

For each α ∈ T, β ∈ T, β ⊂ α and xβ , optimize the bound to the log-partition function
by enforcing sum-consistency:
X
t+1
t+1
t+1
bt+1
α (xα ; θ̃α ) = bβ (xβ ; θ̃β )

A similar result may be obtained for the MAP case
(this result or variants of it appeared in previous
works, e.g., [7, 9, 13]).

α

α6∈T

α∈T

The bound is tight if there exists a reparameterization θ̃ such that the marginals bα (xα ; θ̃α ) are sumconsistent (i.e. b ∈ L(G)). The existence of such a
re-parameterization is guaranteed if the maximum of
the approximated negative free energy F̃ (q; θ) does not
happen at an extreme point [14].

θ̃

UAI 2009

3

Bound optimization and consistency

We propose the tree consistency bound optimization
(TCBO) algorithm as a general framework for minimizing the bounds in Sec. 2.3 for the approximated
log-partition and for the MAP, within a region graph
with positive counting numbers cα .
The idea is to perform updates on trees that are subgraphs of the region-graph. The θ̃ corresponding to
each such tree will be updated simultaneously in a way
that will achieve a monotone decrease in the bound.
The method we propose, as described in Algorithm 1
keeps the beliefs admissible with the positive counting numbers cα (or equivalently, always maintains θ̃(x)
that reparameterize the original energy θ(x)). The corresponding θ̃ thus satisfy the conditions of the bound
in Sec. 2.3. Furthermore, at each iteration, max or sum
consistency of the beliefs is enforced for the subtree T .
As mentioned earlier, maintaining consistency on subsets does not generally result in convergent algorithms.
However, as the following lemmas show, in our case
enforcing consistency is equivalent to block coordinate

UAI 2009

MELTZER ET AL.

397

descent on the bound.
Lemma 3 The sum-consistency lemma: Consider the bound minimization problem for the logpartition function with positive counting numbers
(Lemma 1), defined on a subset of regions and intersections T . The part of the bound which is influenced
by the beliefs of the subset is:
X
P BT (θ̃T ) =
cα ln Zθ̃α
α∈T

The problem is to find {θ̃α } for all α ∈ T that minimize
P BT (θ̃T ) subject to θ̃ being reparameterizations of the
energy {θα }. If for some
θ̃∗ the be
 reparameterization

Figure 1: A simple 2x2 grid, with pair regions.
Proof: The part of the bound which is dependent on
θ̃T is bounded below:
P BT (θ̃T ) ≥ max θ̃T (xT )
xT

where

liefs b(xα ; θ̃α∗ ) ∝ exp θ̃α∗ /cα are sum-consistent, then
it minimizes the bound.

Proof: The part of the bound which is dependent on
θ̃T the is bounded below:
X
P BT (θ̃T ) =
max Fα (qα ; θ̃α , cα )
α∈T

≥

qα

max

qT ∈L(G)

X

Fα (qα ; θ̃α , cα )

α∈T

Now, if we find variables θ̃α for all α ∈ T such
that they provide global re-parameterization θ̃(x) =
θ(x) (so we can have a bound), and the marginals
bα (xα ; θ̃α ) ∝ exp(θ̃α (xα )/cα ) which maximize each
term Fα (qα ; θ̃α , cα ) separately are also sum-consistent
(bT ∈ L(G)), then P BT (θ̃T ) will achieve its optimal
value, and thus we perform block coordinate descent
on the bound.
Note that for optimizing the bound to the logpartition, the subset T does not have to form a tree,
and the sum-consistency of the beliefs is enough. Yet,
it may be easier in practice to enforce sum-consistency
on trees.
Lemma 4 The max-consistency lemma: Consider the bound minimization problem for MAP with
positive counting numbers (Lemma 2), defined on a
subset of regions and intersections that form a tree T .
The part of the bound which is influenced by the beliefs
of the tree is:
X
P BT (θ̃T ) =
max θ̃α (xα )
α∈T

xα

The problem is to find {θ̃α } for all α ∈ T that minimize
P BT (θ̃T ) subject to θ̃ being reparameterizations of the
energy {θα }. If for some
θ̃∗ the be
 reparameterization
liefs b(xα ; θ̃α∗ ) ∝ exp θ̃α∗ /cα are max-consistent, then
it minimizes the bound.

. X
θ̃α (xα )
θ̃T (xT ) =
α∈T

so if we can find an assignment x∗T whose cost θ̃T (x∗T )
equals P BT (θ̃T ), that means we have the tightest
bound. Now, if for some
θ̃T∗ the be
 reparameterization

liefs bα (xα ; θ̃α∗ ) ∝ exp θ̃α∗ /cα are max-marginalizable
then we can always find an assignment x∗T that sits on
the maxima of θ̃α∗ because the subgraph is a tree (so
there cannot be any frustrations). Hence, we obtain
θ̃T (x∗T ) = P BT (θ̃T∗ ), and the bound achieves its optimal value for the coordinates in T .
The above two lemmas show that the TCBO algorithm
monotonically decreases the bound after each update.
In the log-partition case, the bound is strictly convex
and thus this strategy finds the global minimum of
the bound which is the global maximum of Eq. 5. In
the MAP case, the function is not strictly convex and
the algorithm may converge to values that are not its
global optimum. This phenomenon is shared by most
dual descent algorithms (e.g., [2, 7, 13]).
TCBO is a general scheme and can be implemented
for different choices of tree sub-graphs. In the next
section we illustrate some possible choices and their
relation to known algorithms.

4

Existing bound minimizing
algorithms

We identify some existing convergent algorithms as instances of TCBO: Heskes’ algorithm [5] for approximating the marginals, and MPLP [2],TRW-S [7], maxsum diffusion (MSD) [13] for approximating MAP.
Figures 2-5 show the reparametrization, region graph
and the tree sub-graph updated at each iteration of
these algorithms, for the simple example of a 2x2
grid shown in Fig. 1. Note that all algorithms use
a reparameterization with positive double counting
numbers. Furthermore, they update only a subtree at

398

MELTZER ET AL.

Figure 2: Illustration of the max-sum-diffusion (MSD)
algorithm as an instance of the TCBO formalism.
MSD operates on a region graph containing pairs and
singletons (here corresponding to a 2x2 grid). The subgraph T corresponding to the TCBO update is shown
in the blue dashed line.

UAI 2009

Figure 3: Heskes’ sum-product algorithm may be
viewed as a TCBO algorithm updating the subtree
shown in the blue dashed line (a star graph centered
on a singleton node).
Algorithm 3 Heskes’ sum-product algorithm
Iterate over intersection regions β:

Algorithm 2 The max sum diffusion (MSD) algorithm
Iterate over edges between regions < α, β >:

1. ∀α ⊃ β set the message from α to β:

1. Set the message from α to β:

t+1
mα→β (xβ )

=

t
mα→β (xβ )

t+1
mα→β (xβ )

v
u
u maxxα\β btα (xα )
·t
btβ (xβ )

=

t
xα\β bα (xα )
mtβ→α (xβ )

P

2. Update the belief of the intersection region:
t+1

bβ

2. Update the beliefs:

(xβ ) ∝

”cα /ĉ
Y “ t+1
β
mα→β (xβ )

α⊃β
t+1

bβ

(xβ )

∝

t+1

mα→β (xβ ) ·

Y

t

mα′ →β (xβ )

α′ 6=α
t+1
bα (xα )

∝

Ψα (xα )
Q
t
mt+1
β ′ 6=β mα→β ′ (xβ )
α→β (xβ ) ·

3. ∀α ⊃ β set the messages to the parent regions and their beliefs:
t+1

mβ→α (xβ )

=

t+1
bα (xα )

∝

bt+1
(xβ )
β
mt+1
α→β (xβ )
1/cα

Ψα

t+1

(xα ) · mβ→α (xα )

Y

t

′

mβ ′ →α (xβ )

β ′ 6=β

a time. What remains to be shown is that each iteration achieves consistency among the beliefs (in other
words, it satisfies the conditions of TCBO framework
and thus monotonically decreases the corresponding
upper bound).
Heskes’ algorithm can be shown to be an instance of
TCBO using direct substitution. The update rules are
shown in algorithm 3. MPLP (algorithm 4) does not
appear at first sight to use the region graph illustrated
in Fig. 4, but rather works with edges and singletons.
However, as we show in the appendix, there is a way
to transform the messages used in the max-product
version of Heskes’s algorithm into messages of MPLP
using the MPLP region graph. The max-consistency
achieved by MSD (algorithm 2) can again be shown
directly.
It is also possible to use tree graphs (or forests) as
regions, and various existing methods indeed use this
approach. We may consider a TCBO algorithm which
iterates through all edges and nodes, and for each edge
or node enforces consistency between it and all trees
that contain it. This is illustrated in Fig. 5. A naive

implementation of such a scheme is costly, as it requires multiple tree updates for every edge. However,
Kolmogorov [7] showed that there exists an efficient
implementation (which he called TRW-S) of such a
scheme in the MAP case. This implementation may
only be applied if the trees are monotonic chains, defined as follows: given an ordering of the nodes in a
graph, a set of chains is monotonic if the order of nodes
in the chain respects the given ordering. This structure
allows one to reuse messages in a way that simultaneously implements operations on multiple trees. The
scheduling of messages is important for guaranteeing
convergence in this case. It turns out that one needs to
scan nodes along the pre-specified order, first forward
and then backward.
In the marginals case, the TRW algorithm of Wainwright [12] corresponds to optimizing over tree regions
but is not provably convergent. In the next section we
show how to derive a convergent algorithm for this case
using our formalism.

UAI 2009

MELTZER ET AL.

399

Figure 4: MPLP for pairs and singletons is equivalent
to Heskes’ algorithm with stars and pairs.
Algorithm 4 The max product linear programming
(MPLP) algorithm
Iterate over pairs of neighbouring nodes < ij >:
1. Set the message from i to < ij >:
t+1

mi→ij (xi ) =

t

Y

mik→i (xi )

k∈N (i)\j

and equivalently from j to < ij >
2. Update the pairwise beliefs of < ij >:
t+1

bij (xi , xj ) ∝

q
t+1
Ψij (xi , xj ) · mt+1
i→ij (xi ) · mj→ij (xj )

3. Set the messages from < ij > to i (and equivalently from
< ij > to j):
v
“
”
u
u max
Ψij (xi , xj ) · mt+1
xj
u
j→ij (xj )
t+1
mij→i (xi ) ∝ t
mt+1
i→ij (xi )
4. Set the beliefs of i (and same for j):
t+1

bi

t+1

(xi ) ∝ mij→i (xi ) ·

Y

t

mik→i (xi )

k∈N (i)\j

5

Figure 5: A region graph with chains, their pairwise
and singleton components. Such graphs are used by
the TRW-S algorithms. In the above example there
are two chains, which are also monotonic chains since
they agree with the node ordering {1, 2, 3, 4}. TRW-S
may be viewed as a TCBO algorithm on the subgraph
shown in the blue dashed line (and an additional subgraph corresponding to a pairwise component and all
the chains that contain it).
since it is an instance of a TCBO algorithm for the
sum case. Furthermore, this TRW-S variant differs
from the algorithm in [12] only in the scheduling of
messages.
An additional algorithm that can be easily shown to
be convergent is two way GBP [14] with all double
counting numbers cα = 1, both in the sum and in
the max versions. At each iteration, two-way GBP
updates only the beliefs of a region and one of its subregions, which is trivially a tree. The fact that it maintains reparameterization and enforces consistency can
be shown directly. In fact, it can be shown that two
way GBP with cα = 1 is identical to MSD.

New bound minimizing algorithms
6

By replacing the max with a sum (or vice versa) in
the algorithms discussed in the previous section, we
obtain algorithms that enforce a different type of consistency, and keep the same reparameterization and
region graph as shown in the figures. Thus, the maxproduct version of Heskes’ algorithm and the sumproduct versions of TRW-S, MPLP and MSD are convergent with respect to the relevant bound.
The TRW-S sum-product case is especially interesting. In this case the relevant bound becomes the treereweighted log-partition function bound introduced in
[12]. The message passing algorithm suggested in [12]
does not generally converge. In contrast, the TRWS sum-product algorithm is guaranteed to converge,

Experiments

We present two experiments to illustrate the convergence of our sum and max algorithms. All algorithms
were applied to an instance of a 10x10 “spin glass”
with pairwise terms drawn randomly from [−9, 9] and
field from [−1, 1]. In each case we tested the new
TCBO algorithms.
For estimating the log-partition, we ran TRW and considered a uniform distribution over 2 spanning forests
in the graph: all horizontal and all vertical chains.
These chains are monotone with respect to the node
ordering {1, 2, ..., 100}. We ran TRW-S by following
the nodes order first forward and then backward, updating each time only the messages in the direction of

400

MELTZER ET AL.

UAI 2009

Algorithm 5 The sequential tree reweighted BP (TRW-

940

S) algorithm

1/ρij

mi→j (xj ) ∝ max Ψi (xi )Ψij
xi

(xi , xj )

Q

ρik
k∈N (i)\j mk→i (xi )
1−ρ
mj→iij (xi )

2. After each iteration over all edges, update all singleton and
pairwise beliefs:
bi (xi )

∝

Ψi (xi )

Y

∝
·

ρ

ik (x )
mk→i
i

k∈N (i)\j
1−ρ
mj→iij (xi )

Q

ρ

jk
k∈N (j)\i mk→j (xj )

900
890
880

860
0

10

20

30
Iterations

40

50

60

1−ρ

mi→jij (xj )

the scan. Fig. 6 shows a comparison of this schedule to
TRW where the node ordering is followed in a forward
manner, and all outgoing messages are updated from
each node. Both schedules keep a re-parameterization
and provide a bound to the log-partition, yet only
TRW-S monotonically decreases it at each iteration.
For the MAP case, we ran the max-product version of
Heskes’ algorithm using a region graph of pairs (with
double counting numbers 1) and singletons (with double counting numbers 0). We also ran MPLP and MSD
on the same problem. Fig. 7 shows the bounds obtained after each iteration. As can be seen, all three
algorithms monotonically converged to the same value.

7

sum−TRW−S
sum−TRBP

910

870

1/ρ
Ψi (xi )Ψj (xj )Ψij ij (xi , xj )

Q

920

ρ

ij
mj→i
(xi )

j∈N (i)

bij (xi , xj )

Bound to Log−Partition

930

1. Iterate over edges i → j in a certain updating order, and set
the message from i to j:

Discussion

Despite the empirical success of max-product and sumproduct algorithms in applications, the original algorithms are not guaranteed to converge. Much research
in recent years has therefore been devoted to devising convergent algorithms. Typically these recent algorithms are either max-product or sum-product and
their proof of convergence is specific to the algorithm.
Here we have presented a unified framework for convergent message passing algorithms and showed the importance of enforcing consistency in both sum-product
and max-product algorithms. Not only does this analogy allow us to give a unified derivation for existing
algorithms, it also gives an easy way to derive novel algorithms from existing ones by exchanging maximizations and summations.
Although many convergent algorithms are instances
of our framework, it is worth pointing out two convergent algorithms that are not. The first is Hazan and
Shashua’s recent algorithm [3, 4] which works for provably convex double counting numbers (not necessarily

Figure 6: The bound on the log-partition in a
10x10 “spin-glass”, obtained by sum-product TRW
and TRW-S with edge probability appearances of 1/2.
Note that the two algorithms differ only in the order
of updates they perform. TRW-S follows the node ordering {1, 2, ..., 100} that agrees with the monotonic
chains, first forward and then backward. In the TRW
implementation we followed the same nodes order in a
forward manner.

positive as we are assuming). The second is ordinary
BP on a single cycle, which can be shown to be convergent in both its sum and max product forms. We
emphasize that even negative counting numbers can be
handled by us in some cases, by using larger regions.
All the algorithms we discussed here in fact only updated star graphs in the region graph. Our conditions
for monotonicity apply to general tree updates. However, it seems less straightforward to obtain general
(non-star) tree updates that achieve (max or sum) consistency and reparameterization simultaneously. Interestingly, the tree based updates in [9] do monotonically
decrease an upper bound but seem not to satisfy maxconsistency. Thus, it remains an interesting challenge
to find general tree updates that satisfy the consistency
constraints, as these could be easily used interchangeably for MAP and marginals.
Perhaps the most intriguing result of our analysis is
the importance of update schedule for obtaining convergence – a non-convergent algorithm becomes convergent when the right update schedule is used. It
will be interesting to see whether convergent update
schedules can be derived for an even larger class of
message-passing algorithms.

UAI 2009

MELTZER ET AL.

clusters and “hyper stars” respectively, in which the
centers are the intersections of the clusters.

890
885


