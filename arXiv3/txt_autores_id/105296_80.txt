

Recent research on the Symbolic Probabilis­
tic Inference (SPI) algorithm[;:] has focused
attention on the importance of resolving
general queries in Bayesian networks. SPI
applies the concept of dependency-directed
backward search to probabilistic inference,
and is incremental with respect to both
queries and observations. In response to
this research we have extended the evidence
potential algorithm [3] with the same fea­
tures. We call the extension symbolic evi­
dence potential inference (SEPI). SEPI like
SPI can handle generic queries and is incre­
mental with respect to queries and observa­
tions. While in SPI, operations are done on
a search tree constructed from the nodes of
the original network, in SEPI, a clique-tree
structure obtained from the evidence poten­
tial algorithm [3] is the basic framework for
recursive query processing.
In this paper, we describe the systematic
query and caching procedure of SEPI. SEPI
begins with finding a clique tree from a
Bayesian network - the standard procedure
of the evidence potential algorithm. With
the clique tree, various probability distribu­
tions are computed and stored in each clique.
This is the "pre-processing" step of SEPI.
Once this step is done, the query can then
be computed. To process a query, a recursive
process similar to the SPI algorithm is used.
The queries are directed to the root clique
and decomposed into queries for the clique's
subtrees until a particular query can be an­
swered at the clique at which it is directed.
The algorithm and the computation are sim­
ple. The SEPI algorithm will be presented in
this paper along with several examples.

1

Introduction

The Bayesian networks technology provides a rep­
resentation language for uncertain beliefs and infer­
ence algorithms for drawing sound conclusions from
such representations. Bayesian Network is a directed,
acyclic graph in which the nodes represent random
variables, and the arcs between the nodes represent
possible probabilistic dependence between the vari­
ables. The success of the representation is mainly
due to the development of many probabilistic infer­
ence algorithms [3, 4, 5, 6]. While most of the algo­
rithms can efficiently perform simple queries such as
the marginal probability of each node given evidence,
they have not efficiently addressed the problem of more
general queries such as joint or conditional probabili­
ties of any combination of nodes.
The recent work of Symbolic Probabilistic Inference
(SPI) [1, 2] has made a significant step in this direc­
tion. SPI is a goal-driven method which is incremen­
tal with respect to both queries and observations. In
response to this research we have extended the evi­
dence potential (EP) algorithm [3] with the same fea­
tures. We call the extension symbolic evidence poten­
tial inference (SEPI). Unlike traditional Bayesian Net
inferencing algorithms, both SPI and SEPI are goal
directed, performing only those calculations that are
required to respond to queries. While in SPI, opera­
tions are done on a search tree constructed from the
original network, in SEPI, a clique-tree structure ob­
tained from the EP algorithm is the basic framework
for recursive query processing.
In SEPI, the EP algorithm [3] is used as the "pre­
processing" step in which various probabilities such as
"set-chain" conditional [3) and marginal probabilities
of each clique are computed based on the clique tree.
The second step in SEPI is to process the query with
a recursive mechanism similar to the SPI algorithm.
A query is directed to the root clique and decomposed
into queries for the clique's subtrees. This recursive
process continues until a particular query can be an­
swered at the clique at which it is directed. The answer

Symbolic Probabilistic Inference with Evidence Potential

is then computed and returned to the next higher level
in the clique tree. Once a clique has responses from
all of its subtrees it can compute its own response to
its predecessor clique. This process terminates when
the root clique processes all the responses from its sub­
trees.
With similar mechanisms for caching and incorporat­
ing evidence as in SPI, the calculation in SEPI is also
incremental with respect to both query and evidences.
However, since all the necessary probability distribu­
tions are stored in the "pre-processing" step, the SEPI
algorithm is more efficient.
The paper is organized as follows. Section 2 briefly de­
scribes the EP algorithm which includes the construc­
tion of the clique tree. Section 3 describes the SEPI
algorithm. A systematic recursive query and caching
procedure will be presented. Some illustrative exam­
ples are given in Section 4, followed by the concluding
remarks in Section 5.
2

Evidence Potential Algorithm

In this section, we will briefly review the evidence po­
tential (EP) algorithm [3]. The algorithm first orga­
nizes the original network into clique tree, where each
clique is a group of nodes not necessary mutually ex­
clusive. It then performs inference by passing messages
between cliques in a similar way to the distributed al­
gorithm [4].
The first part of the algorithm is to form a clique tree.
This part consists of five steps
1. Marry Parents: link predecessors of a node to­
gether
2. Remove Arc Directions: remove directions of all
arcs
3. Fill in: generate new arcs between nodes when­
ever necessary to form a "perfect" graph
4. Find Cliques: form node clusters/cliques
5. Order Cliques, and Find Residuals and Separa­
tors: form cluster tree
After the clique tree is formed, the second part of the
algorithm is to calculate the marginal probability of
each node. Before this can be done, the "evidence
potential" and "separator potential" likelihoods [3] are
calculated for each cluster.
The second part of the algorithm consists of the fol­
lowing:
1. Calculating Evidence Potentials and Separator
potentials: they are calculated from the prior
node conditionals in each clique.
2. Calculate Set-Chain Conditionals: namely, the
conditional probability of the residuals given the

Figure 1: A Example Network
separators of each clique.
3. Calculate Joint Probability for each clique: from
joint, we then can calculate individual node pos­
teriors (marginal) probability.
To illustrate this algorithm, the example given in [3]
is shown in Figure 1. The corresponding clique tree
and the set-chain conditional of each clique is shown
in Figure 2. It is clear that the joint probability of
the whole network can be obtained by multiplying all
the set-chain conditionals together with the marginal
probabilities of all the root cliques. Any query can
then be obtained from the joint probability. The basic
idea of EP algorithm is to decompose and factor the
original formulae so that only minimum operations are
required to answer the queries.
3

Symbolic Inference with Evidence
Potential

The procedure described in the previous section can
be considered as the pre-processing step for the generic
query algorithm to be described. We call this new al­
gorithm symbolic evidence potential inference (SEPI).
In this algorithm, the goal is to calculate the results of
arbitrary queries. The idea is to derive an efficient in­
ference algorithm which takes advantage of the clique­
tree structure of the EP algorithm.
The SEPI algorithm consists of several major process­
ing steps. The first step is to organize the nodes of
a Bayesian network into a clique tree structure and

83

84

Chang and fung

Note that if the successor clique has nothing to do with
the query, i.e., (Z \Co) n T(C;)
0, then no query
will be sent to that clique.
=

P(LE!T)

At the clique C;, when the request arrives for a prob­
ability distribution represented by P{XIS;}, if such
a distribution had already been computed earlier and
cached, it can be returned immediately. However, usu­
ally it will be necessary to send requests to the clique's
successors in order to compute the response. Since it
can be easily shown that

P(B/LE)

P{XIS;}

=

Lfl P(XnT(C,.i)IS;j)P(Rc,IS;)
Rei

j

(4)

where Rc, is the residual nodes of C;, C;j is the j- th
child clique of C;, and S;j is the separators between
C; and C;j, the request to each child C;j will be
P(XnT(C;i)IS;j)·
(5)
The recursive process continues until it reaches the leaf
node or the request can be answered from the cached
results.

Figure 2: Cluster Tree and Set-Chain Conditional
calculate and store the various probability functions
as described in the previous section (e.g., set-chain
conditional and joint probability distribution). In the
second step, queries from the user are directed to the
root clique of the tree. The query is decomposed into
queries for the clique's subtrees. This recursive pro­
cedure continues until a particular query can be an­
swered.
The general format for a query received by SEPI is as
a conditional probability, namely, P{XIY}, where X
and Y are sets of nodes in the network. This query is
first transformed into joint distribution format P(Z)::::
P{X, Y} and directed to the root clique. In order to
answer the query, it would be sufficient to calculate
P(Z \ CoiC0), where Co is the root clique. This is
because we can calculate the query by
P(Z)

=

L

P(Z \CaiCo)P(Co)

(1)

Co\Z

where the prior probability P(Co) is available at the
clique Co. According to the EP algorithm, the clique
tree is organized in a way that the separators are the
overlapping nodes between the successor and prede­
cessor cliques. Denote the separators between the root
clique and the child clique C; as S;, then
P(Z \CaiCo)

=

P(Z \Co IS;)

To handle the evidence, just substitute the observed
values into all the clique distributions involving the
observed node. This operation is very simple in which
the particular dimension of the observed value is sim­
ply eliminated and the rest of the distribution remain
the same. The substitution needs to be done for all
the distributions including the cached results stored
in each clique which involves the observed node. Af­
ter the substitution, all the other operations can be
applied on distributions with the reduced dimensions.
As in the SPI algorithm, three major operations are
needed in the SEPI algorithm: multiplication, sum­
mation and substitution. Multiplication calculates the
product of two distributions, summation calculates the
sum of a distribution over a set of variables, and substi­
tution calculates the result of substituting an observed
value for a node into a distribution.
Examples

4

With the network given in Figure 1, we will now il­
lustrate the SEPI algorithm with several query exam­
ples. First, assuming the query we are interested is
P(AXS), the recursive algorithm works as follows.
•

•

(2)

Define T(Ci) as all the nodes in the subtree rooted
from C;, then the new request to be sent to each child
C; is
P((Z \Co) n T(C;)IS;)
(3)

•

The query P(AXS) is received at the root clique
(AT), based on eqn. (2) and (3), a new query
P(XSIT) is generated and sent to the successor
clique (TLE)
The query P(XSIT) is received at the clique
(TLE); similarly, a new query P(XSILE) is gen­
erated and sent to the successor clique (LEB)
The query P(XSILE) is received at the clique
(LEB), based on (5), new queries P(SIBL) and
P(XIEB) are generated and sent to the successors
(BLS) and (EBD) respectively.

Symbolic Probabilistic Inference with Evidence Potential

•

- The query P(SIBL) is received at the clique
(BLS) which is available in the cache due to
the pre-processing.
- The query P(XIEB) is received at clique
(EBD), a new query P(XIE) is generated
and sent to the successor clique (EX)
- The query P(XIE) is received at clique (EX)
which is available.
At clique (EBD), compute the query P(XIEB)
by
(6)
P(XIEB) 2::: P(XIE)P(DIBE)
D

evidence and have good potential for parallel process­
ing.
In this paper, we develop a similar query algorithm
based on the combination of evidence potential algo­
rithm and the SPI inference mechanism. Rather than
converting the network into a SPI search tree, we con­
struct a "clique tree" based on the evidence potential
algorithm. Additionally, the evidence potential algo­
rithm is used as the pre-processing step where all the
necessary probability distributions for answering the
query are computed and stored in each clique.

=

•

At clique (LEB), compute the query P(XSILE)
by
P(X SILE)

•

=

2::: P(SIBL)P(XIEB)P(BILE)
B

(7)
At clique (TLE), compute the query P(XSIT) by
P(XSIT)

=

2::: P(XSILE)P(LEIT)

(8)

LE
•

At root clique ( AT), compute the query P(AXS)

by

P(AXS)

=

2::: P(XSIT)P(AT)

(9)

T

Assume in the second example that the node E is
observed and the observed value is E•. To calcu­
late the posterior probability of the same query, we
first substitute the observed value into all the distri­
butions in the cliques related to the observed node.
These include P(DIBE), P(BILE), and P(LEIT) in
the cliques (TLE), (LEB), and (EBD) respectively.
The substitution operation simply eliminates the par­
ticular dimension corresponding to the observed value
in the distributions. Then the same procedure as de­
scribed above to calculate the query can be applied
using the distributions with new reduced dimensions.
The result is therefore,
P(AXSIE E•)
LT LL [LB [P(SIBL) LD [p(XIE.)P(DIBE•)J
P(BILE•)J P(LE.IT)] P(AT)
(10)
=

5

=

Conclusion

SPI algorithm [1, 2] is the latest inference algorithms
in which the emphasis is on the efficient generic query.
The main goal of these algorithms is to respond to
arbitrary queries in an efficient manner. In these al­
gorithms the network is first converted into a search
tree and the probabilities are manipulated by symbol­
ically decomposing or factoring the formulae. These
methods are incremental with respect to queries and

Similar to the SPI algorithm, queries are directed to
the root clique of the tree. They are decomposed into
queries for the clique's subtrees. This recursive pro­
cedure continues until a particular query can be an­
swered. The answer is then computed and returned to
the next higher level. The algorithm and the computa­
tion are simple. With a similar mechanism for caching
and incorporating eviden.ce as in the SPI algorithm,
the calculation is also incremental with respect to both
query and evidence. However, the SEPI algorithm is
more efficient since all the necessary probability distri­
butions are stored in the pre-processing step. A ver­
sion of the SEPI algorithm as well as the SPI algorithm
have been implemented, preliminary results from sev­
eral examples show that with the prep-processing step,
the query process of the SEPI algorithm is faster than
the SPI algorithm.




Research on Symbolic Probabilistic Inference
(SPI) [2, 3) has provided an algorithm for re­
solving general queries in Bayesian networks.
SPI applies the concept of dependency­
directed backward search to probabilistic in­
ference, and is incremental with respect to
both queries and observations. Unlike tra­
ditional Bayesian network inferencing algo­
rithms, SPI algorithm is goal directed, per­
forming only those calculations that are re­
quired to respond to queries. Research to
date on SPI applies to Bayesian networks
with discrete-valued variables and does not
address variables with continuous values.
In this paper1, we extend the SPI algorithm
to handle Bayesian networks made up of
continuous variables where the relationships
between the variables are restricted to be
"linear gaussian". We call this variation of
the SPI algorithm, SPI Continuous (SPIC).
SPIC modifies the three basic SPI opera­
tions: multiplication, summation, and sub­
stitution. However, SPIC retains the frame­
work of the SPI algorithm, namely building
the search tree and recursive query mecha­
nism and therefore retains the goal-directed
and incrementality features of SPI.
1

Introduction

The Bayesian networks technology provides a language
for representing uncertain beliefs and inference algo­
rithms for drawing sound conclusions from such repre­
sentations. A Bayesian network is a directed, acyclic
graph in which the nodes represent random variables,
and the arcs between the nodes represent possible
probabilistic dependence between the variables. The
1 This work is based on research supported by
WRDC under Contract F33615-90-C-1482.

success of the technology is in part due to the devel­
opment of efficient probabilistic inference algorithms
[5, 6, 7). These algorithms have for the most part been
designed to efficiently compute the posterior proba­
bility of each node or the result of simple arbitrary
queries. They have not efficiently addressed the more
general problem of answering multiple queries with re­
spect to differing sets of evidence.
Recent research in Symbolic Probabilistic Inference
(SPI) [2, 3) has made a significant step in this direc­
tion. Unlike traditional Bayesian network inference
algorithms, SPI algorithm is goal directed, performing
only those calculations that are required to respond to
queries. In addition, SPI is incremental with respect to
both queries and observations. However, the research
to date on SPI applies only to Bayesian networks with
discrete-valued variables.
There have been several inference algorithms designed
to handle networks that are made up of continuous
variables where the relationships between the variables
are restricted to be "linear gaussian". The algorithms
include the distributed algorithm (7] and the influence
diagram approach (4, 8).
In this paper, we extend the SPI algorithm to perform
this function-handle Bayesian networks with contin­
uous linear gaussian variables. We call the extension,
SPI Continuous (SPIC). The framework of this algo­
rithm is the same as that for SPI. However, the ba­
sic SPI operations of multiplication, integration and
substitution are quite different. Because SPIC stays
within the SPI framework, the goal-directed and in­
crementality features of the algorithm are preserved.
The paper is organized as follows. Section 2 briefly
summarize the SPI algorithm which includes the con­
struction of the SPI node tree and the recursive query
processing. Section 3 describes the new algorithm with
continuous variables. The representation are described
as well as the "basic" operations. Finally, some con­
cluding remarks are given in Section 4.

78

Chang and fung

2

Overview of the SPI Algorithm

The SPI algorithm consists of several major process­
ing steps. The first step is to organize the nodes of a
Bayesian network into a tree structure for query pro­
cessing. We call these structures SPI trees. In the
second step, queries are directed to the root node of
the SPI tree. The query is decomposed into queries
for the node's subtrees. This recursive procedure con­
tinues until a particular query can be answered at the
node at which it is directed. The answer is then com­
puted and returned to the next higher level in the SPI
tree. Once a node has responses from all of its sub­
trees it can compute its own response to its predeces­
sor node. This process terminates when the root node
processes all the responses from its subtrees.
An SPI tree is constructed by organizing the nodes of
a Bayesian network into a tree structure. The only
constraint on the construction process is that if there
is an arc between two nodes in the original network,
then one of the nodes must be a direct or indirect pre­
decessor of the other in the SPI tree. This constraint
allows many possible SPI trees.
The first step in building a SPI tree is to choose the
root node. This done by computing the maximum
node to node distance for each node. The node that
has the smallest maximum distance is chosen as the
root node. This heuristic is designed to produce a.
"bushy" SPI tree which can take advantage of dis­
tributed processing. The second step is to use max­
imum cardinality search [9] to build the tree from the
root node. This step constructs the tree based on the
connectivity principle and guarantees satisfaction of
the tree construction constraint.

Figure 1: An Example Network

The general format for a query received by SPI is as
a conditional probability, namely, P{XIY}, where X
and Y are sub sets of nodes in the Bayesian networks.
To be processed by SPI, queries of this form are first
transformed into another format. The format consists
of two set of nodes L and M which satisfy:
M=(XUY)nD(L)

(1)
where X= MnL, Y =M\L, and D(L) is the dimen­
sion of the distribution associated with the node set L.
Intuitively, L represents the minimum set of node dis­
tributions needed to respond to the query and M is
dimension of the desired response. L and M can be
computed in linear time and are simple to implement
[3]. Figure 1 and 2 show a simple Bayesian network
and the corresponding SPI tree. For example, if the
query is to find the joint probability of a1 and c2, the
query being sent to the root node will be consisting of
L = {a1,a2,c1,c2} and M= {a1,c2}.
The heart of the SPI algorithm is as follows; at any
node i, a request arrives for a probability distribution
represented by L and M, the algorithm responds to
the request by computing the "generalized" distribu-

Figure 2: The SPI tree

Symbolic Probabilistic Inference with Continuous Variables

tion Q(M) [3]. Q(M) is obtained by multiplying the
distributions in node L and summing over dimensions
L \ M. If such a distribution had already been com­
puted earlier and cached, it can be returned immedi­
ately. However, usually it will be necessary to send
requests to node's successors in the SPI tree in order
to compute the response. It is obvious that if a par­
ticular subtree has nothing to do with the query (i.e.,
there is no intersection), then no query will be sent to
that subtree. For the same example above, the query
can be obtained as,
Q(a1,c2)

= 1l"a1

L 1l"a01l"c11l"c,

(2)

where 1r; represents the probability distribution asso­
ciated with node i. There are three major operations
in SPI algorithm: multiplication, summation and sub­
stitution. Multiplication calculates the product of two
distributions; summation calculates the sum of a dis­
tribution over a set of variables; and substitution cal­
culates the result of substituting an observed value for
a node into a distribution. For networks with con­
tinuous variables, the SPI algorithm can be applied
directly. However the multiplication, summation, and
substitution operations must be modified. In the next
section, we will describe the corresponding multiplica­
tion, integration, and substitution operations for the
networks with continuous variables.
3

The SPI with Continuous Variables

Algorithm

The continuous SPI (SPIC) algorithm requires redef­
inition of the SPI operations: multiplication, integra­
tion, and substitution. The general mechanism for the
continuous SPI algorithm is basically the same as the
discrete one except for the caching operation and the
handling of evidence. We first describe the representa­
tion for conditional probability distributions in linear
gaussian continuous variables and then the three op­
erations in detail.
3.1

Node Representation

A SPIC node represents a vector of continuous vari­
ables. SPIC restricts the conditional probability dis­
tribution of each node to be "linear gaussian". "Linear
gaussian" distributions are the sum of a deterministic
component and a probabilistic component. The de­
terministic component is a linear combination of the
node's predecessor values. The probabilistic compo­
nent is restricted to be gaussian (i.e., normal) which
can be specified with mean vectors and covariance ma­
trices. For a Bayesian network of this type, the nec­
essary prior information needed before any inference
can be drawn are the the prior distributions of the
root nodes (i.e., mean and covariance) and the links
between nodes in the network.

For example, for a random vector represented by a
node x, if it is a root node, only mean x and the corre­
sponding covariance matrix Q, need to be specified. If
it is not a root node, and has a set of predecessor nodes
x�, .. , x�, then the relation between xand its predeces­
sors represented by the following linear equation need
to be specified,
x= Btx{ + .. + BNxj, + w,

(3)

where B1, .. , BN are constant transition matrices rep­
resenting the relative contribution made by each of
the predecessor variables to the determination of the
dependent variable x, and w, is a noise vector sum­
marizing other factors affecting x. w, is assumed to
be normally distributed with mean x and covariance
Q,. For most applications, w, will have a zero mean.
However this is not always true apriori and can occur
when distributions are multiplied together (e.g., a root
node and a non-root node).
For each node xin a network, the sufficient informa­
tion describing the node itself and the relationship to
its predecessors can therefore be represented in the fol­
lowing form:
(4)
With this simple representation, we will then describe
the multiplication, integration, and substitution oper­
ations.
3.2

Multiplication

In this section, we describe the multiplication oper­
ation for SPIC. We describe when distributions can
be multiplied, what the result will look like, and then
describe in detail how each part of the result is com­
puted.
There is a constraint on what distributions can be mul­
tiplied. This constraint called "combinability" was de­
veloped in [1]. According to the theorem derived in [1],
a set of nodes S is "combinable" (i.e., able to be ag­
gregated) if and only if every pair of nodes in the set
is combinable. Two nodes are combinable if all nodes
in the path(s) between the two nodes are in the setS.
It can be shown that if the set of nodes corresponding
to the distributions to be multiplied are "combinable",
then multiplying the distributions is the same as find­
ing the "joint" distribution of those nodes, or in other
words, to find the new probability representation of
the "combined" node.
Based on the separation principle in the SPI tree (i.e.,
any node separate its successors rooted from itself )
(3], it can be easily shown that any distributions that
will be multiplied from any query request during SPI
processing are always combinable. In other words, we
can transform the multiplication operation in SPI al­
gorithm into a node combination operation for the con­
tinuous nodes.

79

80

Chang and fung

The dimension of the resulting distribution will be the
sum of the dimensions of those nodes to be multiplied.
For instance, two representations of nodes (variables)
x1 and x2 each with dimension D(xt) and D(x2) are
to be multiplied, the resulting representation will have
dimension D(xt) + D(x2) , which can be interpretated
as the description of the combined variable xwith x1
stack over x2, i.e., x=

[ :� ] . The question now is

how to calculate the new probability representation of
xbased on the old ones of x1 and x2• It is dear that
this is nothing but to identify the new predecessors xr
of x and calculate the links B; between x and the new
predecessors as well as to calculate the new conditional
mean x and the associated covariance Qx.
F irst of all, the new predecessors of xis just the union
of the predecessors of x1and x2 (excluding Xi or X2
when one is the direct predecessor of the other).· The
new linear relation (coefficients) between xand xf are
obtained based on the old links. Conceptually, this can
be accomplished by first breaking down the combined
node into the original element nodes, and then find
the relation between the predecessor and the element
nodes individually. To do so, all paths between the
predecessor and the desired element node are found
and then combined together. The contribution of a
path is obtained by multiplying the transition matrices
of links along the path in the original network.
The mean and associated noise covariance matrix for
the combined node is the last part of the representa­
tion that needs to be calculated. The first quantity
that requires computation is the implicit linear rela­
tionship T between the two nodes that are to be mul­
tiplied. Based on the SPI tree structure, it can be
shown that the T for two nodes is non-zero only when
one node is the direct or indirect predecessor of the
other. If the nodes do stand in this relation, T can be
calculated by first finding all paths between the two
nodes and adding the contribution from all paths. As
in the process for finding the link coefficients for the
new predecessors, the path contributions are obtained
by multiplying together the transition matrices of links
along the path. Given T, the new mean and covari­
ance matrix of x can be obtained as below, given that
x1 is the direct or indirect predecessor of x2.

C!2 =

[ 2CC1]

(7)
where c12 is the "combined node", Txy are the links
(transition matrices) between xand y, and a1 and a2
are the new predecessors. In addition to the links ob­
tained as above, the new conditional mean and corre­
sponding covariance are obtained as,
(8)
which is zero since both c-1and c2 are zeros, and

(9)
In the discrete case, multiplying distributions can be
expensive since the size of the resulting distribution
grows exponentially with the number of distribution
(nodes) to be multiplied. However, in the linear gaus­
sian case, the resulting representation only increases
quadratically. This is because a gaussian distribution
can be sufficiently represented by a mean vector and
a covariance matrix.
3.3

Integration

The integration operation is relatively simple. All
one has to do is to identify and keep the appropriate
slots from the representation (i.e., links to predeces­
sors, mean, and covariance) and discard the rest of
them. It can be easily shown that the reduced repre­
sentation precisely describes the resulting distribution
after the integration. For example, for the distribution
of the combined node c1 2 obtained from the multipli­
cation above. If the goal is to integrate c1 out of the
joint probability representation, all one has to do is
to grab the appropriate slots from the links to a, and
a2, the mean vector c12, and the covariance matrix
Qc1•2 These slots are corresponding to the c2 vari­
able, namely,

(5)

Q X-

[ TQQx,x,

' T'
QX}
TQx,T + Qx,

]

(11)
(6)

For example, the results of multiplying 'll"e1 and 'll"e, of
the previous example given in F igure 1 can be repre­
sented by

and
(12)
3.4

Substitution

Evidence is represented in the form of exact observa­
tion of the values of variables. The set of variables

Symbolic Probabilistic Inference with Continuous Variables

which have been observed is denoted by E. One easy
way of incorporating evidence is to include evidence in
the query, for instance, P{XIY, E} and then substitute
the observed values E* for E after the more general
query is computed. Suppose the query results before
the substitution of the observation is represented as

(13)
with the associated covariance matrix :!::x. To "sub­
stitute" the observation E*, we first remove the link
KE from the representation, then replace the mean
X by X + KEE*. The covariance matrix remains
the same. It can be easily shown that the new rep­
resentation correctly describe the results of the query,
P{XIY,E = E*}. Other more efficient methods such
as to do substitution before query are currently under
our investigation.
4

Conclusion

Recent research in Symbolic Probabilistic Inference
(SPI) has made a significant step in improving effi­
ciency of general query processing. Unlike traditional
inference algorithms, SPI algorithm is goal directed,
performing only those calculations that are required
to respond to queries. In addition, SPI is incremental
with respect to both queries and observations. In this
paper, we extent the SPI algorithm to handle Bayesian
networks with linear gaussian variables. We call the
algorithm SPIC. The framework of this algorithm is
the same as that for SPI. However, the basic opera­
tions of multiplication, integration and handling ob­
servation are quite different. The equivalent operation
to the multiplication of discrete case is similar to the
"node combination" operation in the continuous case
and the equivalent operation to the summation of dis­
crete case is the integration operation. Because SPIC
stays within the SPI framework, the goal-directed and
incrementality features of the algorithm are preserved.
In this paper, we have only addressed the problem
of continuous variables that are restricted to have
linear gaussian models. Many real-world problems
may require nonlinear or nongaussian models. Classi­
cal methods such as approximation with linearization
(e.g., extended Kalman filters) or sum of gaussians de­
serve attention in further investigation. A version of
the SPIC algorithm has been implemented, prelimi­
nary results show expected performance.



for probabilistic, concept-based information retrieval

W hile concept-based methods for information re­

ically generate relationships between concepts and

trieval can provide improved performance over more
conventional techniques, they require large amounts
of effort to acquire the concepts and their qualitative
and quantitative relationships.
This paper discusses an architecture for probabilistic
concept-based information retrieval which addresses
the knowledge acquisition problem. The architecture
makes use of the probabilistic networks technology
for representing and reasoning about concepts and in­

I
I
I
I
I
I
I
I

cludes a knowledge acquisition component which par­
tially automates the construction of concept knowl­
edge bases from data.
We describe two experiments that apply the architec­
ture to the task of retrieving documents about terror­
ism from a set of documents from the Reuters news
service.

The experiments provide positive evidence

that the architecture design is feasible and that there
are advantages to concept-based methods.

(henceforth PCIR) that can be used first

to automat­

then reason about them given the evidence provided
by individual documents. As in our previous research
on concept-based methods

[12, 16, 17],

our goal has

been to develop techniques that can be used to sup­
port a specific class of information retrieval problems.
Specifically, we believe that the ideas we present here
can form the basis for an effective sy stem to assist
users in sorting through large volumes of time sensi­
tive material. We have in mind such applications as
the day-to-day monitoring of newswires for specific
topics of interest.
The architecture of a generic concept-based system
is shown in Figure

1.

A knowledge base contains a

set of concepts together with their qualitative

(i.e.,

structural) and quantitative relationships with other
concepts.

Queries specify a user's information need

in terms of these concepts. When a new document
is presented with respect to a particular query, fea­
tures are extracted from the document. The features
currently used are the presence or absence of certain

Introduction

1

In this paper we describe some preliminary research
on the use of probabilistic networks for information
retrieval. In particular, we introduce an architecture
·

•Trus work was funded by ADS' Internal Research and De­

velopment Program..

key words, and these features constitute evidence for
the presence of concepts in the document. Using the
features extracted from the document and the sys­
tem knowledge base, inference is performed to assess
the impact of the evidence on the belief in the query
concept.

The documents are sorted by belief and

retrieved by a user-specified rule
"best" ten ) .

(e.g.,

retrieve the

393

I
I
I
I
I
I

Figure 1: Generic Concept-Ba6ed Architecture for IR
Thus, concept-based methods view information re­
trieval primarily as a problem of evidential reason­
ing. However, while they can provide improved per­
formance over more conventional techniques, they do
require large amounts of effort to acquire the con­
cepts and their relationships. Our current research
attempts to address this weakness with the use of
new probabilistic methods to represent, reason about,
and learn the relationships between concepts. While
probabilistic methods have been recognized as an im­
portant evidential reasoning technology with well­
defined semantics (e.g., frequency, strength-of-belief)
and solid theoretical foundations, they have often
been passed over because of their computational com­
plexity. Their use in information retrieval has also
been limited, although many authors have recognized
the benefits of employing such techniques [2, 11; 14].
The probabilistic network technology [7, 13) is a re­
cent development which is computationally tractable.
A probabilistic network is a graph of nodes and arcs
where the nodes represent uncertain variables and
the arcs represent relationships between the variables.
Computationally efficient algorithms have been de­
veloped which perform inference. The technology has
been applied to a wide variety of problems includ­
ing medical diagnosis, machine vision, petroleum ex­
ploration, military situation assessment, and multi­
target tracking. Some initial work has applied this
technology to information retrieval in hypertext [3, 5].

tionships between variables through experience (i.e.,
data). CoNSTRUCTOR [6] is a system for building
probabilistic networks from data. It serves as the pri­
mary mechanism for learning about the relationship
between concepts.

I
I

In the following section of the paper, we discuss both

probabilistic networks and the CONSTRUCTOR sys­
tem in more detail, and then, in Section 3, we de­
scribe the PCIR architecture. In Sections 4 and 5,
we present the results of two exploratory experiments
that show how we might use these techniques for
concept-based retrieval. We conclude, in Section 6,
with some comments and conclusions on the utility
of the ideas we have presented.

2

Component Technologies

The two major component technologies of PCIR are
probabilistic networks and CONSTRUCTOR.
2.1

Probabilistic Networks

Probabilistic networks is a technology for represent­
ing and reasoning with uncertain beliefs, and is based
on the well-established theory of Bayesian probabil­
ity. A successor to decision tree technology, proba­
bilistic networks have been shown to be to be more
Because of the clear semantics behind probabilistic understandable and computationally more tractable
networks, it is possible to identify and quantify rela- than the older technology. These advantages are

I
I
I
I
I
I
I
I

394

I
I
I
I

Table 1: p(shootikill)
-,kill
kill

-,shoot

shoot

0.9
0.1

0.1
0.9

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

achieved primarily through one innovation: the ex­
plicit representation of relevance relations between
factors modeled in the network.

In a Markov network, relationships between nodes
are also indicated with arcs but represented in a dif­
ferent way. Probabilistic models are associated with
the diques (i.e., maximally connected subset) of a
network instead of individual nodes.
Relevance relations are specified by the connectivity
of the network-what arcs are placed between what
nodes, and in what direction. The concept of rele­
vance in a Bayesian network is related loosely with
graph separation and can be illustrated by exami­
nation of Figure 2. If it is known that the concept
killing is present in a document, then the structure
of the network implies that any other known infor­
mation (e.g., the concept terrorism is present in the
document) will be irrelevant to beliefs about whether
the shooting is present in the document. This is
because the node killing separates the node shooting
from every other node in the graph. Similarly, if it is
known that the concepts politician and terrorism
are both present in a document then any other piece
of known information is irrelevant to whether the con­
cept subject is present in the document. These rel­
evance relations are useful not only from a qualita­
tive point of view, but are also useful in reducing the
amount of quantitative information needed and the
amount of computational resources needed in infer­
ence.

There are two major types of probabilistic net­
works, Bayesian networks which contain directed arcs
and Markov networks which contain undirected arcs.
Both types are used in PCIR. There are two types of
nodes: state and evidence nodes. A state node repre­
sents a mutually exclusive and collectively exhaustive
set of propositions about which there is uncertainty.
A state node is represented graphically by a circle.
For example, whether a document is or is not about
terrorism may be uncertain. To model this situation,
the two propositions "this document is about ter­
rorism" and "this document is not about terrorism"
could be represented by a state node in a probabilistic
network. An evidence node represents an observation
and is represented graphically with a rectangle. For
example, the observation that the word "bombing"
is contained as a document may be represented as a Useful inferences can be made given a probabilis­
tic network that represents a situation and evidence
evidence node in a probabilistic network.
about the situation. For example, given the net­
Relationships between nodes in probabilistic net­ work representing the terrorism query and the ev­
works are indicated with arcs. In a Bayesian network, idence (i.e., extracted features) from a document,
a node's relationship with its predeceuors1 is what is one can infer an updated belief that the document
modeled in a probabilistic network. Each node con­ is about terrorism. Several techniques are avail­
tains a probabilistic model of what is expected given able for making inferences (i.e., reaching conclusions)
every combination of predecessor value5. For exam­ from a network and evidence. Shachter [15), Pearl
ple, the predecessor of the shooting node in Figure 2 [13), and Lauritzen and Spiegelhalter [10) all describe
is the killing node. The probabilistic model for the approaches to inference with probabilistic networks.
shooting node is shown in Table 1. The model can be Each approach has its advantages and disadvantages.
interpreted as saying that when the concept killing For this work, we used the distributed algorithm
is present in a document, the concept shooting will [1, 9).
probably be in the document and that when the con­
cept killing is not present in a document then the
concept shooting will probably not be found in the 2.2 CONSTRUCTOR
document.
The CONSTRUCTOR system [6) induces discrete,
probabilistic
models from data. These models con- .
1 The set of nodes which have an arc which points to a given
tain a quantitative (i.e., probabilistic) characterizanode are that node's predeeesson.

395

I
I
I
I
I
I
I
I

Figure 2: Probabili&tic Network for Terrori1m
tion of the data but, perhaps more importantly, also
contain a qualitative structural description of the
data. By qualitative structure we mean, loosely, the
positive and negative cau1al relationships between
factors as well as the positive and negative correla­
tive relationships between factors in the processes un­
der analysis. CoNSTRUCTOR has as a primary focus
the recovery of qualitative structures since structure
not only determines which quantitative relationships
are recovered, but also because such structure have
been found to be cognitively stable [8] and thus are
valuable in explaining the real world processes under
analysis.
The CoNSTRUCTOR system is built upon techniques
and research results from the fields of probabilistic
networks, artificial intelligence (AI), and statistics.
The probabilistic network technologies are central to
the CoNSTRUCTOR system since they not only pro­
vide the representation language for CONSTRUCTOR
results but, more importantly, provide the concep­
tual impetus-the identification of conditional inde­
pendence relations-that drives the CoNSTRUCTOR
system.

low for a computationally efficient implementation.
From classical statistics, we make use of the x2 test
for probabilistic independence and from the newer
field of computer-intensive statistical analysis [4] we
make use of crou-validation to prevent "overfitting"
of models to data.
The CONSTRUCTOR algorithm works by finding the
complete set of (graphical) neighbors for each feature
in the data set. The neighbor relations for each fea­
ture can then be used to identify the structure of a
belief network. The complete set of neighbors for a
feature is called the Markov boundary. The neigh­
bors are identifiable as the smallest set of features
such that all other features are conditionally inde­
pendent of that feature given any fixed set of values
for the feature's neighbors.

Network identification involves successively finding
the neighbor1 of each attribute in the training set.
Despite these observations, managing the exponen­
tial process of finding neighbors is the primary chal­
lenge for the network identification task. Finding the
From the field of AI we have made use of heuristic neighbors for every attribute in a training set is an
search methods. These methods provide the primary .iterative search process based on finding the Markov
problem solving paradigm of CoNSTRUCTOR and al- boundary for each attribute.

I
I
I
I
I
I
I
I
I
I
I

396

I
I
I

For example, the terrorism concept network shown in
Figure

2 contains 24 concepts and requires the speci­
47 quantitative parameters. Also included
knowledge base are 61 concept-evidence rela­

fication of
in the

I

tionships which require the specification of an addi­
tional

Knowledge

Acquisition

I

64

parameters. The relationships encoded by

both sets of parameters are intuitive and include:
•

If the concept terrorism is in a document, it
is almost twice as likely that the concept vio­
lent act will be in the document compared with

I

the case that the document does not contain the
concept terrorism.
•

I

If the concept bombing is in a document, it is
nine times as likely that the concept explosion

will be in the document compared with the case
that the document does not contain the concept
bombing.

I

•

is four times as likely that the word "explosion"
Figure

I
I
I

will occur in the document compared with the

3: PCIR Architecture

case that the document does not contain the con­
cept explosion.

3

Architecture

The PCIR architecture is shown in Figure 3. The ma­
jor difference between it and the generic architecture
in Figure

1 is

the addition of the knowledge acquisi­

tion component. The rest of this section

will

discuss

the PCIR knowledge base, the inference component

I
I
I
I
I
I
I
I

If the concept explosion is in a document, it

and the knowledge acquisition component.

3.2

Inference

Given a document, a concept of interest and some
decision criteria, the function of the inference com­
ponent is to use the knowledge base created by the
knowledge acquisition component to first judge the
likelihood that the document contains the concept of
interest and secondly to use that likelihood and the

3.1

Knowledge Base

Central to the idea of a concept-based approach to
information retrieval is a knowledge base which con­

decision criteria to make a decision about retrieval of
the document. Figure

4 shows the functional flow for

the inference component.
The first step in the inference process is to extract a

tains knowledge about relationships between con­

set of features from the document. Each feature must

cepts and features extractable from the document.

have values which are well-defined and must be mutu­

In the PCIR architecture, the knowledge base takes

ally exclusive and exhaustive. The features currently

the form of a set of probabilistic networks and can be

used by PCIR are words that have been deemed to

obtained directly from a user or from the knowledge

be relevant

acquisition component of PCIR. The knowledge base

in the PCIR knowledge base. For example, the words

(by

a PCIR user ) to the set of concepts

consists of concept networks and concept-evidence re­

"explosive" "blast" and "explosion" would likely be

lationships.

A concept network relates concepts to

deemed relevant to the concept explosion. The fea­

other concepts. A concept-evidence relationship re­

tures currently used in PCIR are binary-valued. The

lates a concept to a subset of the features that will . values represent whether or not a particular word is
be extracted.

present or absent in a document.

I

397

I
I
I
I
I
I
I
Figure 4:

PCIR Inference

The result of feature extraction is a set of feature

(i.e., frequencies)

values. These feature values are instantiated as evi­

spect to the laws of probability.

dence nodes in the PCIR network and are attached

we mean that the domain knowledge is represented

to the appropriate state nodes

(i.e.,

concepts ) in the

and inference is performed with re­
By model-based,

as much as possible, in terms of behavioral models

network. The likelihoods which are required for the

of cause and efFect.

evidence nodes are derived from the concept-evidence

the nodes

relationships stored in the knowledge base.

the belief that the presence of the concept killing in

The third step of the process is to perform proba­
bilistic inference on the modified network. Given a
concept of interest, the inference process computes

will

I

For example the arc between

killing and •hooting in Figure 2 represents

a document

I

with some probability, "cause" the

I

presence of the concept shooting.
A model-based approach stands in contrast with

(i.e., updated belief ) of the an evidential-accrual approach, such as in RUBRIC
concept given the evidence (i.e., feature values) in the [12, 16, 17]. The flow of reasoning in evidence-accrual
network. Since the concept of interest can be any of approaches is directly from from effect to cause (i.e.,
concepts in the network, a single network can serve evidence to conclusions) . Evidence is accrued to the
the posterior distribution

to answer many queries.

first level of conclusions which in turn act as evidence

The fourth step of the process is to apply the given de­

for the next higher layer of conclusions. In contrast,

cision criteria to the updated belief that the concept

the flow of reasoning in model-based reasoning ap­

of interest is in the document. The decision criteria
may be a simple threshold or may require comparison
with the beliefs from other documents (e.g., best n ) .

order to set up expectations for the evidence. And

The probabilistic networks technology provides a
probabilistic, model-based approach to deriving the
strength of belief that a document contains a par­
ticular concept. By probabilistic, we mean that the

the first pass, reasoning flows from cause to effect in

I

in the second pass, these expectations are compared
with the actual evidence, and the comparisons are
transmitted back from the effects to the causes.

I

In applying belief networks to information retrieval,

domain knowledge of relationships between concepts . one major decision was required-what states should
and evidence is represented in probabilistic terms

I

In

proaches can be viewed as a two pass process.

the nodes represent. We choose to follow RUBRIC by

I
I
I

I

398

I
I
I

assigning two states to each node in a network, where

Concept specification is the most user-intensive pro­

the states represent that a concept is present or ab­

cess in the architecture.

sent in a document. Given this choice of states the

each document in the data set which of the concepts

probability distributions of a network represent be­

in the concept specification are contained in the doc­

liefs about how the presence of sets of concepts in a

ument.

document "causes" or "correlates with" the presence

I
I
I
I

of other concepts in the document. For example, the
model shown in Figure

2

shows that the presence of

the concept terrorism in a document "causes," to
some ( probabilistic ) degree, the inclusion of the con­
cept terrorist actor to be in the document.

I
I
I
I

3.3

Knowledge Acquisition

While concept-based approaches such as RUBRIC are
able to provide good results, the effort needed to ac­
quire the knowledge bases needed by such approaches
from experts requires substantial resources.

PCIR

for knowledge acquisition.

I
I

The data set con­

concepts and features present in a particular docu­

STRUCTOR is

CoN­

a probabilistic network that can act as

the knowledge base for the inference component.
If the user desires, a threshold decision criteria can
be obtained for a particular concept of interest by
passing each of the documents through the inference
by the user which provides for an appropriate tradeoff
between precision and recall.

quisition component is to develop a knowledge base
which establishes relationships between concepts and
features. Figure 5 shows the functional flow for the
knowledge acquisition component.
The user of PCm must provide the inputs to the
knowledge acquisition component.

The inputs are

a set of documents, a set of features, and a set of
concepts. The document set is a population of doc­
uments which should be representative of the docu­
ments which will be faced in retrieval. The Reuters
document collection used to generate the terrorism
network contains

730 documents.

A set of concepts must be identified.

Usually the

concepts are identified through association

( by

cepts included to generate the terrorism network were
associated with the concept terrorism.
create a

CONSTRUCTOR

4

Experiments

Two simple experiments were performed with the
Reuters database.

The first experiment entailed

building a probabilistic network where both the struc­
ture of the network and the probability distributions
were given by a "user" (the principal author ) . In the
second experiment, a probabilistic network was built
using the Reuters database

as

input to the knowledge

acquisition component of PCIR.

the

user} to the concept on which it is anticipated most

data set: feature extraction

and concept specification.
Feature extraction is exactly the same process

I

CoNSTRUCTOR.

component of PCIR. A threshold can then be chosen

Given a set of documents, a set of features, and a

Given these inputs, there are two steps required to

I

be processed by

sists of an array of values. Each row represents the

The result of processing the data set through

retrievals will be performed. For example, the con­

I

values for each document creates a data set which can

ment. Each column represents a particular feature or

set of concepts, the function of the knowledge ac­

I

Appending the concept specification and the feature

concept.

provides an approach to reducing the effort needed

I

The user must specify for

4.1

"Hand-constructed" Network

A simple network was built around the terrorism
concept, using as a model a RUBRIC concept tree
built for terrorism. The network contains

23

con­

cepts and was developed in a hierarchical fashion sim­
ilar to the RUBRIC concept tree. The

as

in

terrori&m node
actor performing a violent
&ubject. Similarly, violent act was broken

was broken down into an

the inference component and is performed for each

act on some

document in the document set.

down into different types of violent acts etc..

This

I

399

I
I
I
I
I
I
I
5: PCIR Knowledge Acqui6ition

Figure

network required

47

independent probability assess­

ments. Except for the prior distribution on the

ter­

probability for both documents about terrorism and
documents not about terrorism is shown in Table

2.

of terror­

It can be seen that the posterior probability of docu­

ist documents in the document set, the probabilities

ments about terrorism is significantly higher than for

were assessed qualitatively by the "user."

the documents not about terrorism.

rori6m node which was set to the frequency

words) were extracted from

The precision and :recall results for a range of pos­

Each of these features requires a

sible thresholds are shown in Figure 6. In the mid­

concept-evidence relationship to be present in the

dle range both precision and recall are approximately

A set of61 features
each document.
knowledge base.

(i.e.,

(These relationships are not shown. ) 50%.

While RUBRIC results are significantly better,

Each of the 61 words were assigned by the user to a

much less effort was expended on this experiment a.nd

single concept and probabilities were specified for the

the :results are competitive with conventional tech­
niques.

events that a word appears in a document given their
assigned concept is present in a document.
Because of the difficulty of the knowledge acquisition
task, several assumptions were made to reduce the
number of parameters needed to be specified for this

network.

The

assumptions included the

hierarchical

structure of the network as well as a constant likeli­
hood that a word does not appear

given

its assigned

concept does not appear in a document. The latter
assumption effects the posterior probabilities so that
they are not "normalized." However the assumption
does not effect the separation of the populations.

The goal of the experiment was to assess the feasi­

I
I
I
I
I

bility of using probabilistic networks as the eviden­
tial reasoning mechanism in a concept-based infor­
mation retrieval scheme. This experiment seems to
suggest that this is feasible. Some effort was made
to see if some parameter modification might easily
improve performa.nce.

To this end the feature sets

of relevant, unretrieved documents and irreleva.nt,
retrieved documents were examined.

While several

modifications where made, no significant performance
improvements were found. This points out the diffi­

Using the concept-evidence relationships, evidence

culty of knowledge acquisition from experts, not only

was attached to the probabilistic network in Figure
2. The mean and standard deviation of the posterior

.in the initial acquisition stage but also in the knowl­
edge base tuning stage.

I
I
I
I
I
I

400

I
I
I

Table

I
I
I
I

terrorism
-,terrorism

avg

std dev

.035
.015

.03
.008

Table

100%,-------�

60%-

I

I

.028

.022

I

takeover

encounter

k1dnap event

ransom

explosion

b oanb1ng

device

shooting

killin g

v1olent act

v1olent effect

Using CONSTRUCTOR

For this experiment, each of the

730

VIOL

Reuters docu­

ments was tagged according to whether or not the
document was "about" terrorism.

Decisions about

the relevancy of each document to the terrorism
ers.

A

total of

50 documents

680 were judged
A set of 82

words was selected as the feature set. The presence
or absence of each of the

82

words was determined

for each document in the document set. In addition,

18 concepts

were chosen as being possibly relevant to

the concept of terrorism. The concepts are shown in
Table

3.

The two readers were also asked to indicate

each of the

Figure

7: CONSTRUCTOR Network for Terrori11m

were judged to contain

the concept terrorism and the other

18 different concepts were
730 Reuters documents.

which of the

I

reason

6: Preci&ion (&olid line) & Recall (dotted line)
V6. Thre6hold.

not to contain the concept terrorism.

I

oppositioll

.032

concept were made by a independent pair of read­

I

assasaanataon

govera:aneat

Threshold

I

I

named terror1st

polihclaD

···········¢·······
··

.016

4.2

I

unnaaned terror1st

20%-

I

I

Concepts

-�

40%

Figure

I

3:

80%-

I

I

2· "Hand- con&tructed" re&ultIf

relevant to

data.
•
•
•
•

"A bombing causes an explosion."
"A shooting is a violent act."
"A killing is a violent act."
"A terrorist event is present if two

or more

of the concepts bombing, named terrorist,
killin g or kidnapping is present except for the
combination named terrorist and killing."
The concept-evidence relationships were derived for

CoNSTRUCTOR was first run with a data set made each of 8 concepts in the network, by running CoN­
STRUCTOR on a data set which included one of the
up of the 18 concepts plus the terrorism concept.
concepts and the words associated with the concepts.
The resulting Markov network is shown in Figure 7.
Given these results, the knowledge base was comNodes for which there is not a path to the clau node
(i.e., terrorism) are not shown. Many of the arcs plete.
have intuitive interpretations which are supported by . To test the network's performance, each of the 730
the underlying probability distributions found in the

documents was processed by the inference component

401

I
I

Table 4: CONSTRUCTOR results
avg
std
dev
terrorism
.21
.45
-,terrorism
.09
.036

Table 5: p(ezplosionlbombing)
-,bombing
bombing

-,explosion

explosion

0.98
0.59

0.02
0.41

I
I
I

100%

o.

. <>

80%-

.

.

.

.

.

<>

.

.

.

.

.

·<>·

.

.

.

. ·0.

Table 6: p(terroristiterr01'iam)

60%-

-,terrorism
terrorism

40%-

-,terrorist

terrorist

0.98
0.64

0.02
0.36

20%-

I
I

"If the concept terrorism is not in a document,
then the concept terrorist will not be in the
document"

I

Figure 8: Precision (solid line) & Recall {dotted line) On the other hand, the contrapositive versions of
these statements which are perhaps more intuitive,
vs. Threshold.
are not true. It is not true that:

I

0

I

.1

.2

.3

Threshold

.4

.5

•

of PCIR using the CONSTRUCTOR-derived knowledge
• "If the concept bombing is in a document, then
base. The mean and standard deviation of the poste­
the concept explosion will be in the document"
rior probability for both documents about terrorism
or
and documents not about terrorism is shown in Ta­
• "If the concept terrorism is in a document, then
ble 4. It can be seen that the posterior probability
the concept terrorist will be in the document"
of documents about terrorism is significantly higher
than for the documents not about terrorism and that While many of the structural relationships and their
corresponding quantitative relationships in the net­
separation of the populations is well-defined.
work are intuitive, there are some complicated re­
The precision and recall results for a range of possible lationships present in the network which are quite
thresholds are shown in Figure 8. In the middle range subtle. For example, consider the relationship be­
both precision and recall are in the 70%to 80%range. tween the concept killing and the concept terror­
As this was the first application of CONSTRUCTOR to ism. Whereas the other neighbors of terrorism
real data, we were pleased with the robustness and (i.e., bombing, kidnap, and named-terrorist)
intuitiveness of the relationships and the performance have strong, uncomplicated relationships with ter­
rorism, the concept killing seems to have a rel­
of the resulting network.
atively small effect by itself but seems to act as a
Many of the relationships that were found are quite magnifier of the positive influence of the other neigh­
robust and had similar structures. Consider Table
bors. This can be seen in Table 7 and was borne out
5, and Table 6 as examples. In both these tables, when the frequencies of these events were examined
the relations between the nodes can be interpreted as in the raw data. Such subtle relationships may be the
noisy if-then statements:
cause of the CoNSTRUCTOR network's improved per­
• "If the concept bombing is not in a document,
formance over the "hand-constructed" network and it
then the concept explosion will not be in the . is easy to imagine that such relationships would take
document"
much effort to find manually.

I
I
I
I
I
I
I
I
I
I

402

I
I
I

Table 7: p(terrorismibombing, kidnap, killing, terrorist)

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

5

bombing

-.kidnap

-.bombing

kidnap

bombing

kidnap

bombing

kidnap

-.killing
-.killing
killing
-.killing
-.killing
-.killing
killing
killing
-.killing
-.killing
killing
killing
killing
-.killing
killing

bombing

kidnap

killing

-,bombing

-.kidnap

-,bombing

-.kidnap

-.bombing

-.kidnap

-.bombing

kidnap

bombing

-.kidnap

bombing

kidnap

bombing

-.kidnap

-.bombing

kidnap

bombing

-.kidnap

-,bombing

kidnap

-,bombing

-.kidnap

Conclusions

-.terrorist

terrorist

terrorist
•terrorist
-.terrorist
-.terrorist
-,terrorist
-.terrorist
-.terrorist
terrorist
terrorist
terrorist
terrorist
terrorist
terrorist
-.terrorist

-.terrorism

terrorism

0.994
0.85
0.96
0.61
0.68
0.02
0.44
0.51
0.24
0.05
0.8
0.53
0.07
0.003
0.03
0.02

0.006
0.15
0.04
0.39
0.32
0.98
0.56
0.49
0.76
0.95
0.2
0.47
0.93
0.997
0.97
0.98

tion that the CoNSTRUCTOR-induced network is close
to being correct and the fact that the network is
sparse (i.e., has few arcs). Out of the 153 possible
arcs between the 18 concept nodes of the graph, only
12 of the arcs are instantiated. In addition, there
are the 82 connections to the 82 evidence (e.g., fea­
ture) nodes. In contrast, consider the situation if all
the concept nodes except the terrorism node were re­
moved from the graph by probabilistic manipulation.
The resulting graph would be extremely dense. This
would correspond to the situation of deriving proba­
bilistic relations between terrorism and the features
directly.

We believe that the experimental results presented
above provide positive evidence that the PCIR ar­
chitecture design is feasible. The choice of prob­
abilistic networks for the knowledge base represen­
tation provides for an intuitive and well-defined se­
mantics for acquiring knowledge either from an ex­
pert or automatically. The first experiment shows
that reasonable performance can be obtained through
use of probabilistic networks as the evidential rea­
soning mechanism for concept-based information re­
trieval. The second experiment reinforces this eon­
elusion while also showing that partially automating
Three advantages for concept-based methods can
the knowledge acquisition task is possible.
be seen from this analysis. F irst, concepts orga­
The central hypothesis of concept-based methods for nize information into a small number of manageable
information retrieval is that the representation of, concept-to-concept and concept-to-feature relations.
and reasoning about, unobservable concepts is effec­ This makes both manual and automatic knowledge
tive both from an organizational and from a com­ acquisition easier. Secondly, concepts reduce the
putational point of view. We feel that a secondary computational complexity of inference. Probabiliscontribution of this work is positive evidence for this . tic inference is inherently easier in sparse networks
hypothesis. All the evidence stems from the assump- than in dense networks. Thirdly, concepts make the

403

I
automatic knowledge acquisition problem tractable

[3]

W. B. Croft and H. Turtle.

A

retrieval model

by dramatically reducing the sampling problem. The

incorporating hypertext links. In

probability tables of dense networks are exponentially

Proceeding&, November 1989.

larger than the probability tables for sparse networks.
Dense networks will therefore spread the examples in

[4]

such problems.

[5] M.

medical handbook project. In

ceeding&,

concepts useful computationally, but the robustness
of the relationships between concepts seen in the
network provides strong ev­

[6)

processes.

[7]

amount of work needed by a user to identify what

I
I

document set. However, we think a scenario in which

[8)

untrained people. A research goal is to identify con­
cepts automatically by clustering.
We think that the results are promising and intend to

[9]

pursue further research in this direction. Further ex­

algorithm itself is new and evolving. Im­

I

diagrams. In R.A. Howard and J E Matheson,

I

The Principle& and Application& of De­
ci•ion Analyaia, vol. II, Menlo Park: Strategic
Decisions Group, 1981.

I

D. Kahneman, P. Slovic, and A. Tversky. Judge­
ment under uncertainty: HeuriatiCI and biaae1.
Cambridge University Press, Cambridge, 1982.

I

R.

A.

Howard and J. E. Matheson.

Influence

.

J. H. Kim and J. Pearl. A computational model
for combined causal and diagnostic reasoning in

Proceeding& of the 8th In·
ternationl Joint Conference on Artificial Intelli­
gence, Los Angeles, California, 1985.

terrorism query is planned. Another area of research
is experimentation with different document sets, dif­
The CoN­

I

Constructor:

inference systems. In

perimentation with the Reuters document set and the

ferent features, and different concepts.

Crawford.

editors,

a user incrementally performed this is certainly fea­
special domain, this work can be done by relatively

L.

.

concepts are present for each document in a large

sible. Also, if the concepts of interest are not in a

R. M. Fung and S.

Hypertezt'89 Pro­

1989.

Seventh International Conference on Machine
Learning, June 1990. submitted.

cepts are cognitively significant in people's thought
The most visible drawback of this research is the

November

empirical acquistion of probabilistic models. In

idence for the psychological intuition that these con­

STRUCTOR

E. Frisse and S. B. Cousins. Information re­

I

trieval from hypertext: update on the dynamic

As a secondary point, we feel that not only are

CoNSTRUCTOR-induced

SIAM Rev-21, 460-

480, 1979.

pling can be a serious problem in such situations. On
the other hand, sparse networks do not suffer from

B. Efron. Computers and the theory of statistics:
thinking the unthinkable.

the training set over a much larger space. Undersam­

Hypertezt '89

[10]

S. L. Lauritzen and D. J. Spiegelhalter.

Lo­

cal computations with probabilities on graphical

provements to the algorithm could be the source of

structures and their application in expert sys­
tems. Journal Royal Statiatical Society B, 50,

important improvements to PCIR.

I
I
I

1988.
{11)




I

In almost all situation assessment problems,
it is useful to dynamically contract and ex­
pand the states under consideration as assess­
ment proceeds. Contraction is most often used
to combine similar events or low probability
events together in order to reduce computa­
tion. Expansion is most often used to make
distinctions of interest which have significant
probability in order to improve 'the quality of
the assessment. Although other uncertainty
calculi, notably Dempster-Shafer [4], have ad­
dressed these operations, there has not yet been
any approach of refining and coarsening state
spaces for the Bayesian Network technology.

I
I
I
I
I
I
I
I
I
I
I
I
I

This paper presents two operations for refin­
ing and coarsening the state space in Bayesian
Networks. We also discuss their practical im­
plications for knowledge acquisition.

1

Introduction

Bayesian Networks [1], [2] is a technology for reason­
ing under uncertainty and has been used primarily to
address situation assessment problems (e.g., medical di­
agnosis, battlefield assessment). In situation assessment,
the problem is to infer the strength-of-belief (i.e., proba­
bility) in certain propositions given a set of internal be­
liefs (e. g., rules) and external evidence. In general, the
evidence about a situation does not come in all at once,
instead it is received over a period of time. As evidence
is received and beliefs are updated, some distinctions
which were previously irrelevant become relevant and
some distinctions which were previously relevant become
irrelevant. In general, it will be infeasible to consider all
possible relevant distinctions throughout the assessment
process due to resource limitations. Therefore an op­
portunistic approach is needed in which new states can
be added and existing states which are similar or in­
significant can be combined or removed dynamically as
the assessment proceeds. Other uncertainty calculi have
also recognized the importance of this problem, notably
Dempster-Shafer [4].
The introduction of new distinctions to a state space
refine• the state space and the removal of distinctions
coar1en1 the state space. These operations must fulfill

the intuitive constraint that their use must not afFect
beliefs which do not directly involve the refined or coars­
ened state space. This paper presents operations for re­
fining and coarsening the state spaces of Bayesian Net­
works. The inputs to the operations are a target node
and the desired refinement or coarsening. The outputs
of the operation are revised conditional probability dis­
tributions for the target node and for the target node's
successors which correspond to the modified state space
of the node.·
There are three important observations about these
operations. First, to satisfy the constraint that refine­
ment and coarsening operations do not affect the prob­
ability of states not involved in the operation, it is suf­
ficient that the operations do not affect the probability
of states in the "neighborhood" of the node under con­
sideration. It can be easily shown that this "neighbor­
hood" of a node is the Markov boundary of the node,
namely, the node's predecessors, successors, and succes­
sors' predecessors. In other words, if the joint probabil­
ity distribution of the blanket (other than node itself) is
not changed by the operation, then the joint probability
distribution of the entire network (other than the node
itself) will also be unchanged by the operation.
Second, since refinement operations "introduce" in­
formation to the network some judgements need to be
made about the relative weights of the new distinctions.
This can be done by modifying the relationships ( i.e.,
the conditional probabilities) between the refined vari­
able, its predecessors, and its successors. In order to
satisfy the Markov boundary condition described above I
cer tatn �onstraints need to be met in modifying these re.
lationships. The degree of freedom in assigning the new
probabilities is limited.
•

Third, while coarsening operations can always be ex­
act (i.e., satisfy the Markov boundary condition), the as­
.
soctated costs are high enough that it may be desirable to
make the operation approximate. In such circumstances
information may be lost due to the approximation. B
the loss of information, we mean that the resulting net­
work will have a different probability distribution than
the original one. However, if the states to be coarsened
are "similar" enough, the resulting impact will be small.

;

This paper is organized as follows. Section 2 describes
the refinement and coarsening operations. Section
presents some detailed examples. Some discussions and

3

I

476

I
I
I
I
Figure

1:

concluding remarks are given in Section

2

I

A Simplified Network

4.

I

The Refinment and Coarsening
Operations

In this section, two sets of related operations, one called
"external" and one calle d "internal", for refining and
coarsening a node's state space are presented. The node
to be refined or coarsened will be referred to as the "tar­
get" node. First set of operations is called "external"
since a new node is added "externally' to the target node
which is a successor to the target node and whose state
space is the desired modified state space. In the "in­
ternal" operation, however, the operation works "inter­
nally" on the node without changing the topology of the
original network.
The external operation is straight-forward. An exter­
nal node is added to the diagram which has no successors
and has the target node as its only predecessor. The
state space of the external node is the desired refine­
ment or coarsened state space of the target node. The
arc (conditional probabilities) between these two nodes
describe the mapping, either refinement or coarsening,
between their state spaces. The target node is then re­
moved from the graph probabilistically based on the arc
reversal and node removal operations [3]. This leaves
the external node in place of the target node in the new
graph. By doing so, an extra arc is introduced between
the predecessors and the successors of the target node.
The advantage of this approach is its simplicity. The
disadvantage of the approach is the change in the net­
work topology. In a dense network, this operation may
introduce many extra arcs.
An example of the operation is shown in Figures 1 and
2. Figure shows the original network. Suppose that z
is the target node. We first add an external node z1 as
the original node's successor with the desired new state
space. Figure 2 shows the resulting network after the
removal of the target node z. As can be seen, an extra
arc has been introduced between the predecessor and the
successor of z.
The internal operation refines and coarsens the state
space of a node without changing the topology of the

1

Figure

2:

Modifying Network with External Operation

networks. This operation takes four inputs:

• a state node (z) whose state space (0.) is to be
refined or coarsened,

I
I

• a relationship between (o.) and (0�) which specifies

I

• • auxiliary information, the Markov blanket of the

I

• a new state space (0�),
which values
which values

w.
w�

in o. are refined or coarsened into
in 0�.

node. The Markov blanket of z requires that the
state spaces of it's predecessors P. and successor's
predecessors P,. be specified as well as the proba­
bility distributions of it's successors s. ( see Figure

1).

The output of the operation are two sets of probability
distributions:
•

the new conditional distribution for

•

modified

z, p'(ziP.)

distributions for the successors

p'(•.lz, P,.)

and

of

z,

We specify the relationship between o. and 0� with
two mappings. The refinement mapping Refine maps
a single value in o. into multiple values in n� and the
coarsening mapping Coa?•en maps a single value in 0�
into multiple values in o•.
In the refinement operation, for those values w. in
o. which are refined into w� E Refine(w.) in 0�, an
obvious constraint of the new probability distribution is

I
I
I
I
I

(1)

I

Since w� does not have to be equally weighted, one needs
to make the judgements about the relative weights of the
new distribution.

I

p(w,.jP.)

=

L

c.��ER(c.�.j

p(�&��IP.)

I

477

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

The Markov boundary of the state node II' includes P.,

s., and Ps . They "shield" the node II' f'rom the rest of
the network. n can be easily shown that if the joint

probability distribution of the Markov boundary is not
aft'eded by the refinement operation, then the rest of the
network will not be afFected. To keep the joint probabil­
ity distribution of the Markov boundary the same before
and after the refinement operation, the constraint to be
satisfied is chosen as p(S.!P.,Ps.), namely,
p(S.!P.,Ps.)

In

=

:E. p(•.I��',P,.)p(��'IP.)

=

:E•• p(•.I��'',P,.)p(��''IP.•)

(2)

other words, for the value "'• to be refined,

p (••l"'•' P,.)p("'•IP.) =

:E

p(••l"'�' P,.)p("'�IP. )

(3)
need to be satisfied for all values of P.. An obvious solu­
tion satisfies the above constraints regardless ofp("'�IP.)
is,
(4)
p(••l"'�' P,.) = p(••l"'•' P,.)
This solution states that, regardless of how the condi­
tional probabilities p("'�IP.) being assigned, as long as
they satisfy eqn. (1), then i!the conditional probabilities
of the successors s. given the refined values are set to be
the same as that o!the original value,then the constraint
(3) is satisfied. This solution allows us to assign arbi­
trary proportions in the upper arc p("'�IP.) but leaves
no f'reedom in determining the lower arc p(••l"'�' P,.).
In general, the above solution may be too restridive.
In fact, if the proportions p("'�IP.) assigned in eqn. (1)
are the same for all the predecessor values, namely, if
p("'�IP.)
:Ew�eR(w.) p("'� IP.)

=

K("'�)

(5)

rhere K("'�) is a fundion depending only on "'�' then
qn.(3) can be reduced to a single constraint, i.e.,
p(••l"'•' P,.)

=

�

w�eR(w.)

p(••l"'�' P,.)K("'� ).

{6)

In this case, p (••l"'�' P,.) do not need to be the same as
p (••l"'•' P,.) and as long as they satisfy the constraint
(6), we have f'reedom to assign their numbers. In other
words, by imposing one more restridion (5) in obtaining
the upper arc, more f'reedom is allowed in choosing the
lower arc.
In the internal coarsening operation, for those values
"'• in o. which are coarsened, two constraints similar to
(1) and (3) need to be satisfied,

p("'�IP.) =
and
p(••l"'�' P,.) =

\

�

w.ec(w�)

p("'.IP.)

(7)

� p(••l"'•' P,.)p("'•IP.)
P.
p("'• •) w.ec(w�)
(8)

I! both of these constraints are satisfied, then the coars­
ening procedure is exact and the rest of the network
will not be afFected.
However, if no single value of
p('•'"'�,P,. ) can be found to satisfy (8) for all values
of P., then that means those "'• in C("'� ) cannot be
coarsened without changing the joint probability of the
network. In other words, some information may be lost
when "aggregating" those state values together and the
new network will be "inconsistent" with the old one. I!
that is desirable, one can either use the external opera­
tion described earlier or use the internal operation with
some approximation. If' the values to be coarsened are
"similar", namely, the values of p( '•'"'�, P,.) calculated
based on the right hand side of (8) with different val­
ues of P. are close, then the approximation will have
small impact on the rest of the graph. A reasonable
approximation under such situation will be to calculate
p(••I"'�,P,. ) as the average of the values obtained f'rom
(8).
3

Dlustration of the Operations

We illustrate the refining and coarsening operations for
both the external and internal approaches with the fol­
lowing examples. First consider the graph given in Fig­
ure 3. In this example, the root node M has two values,
Military Unit Type A and Type B. The second node V
has two values representing whether a vehicle exists in
a particular place and time. The terrain condition node
T has two values, good and bad. The feature node F
has'two predecessors, vehicle V and terrain condition T,
and has three values feature A, feature B, and feature
of Others. The original probability distribution of the
graph as well as the computed posterior probabilities of
each node given the evidence are also given in Figure 3.
In this example,suppose we are only interested in dis­
tinguishing whether there is a vehicle or not, which can
help us identifying the type of military unit. When the
posterior probability of the presence of vehicle becomes
very high as supported by evidence, we may become in­
terested in more details about the vehicle. Suppose, we
are interested in what type of vehicle it is, first we refine
the state value Y of node V into two values, Tank A and
Truck U. With the external operation, we can add an
artificial node VI, in which tank and truck are split, say
in a one to four ratio (see Figure 4). After removing the
original node V, the resulting graph, the corresponding
conditional probabilities and the posterior probabilities
of each node are also shown in Figure 4.

With the internal approach, first we assign probabili­
ties for the upper arc. As in the external approach, we
split vehicle into tank and truck with one to four ratio
and we assume it is independent of military unit type.
The new conditional probabilities of refined node V given
M is shown in Figure 5. In this case, the condition given
in eqn.(5) is satisfied, we therefore have f'reedom in as­
signing the conditional probabilities of the lower arc as
long as they satisfy the constraint given in eqn. (6),

478

namely,
[p(F;IV., 7J )p(V.IM•) + p( F;IV., 7J)p(V.IM•)]
p(V.IM•)
(9)
where F, is the i th value of node F. It can be seen
that this is a line equation in a tw�dimensional space.
For instance, for F, = a, 7j = g we have,

p(F.·,IV.•• T.:' )

=

-

0.45 = 0.2p(F.jV., T1) + O.Sp(F.)V., T1)
(10)
Therefore
any
pair
of values p(F.!V., T1) and p(F.!V., T1) between 0.0 and
0.9 (because p(F.IV., T1) = 0.1) and satisfy eqn. (10) are
feasible. Based on the constraints, we choose the feasible
conditional probabilities of node F as given in Figure 5.
The idea of choosing those numbers is that given vehicle
is a Tank, the probability of detecting feature A is much
higher than detecting feature B. On the other hand,
there is a slightly higher probability to detect feature B
than feature A from Truck. With these new arcs, the
posterior probabilities of each node given the evidence
are shown in Figure 5. As can be seen, other than node
V, the probabilities are the same as the one in Figure
4. Apparently, because of the new ares and because the
evidence favor feature B, the new posterior probability
of Tank is smaller.
We may also choose the upper are in such a way that
the split of vehicle between tank and truck depends on
the military unit. For example, as given in Figure 6, the
percentage of tank in type A military unit is assumed
to be much more than that in type B military unit. In
this case, the condition given in eqn. (5) is not satisfied,
the only solution that can satisfy eqn. (6) is the obvi­
ous solution given in eqn. (4), namely, the conditional
probabilities of node F given the refined values v. and
v. must be the same as that of the original value v,
as shown in Figure 6. The resulting posterior probabili­
ties also given in Figure 6 show visible changes in node
V. Note that, while it is possible in refinement to have
dift'erent ratio of splitting in the upper arc with the in­
ternal approach, it can not be done using the extemal
operation. As shown in Figure 4, the external operation
always produces the same ratio of splitting in the upper
arc which may not be desirable in certain cases.
With the refined network given in Figure 5 or Figure
6, if we coarsen the state values v. and V11 back into
v, using the internal operation, obviously, the results
will be the same as the one in Figure 3. However, in
many cases, no coarsening can be done without chang­
ing the joint probability distribution of the network. For
instance, if the conditional probabilities of the same net­
work is set to be the one given in Figure 7, then no single
value of p(F;Il'J, T1) can be found to satisfy (8) for all
values of M;. That means we either have to approximate
the coarsening or we can use the external operation. The
approximated values we use for p(F,Il'J, T,) is to take av­
erage of the values obtained from (8) as described in the
previous section. The resulting conditional probabilities
between F and V and the computed posterior probabil­
ities are also given in Figure 7. The results of extemal
operation which combine v. and Vu into v, are shown in
p(F.jV,, T,)

EV

Figure

3:

An Example Network

=

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

479

I
I
I
I
I
I

Concltllnlll

(i;i] l......,.�zw I
VA
v o.z
N 0.0
ll:.K::J

u
0.8
0.0

l'ftlll tlr HIIM VI

�-!

[W �

�

N

0.0
1.0
..d

I
I
I
I
I
I
I
I
I
I
I
I
I

Figure 4: Refined Network with External Operation

480
Figure 8. As can be seen, the results in Figures 7 and 8
are very similar, except in the ease of Figure 8, we have
introduced an extra are between node F and M.

4

Figure 5: Refined Network with Internal Operation I

Figure

TV A
G A 0.45
8 A 0.3
G U 0.45
e u 0.3
G N 0.1

0.45
0.3
0.1

0.4
0.1
0.4
0.8

e N o.z

o.z

0.6

6:

B
0.45
0.3

0
0.1

Refined Network with Internal Operation ll

Discussion and Conclusion

This paper has presented two operations, the external
operation and the internal operation for refining and
coarsening the state spaces of nodes in Bayesian Net­
works. The operations satisfy the constraint of leav­
ing unrelated probabilities in the network unchanged.
Through the refining or coarsening operations, one can
"emphasize" the important states in the analysis by re­
fining them or "de-emphasize" less important, similar
sta.tes by combining them at any point during the as­
sessment. These operations are especially useful when
the network is large and local changes are desired which
do not affect the rest of the network.
The refinment and coarsening operations have a dual
relationship. In general, information is being removed
in coarsening, and in refining information is being a.dded
to the network. Coarsening can "undo" refinement and
if no information is lost in coarsening, a refinement can
"undo" ·a coarsening. The refinement and coarsening
operations developed in this paper can be thought of as
"change of classification" operations in that they revise
the classification (e.g., discretization) scheme for a given
"axis" in a joint state space. A concrete example of this
is the splitting ofihe state Vehicle into the two substates
Tank and Truck as shown in Figure 4. This "change of
classification" operation is only one type of state space
modification. Another useful type of state space mod­
ification is the introduction or removal of classification
axes. This is easily accomplished by a.dding or removing
nodes from the network. For example, any new node
that has no successors will not change any of the rela­
tionships between existing nodes.
The external and internal operations are closely re­
lated. For the erlemal refinement operation one only
needs to specify the splitting ratio between the new val­
ues. The conditional probabilities of the upper arcs and
lower ares are then generated automatically. The new
ares created by the extemal operation are always redun�and can be removed wtfli:out any change to the

_]@it diStril:llitiea (see i'i� the m\etne:l teftne=

ment operation one can specify more information than in
the external operation since both the conditional proba­
bilities of the upper ares and lower ares can be specified
subject to certain constraints. Thus for refinement, the
external operation is a special case of the internal oper­
ation.
However, this relationship is reversed for the coarsen­
ing operation-the internal operation is a special case of
the extemal operation. The ability of the external oper­
ation to change the topology of the network allows any
states to be coarsened whereas in the internal operation
only i£ the constraints shown in equations (7) and (8)
are satisfied can coarsening be performed. It is intuitive
that only in such cases, the extra arcs create in the ex­
ternal operation are redundant. However since the main
idea in coarsening is to reduce the state space, the intro­
duction of new arcs, which is required in general, seems

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

481

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

Figure
ation

7:

Approximate Coarsening with Internal Oper­

Figure

8:

Coarsening with External Operation

I

482

counterproductive.
We feel an important application of this work is to the
knowledge acquisition process. For Bayesian Networks,
it is typical to first acquire, from an expert, the struc­
ture of a network. After the structure is determined,
the state space of each node is acquired from the expert
and lastly the probability distribution for each node is
acquired. The structure is acquired first since this knowl­
edge is the most robust cognitively. "Evidently, the no­
tion of relevance and dependence are far more basic to
human reasoning than the numerical values attached to
probability judgements ... Once asserted, these depen­
dency relationships should remain a part of the repre­
sentation scheme, impervious to variations in numerical
inputs."1• However this research shows there are definite
constraints between structure, states, and probabilities.
Consider the example shown in Figures and
Imag­
ine that the structure in F igure has been acquired and
a decision is being made about the state space of node V.
Consider the two possibilities: the state space of node V
is Y and N or the state space of node V is A, U, and
N. Imagine that we acquire the conditional probabili­
ties for each possibility and assume the expert gives his
"true" probabilities. Surprisingly, in general, the asso­
ciated joint probability spaces for these two possibilities
will be inconsistent. This leaves the issue of which etate
space possibility should be used. The intuitive answer
is one should choose the state space which contains the
"most information" but does not contain any "indistin­
guishable" states. In other words, a state space which is
big enough but not too big! We call this the "maximumly
distinguished" state space. The refining and coarsening
operations introduced in the paper allow a formal defi­
nition of this term.
A "maximumly distinguished" state space is a state
space which is both "irreducible" and "complete". An
"irreducible" state space is one in which no coarsen­
ing operation can be performed without making the
joint probability inconsistent (for the internal operation)
or without introducing unremovable new arcs (for the
external operation). Conceptually, a "complete" state
space is one which contains enough distinctions to cap­
ture all the expert's knowledge. Stated in another way,
a "complete" state space is a state space in which if
any state is refined into substates, then the expert can­
not distinguish between the substates. Formally then, a
"complete" state space is one in which the expert proba­
bilities on that state space can be reached by an internal
coarsening operation on the expert probabilities of any
more refined state.
This can be translated into broad guidelines for knowl­
edge acquisition as related to network structure and state
spaces. The knowledge engineer should first determine
the structure of the network. Second, he should order the
nodes such that the predecessors of a node are always be­
fore the node. He should then determine the state space
and probability distribution of each node according to
the order. This should be done by refining the state
space of each node step-by-step, eliciting probabilities
for each candidate state space. When the probabilities

7

1

[2), p.

79

7

8.

of a refined state space are "consistent" with a coarser
state, prefer the coarser state. If a more refined state
C:annot be found after some search, then that acquisition
of knowledge for that node can be considered complete.

I
I



Backward simulation is an approximate
inference technique for Bayesian belief
networks. It differs from existing simulation
methods in that it starts simulation from the
known evidence and works backward (i.e.,
contrary to the direction of the arcs). The
technique's focus on the evidence leads to
improved convergence in situations where the
posterior beliefs are dominated by the evidence
rather than by the prior probabilities. Since this
class of situations is large, the technique may
make practical the application of approximate
inference in Bayesian belief networks to many
real�world problems.

1

INTRODUCTION AND MOTIVATION

Because of its sound theoretical foundation in probability
theory, the Bayesian belief network technology has
become, in artificial intelligence, an important alternative
architecture for reasoning to logic�based architectures
(e.g., rule�based systems). Although efficient exact
inference techniques (Shachter, 1986; Lauritzen, 1988,
Shachter, 1990) for Bayesian belief networks can and
have provided excellent solutions to many real�world
problems, their applicability is limited, because exact
inference is NP�complete (Cooper, 1990).
Because of this, significant research has been focused on
finding efficient approximate inference methods. Most
previous research has emphasized simulation methods
(Pearl, 1987; Fung, 1989; Shachter, 1989; Chavez, 1990;
Shwe, 1991a), which repeatedly draw sample values from
the network's nodes using a sampling algorithm, and then
use the relative frequencies of the sample values to
estimate the probabilities of interest. Researchers try to
find methods that converge quickly to the exact result, and
to characterize the convergence properties of the
simulation algorithms.
There are two basic classes of simulation methods:
forward-simulation methods (Fung, 1989; Henrion, 1986;
Shachter, 1989) and stochastic�simulation methods
(Chavez, 1990; Pearl, 1987).
Forward�sirnulation

methods start each trial of the simulation by instantiating
the source nodes (i.e., nodes with no predecessors) and
then proceeding forward along the diagram arcs to
instantiate each downstream node in tum. Because the
sample values from one trial to the next are unrelated, the
trials are independent. In stochastic�simulation methods,
on the other hand, each trial begins by modifying the
previous trial's instantiation. Each node's sample is
chosen with respect to the current instantiations of
neighboring nodes.
Because they are driven by the prior probabilities of
upstream nodes, rather than by the likelihood of the
observed evidence, forward�simulation methods converge
slowly when faced with low�likelihood evidence
(evidence that has low prior likelihood). Because of the
way samples depend on the current instantiation,
stochastic�simulation methods as a group are inefficient
when there are deterministic or near�deterministic
relationships in a network.
In this paper, we present the backward�simulation method
for performing approximate probabilistic inference i n
Bayesian belief networks. Our method i s closely related
to forward�simulation methods, and is not susceptible to
slow convergence in the presence of deterministic
relationships as are stochastic simulation methods. In
addition, the method is not as susceptible to slow
convergence with low�likelihood evidence, the main
problem with other methods of its class.
In Section 2, we present the notation used in this paper.
In Section 3, we discuss forward simulation methods in
detail. Section 4 provides the details on the backward �
simulation method. In Section 5, we give a summary of
the paper, and discuss directions for future research.

2

NOTATION

A Bayesian belief network is a directed acyclic graph D
with an associated probability distribution P. The set of
nodes in a network is denoted by N. Individual nodes are
denoted by capital letters, whereas general references to a
node (such as "node i") are in lowercase italics. Each
node i in the network has a corresponding variable X; in P
and a set of parents Pa( i). If S is a set of nodes, then the

228

Fung and Del Favero

set X s is the set of variables corresponding to the nodes in

s.

The variable

Xi has a corresponding set of conditioning
variables X Pa(i)• called the parents of X1. Each variable
xi has a state space nj and an associated probability
distribution P(X 11Xpa ))· The product of node probability
(i

dis tributions in a network is the joint probability
distribution P of the variables associated with the graph D.

4

BACKWARD SIMULATION

The two defining features of backward simulation are the
direction of simulation and the sampling method for
drawing node values. The direction of sampling in the
backward simulation method is outward from the
evidence. In contrast, forward-simulation methods that
work forward from the source nodes, whereas stochastic­
simulation methods that have no particular direction of

We represent evidence in Bayesian belief networks by

simulation.

setting the values of the appropriate nodes to their

methods, backward simulation permits many possible

observed states. The set of nodes whose values have been

orderings of the nodes to be sampled.

observed is denoted by N e· The nodes that are unobserved
(i.e., that are in

N\Ne) are called state nodes.

Backward simulation is a specialization of the
importance-sampling inference method discussed in

The inference task for Bayesian belief networks is to
compute answers to queries of the

Like forward and stochastic simulation

form P(X 11XK), where

Section 3. Like forward simulation, backward simulation
includes a node ordering step and a simulation step. The

all the observed evidence Ne is typically a subset of the

first step computes an ordering of network nodes, starting

nodes in K. Many exact and approximate algorithms have
been developed for addressing such queries.

general, an ordering will contain only a subset of the

Where there is little potential for confusion, the notation

P(A) will be used to mean P(XA)

.

3

nodes in the network. In the second step, the simulation
trials are performed, with network nodes sampled in the
predetermined order.

1981) is a well-known

technique for improving convergence in Monte Carlo
simulation. It has been adapted for use in forward

simulation models (Shachter, 1989).

It provides the

ability to instantiate the network from an arbitrary

distribution Ps instead of just from the joint distribution P
as in logic sampling. To adjust for sampling from P s
instead of from P, the weight Z associated with each trial
is computed to be the ratio of the likelihood of the sample

based on the network distribution to the likelihood of the
sample based on the sampling distribution:

(I)
The network probability P(XN) is always the product of
node probabilities,

A trial weight Z is computed for

4.1 ORDERING
The

thr ee

requirements

for

node

ordering

in

back ward simulation are flexible and allow significant
variation:

1. A node must be instantiated before it is backward
sampled,

2. A node's predecessors must be instantiated before
the node is forward sampled, and
3. Each node in the network must be either (a) a node
in the ordering or (b) a direct predecessor of a node
in the ordering that is backward sampled.

Items 2 and 3(a) are the usual requirements for an or­
dering in forward simulation.

(2)

Because evidence nodes are instantiated, they can always
be backward sampled.

but the sampling distribution can be arbitrary.

In the

simplest form of the algorithm, the sampling distribution
is the joint distribution over the unobserved nodes (the
state nodes). In that case, where P(XN5)=P5(XN5), the
ratio in Equation 1 is just
likelihood of the evidence.

In

each trial, and is used to increment the counts of each
distribution (i.e., query) of interest.

IMPORTANCE SAMPLING

Importance sampling (Rubinstein,

from the evidence nodes and working outward.

P(XN e IXNs ) the overall
,

An informal argument for why this method works is as
follows. If a large number of trials is done, the frequency
of Xi in the accumulated trials should be approximately
Ps(X1). When multiplied by the weight we get the
probability of X;. P(Xi). A formal proof of the conver­
gence of this method is presented in (Geweke, 1989).

Leaf nodes also can always be

backward sampled, because a dummy evidence node with
uniform likelihoods can be attached to a leaf node without
the posterior distribution being changed.
We shall use the simple network in Figure I to illustrate
the ordering and sampling steps. Each node represents a

probabilistic variable that is conditionally dependent on
the nodes at the ends of the arrows pointing into it. Thus,
the network in Figure 1 represents this probabilistic

factorization:

P(ABCDE) = P(A) P(BIA) P(CIA) P(DIBC) P(E).
Node

D is shaded to indicate that it is an evidence node.

Backward Simulation in Bayesian Networks

229

simulation (the process driving the sampling). Indeed, in
forward simulation, they are linked: forward simulation
involves only forward sampling. However, the process of
backward simulation does involve both backward and
forward sampling.

4.2.1

Backward Sampling

Backward sampling from a node's probability distribution
instantiates those of the node's predecessors that are not
already instantiated. We denote the instantiated value of
node i by X;, the parents of i that are uninstantiated by
Pa ll(i) and the instantiated parents by Pa *ci).
Figure 1: Simple Network.
Four different sampling orders for the example network
shown in Figure 1 are {D,B,E}, (D,E,B}, {D,E,C}, and
{ D,C,E}. First, the evidence node D is sampled,
instantiating nodes B and C. We then have two choices
for instantiating node A, namely by backward sampling
from either B or C. Finally, the value of E is determined
by forward sampling from C.
The nodes in the sampling order will be denoted by Ns.
This set is composed of the nodes to backward sampled,
N b• and the nodes to be forward sampled, Nr· In this
example, if we take Ns to be { D,B ,E}, then N b is { D,B}
andNf is {E}.

The backward-sampling procedure instantiates the
uninstantiated parent nodes according to the following
probability distribution:

ps

Backward sampling differs from forward sampling in
each of these three aspects. First, sampling from a node's
probability distribution occurs only after the node itself
has been instantiated. Second, sampling from a node's
probability distribution does not determine the node's
value but rather the values of the node's predecessors.
Third, the sampling is based not on a particular
conditional probability distribution but rather on
normalized likelihoods of the node's conditional
probability distribution.
Which of the two methods is used to sample a node
depends on the network topology. For nodes with an
evidence node as a descendent, sampling from a node's
conditional probability occurs after the node has been
instantiated, and it determines the values for the node's
predecessors. For nodes with no downstream evidence
nodes, forward sampling is used. Any of the algorithms
developed for forward simulation can be used.
We would like to emphasize the distinction between
sampling (a selection from a set of choices) and

I'

::::

P(x;

xp )

I XP ( )
a

"

r

a

'

'(·)
1

Norm (i)

•

'z E

N b·

(3)

The numerator of the preceding expression is the
likelihood of the current state of node i given a particular
state of the parents of node i. The denominator, Norm(i),
is a normalization constant that ensures that the terms in
this distribution sum to 1. Norm(i) is computed as
follows:

(

u(i)l X; I y, XPa

Norrn(i) = LyeXP(Pa

4.2 SAMPLING
Two sampling methods are used in backward simulation:
forward sampling and backward sampling. In forward
sampling, a node's distribution is sampled only after all
the node's predecessors have been sampled. Forward
sampling a node sets the value for the node itself. The
probability distribution on which the random sampling is
based is determined by the values of the node's
predecessors.

(Pa u { ))

J

• (i

The set XP(Pau(i)) is the set of all possible conditioning
cases of the uninstantiated parents of node i. For nodes
with n binary-valued uninstantiated parents, this set is of
size 2n.
Normalization constants can be precomputed if there is a
fixed order, or they can be cached as computation
proceeds.

4.2.2

Forward Sampling

In forward sampling, the sampling distribution for a node
is the same as the node's probability distribution:

(4)
4.3 SCORING
After all of the nodes have been instantiated, the weight
for each trial can therefore be computed by combining
Equations 1 through 4:

Z(x)=

•e

[

](

(
P (xj I XPa(j) )
rrjENb Norm(J)
n.

NP xi lxPa(i)

)

rrjENf p(

x; XPa(j} ))
I

230

Fung and Del Favero

Tills can be simplified to

(

Z(x) =Die N \ N P x1 I xPa(i)
s

Table

)n

j eN b Norm(})

4: Backward Sampling Distribution for A

(5)

4.4 EXAMPLE
Let us step through an example of backward simulation.

Consider the five-node network in Figure l. All of the
nodes are binary-valued: the values for A, for instance,

are taken to be a1 and a2, whereas the possible joint
values (or states) of nodes B and C are htc1, b 1c2, b2 c1,
and b 2c2• The value of the evidence node D is observed to

be d2 . Suppose that the sampling order { D,B,E} is used.

Table 1 is the conditional probability table for node D.
For instance, P(D= d2 I B=b1, C=c2) = p 122 .

As before, the constant

Suppose that the sampling step selects state a2.
Finally, we would use forward sampling to set node E to

one of the states ('1_, e2) according to the distribution
given in Table 6, which is identical to the second column
of Table 5.

Table I: Probability distribution for D givenB and C

Table 5: Probability ofE given C

P( D IBC )
Pm

Pm

P2 11

P 22 1

P112

P122

P2 12

P222

Since D is observed to be

j) normalizes the terms:

P(E I C )

d.z, the sampling distribution for

the parents of D is based on the second row of Table 1.

Table

The sampling distribution, over the states in XP(Pa 0 (OJ),
{b 1c1, b1 c2, b2c1, b2c2}, is shown in Table 2.

cz

6: Sampling Distribution forE

Table 2: Sampling Distribution forB and C
In forward sampling, the sampling distribution is the same
P tt2

Pt22

P 2 12

P 222

a

0:

a

a

The constant a normalizes the terms to sum to 1, namely:
a"' Nonn(D=dz) = P 1 12 + P 122 + P 2 12 + P 22 2
·

as the probability distribution, so no normalization
constant is necessary (the terms already sum to

Suppose that the sampling step setsE to e 1 .

1).

This example trial has instantiated the network to the joint
state a2b1 c2d2 e 1. The trial score that would be added to
the beliefs of the currently-selected states of each node

would be

Suppose that the sampling step chooses joint state b 1c2
and sets the states of B and C to these values.
Next, we would sample nodeB to set node A to one of the

states { a1, a2} according to the distribution over these
states.
Table 3 shows the conditional probability
distribution of B given A, whereas Table 4 shows the
sampling distribution for A.

Table 3: Probability ofB given A
P(B I A)

4.5 CORRECTNESS AND CONVERGENCE
Backward simulation meets the single constraint for a
valid importance sampling procedure: no point in the

joint state space of the prior distribution with positive
probability can have a probability of zero in the sampling
distribution.

As a form of importance sampling with likelihood

weighting, backward simulation inherits the convergence
properties of importance sampling (Shachter, 1989). That

is, the beliefs generated by the simulation are guaranteed

to converge to their true values, with the errors decreasing
in proportion to the square root of the number of trials.

231

Backward Simulation in Bayesian Networks

5

DISCUSSION

S to s2, and would set the trial score Z to e, a relatively
small number. The belief corresponding to

5.1 BENEFITS AND COSTS

1! 8),

remain at zero. After many trials (on average, about

The backward-simulation method is well-suited to
inference in situations with low-likelihood evidence. By
working from the evidence, the method focuses on
instantiating those scenarios that are most compatible with
the observed network state, rather than with the prior
distribution. The effect

� will be

augmented by this score, whereas the belief of s1 will

of the prior distribution is taken

into account by the trial weights. If the prior probabilities
are diffuse, compared to the evidence likelihoods, the

nodeS will be set to s1 and the trial score Z would be 1-e.

Now, because of this one trial, the belief of s 1 will

discovered, after much work, that s 1 is the most likely

explanation for the evidence observed.
Table

7:

ForwardSampling Distribution forS
P(S)

weights also will be diffuse, and the inference method will
converge to the correct solution much faster than would

for low-likelihood evidence is illustrated by the two-node
network in Figure 2. NodeT has been observed at value
t1, and nodeS has two states, s1 and�-

1-8

8

forward-simulation methods.
This benefit of backward sampling over forward sampling

be

much greater than the belief of s 2; we will have

Table

8 shows the backward sampling distribution for S.

If we use backward sampling fromT to S, S will be set to
state s1 in the preponderance of trials. The belief of s 1
will be augmented in each trial by

Z=o, and the belief of

s2 by zero. Thus, from the start, the simulation is more in
line with the most probable diagnosis, s 1.
Table

8:

BackwardSampling Distribution forS

€

1-€

The main cost of backward sampling is the computational
resources required for computing the normalization
Figure

2: Two-node Network With Low-likelihood
Evidence.

Suppose that the prior and conditional probabilities are as
follows, with 0 < £ <<

� << I:

(
P(S

) o
s2 ) = (1-o)
P{T = t1 IS= st ) (t- e)
=

=

=

)

P T =t 11S=s2 =e
Using exact inference (Bayes's rule), we can show that,
although the prior for state

Although in

general

the

costs

grow

exponentially with the number of predecessors, the costs
can be reduced where there are special network structures
such as invertible continuous functions or noisy-or
relationships

P S = st

(

constants.

� is much less than that for

state s2, s1 is the most likely explanation for the evidence:

Backward simulation is related to the method of evidential
integration (Chin,

1987;

Fung,

1989)

that has been

suggested for use with simulation methods. In evidential
integration, arc reversals are used as a pre-processing step
to integrate the evidence into the network, to convert
extremal

likelihoods

to less

extreme

likelihoods.

Evidence integration is computationally expensive;
backward

simulation

does part of what

evidence

integration does (when it computes the normalization
constants), at a fraction of the cost.
For networks in which the conditional probabilities do not
change, the normalization constants can be precomputed
and cached, taking much of the work out of each trial.

�(1-e)+(1-o)e
8
e
=--=1---"'1
o+e
0+£
e
-=0
P(s2/t1)�1:"u+e
Table

7 shows the forward sampling distribution forS. If

we use forward sampling from S toT, most trials will set

5.2 EXPERIMENTS
We have run some preliminary experiments comparing
the performance of forward simulation with backward

1,
1989). The probabilities are given

simulation. They were based on the network in Figure
as described in (Fung,
inTable
state e1.

9.

D is observed in state

q and E is observed in

232

Fung and Del Favero

The test routines were written in Macintosh Common
Lisp. We tested a forward simulation method against the
Both use likelihood

backward simulation method.
weighted scoring.

evidence is not particularly unlikely, thus there is no
particular benefit for backward sampling.
Most
importantly, Figures 3 and 4 show that backward
simulation works as an inference method.

Table 9: Probabilities for the Experimental Network

P(A)

P(a1)

=0,20

P(BIA)

P(b11a1)

=0,80

P(b11�)

=0.20

P(CIA)

P(c11a1)

=0.20

P(c11�)

=

P(DIBC)

P(d 11b 1c1)

=0,80

P(d 11b2c1)

=0.80

P(d lib tC2)

::::0,80

P(d11b2c2)

=0.05

=0,80

P(d 11b1c1)

=0.60

P(d11b 1c1)

P(EIC)

6
I::

LIJ
._
0
>

0. 05

0.2

0

0

'B
Cl)

0.1

0

As was done in the previously cited paper, we perform a
large number (250) of runs. In each run, we measure the

500

1000, and 2000 trials, using the absolute-value error

2000

Trials

accuracy of each simulation method at 100, 200, 500,
function below:

1500

1000

Figure 4: Standard Deviation vs. Trials:

Forward {Diamonds) and Backward (Squares)
Although both simulation methods will converge to the

same answer, they may do so at different speeds. This is
the motivation of the next set of runs, which were

Here, Bk(xii•t) is the belief (probability estimate) for
state j of node i on trial t of the kth run. The error,
averaged over all runs, is presented in Figure 3.

The

standard deviation of the errors in the runs is presented in

Figure 4.

performed on

the

same

network

with

the

same

distributions, with the exception of the modified entries

listed in Table 10. The evidence in these runs is that node

D is set to d1. These modifications make the observed
evidence much less likely than before.
Table 10: Modifications to Probabilities in Table 9
for Extreme-probability Experiment

0.5

g
�
0

�
:>

<

0.4

P{DIBC)

P(d 11b1c1)
P(d11b1c2)

0.3

=

0.001

P(d11b2c1)

=

0.0001

P(d11b2c2)

=

0.0001

=

0.05

We record the performance of each method at 10, 20, 50,
100, and 200 trials. The average error and standard
deviation are presented in Figures 5 and 6.

0.2
0.1

Figures 5 and

0
0

500

1000

1500

2000

The conclusion is that we can expect good performance of

Trials

backward simulation at a low numbers of trials in

Figure 3: Error vs. Trials for Two Simulation Methods:
Forward (Diamonds) and Backward (Squares)
Figures 3 and

4 show that backward and forward

simulation are performing equivalently well, with the
backward s imulation method showing slightly lower

average error values.

This is to be expected:

given a

large enough number of trials, both methods will

converge to the same answer.

6 show that at low trial numbers, backward

simulation is consistently closer to the true probability
than forward simulation.

In this example, the

networks with low-l ikelihood evidence. Of course, much
more work is necessary to characterize and understand the
conditions under which each simulation method performs

better than the other. There are cases in which backward
simulation would perform worse than forward simulation:

backward simulation is subject to the proof of Dagum
(1993) that, in the worst case, all approximate

probabilistic methods are NP-hard.

Backward Simulation in Bayesian Networks

In backward simulation, on the other hand, the sampling
order can affect the sampling distribution. This may have
a significance in convergence properties of the simulation.
For instance, in the example of Section 4.4, two possible
sampling orders are { D,E,B}and {D,E,C}. Using the
former, A is backward sampled from B, whereas using the
latter, A is backward sampled from C. Depending on the
structure of the joint distribution P(ABC), the sampling
distribution for A could be quite different between the two
orders. One ordering may be better than the other in
terms of simulation performance.

0.5
0.4

j
t
:>

<

0.3
0.2
0.1
0
0

50

100

150

200

Trials
Figure 5: Error vs. Trials for Second Experimental Run:
Forward (Diamonds) and Backward (Squares)

0.3
...
0

t::
UJ

......
0

The added flexibility is exciting, in that it provides an
opportunity to develop heuristics governing when to
sample a node backward or forward. The hope is that
with backward and forward simulation in the probabilistic
tool chest, as well as evidence integration and other
approximate methods, a simulation run can be optimized
based on the particulars of the network being considered.
6

0.1

There are many interesting avenues of research for
backward simulation. Dynamic node ordering (i.e.,
changing Ns within a single trial or between trials) is
possible and may provide a way to improve performance.
Also, it is possible to group nodes for sampling. For
example, in Figure 1, B and C could be aggregated
together for the purpose of sampling the value of A

'1)

"E

The ordering {A,B,C,E} presents a different type of
flexibility, or ambiguity: it is valid under this order to
instantiate C by forward sampling from A or by backward
sampling from D. There may be a difference in
simulation performance under the different interpretations
of this ordering.

0.2

>

0

233

�

0
0

50

100

150

200

Trials
Figure 6: Standard Deviation vs. Trials for Second Exper­
imental Run: Forward (Diamonds) and Backward
(Squares)
5.3 THE SIGNIFICANCE OF NODE ORDERING
Backward simulation provides a new flexibility in
devising strategies for instantiating the network during a
simulation triaL One strategy would be to use backward
sampling wherever possible. Another would use forward
sampling everywhere (this is just forward simulation). In
between these extremes, there are many possibilities for
mixing both forward and backward sampling.
There are often multiple possible node ordering in
forward simulation as welL However, node ordering has
no impact on the sampling distribution for a particular
node: the distribution is always based on the node's
predecessors, which are always instantiated before the
node itself is.

FUTURE RESEARCH AND
APPLICATIONS

One of the most promising areas of research is the
combination of the backward-simulation method with its
dual, forward simulation. The combination would
provide a complete probabilistic architecture that allows
both data-driven and causal reasoning.
Such an
architecture might have the promise of attacking such
problems as natural-language understanding or speech
recognition. We are currently testing this architecture on
two-level networks with noisy-or relationships between
the nodes such as the QMR-DT network (Shwe, 199Ib).
This combination may make feasible the application of
Bayesian belief networks to many real-world settings that
current techniques cannot handle. For example, it should
be applicable to situations that have large and dynamic
state spaces, and strong evidence. Many sensory
situations (e.g., vision) seem to have this flavor. It seems
to match well with how people reason under uncertainty
- by reasoning from evidence to conclusions. This has
the promise of making explanation of the results of
backward simulation more intuitive than for exact
inference methods.

234

Fung and Del Favero

Acknowledgments

This work was supported in part by NSF Grant IRI9120330.
This work has benefited greatly from discussions with
Mark Peot and Kuo-Chu Chang and from the comments
of the reviewers of this paper.

