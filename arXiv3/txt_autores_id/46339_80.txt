
In this paper, we present the DifferenceBased Causality Learner (DBCL), an algorithm for learning a class of discrete-time dynamic models that represents all causation
across time by means of difference equations
driving change in a system. We motivate
this representation with real-world mechanical systems and prove DBCL’s correctness
for learning structure from time series data,
an endeavour that is complicated by the existence of latent derivatives that have to be
detected. We also prove that, under common
assumptions for causal discovery, DBCL will
identify the presence or absence of feedback
loops, making the model more useful for predicting the effects of manipulating variables
when the system is in equilibrium. We argue analytically and show empirically the advantages of DBCL over vector autoregression
(VAR) and Granger causality models as well
as modified forms of Bayesian and constraintbased structure discovery algorithms. Finally, we show that our algorithm can discover causal directions of alpha rhythms in
human brains from EEG data.

1

INTRODUCTION AND
MOTIVATION

In the past 20 years in AI, the practice of learning
causal models from data has received considerable attention [cf., Pearl and Verma, 1991, Cooper and Herskovits, 1992, Spirtes et al., 2000]. Existing methods
∗

Also Department of Biomedical Informatics, School of
Medicine, University of Pittsburgh.
†
Also Faculty of Computer Science, Bialystok University of Technology, Wiejska 45A, 15-351 Bialystok, Poland.

Marek J. Druzdzel†
marek@sis.pitt.edu
Decision Systems Laboratory
School of Information Sciences
University of Pittsburgh
Pittsburgh, PA, 15260, USA

are based on the formalism of structural equation models (SEMs), which originated in the econometrics literature over 50 years ago [cf., Strotz and Wold, 1960],
and Bayesian networks [Pearl, 1987] which started the
paradigm shift of graphical models in AI and machine
learning 20 years ago. These methods have predominately focused on the learning of equilibrium (static)
causal structure, and have recently gained inroads into
mainstream scientific research, especially in biology
[cf., Sachs et al., 2005].
Despite the success of these static methods, many realworld systems are dynamic in nature and are accurately modeled by systems of simultaneous differential equations. Temporal causality, in general, has
been studied extensively in econometrics over the past
four decades: Granger causality and vector autoregression (VAR) methods have become very influential
[cf., Granger, 1969, Engle and Granger, 1987, Sims,
1980]. In AI, there has been work on learning Dynamic
Bayesian Networks (DBNs) [Friedman et al., 1998] and
modified Granger causality [Eichler and Didelez, 2007].
None of these models explicitly take into account the
fact that many dynamic systems are based on differential equations. This makes their representations overly
general for such systems, allowing arbitrary causal relations across time. In this paper, we show that differential equations impose strict constraints on crosstemporal causal edges, and we present a method that
is capable of exploiting that fact.
This paper considers Difference-Based Causal Models
(DBCMs), a class of discrete-time dynamic models inspired by Iwasaki and Simon [1994] that models all
causation across time by means of difference equations
driving change in the system. This paper presents
the first method to learn DBCMs from data: the
Difference-Based Causality Learner (DBCL). This algorithm treats differences as latent variables and conducts an efficient search to find them in the course of
constructing a DBCM. This method exploits the fact
that unknown derivatives have fixed relationships to

known variables and so are easier to find than latent
variables in general. We prove that DBCL correctly
learns DBCMs given faithfulness and a conditional independence oracle, and show empirically that it is also
robust in the sense of avoiding unnecessary calculations of higher-order derivatives, thus preventing mistakes due to numerical errors. We show that compared
to Granger causality and VAR models, DBCL output
is much more parsimonious and informative. We also
show empirically that it outperforms variants of the
PC algorithm and greedy Bayesian search algorithms
that have been modified to assume DBCM structure.
Finally, we prove that DBCL will always identify instantaneous feedback loops when the underlying system is a DBCM, making it easier to detect when an
equilibrated model will be causal. To our knowledge,
no other method for causal discovery is guaranteed to
identify the presence or absence of feedback loops.

2

for the harmonic oscillator are given by Newton’s 2nd
law describing the acceleration a of the mass under
the forces (due to the weight, due to the spring, Fx ,
and due to viscosity, Fv ) acting on the block. These
forces instantaneously determine a; furthermore, they
indirectly determine the values of all integrals of a,
in particular the velocity v and the position x, of the
block. The longer time passes, the more influence the
forces have on those integrals. Writing this continuous time system as a discrete time model, v and x
are approximately determined by the difference equations: v t+1 = v t + at ∆t and xt+1 = xt + v t ∆t, resulting in the cross-temporal causal links in the graph of
Figure 1(a) and (b). Thus, differential equation systems imply cross-temporal arcs with a regular structure. DBCMs assume that all cross-temporal arcs are
of this form.

DIFFERENCE-BASED CAUSAL
MODELS

Stated briefly, a DBCM is a discrete-time model, based
on SEMs, with a graphical interpretation very similar
to DBNs. Contemporaneous causation is allowed, i.e.,
like DBNs, variables can be caused by other variables
in the same time slice. The defining characteristic of
a DBCM is that all causation across time is due to a
derivative (e.g., ẋ) causing a change in its integral (e.g.,
x). This cross-temporal restriction makes DBCMs a
subset of causal models as defined by Pearl [2000] and
structural equation models similar to those discussed
50 years ago by Strotz and Wold [1960]. DBCM-like
models were discussed by Iwasaki and Simon [1994]
and Dash [2003, 2005] to analyze causality in dynamic
systems, but to date no algorithm exists to learn them
from data.
As an example, consider the set of equations describing the motion of a damped simple harmonic oscillator
(SHO). A block of mass m is suspended from a spring
in a viscous fluid and several different forces are acting
on it, such as the forces resulting from the spring and
that of gravity. The harmonic oscillator is an archetypal dynamic system, ubiquitous in nature. Although
a linear system, it can form a good approximation to
many nonlinear systems close to equilibrium. Furthermore, the F = ma relationship is a canonical example of contemporaneous causation: applying a force to
cause a body to accelerate instantly. Thus, although
this system is simple, it illustrates many important
points. Causal interactions even in such a simple system are problematic when using standard representations for causality, as we will show shortly.
Like all mechanical systems, the equations of motion

(a)

(b)

(c)

Figure 1: (a) The causal graph of a DBCM for the
mass-spring system is always first-order Markovian.
(b) The shorthand graph of (a) using dashed edges
to indicate cross-temporal causation. (c) The unrolled
graph with all v’s and a’s marginalized out is infiniteorder Markovian.
More formally, DBCMs are a restricted form of structural equation models (SEMs). We first review these
models, and then discuss our additional constraints.
We use the notation (A ⊥
⊥ B | C ) to indicate that
variable A is conditionally independent on B given a
set of variables C .
Definition 1 (structural equation model). A SEM is
a pair hV , E i, where V = {V1 , . . . , Vn } is a set of
variables, and E = {E1 , . . . , En } is a set of equations
such that each Ei ∈ E can be written in the form:
Vi := fi (W i , γi ) where W i ⊆ V \ Vi is called the set
of causes (or parents) of Vi , denoted by Pa(Vi ), and
the γi are noise terms such that (γi ⊥
⊥ γj ), i 6= j.
The noise terms γi are intended to represent the set of
causes of each variable that are not directly accounted
for in the model. Historically, SEMs use linear equations with normally distributed noise terms.
A SEM defines a directed graph such that each variable X ∈ V is represented by a node and there is
an edge Y → X for each Y ∈ Pa(X). In this way,
SEMs can model relations between variables in a very

general way. Furthermore, SEMs can be used to represent causality in dynamic systems for a discretetime-setting by defining the set of variables to be a
time-series: V = V 0 ∪ V 1 ∪ V 2 , . . ., where V t =
{V1t , . . . , Vnt } denotes the set of n variables at time t.
We call SEMs that partition their variables according
to time indices dynamic SEMs.
DBCMs are a restricted form of dynamic SEMs. They
assume that all causation across time is due to instantaneous causation of the difference of some variables:
Definition 2 (Difference variable). Let V = V 0 ∪
V 1 ∪ V 2 ∪ . . . be a time-series. The n-th order difference variable ∆n V t of variable V t ∈ V t is defined
recursively as:
∆n V t = ∆n−1 V t+1 − ∆n−1 V t ,

with ∆0 V t = V t .

In particular: ∆1 V t = V t+1 − V t , which we sometimes shorten to ∆V t . When we invert the difference equation to give the value of V t+1 in terms of
its past value and its difference, we call it the integral
equation of V t+1 . I.e., the integral equation of V t+1
is V t+1 = V t + ∆V t . Integral equations are identities and so are always deterministic. The graphs of
Figure 1 use the standard notation from physics such
that the derivative of x is velocity (v ≡ ∆1 x) and the
derivative of velocity is acceleration (a ≡ ∆2 x).
A DBCM is a dynamic SEM in which all causation
across time is due to the presence of integral equations. Because all DBCMs are based on difference
equations that do not vary from time to time, we can
restrict ourselves to partitioning the variables into two
time slices {0, 1}, where the 0th time slice determines
the initial conditions and 1st time slice determines the
transitions:
Definition 3 (Difference-Based Causal Model). A
DBCM M is a dynamic SEM S = hV , E i with V =
V 0 ∪ V 1 and E = E 0 ∪ E 1 such that there exists
a cross-temporal parent of some variable Vi1 ∈ V 1 if
and only if Ei1 is the integral equation for variable Vi1 .
This definition implies that the parent set of a variable X 1 that has parents in the previous time slice is
Pa(X 1 ) = {X 0 , ∆X 0 }. If this is the case, we call X an
integral variable. An integral variable X is part of a
chain of causation ∆j X 0 → ∆j−1 X 1 → . . . → X j .
We call the highest derivative (∆j X) of this chain
the prime variable of X, which we will also denote
as Prime(X). In the example of Figure 1, variables x
and v are integral variables, and a is the prime variable
of x and v.
Finally, any variable that is not an integral variable
and is not a prime variable is called a static variable. This term does not imply that the variable is

not changing from time-step to time-step, because it
might have a causal ancestor that is part of an integration chain. However, we use this term to emphasize that the change is not due to a dynamic process
involving these variables. In Figure 1, m, Fv and Fx
are static variables.
The definition of DBCMs does not require that the
contemporaneous structure be acyclic; however, in this
paper we only consider acyclic DBCMs. It should be
emphasized that this assumption does not restrict us
to non-feedback systems; rather, this assumption implies that all feedback requires time to occur and thus
will only occur through an integral variable. E.g., the
position x of the mass in the SHO causes an instantaneous spring force Fx that results in an instantaneous acceleration a. Over time, a causes a change
in x via integration. Thus we have the feedback loop:
x0 → Fx0 → a0 → v 1 → x2 . Although the instantaneous part, x0 → Fx0 → a0 , is acyclic, this is still
a feedback system. Fb(X) is the set of instantaneous
descendants of X which are also ancestors of Prime(X)
(in this example, Fb(x) = {Fx }). Another interpretation is that by rejecting instantaneous loops we assume
that the observation time-scale is much smaller than
any time-scale of the system dynamics.
Since the contemporaneous structure is not changing
over time, the equations in E 0 and E 1 are partially
overlapping: those that correspond to contemporaneous structure are identical in both sets, but E 0 contains initial conditions for all integral variables, and
E 1 contains integral equations for integral variables.
The graph in Figure 1(b) is a compressed version of the
fully unrolled DBCM. The cycle in the graph caused by
the dashed links is really an acyclic structure extending
across time.
2.1

COMPARISON OF
REPRESENTATIONS

Dynamic SEMs, like Granger causality and VAR models, allow arbitrary edges to exist across time. For
many real physical systems this representation is too
general.
DBCMs, by contrast, assume that all causation works
in the same way as in mechanical systems. This restriction represents a tradeoff between expressibility
and tractability. On one hand, DBCMs are only able
to represent mechanical systems that are first-order
Markovian. On the other hand, DBCMs are in principle easier to learn because, even when the derivatives
are unobserved in the data as we will assume (e.g., in
the previously introduced example we do not include
v and a, or any other derivative in the data set), at
least we know something about these latent variables

that are required to make the system Markovian.
When confronted with data that was generated by differential equations with some derivatives missing, the
distinction between DBCL and the other approaches
becomes glaring. Whereas, as we will show shortly,
DBCL attempts to search for and identify the latent
derivative variables, other approaches would try to
marginalize them out. One might suspect that there
is not much difference. For example, one might expect
that a second order differential equation would simply result in a second-order Markov model when the
derivatives are marginalized out. Unfortunately that is
not the case, because the causation among the derivatives forms an infinite chain into the past. Thus, any
approach that tries to marginalize out the derivatives
must include infinite edges in the model, for example,
such as those in Figure 1(c). In the harmonic oscillator system with all derivatives marginalized out, all
parents of a in time-slice i of the DBCM are parents
of x for all time slices j > i + 1. Thus, the benefits of
using the DBCM representation are not merely computational, but in fact, without learning the derivatives directly, the correct model does not have a finite
representation.

3

DBCM LEARNING

The DBCM Learning problem can be posed in the
following way: Given time-series data over a set of
variables V , derive a DBCM over a set of variables
V ∪ V∆ , where V∆ contains differences of variables
that are derived from the original data. In other words,
DBCL does not assume all relevant derivatives or the
order of those derivatives are known. Instead, it treats
these missing derivatives as latent variables and tries
to discover them. We assume that, aside from these
derivatives, there are no other latent confounding variables present. Note, for example, that this assumption
also rules out the existence of structures of the form
∆X → X → Y , where ∆X and X are latent and Y is
observable, because the X process forms a latent chain
across time that can confound Y at different times.
DBCL relies on the standard assumption of faithfulness [Spirtes et al., 2000]. Faithfulness is the converse
of the Markov condition, and it is the critical assumption that allows structure to be uncovered from independence relations. However, when a dynamic system
goes through equilibrium, by definition, faithfulness is
violated. For example, if the motion of the block in the
simple harmonic oscillator reaches equilibrium then,
by definition, the equation a = (Fx + Fv + mg)/m becomes 0 = Fx +Fv +mg. This means that the values of
the forces acting on the block are no longer correlated
with the value of a, even though they are direct causes

of a. Thus, by assuming faithfulness, we are implicitly
assuming that no equilibrations have occurred.
3.1

THE ALGORITHM

DBCL consists of two steps: (1) detecting prime (and
integral) variables (V∆ ), and (2) learning the contemporaneous structure. The first step is achieved by calculating numerical derivatives of all variables and then
deciding which ones should be prime variables. This
is based on the following theorem, which exploits the
fact that only prime variables can always be made independent across time by conditioning on variables in
V 1:
Theorem 1 (detecting prime variables). Let I be the
set of conditional independence relations implied by
faithfulness applied to a DBCM M = hV , E i with
V = V 0 ∪ V 1 and E = E 0 ∪ E 1 . Let ∆j X 0 denote the j-th order difference of some X 0 ∈ V 0 . Then
∆j X 0 is the prime variable of X 0 if and only if it can
be d-separated from itself in the future and none of the
lower order differences can be d-separated, i.e.:
1. there exists a W
⊂
V1
j 0
j 1
(∆ X ⊥
⊥ ∆ X | W ) ∈ I, and

such

that

2. there exists no set W 0 ⊂ V 1 such that
(∆k X 0 ⊥
⊥ ∆k X 1 | W 0 ) ∈ I, for all k < j.
Once we have found V∆ , the set of integral and
prime variables in the model, learning contemporaneous structure over the two-time-slice model becomes a
problem of learning a time-series model from causally
sufficient data (i.e., there do not exist any latent common causes).
Theorem 2 shows that we can learn the contemporaneous structure from time-series data despite the fact
that data from time-to-time is not independent. This
is because we know by construction that the integral
variables will d-separate the time slices, so all structure between variables can be obtained by conditioning
only on variables in the same time slice:
Theorem 2 (learning contemporaneous structure).
Let I be the set of conditional independence relations implied by faithfulness applied to a DBCM M =
hV , E i, where V = V 0 ∪ V 1 . There is an edge
X 1 − Y 1 if and only if:
1. Either X 1 or Y 1 is not an integral variable, and
1

2. there exists no V 0 ⊂ V 1 \ {X 1 , Y 1 } such that
1
(X 1 ⊥
⊥ Y 1 | V 0 ) ∈ I.
In addition to having discovered the latent variables
in the data, and the structure between non-integral

variables, we also know that there can be no contemporaneous edges between two integral variables, and
integral variables can have only outgoing contemporaneous edges. We can thus restrict the search space
of causal structures. Theorems 1 and 2 together with
these constraints form the basis of the DBCL algorithm:
Algorithm 1 (DBCL (sketch)).
Input: a maximum difference parameter kmax > 0,
a time-series dataset D over a set of variables V 0 =
0
0
V0 ∪V1 .
Output: a set V∆ of prime and integral variables,
0
and a partially directed graph G over V = V ∪ V∆ .
1. Find relevant latent derivatives (Theorem 1):
(a) Initialize k = 0, and let V∆ be all differences
up to kmax .
(b) Let W be all variables plus their differences
up to kth order that are in V∆ .
(c) For all V ∈ V 0 without a prime variable,
check to see if there exists a set W 0 ⊂ W
that renders ∆i V 0 independent of ∆i V 1 , for
the i ≤ k. If so, remove all ∆j V 1 , j > i0 ,
from V∆ where i0 is the lowest i for which
the independence occurred.
(d) Let k = k + 1. If not all prime variables have
been found and k ≤ kmax , go to Step 1b.
2. Learn the structure (Theorem 2):
(a) Learn the contemporaneous structure by using any correct causal discovery algorithm
under causally sufficient data. Impose the
following constraints:
i. Forbid edges between all integral variables.
ii. If X is an integral variable with an edge
X − Y , direct the edge such that X → Y .
(b) Add all cross-temporal links specified by the
set of integral and prime variables.
The output of DBCL will depend on the algorithm
used in Step 2. Our implementation is based on
the constraint-based search PC algorithm, so the contemporaneous structure will be a partially directed
graph that represents the statistical equivalence class
in which the true directed graph belongs. One might
argue that because there are deterministic relationships (the integral equations) in a DBCM, the faithfulness assumption is not valid. However, all deterministic relations involve exactly 3 variables, e.g., ∆X 0 , X 0
and X 1 . However two of those variables are in time
slice 0, so DBCL’s conditioning tests never involve all
three variables at the same time. The hidden variable
thus effectively adds noise to the deterministic relationship.

3.2

IDENTIFICATION OF EMC
VIOLATION

Given a model output from DBCL, one might be interested in performing causal inference, i.e., prediciting the effects of manipulating components of the system. This operation is complicated by the presence of
equilibrations that may have occurred in the system.
Dash [2003, 2005] shows that some dynamic systems
do not obey Equilibration-Manipulation Commutability (EMC), i.e., the causal graph that results when
an equilibrium model is manipulated can be different
from the (true) graph that results when the dynamic
model is manipulated and then equilibrated. Dash
points out two conditions which aid in EMC identification: First, if a variable is self-regulating, meaning
that X ∈ P a(Prime(X)), then when X is equilibrated,
the parent set of X and the children set of X are unchanged. Thus, with respect to manipulations on X,
the EMC condition is obeyed. Second, a sufficient condition for the violation of EMC exists when the set of
feedback variables of some (non-self-regulating) X is
nonempty in the equilibrium graph. In this case, there
will always exist a manipulation that violates EMC.
Given a DBCM with all edges oriented, it is trivial to
check these two conditions; however, since DBCL is
not guaranteed to find the orientation of every edge
in the DBCM structure, it is not obvious that DBCL
is useful for identifying EMC violation. The following
theorem shows that DBCL output will always identify
self-regulating variables:
Theorem 3. Let D be a DBCM with a variable X
that has a prime variable Prime(X). The partially
directed graph returned by Algorithm 1 with a perfect
independence oracle will have an edge between X and
Prime(X) if and only if X is self-regulating.
It is easy to show that a feedback set of X is empty
if and only if all paths from X to Prime(X) have
a collider. Again, since DBCL is not guaranteed to
identify all edge orientations, not all colliders are necessarily identified. According to the faithfulness condition, DBCL will detect a correct equivalence class,
and so will detect the correct adjacencies and the
correct v-structures (unshielded colliders); thus Theorem 4 shows that we can always identify whether or
not Fb(X) is empty:
Theorem 4. Let G be the contemporaneous graph
of a DBC model. Then for a variable X in G,
Fb(X) = ∅ if and only if for each undirected path P =
hP0 , P1 , . . . , Pn i between P0 = X and Pn = Prime(X),
there exists a v-structure Pi → Pj ← Pk in G such that
Pi , P j , P k ∈ P .
Theorem 4 asserts that we can determine whether or

not there exists a directed path from X to Prime(X).
In fact, this theorem does not make use of the fact
that the path terminates on a prime variable, so it
actually serves as an identifiability proof for all causal
descendants of any integral variable.

4

RESULTS

For our empirical studies, we generated data from real
physical systems that are representative of the type of
systems found in nature. We also applied DBCL to
real EEG brain data to reveal the causal propagation
of alpha waves.1
Validation of DBCL is complicated by the fact that, as
far as we know, there exist few suitable baseline methods that are even in principle able to correctly learn
a DBCM when derivatives are unknown. As discussed
in Section 2.1, if one tries to learn causal relations with
the latent variables marginalized out, an infinite-order
Markov model results (Figure 1(c)). The FCI algorithm [Spirtes et al., 2000], which attempts to take into
consideration latent variables, would also result in an
infinite-order Markov model because it does not try to
isolate and learn the latent variables and the structure
between them and the observables. The structural EM
algorithm [Friedman, 1998] does try to learn explicit
latent variables and structure. However, applying it
naively would be unfair since DBCL uses background
information about the latent variables that structural
EM would not be privy to.
Thus, in order to provide a fair baseline, we chose
to adapt some standard algorithms for discovery from
causally sufficient data by providing them with known
information about the latent derivatives. We used
both the PC algorithm and a greedy Bayesian approach on a data set with all differences up to some
maximum kmax = 3 calculated a priori, and we applied
some heuristics to interpret the output as a DBCM.
While perhaps not fully satisfying, we felt that this
provided the fairest comparison to a baseline. Essentially, this allows us to assess how well Step 1
of DBCL (the main novel component) performed on
learning latent differences. Once those latent differences are found, we used the PC algorithm and the
Bayesian search algorithm to recover the contemporaneous structure, but without imposing the structure
of a DBCM. In PC and DBCM we used a significance
level of 0.01. The Bayesian approach starts with an
empty network and then first greedily adds arcs using a Bayesian score with the K2 prior [Cooper and
1
All experiments were performed with SMILE,
a Bayesian inference engine developed at the
Decision Systems Laboratory and available at
http://genie.sis.pitt.edu/.

Herskovits, 1992], and then greedily removes arcs. For
the Bayesian approach we discretized the data into five
bins with approximately equal counts. It is possible to
use a Bayesian approach without discretizing the data
[Geiger and Heckerman, 1994], which we may explore
in the future.
4.1

HARMONIC OSCILLATORS

We tested DBCL on models of two physical systems,
namely a SHO and the more complex coupled SHO
shown in Figure 2(a). Although the SHO is a deter-

(a)

(b)

(c)
Figure 2: (a) The causal graph of the coupled SHO
system. (b) A typical Granger causality graph recovered with simulated data. (c) The number of parents
of x1 over time-lag recovered from a VAR model (typical results).
ministic system, having noise is still realistic: e.g., friction, air pressure, temperature, all of these factors are
weak latent causes that add noise when determining
the forces of the system. Thus all non-integral equations used Gaussian error terms that were resampled
at every time interval. For both systems we selected
parameters of our models in such a way that they were
stable, i.e., produced measurements within reasonable
bounds. We generated 100 data sets of 5,000 records
for each system. We should emphasize that, as mentioned earlier, we do not include the derivatives in the
data set, but only the original variables.
We first computed Granger causality models and VAR
models for some of the simulated data for the coupled
SHO just to illustrate how uninformative these models

are when the latent derivatives are unknown. Those results are shown in Figure 2(b) and Figure 2(c), respectively. The Granger graph is more difficult to interpret
than the DBCM because of the presence of multiple
double-headed edges indicating latent confounders. It
was noted that the sole integral variables appeared in
the Granger graph with reflexive edges, which might
lead to an alternative algorithm for finding prime variables. However, the Granger graph does not provide
enough information to perform causal reasoning. The
VAR model is also difficult to interpret, as it attempts
to learn structure over time of an infinite-order Markov
model. The graph of Figure 2(c) shows that variable
x1 has 65 parents spread out over time-lags from 1 to
100 (binned into groups of ∆t = 20) at significance
level of 0.05. Thus while VAR models might be useful for prediction, they provide little insight into the
causality of DBCMs.
There were four algorithms used for quantitative baselines: two based on the PC algorithm and two based on
the Bayesian algorithm. We will call them P C1 , P C2 ,
B1 , and B2 , respectively. For all baselines the procedure for detecting the prime variables was the same:
all derivatives up to a maximum order were precalculated, and prime variables were determined to be the
lowest order derivative that was not connected to itself
in the future in the output graph. In the second step
P C1 and B1 reported the contemporaneous structure
that was found during the search for prime variables.
For P C2 and B2 , a separate step was made wherein we
created a new dataset using only the derivatives found
in step 1, and relearned contemporaneous structure
from this reduced dataset. The results for the SHO
are shown in the following table:
PC1
PC2
B1
B2
DBC

%∆low
0.00
0.00
17
17
0.00

%∆hi
0.50
0.50
72
72
0.50

%Edel
39
100
60
78
0.40

%Eadd
230
100
200
120
1.2

%Oerr
26
1.0
20
14
0.60

The first two columns of the table show the percentage
of derivatives too low and to high, respectively. The
other three columns of the table show the percentage of edges that were deleted, added, and incorrectly
oriented. For example, on average, DBCL added 1.2
extra edges for every 100 edges in the correct graph,
whereas P C2 added 104 extra edges per 100 original
edges.
The table below shows the results for the coupled SHO:
P C1
P C2
B1
B2
DBC

%∆low
0.00
0.00
0.00
0.00
0.00

%∆hi
12
12
93
93
0.25

%Edel
40
84
64
42
0.58

%Eadd
200
26
170
140
1.3

%Oerr
23
14
8.5
21
6.4

These results show that DBCL is effective at both

learning the correct difference variables and of learning contemporaneous structure of these systems. For
the SHO, the PC baselines are performing as well as
DBCL for discovering prime variables; however, when
the network gets more complicated, there is a clear
difference. Also, in all cases the second step makes
a big difference between baselines and DBCM, most
likely because enforcing the DBCM structure is essential. We did try other significance levels besides 0.01,
but all results showed the same trend.
4.2

EEG BRAIN DATA

In our second experiment, we attempted to learn a
DBCM of the causal propagation of alpha waves, an
8-12 Hz signal that typically occurs in the human brain
when the subject is in a waking state with eyes closed.
Subjects were asked to close their eyes and then an
EEG measurement was recorded. The data consisted
of 10 subjects and a multivariate time series of 19 variables was recorded for each subject 2 , containing over
200,000 time steps at a sampling rate of 256 Hz. Each
variable corresponds to a brain region using the standard 10-20 convention for placement of the electrodes
on the human scalp.
Alpha rhythms are known to operate in a specific frequency band peaking at 10 Hz. To focus our results
more on this process, we tried learning a DBCM using just the 10 Hz power signal over time. We divided
the data into 0.5s segments, performed a FFT on that
segment and extracted the power of the 10 Hz bin for
each time slice. When learning the DBCM, we used
the same significance level and kmax as before. The
result for subject 10 is displayed in Figure 3. The circles represent the 19 variables that correspond to the
brain regions. The top of this graph represents the
front of the brain and the bottom the back. The small
squares in each circle represent the derivatives that
were found. The lower left is the original EEG signal,
the lower right the first derivative, the top right the
second derivative, and the top left the third derivative. In some regions, no derivatives were detected, so
those squares have been left out.
Here (and in typical subjects) there are only a few
regions that required derivatives to explain their variation. The locations of those regions varied quite a bit
from subject to subject, but there were some common
patterns. Across all subjects, 16 of 20 occipital regions
had at least one derivative present. This contrasts to
the frontal lobes where across all subjects only 1 of 70
frontal regions had one derivative or more. When a
region had at least one derivative, rarely, if ever, did
2
Data available at http://www.causality.inf.ethz.ch
/repository.php?id=17

5

Figure 3: Output of DBCL on data filtered for alpha
wave power.

it also have an incoming edge from some region that
did not have a derivative. This suggests that the regions containing the dynamic processes were the primary drivers of alpha-wave activity. Since most of
these drivers occurred in the occipital lobes, this is
consistent with the widely accepted view that alpha
waves originate from the visual cortex.
There were many regions that did not require any
derivatives to explain their signals. The alpha wave
activity in these regions is quickly (< 0.5s) determined
given the state of the generating regions. One hypothesis to explain this is given by Gòmez-Herrero et al.
[2008] where they point out that conductivity of the
skull can have significant impact on EEG readings by
causing local signals to be a superposition of readings
across the brain. Thus, if the readings of alpha waves
detected in, say, the frontal region of the brain is due
merely to conductivity of the skull, we would have effectively instantaneous determination of the alpha signal in those regions given the value in the regions generating the alpha waves.
We should note that when DBCL is applied to the
raw (unfiltered) data, the resulting DBCM is much less
neat: Most regions have at least one derivative present,
and connectivity among regions is much higher and
more difficult to interpret. This is not surprising given
the massively parallel activity occuring in the brain,
and it suggests that when seeking to learn causal interactions in the brain, it may be useful to partition
brain signals into different frequency bands. We hope
to look more fully into different bands and possibly for
causal interactions among different bands.

DISCUSSION

The main contribution of this work is to present a new
representation for learning models from time-series
data. While DBCMs have been discussed elsewhere in
terms of analyzing causality of dynamic systems, there
has not as yet been an algorithm to learn them from
data. This paper presents such an algorithm and, in
the process, makes DBCMs accessible to a wide range
of practitioners in econometrics, biology and AI who
currently rely on Granger causality, vector autoregression or graphical models to model dynamic systems.
We have argued that DBCMs are particularly suited
to learning systems which are based on differential
equations, and have shown empirically that, for such
systems when the relevant derivatives are unknown,
DBCL will learn models accurately where existing approaches will fail. We have proven that under common
assumptions DBCL will learn the correct equivalence
class for a DBCM, and have shown that several important feautures of the underlying DBCM are identifiable from this equivalence class, such as the presence
of feedback loops and the set of descendants of integral
variables.
While there exist mathematical dynamic systems that
cannot be written as DBCMs, we believe that systems based on differential equations are ubiquitous in
nature, and, therefore, will be well approximated by
DBCMs. Furthermore, we have argued that there does
not exist a representation that is capable of learning
a finite model of these systems without first finding
the correct latent derivative variables. This is because
marginalizing out latent derivative variables results in
an infinite-order Markov model. Thus our method can
be viewed as contributing to the very hard problem of
discovering latent common causes in difference equation systems.
We have also shown that DBCL can learn parsimonious representations for causal interactions of alpha
waves in human brains that are consistent with previous research. We plan to apply this method to understanding causal pathways in the brain more broadly
using a combination of EEG and MEG brain data.
In general, we find it surprising that after nearly 50
years of developing theories for identification of causes
in econometrics, rarely, if ever, have researchers attempted to apply these theories to even the simplest
dynamic physical systems. We feel that our work thus
exposes a glaring gap in causal discovery and representation, and we hope that by reversing that process—
applying a representation that works well on known
mechanical systems to more complicated biological,
econometric and AI systems—we can make new inroads to causal understanding in these disciplines.

Acknowledgments
Marek Druzdzel was supported in part by the National
Institute of Health under grant number U01HL10106601. We would like to the thank the anonymous reviewers for their useful feedback.



Numerous temporal inference tasks such as
fault monitoring and anomaly detection exhibit a persistence property: for example, if
something breaks, it stays broken until an
intervention. When modeled as a Dynamic
Bayesian Network, persistence adds dependencies between adjacent time slices, often
making exact inference over time intractable
using standard inference algorithms. However, we show that persistence implies a regular structure that can be exploited for efficient inference. We present three successively more general classes of models: persistent causal chains (PCCs), persistent causal
trees (PCTs) and persistent polytrees (PPTs),
and the corresponding exact inference algorithms that exploit persistence. We show
that analytic asymptotic bounds for our algorithms compare favorably to junction tree inference; and we demonstrate empirically that
we can perform exact smoothing on the order of 100 times faster than the approximate
Boyen-Koller method on randomly generated
instances of persistent tree models. We also
show how to handle non-persistent variables
and how persistence can be exploited effectively for approximate filtering.

1

Introduction

Persistence is a common trait of many real-world systems. It is used to model permanent changes in state,
such as when components of a system that have broken until someone intervenes to fix them. Especially
interesting and useful are diagnostic models where misalignments and other process drifts may cause a cascade of other failures, all of which may also persist
until the root cause is fixed. Even when such changes
are not truly permanent, they are often reversed slowly

Denver H. Dash
Intel Research and
Department of Biomedical Informatics
University of Pittsburgh
Pittsburgh, PA 15213

relative to the time scale of the model, and persistence
can be a good approximation in such systems. For instance, vehicular accidents cause obstructions on the
road that last much longer than the required detection time and are thus persistent for the purpose of
detection [20]. Another example is outbreak detection [4], where an infected population stays infected
much longer than the desired detection time. There
are many other examples of persistence and approximate persistence.
Dynamic Bayesian Networks (DBNs) [5] are a general
formalism for modeling temporal systems under uncertainty. Many standard time-series methods are special cases of DBNs, including Hidden Markov Models
[18] and Kalman filters [7]. Discrete DBNs in particular are a very popular formalism, but usually suffer from intractability [1] when dense inter-temporal
dependencies are present among hidden state variables, leading many to search for approximation algorithms [1, 13, 15, 14]. Unfortunately, modeling persistence with DBNs requires the introduction of many
inter-temporal arcs, often making exact inference intractable with standard inference algorithms.
In this paper, we define Persistent Causal DBNs (PCDBNs), a particular class of DBN models capable of
modeling many real-world systems that involve long
chains of causal influence coupled with persistence of
causal effects. We show that a linear time algorithm
exists for inference (smoothing) in linear chain and
tree-based PC-DBNs. We then generalize our results
to polytree causal networks, where the algorithm remains exact, and to general networks, where it inherits properties of loopy belief propagation [21]. Our
method relies on a transformation of the original prototype network, allowing smoothing to be done efficiently; however, this method does not readily deal
with the incremental filtering problem. Nonetheless,
we show empirically that, if evidence is observed at
every time slice, approximate filtering can be accomplished with fixed window smoothing, producing lower
error than approximate Boyen-Koller (BK) filtering [1]

using a fraction of the computation time.
The algorithm that we present exploits a particular type of determinism that is given by the persistence relation. There has been other work that seeks
to directly or indirectly exploit general deterministic
structure in Bayesian networks using compilation approaches [2], a generalized version belief propagation
[10], and variable elimination with algebraic decision
diagrams [3, 19]. These more general methods have
not been tailored to the important special cases of
DBNs and persistency. To our knowledge, this is the
first work to investigate persistency in DBNs.
The paper is organized as follows: In Section 2 we
introduce the changepoint transformation. Section 3
introduces persistent causal chain DBNs and the corresponding inference algorithm, which retains all the
essential properties of later models. Then, Section 4
will discuss the steps leading to a fully general algorithm. Experimental results are presented in Section
5, followed by conclusions.

2

Notation and changepoints

Consider a Bayesian network (BN) with N binary variables Xi ; we will refer to this network as the prototype.
The corresponding Dynamic BN with M slices is created by replicating the prototype M times and connecting some of the variables to their copies in the next
slice. In our notation, upper indices range over time
slices of the DBN; lower indices range over variables
in each time slice. Colon notation is used to denote
sets and sequences. Thus, for instance, X41:M denotes
the entire temporal sequence of values of X4 from time
1 to time M . Variables without an upper index will
refer to their respective counterparts in the prototype.
We say that a variable Xk is persistent if
½
P (Xk |U )
if Xkt−1 = 0
P (Xkt = 1|Xkt−1 , U t ) =
,
1
if Xkt−1 = 1
(1)
where U = P a(Xk ) refers to the parents of Xk in the
prototype. In other words, 1 is an absorbing state.
Sometimes [12] a variable is called persistent if it has
an arc to the next-slice copy of itself. Our definition of
persistence is strictly stronger, but no confusion should
arise in this paper.
There are 2M temporal sequences of values of a binary
variable Xk . If the variable is persistent, the number of
configurations is reduced to M + 1. Information about
Xk1:M can be summarized by looking at the time when
X changed from 0 to 1 (we sometimes refer to the 0
state as the off state and 1 as the on state). Thus,
inference in the persistent DBN with binary variables
is equivalent to inference in a network whose topology closely resembles that of the prototype and whose

variables are M +1-ary discrete changepoint variables,
with correspondingly defined conditional probability
distributions (CPDs), as shown in Figure 1b. The
models in Figure 1a and 1b are identical; one can go
back and forth between them by recognizing that
(X̃ = j) ⇔ (X j = 0) ∧ (X j+1 = 1) and
(X j = 0) ⇔ (X̃ > j).
If the prototype is a tree, belief propagation in the
transformed network yields an algorithm whose complexity is O(M 2 N ). The quadratic part of the computation comes from summing over the M + 1 values
of the single parent for each of the M + 1 values of
the child. Similarly, if the prototype is a polytree,
complexity will be proportional to M Umax +1 , where
Umax is the largest in-degree in the network. This
transformation by itself, when all hidden state variables are persistent, allows us to perform smoothing
much more efficiently than by operating on the original DBN. There is, however, additional structure in
the CPDs that allows us to do better by a factor of M ,
and we can also adapt our algorithm to deal with the
case when some hidden variables are not persistent.

3

PCC-DBN inference

To simplify the exposition, let us now focus on a specific prototype, a persistent causal chain DBN (PCCDBN). This is a chain with P a(Xi ) = {Xi−1 }, i =
1, ..., N and P a(O) = XN (thus it has N+1 nodes).
Let us further assume that the leaves are nonpersistent and observed, while the causes (X nodes)
are all persistent and hidden. The network is shown
in Figure 1a and its transformed version in Figure 1b.
Consider the problem of computing P (O). This is in
general one of the most difficult inference problems, requiring one to integrate out all hidden state variables,
and is implicit in most inference queries:
P (O1:M ) =

X

1:M
1:M
P (O1:M | X1:N
) · P (X1:N
)

(2)

1:M
X1:N

Let {jk : 0 ≤ jk ≤ M } index the sequence of Xk1:M
in which variable Xkjk is the last (highest-time) variable to be in the off state, unless jk = 0 in which case
it indexes the sequence in which all Xk are in the on
state. As an example, if M = 3, then jk = {0, 1, 2, 3}
indexes the states Xk1:M = {111, 011, 001, 000}, respectively, for all k. All configurations not indexed by ji
have zero probability due to the persistence assumption. To simplify notation, we use jk to denote the
event that Xk1:M is the sequence indexed by jk . We
also say that Xk fired at jk . We can decompose Equa-

X11

X12

...

X1M

X̃1

X21

X22

...

X2M

X̃2

where σ̄kL contains all the terms in the sum such that
Xk first fires when Xk−1 has not fired:
X

σ̄kL =

...

...

2
XN

...

...

..

1
XN

.

...

jk <L

M
XN

...

O2

X̃ N

X

σkL =

O1O2 . . . OM

OM

(a)

(7)

σkL contains all the terms in which Xk first fires when
Xk−1 has also fired:

L≤jk <M

O1

k
Pbkjk Pbk · Σjk+1
.

k
PbkL Pkjk −L Pk · Σjk+1
,

(8)

and σ̂kL contains the final term in which Xk never fires:

(b)

σ̂kL = PbkL PkM −L · ΣM
k+1 .

(9)

Figure 1: (a) A PCC-DBN network with N + 1 nodes
per slice; (b) the transformed network. We sometimes
refer to X21 as the temporal parent of X22 and to X12
as its causal parent.

In order to calculate Equation 5 in time O(M N ), we
need to pre-compute σ̄kL , σkL and σ̂kL for all values of L
in O(M ) for each variable Xk .

tion 2 according to the network structure as follows:

3.1

P (O1:M ) =

M
X
j1 =0

...

M
X

P (j1 )

M
X

P (j2 | j1 ) . . .

j2 =0

P (jN | jN −1 ) · P (O1:M | jN )

(3)

jN =0

Denote by Pk the probability that variable Xk will fire
for the first time given that its causal parent has fired,
and by Pbk the probability that Xk will fire for the first
time given that its causal parent has not fired:
Pk

≡

j
P (Xkj = 1 | Xkj−1 = 0, Xk−1
= 1)

Pbk

≡

j
P (Xkj = 1 | Xkj−1 = 0, Xk−1
= 0).

Let Pk and Pbk denote the complements 1 − Pk and
1 − Pbk , respectively. We can define ΣL
k recursively
to denote the partial sum over jk from Equation 3,
conditioned on jk−1 = L:
X
k
ΣL
P (jk | jk−1 = L) · Σjk+1
(4)
k ≡
jk
1:M
with boundary condition ΣL
| jN = L).
N +1 ≡ P (O
Using this notation, Equation 3 can be rewritten as:

P (O1:M ) =

M
X

P (j1 ) · Σj21

(5)

j1 =0

Now we now need to show that one can calculate the
L
entire set Σ0:M
2:N in time O(M N ). Each Σk can be
written as follows:
L
L
L
ΣL
k = σ̄k + σk + σ̂k ,

(6)

Upward Recursion Relations

As a boundary condition for the recursion, assume we
have calculated ΣkN +1 for all 0 ≤ k ≤ M . We show
how to do this in time O(M ) in Section 3.2. Also, this
algorithm requires the pre-calculation and caching of
Pbki for 0 ≤ k ≤ N and 0 ≤ i ≤ M , which can be done
recursively in O(M N ) time and space.
Inspecting Equation 7 more closely, it should be easy
i
to see that one can calculate σ̄N
for 0 ≤ i ≤ M in
O(M ) time using the following recursion:
σ̄li+1 = σ̄li + Pbli · Pbl · Σik+1 ,

(10)

with boundary condition σ̄l0 = 0 for all l. One can also
calculate σki for 0 ≤ i ≤ M with the recursion:
σki−1 =

σki
Pk + Pbki−1 · Pk · Σi−1
k+1 ,
Pb

(11)

k

with boundary condition σkM = 0 for all l. Finally, one
i
can calculate σ̂N
for 0 ≤ i ≤ M with the recursion:
σ̂ki−1 =

σ̂ki
Pk
Pb

(12)

k

with boundary condition σ̂kM = PbkM · ΣM
k+1 for all l.
i
i
i
Once σ̄N
, σN
and σ̂N
are calculated, one can calculate
i
all ΣN for 0 ≤ i ≤ M in O(M ) time using Equations 10, 11, 12 and 6. After Σ0:M
is calculated, we
N
can use Equation 4 to obtain Σ0:M
N −1 in time O(M ),
and repeat N times to get all values of Σ0:M
1:N . Thus
the entire calculation takes O(M N ) time.

3.2

Computing ΣiN +1

To finalize the proof, we have to show how to calculate ΣiN +1 (the probability of the observations for a
1:M
given configuration i of XN
) for all 0 ≤ i ≤ M in
time O(M ). Recall that ΣiN +1 ≡ P (O1:M | jN = i).
Since the parent of each Oj is given, for each i, this
calculation is simply the product of the observations:
P (O1:M | jN = i) =

M
Y

k
P (Ok | XN
, jN = i)

(13)

k=1

Using our existing notation, we define
φ`N +1
φ̄`N +1

=
=

k
P (Ok | XN
= 1),
k

P (O |

k
XN

= 0),

(14)
(15)

ΣiN +1 can be calculated for all 0 ≤ i ≤ M in time
O(M ) via the recursion relation:
M
Y

φ̄`N +1
.
φ`N +1
`=1
(16)
Note that this formulation puts no distributional assumption on P (O|XN ). The leaves can be distributed
as multinomials, Gaussians etc, as is often done with
Hidden Markov models [18] when they are put to their
many uses.
Σ0N +1 =

3.3

φ`N +1

and

`
Σ`+1
N +1 = ΣN +1 ·

Downward Recurrences

The above discussion completes the description of the
“λ-pass” of PCC-DBN algorithm. Similar reasoning
can be applied to obtain the “π-pass” recurrences that
we now give without full derivation. Analogously to
Σ, the semantics of Ψjk is p(Xk = j|Ok+ ), where Ok+ is
the subset of evidence reachable from Xk through its
parent1 . Ψjk is again a sum of three components:
Ψjk = ψkj + ψ̄kj + ψ̂kj

(17)

ψ̄ accounts for the terms where the parent has not yet
changed:
ψ̄k`−1 = ψ̄k` ·

1
+ Pbk`−1 · Pbk · Ψ`k−1
Pk

(18)

with initialization ψ̄kM = 0 for all k.
ψ accounts for the terms where the parent has already
changed:
ψk`+1 = ψk` · Pk + Pbk`+1 · Pk · Ψ`+1
k−1

(19)

1
We only have evidence in the bottom layer in PCCDBNs, but this will come handy in the next section.

with boundary condition ψk0 = Pk Ψ0k−1 for all k. Also,
since Xk eventually changes in this scenario, ψkM = 0.
ψ̂ accounts for the terms where the node never
changes:
X
ψ̂kM =
(20)
Pbki · PkM −i · Ψik−1 .
0≤i≤M

Because the upper index refers to the changepoint of
Xk , only ψ̂kM is non-zero. We can just compute this in
O(M ) without the need for recurrences.
Initialization of the Ψ-recurrences happens at the
root(s) of the network. For any root r, Ψ0r = Pbk and reM −1 b b
= Ψir · Pbr . Finally, ΨM
Pr /Pk .
currently Ψi+1
r
r = Ψr
3.4

PCC-DBN and belief propagation

We have just defined PCC-DBN, a version of belief
propagation that first collects the evidence by passing
the λ-messages towards the root of the chain and the
proceeds to distribute information towards the leaves
via the π-messages. After propagation is complete, we
can obtain any posterior as
p(X̃k |O) = Σk+1 · Ψk .

(21)

It is now useful to recall the types of potentials involved in Pearl’s algorithm [8] and how they relate
to the quantities above. For each node X, there
are local potentials πX (x) ≡def p(X = x|e+
X ) and
+
−
λX (x) ≡def p(e−
|X
=
x),
where
e
and
e
denote
reX
X
X
spectively the evidence reachable through parents and
the evidence reachable from X “downwards”, X included. There are two types of messages in Pearl’s algorithm: πX→Yi sent by X to its children and λX→Ui
sent to its parents. A closer look at PCC-DBN reveals
that each Σk is identical to λXk →Xk−1 — the message
from Xk to its single parent Xk−1 . The local potential
λXk (jk ) is identical to Σk+1 , because there are no children other than Xk+1 and evidence is only observed
at the bottom of the chain. Ψk corresponds directly
to πXk (jk ). This is why Equation 21 works.
3.5

Simple Generalizations and Causal Trees

While PCC-DBNs are useful for demonstrating the
general ideas of handling the probability distributions
arising from the changepoint transformation, they
form a rather restricted class of networks, and the inference query that we performed was also restricted.
Here we state succinctly a set of simple alterations
which allow this algorithm to be relaxed in various
ways:
General evidence patterns We can have observations anywhere in the network, in any time slice.

Casting the inference as belief propagation gives the
answer to any probabilistic query as Equation 21 with
one caveat: An observation such as X33 = 1 does not
tell us with certainty the position of the changepoint,
but it just provides evidence that j3 < 3, thus we
cannot simply set the changepoint variable to state 3.
Rather, the potentials corresponding to such evidence
must be multiplied onto the messages as prescribed by
the belief propagation algorithm (see Equation 22).
Non-stationarity Stationarity of conditional probability distributions was used to simplify the formulae
in the previous exposition, but is not required. All
that is needed is to keep running products of respective
probabilities instead of the powers in the exponents of
Pk , Pbk . They need to be computed incrementally and
tabulated to avoid hidden linear terms in the computation.
Extension to trees The extension of PCC-DBN
to causal trees (PCT-DBNs) is now fairly straightforward. Because each node Xk can now have multiple
children Ch(Xk ), we must replace Σk in all recurrences
with the true λ-potential for Xk :
Y
λXk = λXk →Xk ·
Σi ,
(22)
i∈Ch(Xk )

where λXk →Xk accounts for evidence observed in Xk ’s
temporal chain. The vector λXk →Xk is zero where the
evidence rules out a changepoint — before the time t
of the last observed Xkt = 0 and after the time s of first
observed Xks = 1. Everywhere else, λXk →Xk (jk ) = 1.
Note that λX (x) potential can be obtained in O(M )
time per node.
In computation of ψ potentials, Ψk on the right-hand
side of the recurrences is replaced by the πP a(Xk )→Xk ,
which in turn include the influence of evidence under
Xk ’s siblings:
Y
πP a(Xk )→Xk = πXk ·
Σi .
(23)
i∈Ch(P a(Xk ))\Xk

Again, this preserves the O(M ) per-node complexity.
Thus, PCT-DBN is linear in both N and M .

4

Further Generalizations

In this section we describe three more important generalizations of PC-DBNs: polytrees, non-persistent
nodes, and finally an approximate algorithm for general DAGs. These relaxations are more involved than
those of Section 3.5 and thus require more elaboration.
4.1

Polytrees

Belief propagation [16, 17] is a powerful framework for
exact inference in polytree networks. Polytrees, unlike

trees, allow multiple parents of a node, but remain
acyclic in the undirected sense. In polytree changepoint networks, structure in the conditional probability table P (X = x|U ) can be exploited to save a multiplicative factor of M + 1 just as we showed for tree
networks. The ψ-recurrences run over the first parent variable, while the remaining parents are summed
over by brute force. Similarly, the σ-recurrences run
over the parent that the message is addressed to. For
instance, the definition of σ will be replaced by
" L
# " j
#
k
X
Y (z)
Y
(j +1)
(z)
i
b
σ ∝
P
·
P k
· Σjk
P
k

L≤jk <M

k

z=1

z=L+1

k

k

k+1

(24)
and Equation 11 by
(i)

σki−1
σkM

σki

=
=

·

Pk

(i)
Pbk

+

" i−1
Y
z=1

#
(z)
Pbk

(i)

· Pk · Σi−1
k+1

0,

(25)

where, assuming we are sending to the first parent,
(z)

Pk
(z)
Pb
k

=

P (Xk = 1|U1 = 1, I{U2: ≤ z})

=

P (Xk = 1|U1 = 0, I{U2: ≤ z}) (26)

are now functions of the joint configuration of the remaining parents U2: . The proportionality constant in
Equation 24 equals the product of the remaining parents’ π-messages. We call this PPT-DBN, the persistent polytree algorithm.
The worst-case time complexity of PPT-DBN is dominated by the cost associated with the largest familyclique: O((M + 1)Umax ). The 2T BN algorithm [12]
suffers a worst-case time complexity O(22N M ), as all
nodes in two slices may be entangled [9] in the clique
to connect the two subsequent time-slices, even though
the prototype network is a polytree [12, section 3.6.2].
Therefore, we expect PPT-DBN will be comparatively
better for shorter temporal chains of larger networks.
However, PPT-DBN really shines on space complexity.
At most O(M N ) memory is consumed, compared to
2TBN, where the potentials in the joint tree can grow
as large as O(22N ). Later we show experimentally how
dramatic the difference can be.
4.2

Non-persistent nodes

While it is convenient to assume that all non-leaf variables are persistent, it does limit the modeling power
at our disposal. We now show how an occasional nonpersistent variable in the network can also be handled
in polynomial time. We assume the non-persistent
variable is isolated, that is, all of its neighbors are
persistent. We make this assumption in order to avoid
having to invoke an embedded general DBN inference

X1

X2

X3

with φkj defined appropriately:

X4






P (Y 1 = 0|X 1 )
P (Y = 0|Y k−1 = 0, X k )
φkj (X k ) =
P (Y k = 1|Y k−1 = 0, X k )



1

Ỹ

Figure 2: The minimal example of network with a nonpersistent node.

D

CD

C

BC

(a)
D

(j + 1)
κki (j) = κk+1
i

B

↑ ΣC
D ???

D̃

(b)
(c)
Figure 3: a) Induced cliques and separators b) Enlarged clique for generalized BP c) Σ-message flow in
a network with a non-persistent variable

4.2.2
algorithm such as 2TBN to handle connected nonpersistent variables. It can be done, but quickly becomes complex and inelegant. A simple way to handle connected non-persistent nodes is to combine them
into a single joint node. Obviously, this solution causes
exponential growth in the state space of the joined
nodes, making it somewhat unappealing. A two-slice
approach made aware of the determinism, e.g. by use
of ADD compilation [3, 2], could very well work better
for networks with only a few persistent variables.
4.2.1

To illustrate how an isolated non-persistent node
would be handled, assume first a simple structure
such as in Figure 2. Then we can efficiently compute
P (Ỹ = j) by moving the sums inward:
P
P (Ỹ = j) =
P (X)P (Ỹ = j|X) =
·M X
¸· M
¸
Q
Q k
P
P (X k |X k−1 )
φj =
k=1
X 1 ,...X M k=1X
X
P
P (X 1 )φ1j
P (X 2 |X 1 )φ2j . . .
P (X M |X M −1 )φM
j
X2

|

XM

|

{z

}

{z

κM

}

κ2

This gives rise to the recurrence
X
P (X M = v|X M −1 = i) · φM
κM
j
i (j) =

(27)

v

κki (j) =

X
v

P (X k = v|X k−1 = i) · φkj · κk+1
,
v

∀1 ≤ k < j < M − 1.

The general case

Pearl’s belief propagation has been generalized to the
clique tree propagation algorithm [21]. With belief
propagation (BP), the cliques correspond to edges of
the original polytree and the separators consist of single nodes. In the process of message passing, the variables not in the separator are summed out of the clique
potentials.

A simple example

X1

k=1
1<k≤j
k =j+1
k >j+1

Therefore, we do not need to compute κ for every j,
but compute κki (M ) for all k as a special case and then
κki (M − 1) for all k to start the recursion. All other
values can be read off κki (M − 1) with the appropriate
indexing shift. Thus, we can obtain the entire distribution P (Ỹ ) in O(M ) time! Allowing non-persistent
variables to take on multiple values is also straightforward: we only need to allow the bottom index in κki
to range over the domain of Xk .

j
C 1 C 2 . . . . . . . . .C M ↑ ΣCB

BCD

if
if
if
if

Now, P (Ỹ = j) = κ01 . Moreover, a short analysis will
reveal that

B̃

B

k

The PCT-DBN algorithm used the “natural” cliques
induced by the transformed network. Assume we have
a situation such as in Figure 3. Because the variable
C is not persistent, the size of the induced separator
C is 2M . However, we can work conceptually with
a larger clique BCD. Message propagation then calls
for summing out all C 1:M , which we can do without
actually instantiating the clique potential using a recurrence derived much like that of Equation 27. In
the interest of space, we only show here the simple κ
recurrence. The full recurrence calls for summing over
all persistent variables in the clique and the resulting
complexity is O((M + 1)B ), where B is the number of
persistent neighbors of the non-persistent variable.

5

Experimental evaluation

We implemented our algorithms in Matlab and compare them to the exact and approximate algorithms as
implemented in the Bayesian Network Toolbox (BNT)
[11]. Namely, we will compare to the Boyen-Koller
(BK) algorithm [1] in its 1) exact and 2) fully factored
setting. Although BK reduces in its exact form to
the incremental junction-tree algorithm, we found it
was faster in practice than the 2TBN implementation.

Speedup vs standard inference − growing N

2

Speedup vs standard inference − growing M

2

10

10
exact inference out of memory

1

1

10

Filtering time (sec)

Filtering time (sec)

10

0

10

−1

10

PCT−DBN
BK/exact
BK/approx

−2

10

−1

10

PCT−DBN
BK/exact
BK/approx

−2

10

−3

10

0

10

−3

10

20
30
nodes in thebinary tree

40

50

60

10

70

Figure 4: Performance scale up of PCT-DBN with N .
The temporal length was fixed at M = 20. Note log
scale y-axis.

20

40

60
80
100
Number of time slices

120

140

Figure 5: Performance scale up of PCT-DBN with M .
The number of nodes was held at N = 19.
Scale up − growing N, crosses, M=20

3

10

PPT−DBN
BK/exact
BK/approx

Therefore the 2TBN algorithm is not included in the
evaluation.

5.1

Filtering time (sec)

Matlab run-time is not the ideal measure of algorithm complexity as it is arguably more sensititve to
the quality of implementation compared to other languages. However, we should note that we did not make
any special effort to optimize our code for Matlab, and
the BNT library is a widely used and mature code
base, so we expect any advantages due to code quality
to fall to the competing approaches. Our Matlab code
and further evaluation results can be downloaded at
http://www.cs.pitt.edu/~tomas/papers/UAI08.

2

10

1

10

0

10

−1

10

10

20

30

40
50
60
70
Number of one−slice nodes

80

90

100

Figure 6: Performance scale up of PPT-DBN with N .

Speed of the tree algorithm

To compare inference speed, a network with the structure of a full binary tree with N nodes was generated.
Among the M N possible observations, 10% of the variables were set to a random value (subject to persistence constraints so that P (E) 6= 0). We measured
the time to execute the query p(X̃1 |E)—the posterior
probability over the root node—for each algorithm2 .
This process was repeated 100 times for each M , N
combination and the respective times added up. The
results are graphed out in Figures 4 and 5.
PCT-DBN outperforms both the exact incremental
joint tree algorithm and the approximate BK algorithm (assuming independence) by several orders of
magnitude as N , the size of a slice grows (Figure 4).
In fact, the exact algorithm soon runs out of memory (around N = 20) and only the approximate version keeps up. Exact PCT-DBN inference also performs consistently about 100 times faster than exact
junction-tree and approximate BK inference when we
look at scale-up with the number of slices, as shown in
2
The actual query is in fact irrelevant as all algorithms
compute all posterior marginals simultaneously.

Figure 5.
5.2

Speed of the polytree algorithm

The asymptotic time complexity of PPT-DBN, as M
increases, may be less favorable than that of the incremental approaches. However, its lower memory complexity is very favorable, as documented by the following experiment. We generated a network where most
non-root nodes have exactly 2 parents and measured
the time for the three inference algorithms. Quadratic
scale-up with M is expected for PPT-DBN in such a
network.
Figure 6 shows the exact PPT-DBN algorithm to be
several times faster than, but scaling very similarly
to, the approximate fully factorized Boyen-Koller algorithm with an M = 20 time slice inference window.
Peeking ahead into Figure 7 suggests the time performance would be about identical at M = 70 time slices.
The junction-tree algorithm does not scale beyond 20
nodes due to memory usage.
Figure 7 shows clearly that asymptotically, PPT-DBN

Running error with M, N= 17

Scale up − growing M, crosses, N = 17

3

10

0.35
BK/FF
W=10
W=20
W=50
W=100

0.3
2

0.25
RMS error in posterior

Filtering time (sec)

10

1

10

BK/exact
BK/approx

0.05

−1

10

20

40

60

80
100
120
140
Number of time slices

160

180

0

200

Figure 7: Performance scale up of PPT-DBN with M .
The number of nodes was held at N = 17.
scales with a steeper slope than both BK inference and
junction-tree inference. Indeed, for about N = 70,
BK eventually surpasses PPT-DBN in terms of speed.
However, it remains faster than junction-tree incremental inference throughout the range. On a computer with 1 GB RAM, the exact version begins to hit
memory limits around M = 200 and N = 17.
We conclude that if exact inference is desired for persistent polytree causal networks, using the PPT-DBN
algorithm is a better choice for a wide range of inference window lengths. Furthermore, if approximate
inference is acceptable, we show in Section 5.3 that for
large enough N , fixed window smoothing using PPTDBN can outperform BK inference in terms of RMS
error, while still performing many times faster. For the
special case of persistent causal trees, the new algorithm dominates by orders of magnitude in all ranges
that we tested versus both junction tree and BK assuming intra-slice independence.
5.3

0.15

0.1

PPT−DBN

0

10

0.2

Fixed-window approximation

A minor disadvantage of the PPT-DBN algorithm is
that it cannot do online inference yet. Therefore, when
monitoring a process, M grows and so does the computation time. In practice, only a fixed number of most
recent observations are usually considered with older
observations falling out of the “window”. Thus we
evaluate if reasonable precision can be attained with
small window sizes, where PPT-DBN dominates.
Figure 8 shows, for several time slices t, the root mean
square error of computed posterior marginals
v
uN
uX
t
ErrBK = t [PBK (Xit |O1:t ) − Pex (Xit |O1:t )]2
i=1

incurred by the fully factored Boyen-Koller method
and the same error for PPT-DBN which ignores all

10 20 30

50

70

100

150

200

Time

Figure 8: Accuracy of PC-DBN with growing inference
window M . Averages are over 100 different parameterizations of the network; error bars are omitted for
clarity but standard deviations are the same order of
magnitude as the means for all curves.
evidence older than W , for different values of W . We
use a binary tree prototype with all leaf variables nonpersistent and observed. All non-leaf variables are persistent and hidden. The CPT probabilities are sampled uniformly at random. The observed evidence O is
obtained by forward-sampling the DBN and restricting it to the observables. We find that the error of
our algorithm falls with growing W as expected. The
results become even more favorable for PC-DBN as
N, the number of nodes per slice, grows (see also further results online). The error made by fixing the
inference window tends to be lower than that of the
Boyen-Koller approximation for reasonable values of
W and we can eliminate the unfavorable dependence
on M at a small price of accuracy. One clear drawback to a naive implementation of the fixed-window
approach is that if evidence is not observed at each
time slice, in the presence of persistence a piece of
crucial evidence might drop off the window preventing
the model from “remembering” that a persistent state
was already acheived. This glitch could in principle be
fixed by caching when persistent variables have turned
on.

6

Conclusions and future work

We presented an algorithm for PC-DBNs, a way to
exploit the special structure of the DBN probability
distribution when many variables are persistent. Unlike forward-backward approaches to DBN inference
that work slice-to-slice, we collapse the entire temporal progression and perform inference in the original prototype network structure. For trees, the algorithm is many times faster than state-of-the-art
general-purpose exact and approximate DBN inference
algorithms, while having a space complexity of only

O(M N ). This continues to hold even in the polytree generalization with inference window lengths into
the hundreds. While this method does not directly
yield an incremental filtering algorithm, we show that
a fixed-window smoothing version of PC-DBN inference can perform approximate filtering faster and with
comparable or less error than BK-filtering.
Although we have not presented a filtering algorithm
that can exploit persistence, we do believe that one
is possible. The number of possible joint configurations of variables in two subsequent slices is 3N with
the persistence assumption as opposed to 4N in the
general network. This hints at the possibility of a
2TBN-like algorithm leveraging persistence and still
remaining linear in the number of time slices.

[8] Jin H. Kim and Judea Pearl. A computational model
for combined causal and diagnostic reasoning in inference systems. In Proceedings IJCAI-83 (Karlsruhe,
Germany), pages 190–193, 1983.
[9] Daphne Koller and Nir Friedman. Bayesian Networks
and Beyond. Unpublished manuscript.
[10] David Larkin and Rina Dechter. Bayesian inference in
the presence of determinism. In Proceedings of Workshop on AI and Statistics, AISTAT 2003.
[11] Kevin Murphy. The Bayes Net Toolbox for Matlab.
Computing Science and Statistics, 33, 2001.
[12] Kevin Murphy. Dynamic Bayesian Networks: Representation, Inference and Learning. PhD thesis, EECS,
University of California, Berkeley, Berkeley, CA, July
2002.

Another possible direction for this work is to allow
multi resolution temporal modeling by modeling systems on very short time scales, but utilizing a persistence approximation for the slow processes. In such
cases, a model with a single time-scale could efficiently
and accurately deal with systems that have both fast
and slow processes.

[13] Kevin Murphy and Yair Weiss. The factored frontier algorithm for approximate inference in DBNs. In
Proceedings of 12th NIPS, volume 12, 2000.

Also interesting is the vision of approximate inference
algorithms not requiring persistence, but simply assuming that the hidden state changes at most once
in the period of interest. If the change in the hidden
state is relatively slow, this could be a fairly accurate approximation. Such problems are often found
in bioinformatics areas such as phylogeny discovery,
where time of a mutation is of interest [6].

[15] Mark Andrew Paskin. Exploiting Locality in Probabilistic Inference. PhD thesis, EECS, University of
California, Berkeley, Berkeley, CA, December 2004.


