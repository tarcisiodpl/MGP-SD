
Value-of-information analyses provide a
straightforward means for selecting the best
next observation to make, and for determining whether it is better to gather additional
information or to act immediately. Determining the next best test to perform, given a
state of uncertainty about the world, requires
a consideration of the value of making all possible sequences of observations. In practice,
decision analysts and expert-system designers have avoided the intractability of exact
computation of the value of information by
relying on a myopic approximation. Myopic
analyses are based on the assumption that
only one additional test will be performed,
even when there is an opportunity to make a
large number of observations. We present a
nonmyopic approximation for value of information that bypasses the traditional myopic
analyses by exploiting the statistical properties of large samples.

1

INTRODUCTION

A person faced with a decision usually has the opportunity to gather additional information about the
state of the world before taking action. Decisiontheoretic methods for determining the value of gathering additional information date back to the earliest literature on the principle of maximum expected
utility (MEU). These methods form an integral part
of many probabilistic expert systems, such as Gorry’s
congestive-heart-failure program (Gorry and Barnett,
1968) and Pathfinder (Heckerman et al., 1989; Heckerman et al., 1990), an expert system that assists pathologists with the diagnosis of lymph-node diseases. To
decide whether or not to perform a test, an expert
∗

From the Proceedings of the Seventh Conference on
Uncertainty in Artificial Intelligence, Los Angeles, CA,
pages 135–141. Morgan Kaufmann, July 1991.

Blackford Middleton
Section on Medical Informatics
Division of General Internal Medicine
Stanford University Medical Center
Stanford, California 94305

system computes the value of information of that test.
The system recommends that the test be performed if
and only if the value of information exceeds the cost
of the test.1
In most decision contexts, a decision maker has the
option to perform several tests, and can decide which
test to perform after seeing the results of all previous tests. Thus, an expert system should consider the
value of all possible sequences of tests. Such an analysis is intractable, because the number of sequences
grows exponentially with the number of tests. Builders
of expert systems have avoided the intractability of
complete value-of-information analyses by implementing myopic or greedy value-of-information analyses. In
such analyses, a system determines the next best test
by computing value of information based on the assumption that the decision maker will act immediately after seeing the results of the single test (Gorry
et al., 1973; Heckerman et al., 1990). In this paper,
we present an approximate nonmyopic analysis. The
analysis avoids the traditional myopic assumption by
making use of the statistical properties of large samples.

2

VALUE-OF-INFORMATION
COMPUTATIONS FOR
DIAGNOSIS

We
discuss
myopic
and
nonmyopic
value-of-information computations in terms of the simple model for diagnosis under uncertainty represented
by the influence diagram in Figure 1. In this model,
the chance node H represents a mutually exclusive and
exhaustive set of possible hypotheses, and the decision
node D represents a mutually exclusive and exhaustive
set of possible alternatives. The value node U represents the utility of the decision maker, which depends
on the outcome of H and the decision D. The chance
nodes E1 , E2 , . . . , En are observable pieces of evi1
This prescription for action assumes that the delta
property holds. See Section 3.

D
U
H

E2

En
•••

E1

such that we should take action D if and only if the
probability of H exceeds p∗ . This threshold is the
probability of H at which the decision maker is indifferent between acting and not acting. That is, p∗ is the
point where acting and not acting have equal utility,
or
p∗ U (H, D) + (1 − p∗ )U (¬H, D) =
(2)
p∗ U (H, ¬D) + (1 − p∗ )U (¬H, ¬D)
In Equation 2, U (H, D) is the decision maker’s utility
for the situation where H occurs and action D is taken,
U (H, ¬D) is the utility when H occurs and action D
is not taken, and so on. Solving Equation 2 for p∗ , we
obtain
C
p∗ =
(3)
C +B
where C is the cost of the decision

E3

C = U (¬H, ¬D) − U (¬H, D)

(4)

and B is the benefit of the decision
Figure 1: An influence-diagram representation of the
problem of diagnosis under uncertainty. The decisionmaker’s utility (rounded rectangular node, U ) depends
on a hypothesis (oval node, H) and a decision (square
node, D). The variables Ei are pieces of evidence or
tests about the true state of H.

B = U (H, D) − U (H, ¬D)

(5)

If the decision maker has observed pieces of evidence
E1 , E2 , . . . , Em , then the decision maker should choose
action D if and only if p(H|E1 . . . , Em ) > p∗ . In terms
of the odds formulation, he should act if and only if
O(H|E1 , . . . , Em ) ≥

dence or tests about the true state of H. This model
is identical to that for Pathfinder (Heckerman, 1990).

p∗
1 − p∗

(6)

We make several simplifying assumptions. First, we
assume that H is a binary chance variable and D is a
binary decision variable. We use H and ¬H to denote
the two outcomes of H, and D and ¬D to denote the
two outcomes of D. For definiteness, we assume that
the decision maker chooses D (as opposed to ¬D),
when H occurs. Second, we assume that each piece
of evidence, E1 , E2 , . . . , En , is binary. Finally, we
assume that each piece of evidence is conditionally independent of all other evidence, given H and ¬H. In
Section 6, we relax these assumptions.

The weight of evidence, wi , is defined as the log of the
likelihood ratio, ln λi . Mapping likelihood ratios into
weights of evidence allows us to update the probability of H through the addition of the weights of evidence. Referring to Equations 1 and 6, we can rewrite
the threshold-probability condition in terms of the loglikelihood ratio where wi = ln λi . The decision maker
should choose action D if and only if

Using the assumption of conditional independence of
evidence, we can calculate the posterior probability
of the hypothesis by multiplying together all of the
p(Ei |H)
p(H)
likelihood ratios, p(E
, with the prior odds, p(¬H)
.
i |¬H)

In this expression, W ∗ is the decision threshold in
terms of weights of evidence.

p(H|Ei , . . . , Em )
p(E1 |H)
p(Em |H) p(H)
=
...
P (¬H|Ei , . . . , Em )
p(E1 |¬H)
p(Em |¬H) p(¬H)

We can write this equation more compactly in odds
form as
m
Y
O(H|Ei , . . . , Em ) = O(H)
λi
(1)
i=1

where λi is the likelihood ratio

p(Ei |H)
p(Ei |¬H) .

Because D and H are binary, it follows from the MEU
principle that there exists a threshold probability p∗ ,

W =

m
X
i=1

3

wi ≥ ln

p∗
− ln O(H) = W ∗
1 − p∗

(7)

MYOPIC ANALYSIS

Let us assume that the user of a diagnostic system has
instantiated zero or more pieces of evidence in the influence diagram shown in Figure 1. We can propagate
the eﬀects of these instantiations to the uninstantiated
nodes, and remove the instantiated nodes from the influence diagram. This removal leaves an influence diagram of the same form as that shown in Figure 1. To
simplify our notation, we continue to refer to the remaining pieces of evidence as E1 , E2 , . . . , En ; also, we
use p(H) to refer to the probability of the hypothesis
H, given the instantiated evidence.

The decision maker now considers whether he should
observe another piece of evidence before acting. A
myopic procedure for identifying such evidence computes, for each piece of evidence, the expected utility
of the decision maker under the assumption that the
decision maker will act after observing only that piece
of evidence. In addition, the procedure computes his
expected utility if he does not observe any evidence
before making his decision. If, for each piece of evidence, the expected utility given that evidence is less
than the expected utility given no evidence, then the
decision maker acts immediately in accordance with
Equation 6. Otherwise, the decision maker observes
the piece of evidence with the highest expected utility;
then, the myopic procedure repeats this computation to
identify additional evidence for observation. Because
the myopic procedure allows for the gathering of additional evidence, the procedure is inconsistent with its
own assumptions. We return to this observation in the
next section.
In the remainder of this section, we examine the computation of expected utilities and introduce notation.
Let EU (E, CE ) denote the expected utility of the decision maker who will observe E at cost CE , and then
act. Let CE(E, CE ) be the certain equivalent of this
situation. That is,
U (CE(E, CE )) = EU (E, CE )

(8)

or

CE(E, CE ) = U −1 (EU (E, CE ))
(9)
where U (·) is the decision maker’s utility function: a
monotonic increasing function that maps the value of
an outcome (e.g., in dollars) to the decision maker’s
utility for that outcome. Similarly, let EU (φ, 0) denote the expected utility of the decision maker if he
acts immediately, and let CE(φ, 0) denote the certain
equivalent of this situation. Thus, in the myopic procedure, a decision maker should observe the piece of
evidence E for which the quantity
CE(E, CE ) − CE(φ, 0)

(10)

is maximum, provided it is greater than 0.
In this paper, to simplify the discussion, we assume
that the delta property holds.2 The delta property
states that an increase in value of all outcomes in a
lottery by an amount 4 increases the certain equivalent of that lottery by 4 (Howard, 1967). Under this
assumption, we obtain
CE(E, CE ) = CE(E, 0) − CE

(11)

where CE(E, 0) is the certain equivalent of observing
E at no cost. Therefore, we have
CE(E, CE ) − CE(φ, 0) = V I(E) − CE

(12)

2
The primary result of this research—that we can
use the central-limit theorem to make tractable an
approximate nonmyopic analysis—is unaﬀected by this
assumption.

where
V I(E) = CE(E, 0) − CE(φ, 0)
(13)
3
is the value of information of observing E. The quantity V I(E) represents the largest amount that the decision maker would be willing to pay to observe E.
When we compare Expression 10 with Equation 12,
we see that, in the myopic procedure, a decision maker
should observe the piece of evidence E (if any) for
which the quantity
V I(E) − CE ≡ N V I(E)
(14)
is maximum and positive. We call N V I(E) the net
value of information of observing E.
The decision maker usually specifies directly the cost
of observing evidence. In contrast, we can compute
V I(E) from the decision maker’s utilities and probabilities. Specifically, from Equations 9 and 13, we have
V I(E) = U −1 (EU (E, 0)) − U −1 (EU (φ, 0))
To simplify notation, we use the abbreviations
EU (E, 0) ≡ EU (E) and EU (φ, 0) ≡ EU (φ)
Thus, we obtain
V I(E) = U −1 (EU (E)) − U −1 (EU (φ))
(15)
The computation of EU (φ) is straightforward. We
have

p(H)U (H, ¬D) + p(¬H)U (¬H, ¬D),




p(H) ≤ p∗

EU (φ) =


p(H)U (H, D) + p(¬H)U (¬H, D),



p(H) > p∗
(16)
by definition of p∗ .
To compute EU (E), let us assume that E is defined
such that the observation of E increases the probability of H. If p(H|E) > p∗ and p(H|¬E) > p∗ , then
V I(E) = 0, because the decision maker will not change
his decision if he observes E. Similarly, if p(H|E) < p∗
and p(H|¬E) < p∗ , then V I(E) = 0. Thus, we need
only to consider the case where p(H|E) > p∗ and
p(H|¬E) < p∗ . Let us consider separately the cases H
and ¬H. We have
EU (E|H) =
(17)
p(E|H)U (H, D) + p(¬E|H)U (H, ¬D)
and
EU (E|¬H) =
(18)
p(E|¬H)U (¬H, D) + p(¬E|¬H)U (¬H, ¬D)
where EU (E|H) and EU (E|¬H) are the expected utilities of observing E, given H and ¬H, respectively. To
obtain the expected utility of observing E, we average
these two quantities
EU (E) = p(H)EU (E|H) + p(¬H)EU (E|¬H) (19)
To compute V I(E), we combine Equations 15, 16, and
19.
3
Other names for V I(E) include the value of perfect
information of E and the value of clairvoyance on E.

4

NONMYOPIC ANALYSIS

As we mentioned in the previous section, the myopic procedure for identifying cost-eﬀective observations includes the incorrect assumption that the decision maker will act after observing only one piece of
evidence. This myopic assumption can aﬀect the diagnostic accuracy of an expert system because information gathering might be halted even though there
exists some set of features whose value of information
is greater that the cost of its observation. For example,
a myopic analysis may indicate that no feature is cost
eﬀective for observation, yet the value of information
for one or more feature pairs (were they computed)
could exceed the cost of their observation.
There has been little investigation of the accuracy of
myopic analyses. In one analysis, Kalagnanam and
Henrion, 1990, showed that a myopic policy is optimal, when the decision maker’s utility function U (·)
is linear, and the relationship between hypotheses and
evidence is deterministic. In an empirical study, Gorry,
1968, demonstrated that the use of a myopic analysis
does not diminish significantly the diagnostic accuracy
of an expert system for congenital heart disease.
In a correct identification of cost-eﬀective evidence,
we should take into account the fact that the decision maker may observe more than one piece of evidence before acting. This computation must consider
all possible ordered sequences of evidence observation,
and is, therefore, intractable.
Let us consider, however, the following nonmyopic approximation for identifying features that are cost effective to observe. Again, we assume that the delta
property holds. First, under the myopic assumption,
we compute the net value of information for each piece
of evidence. If there is at least one piece of evidence that has a positive net value of information,
then we identify for observation the piece of evidence
with the highest net value of information. Otherwise, we arrange the pieces of evidence in descending order of their net values of information. Let us
label the pieces of evidence E1 , E2 , . . . , En , such that
N V I(Ei ) > N V I(Ej ), if and only if i > j.
Next, we compute the net value of information of
each subsequence of E1 , E2 , . . . , En . That is, for m =
1, 2, . . . n, we compute the diﬀerence between the value
of information for observing E1 , E2 , . . . , Em , and the
cost of observing this sequence of evidence. If any
such net value of information is greater than 0, then
we identify E1 as a piece of evidence that is cost eﬀective to observe. Once the decision maker has observed
E1 , we repeat the entire computation described in this
section.
This approach does not consider all possible test sequences, but it does overcome one limitation of the
myopic analysis. In particular, the method can iden-

tify sets of features that are cost eﬀective for observation, even when the observation of each feature alone
is not cost eﬀective.

5

VALUE OF INFORMATION FOR
A SUBSET OF EVIDENCE

As in the myopic analysis, we assume that the decision
maker can specify the cost of observing a set of evidence. In this section, we show how we can compute
the value of information for a set of evidence from the
decision maker’s utilities and probabilities.
As in the previous section, let us suppose that the
decision maker has the option to observe a particular subset of evidence {E1 , E2 , . . . , Em } before acting.
There are 2m possible instantiations of the evidence in
this set, corresponding to the observation of Ei or ¬Ei
for every i. Let E denote an arbitrary instantiation;
and let ED and E¬D denote the set of instantiations E
such that p(H|E) > p∗ and p(H|E) ≤ p∗ , respectively.
The computation of the value of information for the
observation of the set {E1 , E2 , . . . , Em } parallels the
myopic computation. In particular, we have
EU (E1 . . . Em ) =
p(H)EU (E1 . . . Em |H)+
p(¬H)EU (E1 . . . Em |¬H)

(20)

where

and

EU (E1 . . . Em |H) =
£P
§
E∈ED p(E|H) U (H, D)+
£P
§
E∈E¬D p(E|H) U (H, ¬D)

EU (E1 . . . Em |¬H) =
£P
§
E∈ED p(E|¬H) U (¬H, D)+
£P
§
E∈E¬D p(E|¬H) U (¬H, ¬D)

(21)

(22)

To obtain V I(E), we combine Equations 15, 16, and
20.
When m is small, we can compute directly the sums in
Equations 21 and 22. When m is large, we can compute these sums using an approximation that involves
the central limit theorem as follows. First we express
the sums in terms of weights of evidence. We have
X
p(E|H) = p(W > W ∗ |H)
(23)
E∈ED

X

p(E|¬H) = p(W > W ∗ |¬H)

(24)

p(E|H)) = 1 − p(W > W ∗ |H)

(25)

p(E|¬H)) = 1 − p(W > W ∗ |¬H)

(26)

E∈ED

X

E∈E¬D

X

E∈E¬D

where W and W ∗ are defined in Equation 7. The term
p(W > W ∗ |H), for example, is the probability that the
sum of the weight of evidence from the observation of
E1 , E2 , . . . , Em exceeds W ∗ . That is, p(W > W ∗ |H) is
the probability that the decision maker will take action
D after observing the evidence, given that H is true.

p(W|H)

Next, let us consider the weight of evidence for one
piece of evidence. We have
wi

p(wi |H)

p(wi |¬H)

p(Ei |H)
ln p(E
i |¬H)

p(Ei |H)

p(Ei |¬H)

p(¬Ei |H)
ln p(¬E
i |¬H)

p(¬Ei |H)

p(¬Ei |¬H)

W*

To simplify notation, we let p(Ei |H) = α and
p(Ei |¬H) = β. The expectation and variance of w,
given H and ¬H, are then
α
(1 − α)
EV (w|H) = α ln + (1 − α) ln
β
(1 − β)

(27)

α(1 − β)
β(1 − α)

(28)

V ar(w|H) = α(1 − α)ln2
EV (w|¬H) = β ln

α
(1 − α)
+ (1 − β) ln
β
(1 − β)

(29)

α(1 − β)
β(1 − α)

(30)

V ar(w|¬H) = β(1 − β)ln2

Now, we take advantage of the additive property of
weights of evidence. The central-limit theorem states
that the sum of independent random variables approaches a normal distribution when the number of
variables becomes large. Furthermore, the expectation and variance of the sum is just the sum of the
expectations and variances of the individual random
variables, respectively. Because we have assumed that
evidence variables are independent, given H or ¬H,
the expected value of the sum of the weights of evidence for E1 , E2 , . . . , Em is
EV (W |H) =

m
X
i=1

EV (wi |H)

(31)

m
X
i=1

V ar(wi |H)

(32)

Thus, p(W |H), the probability distribution over W , is
m
X

p(W |H) ∼ N (

i=1

EV (wi |H),

m
X
i=1

The expression for ¬H is similar.

V ar(wi |H))

Figure 2: The probability that the total weight of evidence will exceed the threshold weight is the area under the normal curve above the threshold weight W ∗
(shaded region).
Finally, given the distributions for H and ¬H, we evaluate Equations 23 through 26 using an estimate or
table of the cumulative normal distribution. We have
Z ∞
−(t−µ)2
1
p(W > W ∗ |H) = √
e 2σ dt
(34)
σ 2π W ∗
where µ = EV (W |H) and σ = V ar(W |H). The probability that the weight will exceed W ∗ corresponds to
the shaded area in Figure 2. Again, the expression
for ¬H is similar. In this analysis, we assume that no
probability (p(Ei |H) or p(Ei |¬H)) is equal to 0 or 1.
Thus, all expected values and variances are finite. We
relax this assumption in the next section.

6

RELAXATION OF THE
ASSUMPTIONS

We can relax the assumption that evidence is twovalued with little eﬀort. In particular, we can extend
easily the odds-likelihood inference rule, Equation 1,
and its logarithmic transform, to include multiplevalued evidential variables. In addition, the computation of means and variances for multiple-valued evidential variables (see Equations 27 through 30) is straightforward.
In addition, we can relax the assumption that no probability is equal to 0 or 1. For example, let us suppose
that

The variance of the sum of the weights is
V ar(W |H) =

W

(33)

0 < p(Ej |H) = α < 1
p(Ej |¬H) = β = 1
0 < p(Ei |H) < 1,

0 < p(Ei |¬H) < 1,

i = 1, 2, . . . , n (i 6= j)
i = 1, 2, . . . , n (i 6= j)

Using Equations 27 through 30, we obtain
EV (wj |H) = +∞

V ar(wj |H) = +∞
EV (wj |¬H) < 0
V ar(wj |¬H) = 0

(a)

Therefore, although the computation of p(W >
W ∗ |¬H) is straightforward, we cannot compute
p(W > W ∗ |H) as described in the previous section.
Instead, we compute p(W > W ∗ |H), by considering
separately the cases Ej and ¬Ej . We have

H

G

1

G2

• • •

G

j

p(W > W ∗ |H) = p(Ej |H) p(W > W ∗ |HEj ) +
p(¬Ej |H) p(W > W ∗ |H¬Ej )
(35)

If ¬Ej is observed, W = +∞, and p(W >
W ∗ |H¬Ej ) = 1. Consequently, Equation 35 becomes

H

(b)

p(W > W ∗ |H) = p(Ej |H) p(W > W ∗ |HEj ) +
p(¬Ej |H)

We compute p(W > W ∗ |HEj ) as described in Equations 31 through 34, replacing EV (wj |H) with wj in
the summation of Equation 31, and V ar(wj |H) with 0
in the summation of Equation 32. The other terms in
the summations remain the same, because we have assumed that evidence variables are independent, given
H or ¬H. This approach generalizes easily to multiplevalued evidence variables and to cases where more
than one probability is equal to 0 or 1.
We can extend our analysis to special cases of conditional dependence among evidence variables. For example, Figure 3 shows a schematic of the belief network for Pathfinder. In this model, there are groups
of dependent evidence, where each group is conditionally independent of all other groups. We can apply
our analysis to this model by using a clustering technique described by Pearl (Pearl, 1988) (pp. 197-204).
As in the previous section, suppose we want to compute the value of information for the set of evidence
S = {E1 , E2 , . . . , Em }. For each group of dependent
features Gk , we cluster those variables in the intersection of S and Gk into a single variable. Then, we
average out all variables in the belief network that are
not in S. What remains is a set of clustered variables that are conditionally independent, given H and
¬H. We can now apply our analysis—generalized to
multiple-valued variables—to this model.
There are special classes of dependent distributions for
which the central-limit theorem is valid. We can use
this fact to extend our analysis to other cases of dependent evidence. For example, the central-limit theorem
applies to distributions that form a Markov chain, provided the transition probabilities in the chain are not
correlated (Billingsley, 1968). Thus, we can extend
our analysis to belief networks of the form shown in
Figure 4. We can generalize the value-of-information
analysis even further, if we use the Markov extension
in combination with the clustering approach described
in the previous paragraph.

Gk
Ei

E i+1

E i+2

Figure 3: A schematic belief network for Pathfinder.
(a) The features in Pathfinder can be arranged into
groups of evidence variables G1 , G2 , . . . Gj . The variables within each group are dependent, but the groups
are conditionally independent, given the disease variable H. (b) A detailed view of the evidence variables
Ei , Ei+1 , and Ei+2 within group Gk .

H

E1

E2

E3

•••

En

Figure 4: A conditional Markov chain. The evidence
variables form a Markov chain conditioned on the variable H. We can extend our analysis involving the
central-limit theorem to this case.

It is diﬃcult for us to extend the analysis to include
multiple-valued hypotheses and decisions. The algebra
becomes more complex, because the simple p∗ model
for action no longer applies. There is, however, the
opportunity for applying our technique to more complex problems. In particular, we can abstract a given
decision problem into one involving a binary hypothesis and decision variable. For example, we can abstract the problem of determining which of n diseases
is present in a patient into one of determining whether
the disease is benign or malignant. In doing so, we
ignore details of the decision maker’s preferences, and
we introduce dependencies among evidence variables.
Nonetheless, the benefits of a nonmyopic analysis may
outweigh these drawbacks in some domains.

7

SUMMARY AND CONCLUSIONS

We presented work on the use of the central-limit theorem to compute the value of information for sets
of tests. Our technique provides a nonmyopic, yet
tractable alternative to traditional myopic analyses for
determining the next best piece of evidence to observe.
Our approach is limited to information-acquisition decisions for problems involving (1) specific classes of dependencies among evidence variables, and (2) binary
hypothesis and action variables. Additional research,
however, may help to relax these restrictions. For now,
we pose the nonmyopic methodology as a new specialcase tool for identifying cost-eﬀective observations. We
hope to see empirical comparisons of the relative accuracy of the nonmyopic analysis with that of traditional
myopic analyses. We expect that the results of such
evaluations will be sensitive to the details of the application areas.

Acknowledgments
This work was supported by the National Cancer Institute under Grant RO1CA51729-01A1, and by the
Agency for Health Care Policy and Research under
Grant T2HS00028.




that we developed, the dynamic network tool that we
designed and implemented to aid knowledge engineering

We present several techniques for knowledge
engineering of large belief networks (BNs) based

for

CPCS, and the Bayesian network algorithms that we

employed for this large, complex network.

on the our experiences with a network derived
from a large medical knowledge base. The noisy­
MAX, a generalization of the noisy-OR gate, is

used to model causal independence in a BN with

knowledge engineering or evaluation, challenging. The

multivalued variables. We describe the use of leak

development of CPCS necessitated the implementation of
algorithms that could make inference in BNs of this size

probabilities

to

enforce

the

closed-world

assumption in our model. We present Netview, a

more efficient. An example of this is a generalization of the

visualization tool based on causal independence
and the use of leak probabilities. The Netview

noisy-OR gate [Cooper 1986; Peng and Reggia 1987; Pearl

software

model causal independence. The

allows

knowledge

engineers

to

dynamically view subnetworks for knowledge
engineering, and it provides version control for
editing a BN. Netview generates sub-networks in
which leak probabilities are dynamically updated

1

The CPCS is one of the largest BNs in use at the current
time, and its sheer size makes most tasks, such as

1988] that is commonly used in binary valued networks to

CPCS BN contains nodes

that are multivalued, for example, disease nodes may have
four values (absent, mild, moderate, severe), consequently
we use a generalization of the noisy-OR gate called the

noisy-MAX. The specification of a complete conditional
m with sm values and n
predecessors requires the assessment of (sm -l)IJ�=I s;

to reflect the missing portions of the network.

probability matrix for a node

INTRODUCTION

probabilities, where

s;is

the

number

of

values

predecessor i (for a binary network this reduces to

of

2n ) In
.

Given the relative maturity of algorithm development in the

contrast, the causal independence assumption in the form of

Bayesian reasoning community, attention is now starting to
focus on applying these algorithms to real-world

a noisy-gate reduces this assessment task to

probabilities. thereby simplifying knowledge

applications.

and greatly reducing storage requirements.

The Quick Medical Reference-Decision

Ln(sm -l)s;

dcquisition

(QMR-DT) project seeks to develop practical
decision analytic methods for large knowledge-based

To aid in the editing and refinement of the

systems. The first stage of the project converted the

have developed a network visualization tool we named

Theoretic

Internist-1 knowledge base [Miller, Pople et al. 1982]

(QMR 's predecessor) into a binary, two-layered belief

CPCS BN, we

Netview. The Netview tool provides dynamic views of the

BN, and can generate subnetworks by taking advantage of

1991; Shwe,

the noisy-MAX and leak assumptions. For inference, the

Middleton et al. 199 1]. In the second stage of the QMR-DT

network, or subnetworks generated by Netview, are sent to
the IDEAL package [Srinivas and Breese 1989] for

network (BN) [Middleton, Shwe et al.

project we are creating a multilayer belief network with
mu1tiva1ued variables, and developing efficient inference
algorithms for the network. This paper will concentrate on
the knowledge engineering issues we faced when building a
large multilayered BN.
To create a large multilevel, multivalued BN we took
advantage of a rich knowledge base, the Computer-based

inference. Netview is a flexible tool which can be used in
any BN that uses noisy-gates, and is described in section

5.1.
Like the Internist- 1 -derived B N, the CPCS BN uses leak
probabilities [Henrion 1988] to represent the chance of an
event occurring when all of its modeled causes are absent.

We discuss our use of leak probabilities,

and the

Patient Case Simulation system (CPCS-PM), developed
over two years by R. Parker and R Miller [Parker and

modifications to the leak probabilities required by the

Miller 1987] in the mid-1980s as an experimental extension

dynamic network tool, in section 5.2.

of the Internist-! knowledge base.
This paper makes contributions both in knowledge
engineering and in algorithm development and
implementation for large BNs. We describe the CPCS BN

2

KNOWLEDGE BASE TO BELIEF NETWORK

The CPCS-PM system is a knowledge base and simulation
program designed to create patient scenarios in the medical

Knowledge Engineering for Large Belief Networks

sub-domain of hepatobiliary disease, and then evaluate
medical students as they managed the simulated patient's
problem. Unlike that of its predecessor lnternist-1, the
CPCS-PM knowledge base models the pathophysiology of
diseases th e intermediate states causally linked between
diseases and manifestations. The original CPCS-PM system
was developed in FranzLisp. Diseases and intermediate
pathophysiological states (IPSs) were represented as Lisp
frames [Minsky 1975].

485

5

and were mapped to probability values, as described in
next section. Frequency weights from the CPCS-PM
were mapped to probability values based on previous work
in probabilistic interpretations of Internist-1 frequencies.

the

-

To construct the BN we converted the CPCS-PM knowledge
base to CommonLisp and then parsed it to create nodes. We
r e pr esented diseases and IPSs as four levels of severity in
the CPCS BN-absent, mild, moderate, and severe.
Predisposing factors of a disease or IPS node were
represented as that node's predecessors, and findings and
symptoms of a disease or IPS node as the successors for that
node. In addition to the findings, CPCS contained causal
links between disease and IPS frames, we converted these
links into arcs in the BN. Frequency weigh t s [Shwe,
Middleton et al. 1991] from the CPCS-PM ranged from 0 to

We generated the CPCS BN automatically, we did manual
consistency checking using domain knowledge to edit the
network. Because the CPCS-PM knowledge base was not
designed with probabilistic interpretations in mind, we had
to make numerous minor corrections to remove artifactual
nodes, to make node values consistent and to confinn that
only mutually exclusive values were contained within a
node.
The resultant network has 448 nodes and 908 arcs (Figure
1). A t o tal of seventy four of the nodes in the network are
predisposing factors and required prior p robab ilities the
remaining nodes required leak probabilities assessed for
each of their values. We thus had to assess over 560
probabilities to specify the network fully.

Figure I. A small portion of the CPCS BN displayed in the Netview visualization program. The node ascending­
cholangitis in the third row shown in inverse has been selected by the user.

,

486

Pradhan, Provan, Middleton, and Henrion

While the CPCS-PM knowledge base is derived from the
Internist-! knowledge base it has been significantly

3

augmented by inclusion of the IPS states, and multivalued

2

representations of both diseases and manifestations of
disesase. The original

QMR-BN transformation of the

Internist-! knowledge base used only binary valued disease
and manifestation nodes. While conceptually simple, this

0

approach does not adequately reflect the potential variation
in presentation of disease manifestations, or the severity of

3

1

0

diseases.

Figure 2.

A node x with

predecessors D i• n,

NOISY-OR

ordered states

The noisy-OR is a simplified

BN representation that

respectively, or disease and manifestation variables
respectively [Peng and Reggia

1987].

variable

variables or predecessors

X

the

variables, and is typically described for a

which are interpreted as either cause and effect variables

that has

n

cause

•••

( 1)

P(X= 2! VI).

If there are multiple "manifestation" variables

j =1 ,.. .,l,

Consider an effect

D1, ,Dn· The noisy-OR can be used when

\tf having

probabilities required to calculate

probability matrix. The noisy-OR is defined over a set of
two level network partitioned into two sets of variables,

E

{0,1,2,3 }. The

shaded area represents the

requires far fewer parameters than the full conditional­
binary-valued

3

q

GENERALIZATION OF THE NOISY-OR

3.1

2

Aj,

P(Xi =xi I VI)=1- II(l-pii)

each D has

i:D;eV1

an activation probability p; being sufficient to produce the
effect in the absence of all other causes, and

(2)

the

probability of each cause being sufficient is independent of

1988].

the presence of other causes [Henrion

In this paper, we define variables using upper-case letters,

X is
ilx. If variable X is present it is denoted using the letter x;

letters.

The domain of possible values for variable

if it is absent, it is denoted using x .
The activation of a variable

X

by a predecessor variable D;

is independent of the value of D;.
assumption,

X is

conditional probability given by
other

Under the noisy-or

activated when D;

P;

is active,_with a

= P(x I d; {'·dk).
'

In

words, this activation probability deh otes the

probability when
inactive.

where Pij is the link probability on the arc from D; to

lJi is active and all other predecessors are

For a two-level noisy-OR network, we define a set V of
cause or disease variables, and a set W of effect or

manifestation variables. If there is a set VI of V of
predecessors of

X

e

W that are present, then since the D;

X will be false when all D; are false:

P(X=X I VI)= II P(D; =d;)
i:D;eV1

P(X =X I Vj)

=

BN

application, since we need to accommodate n-ary variables.

For example, CPCS BN disease and IPSs can take on values
such as absent, mild, moderate, and severe.
3.2

NOISY- MAX

Consider a generalization of the noisy-OR situation in
which each variable is allowed to have a finite discrete state
space (rather

than just a binary state s pace). This

generalization was first proposed by [Henrion

1988], but he

did not describe the algorithmic details. In developing this
generalization, we assume that we have a set

V of

predecessor variables D1, ... ,Dn. Consider first the case
where we have a variable

in VI are independent,

Xi

The simple noisy-OR is insufficient for the CPCS

and values that variables can take on using lower-case

for

then we obtain

X with a subset

present, with the predecessors indexed by

V1 of V that are

i,j, ,q.
...

The variable domains in CPCS BN are all partially ordered,

for example, {absent, mild, moderate, severe}, and it turns
out that such a partial ordering is necessary for all variable
domains. For the remainder of our work we assume that all
variables have ordered domains.
We now want to compute

II

(1- P;).
i:D;eV1

The value xis given by
In other words,

From this, it is simple to derive

domain values

P(X=xiVI)=l- II(l-p;).
i:D1eV1

x =

max(i,j, .
.

.

,q) [Henrion 1988].

X takes on as its value the maximum of the
of

its predecessors,

predecessors are all independent.

given

that

the

Knowledge Engineering for Large Belief Networks

487

V1)

This computation of P(X ==xI
can be viewed as setting
up a hypercube of dimensions i x j x · · x q and summing
·

the cells, each of which contains a probability value

fljk··q P;jk··q. As an example of the derivation of the general
formula, we consider the case of two predecessors D; and
{}_j. If these variables take on values i,j respectively, then
the

probability P(X =xI V1) ,

where

x = max(i, j) .

For

example, Figure 2 graphically depicts the conditional

probability matrix for D; and Dj, b oth of which have

ordered states {0, 1,2,3}. If x=2, then
consists of the shaded squares of the grid.

P(X=21D;.Dj)

Figure 3. Explicit representation

of the leak probability as a cause
of X.

In this multivalued noisy-MA X situation, the probabilities

that are being calculated in these hypercubes are cumulative

probabilities, that is,

P(X s; xI D s; d) .

For notational

convenience, we define the cumulative probability for a
variable

X that has a s ingle predecessor D with maximum
d as:

domain value

\f(x I d)= P(X s; xI D s; d) .
Under the generalized noisy-OR assumption, for a given
variable

X

with a set of

which each D;

q

D1, ... , Dq
d;, we know that

predecessors

has maximum value

for

4

LEAKS

As in any other knowledge representation scheme, the BN
representation suffers from incompleteness, in that it

typically cannot model every possible case. A leak variable

can be used to enforce the closed-world assumption [Reiter
1978]. The leak variable represents the set of causes that
are not modeled explicitly.

A leak probability is assigned as

the probability that the effect will occur in the absence of

of the cause s

D1 , ...,D n that are explicitly modeled. If
the leak variable is explicitly modeled, then it can be

any

treated like any other cause and can be depicted as such

=

IJ 'P(xld;),
i:D;eV1

In this representation, the leak node is always

assumed to be "on", that is
If

Note that using this transformation, we can define the

probability assigned to

3).

(Figure

i:D;E�

P(L=true) = 1.0.

the leak L with value l is factored into the calculation of

the unconditional probability for variable X, then we obtain

X taking on a particular value Xk :

P(X s; x) = P(L s; l)

TI [p;P(D; s; d;)+(1- P;)],

i:D,�V

Explicitly representing leak nodes in the

The unconditional probability assigned to a variable can be

derived in an analogous fashion. First, we nee d to derive

D;. assuming no
1994], this is given

the unconditional probability of variable
predecessors. As described in [Provan
by

P(X $. x) = P(L s; 1)

IJ[p;P(D; s; d;) +(1- P;)]P(x I V1).

i:D,eV1

P(XS:x) =

conditioning parents. The Netview knowledge engineering

tool, described in section 5, facilitates the maintenance and

editing of leak probabilities. Netview stores leak values

separately, as if they were explicit nodes, and then inserts

the leak values into the appropriate probability
exporting a network for inference in IDEAL.

5

The unconditional probability is given by

IJ[p;P(D; :S:d;)+(l-p;) ].

i:D;EV

The unconditional probability assigned to X taking on a
particular value x is:

CPCS BN would

almost double the size of the network, so leaks are
implicitly represented in the probability tables of a node's

5.1

tables when

TOOLS FOR KNOWLEDGE ENGINEERING
NETVIEW:

A TOOL FOR NETWORK

VISUALIZATION AND EDITING

Verification and refinement of the structure of the CPCS BN
is an important part of the QMR -Df project for two reasons.
First, because the

CPCS BN was generated from a pre­

existing knowledge base. Second, the effect of model
structure on network performance and accuracy is an
important aspect of the QMR -Df project.

During the knowledge engineering process, it became

V1)

Using this approach, the value P(xI
can be computed in
time proportional to the number of predecessors in V1. This
generalized noisy-MAX has been implemented in IDEAL.

obvious

that

available tools were not suitable for

visualizing and editing a network the size of
(Figure

1).

CPCS BN

In particular, most tools only permit a static

488

Pradhan, Provan, Middleton, and Henrion

view of the network, a limitation that made editing the

disease," and so on. A node may have any number of
semantic labels. Semantic labeling is a useful technique for

CPCS network very hard.

filtering nodes to focus attention during knowledge
by allowing knowledge engineers to focus on portions of

engineering. It is possible, say, to focus only on "gastric"
findings and diseases when dealing with the appropriate

the network. The program is implemented in Macintosh

domain expert. In the future we will also use the semantic

Netview was created to help knowledge engineering efforts

CommonLISP 2.01. The main features of Netview are
o

dynamic network layout

o

semantic labeling of nodes

o

version control

•

subnetwork generation and dynamic

o

labels in the dynamic layout algorithm to improve the
appearance of subnetwork views.
It is useful to keep track of modifications while editing the

BN. To facilitate this, Netview includes basic version

leak modification

control to store deleted and added arcs and nodes and

leak value editing

changes to probability tables. Arc and node additions and
removals between versions are displayed through the use of

Because of the causal independence assumptions implied
by the use of the noisy-MAX and noisy-0

different colors.

R gates,

knowledge engineers are can select smaller parts of the

5.2

CPCS BN for viewing. Netview allows the user to view all
ancestors, all predecessors, or all ancestors and
predecessors of selected nodes. For example, in Figure l
while the node

ascending-cholangitis is selected (inverse

color), we can use Netview's ability to show all successors
and predecessors of the selected node or nodes, resulting in
the subnetwork view shown in Figure 4 . Other options
include viewing nodes' Markov blanket, and immediate
successors or predecessors.
Netview uses a dynamic layout algorithm to display the
selected nodes. The knowledge engineer is able to move
rapidly between views by selecting nodes and choosing
viewing options, or by retrieving previously saved views.
Quickly viewing a node's predecessors allows rapid
assessment of leak probabilities.
In addition to subnetwork selection, Netview allows
semantic labeling of nodes, and filtering based on semantic
labels. For example, nodes in CPCS BN are labeled "lab
finding," "symptom," "sign," "disease," "IPS," "liver

5.2.1
The

SUBNETWORK GENERATION AND DYNAMIC
LEAK MODIFICATION

Subnetwork generation
Netview

program

is

used

only

for

network

visualization and editing; Netview saves files in IDEAL
format for inference. Because of the size of the CPCS BN it

is not always desirable to send the entire network to

IDEAL

for inference. If we are only interested in verifying a small
set of diseases we can generate a subnetwork including
only those diseases of interest and their associated findings,
IPSs and predisposing factors. When we run test cases

against a subnetwork we don't require the system to
compute the posterior probabilities of diseases that we are
not interested in.

5.2.2 Dynamic leak modification
Subnetworks we select from the full

CPCS

BN using

Netview can be exported to IDEAL for inference. It is

possible to select subsets of the larger CPCS

BN for

i n f e r e n ce

leaks .

due

to

the

presence

of

Figure 4. A subnetwork of the CPCS BN displayed in Netview. This view comprises all predecessors and
successors of the node ascending-cholangitis.

Knowledge Engineering for Large Belief Networks

Figure 6. Subnetwork creation. Node D3is removed from the network, the value of the leak node
updated to p based on the probability of D3•

489

/, p is
,

'

When a subnetwork is saved Netview updates the leak
probabilities to take into account the missing diseases. In
the CPCS BN the node hepatomegaly has parents shown in
figure 5, The leak probability for hepatomegaly is therefore
calculated based on this set of predecessors. In figure 4 a
subnetwork was selected based on the ancestors and
predecessors of the disease ascending-cholangitis. Conse­
quently, the only parent of hepatomegaly in the subnetwork
is ascending-cholangitis, its other parents are not included.
The transformation of leak probabilities required during
subnetwork creation is shown in Figure 6. The leak
probability must be updated from p to p'. This updating is
done in order to preserve the total probability mass. If the
value I of L is updated to a value l' for new leak L', we can
compute the updated leak node probability as

BN, and we are exploring how much the network
performance changes when the assumption is relaxed.
5.2.3 Information metrics

When subnetworks are created some information is lost as
parts of the network are excluded. A future area of research
is to use Netview to calculate the information Joss of a
subnetwork based on information metrics [Provan 1993],
and to compare differences in posterior probability between
the complete network and the subnetwork which has been
selected.

6

RELATED WORK

The generalization of the noisy-OR was first proposed in
[Henrion 1988], and the derivation and implementation
p' = P(L '5.lA D3 '5.d3)
described here follow that original proposal. Two related
= P(L '5.l)P(D3 '5.d3)
generalizations are described in [Srinivas 1993] and [Diez
1993]. The generalization of the noisy-OR by Srinivas is
=[p3P(D3 '5.d3)+(l- p3)]
different to this proposal, and is intended for a different
application. This generalization is for circuits (or other such
If we want to combine a set of Q nodes into a leak node,
devices) which can be either functional or non-functional.
where each node d1 in Q has link probability, then the new
In the case of medicine, findings can take on values such as
leak node probability is given by:
{absent, mild, moderate, severe}, in which case the binary
generalization of Srinivas is insufficient to deal with
p' =P(L'5.lAD1 '5.d1A···ADq '5.dq)
arbitrary n-ary variables. The noisy-MAX generalization in
D i ez 1993] is virtually identical to the one described here,
[
P(L '5./) fl P(Dt '5. d;)
and
we have derived our noisy-MAX independent of that in
i:D1eQ
[Diez 1993). Also, the proposal in [Diez 1993] is described
=P(L-5./) n[p;P(D;'5.d;)+(l-p;)].
within the context of learning models for OR-gates, and its
i:D1eQ
application to inference in Bayesian networks is not directly
apparent.
We prove in [Provan 1994] that if the network is
To our knowledge, there is no other tool which allows
hierarchical and there are no arcs between nodes at the
dynamic selection of subsets of Bayesian networks. There
same level of the hierarchy, then the leak updating is sound,
are several graphical tools for creating Bayesian networks,
that is, the probability assigned to X given the new set of
including IDEAL Edit, Ergo, Hugin [Andersen, Olesen et al.
predecessors is the same as the probability assigned to X
1989], and Demos [Morgan, Henrion et al. 1987]. But these
with the original predecessors. This proof holds if the
tools do not provide dynamic network layout and do not
subnetwork consists of a Markov blanket of a node, all
have features aimed at knowledge engineering large BNs.
predecessors and successors of a node, or all successors of
a node. The assumption for the proofs holds for the CPCS
7 CONCLUSION
=

��Figure 5. Parents of the node hepatomegaly.

In this paper we have presented several methods for
representing, and a software tool for managing, large BNs
based on our experience with the CPCS BN. The noisy-MAX
is a generalization of the noisy-OR gate for multivalued

490

Pradhan, Provan, Middleton, and Henrion

variables which reduces the complexity of the knowledge
acquisition task and storage requirements for a network.
Leak probabilities are used in the CPCS BN to model causes
other than those explicitly modeled in the network.

Middleton, B., Shwe, M. A., et al. (1991). Probabilistic
diagnosis using a reformulation of the Internist-1/QMR
knowledge base-11. Evaluation of diagnostic performance.
Methods of Information in Medicine, 30:256-67.

Based on the causal independence assumptions of the
noisy-MAX, and the use of leak probabilities we have
developed Netview, a tool for visualizing BNs based on the
dynamic layout of subnetworks, and which also provides
basic version control for editing networks. The creation of
subnetworks allows for more efficient knowledge
engineering, and for easier verification of the B N. We
describe a technique for updating leak probabilities based
on the excluded parents of a node in subnetworks.

Miller, R. A., Pople, H. E. J., et al. (1982). Internist-1: An
experimental computer-based diagnostic consultant for
general internal medicine. N Engl J Med, 307:468-476.

Recent advances in creating BNs from pre-existing data or
knowledge bases will result in networks that are larger and
more complex than those created manually. We believe that
the techniques described in this paper are important to
facilitate the management and verification of such
networks.
Acknowledgments

This work was supported by NSF Grant Project IRI9120330, and by computing resources provided by the
Stanford University CAMIS project, which is funded under
grant number LM05305 from the National Library of
Medicine of the National Institutes of Health.
The authors would like to thank K. C. Chang and R. Fung
for their graph layout algorithm on which NetView's layout
method is based, and R.Miller for access to the CPCS
knowledge base.

