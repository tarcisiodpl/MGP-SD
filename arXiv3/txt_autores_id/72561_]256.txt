
The effect of inaccuracies in the parameters of
a dynamic Bayesian network can be investigated
by subjecting the network to a sensitivity analysis. Having detailed the sensitivity functions
involved in our previous work, we now study
the effect of parameter inaccuracies on a recommended decision in view of a threshold decisionmaking model. We describe the effect of varying
one or more parameters from a conditional probability table and present a computational procedure for establishing bounds between which
assessments for these parameters can be varied
without inducing a change in the recommended
decision. We illustrate the various concepts by
means of a real-life dynamic network in the field
of infectious disease.

1 Introduction
Probabilistic graphical models are often used in contexts
where human decision makers have to make a decision in
uncertainty. The marginal probability distributions yielded
by the model then are taken as input to a decision-making
model. The simplest model for choosing between alternative decisions is the threshold decision-making model, in
which an output probability is compared against a number
of fixed threshold probabilities which demarcate the boundaries for the various decisions [13]. In our application for
ICU care, for example, a clinician has to decide whether or
not to start antibiotics treatment for a patient who is suspected of having ventilator-associated pneumonia (VAP),
based upon the probability of VAP being present.
Probabilistic graphical models are typically learned from
data or constructed with the help of domain experts. Due
to incompleteness of data and partial knowledge of the domain under study, the numerical parameters of the model
tend to be inaccurate to at least some degree. The inaccuracies may affect the output probabilities of the model as well
as the decisions based upon these probabilities. The effects

of inaccuracies in the parameters of a network on its output probabilities can be studied by subjecting the network
to a sensitivity analysis [2, 7, 8, 9]. In view of a decisionmaking model, however, robustness of the output of a probabilistic graphical model pertains not just to the computed
output probabilities but also to the decisions based upon
these probabilities. In this paper, we study this type of robustness for dynamic Bayesian networks (DBNs) in view
of the threshold decision-making model.
Previous work on sensitivity analysis of Bayesian networks
(BNs) in general showed that any posterior probability for
an output variable is a quotient of two linear functions in
any of the network’s parameters [8]; the posterior probability can further be expressed as a sum of such functions
in all parameters from a single conditional probability table
[2]. Building upon these results, we show that in sensitivity
analysis of DBNs a quotient of polynomial functions is obtained, where the order of these polynomials is linear in the
time scope taken into consideration [4, 6]. We further show
how the resulting functions can be used to study the robustness of a decision that is based upon an output probability
of the network. By doing so, we focus not just on the effect of varying a single parameter, but also on the effect of
varying all parameters from a given conditional probability table. In our medical application, for example, we thus
provide for studying the extent to which the sensitivity and
specificity rates of a particular diagnostic test can be varied without affecting the clinician’s decision for treatment.
We illustrate the various concepts involved by means of a
sensitivity analysis of our dynamic network in the field of
infectious disease [5].
Establishing the sensitivity functions for a DBN has a time
complexity similar to that of performing exact inference in
such a model. Using quotients of higher-order polynomials
for further processing in view of the threshold decisionmaking model can also be highly demanding from a computational point of view [6]. To handle the complexity involved, we present an approximate method for sensitivity
analysis that reduces the runtime requirements involved yet
incurs only a small loss in accuracy.

three input processes (summarised in immunological status), three input observable variables (hospitalisation, mechanical ventilation, and previous antibiotics), one hidden
input variable (aspiration), and seven output observable
variables (summarised in symptoms-signs). Per time step,
representing a single day, the model includes 30 variables.
Each of the interacting processes consists of seven subprocesses that are a-priori independent. The transition matrices of these subprocesses are moderately stochastic. Figure
1 shows the dVAP network in a compact way.
Figure 1: The dVAP model for the diagnosis of VAP for two
consecutive time steps; clear nodes are hidden, shaded nodes are
observable. The dashed boxes indicate the hidden processes.

3 Sensitivity analysis revisited

2 Preliminaries

Having been studied extensively in the context of BNs, sensitivity analysis has received less attention in DBNs. In
this section, we briefly review previous work on sensitivity
analysis in BNs and extend it to a dynamic context.

The simplest type of dynamic network is a hidden Markov
model (HMM) H = (X, Y, A, O, Γ) involving a single
stochastic process [14]. We use Xn to denote the hidden
variable of the modelled process at time step n. Xn has
the possible states xni , i = 1, . . . , l, l ≥ 2. The transition matrix for Xn is denoted as A = {ai,j } with elements
ai,j = p(Xn+1 = xn+1
| Xn = xni ), i, j = 1, . . . , l, for all
j
n. We denote the observable variables by Yn , with values yjn , j = 1, . . . , m, m ≥ 2. The value of Yn is generated
from the state of the hidden variable according to a timeinvariant observation matrix O = {oi,j } with oi,j = p(Yn =
yjn | Xn = xni ), i = 1, . . . , l, j = 1, . . . , m, for all n. We
further denote by Γ = {γi } the initial probability vector for
the hidden variable, with γi = p(X1 = x1i ), i = 1, . . . , l. A
DBN of more general structure is an extension of an HMM,
capturing a compound process that involves a collection of
hidden variables. We assume that our dynamic networks
are time invariant, that is, neither the topology nor the parameters of the model change across time steps.
In this paper, we focus on the task of monitoring in DBNs,
that is, on computing marginal distributions for the model’s
hidden variables for some time step n given the observations that are available up to and including that time
step. For this purpose, the interface algorithm is available
[11], which basically is an extension of the junction-tree
algorithm for probabilistic inference in graphical models
in general. The interface algorithm efficiently exploits the
concept of forward interface, which is the set of variables
at time step n that affect some variables at time step n + 1
directly; in the sequel, we use F I to denote this set of variables. The computational complexity of the interface algorithm is exponential in the number of hidden variables at
each time step, which is prohibitive for larger models.
Throughout the paper we will use the dVAP network for illustration purposes. The dVAP network is a real-life DBN
for diagnosing VAP in ICU patients and is destined for
use in clinical practice [5]. The network includes two interacting hidden processes (colonisation and pneumonia),

3.1 Sensitivity analysis of BNs
Sensitivity analysis of a BN amounts to establishing, for
each of the network’s parameter probabilities, a function
that expresses an output probability of interest in terms of
the parameter under study [7, 9, 16]. We take the posterior
probability p(b | e) for our probability of interest, where
b is a specific value of the variable B and e denotes the
available evidence; we further let θ = p(hi | π) be our
parameter under study, where hi is a value of the variable
H and π is a specific combination of values for the parents
of H. The sensitivity of the probability p(b | e) to variation
of the parameter θ now is expressed by a sensitivity function
p(b | e)(θ). If the parameters p(hj | π), hj 6= hi , specified
for H are co-varied proportionally according to
½
θ
if j = i
p(hj | π)(θ) =
1−θ
p(hj | π) · 1−p(h
otherwise
i |π)
for p(hi | π) < 1, then this function is a quotient of two
linear functions in θ, that is,
p(b | e)(θ) =

p(b, e)(θ)
c1 · θ + c0
=
p(e)(θ)
d1 · θ + d0

where c1 , c0 , d1 and d0 are constants with respect to θ [7].
Under the assumption of proportional co-variation, therefore, any sensitivity function is characterised by at most
three constants. Note that for parameters of which the probability of interest is algebraically independent, the function
simply equals the posterior probability p(b | e). Any computations can therefore be restricted to the sensitivity set
for the variable of interest, which can be readily established
from the network’s graphical structure. An efficient scheme
for sensitivity analysis is available [8], which requires an
inward propagation in the junction-tree for processing evidence and an outward propagation for establishing the constants of the sensitivity functions for all parameters per output probability.

3.2 Sensitivity analysis of DBNs

0.35
0.3

n−1
+ . . . + c1n,r · θa + c0n,r
p(xnr )(θa ) = cn−1
n,r · θa
0
cn−1
n,r , . . . , cn,r

are constants with respect to θa dewhere
pendent on n; note that the function is a polynomial of
order n − 1 in the parameter under study. For an initial
parameter θγ = γi ∈ Γ, the function is linear
p(xnr )(θγ ) = c1n,r · θγ + c0n,r
where c1n,r and c0n,r are constants with respect to θγ . For an
HMM in which no evidence has been entered, the observable variables do not belong to the sensitivity set of the hidden variable. Its prior probability therefore is algebraically
independent of any observation parameter.
We now assume that some evidence has been entered into
the model; we use en to denote the cumulated evidence up
to and including time step n. For the sensitivity function
that expresses the posterior probability p(xnr | en ) in terms
of a transition parameter θa = ai,j ∈ A, we find that
n−1
+ . . . + c1n,r · θa + c0n,r
p(xnr , en )(θa ) cn−1
n,r ·θa
= n−1 n−1
p(en )(θa )
dn,r ·θa + . . . + d1n,r ·θa + d0n,r
0
n−1
0
where cn−1
n,r , . . . , cn,r , dn,r , . . . , dn,r again are constants
with respect to θa . The function thus is a quotient of two
polynomials of order n − 1. For an observation parameter
θo = oi,j , the sensitivity function is

p(xnr , en )(θo ) cbn,r ·θob + . . . + c1n,r · θo + c0n,r
= n
p(en )(θo )
dn,r ·θon + . . . + d1n,r ·θo + d0n,r
where b = n if r = i and b = n − 1 otherwise;
cbn,r , . . . , c0n,r , dnn,r , . . . , d0n,r are constants with respect to
θo . The order of the polynomials involved again grows linearly with n. For an initial parameter θγ , to conclude, we
have that the sensitivity function is a quotient of two linear
functions. Similar results hold for probabilities of interest
belonging to any possible time step no < n or no > n [4].
The results for HMMs are readily generalised to DBNs. We
consider the posterior probability of interest p(bnr | en ) of
the state br of the hidden variable Bn given the evidence en .
Then, for any variable Hn ∈ Sens(Bn , en ), the sensitivity
function expressing p(bnr | en ) in θ = p(hni | π) is a quotient

0.25

p(vap4  e4)

The main difference with sensitivity analysis of BNs is that
a parameter occurs multiple times in a DBN. In previous
work [4], we derived functional forms to express the sensitivity of a probability of interest of an HMM in terms of
a parameter under study. We briefly review these sensitivity functions. We begin by studying the sensitivities of an
HMM in which no evidence has been entered as yet. The
probability of interest is the prior probability p(xnr ) of some
state xr of the hidden variable Xn . Let θa = ai,j ∈ A be
a transition parameter in the model such that Xn is algebraically dependent on θa . Then,

0.2
0.15
0.1
0.05
0
0

0.2

0.4

θ →

0.6

0.8

1

Figure 2: The sensitivity function expressing the probability of
pneumonia at day 4 given evidence e4 for a patient, in terms of
the parameter θ = p(leucocytosis = yes | pneumonia = yes).

of two polynomials of order n−1 if Hn ∈ F I, or of order
n otherwise.
As an example sensitivity function, Figure 2 depicts, for
the dVAP network, the effect of varying the parameter
θ = p(leucocytosis = yes | pneumonia = yes) on the
probability of pneumonia at day 4 given evidence e4 for a
specific patient. The depicted function is a quotient of two
polynomials of order 4 each. For computing the constants
in the various sensitivity functions, we combined the interface algorithm with the junction-tree scheme for sensitivity
analysis; further details of the resulting algorithm are out
of the scope of this paper.

4 Threshold decision making
BNs in general yield marginal probability distributions for
their output. Often these marginal distributions are input
to a decision maker who has to make a decision. The simplest model for choosing between alternative decisions is
the threshold decision-making model. In this section, we
briefly review the threshold model for decision making and
describe sensitivity analysis of BNs in view of this model.
Although generally applicable, the threshold decisionmaking model is used most notably for patient management
in medicine [13]. Since our dVAP network also pertains
to the field of medicine, we present the model in medical
terms. With the model, a clinician decides whether or not
to gather additional information from diagnostic tests and
whether or not to give treatment based upon the probability
of disease for a patient. The threshold model to this end
builds upon various threshold probabilities of disease.
The treatment threshold probability p∗ is the probability
at which the clinician is indifferent between giving treatment and withholding treatment. If, for a specific patient,
the probability of disease exceeds the treatment threshold
probability, then the clinician will decide to treat the patient
as if the disease were known to be present with certainty.
Alternatively, if the probability of disease is less than p∗ ,
the clinician will basically withhold treatment. As a consequence of the uncertainty concerning the true condition

no treat p−

p+

test
no treat

p

∗

treat

treat

Figure 3: The threshold decision model.
of the patient however, additional information from a diagnostic test may affect the clinician’s basic management
decision. The threshold model therefore includes another
two threshold probabilities. The no treatment-test threshold probability of disease p− is the probability at which
the clinician is indifferent between the decision to withhold
treatment and the decision to obtain additional diagnostic
information. The test-treatment threshold probability p+
is the probability at which the clinician is indifferent between obtaining additional information and starting treatment rightaway. Figure 3 illustrates the various threshold
probabilities employed by the model.
In view of the threshold model for decision making, sensitivity of the output of a network pertains no longer to just a
probability of interest computed from the network, but also
to the decision based upon it. To take the various threshold probabilities employed into consideration, the method
of sensitivity analysis of BNs has been enhanced with the
computation of upper and lower bounds between which
a network’s parameters can be varied without inducing a
change in decision [15]. The computation of these bounds
builds upon the sensitivity functions relating the probability of interest to the network’s parameters. By equating the
function for a specific parameter to the various threshold
probabilities, bounds are obtained between which the parameter can be varied. Since the sensitivity functions for a
BN are either monotonically non-decreasing or monotonically non-increasing, a single lower bound and a single
upper bound are guaranteed to exist.

5 Sensitivity analysis of decisions with DBNs
The probabilities established from a dynamic network are
also often employed for decision making. The goal of
the dVAP model, for example, is to monitor the onset
of ventilator-associated pneumonia in ICU patients and to
start appropriate treatment as soon as possible. Sensitivity
to parameter variation then pertains not just to the probability of VAP but also to the decision that the clinician makes
based upon this probability. To provide for studying this
type of sensitivity, we extend sensitivity analysis of DBNs
in view of threshold decision making.
5.1 Analysis of single parameters
Suppose that a posterior probability p(xnr | en ) of interest
has been computed from a DBN; based upon this probability, a particular decision has been established from the
threshold decision-making model. We now are interested

in the effect of variation of a parameter θ on this decision.
To compute upper and lower bounds between which the
parameter can be varied without inducing a change in decision, the sensitivity function p(xnr | en )(θ) is equated to the
threshold probabilities p− and p+ , respectively. The lower
and upper bounds thus are solutions of the equations
p(xnr , en )(θ)
p(xnr , en )(θ)
= p− and
= p+
p(en )(θ)
p(en )(θ)

(1)

We recall that for DBNs a sensitivity function in general is
a quotient of higher-order polynomials. Contrary to threshold decision making for BNs therefore, there is no guarantee that these functions are monotonically non-decreasing
or non-increasing. The equations stated above may thus
have multiple solutions instead of single ones.
We begin by studying a parameter for which single solutions exist for the two threshold equations above. Suppose
that the lower and upper bounds computed from the equations are θ− and θ+ respectively. If p(xnr | en ) < p− ,
then the decision to withhold treatment remains unaltered
for any value of θ within the interval (−∞, θ− ) ∩ [0, 1].
If p(xnr | en ) > p+ , the decision to start treatment immediately remains unaltered for any value of θ within
(θ+ , +∞) ∩ [0, 1]. If p− ≤ p(xnr | en ) ≤ p+ , then the
decision to gather further information will be the same for
any value of θ within the interval (θ− , θ+ ) ∩ [0, 1].
As an example from the dVAP network, we illustrate the
bounds on variation of the parameter θ = p(leucocytosis =
yes | pneumonia = yes) in view of the management decision for a particular patient at day 4; Figure 2 shows the
sensitivity function that expresses the probability of VAP
for this patient in terms of θ. Suppose that the three threshold probabilities are fixed at p∗ = 0.2, p− = 0.12, and
p+ = 0.64. From the dVAP network, we have that p(vap4 |
e4 ) = 0.134 and hence that p− ≤ p(vap4 | e4 ) ≤ p+ . The
clinician thus decides to gather additional information for
the patient. Solving the two threshold equations from (1),
we find a lower bound on the parameter under study equal
to θ− = 0.676; the upper bound is θ+ = 1.1063. For any
value of the parameter within the interval (0.676, 1], therefore, the decision to gather additional information will remain unaltered. Since the original value of the parameter
has been assessed at 0.7, we conclude that the decision is
not very robust with regard to this parameter.
We now turn to parameters for which the threshold equations have multiple solutions. Suppose that from the notreatment-test threshold probability p− , we find the vector of solutions θ − = (θ1− , θ2− , . . . , θr− ), in which the parameter values θi− are given in ascending order; from the
test-treatment threshold probability p+ , we find the vector
θ + = (θ1+ , θ2+ , . . . , θs+ ), again with the θi+ in ascending
order. We further use v(θi ) to denote the value of the first
derivative of the sensitivity function for the parameter θ at
θi . The value of the first derivative helps in determining

1

treat

0.9

p+=0.88

p(vap4 e4) →

0.8
0.7

test

0.6
0.5

p−=0.34

0.4
0.3
0.2

no treat

0.1
0

0

0.2

0.4

θ →

0.6

0.8

1

Figure 4: Threshold decision making for the treatment of pneumonia when varying the parameter θ = p(temperature = low |
pneumonia = no, a.drugs = yes).

the intervals in which a particular decision holds. Now, if
the output probability p is smaller than p− , the decision
to withhold treatment remains unaltered for any value of θ
that belongs to the compound interval
½
[0, θ1− )∪(θ2− , θ3− )∪. . .∪(θr− , 1]
r is even
Θ−
=
−
+
[0, θ1− )∪(θ2− , θ3− )∪. . .∪(θr−1
, θr− ) r is odd
whenever v(θ1− ) > 0, and for any value of θ belonging to
½ − −
−
(θ1 , θ2 )∪(θ3− , θ4− )∪. . . ∪ (θr−1
, θr− ] r is even
Θ−
=
− −
− −
−
−
(θ1 , θ2 )∪(θ3 , θ4 )∪. . . ∪ (θr , 1]
r is odd
whenever v(θ1− ) < 0. Similarly, if the output probability p
+
is larger than p+ , we find compound intervals Θ+
− and Θ+
for the parameter θ within which the decision to start treatment immediately remains unaltered. Finally, if the output
probability lies between p− and p+ , the vectors θ − and θ +
are merged into the vector θ m = (θ1m , θ2m , . . . , θqm ), q =
r + s. Now, the decision will be the same for any value of
θ within the interval Θm
½
m
, θqm ) v(θ1m ) < 0
[0, θ1m )∪(θ2m , θ3m )∪. . .∪(θq−1
Θm =
m
, θqm ) v(θ1m ) > 0
(θ1m , θ2m )∪(θ3m , θ4m )∪. . .∪(θq−1
Note that in case v(θ1m ) > 0 and the value of the sensitivity
function for θ = 0 is greater than p− , the interval Θm is the
same as when v(θ1m ) < 0.
As an example, Figure 4 depicts the probability of pneumonia at day 4 given evidence e4 in terms of the parameter
θ = p(temperature = low | pneumonia = no, a.drugs =
yes); the original value of θ equals 0.2, giving p(vap4 |
e4 ) = 0.278. The figure also shows the intersection points
with the threshold probabilities, which have been set at
p− = 0.34 and p+ = 0.88. We compute the two lower
bounds to be θ1− = 0.0918 and θ2− = 0.4335; the upper
bound is θ1+ = 0.8781. Using v(θ1− ) < 0, we find that the
decision to withhold treatment remains unaltered for any
value of θ in (0.0918, 0.4335). We conclude that the decision is relatively robust with regard to the parameter.
5.2 Analysis of full conditional probability tables
In addition to single parameters, we may be interested in
the effects of varying multiple parameters, for example

Figure 5: The sensitivity function expressing the probability of
pneumonia given e5 in terms of the sensitivity θse and specificity
θsp rates of the CPT for radiological signs.

from a single conditional probability table (CPT) [3]. In a
medical application for instance, we may wish to study the
robustness of a decision in terms of both the sensitivity and
the specificity of a particular diagnostic test and not just in
one of these rates. Recall that these rates express the probabilities that a test result is found to be positive (negative)
in a patient who does (does not) have the disease. We now
extend the previous results for single parameters to CPTs
to provide for such an analysis.
For BNs, any posterior probability for the output variable
is a quotient of sums of linear functions in the parameters
of a CPT [3, 8]. For a dynamic network we obtain sums of
polynomial functions. For a joint probability p(bnr , en ) we
find that
|πCn |
X
p(bnr , en ) =
gi (θi )
i=1

where |πCn | denotes the number of parent configurations
of the variable Cn and gi (θi ) represents a polynomial function in the parameter θi for a specific parent configuration
for Cn . The polynomial functions gi (θi ) are all of the same
order and can be computed individually using the considerations of the previous section. For the joint probability
p(en ) a similar result holds. We conclude that, for a DBN,
the sensitivity function for a CPT is a quotient of sums of
higher-order polynomials in the parameters under study.
As an example, Figure 5 illustrates the effect of varying the
sensitivity and specificity rates of the CPT for radiological
signs of pneumonia at day 5 given evidence e5 for a specific
patient. The depicted sensitivity function is a quotient of
sums of two polynomial functions of order 5 each.
Upon studying the effects of varying all parameters from
a CPT in view of threshold decision making, we have to
solve threshold equations similar to (1). For a single parameter, we identified intervals for the parameter’s value
within which a decision remains unaltered. For a CPT, we
now identify areas in higher-space with the same meaning.
In the remainder of this section, we consider a CPT with

1

•

0.5
0.45

treat

0.4

+

p =0.64

0.3

θ

se

0.35

test

0.25

•

0.2
0.15
0.1

−

•

p =0.12

0.05

no treat

0
0

0.1

0.2

0.3

0.4

0.5

θsp

0.6

0.7

0.8

0.9

1

Figure 6: Threshold decision making when varying the sensitivity and specificity rates θse , θsp of the CPT for radiological signs.

sensitivity and specificity rates as in the previous example;
similar results hold for more complex CPTs.
We begin again by studying a CPT for which single lower
−
−
and θsp
rebounds exist for the two rates, denoted as θse
spectively. By re-arranging the individual polynomial func−
tions included, we can express the relationship between θse
−
and θsp as
−
−
ge(θse
) = gb(θsp
)
where ge and gb are polynomials of the same order. If ge is
invertible in [0, 1], we have that
−
−
θse
= ge−1 (b
g (θsp
))
−
−
which defines the relationship between the θse
and θsp
. The
horizontal line test can be used for checking whether ge is
invertible in [0, 1]. Establishing ge−1 , however, is computationally expensive if not infeasible [10].
−
−
and
and θsp
To determine the relationship between θse
thereby study the robustness of a recommended decision,
we use a numerical approximation procedure. We repeat0−
0−
edly pick a value θse
∈ [0, 1] and solve for θsp
∈ [0, 1].
0− 0−
From the pairs (θse , θsp ) thus obtained, we construct a line
−
−
. A
and θsp
l− representing the relationship between θse
+
similar approach is used to find a line l that represents the
+
+
relationship between the upper bounds θse
and θsp
for the
two rates. We note that our procedure requires solving just
a single polynomial equation, which is feasible in general
[12]. For larger CPTs, however, the procedure becomes
computationally more demanding, since a larger sample of
points is required to assure good results.

We now have that, if the probability of interest p(xnr | en )
falls below p− , the decision to withhold treatment remains
unaltered for any pair (θse , θsp ) below l− . If p(xnr | en ) >
p+ , the decision to start treatment remains unaltered for
any pair (θse , θsp ) above l+ . Finally, if p− ≤ p(xnr | en ) ≤
p+ , the decision will be the same for any pair (θse , θsp )
between l− and l+ .
Figure 6 now illustrates the sensitivity analysis. With our
approximation procedure, two lines are established that

serve to divide the unit square into three areas in which
different decisions apply. For our example patient, we have
that p(vap5 | e5 ) = 0.9842 > p+ . Since the original values
for the sensitivity and specificity rates under study are 0.9
and 0.95 respectively, we conclude that the decision to start
treatment right away is quite robust with regard to the CPT.
The three bullets in the figure highlight three other interesting cases. For the bullet with θsp = 0.6, we observe that
the decision to test is only moderately robust since a small
change in θsp or θse can alter the decision. For the bullet
with θsp = 0.8, the decision to treat is quite robust since
only a major change in θsp or θse can induce another decision. Finally, for the bullet with θsp = 0.87, the decision
to test is not robust at all since a small change in θsp or θse
suffices to alter the decision.
To conclude, we note that when the function ge−1 is not invertible, our sampling procedure will result in multiple solutions. The unit square for θse and θsp will then be divided
in compound areas per decision, similar to the compound
intervals in the single-parameter case.

6 An approximate scheme
The number of constants in the sensitivity functions of a
DBN and the number of propagations required to compute
these constants grows linearly with n. Moreover, the computational burden of solving polynomials of high order can
grow dramatically [12]. For a larger time scope, therefore,
sensitivity analysis in view of threshold decision making
can become quite hard. To reduce the order of the polynomials in the sensitivity functions and thereby the runtime
requirements, we present a method for approximate sensitivity analysis that builds on the concept of contraction of a
Markov process [1]. We discuss our method for DBNs with
a single hidden process and review its extension to DBNs
with multiple processes.
We consider two probability distributions µ and µ0 over a
variable W . Conditioning on a set of observations is known
to never increase the relative entropy of these distributions.
Denoting the conditioning by o(·), we thus have that
D[o(µ)ko(µ0 )] ≤ D[µkµ0 ]

(2)

where D stands for the relative entropy. Now, consider the
extreme case where µ and µ0 have their entire probability
mass on two different states wi and wk respectively. We
denote by A(·) the distribution that results from processing through the transition matrix A. Even though µ and µ0
do not agree on any state, processing will cause them to
place some mass
£ on some state wj . They then
¤ agree for a
mass of min A(µ(wj ; wi )), A(µ0 (wj ; wk )) on that state
wj . Based on this property, the minimal mixing rate of the
matrix A is defined as
X
£
¤
δA = min
min A(µ(wj ; wi )), A(µ0 (wj ; wk ))
i,k

j

Given the minimal mixing rate of a transition matrix A, the
following theorem now holds [1]:
D[A(µ)kA(µ0 )] ≤ (1 − δA ) · D[µkµ0 ]
We say that the stochastic process with transition matrix
A contracts with probability δA . Combining equation (2)
with the previous theorem gives
D[A(o(µ))kA(o(µ0 ))] ≤ (1 − δA ) · D[µkµ0 ]
Performing conditioning on two different distributions and
subsequently transitioning them, will thus result in two new
distributions whose distance in terms of relative entropy is
reduced by a factor smaller than one.
Our approximate method for sensitivity analysis now builds
on the contraction property reviewed above. Suppose that
we are interested in the probability of some state of the hidden variable Xn at time step n. After entering the available
evidence en into the model, we can compute the exact posterior distribution p(Xn | en ). Building on the contraction
property, however, we can also compute an approximate
distribution pe(Xn | en ) starting from time step nφ , with
1 < nφ < n, without losing too much accuracy. We define
φ
the backward acceptable window ωn,²
for time step n with
a specified level of accuracy ², to be the number of time
steps we need to use from the past to compute the probability distribution of the hidden variable at time step n within
an accuracy of ². We now propose to perform sensitivity
analysis for time step n considering only the backward acφ
. Note that the resulting functions
ceptable window ωn,²
then include polynomials of order O(n − nφ ) rather than
of order O(n) compared to the true functions.
For a given level of accuracy ², we have to determine the
maximum value of nφ for which
D[p(Xn | en )ke
p(Xn | en )] ≤
n−nφ
(1 − δA )
· D[p(Xnφ | enφ )kp(X1 )] ≤ ²
where pe(Xn | en ) denotes the approximate distribution of
φ
Xn that is computed using ωn,²
. Solving for nφ , we find
that
(
$
¡
¢ %)
log ²/D[p(Xnφ | enφ )kp(X1 )]
nφ = max 1, n−
log(1 − δA )
(3)
where b·c stands for the integer part. Starting from nφ =
n and decreasing the value of nφ one step at a time, we
can readily establish the value of nφ that first satisfies the
equation (3). To this end, the interface algorithm needs to
have computed and stored the exact posterior distributions
p(Xno | eno ) for all no ≤ n, given evidence eno .
The procedure to compute the optimal value nφ requires at
most n computations of (3) and thus is not very demanding from a computational point of view. We recall, how-

ever, that for the computation of nφ , the interface algorithm needs to have established the exact posterior distributions given the available evidence. Now in a full sensitivity analysis, the effects of parameter variation are being
studied for a number of evidence profiles. The above procedure may then become rather demanding since for every
such profile a full propagation with the interface algorithm
is required. An alternative way would then be to approximate nφ given ² from the start and perform the entire analφ
ysis with the backward acceptable window ωn,²
. If we assume that D[p(Xnφ )kp(X1 )] is bounded from above by a
known constant M , we find that an approximate value for
nφ would satisfy
%)
(
$
log(²/M )
nφ ≈ max 1, n −
log(1 − δA )
Note that for a given ² and δA , the higher the value of M ,
the smaller the value of nφ and hence the larger the backward acceptable window. Knowledge of the domain under
study can help in determining a suitable value for M . For a
patient profile for example, M can be determined by inserting worst-case scenario observations for the first time step
and computing for that time the posterior probability distribution for the hidden variable from which M can be readily
established. The complexity that our method now entails
is just the complexity of computing M which is similar to
performing a single propagation for a single time step. This
computational burden is considerably less than the burden
of performing nφ time steps of exact inference, which we
thereby forestall in the sensitivity analysis. Note that for
some patients the computation of nφ based upon this value
M will lead to a larger backward acceptable window than
the one computed directly from equation (3).
In view of sensitivity analysis, we observe that the value
of nφ that is established as outlined above, is based on the
original values of all parameters of the model under study.
We further observe that the minimal mixing rate δA used in
the computation of nφ is algebraically dependent only on
φ
the model’s transition parameters. Using ωn,²
based upon
nφ for sensitivity analysis, therefore, is guaranteed to result
in approximate sensitivity functions within an accuracy of
² for any non-transition parameter. For transition parameters, this guarantee does not hold in general. We note, however, that for the original value of a transition parameter,
the difference between the true probability of interest and
the approximate one is certain to be smaller than ². Since
the value nφ changes with δA in a stepwise manner only,
this property holds for a range of values for the parameter. Figure 7 illustrates the relationship between nφ and δA
given particular values for n, ² and M . We observe from
the figure that there is a range of values of δA for which the
value of nφ stays the same. We expect a similar property
to hold for a range of values for the transition parameter
θa . We are currently studying this issue and hope to report
results in the near future.

n = 10, ε = 0.001




Qualitative probabilistic networks have been de­
signed for probabilistic reasoning in a qualita­
tive way. Due to their coarse level of represen­
tation detail, qualitative probabilistic networks
do not provide for resolving trade-offs and typ­
ically yield ambiguous results upon inference.
We present an algorithm for computing more in­
sightful results for unresolved trade-offs. The al­
gorithm builds upon the idea of using pivots to
zoom in on the trade-offs and identifying the in­
formation that would serve to resolve them.
1

INTRODUCTION

Qualitative probabilistic networks were introduced in the
early 1990s for probabilistic reasoning with uncertainty in
a qualitative way [Wellman, 1990]. A qualitative prob­
abilistic network encodes variables and the probabilistic
relationships between them in a directed acyclic graph.
The encoded relationships basically represent influences on
probability distributions. Each of these influences is sum­
marised by a qualitative sign indicating the direction of
shift in one variable's distribution occasioned by a shift in
another variable's distribution. For probabilistic inference
with qualitative networks, an elegant algorithm based upon
the idea of propagating and combining signs is available
[Druzdzel & Henrion, 1993a] .
Qualitative probabilistic networks capture the relationships
between their variables at a coarse level of representation
detail. As a consequence, these networks do not provide
for resolving trade-offs, that is, for establishing the net re­
sult of two or more conflicting influences on a variable's
probability distribution. If trade-offs are represented in a
qualitative network, then probabilistic inference will typi­
cally yield ambiguous results. Once an ambiguity arises,
it will spread throughout most of the network upon infer­
ence, even if only a very small part of the network is truly
ambiguous.

The issue of dealing with trade-offs in qualitative prob­
abilistic networks has been addressed before by several
researchers. S. Parsons has introduced, for example, the
concept of categorical influences. A categorical influence
is either an influence that serves to increase a probability
to 1 or an influence that decreases a probability to 0, re­
gardless of any other influences, and thereby resolves any
trade-off in which it is involved [Parsons, 1995] . C.-L. Liu
and M. P. Wellman have designed a method for resolving
trade-offs based upon the idea of reverting to numerical
probabilities whenever necessary [Liu & Wellman, 1998].
S. Renooij and L.C. van der Gaag have enhanced the ba­
sic formalism of qualitative probabilistic networks by dis­
tinguishing between strong and weak influences. Trade­
off resolution during inference is then based on the idea
that strong influences dominate over conflicting weak ones
[Renooij & Van der Gaag, 1999] . These approaches to
trade-off resolution are all based on a refinement of the rep­
resentation used in the basic formalism.
In this paper, we present a new algorithm for dealing with
trade-offs in qualitative probabilistic networks. Rather than
resolving trade-offs by providing for a finer level of rep­
resentation detail, our algorithm identifies the information
that would serve to resolve the trade-offs present in a quali­
tative probabilistic network. From this information, a more
insightful result than ambiguity is constructed.
Our algorithm for dealing with trade-offs builds upon the
idea of zooming in on the part of a qualitative probabilis­
tic network where the actual trade-offs reside. After a new
observation has been entered into the network, probabilis­
tic inference will provide the sign of the influence of this
observation on the variable of interest, given previously en­
tered observations. If this sign is ambiguous, then there are
trade-offs present in the network. In fact, a trade-off must
reside along the reasoning chains between the observation
and the variable of interest. Our algorithm isolates these
reasoning chains to constitute the part of the network that
is relevant for addressing the trade-offs present. From this
relevant part, an informative result is constructed for the
variable of interest in terms of values for the variables in-

516

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

volved and the relative strengths of the influences between
them.
We believe that qualitative probabilistic networks can play
an important role in the construction of quantitative proba­
bilistic networks for real-life application domains, as well
as for explanation of their reasoning processes. The con­
struction of a probabilistic network typically sets out with
the construction of the network's digraph. As the assess­
ment of the various probabilities required is a far harder
task, it is performed only when the network's digraph is
considered robust. Now, by assessing signs for the influ­
ences modelled in the digraph, a qualitative network is ob­
tained that can be exploited for studying the projected prob­
abilistic network's reasoning behaviour prior to the assess­
ment of its probabilities. For this purpose, algorithms are
required that serve to derive as much information as possi­
ble from a qualitative probabilistic network. We look upon
our algorithm as a first step to this end.
The paper is organised as follows. In Section 2, we pro­
vide some preliminaries concerning qualitative probabilis­
tic networks. In Section 3, we introduce our algorithm for
zooming in on trade-offs informally, by means of an ex­
ample. The algorithm is discussed in further detail in Sec­
tion 4. The paper ends with some concluding observations
in Section 5.
2

PRELIMINARIES

A qualitative probabilistic network encodes the statistical
variables from a domain of application and the probabilis­
tic relationships between them in a directed acyclic graph
G
(V(G) , A(G) ) . Each node in the set V(G) repre­
sents a statistical variable. Each arc in the set A(G) can be
looked upon as expressing a causal influence from the node
at the tail of the arc on the node at the arc's head. More for­
mally, the set of arcs captures probabilistic independence
among the represented variables. We say that a chain be­
tween two nodes is blocked if it includes either an observed
node with at least one outgoing arc or an unobserved node
with two incoming arcs and no observed descendants. If
all chains between two nodes are blocked, then these nodes
are said to be d-separated and the corresponding variables
are considered conditionally independent given the entered
observations [Pearl, 1988] .
=

A qualitative probabilistic network associates with its di­
graph G a set � of qualitative influences and synergies
[Wellman, 1990] . A qualitative influence between two
nodes expresses how the values of one node influence the
probabilities of the values of the other node. A positive
qualitative influence of node A on its successor B expresses
that observing higher values for A makes higher values for
B more likely, regardless of any other direct influences on
B; the influence is denoted S6(A, B) , where'+' is the in­
fluence's sign. A negative qualitative influence, denoted

S(j, and a zero qualitative influence, denoted S2,, are de­
fined analogously. If the influence of node A on node B
is not monotonic or unknown, we say that it is ambiguous,
denoted Sb(A, B) .
The set of influences of a qualitative probabilistic net­
work exhibits various properties [Wellman, 1990] . The
property of symmetry states that, if the network includes
the influence Sb(A, B) , then it also includes Sb(B, A) ,
J E { +, -, 0, ?}. The property of transitivity asserts that
qualitative influences along a simple chain that specifies at
most one incoming arc for each node, combine into a single
influence with the ®-operator from Table 1. The property
of composition asserts that multiple influences between two
nodes along parallel chains combine into a single influence
with the EB-operator.
Table 1: The ®- and EB-operators.
0
+

+
+

0
?

0
?

+
0
?

0
0
0
0
0

?
?
0
?

EB
+

+
+
?

0

?

0
?

+
?

0
?

?
?
?

?

In addition to influences, a qualitative probabilistic net­
work includes synergies that express how the value
of one node influences the probabilities of the values
of another node in view of a value for a third node
[Druzdzel & Henrion, 1993b] . A negative product synergy
of node A on node B (and vice versa) given the value c for
their common successor C, denoted X0 ({A, B}, c) , ex­
presses that, given c, higher values for A render higher val­
ues for B less likely. Positive, zero, and ambiguous prod­
uct synergies are defined analogously. A product synergy
induces a qualitative influence between the predecessors of
a node upon observation of that node; the induced influence
is coined an intercausal influence. In this paper, we assume
that induced intercausal influences are added to a qualita­
tive probabilistic network's graph as undirected edges.
procedure PropagateSign(from,to,message):

sign[to] � sign[to] EB message;
for each (induced) neighbour Vi of to
do linksign � sign of (induced) influence
between to and Vi;
message � sign[to] 0 linksign;
if Vi #from and Vi � Observed
and sign[Vi] =I= sign[Vi] EB message
then PropagateSign(to, Vi,message)

Figure 1: The Sign-propagation Algorithm.
For probabilistic inference with a qualitative probabilis­
tic network, an elegant algorithm is available from
M.J. Druzdzel and M. Henrion (1993a); this algorithm is
summarised in pseudocode in Figure 1. The basic idea of
the algorithm is to trace the effect of observing a node's
value on the other nodes in a network by message-passing

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS

between neighbouring nodes. For each node, a node sign
is determined, indicating the direction of change in the
node's probability distribution occasioned by the new ob­
servation given all previously observed node values. Ini­
tially, all node signs equal ' 0'. For the newly observed
node, an appropriate sign is entered, that is, either a '+'
for the observed value true or a '-' for the value false,
by calling PropagateSign(observed node, observed node, sign).
Each node receiving a message updates its sign and sub­
sequently sends a message to each neighbour that is not
d-separated from the observed node and to every node on
which it exerts an induced intercausal influence. The sign
of this message is the 0-product of the node's (new) sign
and the sign of the influence it traverses. This process is re­
peated throughout the network, building on the properties
of symmetry, transitivity, and composition of influences.
The process repeatedly visits each node that needs a change
of sign. Since a node can change sign at most twice, once
from 0 to +or-, and then only to ?, each node is visited
at most twice. The process is therefore guaranteed to halt.
3

OUTLINE OF THE ALGORITHM

If a qualitative probabilistic network models trade-offs, it
will typically yield ambiguous results upon inference with
the sign-propagation algorithm. From Table 1, we have
that whenever two conflicting influences on a node are
combined with the EEl-operator, an ambiguous sign will re­
sult. Once an ambiguous sign is introduced, it wil.l spread
throughout most of the network and an ambiguous sign is
likely to result for the node of interest. By zooming in on
the part of the network where the actual trade-offs reside
and identifying the information that would serve to resolve
these trade-offs, a more insightful result can be constructed.
We illustrate the basic idea of our algorithm to this end.

2000

517

Figure 3: The Result of Propagating '+' for NodeH.
has been observed for the node H and that we are inter­
ested in its influence on the probability distribution of node
A. Tracing the influence of the node sign'+' for nodeH,
indicating its observed value, on every node's distribution
by means of the sign-propagation algorithm, results in the
node signs shown in Figure 3. These signs reveal that at
least one trade-off must reside along the reasoning chains
between the observed node H and the node of interest A.
These chains together constitute the part of the network that
is relevant for addressing the trade-offs that have given rise
. to the ambiguous result for node A; we term this part the
relevant network. For the example, the relevant network is
shown in Figure 4 below the dashed line. Our algorithm
now isolates this relevant network for further investigation.
To this end, it deletes from the network all nodes and arcs
that are connected to, but no part of the reasoning chains
fromH to A.
A relevant network for addressing trade-offs typically in­
cludes many nodes with ambiguous node signs. Often,
however, only a small number of these nodes are actually
involved in the trade-offs that have given rise to the am­
biguous result for the node of interest. Figures 3 and 4,
for example, reveal that, while the nodes A, B, and C have
ambiguous node signs, the influences between them are not
conflicting. In fact, every possible unambiguous node sign
sign[C] for node C would result in the unambiguous sign
sign[C]0 ( ( +0-) EB-) sign[C]0- for node A. For
addressing the trade-offs involved, therefore, the part of the
relevant network between node C and node A can be dis­
regarded. Node C in fact separates the part of the relevant
network that contains trade-offs from the part that does not.
We call node C the pivot node for the node of interest.
=

Figure 2: The Example Qualitative Probabilistic Network.
As our running example, we consider the qualitative proba­
bilistic network from Figure 2. Suppose that the value true

In general, the pivot node in a relevant network is a node
with an ambiguous sign for which every possible unam­
biguous sign would uniquely determine an unambiguous
sign for the node of interest; in addition, no other node hav­
ing this property resides on an unblocked chain from the

518

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

Figure 5: The Construction of a Sign for Node C.
network, the nodes from the resolution frontier exert two
separate influences on the pivot node C: the influence from
node I via node Don C and the influence from G on C.
For the sign 8 of the influence of node I via node Don C
and for the sign o' of the influence of G on C, we find that

8
Figure 4: The Relevant Network, below the Dashed Line.
observed node to the pivot node, that is, the pivot node is
the node with this property "closest" to the observed node.
Note that every network includes such a node. Our algo­
rithm now selects from the relevant network the pivot node
for the node of interest.
From the definition of pivot node, it can be shown that there
must be two or more different reasoning chains in the rel­
evant network from the observed node to the pivot node;
the net influences along these reasoning chains, moreover,
must be conflicting or ambiguous. To resolve the ambiguity
at the pivot node, the relative strengths of the various influ­
ences as well as the signs of some of the nodes involved
need be known. From Figures 3 and 4, for example, we
have that node I lies at the basis of the ambiguous sign for
the pivot node C. Note that it receives an ambiguous node
sign itself as a result of two conflicting (non-ambiguous)
influences. An unambiguous node sign for node I would
not suffice to fix an unambiguous sign for node C. Even
knowledge of the relative strengths of the two conflicting
influences from node I on the pivot node would not suf­
fice for this purpose, however: a positive node sign for
node I, for example, would still cause node G, residing
on one of the reasoning chains from I to C, to receive an
ambiguous node sign, which in tum gives rise to an am­
biguous influence on C. Node G therefore also lies at the
basis of the ambiguity at the pivot node. Now, every com­
bination of unambiguous node signs for the nodes G and
I would render the separate influences on the pivot node
unambiguous. Knowledge of the relative strengths of these
influences would suffice to determine an unambiguous sign
for the pivot node. We call a minimal set of nodes having
this property the resolutionfrontier for the pivot node.
In terms of signs for the nodes from the resolution frontier,
our algorithm now constructs a (conditional) sign for the
pivot node by comparing the relative strengths of the vari­
ous influences exerted on it upon inference. In the example

=

=

sign[I] 0 81 0 83
sign[I]0 +

8'

=

=

sign[G] 0 84
sign[G]0-

where Di, i
1, 3, 4, are as in Figure 5. For the node sign
sign[C] of the pivot node, the algorithm now constructs the
=

following result:
if 181 2: 10'1, then sign[C]

=

8, else sign[C]

=

8';

where 181 denotes the strength of the sign 8. So, if the two
influences on node C have opposite signs, then their rela­
tive strengths will determine the sign for node C. The sign
of the node of interest A then follows directly from the node
sign of C.
4

SPLITTING UP AND CONSTRUCTING
SIGNS

In this section we detail some of the issues involved in our
algorithm for pivotal pruning of trade-offs. In doing so, we
assume that a qualitative probabilistic network does not in­
clude any ambiguous influences, that is, ambiguous node
signs upon inference result from unresolved trade-offs. We
further assume that observations are entered into the net­
work one at a time. We also assume that sign propagation
resulted in an ambiguous sign for the network's node of in­
terest. For ease of reference, Figure 6 summarises the zoom
algorithm in pseudocode.
procedure PivotalPruning(Q):

Qrel +-- ComputeRelevantNetwork(Q);
pivot+-- ComputePivot(Qrel);
ConstructResults(Qrel ,pivot)

Figure 6: The Basic Algorithm.
In detailing the algorithm, we focus attention on identify­
ing the relevant part of a qualitative probabilistic network
along with its pivot node and on constructing from these an
informative result for the node of interest.

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS

4.1

IDENTIFYING THE RELEVANT NETWORK

Our algorithm identifies from a qualitative probabilistic
network the relevant part for addressing the trade-offs that
have resulted in an ambiguous sign for the node of inter­
est. We begin by formally defining the concept of relevant
network.
Definition 1 Let Q
(G, �) be a qualitative probabilistic
network as defined in Section 2. Let 0 be the set of previ­
ously observed nodes in Q, let E be the node for which new
evidence has become available, and let I be the network's
node of interest. The relevant network for E and I given
0 is the qualitative probabilistic network Qrel
(G', �')
such that
=

=

•

•
•

V(G') consists of all nodes that occur on a chain from

E to I that is not blocked by 0;

A(G')

=

(V(G')

x

V(G') ) n A(G) ; and

�' consists of all qualitative influences and synergies
from � that involve nodes from G' only.

The concept of relevance has been introduced before, most
notably for quantitative probabilistic networks (see for ex­
ample [Druzdzel & Suermondt, 1994, Shachter, 1998]). In
fact, for quantitative and qualitative probabilistic networks
various different concepts of relevance have been distin­
guished. For a node of interest I, previously observed
nodes 0, and a newly observed nodeE, we say that a node
N is
•

structurally relevant to I, if N is not d-separated from
I given 0 U {E};

•

•

519

computationally nor dynamically relevant to the node of
interest A.
The concept of dynamic relevance was introduced to de­
note the nodes constituting the reasoning chains between a
newly observed node and a node of interest in a probabilis­
tic network [Druzdzel & Suermondt, 1994]. The set of all
nodes that are dynamically relevant to the node of interest
I and the newly observed nodeE, given the previously ob­
served nodes 0, can in fact be shown to induce the relevant
network forE and I given 0, as defined in Definition 1.
From a qualitative probabilistic network, the set of dy­
namically relevant nodes can be established by first deter­
mining all nodes that are computationally relevant to the
node of interest I and then removing the nodes that are not
on any reasoning chain from the newly observed node E
to I. For computing the set of all computationally rele­
vant nodes, the efficient Bayes-Ball algorithm is available
from R.D. Shachter (1998). The algorithm takes for its in­
put a probabilistic network, the set of all observed nodes
0 U {E}, and the node of interest I; it returns the sets
of nodes that are computationally relevant, or requisite,
to I. From the set of computationally relevant nodes, all
nodes that are not on any reasoning chain from the newly
observed node E to the node of interest I need be iden­
tified; these nodes are termed nuisance nodes for E and
I. An efficient algorithm is available for identifying these
nodes [Lin & Druzdzel, 1997]. The algorithm takes for its
input a computationally relevant network, the set of previ­
ously observed nodes 0, the newly observed node E, and
the node of interest I; it returns the set of nuisance nodes
for E and I. The algorithm for computing the relevant
part of a qualitative probabilistic network is summarised
in pseudocode in Figure 7.
function ComputeRelevantNetwork(Q):

computationally relevant to I, if the (conditional)
probabilities for N are required for computing the
posterior probability distribution for I given the ob­
servations for 0 U {E}; and

Qrel

requisites+--- BayesBaii(G, 0 U {E}, I);
V(G)+--- (V(G) \requisites) U {E};
A(G) +--- (V(G) x V(G)) n A(G);
nuisances+--- ComputeNuisanceNodes(G);
V(G)+--- V(G) \ nuisances;
A(G)+--- (V(G) x V(G)) n A(G);
L1 +--- {all influences and synergies from L1 in G};
return Qrel
(G, L1)

dynamically relevant to I andE, if N partakes in the
impact of E on I in the presence of the observations
forO.

In our example qualitative network, node D is structurally
relevant, computationally relevant, and dynamically rele­
vant to the node of interest A. NodeE is structurally rele­
vant to node A yet neither computationally nor dynamically
relevant. Node J is structurally irrelevant to the observed
nodeH, as is also evidenced by its node sign '0' upon in­
ference; it is both structurally and computationally relevant
to the node of interest A, yet dynamically irrelevant. The
newly observed node H is d-separated from A by its be­
ing observed. It therefore is not structurally relevant to A;
it is computationally as well as dynamically relevant to A,
however. Node M, to conclude, is neither structurally nor

2000

=

Figure 7: The Algorithm for Computing the Relevant Net­
work.
4.2

IDENTIFYING THE PIVOT NODE

After establishing the relevant part of a qualitative proba­
bilistic network for addressing the trade-offs present, our
algorithm identifies the pivot node. The pivot node serves
to separate the part of the relevant network that contains
the trade-offs that have given rise to the ambiguous sign
for the node of interest, from the part that does not con-

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

520

tain these trade-offs. The pivot node will allow for further
focusing. We recall that the pivot node is a node with an
ambiguous node sign, for which every possible unambigu­
ous sign would uniquely determine an unambiguous sign
for the node of interest. We define the concept of pivot
node more formally.

Let Q
(G, � ) be a relevant qualitative
probabilistic network; let 0 be the set of previously ob­
served nodes, let E be the newly observed node, and let I
be the network's node of interest, as before. The pivot node
for I and E is a node P E V (G) such that

Definition 2

•

Sb(E, P)

•

Sb (P, I)

•

=

E
E

� with o

=

'?';

� with <5' =/:- '?';and

there does not exist a node P' with the above prop­
erties that resides on a chain from E to P that is not
blocked by 0.

The pivot node in a relevant qualitative probabilistic net­
work has various convenient properties. Before discussing
these properties, we briefly review the concept of an ar­
ticulation node from graph theory. In a digraph, an ar­
ticulation node is a node that upon removal along with
its incident arcs, makes the digraph fall apart into vari­
ous separate components. In the digraph of our example
network, as shown in Figure 2, the articulation nodes are
the nodes C, D, H, I, and L; for the relevant network, de­
picted in Figure 4, node C is the only articulation node,
however. Articulation nodes are identified using a depth­
first search algorithm; for details, we refer the reader to
[Cormen et al., 1990]. Theorems 1 and 2 now state impor­
tant properties of a pivot node that allow for its identifica­
tion.
Theorem 1

Theorem 2 Let Q
(G, � ) be a relevant qualitative
probabilistic network; let E and I be as before. The pivot
node for I and E is unique.
=

Proof

(sketch). From Definition 1 we have that the rele­
vant network consists of only nodes that reside on an un­
blocked chain from the newly observed node E to the node
of interest I. From the definition of articulation node, we
further have that every such chain must include all articula­
tion nodes in the relevant network. In fact, every reasoning
chain from E to I visits the articulation nodes in the same
order. From Definition 2 we have that no two pivot nodes
can reside on the same unblocked chain to the node of in­
terest. We conclude that the pivot node is unique. 0

From the proof of Theorem 2 we have that the articula­
tion nodes in a relevant network allow a total ordering. We
number the articulation nodes, together with the node of in­
terest I, from I, for the node closest to the newly observed
node, to m, for the node of interest. The pivot node now
is the node with the lowest ordering number for which an
unambiguous sign would uniquely determine an unambigu­
ous sign for the node of interest. To identify the pivot node,
our algorithm starts with investigating the articulation node
closest to the node of interest; this node is numbered m - 1.
The algorithm investigates whether an unambiguous sign
for this candidate pivot node would result in an unambigu­
ous sign for the node of interest upon sign propagation. By
propagating a '+' from the candidate pivot node to the node
of interest I, the node sign resulting for I is the sign of the
net influence of the candidate pivot node on I. If this sign is
ambiguous, then the node of interest itself is the pivot node.
Otherwise, the algorithm proceeds by investigating the ar­
ticulation node numbered m 2, and so on. The algorithm
is summarised in pseudocode in Figure 8.
-

function ComputePivot(Q):

candidates+- {I} U FindArticulationNodes(G);
order the nodes from candidates from 1 to m;
return FindPivot(m- 1);

Let Q
(G, � ) be a relevant qualitative
probabilistic network; let E be the newly observed node
and let I be the node of interest. The pivot node for I and
E is either the node of interest I or an articulation node in
=

function FindPivot(i): pivot

G.

PropagateSign(node i,node i,'+')
if sign[node i + 1]
'?'
then return node i + 1;
else FindPivot(i
1)

Proof (sketch).

By definition we have that every possible
unambiguous node sign for the pivot node determines an
unambiguous sign for the node of interest I. It will be ev­
ident that node I itself satisfies this property. Either the
node of interest I or another node on an unblocked chain
from E to I, therefore, is the pivot node. Now, suppose
that node I is not the pivot node. As a sign for the pivot
node uniquely determines the sign for I, we conclude that
all influences exerted upon I must traverse the pivot node.
Every unblocked chain from E to I, therefore, must include
the pivot node. As a consequence, removing the pivot node
along with its incident arcs from the relevant network will
cause the network to fall apart into separate components.
We conclude that the pivot node is an articulation node. 0

pivot

=

-

Figure 8: The Algorithm for Computing the Pivot Node.
4.3

CONSTRUCTING RESULTS

From its definition, we have that there must be two or more
different reasoning chains in the relevant network from the
newly observed node to the pivot node; the net influences
along these reasoning chains are conflicting or ambiguous.
Our algorithm focuses on the ambiguity at the pivot node
and identifies the information that would serve to resolve
it. For this purpose, the algorithm zooms in on the part

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

of the relevant network between the newly observed node
and the pivot node; we call this part the pruned relevant
network. Note that the pruned relevant network is readily
computed by exploiting the property that the pivot node is
an articulation node. From the pruned relevant network, the
algorithm first selects the so-called candidate resolvers.
Definition 3 Let Q
(G, �) be a relevant qualitative
probabilistic network; let E be the newly observed node
and let I be the network's node of interest. Let P be the
pivot node for I and E. Now, let Qpru
(G', �1) be the
pruned relevant network for P. A candidate resolver for P
is a node Ri E V(G') , Ri =f. P, such that
=

where j8j once again is used to denote the strength of the
sign 8. We would like to note that as, in general, the resolu­
tion frontier includes a small number of nodes, the number
of signs to be computed for the pivot node is limited. In ad­
dition, we note that the process of constructing informative
results can be repeated recursively for the nodes in the pivot
node's resolution frontier, until the newly observed node is
reached. The basic algorithm is summarised in pseudocode
in Figure 9.
procedure ConstructResults(Q,pivot):

=

Ri

•

sign[Ri] ='?'and in-degree[Ri J 2: 2.

=

Qpru +- ComputePrunedNetwork(Q,pivot);
candidates +- ComputeCandidates(Qpru,pivot);
output ComputeResults(Qpru,pivot,candidates)

E, or

•

function

=

From among the candidate resolvers in the pruned relevant
network, our algorithm now constructs the resolution fron­
tier. We recall that the resolution frontier is a minimal set of
nodes for which unambiguous node signs would uniquely
determine the signs of the separate influences on the pivot
node.

function ComputeFrontier(pivotfrontier,
candidates): frontier
for all Vi

such that (Vi,pivot) or (pivot, Vi)
on a reasoning chain from E
do if Vi E candidates
thenfrontier +-frontier U {Vi}
else ComputeFrontier(Vi Jrontier,candidates)

=

The resolution frontier can be constructed by recursively
traversing the various reasoning chains from the pivot node
back to the observed node E and checking whether the
nodes visited are candidate resolvers.
Once the resolution frontier has been identified from the
pruned relevant network, the algorithm constructs a (con­
ditional) sign for the pivot node in terms of signs for the
nodes from the frontier. Let F be the resolution frontier
for the pivot node P. For each resolver Ri E F, let s;,
j 2: 1, denote the signs of the various different reasoning
chains from Ri to the pivot node. For each combination of
node signs sign[Ri], Ri E F, the sign of the pivot node is
computed to be
if

I EB(sign[R;]®s;

)=+

I EB(sign[R;]®s; )
then sign[PJ

=

=-

+,

( sign[Ri]

l8l

s}) 12:

( sign[Ri]

l8l

s}) I

else sign[P]

=

-

(I)

ComputeResults(Qpru.pivot,candidates):

frontier +- ComputeFrontier(pivot, 0,candidates);
for all Ri E frontier
do determines; , j 2 1;
for all R; Efrontier and sign[R;]
+,­
do return inequality (1);

The candidate resolvers for the pivot node are easily iden­
tified from the pruned relevant network.

Definition 4 Let Q
(G, �) be a pruned relevant quali­
tative probabilistic network; let E and I be as before. Let
P be the pivot node for I and E, and let R be the set of
candidate resolvers for P, as defined in Definition 3. The
resolution frontier F for P is the maximal subset of R such
that for each candidate resolver Ri E F there exists at
least one unblocked chain from E via Ri to P such that no
node Rj E R resides on the subchain from Ri to P.

521

Figure 9: The Algorithm for Constructing Results.
To conclude, we would like to note that for computing in­
formative results for a relevant network's pivot node, the
pruned network can be even further restricted. To this end,
a so-called boundary node can be identified for the newly
observed node. The boundary node is the articulation node
closest to the node of interest that has an unambiguous node
sign after propagation of the observation entered. Con­
structing results can then focus on the part of the relevant
network between the pivot node and the boundary node.
Moreover, if the thus pruned network includes many artic­
ulation nodes, it may very well be that trade-offs exist be­
tween the articulation nodes numbered k 1 and k, but not
between k and k + 1. Distinguishing between these com­
ponents is straightforward and allows for further focusing
on the actual trade-offs involved in inference.
-

5

CONCLUSIONS

We have presented a new algorithm for dealing with trade­
offs in qualitative probabilistic networks. Rather than re­
solve trade-offs by providing for a finer level of representa­
tion detail, our algorithm identifies from a qualitative prob­
abilistic network the information that would serve to re­
solve the trade-offs present. For this purpose, the algorithm
zooms in on the part of the network where the actual trade­
offs reside and identifies the pivot node for the node of in-

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

522

terest. The sign of the pivot node uniquely determines the
sign of the node of interest. For the pivot node, a more
informative result than ambiguity is constructed in terms
of values for the node's resolvers and the relative strengths
of the influences upon it. This process of constructing in­
formative results can be repeated recursively for the pivot
node's resolvers.
As we have already mentioned in our introduction, we be­
lieve that qualitative probabilistic networks can play an im­
portant role in the construction of quantitative networks for
real-life application domains, as well as for explanation of
their reasoning processes. For the purpose of explanation,
qualitative probabilistic networks have been proposed be­
fore. The concept of pivot node for zooming in on trade­
offs and constructing insightful results for a network's node
of interest is a very powerful concept to enable explanation
of complex reasoning processes in quantitative probabilis­
tic networks.
Acknowledgments

This work was partially supported by the EPSRC under
grant GR/L84117 and a Ph.D. studentship.



Qualitative probabilistic networks have been
introduced as qualitative abstractions of
Bayesian belief networks. One of the ma­
jor drawbacks of these qualitative networks
is their coarse level of detail, which may lead
to unresolved trade-offs during inference. We
present an enhanced formalism for qualita­
tive networks with a finer level of detail.
An enhanced qualitative probabilistic net­
work differs from a regular qualitative net­
work in that it distinguishes between strong
and weak influences. Enhanced qualitative
probabilistic networks are purely qualitative
in nature, as regular qualitative networks are,
yet allow for efficiently resolving trade-offs
during inference.

1

INTRODUCTION

The formalism of Bayesian belief networks is generally
considered an intuitively appealing and powerful for­
malism for capturing complex problem domains along
with their uncertainties. The usually large number
of probabilities required for a belief network, how­
ever, tends to pose a major obstacle to their applica­
tion. To mitigate this obstacle, qualitative probabilis­
tic networks have been introduced as qualitative ab­
stractions of Bayesian belief networks [Wellman, 1990].
Like a Bayesian belief network, a qualitative proba­
bilistic network encodes variables and the probabilis­
tic interrelationships among these variables in a di­
rected graph; the relationships are not quantified by
conditional probabilities as in a belief network, but are
summarised by qualitative signs instead. For inference
with a qualitative probabilistic network, an elegant al­
gorithm is available, based on the idea of propagating
signs [Druzdzel & Henrion, 1993].

One of the major drawbacks of qualitative probabilis­
tic networks is their coarse level of detail. As a conse­
quence of their high abstraction level, qualitative prob­
abilistic networks do not provide for modelling the
intricacies involved in weighing conflicting influences
and, hence, do not provide for resolving trade-offs. In­
ference with a qualitative probabilistic network for a
real-life domain of application, therefore, quite often
leads to ambiguous results.
Ambiguous results in inference can be averted by en­
hancing the formalism of qualitative probabilistic net­
works to provide for a finer level of detail. Roughly
speaking, the finer the level of detail, the more trade­
offs can be resolved during inference. The problem
of trade-off resolution within the framework of quali­
tative networks has been addressed before by others.
S. Parsons has introduced, for example, the concept of
categorical influences. A categorical influence is either
an influence that serves to increase a probability to 1
or an influence that decreases a probability to 0, re­
gardless of any other influences, and thereby resolves
any trade-off in which it is involved [Parsons, 1995].
C.-1. Liu and M.P. Wellman have designed two meth­
ods for resolving trade-offs based upon the idea of re­
verting to numerical probabilities whenever necessary
[Liu & Wellman, 1998]. While only some trade-offs
can be resolved by the use of categorical influences,
the methods of Liu and Wellman provide for resolving
any trade-off. Their methods, however, require a fully
specified, numerical belief network. We would like to
mention that various other approaches to dealing with
uncertainty in a qualitative way have been proposed in
the literature. These approaches are not tailored for
use within the framework of qualitative probabilistic
networks and therefore will not be reviewed here.
To provide for trade-off resolution without resorting to
numerical probabilistic information, we have designed
an intuitively appealing formalism of enhanced quali­
tative networks. An enhanced qualitative probabilis­
tic network differs from a regular qualitative network

560

Renooij and van der Gaag

in that it distinguishes between strong and weak in­
fluences. For inference, we have generalised the sign­
propagation algorithm for regular qualitative networks
to deal with the strong and weak influences of an en­
hanced qualitative network. Trade-off resolution dur­
ing inference is based on the idea that strong influences
dominate over conflicting weak influences.
The paper is organised as follows. In Section 2, we
provide some preliminaries from the field of qualita­
tive networks to introduce our notational conventions.
In Section 3, we present the formalism of enhanced
qualitative probabilistic networks. In Section 4, we
detail various properties of these enhanced networks,
thereby providing for a sign-propagation algorithm for
inference. The paper is rounded off with some conclu­
sions and directions for future research in Section 6.
2

PRELIMINARIES

Qualitative probabilistic networks have been intro­
duced as abstractions of Bayesian belief networks. Be­
fore addressing qualitative networks, we briefly review
their quantitative counterparts. A Bayesian belief net­
work is a concise representation of a joint probability
distribution on a set of statistical variables. It encodes,
in an acyclic directed graph, the variables concerned
along with their probabilistic interrelationships. Each
node in the digraph represents a variable; the prob­
abilistic relationships between the variables are cap­
tured in the digraph's set of arcs. Associated with
each variable is a set of conditional probability dis­
tributions describing the relationship of this variable
with its (immediate) predecessors in the digraph.
We introduce a small Bayesian belief network that will
serve as our running example throughout the paper.
Example 2.1 We consider the small belief network
shown in Figure 1. The network represents a fragment
Pr(a) =

0.70

I

=

Pr(d tJ) =
Pr(d tf)

I

iil

Pr{f
Pr(/ a

Pr(t �) 0.01
Pr(t a) = 0.35
=

0.95
0.15

ij_l

Pr(d
Pr(d tf

I

I

=
=

=
=

0.45
0.50

0.80
0.01

Figure 1: The Antibiotics Belief Network.
of fictitious and incomplete medical knowledge, per­
taining to the effects of administering antibiotics on
a patient. Node A represents whether or not a pa­
tient takes antibiotics. Node T models whether or not
the patient has typhoid fever and node D represents
presence or absence of diarrhoea in the patient. Node

F, to conclude, describes whether or not the composi­
tion of the patient's bacterial flora has changed. Ty­
phoid fever and a change in the patient's bacterial flora
are modelled as the possible causes of diarrhoea. An­
tibiotics can cure typhoid fever by killing the bacteria
that cause the infection. However, antibiotics can also
change the composition of the patient's bacterial flora,
thereby increasing the risk of diarrhoea. D
Qualitative probabilistic networks bear a strong re­
semblance to their quantitative counterparts. A qual­
itative probabilistic network also comprises an acyclic
digraph modelling variables and probabilistic interre­
lationships among variables. Instead of conditional
probability distributions, however, a qualitative prob­
abilistic network associates with its digraph qualitative
influences and qualitative synergies [Wellman, 1990].
A qualitative influence between two nodes expresses
how the values of one node influence the probabilities
of the values of the other node. A positive qualita­
tive influence of node A on its (immediate) successor
B, denoted s+(A,B), expresses that observing higher
values for A makes higher values for B more likely,
regardless of any other direct influence on B, that is,
Pr(b I ax)- Pr(b I iix) � 0
for any combination of values x for the set 7r(B) \ {A}
of (immediate) predecessors of B other than A. A
negative qualitative influence, denoted by s-, and a
zero qualitative influence, denoted by S0, are defined
analogously, replacing � in the above formula by ::;
and =, respectively. If the influence of node A on
node B is not monotonic or unknown, we say that it
is ambiguous, denoted S7 (A,B).
The set of influences of a qualitative probabilis­
tic network exhibits various convenient properties
[Wellman, 1990]. The property of symmetry guar­
antees that, if the network includes the influence
s+(A, B), then it also includes s+(B, A). The prop­
erty of tmnsitivity asserts that qualitative influences
along a trail, that specifies at most one incoming arc
for each node, combine into a single influence with the
®-operator from Figure 2. The property of compo­
sition asserts that multiple qualitative influences be­
tween two nodes along parallel chains combine into a
single influence with the $-operator.
®

+

+

+

0
?

0
?

+
0
?

0

?

0
0
0

?
0
?

Figure 2: The

0-

Ell
+

+
+

0
?

+

?

?

?

0
?

and $-Operators.

?
?
?

Enhancing QPNs for Trade-off Resolution

From Figure 2, we have that combining parallel qual­
itative influences with the Ell-operator may yield an
ambiguous result. Such an ambiguity, in fact, results
whenever influences with opposite signs are combined.
We say that the trade-off that is reflected by the con­
flicting influences cannot be resolved. Note that, in
contrast with the Ell-operator, the ®-operator cannot
introduce ambiguities upon combining signs of influ­
ences along trails.

bilities of the original belief network, in real-life appli­
cations, these relationships are elicited directly from
domain experts.
For reasoning with a qualitative probabilistic network,
an elegant algorithm is available from M.J. Druzdzel
and M. Henrion (1993); this algorithm is summarised
in pseudocode in Figure 4. The basic idea of the algoprocedure

Propagate-Sign(from, to, message):
sign[ to] +--- sign[to] Ell message;
for each (induced) neighbour V; of to
do linksign +--- sign of (induced) influence
between to and V;;
message +--- sign[to] ® linksign;
if V; f. from and V; ¢. Observed
and sign[V;] f. sign[V;] Ell message
then Propagate-Sign(to, V;, message)

In addition to influences, a qualitative probabilistic
network includes synergies, that express how the value
of one node influences the probabilities of the values
of another node in view of a given value for a third
node [Henrion & Druzdzel, 1991]. A negative product
synergy of node A on node B (and vice versa) given
the value c for their common successor C, denoted
x-({A,B},c), expresses that, given c, higher values
for A render higher values for B less likely, that is,
Pr(c I abx)- Pr(c I abx)- Pr(c I abx)- Pr(c I abx) :S 0
for any combination of values x for the set 71' ( C) \
{A,B} of predecessors of C other than A and B. A
product synergy induces a qualitative influence be­
tween the predecessors of a node upon observation;
the induced influence is coined an intercausal influ­
ence. Positive, zero, and ambiguous product synergies
again are defined analogously.
Example 2.2 We consider the qualitative abstraction
of the Antibiotics belief network from Figure 1. From
the conditional probability distributions specified for
node T, we have that
Pr(t I a)

-

Pr(t I a) :S 0

and therefore that s-(A,T); we further find that
s+(A,F ), s+(T,D), and s+(F,D). Either value for
node D, in addition, induces a negative intercausal
influence between the nodes T and F. The result­
ing qualitative probabilistic network is shown in Fig­
ure 3. D

Figure 3: The Qualitative Antibiotics Network.

We would like to note that, although in the previous
example,we have computed the qualitative probabilis­
tic relationships among the variables from the proba-

561

Figure 4: The Sign-Propagation Algorithm.
rithm is to trace the effect of observing a node's value
on the other nodes in the network by message-passing
between neighbouring nodes. For each node, a sign is
determined, indicating the direction of change in the
node's probabilities occasioned by the new observation
given all previously observed node values. Initially, all
node signs equal '0'. For the newly observed node, an
appropriate sign is entered, that is, either a '+' for
the observed value true or a '-' for the value false.
The node updates its sign and subsequently sends a
message to each neighbour and every node on which
it exerts an induced intercausal influence. The sign of
this message is the ®-product of the node's (new) sign
and the sign of the influence it traverses. This process
is repeated throughout the network, building on the
properties of symmetry, transitivity, and composition
of influences.
3

THE ENHANCED FORMALISM

Qualitative probabilistic networks model a problem
domain at a coarse level of detail. This coarseness
of representation is most visible in the way relation­
ships among variables are captured: the relationships
are summarised by qualitative influences without any
indication of their strengths. As a consequence of the
coarse level of detail, any trade-off encountered dur­
ing inference will remain unresolved. To allow for re­
solving trade-offs in a qualitative way, we enhance the
formalism of qualitative probabilistic networks by as­
sociating a relative strength with influences. If in a
trade-off, for example, the positive influence is known
to be stronger than the conflicting negative one, we
may then conclude the combined influence to be posi­
tive, thereby resolving the trade-off.

562

Renooij and van der Gaag

In our formalism of enhanced qualitative probabilistic
networks, we distinguish between strong and weak in­
fluences. We begin by focusing on the strong and weak
positive influences. The basic idea is to partition the
set of all positive influences into two disjoint sets of in­
fluences in such a way that any influence from the one
subset is stronger than any influence from the other
subset. To this end, a cut-off value 6 is introduced.
This value serves to partition the set of qualitative
influences into a set of influences that capture a differ­
ence in probabilities larger than 6 and a set of influ­
ences that model a difference smaller than 6. An influ­
ence from the former subset will be termed a strongly
positive influence; an influence from the latter subset
will be termed a weakly positive influence.
More formally, a strongly positive qualitative influence
of a node A on its successor B, denoted s++(A,B),
expresses, first and foremost, that observing higher
values for A makes higher values for B more likely,
regardless of any other influence on B; in addition, it
expresses that
Pr(b I ax)

-

Upon abstracting a Bayesian belief network to an en­
hanced qualitative probabilistic network, the cut-off
value 6 needs to be chosen explicitly. This cut-off
value will typically vary from application to applica­
tion. Note that it is always possible to choose a cut-off
value, as the value 6 = 1 yields a trivial partitioning
of the set of influences.
Example 3.1 We consider once again the Antibiotics
belief network from Example 2.1. Suppose that we
choose for our cut-off value 6 = 0.30. For the influence
of node A on node T, we now find that
Pr(t I a) - Pr(t I a) � 0, and
I Pr(t I a) - Pr(t I a) I = 0.34;::: 6
We therefore conclude that s--(A, T). We further
find that s++(T, D), s+(A, F), and s+(F, D). The
resulting enhanced qualitative probabilistic network is
shown in Figure 5. 0

Pr(b I ax) ;::: 6

for any combination of values x for the set 1r( B) \ {A}
of predecessors of B other than A, where 6 is the cut­
off value used. A weakly positive qualitative influence
of A on B, denoted s+(A, B), is a positive qualitative
influence such that
Pr(b I

ax

)

-

Figure 5: The Enhanced Antibiotics Network.

Pr(b I ax) � 6

for any combination of values x for the set 1r(B) \ {A}
of predecessors of B other than A, where 6 once again
is the cut-off value used. Strongly negative qualitative
influences, denoted s--' and weakly negative qualita­
tive influences, denoted s-' are defined analogously;
zero qualitative influences and ambiguous qualitative
influences are defined as in regular qualitative proba­
bilistic networks. In the sequel, we will use the phrase
strong influences to refer to both strongly positive and
strongly negative influences; the phrase weak influ­
ences is meant to have an analogous meaning. We
further say that a product synergy is strongly negative
if it induces a strongly negative intercausal influence.
Strongly positive product synergies are defined analo­
gously; zero product synergies and ambiguous product
synergies again are defined as in regular qualitative
networks.
We would like to note that, in our enhanced formal­
ism, the meaning of the sign of an influence has slightly
changed. W hile in a regular qualitative probabilistic
network, the sign of an influence represents the sign of
a difference in probabilities only, in an enhanced qual­
itative network a sign in addition captures the relative
magnitude of the difference.

We would like to note that, in real-life applications of
enhanced qualitative probabilistic networks, a cut-off
value need not be established explicitly. The parti­
tioning into strong and weak influences then is elicited
directly from the domain experts involved in the con­
struction of the network.
4

INFERENCE WITH AN
ENHANCED NETWORK

For inference with a regular qualitative probabilistic
network, an elegant algorithm is available. We recall
from Section 2 that this algorithm builds on the idea
of propagating signs throughout a network and com­
bining them with the 0- and Ell-operators. We fur­
ther recall that the algorithm exploits the properties
of symmetry, transitivity, and parallel composition of
influences. To generalise the idea of sign-propagation
to inference with an enhanced qualitative probabilis­
tic network, we enhance, in the Sections 4.1 and 4.2,
the 0- and Ell-operators to provide for the properties
of transitivity and parallel combination of strong and
weak influences; in Section 4.3, we address the prop­
erty of symmetry.

Enhancing QPNs for Trade-off Resolution

4.1

ENHANCING THE 0-0PERATOR

For propagating qualitative signs along trails of nodes
in an enhanced qualitative probabilistic network, we
enhance the 0-operator that is defined for regular
qualitative networks, to apply to strong and weak in­
fluences. We recall that the 0-operator basically pro­
vides for multiplying signs of influences. In a regular
qualitative probabilistic network, an influence captures
a difference between two probabilities. Upon multiply­
ing the signs of two influences, therefore, the sign of
the result of the multiplication of two such differences
is computed. In our formalism of enhanced qualitative
probabilistic networks, we have added an explicit no­
tion of relative magnitude to influences. It will be ev­
ident that these relative magnitudes need to be taken
into consideration when multiplying signs.
To address the effect of multiplying two signs in an en­
hanced qualitative probabilistic network, we consider
the network fragment shown in Figure 6. The frag-

-0
Figure 6: A Fragment of a Network.
ment includes the trail of nodes A, B, C, with two
qualitative influences between them; in addition, X
denotes the set of all predecessors of B other than A,
and Y is the set of all predecessors of C other than B.
For the qualitative influence of A on C,we have that
Pr(c I axy)- Pr(c I axy) =
(Pr(c I by)- Pr(c I by))· (Pr(b I ax)- Pr(b I ax))
for any combination of values x for the set of nodes X
and any combination of values y for the set Y.
Suppose that both qualitative influences in the net­
work fragment under consideration are strongly posi­
tive, that is, we have that s++(A, B) and s++(B, C);
suppose that we have used the cut-off value 8 for dis­
tinguishing between strong and weak influences. From
the expression stated above for the influence of node
A on node C, we now find that
Pr(c I axy)- Pr(c I axy) � ()2
for any combination of values xy for the set of nodes
XU Y. Since 8 ::; 1, we have that 82 :S 8. Upon mul­
tiplying the signs of two strong influences, therefore,

563

a sign results that expresses an influence that may or
may not be stronger than a single weakly positive in­
fluence.
Now suppose that both qualitative influences in the
network fragment from Figure 6 are weakly positive,
that is, we have that s+(A, B) and s+(B, C). For the
influence of node A on node C, we now find that
Pr(c I axy)- Pr(c I axy) :S (j2
for any combination of values xy for the set X U Y.
While the influence resulting from the multiplication
of two strong influences cannot be compared to a sin­
gle weak influence, the above observation shows that
the resulting influence will always be at least as strong
as an influence resulting from the multiplication of two
weak influences. To provide for comparing qualitative
influences along different trails with respect to their
magnitude, as required for trade-off resolution, there­
fore, we need to retain the length of the trail in the
network over which influences have been multiplied.
To provide for comparing qualitative influences along
different trails, we augment every influence's sign by
a superscript, called the sign's multiplication index. A
strongly positive qualitative influence with multiplica­
tion index i of node A on node B, written s++' (A, B),
is now taken to denote that
Pr(b I ax)- Pr(b I ax) � 8i
for every combination of values x for the set X of pre­
decessors of B other than A. A weakly positive quali­
tative influence with multiplication index i of A on B,
written s+; (A, B), is taken to indicate that
0 :s Pr(b I ax)- Pr(b I ax) :s 8i
for every combination of values x for the set X. The
signs associated with the arcs of the digraph are inter­
preted as having a multiplication index equal to 1.
Building on the concept of multiplication index, Fig­
ure 7 shows the table for the enhanced 0-operator.
From the table, it is readily seen that the +, -, 0, and
? signs combine as in a regular qualitative probabilistic
network; the difference is just in the handling of the
multiplication indices. In the table, there appear signs
+? and -7; we will elaborate on the meaning of these
signs in Section 4.2.
We like to further comment on the combination of the
signs +; and ++i. In doing so, we consider once again
the network fragment from Figure 6. Suppose that we
have s+" (A, B) for the influence of node A on node
B, and s++; (B, C) for the influence of B on C. The
weakly positive influence of A on B expresses that
Pr(b I ax)- Pr(b I ax) :s 8i

564

Renooij and van der Gaag

181

++

'

++j

+j

+?

0

-?

++'+i

+j
+'+i
+j

+?

0

-?

+?
0

0
0

-?

_i+j
_i

-?

0

+?
+i
+?

+j
+i+i
+j

+'

+'

+?

+?

-?

-?

0

?

0

0

__i+j

_j
_i+i
_j

?

?

+'

-?
?

0

0
0
0

0

?

i

_

i

_

0

?

__j
__

i+j

?
?
?

-?

?

+?
+i
+ +i+j

?

0

?

0
?
?
?

F igure 7: The Enhanced ®-Operator.
for every combination of values x for the set X of pre­
decessors of B other than A. The strongly positive
qualitative influence of B on C further expresses that
Pr(c I by)- Pr(c I by) 2 8i
for every combination of values y for the set Y of pre­
decessors of C other than B. For the influence of A
on C, we now find that
Pr(c I axy)- Pr(c I axy) � 8i

B, C, respectively, between the nodes A and C, and
various qualitative influences; in addition, X denotes
the set of all predecessors of B other than A, and Y
is the set of all predecessors of C other than A and B.
For the net qualitative influence of node A on node C
along the two parallel trails, we have that
Pr(c I axy)- Pr(c I axy) =
(Pr(c I aby)- Pr(c I aby)) Pr(b I ax)+
-(Pr(c I aby)- Pr(c I aby)) Pr(b I ax)+
+(Pr(c I aby)- Pr(c I aby))
·

·

for every combination of values xy for the set X U Y.
'
We therefore conclude that s+ (A, C). So, +;18>++; =
i
+ . Similar observations apply to any multiplication
of a weak and a strong influence.
4.2

for any combination of values x for the set of nodes X
and any combination of values y for the set Y.

ENHANCING THE EB-OPERATOR

For combining multiple qualitative influences between
two nodes along parallel trails in an enhanced quali­
tative network, we enhance the EB-operator that is de­
fined for regular qualitative probabilistic networks, to
apply to strong and weak influences. We recall that the
EB-operator basically provides for adding signs of influ­
ences. We further recall that, upon adding the signs of
two conflicting influences in a regular qualitative net­
work, the represented trade-off cannot be resolved and
an ambiguous influence results. In our formalism of
enhanced qualitative probabilistic networks, we have
added an explicit notion of relative magnitude to in­
fluences. These relative magnitudes can now be taken
into consideration when adding the signs of conflict­
ing influences and used to resolve trade-offs, thereby
forestalling ambiguous results.
When addressing the enhanced ®-operator, in the pre­
vious section, we have argued that the multiplication
of two influences yields an influence of possibly smaller
magnitude. We will now see that the addition of two
influences, in contrast, may result in an influence of
larger magnitude. To address the effect of adding two
signs in an enhanced qualitative probabilistic network,
we consider the network fragment shown in Figure 8.
The fragment includes the parallel trails A, C, and A,

Figure 8: Another Network Fragment.
Suppose that all qualitative influences in the network
fragment under consideration are weakly positive, that
is, we have that s+(A, B), s+(B, C), and s+(A, C);
suppose that we have used the cut-off value 8 for dis­
tinguishing between strong and weak influences. The
net influence of node A on node C equals the sum of
the influence with sign +1 along the trail A, C, and
the influence with sign +2 along the trail A, B, C.
From the expression stated above for the net influence
of A on C, we find that
Pr(c I axy)- Pr(c I axy) 2 0
The minimum of this difference is attained, for exam­
ple, for Pr(c I aby) = 0, which enforces Pr(c I aby) = 0,
and Pr(b I ax) = Pr(b I ax) = 0. We further find that
Pr(c I axy)- Pr(c I axy) � 8 + 82

Enhancing QPNs for Trade-off Resolution

E&
i
++
+'
+?
0
-?

?

'
++

'
+

m
'
++
'
++
'
++

i
++
+?

i
++

+?
'
+

+?

?
b)
?
?

?
?
c)
?

?
?
?
?

++

0

+?

+?

++
i
+
+?
0

+?

-?

?

j

-?
i

?
?
?

-?
-?
-?

?

__

a)
?
?

j

?
d)
?

j

_

__

-?

__

j

-?

?

?

?
?
?
?
?
?
?
?
?

565

where m = min(i,j),

a) +?,if i::::; j; ?, otherwise
b)

+7,

if j::::; i; ?, otherwise

c) -?,if i ::::; j; ?, otherwise
d) -?,if j ::::; i; ?, otherwise

Figure 9: The Enhanced E&-Operator.
This maximum is attained, for example, for Pr(c I
aby) = 1, Pr(c I aby) = 1- 8, Pr(c I aby) = 1- 2 · 8,
Pr(c I aby) = 1- 8, and Pr(b I ax) = 1. In computing
the maximum of the difference,we have used explicitly
the information that all influences are weakly positive.
From the maximum attained, it is readily seen that
the addition of two weakly positive influences yields a
result that may or may not be stronger than a weakly
positive influence. In general,we have that the result
of adding two positive or two negative influences is at
least as strong as the strongest of the influences added.
From the preceding observations, we have that the
qualitative influence that results from adding two
weakly positive influences,is either weakly positive or
strongly positive. So,although the resulting influence
is known to be positive, its relative magnitude is un­
known. To capture this ambiguity,we use +? to denote
the influence's sign. An ambiguously positive qualita­
tive influence of node A on node C,written s+'(A, C),
is therefore taken to indicate that
0::::; Pr(c I axy)- Pr(c I axy) ::::;

1

for any combination of values xy for the set X U Y.
Similarly, -7 is used to denote an ambiguously nega­
tive qualitative influence.
The enhanced EB-operator is shown in Figure 9. From
the table, it is readily seen that the +, -, 0, and ?
signs combine as in a regular qualitative probabilistic
network; the difference is just in the handling of the
multiplication indices and the ambiguity subscripts.
We like to further comment on the resolution of trade­
offs using the enhanced EB-operator. In doing so, we
consider once again the network fragment from Fig­
ure 8. Suppose that we have s++(A, C) for the direct
influence of node A on node C, and that we further
have s+( A,B) and s-(B,C). The net influence of
node A on node C equals the sum of the influence with
sign ++1 along the trail A, C,and the influence with
sign -2 along the trail A, B, C. From the expression
for the net influence of A on C,we find that
Pr(c I axy) - Pr(c I axy) � 8- 82

The minimum for the difference is attained, for ex­
ample, for Pr(c I aby) = 2 8, Pr(c I aby) = 8,
Pr(c I aby) = 8,Pr(c I aby) = 0,and Pr(b I ax)- Pr(b I
ax)= 6. In computing the minimum of the difference,
we have once again exploited the information with re­
gard to the signs and relative magnitudes of the in­
fluences involved. From the minimum attained, it is
readily seen that the net influence of node A on node
C is positive. However,as 8 -82 < 8,the net influence
may either be strong or weak. We conclude that the
net influence of A on C is ambiguously positive. So,
+ +1 EB-2 = +7. Similar observations apply to various
other trade-offs.
·

4.3

THE PROPERTY OF SYMME TRY

The sign-propagation algorithm for inference with a
regular qualitative network explicitly builds on the
properties of symmetry,transitivity,and parallel com­
position of influences. We have so far addressed the
0- and E&-operators and have thereby guaranteed the
transitivity and parallel-composition properties of in­
fluences. We now focus on the property of symmetry
to enable the propagation of qualitative influences over
a single arc in the network in both directions.
In a regular qualitative probabilistic network, the
property of symmetry guarantees that, if a node A
exerts an influence on a node B, then node B exerts
an influence of the same sign on node A. In an en­
hanced qualitative network, an influence and its re­
verse also are both positive or both negative. The
symmetry property,however, does not hold with re­
gard to the relative magnitudes of an influence and its
reverse. The reverse of a strongly positive qualitative
influence may be a weakly positive influence, and vice
versa. As the relative magnitude of the reverse of a
positive influence is unknown, the reverse is taken to
be ambiguously positive. A similar observation applies
to the reverse of a negative influence.
To conclude, we would like to mention that an alter­
native way of ensuring that the property of symmetry
holds in an enhanced qualitative network is to spec-

566

Renooij and van der Gaag

ify the signs of all reversed influences explicitly; these
signs will then have to be elicited from the domain
experts involved in the network's construction.
4.4

TRADE-OFF RESOLUTION: AN
EXAMPLE

In the previous sections, we have argued that the
properties of symmetry, transitivity, and parallel com­
position of influences hold in an enhanced qualita­
tive probabilistic network. The sign-propagation algo­
rithm from Section 2 therefore is generalised straight­
forwardly to apply to enhanced qualitative networks:
instead of the regular®- and E&-operators, it just has to
use the enhanced operators for propagating and com­
bining influences. We illustrate the application of the
algorithm by means of our running example.
Example 4.5 We consider once again the qualitative
Antibiotics network from Figure 3. Suppose that we
enter the sign + for node A. Node A propagates this
sign towards node T. Node T thereupon receives the
sign + ®- = - and sends it to node D. Node D in
turn receives the sign -® + = - ; it does not pass on
any sign. Node A also sends its positive sign to node
F. Node F receives the sign + ® + = + and passes
it on to node D. Node D then receives the additional
sign +® + = +. The two signs that enter node D are
combined and result in the ambiguous sign - E& + =?
.

Now, consider the enhanced Antibiotics network from
Figure 4. We enter the sign ++0 for node A; this sign
reflects a positive observation for A. We once again
apply the sign-propagation algorithm, this time using
our enhanced operators. Recall that initially all influ­
ences' signs have a multiplication-index of 1. Node A
propagates its sign towards node T. Node T receives
the sign + +0 ® - -1 = --1 and sends it to node
D. Node D receives - -1 0 + +1 = --2. Node A
sends its sign ++0 also to node F. Node F there­
upon receives the sign + +0 ®+1 = +1 and passes it
on to node D. Node D receives the additional sign
+1 ® +1 = +2. Combining the two signs that enter
node D results in the sign - -2 E&+2 = -? · Note
that, while in the regular qualitative network the rep­
resented trade-off cannot be resolved and results in an
ambiguous influence, the trade-off is resolved in the
enhanced qualitative probabilistic network. 0
5

Conclusions and further research

One of the major drawbacks of qualitative probabilis­
tic networks is their coarse level of detail. Although
it may suffice for some problem domains, the coarse­
ness of detail may lead to unresolved trade-offs dur­
ing inference in other domains. To provide for re-

solving trade-offs, we have enhanced the formalism
of qualitative probabilistic networks by distinguish­
ing between strong and weak influences. We have
enhanced the multiplication and addition operators
to guarantee the transitivity and parallel-composition
properties of influences, thereby generalising the basic
sign-propagation algorithm to apply to enhanced qual­
itative networks. We have shown that our formalism
provides for resolving trade-offs in a qualitative, yet
efficient way.
Our formalism of enhanced qualitative probabilistic
networks does not provide for resolving all possible
trade-offs during inference. Since qualitative abstrac­
tions do not have the same expressiveness as numerical
belief networks, it is hardly likely that any qualitative
abstraction will be able to resolve all possible trade­
offs. We suspect, however, that in our enhanced signs
more information is hidden than we currently exploit
upon multiplying and adding influences. In the near
future, we will therefore investigate whether still more
trade-offs can be resolved within the framework of our
enhanced qualitative networks. In addition, we will
address the non-associativity of the addition-operator
for influences and design heuristics to forestall unnec­
essary ambiguous results. To conclude, we will extend
our formalism to incorporate non-binary variables.


Many AI researchers argue that probability theory is only
capable of dealing with uncertainty in situations where a
fully specified joint probability distribution is available,
and conclude that it is not suitable for application in
AI systems. Probability intervals, however, constitute a
means for expressing incompleteness of information. We
present a method for computing probability interval! for
probabilities of interest from a partial specification of a
joint probability distribution.

Our method improves on

erties of this graph are then exploited for computing
precise intervals.
In Section 2 we introduce the notion of a partial
specification of a joint probability distribution. Fur­
thermore, the foundation for our method for comput­
ing probability intervals from such a partial specifi­
cation is layed. In Section 3 we discuss how indepen­
dency constraints can be taken into consideration. In
Section 4 we briefly point out that our method can
be of real help in the process of knowledge acquisition
for so-called belief networks.

earlier approaches by allowing for independency relation­
ships between statistical variables to be exploited .

1

Introduction

The adversaries of probability theory for dealing with
uncertainty in AI systems often argue that it is not
expressive enough to cope with the different kinds
of uncertainty that are encountered in real-life sit­
uations. More in specific, it has been argued that
probability theory is not able to distinguish between
uncertainty and ignorance due to incompleteness of
information. The suitability of probability intervals
for expressing incompleteness has been pointed out
decisively by J. Pearl in [Pearl, 1988a]. In this pa­
per, we present a framework for computing probabil­
ity intervals from an incomplete set of probabilities.
The general idea of our approach is to take the ini­
tially given probabilities as defining constraints on a
yet unknown joint probability distribution. Several
authors have already addressed the problem of com­
puting probability intervals, see for example (Cooper,
1984] and (Nilsson, 1986]. Our approach differs from
the mentioned ones by taking independency relation­
ships between the statistical variables discerned into
consideration. In order to do so, we assume that the
independencies in the unknown distribution are spec­
ified in a special type of graph. The topological prop-

2

Computing

Probability In­

tervals
In this section, we concentrate ourselves on the notion
of a partial specification of a joint probability distri­
bution and develop a method for computing proba­
bility intervals for probabilities of interest from such
a partial specification. For the moment, we assume
that no independencies between the statistical vari­
ables discerned exist. We begin by introducing some
terminology.
Let 8( a 1, .. .,a,.) be a free Boolean algebra gen­
erated by a set of atomic propositions A =
{al, ...,a,.}, n � 1; alternatively, the Boolean al­
gebra 8(a 1 ,...,a,.) may be viewed as a sample space
being 'spanned' by a set of statistical variables Ai,
i = 1, . .. ,n, each taking values from {ai,-.ai}· A
partial specification of a joint probability distribution

on B(a1, ... , a,.) is a total function P : C - [0, 1]
where C � 8( a 1 , ... , a,.). We call such a partial
specification consistent if there exists at least one
joint probability distribution Pr on 8 such that Pr
is an extension of P onto B(a1, ...,a,.) (notation:
Pr lc = P); otherwise, P is said to be inconsis­
tent. Furthermore, we say that P (uniquely) defines
Pr if Pr is the only joint probability distribution on
B(at, ...,a,.) such that Prlc = P. Now, let Bo be

492

I
I

the subset of B(a1, ..., an) consisting of its 'smallest

following inhomogeneous system of linear

elements', that is, let

...

+

equations

+

P1

I

n
Bo = {/\ Ld L; =a; or£; =.,a;, a; E .A}
i=l

We state some convenient p rop er ties of this set Bo.
Let th e elements of Bo be enumera ted as b;, i =
1, ..., 2n. Then, for any joint probability distribu­
tion Pr on B(a1, ..., an) we have that

(I)

0
1

if j � I.;
if j E Ie,
1, .. . ' 2n, in which Ie; is the index set for Cj E
Th is system of linear equations has the 2" unkn o wn

where d;,j =

Xt,

I: Pr(b;) = 1

+

{

I

.. . , x2 ... Now, let

right-hand sides and

p

:ll

denote the column

Fur�-

vector

the vector of unknowns.

cl
of

thermore, let D denote the coefficient matrix of th
sys tem. We will use the matrix equation D:�: = p t
The probabilitie s Pr(b;) for the elements b; E 80 will denote the system of linear equations obtained from
be called the constituent probabilities of Pr. Fur ther- a partial specification P as described
We ha ve th e follo wing relation between extension
more, for each element b E B(a1, ..., an) there exists
a uniqu e set of indic es Ib E { 1, ... , 2n} such that of a consistent partial specification of a joint probabil­
b = V b;; this set Ib will be called the index set ity distribution and solutions to the matrix equatio
i=l

above.

iEZ'�

for b. For each joint p rob ability distribution Pr on
B( a1, ..., a n) we then have that
Pr(b) =

obtained from it:
•

n

i = 1, ... , 2 , is a solution to D:ll

i E Z'b
•

In addition, it can easily be shown that any consistent
partial specification P : 80 - [0, 1] defined on 80

uniquely defines a joint probability distribution Pr
8(a 1, ... , an). In the sequel,
, an) as long as
we will write 8 instead of 8(a11
•

•

ambiguity cannot occur.
We exploit the set 8o and its properties for com­
puting probability intervals from an arbitrary partial
specification. Suppose that we are given probabilities
for a number of arbitrary elements of the Boolean al­
gebra

8, that is, we consider the case in which we are

given a consistent partial specification P of a joint
probability distribution on 8 that is defined on an
arbitrary subset C � 8. The problem of computing
probability intervals from P will now be transformed
into an equivalent problem in linear algebra. The

Pr on

I
l

= p.

�

Pr on B

such

that Pr I c

=

C = {c11 1 cm}1 m ;::: 1, be a subset of 81
P: C - [0, 1] be a consistent partial speci­
fication of a joint probability distribution on B. We
Let

•

•

Note that although every joint probability distri

l

�

Dz =p corresponds with a 'probabilistic' extension
P: Dz = p may have solutions in which at leas
one of the x; 's is less than zero.
It can easily be shown that the problem of find
ing for a given 6 E B the least upper bound to the
probability of b relative to a partial sp eci fic a ti on Pi.

of

equivalent to the following linear programming pro
lem:

2"

•

constituent probabilities Pr(b;)1 6; E 80, of Pr be de­
noted by z; 1 i = 11
1 2n, and let the initially speci­
1m,
fied probabilities P(c;) = Pr(c;)1 e; e C1 i = 11

L CjZj(= Pr(b))

•

•

•

•

be denoted by

p;.

Using

(1)

and

(2), we

•

i=l

subject to
2"

(i)

"'diJZi =p;,
�
i=1

•

obtain the

(ii)

z;

lll

I

maximize

and let

now consider an arbitrary (yet unknown) joint prob­
ability distribution Pr on B with Pr I c= P. Let the

Rl

bution Pr which is an extension of P corresponds
uniquely with a solution to the matrix equatio
Dz = p obtained from P, not every solution t

general idea is to take the initially given probabili­
ties as defining constraints on a yet unknown joint
probability distribution.

B

For any non ega ti v e solution vector :ll with com
n
ponents z;, t = 1, . . ., 2 1 to Dz = p, we hav
that Pr(6;) = x;, b; E Bo1 de fin es a joint proba­
bility distribution

on the entire algebra

•

For any joint p roba bility distribution

such tha t Pr I c = P, we have that the vector
of constituent probabilities x; = Pr(b;), b; E 6

(2)

L Pr(b;)

I
l

fori=1, . . . , I Cl+l,

;::: 0 , for J·=1, . . . , 2n

I
I

I

493

I

I

I

I

I

I

I
I

I
I

I

I

I

I
I

I
I

I

I

{

if j ¢ Ib
& and di,j constitute the
if j E I
matrix D. A similar statement can be made for the
greatest lower bound to the probability of b relative
to P. Note that this linear programming approach
can deal with conditional probabilities in the same
way in which it handles prior ones; furthermore, the
approach allows for initial specifications of bounds to
probabilities instead of point estimates.
It is well-known that an LP-problem can be solved
in polynomial time, that is, polynomial in the size of
the problem, (Papadimitriou, 1982). The size of an
LP-problem is dependent, among other factors, upon
the number of variables it comprises. Now note that
the specific type of problem discussed in the foregoing
has exponentially many variables, that is, exponential
in the number of statistical variables discerned in the
problem domain. Therefore, computing probability
intervals requires an exponential number of steps.
0

tionships exist and that the cliques are interrelated
only through their intersections. In order to be able
to exploit these properties, we further assume that all
initially given probabilities are local to the cliques of
G. Once more we introduce some new terminology.
Let G = (V(G), E(G)) be a decomposable graph
with the vertex set V(G) = {V1, ... , Vn}, n 2: 1, and
the clique set C/ (G) = {C/1, ..., Clm}, m 2: 1, to be
taken as a decomposable 1-map of an unknown joint
probability distribution Pr. We take the graph from
Figure l(a) as our running example. Let B be the free
Boolean algebra generated by {V; IV; E V(G)}; fur­
thermore, for each clique C/i, let B(Cli) � 6 be the
free Boolean algebra generated by {Vj I Vj E V(C/i)}.
Now, let P be a partial specification of a joint proba­
bility distribution on B (recall that all initially given
probabilities are local to the cliques of G). We say
that P is consistent with respect to G if P can be
extended in at least one way to a joint probability
distribution Pr on B such that Pr is decomposable
relative toG, that is, such that Pr can be expresssed
3
Exploiting
Independency in terms of marginal distributions on the cliques of
G. The initi ally given probabilities being local now
Relationships
allows us to apply the notions introduced in the pre­
In the preceding section we have presented a linear ceding section separately to marginal distributions on
programming method for computing probability in­ th e cliques of G. We begin by taking the definition
tervals from a consistent partial specification of a of a partial spec ification of a joint probability distri­
joint probability distribution. The initially assessed bution to apply to margin al distr�butions: a partial
probabilities were viewed as defining constraints on specification of a marginal distribution on B( Cli) is a
an unknown probability distribution. We assumed total function met; : Ci - [0, 1) where Ci � B(Cli).
that no independency relationships existed between Note that we may now view Pas been defined by a
the statistical variables discerned. In this section, set of partial specifications of marginal distributions
the linear programming approach is extended with M ={met; I C/i E C/(G)}. Furthermore, we take the
an additional method for representing and exploiting notion of consistency to apply to partial sp ec ifi ca ti ons
tions: we call such a partial spec­
independency relationships. Note that representing of marginal
it can be extended in at least
independency relationships in a straightforward man­ ification consistent
tual marginal dist rib u tion.
ner yields nonlinear constraints and therefore is not one way
The analogy between the notions of a consistent
suitable for our purposes.
where Cj

=

1

·

·

·

We assume that the independency relationships be.

partial specification of a joint probability distribution

tween the statistical variables have been specificed as

and a consistent partial specification of

an 1-map of the unknown joint probability distribu­

distribution suggest that we may apply the linear

tion

programming method presented in the preceding

Pr.

Informally speaking, an 1-map of

Pr

is an

undirected graph in which the vertices represent the

a marginal
sec­

tion separately to each of the partial specifications

statistical variables discerned and the missing edges

of marginal distributions associated with the

indicate the independencies holding between the vari­

of G.

ables. Furthermore, we assume that the fill-in algo­

of marginal distributions have been specified consis­

rithm by R.E. Tarjan and

M.

Yannakakis has been

applied to yield a decomposable 1-map G of

Pr.

An

cliques

However, even if all partial specifications

tently, they might still not give rise to a

joint prob­

ability distribution that respects the independency

I- map is decomposable if it does not contain any ele­

relationships shown in G. We therefore

mentary cycles of length four or more without a short­

additional notions of consistency:

define

some

cut. For further information, the reader is referred to

[Pearl,

1988b] . We will show that we can take advan­

. •

The set M of partial specifications of

marginal
if each

tage of the topology of G by observing that between

distributions is called locally consistent

the variables in a clique of G no independency rela-

mcz, E M, i

=

1,

... , m,

is c o ns i ste nt .

494

I

I

I

I

I

I

I

I
I
I

(a)

I
separate systems of constraints �re subseque�tly
1
bined into one large system of
constramts; thts

Figure 1

•

M is called globally consistent if there exists

a set M = {J.'cJ, I J.'CJ, : 8( Cl;) - [0, lj} of
marginal distributions IJCI, on B(Cl;) such that
for each clique Cl, E C/(G), IJCI; is an ex­
tension of mcz; e M, and furthermore that
for each pair of cliques Cl;, Cli E Cl(G) with
V(Cii)n V(CI;) ¢ 0 we have that J.'CI,(V(Cl;)n
V(Clj)) = IJcz;(V(CI;) n V(Cij)); such a set M
is called a global extension of M.

It can be shown that global consistency of M is a
necessary and sufficient condition for P being consis­
tent with respect to G; further details are provided
in [Gaag, 1990].
We now apply the linear programming method
from the preceding section separately to each of the
partial specifications of marginal distributions asso­
ciated with the cliques of G. For each clique Cl; E
Cl( G) we now define a vector z; of constituent proba­
bilities of a yet unknown marginal distribution J.'CI, in
the manner described in Section 2. From the partial
specification met, associated with clique Cl; we then
obtain an appropriate system of linear constraints
with the constituent probabilities as unknowns. This
system will be denoted by D;z; = m;, z; 2 0. The

com-

hnear

�
l

system will be denoted by Dz = m, z !:: 0. To
guarantee that every nonne�a.tive solution to the t �u
obtained system of constramts defines an extenston
of the initially given probabilities to a joint proba­
bility distribution that is decomposable relative to
G, we have to augment the system with some ad­
ditional constraints, called independency constraints,
expressing that the set M of partial specifications
marginal distributions has to be globally consistent.
In theory we now have to obtain for each pair o
cliques Cli, Cl; E C/(G) with V(Cli) n V( Cli) # 0, a
number of constraints specifying that IJcz,(V(Cli)
V(Clj)) = J.'Ct·(V(CI;) n V(Clj)). However, if we
do so, we get �any redundant constraints; in fact,
the reader may verify that it suffices to obtain independency constraints from the clique intersections
represented in a join tree of G only. Figure l(b)
shows a join tree Ta of our example graph. Note
that the resulting independency constraints each in­
volve variables from two cliques only. In the sequel,
the system of independency constraints for the intersection of two cliques Cli and Clj will be denoted

o­
nl
�

l
�

495

I

I

I

I

I

I

I

I

I

I

I

I

I
I

I

I

I

I
I

by T;,j�i- Tj,i�i = 0; the system of independency
constraints obtained from an entire clique tree of G
will be denoted by T� = 0. From now on we will call
D� = m, T� = 0, � 2: 0, the joint system of con­
straints. Analogous to our observations in Section
2, we have that the problem of finding for a given
b e B (which is local to a clique of G), the least
upper bound to the probability of b is equivalent to
maximizing the probability of b subject to this joint
system of constraints. Again, a similar statement can
be made concerning the greatest lower bound to the
probability of b. It should be evident that in the
resulting probability interval the independency rela­
tionships shown in G have been taken into account
properly.
We can solve the linear programming problem dis­
cussed above using a traditional LP-program or a de­
composition method like Dantzig-Wolfe decomposi­
tion, [Papadimitriou, 1982]. In such a straightfor­
ward approach, however, the modular structure of
the problem at hand is not fully exploited. We will
present an algorithm for solving the problem in which
the computations are restricted to local computations
per clique only. First, we describe its basic idea in­
formally for our running example.
Consider Figure 2 in which the join tree Ta of
G has been depicted once more, this time explicitly
showing the clique intersections. We view Ta as a
computational architecture in which the vertices are
autonomous ohjuts holding the local systems of con­
straints as private data. These objects are only able
to communicate with their direct neighbours and only
'through' the independency constraints: the edges
are viewed as communication channels. The indepen­
dency constraints are used for relating variables from
one clique to variables from another one. Now, sup­
pose that we are interested in the least upper bound
to a probability of interest which is local to a specific
clique, like the one shown in the figure. The object
corresponding with the clique now sends a request
for information about further constraints, if any, to
its neighbours and then waits until it has received the
requested information from all of them. For the mo­
ment, each 'interior' object in the join tree just passes
the request on to its other neighbours and awaits the
requested information. As soon as a leaf( or the root)
of the tree receives such a request for information, a
second pass through the tree is started. The leaf com­
putes the feasible set of its local system of constraints
and derives from it (by means of projection) the set
of feasible values for the probabilities which are the
constituent probabilities for the intersection(s) with
its neighbour(s). This information then is passed on
to these neighbours via the appropriate communica-

tion channels using the independency constraints for
'translation' of the variables. This results in the ad­
dition of extra constraints to the local system of con­
straints of these neighbours. These computations are
performed by the interior vertices as well until the ob­
ject that started the computation has been reached
again. The arcs in Figure 2 represent the flow of com­
putation from this second pass through the join tree.
From its (extended) local system of constraints, the
object that started the computation may now com­
pute the least upper bound to our probability of inter­
est. The result obtained is the same as when obtained
directly from the joint system of constraints. The in­
tuition of this property is that when the process has
again reached the object that started the computa­
tion, this object has been 'informed' of all constraints
of the entire joint system. By directing the same pro­
cess once more towards the root and the leaves of the
tree, all objects can be brought into this state. So, in
three passes through a join tree, each object locally
has a kind of global knowledge concerning the joint
system of constraints. It will be evident that for any
probability of interest which is local to a clique we
can now compute a probability interval locally.
The

following algorithm describes

these

three

Without loss of generality we assume that
the computation is started by the root Cl, of the
clique tree Ta. It performs the following actions:

passes.

1. Send a request for information to all neighbours

and wait.
2.

If a return message, having the form of a system
of constraints, has been received from all neigh­
bours, then add these systems of constraints to
the local system of constraints D,�. = m,,
z, 2: 0; compute the feasible set F, of the re­
sulting system and derive from it the (convex)
set {T,Jz,l z, E F,}, for each neighbour Cli of
Cl,.

Clj, send this
information as a system of constraints to Cli us­
ing T,J�•- T1,,�i = 0.

3. For each such neighbouring clique

Each leaf Cli of Ta performs the following actions:
1. Wait for a message.

2. If a request for information is received, then com­
pute the feasible set F; of the local system of
constraints DiZi = m;, z; � 0, and derive from
it the set {TiJZil Zi E Fi}, for the neighbour
Cl1.
3. Send this information as a system of constraints

to Cli using TaJZi- Tj,&ZJ
for a message.

=

0, and then wait

496

I

I

I

I

I

maximize
Pr(v� V -,116)

I

I

I

c:ompuce

I

add

add

I

compute

I

add

compute

I

I

I
l

Figure 2

4. If a system of linear constraints is received, then

add this system to the local system of constraints

D;z;

=

m;, z;

� 0.

Cit be
defined as the vertex on the path from Cl; to Cl, and
let Cli be defined as the set of all other neighbours of
Cl;. Each interior vertex Cl; performs the following
For each interior vertex

Cl,,

let the vertex

actions:

1. Wait for a message.

2.

3. If systems of constraints have been received from
all neighbours Cl�c E Cli (or from Ctt, respec­
tively), then add these additional systems of con­
straints to D;z; = m;, z; � 0; compute the feasible set F, of the resulting system of constraints
and derive from it the set {TiJ z; lza E Fi} for
Cli =Cit (or for each Clj E Cli, respectively).

1

.

4. For each such clique

Clj,

send this information

as a system of constraints to Cli using

Tj,iZj

=

�

T;,jZ; -

0.

.

I
l

The correctness of the algorithm has been proven in
If a request for information is received from the

[Gaag, 1990]. In general, the algorithm may take ex­
ponential time. However, if the maximal clique size

other neighbours Cli e Cli.

is small compared to the number of statistical vari-

neighbour Cit, then pass this message on to all

497

I

I
I

I

I

I

I

I

I
I

I

I

I

I

I

I

I

I

.I

ables, the algorithm will take polynomial time. An
important question for the algorithm to be of prac­
tical use is the question whether it is likely that the
mentioned restriction will be met in practice. Con­
cerning this, J. Pearl argues that sparse, irregular
graphs are generally appropriate in practical applica­
tions, [Pearl, 1988b].
The probability intervals obtained after application
of the algorithm may be rather wide, in fact they
may be too wide for practical purposes. However,
the intervals are precise and in a sense 'honest': they
just reflect the lack of knowledge concerning the joint
probability distribution.

4

Conclusion

intervals can guide the expert in providing further
information.




In building Bayesian belief networks, the elic­
itation of all probabilities required can be a
major obstacle. We learned the extent of
this often-cited observation in the construc­
tion of the probabilistic part of a complex
influence diagram in the field of cancer treat­
ment. Based upon our negative experiences
with existing methods, we designed a new
method for probability elicitation from do­
main experts. The method combines various
ideas, among which are the ideas of transcrib­
ing probabilities and of using a scale with
both numerical and verbal anchors for mark­
ing assessments. In the construction of the
probabilistic part of our influence diagram,
the method proved to allow for the elicita­
tion of many probabilities in little time.
1

INTRODUCTION

As more and more Bayesian belief networks are be­
ing developed for complex problem domains, it is be­
coming increasingly apparent that the elicitation of all
probabilities required is not an easy task. In fact,
the elicitation of probabilities is often referred to as
a major obstacle in building a Bayesian belief network
[Jensen, 1995, Druzdzel & Van der Gaag, 1995]. We
experienced the extent to which probability elicitation
can be an obstacle to advancement in the construc­
tion of the probabilistic part of a complex influence
diagram in the field of cancer treatment.
The Antoni van Leeuwenhoekhuis in the Netherlands,
hosting the Netherlands Cancer Institute, is spe­
cialised in the treatment of cancer patients. In the hos­
pital, every year some hundred patients receive treat­
ment for oesophageal carcinoma. Patients with oe­
sophageal carcinoma currently are assigned to a ther­
apy by means of a standard protocol, involving a small

and B.G. Taal
The Netherlands Cancer Institute
Antoni van Leeuwenhoekhuis
Plesmanlaan 121
1066 CX Amsterdam
The Netherlands

B.M.P. Aleman,

number of variables. Based upon this protocol, 80%
of the patients show a favourable response to the ther­
apy instilled. In the context of a project aimed at the
development of a more fine-grained protocol with a
higher favourable response rate, an influence diagram
is being developed for patient-specific therapy selec­
tion for oesophageal carcinoma. The influence diagram
is destined for use in the Antoni van Leeuwenhoekhuis.
The oesophagus influence diagram is being hand­
crafted with the help of two experts in oncology from
the Netherlands Cancer Institute. After carefully
modeling the characteristics of an oesophageal carci­
noma and the possible effects of the various different
therapeutic alternatives available in the graphical part
of the diagram, we focused on the elicitation of the
probabilities required for the diagram's quantitative
part. As in many problem domains, various differ­
ent sources of probabilistic information appeared to
be readily available for the elicitation task. Neither
data collection nor a thorough literature review, how­
ever, yielded any usable results. The single remaining
source of probabilistic information, therefore, was the
knowledge and personal clinical experience of the two
domain experts involved in the project.
For eliciting the conditional probabilities required for
the oesophagus influence diagram, we set out us­
ing various well-known methods with our domain
experts: we used a numerical scale for marking
assessments and we used the concept of lotteries
[Morgan & Henrion, 1990]. The various problems we
encountered with these methods and the amount of
time these methods tended to take for the separate
assessments, soon revealed that the elicitation of the
large number of probabilities required was infeasible
with these methods.
Based upon our negative experiences with existing
methods, we designed a new method for eliciting
probabilities from domain experts. We tailored our
method to eliciting a large number of probabilities
in little time. As assessments obtained in little

648

van der Gaag, Renooij, Witteman, Aleman, and Taal

time can be quite inaccurate, we envisage the use of
our method as the first step in an iterative proce­
dure of stepwise refinement of probability assessments
[Coupe et al., 1999]. Our method combines various
different ideas. Among these are the ideas of present­
ing conditional probabilities as fragments of text and
of providing a scale for marking assessments with both
numerical and verbal anchors. Using our method in
the construction of the probabilistic part of the oe­
sophagus influence diagram, we elicited from our do­
main experts the conditional probabilities required at
a rate of 150- 200 probabilities per hour. In an eval­
uation interview, the experts indicated that they had
felt very comfortable with the method.
The paper is organised as follows. In Section 2, we
provide some details of the oesophagus influence di­
agram and .discuss our initial experiences with prob­
ability elicitation for the diagram. In Section 3, we
describe the method we designed for eliciting a large
number of probabilities from domain experts. In Sec­
tion 4, we evaluate the use of our method in the con­
struction of the probabilistic part of the oesophagus
influence diagram; more specifically, we comment on
the observations put forward by the domain experts
using the method. The paper is rounded off with some
conclusions in Section 5.
2

reduction of the patient's primary tumour and an im­
proved passage of food through the oesophagus. The
various therapeutic alternatives available differ in the
extent to which these effects can be attained. Instilla­
tion of a therapy further is expected to be accompa­
nied not just by beneficial effects but also by various
complications; these complications can be very serious
and may even lead to death. The effects and com­
plications to be expected from the various therapeu­
tic alternatives available for a patient depend on the
characteristics of his or her carcinoma, on the depth
of invasion of the carcinoma into the oesophageal wall
and neighbouring structures, and on the extent of the
carcinoma's metastases. It will be evident that the
possible effects and complications require careful bal­
ancing before a therapy is decided upon.
The overall structure of the oesophagus influence di­
agram is shown in Figure 1. The graphical part of
the diagram was handcrafted with the help of two do­
main experts from the Netherlands Cancer Institute;
the construction of this graphical part took approxi­
mately two years, with one two-hour interview every
two or three weeks. The influence diagram currently

THE OESOPHAGUS INFLUENCE
DIAGRAM

As a consequence of a lesion of the oesophageal wall,
for example as a result of frequent reflux, a carci­
noma may develop in a patient's oesophagus. An oe­
sophageal carcinoma has various characteristics that
influence its prospective growth. These characteristics
include the location of the carcinoma in the oesopha­
gus, the histological type of the carcinoma, its length,
and its macroscopic shape. An oesophageal carcinoma
typically invades the oesophageal wall and upon fur­
ther growth may invade neighbouring structures such
as the trachea and bronchi. In due time, the carcinoma
may give rise to lymphatic metastases in distant lymph
nodes and to haematogenous metastases in, for exam­
ple, the lungs and the liver of the patient. The depth
of invasion and the extent of the metastases of the
carcinoma largely influence a patient's life expectancy.
While establishing the presence of an oesophageal car­
cinoma in a patient is relatively easy, the selection of
an appropriate therapy is a far harder task. In the
Antoni van Leeuwenhoekhuis, various different thera­
peutic alternatives are available, ranging from surgical
removal of the oesophagus, to radiotherapy, and po­
sitioning a prosthesis in the oesophagus. The effects
aimed at by instilling a therapy include removal or

complications

Figure 1: The Overall Structure of the Oesophagus
Influence Diagram.
includes one decision node and over 70 chance nodes.
Of these, 40 chance nodes pertain to the characteris­
tics of an oesophageal carcinoma, to the depth of its
invasion, and to the extent of its metastases; the re­
maining chance nodes model the possible effects and
complications of the various therapies available. For
the chance nodes, a total of almost 3000 probabilities
is required.
So far, we focused our elicitation efforts on the part
of the diagram that pertains to the characteristics,
depth of invasion, and metastases of an oesophageal
carcinoma. This part constitutes a coherent and self­
supporting Bayesian belief network. The 40 nodes in-

How to Elicit Many Probabilities

valved require some thousand probability assessments.
The node requiring the largest number of assessments,
144, models the staging of the carcinoma; this node is
a deterministic node, classifying an oesophageal carci­
noma according to the depth of its invasion and the ex­
tent of its metastases. The non-deterministic node re­
quiring the largest number of probability assessments
is the node describing the result of an echo-endoscopic
examination of a patient's oesophagus with respect
to the depth of invasion of the carcinoma in the oe­
sophageal wall; it requires 80 assessments.
The elicitation of the probabilities required for the 40
nodes indicated above proved to be a major obstacle
in the construction of our influence diagram. As in
many problem domains, various sources of probabilis­
tic information were available. We collected data from
historical patient records and we performed a litera­
ture review. Unfortunately, the Netherlands being a
low-incidence country for oesophageal carcinoma, we
were not able to compose an up-to-date, large and rich
enough data collection to allow for reliable assessment
of the probabilities required; after due consideration,
we decided instead to save the collected data for eval­
uation purposes. Our literature review, although very
thorough, also did not result in ready-made assess­
ments; in fact, hardly any results reported in the lit­
Prature turned out to be usable for our influence dia­
gram. The single remaining source of probabilistic in­
formation, therefore, was the knowledge and personal
clinical experience of the two domain experts involved
in the project. The problems of bias and poor cali­
bration that, unfortunately, are typically encountered
when eliciting judgemental probabilities from experts
are widely known [Kahneman et al., 1982].
In our first efforts to elicit conditional probabilities for
the oesophagus influence diagram from our domain ex­
perts, we focused on the use of a probability scale for
marking assessments, on the frequency method, and
on the concept of lotteries, as well-known methods
for probability elicitation [Morgan & Henrion, 1990,
Gigerenzer & Hoffrage, 1995]. These methods were
dPsigned to avert to at least some extent the typ­
ical problems found with human probability assess­
ment. Before commenting on our experiences with
these methods, we would like to emphasise that, prior
to the construction of the oesophagus influence dia­
gram, the domain experts involved had little or no ac­
quaintance of expressing their knowledge and clinical
experience into numbers.
The probability scale we used in the elicitation was a
horizontal line with the three anchors 0, 0.5, and 1.
The domain experts were asked to mark their assess­
ments for all conditional probabilities pertaining to
a single variable given some conditioning context on

649

the same line. The probabilities to be assessed were
presented to them in mathematical notation. Unfor­
tunately, the experts involved in the project had some
difficulties working with the mathematical notation.
In addition, they felt quite uncomfortable with the
probability scale, as it gave them very little to go by.
The request to mark various assessments on a single
line further appeared to introduce a bias towards aes­
thetically distributed marks.
With the frequency method, the domain experts were
asked to envisage a population of one hundred patients
suffering from an oesophageal carcinoma with certain
characteristics. They were asked to assess the num­
ber of patients from among this population who would
show a characteristic under study. Since oesophageal
carcinoma has a low incidence in the Netherlands, vi­
sualising one hundred patients with certain specific
characteristics turned out to be a demanding, if not
impossible, task.
The use of lotteries for probability elicitation, unfor­
tunately, also entailed various difficulties. The domain
experts indicated that they often felt confronted with
lotteries that were very hard to conceive because of the
rare, or unethical, situations they represented. More­
over, the use of lotteries tended to take so much time
that it soon became apparent that the elicitation of
several thousands of conditional probabilities in this
way was quite infeasible.
3

THE ELICITATION M ETHOD

For the probabilistic part of the oesophagus influence
diagram, several thousands of conditional probabili­
ties had to be assessed. As we argued in the previous
section, these probabilities had to be elicited from the
domain experts involved in the construction of the dia­
gram. Experience with well-known methods for prob­
ability elicitation had shown that assessing all prob­
abilities required was no easy task. Based upon the
negative experiences with these methods, we designed
a new method for eliciting probabilities from domain
experts that is tailored to the elicitation of a large
number of conditional probabilities in little time. In
this section, we present our method; its use will be
commented upon in Section 4.
Our method for probability elicitation from domain ex­
perts combines various different ideas. Although sev­
eral of these ideas were presented before by others, we
combined and enhanced them to yield a novel and, as
we will argue in the next section, effective elicitation
method. At the heart of our method lies the idea of
presenting domain experts with a separate figure for
every conditional probability that needs to be assessed.
Figure 2 shows, as an example, the figure pertaining

650

van der Gaag, Renooij, Witteman, Aleman, and Taal

certain
(almost)
probable

100

85
75

expected

polypoid oesophageal carci­
less than 5 em. How
carcinoma invades into the muscu­

Consider a patient with a

noma; the carcinoma has a length of
likely is it that this

laris propria {T2}

fifty-fifty

50

of the patient's oesophageal wall, but

not beyond?

uncertain
25
improbable
(almost)
impossible

15

0

F igure 2: The Fragment of Text and Probability Scale for the Assessment of the Conditional Probability
Pr(Invasion == T2 I Shape== polypoid, Length< 5 em ) .
to the conditional probability
Pr(

Invasion

==

T2

Shape

=

Length<

polypoid,

5

em

)

for the oesophagus influence diagram. On the left of
the figure is a fragment of text that transcribes the
conditional probability to be assessed. Using a frag­
ment of text to denote a probability circumvents the
need to use mathematical notation. The fragment is
stated in terms of likelihood rather than in terms of
frequency to forestall difficulties with the assessment
of a conditional probability for which the conditioning
context is quite rare. To facilitate the assessment of
a required probability, a vertical scale is depicted to
the right of the text fragment. Indicated on this scale
are various different numerical and verbal anchors. We
will presently comment on the specific anchors used.
The figures pertaining to the various conditional prob­
abilities to be assessed are grouped in such a way that
the probabilities from the same conditional distribu­
tion can be taken into consideration simultaneously;
the figures are presented in groups of two or three
on consecutive single-sided sheets of paper. Explic­
itly grouping related probabilities has the advantage
of reducing the number of times a mental switch of
conditioning context is required of the domain experts
during the elicitation.
The probability scale to be used with our method spec­
ifies both numerical and verbal anchors. Research on
human probability judgement has indicated that most
people tend to feel more at ease with verbal probabil­
ity expressions than with numbers. Verbal expressions
of probability are considered to be more natural than
numerical probabilities, easier to understand and com-

municate, and better suited to convey the vagueness
of one's opinions [Wallsten et al., 1993]; this observa­
tion also holds for physicians and other health workers
[Merz et al., 1991]. Words, however, should not self­
evidently be preferred to numbers, as neither should
numbers to words. In fact, the two modes of commu­
nicating probabilistic information can both be used
[Brun & Teigen, 1988]. Motivated by these observa­
tions, we decided to search for a probability scale for
marking assessments that is based on both numbers
and verbal probability expressions.
To develop a scale of verbal probability expressions
to be used with numbers, we undertook four separate
studies. In the first study, we asked subjects to pro­
vide a list of the verbal probability expressions they
commonly use. This study yielded seven most fre­
quently used expressions, being (translated from the
corresponding Dutch expressions) "certain" , "proba­
ble" , "expected" , "fifty-fifty" , "uncertain" , "improba­
ble" , and "impossible" . In the second study, (other)
subjects were asked to rank order these expressions.
The results from this study indicated that the seven
verbal probability expressions had a considerably sta­
ble rank ordering between subjects. To establish the
relative distances among the seven expressions, in the
third study, subjects were asked to compare each pair
of expressions and assess the degree to which the two
expressions conveyed the same probability. The dis­
tances yielded by this study were used to project the
verbal probability expressions onto a numerical scale.
The expression "certain" was calculated to be equiva­
lent to 100%, "probable" to be equivalent to approx­
imately 85%, and "expected" approximately to 75%;
"fifty-fifty" was calculated to be equal to 50%, "uncer-

How to Elicit Many Probabilities

tain" approximately to 25%, "improbable" to approx­
imately 15%, and "impossible", to conclude, was cal­
culated to denote 0%. Using this projection of verbal
probability expressions onto numbers, the fourth study
focused on the question whether decisions were influ­
enced by the mode in which probability information
was presented. The results indicated that the decisions
made were independent of whether the probability in­
formation was expressed numerically or verbally. We
would like to note that the four studies included sub­
jects from the field of medicine. For further details of
the studies, we refer the reader to an extended paper
[Renooij & W itteman, 1999].
The fact that the subjects in our studies interpreted
the verbal probability expressions as intended, moti­
vated us to further elaborate on a scale with both nu­
merical and verbal anchors for use as an aid for prob­
ability elicitation. Since the verbal probability expres­
sions were explicitly intended as independent anchors
on the scale rather than as translations for the nu­
merical probabilities, we decided to position the verbal
probability expressions close by rather than simply be­
side the numerical anchors. We further decided to add
the moderator "(almost)" to the most extreme ver­
bal expressions to indicate the positions of very small
and very large probabilities. The resulting probability
scale is the scale shown in Figure 2.
4

EVA LUATION OF THE
ELICITATION M ETHOD

We used our newly designed method for probability
elicitation from domain experts in the construction of
the probabilistic part of the oesophagus influence di­
agram. In this section, we evaluate the use of our
method. More specifically, we comment upon the ob­
servations put forward by the domain experts involved.
In addition, we briefly review the preliminary results
from an initial evaluation of the influence diagram in
the making.
4.1

USING THE METHOD

The elicitation of the conditional probabilities required
for the part of the oesophagus influence diagram out­
lined in Section 2, took approximately two months,
with one two-hour interview with the domain experts
every two weeks. Each interview focused on a small
coherent part of the diagram. Prior to every inter­
view, the elicitors spent some ten hours preparing the
fragments of text to be presented with our probability
scale to the experts.
In the first interview, the domain experts were in­
formed of the basic ideas underlying the new elicitation

651

method. The intended use of the probability scale was
detailed to them. In addition, the experts were told
that their initial probability assessments would be sub­
jected to a sensitivity analysis to reveal the sensitivi­
ties of the diagram's results to the various assessments,
and that we would try and refine the most influential
ones later on in the project; for details of our proce­
dure for stepwise refinement of assessments, we refer
the reader once again to [Coupe et al., 1999]. The ba­
sic idea of sensitivity analysis was explained to the
domain experts in depth to reassure them that rough
assessments for the requested conditional probabilities
would suffice at this stage in the construction of the
influence diagram.
Following the last interview, the domain experts were
asked to evaluate the new method we had used with
them for probability elicitation. For this purpose, a
written evaluation form was designed so as to not influ­
ence their observations. In the evaluation, the domain
experts indicated that they had felt very comfortable
with the elicitation method. They found the method
most effective and much easier to use than any method
for probability elicitation they had used before.
We recall from Section 3 that one of the ideas under­
lying our method for probability elicitation is the use
of a fragment of text to indicate a conditional prob­
ability that needs to be assessed. The use of these
fragments of text seemed to work very well. The two
domain experts mentioned that they had had no dif­
ficulties understanding the described patient charac­
teristics. During the interviews, the elicitors had of­
ten noted that the described characteristics served to
call to mind various different concrete patients. Al­
though the experts could not envisage a large group of
patients with certain specific characteristics, their ex­
tensive clinical experience with cancer patients in gen­
eral and their knowledge of reactive growth of cancer
cells, along with information recalled from literature,
enabled them to provide the requested assessments.
With respect to the probability scale used for marking
assessments, the domain experts indicated that they
had found the presence of both numerical and verbal
anchors helpful. They mentioned that, upon thinking
about a conditional probability to be assessed, they
used words as well as numbers. Depending on how fa­
miliar they felt with the characteristics described in a
fragment of text, they preferred using verbal or numer­
ical expressions. The more uncertain they were about
the probability to be assessed, for example, the more
they were inclined to think in terms of words. The
verbal anchors on the scale then helped them to deter­
mine the position that they felt expressed the proba­
bility they had in mind.

652

van der Gaag, Renooij, Witteman, Aleman, and Taal

The two domain experts further mentioned that they
had felt comfortable with the specific verbal anchors
used with the probability scale. They indicated, how­
ever, that the expression "impossible" is hardly ever
used in oncology. Especially in their communication
with patients, oncologists appear to prefer the more
cautious expression "improbable" to refer to almost
impossible events. As a consequence, our domain ex­
perts tended to interpret the expression "improbable"
as a 5% or even smaller probability rather than as a
probability of around 15%. Since the probability scale
provided both words and numbers, they had no dif­
ficulties indicating what they meant to express. The
experts also mentioned that an extra anchor around
40% would have been useful. Note that these ob­
servations pertain to the lower half of the scale only.
We would like to add to these observations that our
probability scale hardly accommodates for indicating
extreme probability assessments, that is, assessments
very close to 0 or 1. During the various interviews,
however, the domain experts never seemed to want to
express such extreme assessments. When asked about
extreme probabilities, they confirmed our observation.
Another idea underlying our method is the idea of
grouping the figures used in such a way that the prob­
abilities from the same conditional distribution can
be taken into consideration simultaneously. During
the elicitation interviews, the domain experts were ad­
vised first to focus on the probabilities from a condi­
tional distribution that were the easiest to assess, and
then to distribute the remaining probability mass over
the more difficult probabilities. This turned out to be
a most effective heuristic for eliciting assessments for
variables with more than two or three values.
To conclude, we would like to point out that, during
the earlier, rather unsuccessful, elicitation efforts, our
domain experts had acquired some acquaintance of ex­
pressing their knowledge and personal clinical experi­
ence into numbers. As a result, they now appeared to
be less daunted by the assessment task.

into the oesophageal wall and the worse off the pa­
tient is. For the variable Invasion, various conditional
probabilities had to be assessed, pertaining to differ­
ing shapes and varying lengths of a carcinoma. Upon
assessing the conditional probabilities required for the
variable Invasion, the domain experts started with the
probabilities for the depth of invasion of a polypoid oe­
sophageal carcinoma with a length of less than 5 cen­
timeters. They subsequently indicated that patients
with ulcerating tumours of this length were 10% worse
off with regard to the depth of invasion of the carci­
noma than patients with equivalent polypoid tumours.
They thus explicitly related two conditional probabil­
ity distributions for the variable Invasion to one an­
other. As trends appeared to be a quite natural way
of expressing probabilistic information, we encouraged
our domain experts to provide trends wherever appro­
priate.
We designed a generic method for handling the trends
provided by our domain experts in an intuitively ap­
pealing and mathematically correct way. The method
is best explained in terms of the example trend stated
above. Suppose that, given a polypoid oesophageal
carcinoma of less than 5 centimeters, the probabilities
for the four different values of the variable Invasion
have been assessed at x1, x2, x3, and x4 - x; be­
ing the probability assessment for the value Ti. After
consultation with our domain experts, we interpreted
the specified trend as follows: 10% of the patients with
a polypoid tumour of less than 5 centimeters with Ti
for its depth of invasion would have had Ti +

for

an ulcerating tumour, i = 1, 2, 3. The basic idea of
the interpretation of the trend is depicted in Figure 3.
For the probability assessments Yt, Y2, Y3, and Y4 for

�
10%

1

10%

T1
4.2

1

the depth of invasion if the tumour would have been

T2

T3

T4

THE USE OF TRENDS

Figure 3: Handling Trends.
During the elicitation interviews with our domain ex­
perts, the concept of trend emerged. We use the term
to denote a fixed relation between two conditional
probability distributions for the same variable given
different conditioning contexts.
To illustrate the concept of trend, we address the vari­
able Invasion modelling the depth of invasion of an
oesophageal carcinoma into the wall of a patient's oe­
sophagus. This variable can take one of the values
Tl, T2, T3, and T4; the higher the number indicated
in the value, the deeper the carcinoma has invaded

the different values of the variable Invasion given an
ulcerating oesophageal carcinoma of less than 5 cen­
timeters, we thus find
Yt

+--

Y2

+--

Y3

+--

Y4

+--

0.10 ·X!
0.10 · X2 + 0.10 ·X!
X2
0.10 ·X3 + 0.10 ·X2
X3
X4 + 0.10 X3
X!

-

-

-

·

It is readily verified that the resulting assessments Yt,
Y2, Y3, and Y4 each lie between 0 and 1, and together

How to Elicit Many Probabilities

add up to 1. In addition, it will be evident that this
method for handling trends can easily be generalised to
variables with another number of values and to trends
specifying other percentages and other directions of
change.
4.3

AN INITIAL EVALUATION OF THE
DIAGRAM

With our new method, we elicited from the domain
experts involved all conditional probabilities required
for the part of the oesophagus influence diagram that
pertains to the characteristics, depth of invasion, and
metastases of an oesophageal carcinoma. As men­
tioned before in Section 2, this part of the diagram
constitutes a coherent and self-supporting Bayesian
belief network; it provides for predicting the stage of
a patient's oesophageal carcinoma from the results of
various different diagnostic tests. To get some prelim­
inary insight in the quality of the influence diagram
in the making, we performed an initial evaluation of
the 40-node belief network with patient data from 184
patients, available from the Netherlands Cancer Insti­
tute. Before detailing this evaluation and its results,
we would like to note that the data collection used is
known to be biased, to contain inconsistencies, and to
be incomplete in a non-random way.
For each patient from our data collection, we instan­
tiated, in the belief network, all nodes pertaining to
diagnostic tests for which a test result was available
for the patient under consideration. These diagnos­
tic tests range from a biopsy of the primary tumour
to an echo-endoscopic examination of the oesophagus,
and an X-ray of the patient's chest. From the thus
partially instantiated belief network, we computed the
most likely stage of the patient's oesophageal carci­
noma and compared it with the stage recorded in the
data. The stage of an oesophageal carcinoma can be
either I, IIA, liB, III, IVA, or IVB.
For 29 patients from our data collection, unfortu­
nately, the stage of the oesophageal carcinoma was not
recorded, which left us with 155 patients for our eval­
uation. In 94 of these 155 patients, the stage of the
carcinoma recorded in the data matched the stage with
highest probability computed from the belief network.
Under the assumption that the stages recorded in the
data are correct, therefore, in 61% of the patients the
network predicted the correct stage. We would like to
note that this percentage is not uncommon in evalua­
tions of knowledge-based systems [Berner et al., 1994].
Careful examination of the data of the patients for
which the belief network returned an incorrect stage
learned that the network's prediction deviated from
the data most notably for patients with an oesophageal

653

carcinoma of stage IVB. For some 70% of the patients
with a IVB-staged carcinoma, another stage was pre­
dicted by the network; the stage IVB was quite often
yielded as the second most likely stage, however. Af­
ter removing all patients with a IVB-staged carcinoma
from our data collection, the network predicted the
correct stage for 68% of the remaining patients.
To conclude our initial evaluation, we re-addressed the
data of patients for whose oesophageal carcinoma the
belief network predicted a stage that differed from the
stage recorded in the data; in doing so, we once again
included the patients with a IVB-staged carcinoma.
Since most probability assessments for the network
had been rounded off at 5%, we investigated the effect,
on the percentage of correct predictions, of consider­
ing certain stages as (almost) correct. To this end, we
considered an oesophageal carcinoma as (almost) cor­
rectly staged by the network, if for the stage recorded
in the data a probability was computed from the net­
work that differed by at most 5% from the probability
of the most likely stage. The percentage of correct pre­
dictions then approached 70%. Given that the proba­
bilities used are rough, initial assessments and that the
patient data definitely require clearing out, the results
from the initial evaluation are quite encouraging.
5

CONCLUSIONS

We experienced the extent to which probability elici­
tation can be an obstacle to advancement in the con­
struction of the probabilistic part of the oesophagus
influence diagram. Motivated by our negative ex­
periences with existing methods, we designed a new
method for eliciting probabilities from domain experts.
Our method combines various different ideas, among
which are the ideas of transcribing probabilities and of
using a scale with both numerical and verbal anchors.
We used our new elicitation method for eliciting the
probabilities required for the oesophagus influence di­
agram and evaluated its use with the domain experts
involved. The experts indicated that they found the
method much easier to use than any method for prob­
ability elicitation they had used before.
For the construction of the oesophagus influence dia­
gram, our newly designed elicitation method entailed
a major breakthrough. Prior to the use of our method,
we had spent over a year experimenting, on and off,
with other methods for probability elicitation without
success. Using our elicitation method, the probabili­
ties for a major part of the oesophagus influence di­
agram were elicited in just two months' time. Our
method tends to take considerable time on the part of
the elicitors in preparing the various interviews with
the experts. However, the ease with which probabili-

654

van der Gaag, Renooij, Witteman, Aleman, and Taal

ties are elicited with the method makes this time cer­
tainly well spent.


While known algorithms for sensitivity analysis and parameter tuning in probabilistic
networks have a running time that is exponential in the size of the network, the exact computational complexity of these problems has not been established as yet. In this
paper we study several variants of the tuning problem and show that these problems
are NPPP -complete in general. We further
show that the problems remain NP-complete
or PP-complete, for a number of restricted
variants. These complexity results provide
insight in whether or not recent achievements
in sensitivity analysis and tuning can be extended to more general, practicable methods.

1

Introduction

The sensitivity of the output of a probabilistic network to small changes in the network’s parameters, has
been studied by various researchers [1, 14, 7, 2, 19, 4].
Whether the parameter probabilities of a network are
assessed by domain experts or estimated from data,
they inevitably include some inaccuracies. In a sensitivity analysis of the network, the parameter probabilities are varied within a plausible range and the
effect of the variation is studied on the output computed from the network, be it a posterior probability
or the most likely value of an output variable.
The results of a sensitivity analysis are used, for example, to establish the robustness of the network’s
output. The results are used also upon engineering
a probabilistic network, for example to distinguish between parameters which allow some imprecision and
parameters which should be determined as accurately
as possible [6]. Another use is for carefully tuning the
parameter probabilities of a network to arrive at some
desired model behavior [3].

Research efforts in sensitivity analysis and parameter
tuning for probabilistic networks have resulted in a variety of fundamental insights and computational methods. While the majority of these insights and methods
pertain to a one-way sensitivity analysis in which the
effect of varying a single parameter probability on a
single output probability or output value is studied,
recently there also has been some pioneering work on
extending these insights to higher-order analyses [2, 6].
The currently available algorithms for sensitivity analysis and parameter tuning of probabilistic networks
have a running time that is exponential in the size
of a network. This observation suggests that these
problems are intractable in general. The actual computational complexity of the problems has not been
studied yet, however. In this paper we define several
variants of the tuning problem for probabilistic networks and show that these variants are NPPP -complete
in general. We further show that the tuning problem
remains NP-comlete, even if the topological structure
of the network under study is restricted to a polytree,
and PP-complete, even if the number of conditional
probability tables involved is bounded.
Given the unfavorable complexity results obtained,
even for restricted cases of the tuning problem, we
have that we cannot expect to arrive at efficient, more
general computational methods for sensitivity analysis
and parameter tuning for probabilistic networks. Our
complexity results in fact suggest that further research
should concentrate on tuning a limited number of parameters, in networks where inference is tractable.
The paper is organized as follows. After briefly reviewing the basic concepts involved in sensitivity analysis
and parameter tuning in Section 2, we present some
preliminaries from complexity theory in Section 3 and
formally define several variants of the tuning problem
in Section 4. We give a general completeness proof for
these problems in Section 5. We further address some
special, restricted cases of these problems in Section
6. The paper ends with our concluding observations

in Section 7.

2

Sensitivity analysis and tuning

A probabilistic network B = (G, Γ) includes a directed
acyclic graph G = (V, A), where V = {V1 , . . . , Vn }
models a set of stochastic variables and A models the
(in)dependences between them, and a set of parameter probabilities Γ, capturing the strengths of the relationships between the variables. The network
Qn models
a joint probability distribution Pr(V) = i=1 Pr(vi |
π(Vi )) over its variables, where π(V ) denotes the parents of V in G. We will use Pr(C = c | E = e) to denote
the probability of the value c of the output variable C,
given an instantiation e to the set of evidence variables E, which will be abbreviated as Pr(c | e). We
will denote a particular set of parameter probabilities
as X ⊆ Γ, and we will use X to denote a single parameter. We will use x and x to denote the combination of
values of a set of parameters, respectively the value of
a single parameter. In sensitivity analysis and parameter tuning, we are interested in the effect of changes
in the parameter probabilities X on an output probability for a designated variable C. The sensitivity
function fPr(c|e) (X) expresses the probability of the
output in terms of the parameter set X. We will omit
the subscript if no ambiguity can occur.
In a one-way sensitivity analysis, we measure the sensitivity of an output probability of interest with respect
to a single parameter. The parameter under consideration is systematically varied from 0 to 1 and the other
parameters from the same CPT are co-varied such
that their mutual proportional relationship is kept constant [20]. Thus, if the parameter X = Pr(bi | ρ) (denoting the conditional probability of the value bi of
the variable B given a particular configuration ρ of
B’s parents) is varied from 0 to 1, the other parameters P r(bj | ρ) for the variable B are varied such that
Pr(bj | ρ)(X) = Pr(bj | ρ) ·

1−X
1 − Pr(bi | ρ)

for any value bj other than bi . Under the condition of
covariation, the sensitivity function f (X) is a quotient
of two linear functions [7] and takes the form
c1 · X + c2
c3 · X + c4
where the constants can be calculated from the other
parameter probabilities in the network.
f (X) =

A one-way sensitivity analysis can be extended to measure the effect of the simultaneous variation of two parameters on the output [5]. The sensitivity function
then generalizes to
f (X1 , X2 ) =

c1 · X1 · X2 + c2 · X1 + c3 · X2 + c4
c5 · X1 · X2 + c6 · X1 + c7 · X2 + c8

In this function, the terms c1 · X1 · X2 and c5 · X1 · X2
capture the interaction effect of the parameters on the
output variable. This can further be generalized to nway sensitivity analyses [6, 2] where multiple parameters are varied simultaneously. While higher-order
analyses can reveal synergistic effects of variation, the
results are often difficult to interpret [20].
For performing a one-way sensitivity analysis, efficient
algorithms are available that build upon the observation that for establishing the sensitivity of an output
probability it suffices to determine the constants in the
associated sensitivity function. The simplest method
for this purpose is to compute, from the network, the
probability of interest for up to three values for the parameter under study; using the functional form of the
function to be established, a system of linear equations
is obtained, which is subsequently solved [7]. For the
network computations involved, any standard propagation algorithm can be used. A more efficient method
determines the required constants by propagating information through a junction tree, similar to the standard junction-tree propagation algorithm [12]. This
method requires a very small number of inward and
outward propagations in the tree to determine either
the constants of all sensitivity functions that relate the
probability of interest to any one of the network parameters, or to determine the sensitivity functions for
any output probability in terms of a single parameter.
Both algorithms are exponential in the size of the network, yet have a polynomial running time for networks
of bounded treewidth.
Closely related to analyzing the effect of variation of
parameters on the output—and often the next step after performing such an analysis—is tuning the parameters, such that the output has the desired properties.
The output may need to satisfy particular constraints,
e.g. Pr(c | e) ≥ q, Pr(c1 | e)/ Pr(c2 | e) ≥ q or
Pr(c1 | e) − Pr(c2 | e) ≥ q, for a particular value q.
There are a number of algorithms to determine the
solution space for a set of parameters given such constraints [2]. The computational complexity of these
algorithms is always exponential in the treewidth w of
the graph (i.e., the size of the largest clique in the jointree), yet varies from O(cw ) for single parameter tunQk
ing, to O(n · i=1 F (Xi ) · cw ) for tuning n parameters,
where c is a constant, k is the number of CPTs that include at least one of the parameters being varied, and
F (Xi ) denotes the size of the i-th CPT. Note that the
tuning problem is related to the inference problem in
so-called credal networks [8], where each variable is associated with sets of probability measures, rather than
single values as in Bayesian networks. This problem
has been proven NPPP -complete [9].
Often, we want to select a combination of values for the

parameters that satisfies the constraints on the output
probability of interest, but has minimal impact on the
other probabilities computed from the network. In
other cases, we want the modification to be as small
as possible. In other words, we want to find a tuning
that not merely satisfies the constraints, but is also optimal, either with respect to the minimal amount of parameter change needed, or the minimal change in the
joint probability distribution induced by the parameter change. Here we discuss two typical distance measures between joint probability distributions, namely
those proposed by Kullback and Leibler [13], and Chan
and Darwiche [3].
The distance measure introduced by Chan and Darwiche [3], denoted by DCD , between two joint probability distributions Prx and Prx0 is defined as:
def

DCD (Prx , Prx0 ) = ln max
ω

Prx (ω)
Prx (ω)
− ln min
ω Prx0 (ω)
Prx0 (ω)

where ω is taken to range over the joint probabilities
of the variables in the network. The Kullback-Leibler
measure [13], denoted by DKL , is defined as:
def

DKL (Prx , Prx0 ) =

X

Prx (ω) ln

ω

Prx (ω)
Prx0 (ω)

Calculating either distance between two distributions
is intractable in general. It can be proven that calculating DCD is NP-complete and that calculating DKL
is PP-complete1 . The Euclidean distance is a convenient way to measure the amount of change needed in
x to go from Prx to Prx0 . This distance, denoted by
DE , is defined as:
s X
def
(xi − x0i )2
DE (x, x0 ) =
xi ∈x,x0i ∈x0

The Euclidean distance depends only on the parameters that are changed and can be calculated in O(| X |).

3

Complexity theory

In the remainder, we assume that the reader is familiar with basic concepts of computational complexity
theory, such as the classes P and NP, and completeness proofs. For a thorough introduction to these subjects we refer to textbooks like [10] and [16]. In addition to these basic concepts, we use the complexity class PP (Probabilistic Polynomial time). This
class contains languages L accepted in polynomial time
by a Probabilistic Turing Machine. Such a machine
augments the more traditional non-deterministic Turing Machine with a probability distribution associated
1
These results are not yet published but will be substantiated in a forthcoming paper.

with each state transition, e.g. by providing the machine with a tape, randomly filled with symbols [11]. If
all choice points are binary and the probability of each
transition is 21 , then the majority of the computation
paths accept a string s if and only if s ∈ L.
A typical problem in PP (in fact PP-complete) is the
Inference problem [15, 18]: given a network B, a
variable V1 in V, and a rational number 0 ≤ q ≤ 1,
determine whetherQPr(V1 = v1 ) ≥ q. Recall that
n
Pr(V1 , . . . , Vn ) = i=1 Pr(Vi | π(Vi )). To determine
whether Pr(v1 ) ≥ q, we sum over all marginal probabilities Pr(V1 , . . . , Vn ) that are consistent with v1 . This
can be done using a Probabilistic Turing Machine in
polynomial time. The machine calculates the multiplication of conditional probabilities Pr(Vi | π(Vi )),
i = 1, . . . , n, choosing a computation path in which
each variable Vi is assigned a value according to the
conditional probability Pr(Vi | π(Vi )). Each computation path corresponds to a specific joint value assignment, and the probability of arriving in a particular
state corresponds with the probability of that assignment. At the end of this computation path, we accept
with probability 21 + ( 1q − 1), if the joint value assignment to V1 , . . . , Vn is consistent with v1 , and we accept
with probability ( 21 − ) if the joint value assignment
is not consistent with v1 . The majority of the computation paths (i.e., 12 + ) then arrives in an accepting
state if and only if Pr(v1 ) ≥ q.
Another concept from complexity theory that we will
use in this paper is oracle access. A Turing Machine
M has oracle access to languages in the class A, denoted as MA , if it can query the oracle in one state
transition, i.e., in O(1). We can regard the oracle as
a ‘black box’ that can answer membership queries in
constant time. For example, NPPP is defined as the
class of languages which are decidable in polynomial
time on a non-deterministic Turing Machine with access to an oracle deciding problems in PP. Informally,
computational problems related to probabilistic networks that are in NPPP typically combine some sort of
selecting with probabilistic inference.
Not all real numbers are exactly computable in finite
time. Since using real numbers may obscure the true
complexity of the problems under consideration, we assume that all parameter probabilities in our network
are rational numbers, thus ensuring that all calculated
probabilities are rational numbers as well. This is a realistic assumption, since the probabilities are normally
either assessed by domain experts or estimated by a
learning algorithm from data instances. For similar
reasons, we assume that ln(x) is approximated within
a finite precision, polynomial in the binary representation of x.

4

Problem definitions

In the previous sections, we have encountered a number of computational problems related to sensitivity
analysis and parameter tuning. To prove hardness results, we will first define decision problems related to
these questions. Because of the formulation in terms
of decision problems, all problems are in fact tuning
problems.
Parameter Tuning
Instance: Let B = (G, Γ) be a Bayesian network
where Γ is composed of rational probabilities, and let
Pr be its joint probability distribution. Let X ⊆ Γ be
a set of parameters in the network, let C denote the
output variable, and c a particular value of C.
Furthermore, let E denote a set of evidence variables
with joint value assignment e, and let 0 ≤ q ≤ 1.
Question: Is there a combination of values x for the
parameters in X such that Prx (c | e) ≥ q?
Parameter Tuning Range
Instance: As in Parameter Tuning.
Question: Are there combinations of values x and
x0 for the parameters in X such that
Prx (c | e) − Prx0 (c | e) ≥ q?
Evidence Parameter Tuning Range
Instance: As in Parameter Tuning; furthermore
let e1 and e2 denote two particular joint value
assignments to the set of evidence variables E.
Question: Is there a combination of values x for the
parameters in X such that
Prx (c | e1 ) − Prx (c | e2 ) ≥ q?
Minimal Parameter Tuning Range
Instance: As in Parameter Tuning; furthermore
let r ∈ Q+ .
Question: Are there combinations of values x and
x0 for the parameters in X such that DE (x, x0 ) ≤ r
and such that Prx (c | e) − Prx0 (c | e) ≥ q?
Minimal Change Parameter Tuning Range
Instance: As in Parameter Tuning; furthermore
let s ∈ Q+ , and let D denote a distance measure for
two joint probability distributions as reviewed in
Section 2 .
Question: Are there combinations of values x and
x0 for the parameters in X such that D(x, x0 ) ≤ s
and Prx (c | e) − Prx0 (c | e) ≥ q?
Mode Tuning
Instance: As in Parameter Tuning; furthermore
let >(Pr(C)) denote the mode of Pr(C).
Question: Are there combinations of values x and
x0 for the parameters in X such that
>(Prx (C | e)) 6= >(Prx0 (C | e))?

Furthermore, we define Evidence Mode Tuning,
Minimal Parameter Mode Tuning, and Minimal
Change Mode Tuning corresponding to the Parameter Tuning variants of these problems.

5

Completeness results

We will construct a hardness proof for the Parameter Tuning Range problem. Hardness of the other
problems can be derived with minimal changes to the
proof construction. More specifically, we prove NPPP hardness of the Parameter Tuning Range-problem
by a reduction from E-Majsat; this latter problem
has been proven complete by Wagner [21] for the class
NPPP . We will use a reduction technique, similar to
the technique used by Park and Darwiche [17] to prove
NPPP -hardness of the Partial Map-problem.
We first observe that all tuning problems from Section
4 are in NPPP : given x, x0 , q, r and s, we can verify all claims in polynomial time using a PP oracle,
since inference is PP-complete [18]. For example, with
the use of the oracle, we can verify in polynomial time
whether Prx (c | e) − Prx0 (c | e) ≥ q, for a given x, x0 ,
and q. Likewise, we can calculate the Euclidean distance of x and x0 in polynomial time and verify that it
is less than r. Determining whether a distance between
two joint probability distributions is smaller than s is
NP-complete (for the distance DCD defined by Chan
and Darwiche [3]) or PP-complete (for the distance
DKL defined by Kullback and Leibler [13]). Thus, we
can non-deterministically compute an assignment to
X and check (using a PP oracle) that the distance is
smaller than s. Therefore, all problems are in NPPP .
To prove hardness, we will reduce Parameter Tuning Range from E-Majsat, defined as follows:
E-Majsat
Instance: Let φ be a Boolean formula with n
variables Vi (1 ≤ 1 ≤ n), grouped into two disjoint
sets VE = V1 , . . . , Vk and VM = Vk+1 , . . . , Vn .
Question: Is there an instantiation to VE such that
for at least half of the instantiations to VM , φ is
satisfied?
We construct a probabilistic network Bφ from a given
Boolean formula φ with n variables Vi and instantiation templates VE and VM . For all variables Vi , in
the formula φ, we create a matching stochastic variable Vi in V for the network Bφ , with possible values true and false with uniform distribution. These
variables are roots in the network Bφ . We denote
Xi = Pr(Vi = true) as the parameter of Vi .
For each logical operator in φ, we create an additional
stochastic variable in the network, whose parents are

constructed as described above. Trivially, there exists a combination of parameter values x0 such that
Prx0 (C = true) = 0, namely all assignments in which
XS = 0. In that case, at least one of the parents
of C has the value false with probability 1 and thus
Prx0 (C = true) = 0.

C
∧

S
¬

¬

∨
V1

Vφ

V3
V2

VM

VE

Figure 1: Example of construction

the corresponding sub-formulas (or single variable in
case of a negation operator) and whose conditional
probability table is equal to the truth table of that
operator. For example, the ∧-operator would have a
conditional probability Pr(∧ = true) = 1 if and only
if both its parents have the value true, and 0 otherwise. We denote the stochastical variable that is
associated with the top-level operator in φ with Vφ .
Furthermore, we add a variable S with values true
and false, with uniform probability distribution where
XS = Pr(S = true) is the parameter of S. Lastly, we
have an output variable C, with parents S and Vφ and
values true and false, whose CPT is equal to the truth
table of the ∧-operator. The set of parameters X in
the Parameter Tuning Range problem now is defined to be {X1 , . . . , Xk } ∪ XS , i.e., the parameters of
the variables in VE and the parameter of S. We set
q = 21 .
Figure 1 shows the graphical structure of the probabilistic network constructed for the E-Majsat instance (φ, VE , VM ), where φ = ¬(V1 ∨ V2 ) ∧ ¬V3 ,
VE = {V1 , V2 }, and VM = {V3 }. Note that this EMajsat instance is satisfiable with V1 = V2 = F ; for
that instantiation to VE , at least half of the possible
instantiations to VM will satisfy the formula.
Theorem 1. Parameter Tuning Range is NPPP complete.
PP

Proof. Membership of NP can be proved as follows.
Given x0 and x, we can verify whether Prx (c | e) −
Prx0 (c | e) ≥ q in polynomial time, given an oracle that
decides Inference. Since Inference is PP-complete,
this proves membership of NPPP .
To prove hardness, we construct a transformation from
the E-Majsat problem. Let (φ, VE , VM ) be an instance of E-Majsat, and let Bφ be a probabilistic
network, with parameters x = {X1 , . . . , Xk } ∪ XS ,

On the other hand, if x includes XS = 1, then Prx (C =
true) depends on the values of X1 , . . . , Xk . More
in particular, there exist parameter values such that
Prx (C = true) ≥ 21 , if and only if (φ, VE , VM ) has a
solution. We can construct a solution x by assigning 1
to XS , 1 to all variables in {X1 , . . . , Xk } where the corresponding variable in VE is set to true, and 0 where
it is set to false. On the other hand, if (φ, VE , VM ) is
not satisfiable, then Prx (C = true) will be less than
1
2 for any parameter setting. Due to the nature of
the CPTs of the ‘operator’ variables which mimic the
truth tables of the operators, Prx (C = true) = 1 for
a value assignment to the parameters that is consistent with a satisfying truth assignment to φ. If there
does not exist a truth assignment to the variables in
VE such that the majority of the truth assignments to
the variables in VM satisfies φ, then there cannot be a
value assignment to X such that Prx (C = true) ≥ 12 .
Thus, if we can decide whether there exist two sets of
parameter settings x and x0 such that in this network
Bφ , Prx (C = true) − Prx0 (C = true) ≥ q, then we can
answer (φ, VE , VM ) as well. This reduces E-Majsat
to Tuning Parameter Range.
Note that the constructed proof shows, that the Parameter Tuning Range problem remains NPPP complete, even if we restrict the set of parameters to
constitute only prior probabilities, if all variables are
binary, if all nodes have indegree at most 2, if the output is a singleton variable, and if there is no evidence.
We will now show completeness proofs of the other
problems.
Corollary 2. All tuning problems defined in Section
4 are NPPP -complete.
Proof. We will show how the above construction can
be adjusted to prove hardness for these problems.
• Parameter Tuning: From the above construct, leave out the nodes S and C, such that
x = {X1 , . . . , Xk }. There is an instantiation x
such that Prx (Vφ = true) ≥ 12 , if and only if
(φ, VE , VM ) has a solution.
• Evidence Parameter Tuning Range: From
the above construct, replace S with a singleton
evidence variable E with values true and false
and uniform distribution; denote E = true as e1
and E = false as e2 and let x = {X1 , . . . , Xk }.

Prx (C = true | E = e2 ) = 0 for all possible parameter settings of x. On the other hand,
Prx (Vφ = true) ≥ 12 and thus Prx (C = true | E =
e1 ) ≥ 21 if and only if (φ, VE , VM ) has a solution.
• Minimal Parameter Tuning Range and
Minimal Change Parameter Tuning
Range: These problems have Tuning Parameter Range as a special case (set r, s = ∞) and
thus hardness follows by restriction.
• Mode Tuning: Since C has two values, Pr(C =
false) = 1 − Pr(C = true). In particular, >(C) =
true if Pr(C = true) ≥ 12 , and >(C) = false if
Pr(C = false) ≥ 21 . If XS = 0 then >(C) = false.
Pr(C = true) ≥ 21 , if and only if >(C) = true.
Evidence Mode Tuning, Minimal Parameter
Mode Tuning, and Minimal Change Mode Tuning: Apply similar construct modifications as with the
corresponding Parameter Tuning problems.

6

Restricted problem variants

In the previous section, we have shown that in the
general case, Parameter Tuning Range is NPPP complete. In this section, the complexity of the problem is studied for restricted classes of instances. More
in particular, we will discuss tuning problems in networks with bounded topologies and tuning problems
with a bounded number of CPTs containing parameters to be tuned.
6.1

S0

V1

V2

Vn

VS

S1

S2

Sn

C

Figure 2: Construction with polytrees

probability distribution. We denote the parameter of
Vi as Xi as in the previous construct. We define a
clause selector variable S0 with values c1 , . . . , cm and
1
uniform probability, i.e. Pr(S0 = ci ) = m
. Furthermore, we define clause satisfaction variables Si , with
values c0 , . . . , cm , associated with each variable. Every variable Si has Vi and Si−1 as parents. Lastly, we
define a variable VS , with values true and false, with
uniform probability distribution, and parameter XS ,
and a variable C with values true and false, parents
XS and Sn . See Figure 2 for the topology of this network. The CPT for Si (i ≥ 1) and C is given in Table 1.
In this table, T (Vi , j) and F (Vi , j) are Boolean predicates that evaluate to 1 if the truth assignment to Vi
satisfies, respectively does not satisfy, the j-th clause.

Si−1
c0
cj

Pr(Si | Vi , Si−1 )
Si = c0
Si 6= c0
1
0
T (Vi , j) F (Vi , j)

Pr(C = T | VS , Sn )
Sn xS
¬xS
c0
1
0
cj
1
1

Table 1: CPT for Pr(Si | Vi , Si−1 ) and Pr(C | Sn , VS )

Bounded topologies

In this section we will show that restrictions on the
topology of the network alone will not suffice to make
the problem tractable. In fact, Parameter Tuning
Range remains hard, even if B is a polytree. Similar
results can be derived for the other problems. To prove
NP-completeness of Parameter Tuning Range on
polytrees, we reduce Maxsat to Parameter Tuning
Range on polytrees, using a slightly modified proof
from [17]. The (unweighted) Maxsat problem is defined as follows:
Maxsat
Instance: Let φ be a Boolean formula in CNF
format, let Cφ = C1 . . . Cm denote its clauses and
Vφ = V1 . . . Vn its variables, and let 1 ≤ k ≤ m.
Question: Is there an assignment to the variables in
φ, such that at least k clauses are satisfied?
We will construct a polytree network B as follows. For
each variable in the formula, we create a variable in
the network with values true and false, with uniform

Theorem 3. Parameter Tuning Range remains
NP-complete if B is restricted to polytrees.

Proof. Membership of NP is immediate, since we can
decide Inference in polynomial time on polytrees.
Given x0 and x, we can thus verify whether Prx0 (C =
c) − Prx (C = c) ≥ q in polynomial time.
To prove NP-hardness, we reduce Maxsat to Parameter Tuning Range. Let (φ, k) be an instance of
Maxsat. From the clauses Cφ and variables Vφ , we
construct Bφ as discussed above. Similarly as in the
previous proof, if XS = 0 then Pr(C = true) = 0
for any instantiation to the parameters X1 to Xn . If
XS = 1 then we observe the following. For every instantiation cj to S0 , the probability distribution of Si
is as follows. Pr(Si = c0 | Vi ) = 1 if the instantiation to V1 . . . Vi satisfies clause cj , and 0 otherwise.
Pr(Si = cj | Vi ) = 1 if this instantiation does not satisfy clause cj .

Pr(Si | xi ) =


Si = c0 , V1...i satisfies cj


 Si = cj , V1...i satisfies cj

Si = c0 , V1...i does not satisfy cj



 Si = cj , V1...i does not satisfy cj
otherwise

1
0
0
1
0

Of course, Pr(Si ) is conditioned on Vi and thus depends on Xi . For Xi = 0 or Xi = 1, either Pr(Si =
c0 ) = 1 or Pr(Si = cj ) = 1, for intermediate values of
Xi the probability mass is shared between Pr(Si = c0 )
and Pr(Si = cj ). But then Pr(Sn = c0 ) is 1 for a particular clause selection cj in S0 , if and only if the parameter setting to X1 to Xn satisfies that clause. Due
to the conditional probability table of C and XS = 1,
Prx (C = true) = 1 if and only if the parameter setting x satisfies that clause. Summing over S0 yields
Prx (C = true) = nk , where k is the number of clauses
that is satisfied by x. Thus, a Parameter Tuning
Range query with values 0 and nk would solve the
Maxsat problem. This proves NP-hardness of Parameter Tuning Range on polytrees.
6.2

Bounded number of CPTs

In the previous section we have shown that a restriction on the topology of the network in itself does not
suffice to make parameter tuning tractable. In this section we will show that bounding the number of CPTs
containing parameters in X in itself is not sufficient
either. Note that trivial solutions to the Parameter
Tuning may exist for particular subsets X of the set
of parameter probabilities Γ. For example, if X constitutes all conditional probabilities Pr(C = c | π(C)), for
all configurations of parents of C, then a trivial solution would set all these parameters to q. If the number
of parameters in X is logarithmic in the total number
of parameter probabilities, i.e., | X |≤ p(log | Γ |) for
any polynomial p, then the problem is in PPP , since we
can try all combinations of parameter settings to 0 or
1 in polynomial time, using a PP-oracle.
If both the number of CPTs containing one or more
parameters in the set X is bounded by a factor k (independent of the number of total number of parameter probabilities), and the indegree of the corresponding nodes is bounded, then Parameter Tuning is
PP-complete. Hardness follows immediately since Parameter Tuning has Inference as a trivial special
case (for zero parameters). We will prove membership of PP for this problem for a single parameter in
a root node and show that the result also holds for a
k-bounded number of CPTs with m parents. Similar
observations can be made for the other tuning problems defined in Section 4.
Theorem 4. Parameter Tuning is PP-complete if
the number of CPTs containing parameters and the
indegree of the corresponding nodes are bounded.

Proof. First let us assume k = 1, i.e., all n parameters are taken from the CPT of a single node V .
Furthermore, let us assume for now that V is a root
node. To solve Parameter Tuning, we need to decide whether Pr(C = c) ≥ q for a particular combination of values of
Pthe parameters in X. Conditioning
on V gives
us
i Pr(C = c | V = vi ) · Pr(V = vi ).
P
Since
Pr(V
=
vi ) = 1, Pr(C = c) is maximal
i
for Pr(V = vi ) = 1 for a particular vi . Thus, if we
want to decide whether Pr(C = c) ≥ q for a particular combination of values of the parameters, then it
suffices to determine whether this is the case when we
set Pr(V = vi ) = 1 for a particular parameter vi .2
Using this observation, we will construct a Probabilistic Turing Machine M by combining several machines
accepting Inference instances. At its first branching step, M either accepts with probability 12 , or
1
runs, with probability 2n
, one of n Probabilistic Turing Machines Mi (i = 1, . . . , n), which on input Bφ,i
(with Pr(V = vi ) = 1) and q accept if and only if
Pr(C = c) = q. If any Mi accepts, then M accepts.
The majority of computation paths of M accepts if
and only if the Parameter Tuning instance is satisfiable. If V is not a root node, then we must branch
over each parent configuration. For k CPTs with at
most n parameters in each CPT and m incoming arcs,
we need to construct a combined Probabilistic Turk
ing Machine consisting of O(nm ) Probabilistic Turing Machines accepting instances of Inference. For
bounded m and k, this is a polynomial number of machines and thus computation takes polynomial time.
Thus, Parameter Tuning is in PP for a bounded
number of CPTs containing parameters and a bounded
indegree of the corresponding nodes m and k.

7

Conclusion

In this paper, we have addressed the computational
complexity of several variants of parameter tuning.
Existing algorithms for sensitivity analysis and parameter tuning (see e.g. [2]) have a running time, exponential in both the treewidth of the graph and in the
number of parameters varied. We have shown that parameter tuning is indeed hard, even if the network has
a restricted polytree and if the number of parameters is
bounded. We conclude, that Parameter Tuning is
tractable only if both constraints are met, i.e., if probabilistic inference is easy and the number of parameters
involved is bounded.
2
If the number of parameters subject to tuning does not
constitute all parameter probabilities in the CPT, then we
need to test whether Pr(C = c) ≥ q when all parameters
have the value 0 as well.

Acknowledgments
This research has been (partly) supported by the
Netherlands Organisation for Scientific Research
(NWO). The authors wish to thank Hans Bodlaender
and Gerard Tel for their insightful comments on earlier
drafts of this paper. We wish to thank the anonymous
reviewers for their thoughtful remarks.



We present a method for learning the parameters of a Bayesian network with prior knowledge
about the signs of influences between variables.
Our method accommodates not just the standard
signs, but provides for context-specific signs as
well. We show how the various signs translate
into order constraints on the network parameters
and how isotonic regression can be used to compute order-constrained estimates from the available data. Our experimental results show that
taking prior knowledge about the signs of influences into account leads to an improved fit of the
true distribution, especially when only a small
sample of data is available. Moreover, the computed estimates are guaranteed to be consistent
with the specified signs, thereby resulting in a
network that is more likely to be accepted by experts in its domain of application.

1

INTRODUCTION

For constructing a Bayesian network, often knowledge is
acquired from experts in its domain of application. Experience shows that domain experts can quite easily and reliably specify the graphical structure of a network [7], yet
tend to have more problems in coming up with the probabilities for its numerical part [8]. If data from every-day
problem solving in the domain is available therefore, one
would like to use these data for estimating the probabilities that are required for the graphical structure to arrive
at a fully specified network. For many applications, unfortunately, the available data sample is quite small, giving
rise to inaccurate estimates. The inaccuracies involved may
then lead to a reasoning behaviour of the resulting network
that violates common domain knowledge and the network
will not easily be accepted by experts in the domain.
While domain experts often are found to have difficulties in coming up with probability assessments, evidence

is building up that they feel more comfortable with providing qualitative knowledge about the probabilistic influences between the variables concerned [7, 11]. The qualitative knowledge provided by the domain experts, moreover,
tends to be more robust than their numerical assessments.
We demonstrated before that expert knowledge about the
signs of influences between the variables in a Bayesian network can be used to improve the probability estimates obtained from small data samples [9]. We now extend our
previous work to accommodate the wider range of contextspecific signs, and context-specific independences more
specifically. We argue that these signs impose order constraints on the probabilities required for the network. We
then show that the problem of estimating probabilities under these order constraints is a special case of isotonic regression. Building upon this property, we present an estimator that is guaranteed to produce probability estimates
that reflect the qualitative knowledge specified by the experts. The resulting network as a consequence is less likely
to exhibit counterintuitive reasoning behaviour and is more
likely to be accepted than a network with unconstrained estimates.
The paper is organised as follows. In the next section, we
briefly review qualitative influences. In section 3, we discuss isotonic regression and provide an algorithm for its
computation. We then show in section 4, that the problem of learning constrained network parameters is a special case of isotonic regression; we also discuss how the
different constraints that result from qualitative influences
are handled, and how the order constraints can be used in
a Bayesian context. In section 5, we report on experiments
that we performed on a small artificial Bayesian network
and on a real-life network in the medical domain. Finally,
we draw a number of conclusions from our work and indicate interesting directions for further research.

2

QUALITATIVE INFLUENCES

From a qualitative perspective, the variables in a Bayesian
network may be related in different ways. In the sequel

we assume all variables of the network to be binary. Let
X = (X1 , . . . , Xk ) be the parents of a variable Y , and
let Ω(X) = Ω(X1 ) × Ω(X2 ) × . . . × Ω(Xk ) = {0, 1}k
consist of vectors x = (x1 , x2 , . . . , xk ) of values for the k
variables in X, that is, Ω(X) is the set of all parent configurations of Y . Slightly abusing terminology, we sometimes
say that Xi occurs or is present if it has the value one. We
write Xa for the sub-vector of X containing the variables
Xj for j ∈ a, where a is a subset of K = {1, . . . , k}. We
further write X−a for XK\a .
A qualitative influence [14] between two variables expresses how observing a value for the one variable affects
the probability distribution for the other variable. A positive influence of Xi on Y along an arc Xi → Y means that
the occurrence of Xi increases the probability that Y occurs, regardless of any other direct influences on Y , that is,
for all x, x0 ∈ Ω(X) with xi = 1, x0i = 0 and x−i = x0−i ,
we have p(y = 1|x) ≥ p(y = 1|x0 ). Similarly, there is
a negative influence of Xi on Y along an arc Xi → Y if
the occurrence of Xi decreases the probability that Y occurs, that is, for all x, x0 ∈ Ω(X) with xi = 1, x0i = 0 and
x−i = x0−i , we have p(y = 1|x) ≤ p(y = 1|x0 ). A pos+

itive influence of Xi on Y is denoted by Xi −→ Y and a
−
negative influence by Xi −→ Y . An influence with either
a positive or negative sign is called a signed influence. If
no sign is specified, we call the influence unsigned.
The idea of signs of influences is readily extended to include context-specific signs [12]. A positive influence of
Xi on Y within the context XC = c, C ⊆ {1, . . . , k} \ i,
means that whenever XC = c, the occurrence of Xi increases the probability that Y occurs, that is, for all x, x0 ∈
Ω(X) with xC = x0C = c, xi = 1, x0i = 0 and x−C∪{i} =
x0−C∪{i} , we have p(y = 1|x) ≥ p(y = 1|x0 ). A contextspecific negative influence is defined analogously. A zero
influence of Xi on Y within the context XC = c models
a local context-specific independence (cf. [2]), that is, for
all x, x0 ∈ Ω(X) with xC = x0C = c, xi = 1, x0i = 0 and
x−C∪{i} = x0−C∪{i} , we have p(y = 1|x) = p(y = 1|x0 ).
A signed context-specific influence of Xi on Y along an
s
arc Xi → Y is denoted by Xi −→ Y [XC = c], with
s ∈ {+, −, 0}. Note that ordinary signed influences are
special cases of context-specific influences with C = ∅.
Further note that a signed influence in essence specifies a
constraint on the parameters associated with a variable.
We assume, throughout the paper, that a domain expert provides the signs of the qualitative influences between the
variables in a network. We would like to mention that
for real-life applications these signs are quite readily obtained from experts by using a special-purpose elicitation
technique tailored to the acquisition of signs of qualitative
influences [11].

3

ISOTONIC REGRESSION

Our approach to obtaining parameter estimates for a
Bayesian network that satisfy the signs of the influences
specified by experts, is a special case of isotonic regression [13]. In this section we review isotonic regression in
general; in the next section we discuss its application to
parameter estimation for Bayesian networks.
Let Z = {z1 , z2 , . . . , zn } be a nonempty finite set of constants and let  be a quasi-order on Z, that is:
1. for all z ∈ Z: z  z (reflexivity), and
2. for all x, y, z ∈ Z : x  y, y  z ⇒ x  z
(transitivity).
Any real-valued function f on Z is isotonic with respect to
 if, for any z, z 0 ∈ Z, z  z 0 implies f (z) ≤ f (z 0 ). We
assume that each element zi of Z is associated with a real
number g(zi ); these real numbers typically are estimates of
the function values of an unknown isotonic function on Z.
Furthermore, each element of Z has associated a positive
weight w(zi ) that typically indicates the precision of this
estimate. An isotonic function g ∗ on Z now is an isotonic
regression of g with respect to the weight function w and
the order  if and only if it minimizes the sum
n
X

w(zi ) [f (zi ) − g(zi )]2

i=1

within the class of isotonic functions f on Z. The existence
of a unique g ∗ has been proven by Brunk [5].
Isotonic regression provides a solution to many statistical
estimation problems in which we have prior knowledge
about the order of the parameters to be estimated. For example, suppose that we want to estimate binomial parameters
p = (p(z1 ), p(z2 ), . . . , p(zn ))
where p(zi ) denotes the probability of success in population zi . Let ni denote the number of observations
sampled from population zi , and let the number of successes Yi in this sample be binomially distributed with
Yi ∼ B(ni , p(zi )). Then the isotonic regression of the
estimates Ȳi = Yi /ni with weights w(zi ) = ni provides
the maximum-likelihood estimate of p given that p is isotonic on (Z, ). Note that this example suggests that the
order-constrained estimates are obtained by first computing the unconstrained estimates and then performing the
isotonic regression of these basic estimates with appropriate weights.
Isotonic regression problems can be solved by quadratic
programming methods. Various dedicated algorithms, often restricted to a particular type of order, have been proposed as well. For Z linearly ordered, for example, the pool

adjacent violators (PAV) algorithm is well-known. For our
application, however, we require an algorithm that is applicable to sets of constants with arbitrary quasi-orders. For
this purpose we will use the minimum lower sets (MLS) algorithm proposed by Brunk [3]. The MLS algorithm builds
upon the concept of a lower set. A subset L of Z is a lower
set of Z if z ∈ L, z 0 ∈ Z, and z 0  z imply z 0 ∈ L.
The weighted average of a function g on Z for a nonempty
subset A is defined as
P
z∈A w(z)g(z)
Av(A) = P
z∈A w(z)
The algorithm now takes for its input the set of constants
Z = {z1 , z2 , . . . , zn } with quasi-order . With each
zi ∈ Z again is associated a weight w(zi ) and a real number g(zi ). The algorithm returns the isotonic regression g ∗
of g with respect to w and . The MLS algorithm resolves
violations of the order constraints by averaging over suitably chosen subsets of Z. For the final solution, it partitions the set Z into a number of subsets on which the isotonic regression is constant. The first subset B1 in the final
solution is a lower set of (Z, ). The second subset is a
lower set of (Z \ B1 , 2 ), where 2 is obtained from  by
removing all order relations involving elements of B1 . This
process is continued until Z is exhausted. In each iteration
the lower set with minimum weighted average is selected;
in case multiple lower sets attain the same minimum, their
union is taken.
MinimumLowerSets(Z, , g(z), w(z))
L = Collection of all lower sets of Z wrt 
Repeat S
B = {A ∈ L | Av(A) = minL∈L Av(L)}
For each z ∈ B do
g ∗ (z) = Av(B)
For each L ∈ L do
L=L\B
Z =Z \B
Until Z = ∅
Return g ∗

The bottleneck of the algorithm from a computational point
of view clearly is the generation of the lower sets, which is
exponential in the size of the set of constants. We return to
this observation in section 4.2.

4

PARAMETER LEARNING

In this section we address the maximum-likelihood estimation of parameters for a Bayesian network subject to the
constraints imposed by the signs of influences, and show
that it can be viewed as a special case of isotonic regression. We note that in the presence of signs, the parameters associated with the different parent configurations of
a variable are no longer unrelated. Only those combinations of parameter values that are isotonic with respect to

the quasi-order imposed by the specified signs, are feasible.
The parameters associated with different variables are still
unrelated however, because a sign imposes constraints on
the parameters for a single variable only. We restrict our attention therefore to the parameters associated with a single
variable.
4.1

ISOTONIC REGRESSION FORMULATION

To cast our problem of constrained parameter estimation
into the isotonic regression framework, we proceed as follows. For parents X of Y , we construct an order  on
Ω(X) in such a way that  corresponds to the order ≤ on
the parameters p(y = 1|x), x ∈ Ω(X), that is implied by
the specified signs. More specifically, for any qualitative
s
influence Xi −→ Y [XC = c], s ∈ {+, −, 0}, we impose
the following order on Ω(X): for all x, x0 ∈ Ω(X) with
xC = x0C = c, xi = 1, x0i = 0 and x−C∪{i} = x0−C∪{i} :
• if s = + then x0  x, since the positive sign implies
p(y = 1|x0 ) ≤ p(y = 1|x);
• if s = − then x  x0 , since the negative sign implies
p(y = 1|x) ≤ p(y = 1|x0 );
• if s = 0 then x  x0 and x0  x, since the zero
enforces the equality p(y = 1|x0 ) = p(y = 1|x).
The other ordering statements follow from the transitivity
and reflexivity properties of quasi-orders. The specified influences constrain the parameters p(y = 1|x) to be nondecreasing on (Ω(X), ).
Now suppose that we have available a data set D from
which we would like to estimate the parameters p(y =
1|x). The unconstrained maximum-likelihood estimate of
p(y = 1|x) is given by
p̂(y = 1|x) =

n(y = 1, x)
n(x)

where n(y = 1, x) denotes the number of observations in
D with y = 1 and X = x.
The following observation now links isotonic regression to
the problem currently considered: the isotonic regression
p∗ (y = 1|x) of p̂(y = 1|x) with weights w(x) = n(x)
provides the maximum-likelihood estimate of p(y = 1|x),
for all x ∈ Ω(X), subject to the constraint that these estimates must be non-decreasing on (Ω(X), ) ([4], see also
[13] page 32).
To illustrate the above observation, we consider a fragment
of a Bayesian network. Let X = (X1 , X2 , X3 ) be the parents of a variable Y , with qualitative influences on Y as
shown in figure 1. The fragment expresses the prior knowledge that X1 has a positive influence on Y and that, if X1
is absent, X3 has a negative influence on Y ; it further models that if X1 is present and X2 is absent, then X3 has no

thermore, the estimates in the second row should be equal,
due to the context-specific independence specified. Clearly,
this constraint is violated as well. Finally, the estimates
should be non-increasing in the first row, due to the contextspecific negative influence of X3 . This constraint is satisfied.

Figure 1: An example network fragment

influence on Y . The network does not specify any prior
knowledge about the sign of the influence of X2 on Y .
Figure 2 shows the quasi-order on the parent configurations
that is imposed by the specified influences, where an arrow
from x to x0 indicates that x immediately precedes x0 in the
order. Because no influence of X2 on Y has been specified,
the parent configurations that have a different value for X2
are incomparable. As a consequence, the order consists of
two components, one for X2 = 0 and one for X2 = 1. Estimates may be computed for the two components separately,
because there are no order constraints between parent configurations contained in different components. Also note
that the component for X2 = 0, depicted in the left part of
figure 2, contains a cycle as a result of the context-specific
independence specified for X3 . Because of the independence the constraint p∗ (y = 1|1, 0, 0) = p∗ (y = 1|1, 0, 1)
must be satisfied. This is modelled by considering the two
parent configurations (1, 0, 0) and (1, 0, 1) as a single element in the ordering, as shown in figure 3.
(0,0,1)
(0,0,0)

(0,1,1)
(1,0,1)

(0,1,0)

(1,0,0)

(1,1,1)
(1,1,0)

Figure 2: Order corresponding to the network fragment

(0,0,1)
(0,0,0)

(0,1,1)
(1,0,*)

(0,1,0)

Figure 3: Updated order for X2 = 0

(1,1,0)

Table 1 shows for each parent configuration with X2 = 0
the counts obtained from a given sample, as well as the associated maximum-likelihood estimates p̂(y = 1|x). We
note that the estimates should be non-decreasing in both
columns of the table, due to the positive influence of X1
on Y . This constraint is violated in the first column. Fur-

The MLS algorithm resolves the identified constraint violations by averaging the unconstrained estimates p̂(y = 1|x)
over conflicting cells from the table. It starts with the computation of the weighted average of p̂(y = 1|x) for all
lower sets of Ω(X); table 2 shows the resulting averages.
The minimum average is achieved by {(0, 0, 1)}, so the
algorithm sets p∗ (y = 1|0, 0, 1) = 1/5. This element
is removed from all lower sets, and their weighted averages are recomputed. Now {(0, 0, 0)} has the minimum
weighted average, and we get p∗ (y = 1|0, 0, 0) = 4/10.
The element (0, 0, 0) is removed from all lower sets, and
{(1, 0, 0), (1, 0, 1)} is the only remaining lower set. Its
weighted average is 10/23, so the algorithm sets p∗ (y =
1|1, 0, 0) = p∗ (y = 1|1, 0, 1) = 10/23. Now the component of the order with X2 = 0 has been solved. Note that
the two constraint violations have been resolved simultaneously by averaging the pair of violators p̂(y = 1|1, 0, 0)
and p̂(y = 1|1, 0, 1).
Next we consider the parent configurations with X2 = 1.
Table 3 shows for each such parent configuration the counts
obtained from the available sample, and the associated
maximum-likelihood estimates p̂(y = 1|x). Note that there
are no observations in the sample with the parent configuration (0, 1, 1). In such cases we put p̂(y = 1|x) = 0.5 and
give the cell an arbitrary small weight. As a consequence
the estimate will the be dominated by other parameter estimates as soon as it is pooled to resolve conflicts.
From the specified signs, we have that the estimates should
be non-decreasing within each column, and non-increasing
in the first row. The row constraint is satisfied, but the
column constraints are not. Table 4 gives all lower sets
with X2 = 1, and their weighted averages. The set
{(0, 1, 1), (1, 1, 1)} achieves the minimum and the MLS
algorithm sets p∗ (y = 1|0, 1, 1) = p∗ (y = 1|1, 1, 1) =
0.4. Note that the constrained estimate for the empty cell
(0, 1, 1) has simply been set equal to the estimate for the
conflicting cell (1, 1, 1). The elements (0, 1, 1) and (1, 1, 1)
are removed from all lower sets, and the weighted averages
(1,1,1)
are recomputed. Now the minimum weighted average of
12/25 = 0.48 is achieved by {(0, 1, 0), (1, 1, 0)}, so we
get p∗ (y = 1|0, 1, 0) = p∗ (y = 1|1, 1, 0) = 0.48. In this
step the violation of the order constraint in the first column
is resolved by averaging the parameter estimates for the two
conflicting cells. Note that the constrained joint estimate is
closer to the unconstrained estimate for cell (0, 1, 0) than
to the unconstrained estimate for cell (1, 1, 0) because we
have more observations in the former than in the latter and
the former thus has a larger associated weight.

Table 1: Counts and ML estimates for X2 = 0
X2 = 0
X1 = 0
X1 = 1

X3 = 0
4/10 = 0.4
6/18 = 0.33

X3 = 1
1/5 = 0.2
4/5 = 0.8

Table 2: The weighted average of the lower sets for X2 = 0
Lower set
{(0, 0, 1)}
{(0, 0, 1), (0, 0, 0)}
{(0, 0, 1), (0, 0, 0), (1, 0, 0), (1, 0, 1)}

Weighted average
1
2
3
1/5
−
−
5/15
4/10
−
15/38 14/33 10/23

We would also like to note that, although the algorithm
computes p∗ (y = 1|0, 1, 1) = 0.4 for the empty cell
(0, 1, 1), any value in the interval [0, 0.4] would actually
have satisfied the constraints. An alternative to the proposed procedure would be to remove the empty cells before
application of the MLS algorithm, and after the estimates
for the other cells have been computed, determine feasible
estimates for the empty cells.
Since Ω(X) is exhausted after this step, the algorithm halts.
We observe that the resulting parameter estimates indeed
satisfy the constraints imposed by the qualitative influences. Also note that the parameters that have not been involved in any constraint violations have retained their original estimates.
4.2

COMPLEXITY OF THE MLS ALGORITHM

We argued in section 3 that the number of lower sets is
the dominant factor in the runtime complexity of the minimum lower sets algorithm. To determine this number, we
start with the simple case where all k parents of a variable
have a context-independent signed influence. Without loss
of generality, we assume all signs to be positive. Since all
parents are binary, any parent configuration from Ω(X) is
uniquely determined by the parents that have the value 1, or
alternatively, by a subset of {1, 2, . . . , k}. The partial order
on Ω(X) is therefore isomorphic to the partial order generated by set inclusion on P({1, 2, . . . , k}). Every lower
set now corresponds uniquely to an antichain in this partial order. Hence, the number of distinct lower sets equals
the number of distinct nonempty antichains of subsets of a
k-set, which adheres to the well-known Sloane sequence

Table 3: Counts and ML estimates for X2 = 1
X2 = 1
X1 = 0
X1 = 1

X3 = 0
10/20 = 0.5
2/5 = 0.4

X3 = 1
0/0 = 0.5
4/10 = 0.4

Table 4: The weighted average of the lower sets for X2 = 1
Lower set
{(0, 1, 1)}
{(0, 1, 1), (0, 1, 0)}
{(0, 1, 1), (1, 1, 1)}
{(0, 1, 1), (0, 1, 0), (1, 1, 0)}
{(0, 1, 1), (0, 1, 0), (1, 1, 1)}
{(0, 1, 1), (0, 1, 0), (1, 1, 0), (1, 1, 1)}

Weighted average
1
2
0.5
−
10/20
10/20
4/10
−
12/25
12/25
14/30
−
16/35
−

A014466. Writing |L(k)| for the number of lower sets
for k parents as above, we thus find that |L(5)| = 7580,
|L(6)| = 7828353, and |L(7)| = 2414682040997. We
conclude that the MLS algorithm is feasible for up to five
or six parents with signed influences only.
From our example network fragment, we noted that unsigned influences serve to partition the set of parent configurations Ω(X) into disjoint subsets, such that no element
of the one subset is order related to any element of the
other subsets. We argued that constrained estimates may be
computed for these subsets separately, thereby effectively
decomposing the parameter learning problem into a number of independent smaller problems. This decomposition
yields a considerable improvement of the efficiency of the
computations involved. In general, let k1 denote the number of parents with a signed influence and let k2 denote the
number of parents with an unsigned influence. The number
of configurations for the parents with an unsigned influence
equals 2k2 . The order graph thus consists of 2k2 components. The number of lower sets of the entire order is given
by
k2
|L(k1 + k2 )| = (|L(k1 )| + 1)2 − 1
This number grows very rapidly. For k1 = 4 and k2 =
3, for example, the algorithm would need to compute the
weighted average of 1688 −1 = 6.35×1017 lower sets. By
treating each component in the order as a separate problem,
the algorithm initially has to compute the weighted average
of
|L(k1 + k2 )| = 2k2 |L(k1 )|
lower sets. For k1 = 4 and k2 = 3, this amounts to just
8 · 167 = 1336 lower sets.
In the presence of context-specific signs, the analysis of
the algorithm’s runtime complexity becomes more complicated. We restrict ourselves to the following observations.
First, the absence of signs in particular contexts can also
lead to a decomposition of the order, and hence to a similar reduction of the computations involved as in the case
of unsigned influences. On the other hand, the absence of
signs in particular contexts can also lead to an increase of
the number of lower sets. Secondly, context-specific independences lead to a reduction of the number of elements
in the ordering, that is of the number of parameters to be
estimated, and hence to a reduction of the number of lower

sets.
4.3

MC

The parameter learning method described in the previous
sections does not require that an expert specifies numerical values for the parameters concerned. The expert only
has to provide signs for the various influences. Should uncertain prior knowledge about the numeric values of the
parameters be available in addition to knowledge about
the signs of influences, then we can accommodate this information. Suppose that the expert is willing to specify
a Beta prior for the parameters p(y = 1|x), x ∈ Ω(x).
We assume that he chooses the hyperparameters a(x) and
b(x) such that his experience is equivalent to having seen
the value y = 1 a total of a(x) − 1 times in h(x) =
a(x) + b(x) − 2 trials; h is called the prior precision.
Let p0 (y = 1|x) denote the modal value of p(y = 1|x),
that is, p0 (y = 1|x) is a priori considered the most likely
value of p(y = 1|x). We now further assume that the expert’s values for a(x) and b(x) are such that the modes
p0 (y = 1|x) = (a(x) − 1)/h(x), x ∈ Ω(X), are isotonic
with respect to the order imposed by the signs he specified.
In forming the joint prior for p(y = 1|x), x ∈ Ω(x), we assume local parameter independence (cf. [10]), except that
the parameter values must be isotonic. This means that the
prior density is 0 for non-isotonic value combinations for
the parameters, and proportional to the product Beta distribution for isotonic value combinations. The isotonic MAP
estimates then are given by the isotonic regression of
p0 (y = 1|x, D) =

n(x)p̂(y = 1|x) + h(x)p0 (y = 1|x)
n(x) + h(x)

with weights n(x) + h(x) (see [1]).
As before order-constrained estimation now amounts to
performing isotonic regression on basic estimates with appropriately chosen weights. The basic estimates are the unconstrained MAP estimates p0 (y = 1|x, D) for the parameters. The weight is n(x) + h(x), that is the sum of the
number of actual observations for parent configuration x
and the prior precision h(x) specified by the expert. Note
that in case of a flat prior (Beta(1,1); h = 0), the orderconstrained maximum likelihood estimates are returned.

5

+

BAYESIAN ESTIMATION

EXPERIMENTAL RESULTS

To study the behaviour of the isotonic estimator in a slightly
more involved setting, we compare it to the standard
maximum-likelihood estimator on the well-known Brain
Tumour network [6]; the network and the signs of the influences are depicted in figure 4. For the network, we specified probabilities consistent with the constraints to generate
data samples for our experiments. Note that, even though
the true distribution satisfies the constraints, this need not

SH

+
+

CT

+
ISC

B
ISC = 0: +
ISC = 1: 0

B = 0: +
B = 1: 0
C

Figure 4: The Brain Tumour network

hold for the relative frequencies in the samples, especially
not for smaller sample sizes.
Our implementation first generates, for each variable, the
quasi-order on its parent configurations that corresponds
with the specified signs. For each order it finds the separate components; all parent configurations contained in the
same cycle are mapped to a single element and the order is
adjusted accordingly. For each component of the order, the
parameters for the parent configurations contained in that
component are estimated using the MLS algorithm.
We drew samples of various sizes from the network using
logic sampling; for each sample size, 100 data sets were
drawn. From each data set, both the standard maximumlikelihood estimates and the constrained estimates of the
network parameters were calculated. Given these parameter estimates, the joint distribution defined by the resulting
network was computed. This distribution then was compared to the true joint distribution defined by the original
network. For comparing the distributions, we used the
well-known Kullback-Leibler divergence. The KullbackLeibler divergence of Pr0 from Pr is defined as
KL(Pr, Pr0 ) =

X
x

Pr(x) log

Pr(x)
Pr0 (x)

where a term in the sum is taken to be 0 if Pr(x) = 0, and
infinity whenever Pr0 (x) = 0 and Pr(x) > 0.
c is used to
The results are summarized in table 5, where Pr
denote the joint distribution that was obtained with unconstrained maximum-likelihood estimation. To illustrate the
benefits of modeling context-specific independences, we
first estimated the various parameters without taking the
+
embedded zeroes into account, that is, we used B −→ C,
+
and ISC −→ C. The resulting distribution is denoted by
∗
Pr in the table. Finally, Pr∗∗ denotes the distribution that
was obtained with the isotone estimator using the embedded zeroes. The averages reported in the table were computed from those data sets for which the KL divergence
was smaller than infinity for the maximum-likelihood estimates: the isotone estimates always have KL divergence

Table 5:
n
20
30
40
50
150
500
1500

Experimental results: the Brain Tumour network
c
KL(Pr, Pr)
KL(Pr, Pr∗ ) KL(Pr, Pr∗∗ )
0.2149
0.1891
0.1814
0.1572
0.1401
0.1317
0.1442
0.1230
0.1149
0.1286
0.1162
0.1066
0.0481
0.0442
0.0400
0.0132
0.0123
0.0115
0.0043
0.0041
0.0036

smaller than infinity in these cases as well. The number
of data sets from which the averages were computed was
61, 97, 100, and 100 for sample sizes 50, 150, 500, and
1500, respectively. For sample sizes 20, 30, and 40, we
used Bayesian estimation with a Beta(2,2) prior for all parameters, that is, the prior mode of all parameters was set
to 0.5 with prior precision equal to 2. Note that by setting
all parameters to the same value we never violate any order
constraints. The unconstrained and isotonic MAP estimates
were used as point estimates for the parameters. We used
Bayesian estimation for the smallest sample sizes because
otherwise the KL divergence would almost always be equal
to infinity.
The results reveal that the isotonic estimator consistently
yields a better fit of the true distribution compared to the
unconstrained maximum-likelihood estimator, although the
differences are small. We note that for the smaller data
sets the differences are more marked than for the larger
data sets. This conforms to our expectations, since for
smaller data sets standard maximum-likelihood estimation
has a higher probability of yielding estimates that violate
the specified constraints. For larger data sets, the standard
estimator and the isotonic estimator are expected to often
result in the same estimates. Note that using the contextspecific independences gives an additional improvement of
fit, as was to be expected.
To conclude, we applied the isotonic estimator to a real-life
Bayesian network in the field of oncology. The O ESOCA
network provides for establishing the stage of a patient’s
oesophageal cancer, based upon the results of a number of
diagnostic tests. The network was constructed with the help
of gastroenterologists from the Netherlands Cancer Institute, Antoni van Leeuwenhoekhuis; the experts provided
the knowledge for the configuration of the network’s structure and also provided probability assessments for the network’s parameters. From the original O ESOCA network,
we constructed a binary network for our experiment, carefully building upon knowledge of the domain. The resulting network includes 40 variables with a total of 95 parameters. From values of the the various parameters, we established the signs for the qualitative influences between the
variables. The network includes 45 influences; figure 5 de-

Table 6: Experimental results: the O ESOCA network
c
n KL(Pr, Pr)
KL(Pr, Pr∗ )
50 0.5247
0.5044
100 0.2908
0.2774
150 0.2005
0.1919
500 0.0665
0.0640
1000 0.0342
0.0333
1500 0.0225
0.0219

picts the binary O ESOCA network. The signs of the qualitative influences are shown over the corresponding arcs; for
readibility, only the context-independent signs are shown,
where a question mark is used to denote an ambiguous influence.
c again
The experimental results are displayed in table 6: Pr
denotes the joint distribution resulting from the unconstrained MAP estimates, and Pr∗ the joint distribution resulting from the isotonic MAP estimates. The results are
in line with the results obtained for the brain tumour network: the isotonic estimator is consistently better, and the
difference becomes smaller as the sample size increases.

6

CONCLUSIONS

Taking prior knowledge about the signs of influences between variables into account upon estimating the parameters of a Bayesian network, results in an improved fit of the
true distribution. The improvement is relatively large for
small samples, since these are more likely to give rise to
maximum-likelihood estimates that violate the constraints.
Since the constrained parameter estimates are in accordance with prior knowledge specified by experts, the resulting network is more likely to be accepted in its domain
of application.
An interesting extension of our method would be to allow
for non-binary variables with linearly-ordered discrete values. A signed influence on such a variable is defined in
terms of a stochastic order on the distributions given the
different parent configurations. Learning the parameters of
a network subject to the resulting constraints in our opinion
merits further research.
Acknowledgement
The authors would like to thank Kim H. Liem for writing
part of the program code, and performing the experiments.




The currently most efficient algorithm for infer­
ence with a probabilistic network builds upon a
triangulation of a network's graph. In this paper,
we show that pre-processing can help in finding
good triangulations for probabilistic networks,
that is, triangulations with a minimal maximum
clique size. We provide a set of rules for step­
wise reducing a graph. The reduction allows us
to solve the triangulation problem on a smaller
graph. From the smaller graph's triangulation, a
triangulation of the original graph is obtained by
reversing the reduction steps. Our experimental
results show that the graphs of some well-known
real-life probabilistic networks can be triangu­
lated optimally just by pre-processing; for other
networks, huge reductions in size are obtained.

1

Introduction

The currently most efficient algorithm for inference with a
probabilistic network is the junction-tree propagation al­
gorithm that builds upon a triangulation of a network's
moralised graph [1, 2]. The running time of this algorithm
depends on the triangulation used. In general, it is hard to
find a triangulation for which this running time is minimal.
As there is a strong relationship between the running time
of the algorithm and the maximum of the triangulation's
clique sizes, for real-life networks triangulations are sought
for which this maximum is minimal. The minimum of the
maximum clique size over all triangulations of a graph is
a well-studied notion, both by researchers in the field of
probabilistic networks and by researchers in graph theory
and graph algorithms. In the latter field of research, the no­
tion of treewidth is used to denote this minimum minus one.
Unfortunately, computing the treewidth of a given graph is
an NP-complete problem [3].
When solving hard combinatorial problems, pre-process­
is often profitable. The basic idea is to reduce the size

ing

{frankvde,linda}®cs.uu.nl

of the problem under study, using relatively little compu­
tation time and without losing optimality. The smaller,
and presumably easier, problem is subsequently solved. In
this paper, we discuss pre-processing for triangulation of
probabilistic networks. We provide a set of rules for step­
wise reducing the problem of finding a triangulation for a
network's moralised graph with minimal maximum clique
size, to the same problem on a smaller graph. Various al­
gorithms can then be used to solve the smaller problem.
Given a triangulation of the smaller graph, a triangulation
of the original graph is obtained by reversing the reduction
steps. Our reduction rules are guaranteed not to destroy op­
timality with respect to maximum clique size. Experiments
with pre-processing revealed that our rules can effectively
reduce the problem size for various real-life probabilistic
networks. In fact, the graphs of some well-known networks
are triangulated optimally just by pre-processing.
In this paper, we do not address the second phase in the pre­
processing approach outlined above, that is, we do not ad­
dress actually constructing triangulations with a minimal or
close to minimal maximum clique size. Recent research re­
sults indicate, however, that for small graphs optimal trian­
gulations can be feasibly computed. Building upon a vari­
ant of an algorithm by Amborg, Corneil, and Proskurowski
[3], K. Shoikhet and D. Geiger performed various exper­
iments on randomly generated graphs [4]. Their results
indicate that this algorithm allows for computing optimal
triangulations of graphs with up to I 00 vertices.
The paper is organised as follows. In Section 2, we review
some basic definitions. In Section 3, we present our pre­
processing rules. The computational model in which these
rules are employed, is discussed in Section 4. In Section
5, we report on our experiments with well-known real-life
probabilistic networks. The paper ends with some conclu­
sions and directions for further research in Section 6.

2

Definitions

The currently most efficient algorithm for probabilistic in­
ference operates on a junction tree that is derived from a

UAI2001

BODLAENDER ET AL.

triangulation of the moralisation of the digraph o f a proba­
bilistic network. We review the basic definitions involved.
Let G
(V, A) be a directed acy clic graph. The moral­
isation of G is the undirected graph M(G) obtained from
G by adding edges between everypair ofnon-adjacent ver­
t i ces that have a common successor (vertices v and w have
a common s ucc essor if there is a vertex x with ( v, x) E A
a nd (w, x) E A), and then dropping the arcs' directions.
=

Let G
(V, E) be an undirected graph. A set of vertices
W � V is called a clique in G if there is an edge between
every pair of disjoint vertices from W; the cardinality of
W is the clique's size. For a set of vertices W � V, the
subgraph induced by W is the graph G[WJ = (W, (W x
W) n E); for a single vertex v, we write G- v to denote
G[V - {v}]. The graph G is triangulated if it does not
contain an induced subgraph that is a simple cycle of length
at least four. A triangulation of G is a triangulated graph
H (G) that contains G as a sub graph. The treewidth of the
triangulation H (G) of G is the maximum clique size in
H (G) minus 1. The treewidth of G, denoted r (G), is the
minimum treewidth over all triangulations of G.
=

graph H is a minor of a graph G if H can be obtained
from G by zero or more vertex deletions, edge deletions,
and edge contractions (edge c ontra cti on is the operation
that replaces two adjacent vertices v and w by a single ver­
tex that is connected to all neighbours of v and w). It is
well known (see for example [5]), that the treewidth of a
minor of Gis never larger than the treewidth of G itself.

A

of an undirected graph G = (V, E) is a
bijection V t-t {1, . . . , jVI}. For v E V and a linear or­
dering f of G- v, we denote by (v;f) the linear ordering
F of G that is obtained by addingv at the beginning off,
that is,f'(v)
1 and, for all w =/= v, F(w)
f(w) + 1.
A linear ordering f is a perfect elimination scheme for G
if, for each v E V, its higher ordered neighbours form a
clique, that is, if every pair of distinct verti ces in the set
{wE V I {v, w} E E and f(v) < f(w)} is adjacent. It is
well known (see for example [6]), that a graph is triangu­
lated if and only if it allows a perfect elimination scheme.

A linear ordering

=

33

of maximal cliques in G and, for each vertex v, the set
= { i I v E Vi} c ons titu tes a connected subtree ofT.
It is well known (see for example [6]), that a graph is trian­
gulated if and only if it has a junction tree.

Tv

3

Safe reduction rules

Pre-processing a probabilistic network for triangulation
builds upon a set of reduction rules. Th ese rules allow for
stepwise reducing a network's moralised graph to another
graph with fewer vertices. The steps applied during the re­
duction can be reversed, thereby enabling us to compute a
triangulation of the original graph from a triangulation of
the smaller graph. In this section, we discuss the various
rules; a discussion ofthe computational method in which
these rules are employed, is deferred to Section 4.
During a graph's reduction, we maintain a stack of elimi­
nated vertices and an integer low that gives a lower bound
for the treewidth of the original graph. Application of a re­
duction rule serves to modify the current graph G to G' and
to possibly update low to low'. We say that the rule is safe
if max(r(G), low)
m ax(r(G') , low'). By applying safe
rules, therefore, we have as an invariant that the treewidth
of the original graph equals the maximum ofthe treewidth
ofthe reduced graph and the value low. In the sequel, we
assume that the original moralised graph has at least one
edge and that low is initialised at 1.
=

Our first reduction rule applies to simplicial vertices. A
vertex v is simplicial in an undirected graph G if the neigh­
bours ofv form a clique in G.
Lemma 1 Let

G

be an undirected graph and let v be a

simplicial vertex in

G with degree d ;::: 0. Then,

=

For a graph G and a linear ordering f of G, thereis a unique
minimal triangulation H (G) of G that has f forits perfect
elimination scheme. This triangulation, which we term the
fill-in given j, can be constructed by, fori
1, ... , !VI,
turning the set of higher numbered neighbours of f-1 (i)
into a clique. The maximum clique size minus 1 of this
fill-in is called the treewidth of f. The treewidth of a lin­
ear ordering of a triangulated graph equals the maximum
number of higher numbered neighbours of a vertex [ 6].
=

To conclude, a junction tree of an undirected graph G =
(V, E) is a tree T = (I, F), where every node i E I
has associated a vertex set Vi, such that the following two
properties hold: the set {Vi I i E I} equals the set

•
•

r(G)

=

max(d,r(G- v));

(v; f) of G of minimum
G - v of
treewidth at most max(d, r(G- v)).
there is a linear ordering

treewidth, where f is a linear ordering of

Proof. Since G contains a clique of size d + 1, we have
that r(G) ;::: d. We further observe that r(G) ;::: r(G - v),
because G - v is a minor of G. We therefore have that
r(G) ;::: max(d, r(G- v )) . Now, let f be a linear ordering
of G-v of treewidth k:::; max(d, r(G- v)). Let H be the
fill-in of G- v given f. Adding vertex v and its (formerly)
incident edges to H yields a graph H' that is still triangu­
lated: as every pair of neighbours of vis adjacent, v cannot
belong to a simple (ch ordless ) cycle of length at least four.
The maximum clique size of H' therefore equals the maxi­
mum ofd+1andk+l. Hence,r(G) � max(d,r(G-v)),
from which we conclude the first property stated in the
lemma. To prove the second property, we observe that the
linear ordering (v; f) is a perfect elimination scheme for
H', as removal of v upon computing the fill-in of H' does
0
not create any additional edges.

34

UAI2001

BODlAENDER ET AL.

Our first reduction rule, illustrated in Figure

1,

now is:

Reduction Rule 1: Simplicial vertex rule

G if there is a neighbour w of v such that all other neigh­
bours of v form a clique in G. Figure 2 illustrates the basic
idea. As we allow other neighbours of v to be adjacent to
simplicial vertices are also almost simplicial.

Letv be a simplicial vertex of degree d � 0.
Removev.
Set low to max(/ow, d).

w,

·

From Lemma 1 we have that the simplicial vertex rule is
safe. The second property stated in the lemma further pro­
vides for the rule's reversal when computing a triangulation
of the original graph from one of the reduced graph.

�
·

.
·
·..

·.

.

·

....

..: .··

·
.

x

.

· · · · · · · · : :•
w

-=edge
=edge or non-edge

Figure 2: An almost simplicial vertex.

·

.·
·

.

. . .

....

.

v

�

Figure 1: The simplicial vertex rule.

Because the digraph G of a probabilistic network is
moralised before it is triangulated, it is likely to give rise
to many simplicial vertices. We consider a vertex v with
outdegree zero in G. Since all neighbours of v have an arc
pointing into v, moralisation will connect every two neigh­
bours that are not yet adjacent, thereby effectively turning v
into a simplicial vertex. The simplicial vertex rule wiii thus
remove at least all vertices that have outdegree zero in the
network's original digraph. As every directed acyclic graph
has at least one vertex of outdegree zero, at least one reduc­
tion will be performed. As the reduced graph need not be
the moralisation of a directed acyclic graph, it is possible
that no further reductions can be applied.
/
The digraph G of a probabilistic network may also include
vertices with indegree zero and outdegree one. These ver­
tices will always be simplicial in the moralisation of G.
We consider a vertex v with indegree zero and a single arc
pointing into a vertex w. In the moralisation of G, w and
its (former) predecessors constitute a clique. As all neigh­
bours ofv belong to this clique, v is simplicial.
A special case of the simplicial vertex rule applies to ver­
tices of degree 1; it is termed the twig rule, after [7].
Reduction Rule la: Twig rule

Letv be a vertex of degree 1.
Removev.
The twig rule is based upon the observation that vertices of
degree one are always simplicial. Another special case is
the islet rule that serves to remove vertices of degree zero.
We would like to note that many heuristic triangulation al­
gorithms, such as the algorithm described in [8], remove
simplicial vertices.
Our second reduction rule applies to almost simplicial ver­
tices. A vertex v is almost simplicial in an undirected graph

Let G be an undirected graph and let v be an
almost simplicial vertex in G with degree d � 0. Let G' be
the graph that is obtained/rom G by turning the neighbours
ofv into a clique and then removing v. Then,

Lemma 2

•
•

r(G') :-:; r(G) and r(G) :-:; max(d, r(G'));
the linear ordering (v; f) of G, with f a linear or­
dering ofG' oftreewidth at most max(d,r(G')), has
treewidth at most max(d, r(G')).

Let w be a neighbour of v such that the other
neighbours of v form a clique. As we can obtain G' from
G by contracting the edge {v, w } , G' is a minor of G. We
therefore have that r(G') :-:; r(G). Now, let f be a linear
ordering ofG' of treewidthk :-:; max(d, r(G')). Let H be
the fill-in ofG' given f. If we add v and its (formerly) adja­
cent edges to H, thenv is simplicial in the resulting graph
H1• Using Lemma l, we find that r(H') max(k, d). The
D
two properties stated in the lemma now follow.
Proof.

=

Our second reduction rule, illustrated in Figure 3, is:
Reduction Rule 2: Almost simplicial vertex rule

Let v be an almost simplicial vertex of degree d � 0.
If low � d, then
add an edge between every pair of non-adjacent
neighbours of v;
removev.
Building upon Lemma 2 we find that the almost simpli­
cial vertex rule is safe. Suppose that we have G and
low before, and G' and low1 after application of the rule.
Then, r(G') :-:; r(G), r(G) :-:; max(d,r(G')), and
d :-:; low = low1• We conclude that max(r(G),low)
max(r(G'),low1). Examples can be constructed, unfortu­
nately, that show that the rule is not safe for low < d.
=

Figure 3: The almost simplicial vertex rule.

35

BODLAENDER ET AL.

UAI2001

A special case of the almost simplicial vertex rule applies

Lemma 3 Let G be an undirected graph and let v, w be

to vertices of degree two. A vertex of degree two is, by def­

two vertices of degree three having the same set of neigh­
bours. Let G' be the graph that is obtained from G by
turning the set of neighbours ofv into a clique and then
removingv and w. Then,

inition, almost simplicial and we can therefore replace it by
an edge between its neighbours, provided that the original
graph has treewidth at least two. The resulting rule, illus­
trated in Figure 4, is called the series rule, after [7].

•

Reduction Rule 2a: Series rule

•

Let v be a vertex of degree 2.
If low � 2, then
add an edge between the neighbours of v, if
they are not already adjacent;

·
... ·

v

..
......

·

Now, let

in of G1 given

·. . .

. .

.

· ·

be a vertex of degree 3 such that at least

··

·.
···

.

.
.

..
.

·

.

.

.·

.

......

f))

of G,
0

From Lemma 3 we have safeness of the buddy rule, which
is illustrated in Figure 6.

.·

..

�
·

·

.

.

·

w

be vertices of degree 3 having the same

add an edge between every pair of non­

.
.

.

.

. ..

:. .

·

adjacent of neighbours of v;
removev;

� �

removew.
··

Figure 5: The triangle rule.
As the series and triangle rules are special cases of the al­

most simplicial vertex rule, both are safe.
If the twig and islet rules cannot be applied to a non-empty
undirected graph, then the graph has treewidth at least two.
We can then set low to max.(low, 2). Note that from this ob­
servation we have that the islet and twig rules suffice for re­
ducing any graph of treewidth one to the empty graph. The

islet, twig and series rules suffice for reducing any graph of
treewidth two to the empty graph. So, if low ;::: 2 for a given
non-empty graph and the islet, twig and series rules cannot
be applied, then we know that the graph has treewidth at
least three. We can then set low to max{low, 3).
As for treewidths one and two, there is a set of rules that

:·.... ::

···

·

·

··

.

.

··

·.

..

.
· .·

.

V

·

.

.

.

.

.

....

.. .

•

•

.. ·

..

w

Figure 6: The buddy rule.
The cube rule, presented schematically in Figure 7, is
slightly more complicated. The subgraph shown on the left
is replaced by the one on the right; in addition, low is set
to max( low, 3). Vertices v,

w

and

x

in the subgraph may

be adjacent to other vertices in the rest of the graph; the
four non-labeled vertices cannot have such 'outside' edges.
Due to space limitations we do not provide a lemma from
which safeness of the rule can be seen; the proof of safe­
ness, however, is similar to the proofs given above.

This set of rules was first identified by S.

Arnborg and A. Proskurowski [7). The islet, twig, series
and triangle rules are among the set of six. The two other
rules are of interest to us, not just because they provide for
computing optimal triangulations for graphs of treewidth
three, but also because they give new reduction rules.

.. ·

.

suffice for reducing any graph of treewidth three to the
empty graph.

their (formerly)

H, then both are simplicial in the result­

If low ;::: 3, then

removev.
.
·

By

set of neighbours.

adjacent neighbours of v;

·.

f. If we add v and w with

The properties stated in the lemma now follow.

Letv,

add an edge between every pair of non­

·

w.

Reduction Rule 3: Buddy rule

If low � 3, then

�

and

v

therefore, equals the maximum of 3 and the treewidth off.

two of its neighbours are adjacent.

··

be the neighbours of

ing graph. The treewidth of the ordering (v; (w;

Reduction Rule 2b: Triangle rule

·

y and z

adjacent edges to

Another special case is the triangle rule, shown in Figure 5.

v

x,

G'. So, G' is a minor of G. We find that r(G1) :-::; r(G).
f be a linear ordering of G' and let H be the fill­

: :I

Figure 4: The series rule.

Let

Let

contracting the edges { v, x} and { w, y} in G, we obtain

.. :::�
...

the linear ordering (v; (w; f)), with f a linear or­
dering ofG' oftreewidth at most max(3, r(G')), has
treewidth at most max(3, r(G')).

Proof.

remove v.

··

r(G') :-::; r(G) and r(G) :-::; max(3, r(G'));

Figure 7: The cube rule.

BODLAENDER ET AL.

36

The sub graph in the left hand side of the

cube rule

is not

UAI2001

2. If a reduction rule can be applied to G', it is executed,

very likely to occur in the moralisation of a probabilistic

modifying G' accordingly. Each vertex thus removed

network's digraph, but it is not impossible. The main rea­

is pushed onto the stack S; if prescribed by the rule,

son for our interest in the rule is that it is one of the six

the lower bound

rules that suffice for reducing graphs of treewidth three to

until the reduction rules are no longer applicable.

low � 3 for a given non-empty
islet, twig, series, triangle, buddy and cube

the empty graph. So, if
graph and the

rules

cannot be applied, then we know that the graph has

treewidth at least four. We can then set
To conclude this section, Figure

low to max (low, 4).

The figure depicts how application of our reduction rules
serves to reduce the fragment to a single vertex. In fact, the
moralised graph of the

entire

ALARM network is thus re­

duced to the empty graph, which indicates that our reduc­
tion rules provide for constructing an optimal triangulation.

This step is repeated

3. If no rule can be applied and low

< 4, then

low

is

increased by I. The reduction is continued at step 2.
4. L et G' be the graph

that results after execution of the

previous steps. Using an exact or heuristic algorithm,

8 shows a fragment of the

well-known ALARM network, along with its moralisation.

low is updated.

G' is triangulated.

5.

Let H be the triangulation that results from step 4. For
H, a perfect elimination scheme f is constructed.

6. Until S is empty, the top element

v

and f is replaced by (v; f).

is popped from S

7. Let f' be the linear ordering resulting from the previ-

ous step. The fill-in of M(G) given f' is constructed.
The steps I through

3 describe the reduction of the graph
In step 4, the graph that re­

of a probabilistic network.

sults after reduction is triangulated. For this purpose, vari­

ous different algorithms can be used. If the algorithm em­
ployed is

exact,

that is, if it yields a triangulation of min­

imal treewidth, then our method yields an optimal trian­
gulation for the original moralised graph. For many real­
life networks, the combination of our reduction rules with
an exact algorithm results in an optimal triangulation in
reasonable time.
Figure 8: A fragment of the ALARM network and the re­

duction of its moralisation.

4

implements

We argued that application of our rules may reduce a net­
work's moralised graph to the empty graph. The computa­
tional method complements this reduction by its reversal,
thereby providing for the construction of a triangulation of
minimal treewidth. For networks that cannot be triangu­
lated optimally just by pre-processing, our rules are com­
bined with an algorithm that serves to find an optimal or
close to optimal triangulation of the reduced graph.
The computational method takes for its input the directed
acyclic graph G of a probabilistic network; it outputs a tri­
angulation of the moralisation of G. The method uses a
stack S to hold the eliminated vertices in the order in which
they were removed during the graph's reduction. Moreover,

low

maintains a lower bound for the treewidth

of the original moralised graph; it is initialised at 1. The
method now amounts to the following sequence of steps:
I. The moralisation M (G) of G is computed and G' is

initialised at M(G).

triangulation algo­

we will argue in the next section, however, these heuris­

pre-processing of probabilistic networks for triangulation.

the value

heuristic

moralised graph then is not guaranteed to be optimal. As

The reduction rules described in the previous section are

computational method that

not be feasibly computed, a

rithm can be used. The treewidth yielded for the original

Computational method

employed within a

If after reduction a graph of consider­

able size remains for which an optimal triangulation can­

tic algorithms tend to result in better triangulations for the
graphs that result from pre-processing than for the original
graphs. If, after executing the steps I through 3, the re­
duced graph is empty, we can construct a triangulation of
minimal treewidth for the moralised graphjust by reversing
the various reduction steps, and further triangulation is not
necessary. This situation occurs, for example, if the origi­
nal graph is already triangulated or has treewidth at most 3.
The ALARM network gives another example: its moralised
graph has treewidth four and is reduced to the empty graph.
In step

2 of our computational method, each of the reduc­

tion rules is investigated to establish whether or not it can
be applied to the current (reduced) graph G'. As soon as
an applicable rule is found, it is executed. When analysing
the computational complexity of our method, it is readily
seen that investigating applicability of the various reduc­
tion rules is the main bottleneck, as all other steps (except
for the triangulation in step

4) take linear time [6].

Investigating applicability of the islet,

twig and series rules

takes a total amount of computation time that is linear in
the number of vertices. To this end, we maintain for each

BOPLAENDER ET AL.

UAI2001

37

network

vertex an integer that indicates its degree; we further main­

before
moralisation

tain lists of the vertices of degree zero, one, and two. The

buddy, triangle and cube rules

lVI

can also be implemented to

WILSON

take overall linear time, for example using techniques from
[9]. More straightforward implementations, however, will

ALARM

VSD

also be fast enough for moderately sized networks.

OESOPHAGUS

For the simplicial vertex and almost simplicial vertex rules,
efficient implementation is less straightforward. To inves­

MUNIN

OESOPHAGUS+

ICEA
PATHFINDER

tigate whether or not a vertex is simplicial, we must verify
that each pair of its neighbours are adjacent. For this pur­
pose, we have to use a data structure that allows for quickly
checking adjacency, such as a two-dimensional array. For
a vertex of degree d, investigating

O(d2) time. In

a graph with

n

simpliciality

then takes

vertices, we may

have

to

O(n) times. Each such check
O(ne) time, where d(v) is the
de.

check for simplicial vertices
costs

OCL v d(v)2)

gree of vertex v

=

and e

denotes the number of edges m the

graph. The total time spent on investigating applicability
of the

simplicial vertex rule

is therefore

O(n2e). As

the

treewidth of the moralised graph of a real-life probabilistic

network is typically bounded, we can refrain from checking
simpliciality for vertices of large degree, giving a running
time of

O(n2)

in practice. For the almost

simplicial vertex

rule, similar observations apply.

Table l:

IAI

21
37
38
42
67
1003

23
44
51

57

117
1244

after
moralisation

lVI

lEI

37
38
42
67
!003

194
1662

21

27
62
61
68

89

!54

89

215

109

192

l09

211

The sizes of the digraphs of the various networks

and of their moralisations.

PR-2
PR-3
PR-4

PR-l U {series}
PR-2 U {triangle, buddy, cube}
S UPR-3

With each of these sets of rules, the moralisations of

the networks' graphs were reduced until the rules were
no longer applicable.

T he table reports the sizes of the
It reveals, for example, that

resulting reduced graphs.
the set of rules

P R-3 suffices for reducing the moralised

graphs of the WILSON and OESOPHAGUS networks to the
empty graph;

with the additional simplicial vertex rule,

the moralised graphs of the ALARM and VSD networks are
also reduced to the empty graph. These four networks are

5

therefore triangulated optimally just by pre-processing. We

Experimental results

would like to note that addition of the almost simplicial ver­

T he computational method outlined in the previous section
implements our method of pre-processing probabilistic net­

tex rule to PR-4 did not result in any further reductions.
For the OESOPHAGUS+, MUNIN, ICEA and PATHFINDER

works for triangulation. We conducted some experim ents

networks, we further studied the effect of pre-processing

results of these experiments are reported in this section.

algorithms. Table

with the method to study the effect of pre-processing. The

The experiments were conducted on eight real-life prob­
abilistic networks in the field of medicine: the WILSON
network for the diagnosis of Wilson's liver disease; the

well-known

ALARM network for

anaesthesia monitoring;

the VSD network for the prognosis of ventricular septal de­
fect in infants; the OESOPHAGUS network for the staging
of oesophageal cancer and the extended OESOPHAGUS+

network for the prediction of response to treatment; the
well-known MUNIN network for the interpretation of elec­
tromyographic findings; the ICEA network for the predic­
tion of coverage by antibiotics of pathogens causing pneu­
monia· and the well-known PATHFINDER network for the

�

diagn sis of lymphatic disease. The sizes of the digraphs
of these networks and of their moralisations, expressed in
terms of the

number of vertices and the number of arcs and

edges, respectively, are given in Table I.
The effects of employing various different sets of pre­
processing rules on the eight networks under study are sum­
marised in Table

S
P R-1

2. T he sets employed are denoted:

{simplicial vertex}
{islet, twig}

y

on the treewidths yielded b various heuristic triangulation

3 summarises the results obtained with
maximum cardinality search (denoted MCS) [10] and with

the

perfect-triangulation and minimal-triangulation vari­
breadth-first search (denoted LEX_p

ants of lexicographic

and LEX_M, respectively) [11]. We ran the three heuris­
tic algorithms on the original moralisations of the four net­
works and on the reduced graphs after employing the sets
of rules P R-1 through PR-4. The table reveals that, for
the MUNIN and ICEA networks, the heuristic algorithms
tend to yield a smaller treewidth from the reduced graphs
than from the original moralisations.

The table in addi­

tion shows that the further reduced a graph, the less com­
putation time is spent by the algorithms. As the time spent
on pre-processing is negligible, these results indicate that
pre-processing a probabilistic network is profitable, not just
with respect to the quality of the triangulation yielded but
also with respect to the computation time spent.
In our experiments we observed that the treewidths found
by the heuristic algorithms depend to a large extent on the
vertex with which the computation is started. To investigate
the effect of the starting vertex, we ran the three heuristic
algorithms a number of times every time starting with
,

different vertex. Table

a

4 summarises the results, indicating

BODLAENDER ET AL.

38

network

before

pre-pro

pre-pro

pre-pro

pre-pro

withS

with PR-1

with PR-2

lVI

WILSON
ALARM
VSD
OESOPHAGUS
OESOPHAGUS+
MUNIN

21
37
38
42
67
1003
89
109

ICEA
PATHFINDER

UA12001

lEI

27
62

61
68
194
1662
215
211

lVI

6
7
16
5
28
449

64
14

lEI

8
II

21
8
125
826
176
49

lVI

lVI

lEI

II
30
22
22
46
819
85
68

4
13

17
55
45
48
173
1478
211
170

12
12
31
367
66
37

lEI

pre-pro

pre-pro

with PR-3

with PR-4

lVI

6
28

0
5
6

28
28
144

0
28
175
59

736
181
112

17

lEI

0
10
14
0
135
471
170
63

lVI

lEI

0
0
0
0
26
175
59
14

0
0
0
0
121
471
170
49

Table 2: The effects of employing different sets of reduction rules.

lVI

lEI

67
46
31

194
173
144

28
26

135
121

MUNIN_O

1003

MUNIN_1

819
367
175

network

CPU time spent

computed treewidth

MCS

LEX_F

LEX..M

MCS

LEX_p

LEX..M

10
10
10
10

11

10

11
11

10
10

10

10
10

0.04
0.02
0.01
0.01

0.25
0.13
0.06

11
11

0.04
0.02
0.01
0.01
0.01

0.01

1662
1478
736
471

10
10
10
9

16
16
10
8

16
16
10

35.78
23.12
4.78
0.37

330.90
216.29

8

28.60
17.99
1.68
0.29

89
85
66
59

215

15
15
16

14
14
15

13
13
13

0.12
0.11
0.09

0.14

211
181
170

15

13

0.08

0.72
0.65
0.42
0.33

PATHFINDER_O

109

PATHFINDER_ I

7
7

7
7

PATHFINDER3

68
37
17

211
170
112

14
7

0.13
0.09
0.08

0.07
0.02
0.01
0.00

PATHFINDERA

14

0.05
0.02
0.01
0.00
0.00

0.35
0.15
0.05
0.01
0.01

OESOPHAGUS+ _0
OESOPHAGUS+ _1
OESOPHAGUS+.2
OESOPHAGUS+3
OESOPHAGUS+A

MUNIN...2
MUNIN3
ICEA_O
ICEA_l
ICEA..2
ICEA.J

PATHFINDER..2

63
49

7
7

7
7
7

7
7
7

7
7

0.00

0.05
0.04

30.16
3.29

Table 3: The effect of pre-processing on the treewidths yielded by the three heuristic triangulation algorithms.

network

lVI

lEI

67
46

LEX_p

MCS

rEX..M

min

average

max

min

average

max

min

average

max

194
173

10
10

31
28

144
135

to
10

13
15
15
15

121

10

15

11
11
11
11
11

12.8
12.8
12.7

26

12.1
12.2
11.9
12.1
11.8

16
16
16
16
16

10
10
10
10
10

12.0
12.1
11.8
11.6
11.6

14
14
13
13
13

1003
819
367
175
89
85
66
59

1662
1478
736
471

10
10
10
9

15.1

16
16
10
8

23.3
23.7
22.1
13.8

56
57
50

16
16
10

22.1
22.0

56
56

9.7

26
24
25
15

49

8

20.7
12.1

50
30

215
211
181
170

15
15
16
15

19.8
18.7
19.3
19.5

22
22
22
22

14
14
15

23
23
23
23

13
13

14

19.1
18.9
18.9
18.6

13
13

16.3
16.2
16.3
16.4

20
20
20
20

211
170
112
63

PATHFINDER_4

14

49

7
7
7
7
7

7.2
7.6
7.5
7.4
7.6

8

PATHFINDER_3

109
68
37
17

7
7
7
7
7

8.0
7.6
7.6
7.5
7.4

9
9
9
9
9

7
7
7
7
7

7.6
7.2
7.2
7.1
7.1

8
8
8
8
8

OESOPHAGUS+_0
OESOPHAGUS+_I
OESOPHAGUS+...2
OESOPHAGUS+.3

OESOPHAGUS+A
MUNIN_O
MUNJN_l
MUNIN...2
MUNIN3
ICEA_O
ICEA_ I
ICEA..2
ICEA3
PATHFINDER_Q
PATHFINDER_!
PATHFINDER...2

15.6
14.8

8
8
8
8

12.6
12.6

Table 4: Some statistics for the three heuristic triangulation algorithms.

UAI2001

per graph the minimum and maximum treewidth found and

form better. Some of our reduction rules are safe also with

the average treewidth over all possible starting vertices. We

respect to minimum overall state space. Other rules, how­

would like to note that, using integer linear programming

ever, are safe only under additional constraints on their ap­

techniques on the most reduced graph, we found the exact

plication. We plan to further investigate pre-processing for

treewidth of the PATHFINDER network to be 6.

finding triangulations with minimum overall state space.

6

Conclusions and further research

When solving hard combinatorial problems, pre-processing
is often profitable.

Based upon this general observation,

we designed a computational method that provides for pre­
processing of probabilistic networks for triangulation. Our
method exploits a set of rules for stepwise reducing the
problem of finding a triangulation of minimum treewidth
for a network's moralised graph to the same problem on a

Acknowledgements. The research of the first author was partly
supported by EC contract IST-1999-14186: Project ALCOM-FT
(Algorithms and Complexity - Future Technologies). The re­
search of the last two authors was partly supported by the Nether­
lands Computer Science Research F oundation with financial sup­
port from the Netherlands Organisation for Scientific Research.




To investigate the robustness of the output
probabilities of a Bayesian network, a sensi­
tivity analysis can be performed. A one-way
sensitivity analysis establishes, for each of the
probability parameters of a network, a func­
tion expressing a posterior marginal proba­
bility of interest in terms of the parameter.
Current methods for computing the coeffi­
cients in such a function rely on a large num­
ber of network evaluations. In this paper, we
present a method that requires just a single
outward propagation in a junction tree for es­
tablishing the coefficients in the functions for
all possible parameters; in addition, an in­
ward propagation is required for processing
evidence. Conversely, the method requires
a single outward propagation for computing
the coefficients in the functions expressing all
possible posterior marginals in terms of a sin­
gle parameter. We extend these results to an
n-way sensitivity analysis in which sets of pa­
rameters are studied.

1

INTRODUC TION

The robustness of the output probabilities of a
Bayesian network can be investigated by performing
a sensitivity analysis of the network. For mathemat­
ical models in general, sensitivity analysis serves to
identify the effects of the inaccuracies in a model's pa­
rameters on its output (Morgan & Henrion 1990). For
a Bayesian network, more specifically, performing a
sensitivity analysis yields insight in the relation be­
tween the probability parameters of the network and
its posterior marginals. The simplest type of sensi­
tivity analysis is a one-way analysis in which a single
parameter is studied; a more general n-way analysis
serves to investigate the joint effects of inaccuracies in

a set of parameters.
In the brute-force approach to performing a one-way
sensitivity analysis of a Bayesian network, each proba­
bility parameter of the network is varied systematically
and the effect on the output probabilities of the net­
work is investigated. Performing a sensitivity analysis
in this way requires thousands of network evaluations,
or (full) propagations, and is, therefore, much too time
consuming to be of any practical use.
Laskey (1995) has been the first to address the compu­
tational complexity of sensitivity analysis of Bayesian
networks. She has introduced a method for computing
the partial derivative of a posterior marginal proba­
bility with respect to a parameter under study. Her
method thus yields a first-order approximation of the
effect of varying a single probability parameter on a
posterior marginal. Compared to the brute-force ap­
proach, her method requires considerably less compu­
tational effort. The method, however, provides insight
only in the effect of small variations of parameters;
when larger variations are considered, the quality of
the approximation may rapidly break down.
The relation between a posterior marginal probability
of interest and a parameter under study can be ex­
pressed through a simple mathematical function. The
function expressing the posterior marginal is a quo­
tient of two linear functions in the parameter, as has
been shown by Castillo et al. (1996). Building upon
this property, it suffices to establish the coefficients
in this function to determine the effect of parameter
variation. Castillo et al. (1997) and Coupe & van der
Gaag (1998) have designed methods to this end. These
methods require a single network evaluation for each
coefficient to be established. Although these methods
currently are the most efficient available, they rely on
a large number of network evaluations and, as a con­
sequence, are infeasible for large realistic networks.
In this paper, we present a new method for sensitivity
analysis of Bayesian networks. Our method, like the

318

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

two methods mentioned above, exploits the property
that a posterior marginal probability relates by a sim­
ple mathematical function to a parameter under study.
It requires just a single outward propagation in a junc­
tion tree, however, to compute the coefficients in the
functions for all possible parameters; in addition, it re­
quires an inward propagation for processing evidence.
Conversely, the method requires a single outward prop­
agation for establishing the coefficients in the functions
expressing all possible posterior marginals in terms of
a single parameter. Our method can be readily ex­
tended to an n-way sensitivity analysis in which sets
of parameters are varied.
In addition to a sensitivity analysis, an uncertainty
analysis can be performed for investigating the robust­
ness of the output probabilities of a Bayesian network.
In an uncertainty analysis, all parameters are varied si­
multaneously through sampling; it therefore provides
little insight into the effects of variation of specific pa­
rameters. Experiments with uncertainty analysis have
led to the suggestion that Bayesian networks are in­
sensitive to inaccuracies in their parameters (Pradhan
et al. 1996, Henrion et al. 1996). In these experiments,
however, a measure of model robustness was obtained
by assuming a lognormal distribution for each parame­
ter and averaging over the probability of the true diag­
nosis for various diagnostic situations in a medical ap­
plication. Rather than in the average of the probabili­
ties of the true diagnosis, however, it is in the variation
of these probabilities that inaccuracies in parameters
are reflected. From these experimental results, there­
fore, no decisive conclusions can be drawn as to the
sensitivity of Bayesian networks. In fact, Coupe et al.
(1999) have reported high sensitivities in an emprical
study in the medical domain, involving real patient
data. We feel that these and emerging similar expe­
riences warrant further investigation into sensitivity
analysis of Bayesian networks.

2

THE BASIC P ROPERT Y

Sensitivity analysis of a Bayesian network basically
amounts to establishing, for each of the network's pa­
rameters, a function expressing an output probabil­
ity in terms of the parameter under study. For out­
put probabilities, we shall consider posterior marginal
probabilities of the form y = p(a I e), where a is a
value of a variable A and e denotes the evidence avail­
able. Each of the network's parameters is of the form
x = p(bi l1r), where b; is a value of a variable B and
1r is an arbitrary combination of values of the set of
parents II= pa(B) of B. We will write p(ale)(x) to
denote the function expressing the posterior marginal
p(a I e) in terms of the parameter x.
In the sequel, we will assume that in a sensitivity anal­
ysis, upon varying a parameter x p(b; l1r), each of
the other probabilitiesp(bj l1r) is co-varied accordingly,
by scaling by the ratio between the probability masses
left. More formally, let the variable B have for its do­
main dom(B)
{b1,...,bm}, m 2: 1. Note that the
parameters p(bj l1r), j =f. i , are functions of x. We now
assume for these functions that
=

=

if j= i
otherwise,
with p(b; l1r)

<

(1)

1.

With the assumption of co-variation as outlined above,
the function y(x) yielded by a sensitivity analysis is a
quotient of two linear functions in x. The following
theorem reviews this important property; the associ­
ated proof provides the basis for the algorithms pre­
sented in Sections 4 and 5.
Theorem 1 Let p be the probability function defined
by a Bayesian network over a set of variables V. Let
y = p(a I e) and x p(b; l1r) be as indicated above.
Then,
=

The paper is organised as follows. Section 2 reviews
the important basic property that a posterior marginal
probability can be expressed as a quotient of two linear
functions in a parameter under study. In Section 3, we
briefly describe currently available methods for sensi­
tivity analysis that build upon this property. In Sec­
tion 4, we present our method for computing the co­
efficients in the functions for all possible parameters,
using just one propagation in a junction tree. In Sec­
tion 5, we describe a similar method for computing
the coefficients in the sensitivity functions relating all
possible posterior marginals to a single probability pa­
rameter. These methods are generalised to an n-way
sensitivity analysis in Section 6. The paper ends with
some concluding remarks in Section 7.

y=
where a, (3,

"(,

p(a,e)(x)
p(e)(x)

ax+ f3
"(X+ 8'

(2)

and 8 are constants with respect to x.

Proof: The joint probability p(a,e) can be expressed

in terms of x as

p(a,e}(x)

�

(�:{V)) (x),

where Lv:a,...,dp(V) denotes summation over the variables V\ {A, . . . , D} with A, ... , DE V fixed at values
a, ... , d, respectively.
The sum Lv:a,ep(V) in the above equation can be
split into n+ 1 separate sums, such that the first sum

319

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

includes only terms with the value b1 for B and the
state 1r for II, the second sum includes only terms with
the value b2 for B and II in state 1r, and so on, and
the last sum includes the remaining terms. So,

(1990), as described by Castillo et a!. (1997). After
having identified the set of relevant parameters, the
sensitivity analysis can be restricted to this set.
Building upon the set of n relevant parameters,
x1, . . . , Xn, the algorithm of Castillo et a!. (1997) iden­
tifies sets of monomials for which the coefficients will
be zero in the linear function p(a, e)(x1, . . . , Xn ) · For
the resulting m monomials, the algorithm constructs
a system of m independent equations of the form
i
y
p(a, e)(xi, . . . , x�), where, for each j, xj denote
arbitrary values for parameter Xj. The corresponding
values yi, i
1, ... , m, are obtained through m net­
work evaluations. The coefficients in the function are
now determined by solving the set of equations thus
obtained. Coupe & van der Gaag independently de­
scribed a similar method, also based on the idea of
solving a system of independent equations. They fur­
ther argue that in a one-way sensitivity analysis three
network evaluations suffice per relevant parameter.
=

=

p( )

" p(V).
" l:v:a,e,b;,11' V +
L
L
1-p(b·l7r)
'
V:a,e,n'f11'
j#i
For the probability p(e) we derive a similar expression
by summing, in the above derivation, over all values of
the variable A instead of keeping it fixed at a. From
the resulting expressions p(a, e)(x) and p(e)(x), it is
readily seen that the output y p(a I e) can be written
as a quotient of two functions that are linear in x. D
=

From Theorem 1 we have that the function that ex­
presses a posterior marginal probability y in terms
of a single parameter x is characterised by at most
three coefficients. The theorem is easily extended to
n parameters. The function then includes the prod­
ucts of all possible combinations of parameters, termed
monomials, in both its numerator and its denomina­
tor. The numerator as well as the denominator are
characterised by 2n coefficients, many of which may
be zero.
3

CURRENT METHODS

The most efficient methods for sensitivity analysis of
Bayesian networks currently available exploit the basic
property reviewed in the previous section. We briefly
review these methods.
Not all parameters in a Bayesian network can influ­
ence a posterior marginal probability of interest. The
subset of parameters (possibly) influencing the poste­
rior marginal is dependent upon the evidence e. The
set of relevant parameters is easily identified using a
variation of the algorithm described by Geiger et a!.

The methods reviewed above have a computational
complexity that is considerably less than the brute­
force approach of systematic variation of parameters.
However, the methods can still be quite time consum­
ing: for a network of realistic size, it can easily require
several hundreds of network evaluations to perform a
one-way sensitivity analysis. An more general n-way
sensitivity analysis to study the joint effect of simulta­
neous variation of n parameters can in fact be so time
consuming that it is infeasible in practice.
4

ANALYSIS OF ONE OUTPUT
WRT. ALL PARAMETERS

The new methods for sensitivity analysis presented in
this paper have been tailored to Bayesian networks in
their junction-tree representation. The methods basi­
cally perform a single or a few outward propagations
in a junction tree and, as a result, are much less time
consuming than the methods reviewed in the previous
section.
In this section, we present our method for computing
the coefficients in the sensitivity functions expressing
a posterior marginal of interest y p(a I e) in terms of
all possible probability parameters x. Recall that these
functions are of the form presented in Theorem 1. Our
method now builds on the idea that, in a junction tree,
the expressions for p(a, e) and p(e) in terms of x can be
derived from the potential of a clique containing both
the variable and the parents to which the parameter x
pertains. The following theorem details the coefficients
to be computed.
=

Theorem 2 Let p be the probability function defined
by a Bayesian network and let T be a junction tree

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

320

for the network. Let y = p(aie) and x = p(b; l1r) be
as before. Suppose that, in T, an inward propagation
has been performed towards a clique containing the
variable of interest A; suppose that subsequently an
outward propagation from this clique has been per­
formed with the value a for A. Now, let K be a
clique in T containing both the variable B and its par­
ents II= pa(B); let ¢x = p(K,a,e) be the potential
of clique K after the abovementioned propagations.
Then, p(a,e)(x)= ax+ (3 with

a=

LK:b; ,,. ¢x ""'LK:b; ,,. ¢x
p(b;l1r) - �1-p(b;l7r)'

(3)

J -r- 1

(3 = L

#i

LK:b; ,,. ¢x
+ L ¢x
.
1-p(b; 17r) K:ll-=f-11"

(4)

Proof: The property follows directly from the proof
of Theorem 1 by observing that p(a,e)= 2:: K ¢ K. D

Building upon similar observations, we have the fol­
lowing corollary.
Corollary 1 Letp be the probability function defined
by a Bayesian netwerk and let T be a junction tree for
the network. Let x = p(b;l1r) and K be as before.
Suppose that the evidence e has been processed in T
by an inward and subsequent outward propagation.
Let ¢'K = p(K,e) be the potential of clique K after
the propagation. Then, p(e)(x)= "(X+ 6 with

(5)

6

=

'K
""' 'K.
""'LK:b;,,. ¢
¢
+
�
� 1- p(b1·i7r)
j-=f-i
K:0-=/-1r

4. Compute the coefficients a and (3, using the equa­
tions (3) and (6) from Theorem 2, for all relevant
parameters, locally per clique.
We would like to note that our method requires just
one inward and two outward propagations to estab­
lish all sensitivity functions for a specific posterior
marginal, whereas the methods reviewed in the pre­
vious section require three inward and outward prop­
agations per parameter.
The method described above outlines the basic idea.
The method, however, may be easier to implement in
the alternative form based upon Theorems 3 and 4.
Theorem 3 Let the junction tree T be as before.
Also, let y = p(aie) and x = p(b;l1r) be as before
and let K be a clique in T including both B and
II = pa(B). Now, let x1 be the initially specified
value for x and let x2 denote an arbitrary other value
for x. Suppose that, in T, an inward propagation has
been performed towards a clique containing the vari­
able of interest A; suppose that subsequently an out­
ward propagation has been performed with the value a
for A. Now, let ¢x =p(K,a,e) be the resulting clique
potential for clique K. Let

y1 =p(a,e)(x1)= L ¢x,
p'(Bi1r)
y2=p(a,e)(x2)= ""'
¢K
'
�
p(B i
7r)

1. Enter the evidence e into the junction tree and
perform an inward and an outward propagation
using an arbitrary root clique.
2. Compute the coefficients 'Y and 6, using the equa­
tions (5) and (6) from Corollary 1, for all relevant
parameters, locally per clique.
3. Perform an outward propagation from a clique
containing the variable of interest A, with the ad­
ditional evidence A= a.

(8)

where p(B l1r) and p'(B l1r) denote parameter vectors
with x = x1 and x = x2, respectively. Then, y =
ax+ (3 with

(6)

Theorem 2 and Corollary 1 provide the basis for our
method for computing the coefficients in the func­
tions expressing the posterior marginal of interest
y =p(a I e) in terms of all possible parameters x. The
method is composed of the following steps:

(7)

K

(9)
Since both variable B and its parents are in­
cluded in clique K, we can obtain from the parameter
vector

Proof:

p(Bi1r)

= (q1(x1 ), ... , Qi- (x1 ), x1, Qi+l (x1 ), ...,Qn(x1))
1

the parameter vector
p'(Bi1r)

(q� (x2),... 'q�- (x2),x2,q�+l (x2),...,q�(x2))
1

where q and q' are parameters co-varying according
to equation (1), by multiplication of the potential ¢x
by p'(Bl1r)jp(Bl1r). From Theorem 1, we have that
y= ax+ (3. The expressions for a and (3 now follow
D
from simple mathematical manipulation.

321

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

Let the junction tree T be as before.
Also, let y = p(afe) and x = p(bi f1r) be as before.
Suppose that, in T, an inward propagation has been
performed towards a clique including the variable of
interest A. Then, p(e)(x)= "(X + 8 with

9. Compute the coefficients
(10) from Theorem 4.

Theorem 4

"(= eta + a�a and 8 =f3a + f3�a1

(10)

where aa,f3a and a�a,f3�a are as in equation (9), ob­
tained from outward propagations with the evidence
A = a and A -::/:- a, respectively.
Proof:
We begin by observing that p(e)(x) =
p(a,e)(x) + p(•a,e)(x). By entering the evidence
A = a in a clique H containing the variable A
and propagating outwards, we obtain the potential
p(K, a, e) for clique K. From this potential,
¢K
p(a, e)
Y1.
LK cPK is readily computed, as de­
scribed in equations (7) from Theorem 3. Similarly,
by entering the evidence that A does not have the
value a (that is, by multiplying the clique potential
for H with a vector over dom(A), in which the en­
try corresponding to state a is zero and all other en­
tries equal 1) and propagating outwards, we obtain
the potential ¢�
p(K, •a, e). From this poten­
tial, Y�a = p(•a,e) = LK ¢� is readily computed.
Using equation (8) from Theorem 3, we get y� and
Y�a· Now, using equation (9), we find eta, a�a, f3a,
and f3�a· Inserting these coefficients into the expres­
sion p(e)(x)= p(a, e)(x) + p(•a, e)(x) yields the result
D
stated in the theorem.
=

=

=

=

Our alternative method, building upon Theorems 3
and 4, is composed of the following steps:
1. Enter the evidence e into the junction tree and
perform an inward propagation towards a clique
H containing the variable of interest A.
2. Perform an outward propagation from H with the
additional evidence A a.
=

3. Compute y;,_ and y�, using the equations (7)
and (8) from Theorem 3.
4. Compute the coefficients a = aa and f3 = f3a,
using (9), for all relevant parameters, locally per
clique.
5. Retract the evidence A
the evidence e.

=

a without retracting

6. Perform an outward propagation from H with the
additional evidence A -::/:- a.
7. Compute Y�a and Y�a' using the equations (7)
and (8) from Theorem 3.

and 8, using equation

To allow for retracting the evidence A = a in Step 5 of
our method without retracting e, fast-retraction prop­
agation (Cowell & Dawid 1992) is used in Step 2.
Comparing the computational costs of the two al­
ternative methods, we note that they both require
one inward and two outward propagations. Consider­
ing the first method, we observe that Steps 2 and 4
are equally costly. The computation of the coeffi­
cients a and 'Y costs 2 ·Jdom(K)J/m operations, where
m = fdom(pa(B))J; the computation of j3 and 8 costs
2fdom(K) I arithmetic operations. Thus, the addi­
tional cost of the first method is roughly in the or­
der of 2 to 3 times Jdom(K)f. The additional costly
steps in the second method are Steps 3 and 7, both
costing approximately 3 ·fdom(K)J operations. Thus,
the additional cost of the second method is roughly
6 fdom(K)f arithmetic operations. This rough com­
parison of the computational costs of the two methods
only addresses the number of arithmetic operations in­
volved. The first method, however, has a much larger
overhead in terms of computing indices in performing
the various summations. Thus, depending on the im­
plementation, the two methods might very well have
comparable performance.
·

5

ANALYSIS OF ALL OUTPUTS
WRT. ONE PARAMETER

Having identified a parameter x to which an output
probability of a Bayesian network is particularly sensi­
tive, one might be interested in establishing sensitivity
functions for all possible posterior marginals in terms
of this parameter. Such an analysis amounts to com­
puting the coefficients in these functions. Note that
while the method described in Section 4 provides for
evaluating the overall robustness of a Bayesian net­
work, the method described in this section is provides
for getting insight in the spread of influence from sep­
arate parameters.
The method of Castillo et a!. (1997) and the method of
Coupe & van der Gaag (1998) can be exploited for es­
tablishing the coefficients in the sensitivity functions
for all possible output probabilities, requiring three
propagations per posterior marginal. Building upon
the ideas put forward in the previous section, how­
ever, a more efficient method is obtained. Theorem 5
provides the basis for our method.
Let the junction tree T be as before.
Also, let y
p(afe) and x
p(bl1r) be as be­
fore. Suppose that, in T, an inward propagation has
Theorem 5

=

8. Compute a�a and f3�a, using (9).

'Y

=

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

322

been performed towards a clique containing the vari­
able B to which the parameter x pertains. Then,
p(e)(x) ="(X+ J with

'Y = O:a + O:�a and J =f3a + f3�a,

(11)

where O:a,f3a and a.�a,f3�a are as in equation (9), ob­
tained from two outward propagations with two dis­
tinct values for x.
Proof: Let K be a clique containing both the variable
B and its set of parents II = pa(B). Let x1 and x2
denote two different values of the parameter x. From
the outward propagation using x1 from clique K, we
obtain the probability vector p(A,e)(x1) = (y�, Y�a)
through marginalization of the clique potential for a
clique H containing A. Similarly, from the outward
propagation with x2, we find the vector p'(A,e)(x2) =

(y�, Y�a)·

From

6

n-WAY SENSITIVITY ANALYSIS

So far, we have addressed one-way sensitivity analy­
ses only, in which the effects of separate parameters
are studied. In this section, we turn our attention to
more general n-way analyses in which the effects of
simultaneous variation of n parameters are studied.
One can regardn-way sensitivity analysis as involving
analyses of joint effects for all subsets of size n or less
of all, say m, relevant parameters. Using the method
of Castillo et al. (1997), this would involve L:::�=l

( 7)

separate analyses and I::�=I ri
probability propa­
gations to compute the 2n coefficients, assuming r-ary
variables.

( 7)

Provided the n parameters all belong to the same
clique, Theorem 6 below states that we only need
one propagation to compute the 2n coefficients, but
I::�= I
local computations involving marginaliza­
tions of clique potentials.

( 7)

=

we get the result stated in the theorem.

0

Theorem 5 provides the basis for our method for com­
puting the coefficients in the functions expressing all
possible output probabilities y = p(a I e) in a single pa­
rameter x p(blrr). The method is composed of the
following steps:
=

1. Enter the evidence e into the junction tree and
perform an inward and an outward propagation
using an arbitrary root clique.
2. Compute the probability vector p(A,e )
(y�, Y�a) through marginalization of the clique po­
tential for a clique H containing A, for all vari­
ables of interest.
3. Change the value of parameter x and perform
an outward propagation from a clique containing
both the variable B and its parents.
4. Compute the probability vector p'(A,e) =
(y�, Y�a) through marginalization of the potential
for clique H, for all variables of interest.

In essence, Theorem 1 states that the mathematical
expression for a probability, p(e)(x), of a vector of in­
stantiations, e, as a function of a probability parame­
ter, x, takes the form of a linear function of x. The­
orem 6 generalizes this statement to the case with n
parameters, x1,. . . , Xn, and states that the resulting
function is a multilinear function in x1, ... , Xn.
To simplify the exposition, we shall assume that the
parameters are independent; that is, for each pair of
parameters, x; = p(bx; lrrx;) and Xj = p(bx; lrrx;), with
the associated variables Bx;, IIx;, Bx;, and IIx;, it
holds true that rrx; # rrx;, Bx; (j. IIx;, and Bx; (j.
IIx;. To generalize the theorem to cover the case of
dependent parameters is fairly straightforward.
Let p be the probability function for a
Bayesian network, where evidence e has been prop­
agated in a junction tree, T, for the network. Let
X
{ x1, . . . , Xn} be a set of parameters of the net­
work, where, for each i = 1, . . . ,n,

Theorem 6

=

X;= p(bx; lrrx;),
with the associated variables, Bx; and IIx;, being
members of a clique, C, in T. Then

p(e)(X) =

5. Compute a.a, a.�a, f3a, and f3�a, using the equation
(9) from Theorem 3.
6. Compute

'Y

and J, using the equation (11).

We would like to note that our method requires just
one inward and two outward propagations to estab­
lish all sensitivity functions for a specific probability
parameter.

L 'Yx(Z) II

z�x

z

+

zEZ

L

1/Jc,

C:ll#1r

where II= {IIx,,...,IIxn }, rr= (rrx,,...,rrxn ), and

'Yx(Z) = (-1)1X\ZI
where

fx(Y)

(-1)1X\YI

L !x(Y),

y�z

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

323

If, instead of summing over subsets S � X\Z, we sum
over the subsets of Z and takes care that the signs of
the terms are preserved, we get the desired result. D
where¢>c = p(C,e), W = X\Y
{w1, ,wk },
k = ! W I , by= (byp···,byiY1), b� = (b:n ,,... ,b: n1w1),
and Px, denotes the initial value of Xi.
=

•

•

•

Proof: Using the same procedure as in the proof of
Theorem 1 we get

p(e)(X)

(� )
(F � c,o�,�·�. /
L L
(X)

¢>c

=

c+

=

·

b'zt

�/c) (X)

c

·· P(b�1 !1l"x,)(xr) · · · p(b�n !1l"xn )(xn)
b'Zn

Lc.·b'zl ,... ,b':l!n ,1f ¢>c
p(b�,17l"x,) ...p(b�n 11l"xJ

+

L

C:0¥71"

¢>c.

L:: li

L:: ...

z

p(b�, !1ru,)(ur)

· .

flzEZ p(bz !1rz ) fluEU p(b� i1ru )
C:07"'7r

+

p(b�, l1ru,)(ur) · p(b�1u1 l1ru1u1)(uiUI)

=

uEU
=

II

· ·

p(b� 17ru)
p(b� 17ru)
-U
1-p(bul1ru)
1 -p(bu l1ru)

�;

(b� 1l"u
1 p( u I u)
uEU

�

)

II x (13)
(-1)ISI
.
xES
sr::;u

(L

)

Inserting (13) in (12) and rearranging terms yields
p(e)(X)

=

L IT L
z

Z<;;X zEZ S<;;U

n

,

p(e)(X)=

(-1)ISI

IT x

xES

L r(Z) II

Z<;;X

z

+

zEZ

J.

(15)

Through one-way analysis involving the parameter x
we obtain the constants ax and f3x in
=

axx + f3x·

The 2n constants in (15) are related to ax and f3x
in the way that ax equals the sum of all coefficients,
r (Z), for which xE Z, and f3x equals the sum of the
remaining coefficients. That is,
ax=

f3x

(12)

¢>c,

=

(

.

and

where U = X\ Z
{u1,... ,uiU I}. Now, expand­
ing the terms p(b� 17ru)(u), uE U, using (1), an easy
calculation yields

II

•

· p(b�1u111l"uiui)(uiUI)

Lc:bz,b;_,,11" ¢>c

L

•

p(e)(x)

The multiple sum can be grouped into sums over the
subsets Z � X such that b� = bz for each zE Z:
p(e)(X)

Note that, since the computation of /X (X) ranges over
all subsets of X, rx(Z) can be computed, for each
Z C X, as a sum over a subset of the terms involved
in the computation of 'Yx(X)
.
The result presented in Theorem 6 is limited in the
sense that all parameters under investigation must
belong to the same clique in the junction tree. We
shall now present a more general method which uti­
lizes the results obtained by lower-order analyses. Let
X n } be the
parameters under investi­
X { x1 ,
gation and write

=

L
L

r (Z)

(16)

r (Z) + J.

(17)

Z<;;X:xEZ

Z<;;X:x{lZ

... , n,

2

Thus, for each one-way analysis of a parameter Xi,
i
1,
we obtain equations of the form (16)
and (17). In addition, we obtain the equation
=

p(e)

=

L

Z<;;X

r (Z)

II Zo + J,

(18)

zEZ

2n

where z0 denote the value specified for parameter z in
the Bayesian network. This gives us a total of
+ 1
equations. However, we need (at least) 2n equations
to compute the 2n coefficients.
Now, if for each parameter, z E Z, we assign a new
value and perform a full propagation, then we obtain
an additional
+ 1 equations. Thus, we can obtain
at least 2n equations by performing

2n

2
l2n : 1J

full propagations with different parameter values, in
addition to the initial propagation performed for the

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

324

one-way analyses. For example, to perform 4-way
analyses, a total of two full propagations is sufficient.
This result can be generalized very easily, since each
m-way analysis gives rise to 2m equations of the form
(16) and (17). Thus, to perform n-way analyses, where
n > m, we need at most

( )

additional propagations, as there are ;:, relevant m­
way analyses. So, for example, if we have performed
2-way analyses and want to perform 5-way analyses,
no further propagations are needed.
7

CONC LUD ING REMARKS

We have presented methods for sensitivity analysis
of Bayesian networks which are significantly more ef­
ficient than current methods. In the case of one­
way analysis, the number of probability propagations
of current methods grows linearly in the number of
relevant parameters, whereas the methods presented
above only requires one inward and one or two out­
ward propagations, no matter the number of relevant
parameters.
To substantiate the importance of this difference, we
have investigated three real-world networks to get an
idea of the typical number of relevant parameters in
a realistic scenario. All three networks are from the
medical domain: a subnetwork of Munin (Andreassen
et a!. 1989) containing 1003 variables, a network mod­
elling the pathophysiology of ventricular septal defect
(Coupe et al. 1999) containing 38 variables, and a net­
work related to disorders in the oesophagus containing
70 variables. The investigation were conducted using
real patient data involving, respectively, 15, 5, and 3
patients. The average number of relevant parameters
were found to be 16313, 738, and 992, respectively.
(Since no censoring of parameters representing func­
tional relationships were performed on parameters for
the Munin network, the figure 16313 is probably some­
what overestimated.)
Efficient methods for sensitivity analysis play an im­
portant role in both the knowledge acquisition and the
validation phases for manually constructed Bayesian­
network models.
Coupe et al. (1999) reports on an empirical study using
sensitivity analysis to focus attention on the most in­
fluential parameters in the knowledge acquisition pro­
cess, thereby considerably reducing the time required
to acquire the parameter values.
The validation phase involves two aspects: fine-tuning
and robustness analysis. The fine-tuning aspect in-

volves adjustment of the parameter values to make the
network respond correctly to a number of test cases.
A gradient descent approach is useful for that purpose
(cf. neural network type training), where the gradi­
ent of a posterior marginal with respect to a subset of
parameters can easily be computed through a minor
modification of the algorithms for sensitivity analy­
sis. Based on the work described in the present paper,
Jensen (1999) has suggested a method for gradient de­
scent training of Bayesian networks.
Once a network has been fine-tuned, and thus responds
correctly on a selection of test cases, the robustness
of the network may be investigated. This involves,
in essence, determining lower and upper bounds for
parameter values for which the output of the network
still agrees with the test cases. A parameter value
close to one of the bounds indicate a possible lack of
robustness. Given analytic expressions for the outputs
in terms of the parameters, derived by e.g. methods
described in the present paper, these bounds are easily
determined.
The time complexity ofn-way sensitivity analysis may
be fairly high for large n, even with the methods pre­
sented in this paper. Also, our method assumes that
the variables and the parents associated with then pa­
rameters reside in the same clique in a junction tree.
The method of Coupe et al. (2000) for n-way sensitiv­
ity analysis is based on propagation of tables of coeffi­
cients in a junction tree, and, therefore, has a (poten­
tially very much) larger space requirement. However,
their method is general in the sense that it does not
put any restrictions on the location of the parameters.
During the initial phase of the
work, the authors received valuable comments from
Finn V. Jensen. Also, he suggested the basis for the
general method for n-way analysis, described at the
end of Section 6.
Acknowledgements

The research has been partly funded by the Danish
National Centre for IT research, Project no. 87.2.



Straightforward sensitivity analysis of a probabilistic net­
work is highly time-consuming. The probability of interest

With the advance of efficient algorithms for

sen­
sitivity analysis of probabilistic networks, study­

has to be computed from the network for a number of devi­

ing the sensitivities revealed by real-life net­

eter. Even for a rather small network, this easily requires

works is becoming feasible. As the amount of
data yielded by an analysis of even a moderately­
sized network is already overwhelming, effective
methods for extracting relevant information from
these data are called for.
to study the

derivatives

One such method is

of the sensitivity func­

tions yielded, to identify the parameters that upon
variation are expected to have a large effect on
a probability of interest. We further propose to
build upon the concept of

admissible deviation,

which captures the extent to which a parameter
can be varied without inducing a change in the
most likely outcome.

We illustrate these con­

cepts by means of a sensitivity analysis of a real­
life probabilistic network in the field of oncology.

ations from the original assessment for every single param­
thousands of propagations.

Recently, however, efficient

algorithms for sensitivity analysis have become available,
rendering analysis of real-life probabilistic networks feasi­
ble [2, 3]. These algorithms build upon the observation that
the sensitivity of a probability of interest to parameter vari­
ation complies with a simple mathematical function; this

sensitivity function

basically expresses the probability of

interest in terms of the parameter under study. Computing
the constants for these sensitivity functions requires just a
limited number of propagations.
Sensitivity analysis of a real-life probabilistic network
tends to result in a huge amount of data. For example, for a
real-life network in the field of oncology, comprising some
lOOO parameters, we found that a single analysis yielded
close to 5000 sensitivity functions with two or three con­
stants each. Because the sensitivities exhibited by a prob­

1

abilistic network typically change with evidence, such

Introduction

The numerical parameters for a probabilistic network are
generally estimated from statistical data or assessed by hu­
man experts in the domain of application. As a result of
incompleteness of data and partial knowledge of the do­
main, the assessments obtained inevitably are inaccurate.
Since the outcome of a probabilistic network is built upon
these assessments, it may be sensitive to the inaccuracies
involved and, as a result, may even be unreliable.
The reliability of the outcome of a probabilistic network
can be evaluated by subjecting the network to a

analysis.

an

analysis has to be performed a number of times. For our

sensitivity

In general, sensitivity analysis of a mathematical

model amounts to investigating the effects of inaccuracies
in the model's parameters by systematically varying the
values of these parameters [1]. For a probabilistic network,
sensitivity analysis amounts to varying the assessments for
one or more of its numerical parameters and investigating
the effects on, for example, a probability of interest [2].

network, for example, we conducted over 150 analyses in­
volving data from real patients. For extracting relevant in­
formation from the data thus generated, effective methods
are called for that allow for (automatically) identifying pa­
rameters that are quite influential upon variation.

These

parameters should be selected for further investigation as

the inaccuracies in their assessments are likely to affect the
network's outcome.
In her work on sensitivity analysis of probabilistic net­
works, K. Blackmond Laskey introduced the concept of

sensitivity value [4]. The concept builds upon the (par­
derivative of the sensitivity function that expresses the

tial)

network's probability of interest in terms of a parameter

under study: the sensitivity value is the absolute value of
this derivative at the original assessment for the parame­
ter. As currently available algorithms for sensitivity anal­
ysis of probabilistic networks yield the probability of in-

UAI 2001

VAN DER GAAG & RENOOIJ

terest explicitly as a fimction of the parameter under study,
the derivative and its associated sensitivity value are read­
ily determined. In this paper, we study the derivatives of
sensitivity functions and show how sensitivity values can
be used for selecting parameters for further investigation.
In many real-life applications of probabilistic networks, the
outcome of interest is not a probability, but rather the most
likely value of a variable of interest. In a medical applica­
tion, for example, the outcome of interest may be the most
likely diagnosis given a patient's symptoms and signs. For
this type of outcome, the derivative of a sensitivity fimction
and its associated sensitivity value are no longer appropri­
ate for establishing the effect of parameter variation: a pa­
rameter with a large sensitivity value may upon variation
not induce a change in the most likely outcome, while a
parameter with a small sensitivity value may induce such a
change for just a small deviation from its original assess­
ment. To describe the sensitivities of this type of outcome,
we introduce the concept of admissible deviation. This
concept captures the extent to which a parameter can be
varied without inducing a change in the most likely value
for the variable of interest. We show how the concept of
admissible deviation can be used for selecting parameters.
The various concepts introduced in this paper will be illus­
trated by means of a sensitivity analysis of a moderately­
sized real-life probabilistic network in the field of oncol­
ogy. We would like to note that this network exhibits con­
siderable sensitivity to parameter variation. This observa­
tion contradicts earlier suggestions that probabilistic net­
works are highly insensitive to inaccuracies in the assess­
ments for their parameters I 5, 6]. Our results now seem
to indicate that the sensitivities exhibited by probabilistic
networks may vary from application to application.
The paper is organised as follows. In Section 2, we provide
some preliminaries on sensitivity analysis of probabilistic
networks. In Section 3, we briefly discuss the oesophagus
network with which we will illustrate the concepts intro­
duced in the subsequent sections. In Section 4, we study
the derivative of a sensitivity function and its associated
sensitivity value. In Section 5, we introduce the concept
of admissible deviation and discuss its use for extracting
relevant information from sensitivity data. The paper ends
with our conclusions and directions for further research in
Section 6.
2

Preliminaries

Sensitivity analysis of a probabilistic network amounts to
establishing, for each of the network's numerical parame­
ters, the sensitivityfunction that expresses the probability of
interest in terms of the parameter under study. In the sequel,
we denote the probability of interest by Pr( A a I e ) , or
Pr(a I e) for short, where a is a specific value of the vari­
able A of interest and e denotes the available evidence. The
=

531

network's parameters are denoted by x = p(bi I 1r), where
bi is a value of a variable B and 1r is a combination of val­
ues for the parents of B. We write !Pr(ale)(x) to denote the
sensitivity function that expresses the probability Pr(a I e )
in terms of the parameter x; for ease of exposition, we will

often omit or abbreviate the subscript for the fimction sym­
bol f, as long as ambiguity cannot occur.

Upon varying a single parameter x p(bi I 1r) in a prob­
abilistic network, the other parameters p(bi I 1r), j =f:. i,
specified for the variable B need to be co-varied. Each pa­
rameter p(bi I 1r) can thus be seen as a function gj(x) of
the parameter x under study. In the sequel, we assume that
the parameters p(bj I 1r) are co-varied in such a way that
their mutual proportional relationship is kept constant, that
is, a parameter p(bi I 1r ) is co-varied according to
=

if j

=

i

otherwise
for p(bi I 1r) < 1.
Under the assumption of co-variation described above, a
sensitivity function f(x) is a quotient of two functions that
are linear in the parameter x under study [2, 7]; more for­
mally, the function takes the form

f(x)

x+ b
c·x+ d

=a ·

where the constants a, b, c, and d are built from the assess­
ments for the numerical parameters that are not being var­
ied. From this property we have that a sensitivity function
is characterised by at most three constants. These constants
can be feasibly determined from the network, for example
by computing the probability of interest for a small num­
ber of values for the parameter under study and solving the
resulting system of equations [2]. An even more efficient
algorithm that is closely related to junction-tree propaga­
tion, is available from [3].
3

The oesophagus network

The oesophagus network that will be used to illustrate con­
cepts throughout this paper, is a real-life probabilistic net­
work for the staging of oesophageal cancer. The network
was constructed and refined with the help of two experts
in gastrointestinal oncology from the Netherlands Cancer
Institute, Antoni van Leeuwenhoekhuis, and is destined for
use in clinical practice [8].
As a consequence of a lesion of the oesophageal wall, a
tumour may develop in a patient's oesophagus. The char­
acteristics of the tumour, such as its location in the oe­
sophagus and its macroscopic shape, influence the tumour's
prospective growth. The tu±nour typically invades the oe­
sophageal wall and upon further growth may affect neigh-

VAN DER GMG & RENOOIJ

532

UAI 2001

\..Gutro-eirrami

�--��--.��F��

""""""""'

-:'

I
...
.
--

CT.­

': "

Figure 1: The oesophagus network.
bouring organs. In time, the tumour may give rise to lym­
phatic and haematogenous metastases. The characteristics,
depth of invasion, and extent of metastasis of the cancer
largely influence a patient's life expectancy and are indica­
tive of the effects and complications to be expected from
the various therapeutic alternatives. The three factors are
summarised in the stage of the cancer, which can be ei­
ther I, IIA, liB, III, IVA or !VB, in the order of progressive
disease. To establish the stage of a patient's cancer, typi­
cally a number of diagnostic tests are performed, ranging
from biopsies of the primary tumour to gastroscopic and
endosonographic examinations of the oesophagus.
The oesophagus network is depicted in Figure 1. It cur­
rently includes4 2 variables. The number of values per vari­
able ranges between two and six, with an average of 3.4.
The number of incoming arcs per variable ranges between
zero and three with an average of 1.7; the average number
of outgoing arcs is 2.5, with a minimum of zero and a maxi­
mum of 11. For the network, a total of932 probabilities are
specified. The variable with the largest number of proba­
bilities, 144 , models the stage of the cancer; this variable is
deterministic. The largest number of probabilities specified
for a non-deterministic variable is 80.
Building upon the concepts outlined in Section 2, we per­
formed a sensitivity analysis of the oesophagus network.
We took the probability of a specific stage for the proba­
bility of interest. As six different stages are defined, we
performed six separate analyses, each time focusing on an-

other stage. Of the prior network, that is, the network with­
out any evidence entered, we found 206 of the 932 param­
eters to be influential upon variation. For these parameters,
the analyses yielded a total of 1236 sensitivity functions
with two or three constants each. Because a network's
sensitivities typically change with evidence, we repeated
the analysis with data entered from 156 patients diagnosed
with oesophageal cancer. The number of data entered per
patient ranged between 6 and 21, with an average of 14 .8.
The parameters that we found to be influential upon vari­
ation differed between patients. The number of influential
parameters also differed considerably and was found to be
as high as 826.
4

The derivative and its sensitivity value

For extracting relevant information from the huge amount
of sensitivity data that is typically generated from a proba­
bilistic network, effective methods are needed. In this sec­
tion, we discuss a method for this purpose that is based
on the derivative of a sensitivity function and its associated
sensitivity value. This method provides for selecting pa­
rameters that upon variation have a large effect on a proba­
bility of interest. In the next section, we introduce another
method, based on the concept of admissible deviation, that
focuses on the most likely value of a variable of interest.
In Section 2, we argued that the sensitivity of a probability
of interest to variation of a parameter x can be expressed as

VAN DER GMG & RENOOIJ

UAI 2001

a function f ( x) of the form
f(x)

effect may break down rapidly, as noted before by Laskey
[4]. For some parameters, it may be that the sensitivity val­

a· x + b
=
c·x+d

ues for slightly smaller assessments are very large and the
sensitivity values for slightly larger assessments are quite

The first derivative r ( X) of this function is

especially the sensitivity values become quite large. Find­

The probability of interest is sensitive to deviations from
the original assessment x0 of the parameter under study, if

lf'(xo)l

is greater than zero.

As an example, Figure 2 depicts a sensitivity function that
we found for the oesophagus network. The function shows

p(Sono-cervix = yes I
probability Pr(Stage = III I

the effect of varying the parameter
=

no) on the

specific patient. The assessment for the pa­
=

0.07. For this assessment, we
find a sensitivity value of 0.53, which indicates that devia­
rameter under study is x0

tions from the original assessment would not greatly affect
the probability of interest. If the assessment would have
been 0.02 rather than 0.07, however, a much larger sensitiv­
ity value, of

4.74, would have been found, which indicates

that even minor deviations would have had a considerable
effect. For the value
value of just

0.07

ample, this property holds: the sensitivity value of the orig­

ing a relatively small sensitivity value for a parameter's as­

·

Metas-cervix
case 6) for a

small. For the parameter under study in Figure 2, for ex­
inal assessment is rather small, but for smaller assessments

a·d-b·c
f'(x) =
(c x + d)2

the sensitivity value

533

0.20,

on the other hand, a sensitivity

is found. If the assessment for the pa­

rameter would have been 0.20, therefore, deviations would
have had hardly any effect on the probability of interest.
Based upon the concept of sensitivity value, we might con­
clude that the parameters for whose assessments the sensi­
tivity values are the largest, are the most likely to be quite
influential upon variation and therefore should be selected
for further investigation. Sensitivity values, however, pro­
vide insight in the effect of small deviations only from a
parameter's assessment. When larger deviations are con­
sidered, the quality of the value

as

an approximation of the

sessment is therefore no guarantee that the probability of
interest is hardly affected by variation of this parameter.
From our discussion of the sensitivity function shown in
Figure 2, we have that the quality of a sensitivity value
for indicating the effect of parameter variation decreases
as the parameter's original assessment lies closer to the x­
coordinate of the function's

Therefore, to de­

"shoulder".

cide whether or not the probability of interest is likely to
be affected by inaccuracies in the assessment for a specific
parameter, we should consider not just the associated sen­
sitivity value but also the distance of the assessment to the
x-coordinate of the shoulder of the sensitivity function. We
define the concept of shoulder more formally.
A sensitivity function is either a linear function or a hyper­
bola. For

c = 0,

for example, the sensitivity function is

linear, as we then have that

f(x) =a·x + b = a·x + b
c·x+d

d

=

�.
d

x

+

�
d

If the sensitivity function is not linear, it takes the form of
a hyperbola:
f(x)

1"

x

=-

-s

+ t,

with

c2

1" = --:::­

s =

d
--,
c

and t

=

a
-

c

For ease of reference, Figure 3 depicts the general shape of
a hyperbola. The hyperbola has two asymptotes, parallel
to the x- andy-axes, in x
�
"'

.."

=

sand f(x)

= t, respectively.

The hyperbola further is symmetrical in the line that has

0.8

an absolute gradient of 1 and goes through the intersection

d
<>

point (s, t) of the hyperbola's asymptotes. The point

§" 0.6
II

is termed the

.."'
§.d 0.4

center

(s, t)

of the hyperbola. The point at which

the hyperbola intersects with the line in which it is symmet­
rical, is called the vertex of the hyperbola; this vertex is the

0::

point referred to before as the function's shoulder. As the

0.2

symmetry line has a gradient with an absolute value of

1,

the gradient of the hyperbola at the vertex also has an abso­
OL_�___L______L-----�------�----�
0
0.2
0.4
0.6
0.8
xo

p(Sono-�eTuiz = yes!Meta.:'I-CeTvix =no)

Figure

2:

Pr(Stage = III I case 6) in terms of the pa­
= p(Sono-cervix =yes I Metas-cervix = no).

probability
rameter x

The sensitivity function J(x) expressing the

lute value ofl. Using this property we can easily determine
the x-coordinate x of the vertex:

'
lf (x)l

=

I (x =rs)2 1

=

1 ¢::::::> x = s ±

vfrT

We now return to a sensitivity function f(x) expressing a

534

VAN DER GAAG & RENOOIJ

j(x)

,,

,,

,'/
t

--

�

,

,
-'

)

_

,,

,

,
,,

UAI 2001

tivity value can be used for selecting parameters that upon

,

variation have a large effect on a specific probability of in­
terest. Often, however, we are interested not in the effect of
parameter variation on a probability of interest, but in the
effect on the most likely value for a variable of interest. In
a medical application, for example, the most likely diagno­

vertex

sis given a patient's symptoms and signs may be the out­
come of interest. For this type of outcome, the derivative

45°

________________________________ _

center

of a sensitivity function and its associated sensitivity value
are no longer appropriate for establishing a parameter's ef­
fect upon variation. For some parameters, deviation from
their original assessment may have a considerable effect on

X

s

the probability of a specific outcome and yet not induce a
Figure3: Ahyperbolaf(x).

change in the most likely one; for other parameters, varia­

network's probability of interest in terms of a parameter x

nonetheless result in a change in the most likely outcome.

under study. As noted above, if this function is not linear, it

We would like to note that the idea of focusing on the most

takes the form of a hyperbola. The center of the hyperbola

likely value of a specific variable conforms to the practice

tion may have little effect on the probabilities involved and

is

(- �, �).

Because a sensitivity function is defined on

of sensitivity analysis of decision-theoretic models where

[9].

the entire probability interval [0, 1] and moreover is non­

the most preferred decision is the outcome of interest

negative, we have that -4
< 0 and .!!.
> 0. For the xc
c -

To provide for studying the effects of parameter variation

coordinate x of the vertex of the hyperbola, we find

,

x=

in view of a most likely outcome, we enhance the basic
method of sensitivity analysis for probabilistic networks

-d
± Jia d-b · c l
-___!_...!..._
...:

with the computation of an interval within which a param­

·

-

___

c

eter can be varied without inducing a change in the most

For the sensitivity function shown in Figure 2, for example,

the x-coordinate of the vertex of the hyperbola is x
We observe that the original assessment x0

=

=

0.05.

0.07 for the

likely value of a variable of interest. Now, let A be the

variable of interest. Let x be the parameter under study and
let xo be its assessment. The admissible

( r, s)

parameter under study lies quite close to this coordinate.

is a pair of real numbers

We recall that the sensitivity value for x0 is just 0.53. Be­

between the bounds max(xo

cause the assessment lies close to x, however, the sensitiv­
ity value cannot be considered a good approximation of the

effect of the parameter's variation: small deviations from
the assessment, especially to smaller values, have a con­
siderable effect on the probability of interest. We conclude
that this parameter should be selected for further investiga­

deviation

for x0

such that x0 can be varied

- r,

0) and min ( xo +

s,

1)

without inducing a change in the most likely value for the

variable A;

r

and s, moreover, are the largest numbers for

which this property holds. Note that the interval within
which a parameter can be freely varied can be bounded
for two reasons: either the most likely outcome changes

if the parameter is varied beyond the specified boundary,

tion, regardless of its small sensitivity value.
From the above observations, we have that for extracting

from the sensitivity data the parameters that deserve fur­
ther attention, parameters whose assessment has a sensi­
tivity value larger than 1 should be identified. In addition,
parameters whose original assessment lies close to the

x­

coordinate of the vertex of the associated sensitivity func­
tion should be selected.
To conclude our discussion of sensitivity values, we would
like to note that in the analysis of the oesophagus network
we found rather strong sensitivities. An example is shown

0.2

in Figure 4: for the parameter under study, a sensitivity
value of6.97 was found.

5

Admissible deviation

In the previous section, we focused on the derivative of a
sensitivity function and showed how its associated sensi-

Q UL------�

0.02

Figure

p(X-lung�

=

1/MIMetas-lungs

T he sensitivity function

4:

f(x)

=

110)

expressing the

Pr(Stage = IVB I case 1) in terms of the pa­
p(X-lungs yes I Metas-lungs = no).
rameter x
probability

=

=

VAN DER GAAG & RENOOIJ

UAI2001

or the boundary of the probability interval

[0, 1]

has been

535

Metas-lungs = no)

on the probabilities of the various

reached. To express that a parameter can be varied as far as

different values of the variable

the boundary of the probability interval, we use the symbol

tient. From the figure, it is readily seen that the param­

oo

eter's assessment has associated a small sensitivity value

in the admissible deviation associated with its assess­

Stage

for a specific pa­

ment.

from each of the sensitivity functions. The sensitivity func­

The admissible deviation for a parameter's assessment can

tion f1v8(x), for example, that expresses the probability
Pr(Stage = IVB I case 138) in terms of the parameter

be computed from the sensitivity functions
are yielded for the various values

a,

!Pr(a;le)

that

of the variable A.

under study, is

f

More specifically, the admissible deviation is established

xo
ai is the most likely value for

(

!VB X

by studying the points at which two or more of these func­

)

tions intersect. Suppose that for the original assessment

of the parameter x, the value

lf:vs(0.05)I = 0.71145

tion, that neither of the bounds of the admissible deviation

(r, s) ,

oo.

The admissible deviation for x0 now is the pair

where the leftmost deviation

number for which x0

-r

r

is the smallest real

is the x-coordinate of a point at

!Pr(a;le)(x) intersects with
fPr(a11e)(x) with j "1- i; the

which the sensitivity function
another sensitivity function
rightmost deviation

s

We further observe that the assessment

x0

=

0.05 for the

parameter lies relatively far from the x-coordinate i; of the
function's vertex:

i;

is defined analogously.

=

-1.17403+yi0.09208·l.l7403-1 '17403·11
1

-0.14

We present various examples to illustrate the difference be­
tween using sensitivity values and admissible deviations for

0.09208 ·X + 1.17403
X+ 1.17403

from which we find a sensitivity value of

the variable of interest. Also suppose, for ease of exposi­
equals

_

-

Based on the concept of sensitivity value as discussed in the

studying the effects of parameter variation. The examples

previous section, we conclude that the parameter does not

are taken from patient-specific analyses of the oesophagus

deserve additional attention. Inspection of Figure 5 now

network. The figures used display the sensitivity functions

further reveals that the admissible deviation for the param­

yielded for all the values of the variable

eter's assessment equals

Stage

that models

the stage of a patient's cancer. As we are now considering

( oo, oo) ,

which indicates that the

parameter can be varied over the entire probability interval

a variable of interest rather than a probability of interest,

[0, 1]

using the concept of sensitivity value for selecting interest­

Based on the concept of admissible deviation, therefore,

ing parameters amounts to examining the sensitivity values

the parameter should also be further disregarded.

from all functions for the parameter under study.

without inducing a change in the most likely stage.

For our next example, we consider a parameter that induces

Our first example addresses a parameter that induces small

large sensitivity values, but upon variation is not expected

sensitivity values and upon variation does not result in a

to result in a change in the most likely outcome. The sensi­

change in the most likely outcome. The sensitivity func­

tivity functions for the parameter are depicted in Figure

tions for the parameter are depicted in Figure 5: the fig­

the figure shows the effects of varying

ure shows the effects of varying

x = p( CT-lungs = yes I

yes I Metas-loco = no)

x

=

p( CT-loco

6:
=

on the probabilities of the dif-

0.6 ,-------,
IIA
"'
""
•
.,

�

8

"'
�

0.4

•

�
Q:

0.05

p(CT-Iung• = ye•IMetas-lungs =no)

5: The sensitivity functions expressing the prob­
Pr(Stage I case 138) in terms of the parameter
p(CT-lungs =yes I Metas-lungs =no).
Figure

abilities

p(CT-Ioco

=

li""IMetas-loco =no)

6: The sensitivity functions expressing the prob­
Pr(Stage I case 82) in terms of the parameter
p(CT-loco =yes I Metas-loco =no).
Figure

abilities

536

VAN DER GMG & RENOOIJ

Stage. For the parameter's
0.02, large sensitivity values

ferent values of the variable

original assessment x 0

=

are found from some of the six functions.

UAI 2001

computed to be

(0.10, oo).

As the leftmost deviation is

quite small compared to the assessment

0.20,

we find that

For example,

the parameter deserves further investigation. We would like

from the sensitivity function that expresses the probability

to note that, if the original assessment had been in the inter­

Pr(Stage

=

IIA

sitivity value of

I case 82) in terms of the parameter, a sen­

2.07 is found.

W hen studying the effects of

variation on the probabilities of interest, therefore, the pa­
rameter should be selected for further investigation. Now
consider the effects of variation on the most likely value
of the variable

Stage.

For the parameter's assessment xo,

we find that stage III is the most likely stage for the patient
under study. The sensitivity function for this stage inter­
sects with the sensitivity function for stage IIA at x

= 0.17.

Further inspection of the figure reveals that the admissible
deviation for the parameter's assessment is

(oo, 0.15).

We

observe that the rightmost deviation is relatively large com­
pared to the original assessment.

We therefore conclude

that inaccuracies in the assessment are not reasonably ex­
pected to affect the most likely outcome, and the parameter
should not be selected for further investigation.

values but upon variation affects the most likely outcome.
Figure 7 depicts the sensitivity functions for the parameter

x

= p(Wall-inv = T2 I Shape = polypoid, 5 :::; Length <
lOcm). For the original assessment x0 = 0.2 of the pa­

rameter, the largest sensitivity values are found from the

lf{IA(Q.2)1
lf{u(0.2)[

=

=

III:

then the sensitivity values would not have

extremely small for both directions of variation.
Our final example pertains to a parameter that induces large
sensitivity values and upon variation is expected to result
in a change in the most likely outcome.

The sensitivity

8: the
p( CT-organs =

functions for the parameter are displayed in Figure
figure shows the effects of varying x

medias! llnv-organs

=

none).

=

From two of the sensitivity

functions, we find relatively large sensitivity values:

lf{1A(0.05) I
lf{n (0.05) I

1.34333
0.99446

In addition, the original assessment x0

= 0.05

for the pa­

xm of the vertices of the two functions:

XnA
:i:m

= 0.0597
0.0499

Based upon the concept of sensitivity value, therefore, the
parameter should be selected for further investigation. We
now consider the effects of variation on the most likely out­
come. We observe that for the original assessment the most

0.32151
0.34832

likely stage is IIA. The admissible deviation for the assess­
ment is computed to be

As the sensitivity functions are linear in the parameter
under study, the computed sensitivity values describe the
effects of variation exactly.

[0.04, 0.10],

changed, but the admissible deviation would have become

rameter lies very close indeed to the x-coordinates :i:nA and

We now address a parameter that induces small sensitivity

functions for the stages IIA and

val

Based upon the concept of

sensitivity value, we therefore conclude that the parame­
ter should not be selected for further investigation. Now,
the admissible deviation for the parameter's assessment is

(0.002, oo).

We observe that the

leftmost deviation is extremely small, indicating that an in­
accuracy by just

0.002 in the original assessment will lead
Stage and

to a different most likely value for the variable

may in fact result in a different treatment decision for the
patient under consideration.
The above examples illustrate that admissible deviations

0.6 ,-------,---,

IIA

0.6

��-�-------j iiA
-------.__.j ill
0.2

0.2

p(Wall·inv

= T2ISI>ape =polypoid, 5::;

0.05

Length< 10)

Figure 7: The sensitivity functions expressing the prob­

Pr(Stage I case 120) in terms of the parameter
p(Wall-inv = T2[Shape =polypoid, 5:::; Length< 10cm).
abilities

p(CT-organl! = m.edia.!tllnv-organ.s =none)

8: The sensitivity functions expressing the prob­
Pr(Stage I case 63) in terms of the parameter
p(CT-organs =medias! [Inv-organs =none).
Figure

abilities

UAI 2001

VAN DER GAAG & RENOOIJ

provide additional insight into the sensitivity of a proba­
bilistic network's outcome to inaccuracies in its parame­
ters. We would like to note that the use of admissible de­
viations is especially of interest when decisions are to be
based on the most likely value of a variable of interest [10].

537

Acknowledgements. This research has been (partly) supported
by the Netherlands Computer Science Research Foundation with
financial support from the Netherlands Organisation for Scien­
tific Research (NWO). We are most grateful to Babs Taal and
Berthe Aleman from the Netherlands Cancer Institute, Antoni van
Leeuwenhoekhuis, who spent much time and effort in the con­

struction of the oesophagus network.

6

Conclusions


