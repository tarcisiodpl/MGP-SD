

no restriction that a valid plan need have any sort of
compact (polynomial-size) representation.

We examine the computational complexity
of testing and finding small plans in prob­
abilistic planning domains with succinct rep­
resentations. We find that many problems
of interest are complete for a variety of com­
plexity classes: NP, co-NP, PP, NPPP, co­
NPPP, and PSPACE. Of these, the proba­
bilistic classes PP and NPPP are likely to
be of special interest in the field of uncer­
tainty in artificial intelligence and are deserv­
ing of additional study. These results suggest
a fruitful direction of future algorithmic de­
velopment.

These results are not directly applicable to the prob­
lem of finding good plans because they place no re­
strictions on the form of valid plans. It is possible, for
example, that for a given planning domain, the only
valid plans require exponential space (and exponential
time) to write down. Knowing whether or not such
plans exist is simply not very important.

INTRODUCTION

Recent work in artificial-intelligence planning has ad­
dressed the problem of finding effective plans in
domains in which operators have probabilistic ef­
fects (Kushmerick, Hanks, & Weld 1995; Draper,
Hanks, & Weld 1994; Dearden & Boutilier 1997;
Boutilier, Dearden, & Goldszmidt 1995; Boutilier,
Dean, & Hanks 1995). In probabilistic propositional
planning, operators are specified in a Bayes network
or an extended STRIPS-like notation, and the planner
is asked to determine a way of choosing operators to
achieve a goal configuration with some user-specified
probability. This problem is closely related to that of
solving a Markov decision process when it is expressed
in a succinct representation.
In previous work (Littman 1997; Mundhenk, Gold­
smith, & Allender 1996), we examined the complexity
of determining whether a valid plan exists; the prob­
lem is EXP-complete in its general form and PSPACE­
complete when we are limited to polynomial-depth
plans. For these results to hold, plans must be permit­
ted to be arbitrarily complicated objects, and there is

In the present paper, we consider the complexity of
a more practical and realistic problem-that of de­
termining whether or not a plan exists in a given re­
stricted form. The plans we consider take several pos­
sible forms that have been used in previous planning
work: totally ordered plans, partially ordered plans,
conditional plans, and looping plans. In all cases, we
limit our attention to plans that can be expressed in
size bounded by a polynomial in the size of the speci­
fication of the problem. This way, once we determine
that such a plan exists, we have some hope that we
can write it down in a reasonable amount of time.
In the deterministic planning literature, several au­
thors have addressed the computational complexity
of determining whether a valid plan exists, of deter­
mining whether a plan exists of a given cost, and
of finding the valid plans themselves under a vari­
ety of assumptions (Chapman 1987; Bylander 1994;
Backstrom & Klein 1991). These results provide lower
bounds (hardness results) for probabilistic planning,
since deterministic planning is a special case. In deter­
ministic planning, optimal plans can be represented by
a simple sequence of operators (totally ordered plan).
In probabilistic planning, good conditional plans will
often perform better than any totally ordered plan;
therefore, we need to consider the complexity of the
planning process for a richer set of plan structures.
The computational problems we look at are complete
for a variety of complexity classes ranging from NP to
PSPACE. Two results are deserving of special men-

Complexity of Probabilistic Planning

183

tion; first, the problem of evaluating a totally or­

In the fiat representation, the transition function t

dered plan in a succinctly represented planning do­

is represented by a collection of lSI

main (as might be described by a two-stage temporal

We do not treat this representation directly; see our

Bayes network (Boutilier, Dean, & Hanks 1995)) is
PP-complete. The class PP is closely related to #P1,
which has been recognized as an important complex­
ity class in computations involving probabilistic quan­
tities, such as the evaluation of Bayes networks (Roth
1996). Of course, probabilistic computations are cen­
tral to the area of uncertainty in artificial intelligence.
Second, the problem of determining whether a good
totally ordered plan exists for a succinctly represented

x

lSI matrices3.

extended technical report (Goldsmith, Li t tm an , &
Mundhenk 1997) for details on this type of problem.
In the succinct representation, straightforward prob­
ability matrices would be huge, so the transition
function must be expressed another way.

In artifi­

cial intelligence, two popular succinct representations
for probabilistic planning domains are probabilistic
state-space operators (PSOs) (Kushmerick, Hanks, &
Weld 1995) and two-stage temporal Bayes networks

planning domain is NPPP -complete. Whereas the class

(2TBNs) (Boutilier, Dearden, & Goldszmidt 1995).

NP

Although these representations differ in the type of

can be thought of as the set of problems solvable

by guessing the answer and checking it in polynomial

planning domains they can express naturally, they

time, the class

are computationally equivalent ; a planning domain

NPPP

can be thought of as the set of

problems solvable by guessing the answer and checking

expressed in one representation can be converted in

it using a probabilistic polynomial-time computation.

polynomial time to an equivalent planning domain ex­

It is likely that NPPP characterizes many problems of

pressed in the other with at most a polynomial increase

interest in the area of uncertainty in artificial intelli­

in representation size (Littman 1997).

gence; this paper and earlier work

(Mun dhenk,

Gold­

smith, & Allender 1996) give initial evidence of this.
1.1

to representations used in the complexity theory litera­

REPRESENTING DOMAINS

A planning domain

M

=

ture. In the circuit representation, the transition prob­

{S, s0, A, t, 9) is character­

ized by a finite set of states S, a finite set of operators
or actions

A.

an initial state so E S, and a set of goal

states 9 c; S.

The application of an action a in a

state s results in a probabilistic transition to a new
state s', according to the probability transition func­
'
tion t ( s, a, s ) .

The objective is to choose actions to

move from the initial state s0 to one of the goal states

with probability above some threshold ()2.

The

state

of the system is known at all times (fully observable)
and so can be used to choose the action to apply.
We are concerned with two main representations for
planning domains;

fiat

In this paper, we use a different succinct representa­
tion for planning domains that is more closely related

representations, which enu­

merate states explicitly, and succinct representations
(sometimes propositional, structured, or factored rep­
resentations), which view states as assignments to a set
of Boolean state variables. Compared to the size of the
representation, fiat domains typically have a polyno­
mial number of states and succinct domains have an
exponential number (though a "bad" succinct repre­
sentation can be as large as a flat one).
PP
1Toda (1991) showed that p#P =P , from which it fol­
P
lows that NP# =NPPP. Roughly speaking, #P is as pow­
erful as PP if used as an oracle.

21t is also possible to formulate the objective as one of
maximizing expected discounted reward (Boutilier, Dear­
den, & Goldszmidt 1995), but the two formulations are es­
sentially polynomially equivalent (Condon 1992) (the only
difficulty is that succinct domains may require discount
factors exponentially close to one for equivalence to hold).

abilities for an action

a,

t(s, a, s'),

are represented by a

circuit of simple logic gates that takes as input succinct
representations of s and s' and outputs a probability
value in binary representation4.
Planning domains in the PSO and 2TBN representa­
tions can be converted to the circuit representation
in polynomial time, but it is not clear how to con­
vert a circuit to a PSO or

2TBN

in polynomial time.

However, this conversion can be carried out by a PP
machine (the basic idea is used in the proof of The­
orem 2.1), so the circuit representation is equivalent
to PSOs and 2TBNs in any complexity class contain­
ing PP. Since the complexity results we report for the
circuit representation are all for complexity classes at
least as hard as PP, these completeness results apply

to PSOs and 2TBNs as well.

1.2

EXAMPLE DOMAIN

To help make these ideas more concrete, consider the
following simple probabilistic planning domain based
on the problem of building a sand castle at the beach.
There are a total of four states in the domain, de3We assume that the number of bits used to represent

the individual probability values isn't too large.

4This implies that the transition probabilities have at
most as many bits as the circuit representing the domain
has gates. There are other circuit-based representations
that can represent probabilities with an exponential num­
ber of bits (Mundhenk, Goldsmith, & Allender 1996).

184

Goldsmith, Littman, and Mundhenk
after

before
moat

1.00

Figure

1:

moat

castle

0.50

castle

0.25

Circuit representation for

erect-castle.

scribed by combinations of two Boolean state vari­
ables, moat and castle. The proposition moat sig­
nifies that a moat has been dug in the sand and the
proposition castle signifies that the castle has been
built. In the initial state, both moat and castle are
false, and the two states in which castle is true are
goal states.
There are two actions: dig-moat and erect-castle. Exe­
cuting dig-moat has two possible equiprobable effects,
"no op" (state does not change), and "moat" (moat
becomes true). The erect-castle action is more com­
plex. If moat is true, then the possible effects are
"castle" (probability 0.50), in which castle becomes
true, "no op" (probability 0.25), in which the state
doesn't change, and "collapse" (probability 0.25), in
which moat becomes false. On the other hand, if
moat is false when erect-castle is executed, then pos­
sible effects are "castle" (probability 0.25), in which
castle becomes true, and "no op" (probability 0.75),
in which the state doesn't change. The idea here is
that building a moat first protects the castle from be­
ing destroyed prematurely by the ocean waves.
To illustrate the circuit representation, Figure 1 gives
one possible circuit representation for the erect-castle
action. This circuit takes, as input, binary representa­
tions of the "before" state s and the "after" state s',
and outputs a binary representation of the probabil­
ity of reaching s' from s under the erect-castle action.
While this representation is not convenient for specify­
ing complex planning domains, more natural represen­
tations can be converted into this form automatically.
1.3

TYPES OF PLANS

We consider four basic classes of plans for probabilistic
domains: totally ordered, acyclic, looping, and par­
tially ordered. We illustrate examples from each of
these classes for the sand-castle domain in Figure 2. A
totally ordered plan is a sequence of actions that must

be executed in order. The plan terminates after the
final action in the plan has been executed, or whenever
a goal state is reached. For example, with probability
0.4375, the totally ordered plan in Figure 2(a)) suc­
cessfully builds a sand castle.
Acyclic plans generalize totally ordered plans to in­
clude conditional execution of actions. They are
roughly loop-free finite-state controllers for a planning
domain; they express a simple type of conditional plan
in which the next plan step to execute is a function of
the current step and an "effect label" that describes
the outcome of executing the current step. No step in
an acyclic plan may be repeated more than once during
plan execution. The acyclic plan in Figure 2(b) suc­
ceeds with probability 0.46875 and executes dig-moat
an average of 1. 75 times. Thus, it succeeds more often
and with fewer actions than the totally ordered plan
in Figure 2(a).

A partially ordered plan is a different way of gener­
alizing a totally ordered plan. It contains no loops
and no conditional branches, but can leave flexible the
precise sequencing of actions (Kushmerick, Hanks, &
Weld 1995). Figure 2(c) illustrates a partially ordered
plan for the sand-castle domain. The dashed arrows
indicate ordering constraints in contrast to solid ar­
rows, which indicate flow of controL There are two
distinct totally ordered plans consistent with the par­
tially ordered plan in Figure 2(c): dig-moat, dig-moat,
dig-moat, erect-castle, erect-castle and dig-moat, dig­
moat, erect-castle, dig-moat, erect-castle.

There are several possible interpretations for how the
performance of a partially ordered plan is measured.
The pessimistic interpretation is that the performance
of a partially ordered plan is equal to the performance
of the worst possible totally ordered plan consistent
with the partial order. This is closely related to the
standard interpretation in deterministic partial order
planning (McAllester & Rosenblitt 1991). The opti­
mistic interpretation of the performance of a partially
ordered plan is that it is the performance of the best
consistent totally ordered plan, and the average in­
terpretation is that it is the average over all possible
consistent orders.
Totally ordered, partially ordered, and acyclic plans
are all inherently finite horizon; plans terminate after
a polynomial number of actions. Looping plans gen­
eralize acyclic plans to the case in which plan steps
can be repeated (Smith & W illiamson 1995). This
type of plan is also referred to as a plan graph or pol­
icy graph (Kaelbling, Littman, & Cassandra 1995). A
looping plan can express an infinite-horizon strategy
because the plan will continue to execute as long as a
goal state is not reached (there is no a priori bound on

Complexity of Probabilistic Planning

.

(erect-castle)

_ .

(dig-moat)

(a) A total ly ordered plan.

. . · · ·

185

� •(erect-castle)
· ·

� •(erect-castle)
- ·

(c) A partially ordered plan.
"no op"

(erect-castle)

"no op"

(b) An acyclic (conditional) plan.
"collapse"

(d) A looping plan.
Figure 2: Example plans for the sand-castle domain.
the length of the sequence of actions chosen by such

a plan). For example, the looping plan in F igure 2(d)

does not terminate until it succeeds in building a sand

castle, which it will do with probability 1.0 eventually.
1.4

#PSPACE is the same as the class of polynomial­

space-computable functions (Ladner 1989).

For any complexity classes C and C' the class cc' con­

sists of those sets that are C- Turing reduc ible to sets in

C', i.e., sets that can be accepted with resource bounds

DECISION PROBLEMS

specified by C, using some problem in C' as a subrou­

Given a particular class of plans, we consider two com­

putational problems. The first is the plan-evaluation

problem; given a plan, a planning domain, and some
threshold (), does the given plan reach the goal with

probability at least B? The second problem is plan ex­
istence; given a planning problem and a threshold(), is

there a polynomial-size plan of the required form that
can reach the goal with probability at least B?

tine (oracle) with instantaneous output. For any class

C � PSPACE, it is the case that NPc�PSPACE, and

therefore PSPACEPSPACE=PSPACE; see Papadim­
itriou's (1994) textbook.

The complexity classes we consider satisfy the follow­

ing containment properties:
PC

_

1.5

COMPLEXITY BACKGROUND

standard results from complexity theory, we refer to
Papadimitriou's (1994) complexity te xtbook. In the

interest of completeness, in this section we give a short

description of the probabilistic and counting complex­
ity classes we use in this work.

f

such that,

for some nondeterministic polynomial-time bounded
machine N, the number of accepting paths of N on

equals

f(x).

x

Probabilistic polynomial time, PP, is the class of sets

A for which there exists a nondeterministic polynomial
time bounded machine N such that x E A if and only
if the number of accepting paths of N on x is greater
than its number of rejecting paths.

1.6

NPPP
co-NPPP � PSPACE � EXP.

SUMMA RY OF RESULTS

Table 1 summarizes our results, which are explained

in more detail in later sections. Table 2 summarizes a
set of results for flat domains; these are described in
our extended technical report (Goldsmith, Littman, &

Mundhenk 1997).

2

ACYCLIC PLANS

Given a planning domain M

P

=

•

{Q,qo, �,o,tr,w)

Q

=

(S, so,A,t,9), a

is an acyclic plan where

•

plan

and � are finite sets of plan steps and effects

labels, respectively,

For polynomial-space-bounded computations ,

PSPACE equals probabilistic PSPACE, and

� PP �

It is known that P is properly contained in EXP.

For definitions of complexity classes , reductions, and

The class #P is the class of functions

NP

co-NP

Qo E Q

is the initial plan step,

186

Goldsmith, Littman, and Mundhenk

Table 1: Complexity results for succinct representations.
plan evaluation

plan existence

PSPACE-complete
PP-complete
PP-complete
NpPP -complete
PP-complete
co-NPPP -complete

EXP-complete
PSPACE-complete
PSPACE-complete
NPPP -complete
NPPP -complete
NPPP -complete
NPPP -complete
NpPP -complete

unrestricted
polynomial-depth

looping
acyclic
totally ordered
partially ordered (optimistic)
partially ordered (average)
partially ordered (pessimistic)

reference
Littman (1997)
Littman (1997)
Section 3
Section 2
Section 2
Section 4
Section 4
Section 4

Table 2: Complexity results for flat representations.
unrestricted
polynomial-depth
looping
acyclic
totally ordered
partially ordered (optimistic)
partially ordered (average)
partially ordered (pessimistic)
•

6: Q

x

:E

function,
•

•

--+

Q is the (cycle free)

1r : Q --+ A is the
to actions, and

action mapping

plan evaluation

plan existence

PL-complete
PL-complete
PL-complete
NP-complete
(co-)NP-hard, in PP
co-NP-complete

P-complete
P-complete
P-complete
P-complete
NP-complete
NP-complete
NP-complete
NP-complete

state-tran sition

Proof

from plan steps

Let ¢> be a Boolean formula with n variables.
Define the planning domain M(¢>) with states
so, {0, 1}n, Bacc, Srej, one action a and transition proba­
bilities t( so, a, w) = 2- n, t(w, a, Sacc ) = 1 if w satisfies
¢>, and t( w, a, Brej)
1 if w does not satisfy ¢, for
wE {0, 1}n. Let Sacc be the only goal state. It is clear
that ¢> is in MAJSAT if and only if M(¢>) reaches the
goal state with probability at least 1/2 under the plan
that repeats action a twice.

w : S --+ :E is the transition mapping from states
of the planning domain to effects labels.

Note that the quantities Q, qo, :E, and 6 jointly specify
a deterministic finite-state automaton. Also, c5 may be
a partial function since some plan steps are final steps.
Let M be a planning domain and P be an acyclic plan.
Then M under P behaves as follows. Both M and P
are started "in parallel" in their initial states. Both
perform steps 1, 2,.. .. In step i ;:::: 1, let s be the
current state of M and q be the current plan step of P.
The current action is determined by the current state
q of P (i.e., the new state of M is s' with probability
t(s, 1r(q), s')) and P gets a translation of the new state
s' of M as an effects label (i.e., the new state of P is
6(q,w(s'))). If c5 is not defined on q, or s' is a goal
state, then the process stops.
Given these definitions, we can present our first com­
plexity result.
Theorem 2.1 The plan-evaluation problem for
acyclic and totally ordered plans is PP-complete.

To show PP-hardness, we give a reduction from
the PP-complete problem MAJSAT: given a Boolean
formula, do the majority of assignments satisfy it?

=

For membership in PP, note that a planning domain
M and an acyclic plan P induce a tree consisting of all
paths through M under P. This tree can be normal­
ized in a way that makes each path have equal proba­
bility, and an accepting leaf is reached with probabil­
ity at least 1/2 if and only if M reaches a goal state
with probability at least B. F inally, we can define a
polynomial-time probabilistic Turing machine that has
this tree as its computation tree.
•
The plan-existence problem is essentially equivalent to
guessing and evaluating a good plan, hence the prob­
lem is in NPPP. Hardness for NPPP can be shown us­
ing the techniques from a paper by Mundhenk, Gold­
smith, and Allender (1996). T he proof uses the idea
that every NPPP computation can be reduced to the

187

Complexity of Probabilistic Planning

problem of whether a succinctly described set of expo­

of N.

nentially many plan-evaluation problems contains one

This planning domain can be encoded succinctly, and

that is satisfied.

All accepting configurations reach goal states.

this encoding can be produced from N and
nomial time. Given a description of N and

Theorem 2.2 The plan-existence problem far acyclic
and totally ordered plans is NPPP -complete.
In the above results, we consider succinctly repre­
Suc­

cinctly represented plans are also quite useful.

A

s uccinct acyclic plan is an acyclic plan in which the
names of the plan steps are encoded in binary and a
polynomial-size circuit represents the state-transition
function 8. In addition, we require that the plan is at
most polynomially deep even though the total number
of steps in the plan might be exponential.
the proof technique used in Theorem

2. 1

Because

to succinct acyclic plans, analogous complexity results
plan, which is a plan in which the state-transition func­
tion 8 is probabilistic. These insights can be combined
to yield the following corollary.
Corollary 2. 1 The plan-evaluation problem for suc­
the plan-existence problem for s uccinct probabilistic
acyclic plans is NPPP -complete.

allow the state-transition functions to loop; this way,
looping plans can b e applied to infinite-horizon con­
trol. For looping plans, the complexity of plan exis­
tence and plan evaluation is quite different from the
acyclic case. Looping plan evaluation is very hard.
Theorem 3. 1 The plan-evaluation problem for loop­

Proof The plan-evaluation problem for fiat domains
en

states and a

a looping plan can be eval­

uated in probabilistic space O(log(cn)), which is to
say probabilistic space polynomial in the size of the
input. Since probabilistic PSPACE equals PSPACE,
this shows that the plan-evaluation problem for loop­
ing plans in succinct domains is in PSPACE.
It remains to show PSPACE-hardness.

M(x)

that the goal state is reached with probability

1

un­

der the "constant plan" (which repeatedly chooses the
only action) if and only if N on input x accepts.

•

Looping plan existence is not actually any harder than
looping plan evaluation, although it is still quite hard.
Theorem 3.2 The plan-existence problem for looping

Proof Hardness for PSPACE follows from the same
construction as in the proof of Theorem 3.1: either
the "constant plan" is fine, or it is not. No other plan

tion of the planning domain. Thus, it can be guessed
in polynomial time and checked in PSPACE. Because
NPPSPACE=PSPACE, the result follows.
Recall that the

•

unrestricted infinite-horizon plan­

existence problem is EXP-complete; this shows the
problem of determining unrestricted plan existence is
EXP-hard only because some domains require plans
that are larger than polynomial-size looping plans.

3.2

shows that plan existence is ?SPACE­

complete in deterministic domains also. This is closely
related to the PSPACE-completeness result of Bylan­
der (1994); the main difference is that our theorem ap­
plies to more succinct plans (a single action in a loop)
with more complex operator descriptions. Also, as the
proofs above show, PSPACE-hardness is retained even
in planning domains with only one action, so it is not
simply the conditional aspect of plans that makes them
hard to work with.

Let N be a

deterministic polynomial-space-bounded Turing ma­

input

that computation.) Because all transitions are deter­
ministic and only one action can be chosen, it follows

T heorem

ing plans is PSPACE-complete.

x,

(In fact, N' can even check whether c is a valid con­
figuration in the computation of N(x), by simulating

The problem is in PSPACE because the plan being

as with acyclic plans in the previous section, but we

chine. For any input

unique action), outputs the next configuration of N.

sought is no larger than the size of the succinct descrip­

To represent looping plans, we use the same notation

n,

words, N' on input c, a configuration of N (and a, the

yields a better result.

LOOPING PLANS

representation of size

produce a description of a Turing machine N'

plans is PSPACE-complete.

c inct probabilistic acyclic plans is PP -complete and

is in PL. For a planning domain with

x,

that computes the transition function for N. In other

generalizes

apply. The same holds true for a probabilistic acyclic

3

in poly­
one can,

in time polynomial in the size of the descriptions of N
and

sented planning domains but only flat plans.

x

x,

4

PARTIALLY ORDERED PLANS

construct a planning domain

that has as states all configurations of N on

A k-step partially ordered plan corresponds to a set of

only one action, and state transitions with

k-step totally ordered plans-all those that are consis­

probability 1 according to the configuration transitions

tent with the given partial order. The evaluation of a

x,

188

Goldsmith, Littman, and Mundhenk

partially ordered plan can be defined to be the evalua­
tion of the best, worst, or average member of the set of
consistent totally ordered plans; these are optimistic,
pessimistic, and average interpretations, respectively.
More formally, a partially ordered plan P is a directed
acyclic graph that has an action assigned to each node.
A totally ordered plan A = a1, ... , ak is consistent
with P if it satisfies the constraint that for all pairs
of nodes ai, aJ if ai is an ancestor of aJ in the partial
order, then i < j, i.e., ai comes before ai in the totally
ordered plan.
The plan-existence problem for partially ordered plans
under the optimistic interpretation asks whether­
given a domain M, a partially ordered plan P, and a
threshold 0-there is a totally ordered plan consistent
with P under which M reaches a goal state with prob­
ability at least B. Under the pessimistic interpretation,
we wish to know whether M reaches a goal state with
probability at least (;I under every consistent totally or­
dered plan. Under the average interpretation, we wish
to know whether M reaches a goal state with prob­
ability at least () averaged over all consistent totally
ordered plans.
The plan-existence problem for partially ordered plans
is identical to that for totally ordered plans. This is
because a totally ordered plan is a special kind of par­
tially ordered plan and its evaluation is unchanged un­
der the pessimistic, optimistic, or average interpreta­
tions. Conversely, the value of a partially ordered plan
under any interpretation is a lower bound on the value
of the best totally ordered plan.
Theorem 4.1 The plan-existence problem for par­
tially ordered plans is

NPPP -complete

under the pes­

simistic, o ptimistic and average interpretations.

The plan-evaluation problem for partially ordered
plans is different from that of totally ordered plans.
This is because a single partial order can encode an
exponential-size set of totally ordered plans, and eval­
uating the partially ordered plan involves figuring out
the best or worst member of this combinatorial set.
Theorem 4.2 The plan-evaluation problem for par­
tially ordered plans is

NPPP -complete

under the o p­

timistic interpretation, co-NPPP -complete under the
pessimistic interpretation, and PP -complete under the
average interpretation.

The proofs of the first two of these results are closely
related to the proof of Theorem 2.2. The average inter­
pretation problem can be shown to be in PP by com­
bining an argument showing how to average over con­
sistent totally ordered plans with the argument in the
proof of Theorem 2.1 showing how to evaluate a plan in

a succinct domain in PP. PP-hardness follows trivially
from Theorem 2.1, because totally ordered plans are a
special case of partially ordered plans and evaluating
totally ordered plans is PP-hard.
5

CONCLUSIONS

In this paper, we explored the computational complex­
ity of plan evaluation and plan existence in probabilis­
tic domains. We found that, in succinctly represented
domains, restricting the form of the policies under
consideration reduced the computational complexity
of plan existence from EXP-complete for unrestricted
plans to PSPACE-complete for polynomial-size loop­
ing plans to NPPP -complete for polynomial-size acyclic
plans.
The class NpPP promises to be very useful to re­
searchers in uncertainty in artificial intelligence be­
cause it captures the type of problems resulting from
choosing a good combinatorial structure and then eval­
uating its probabilistic behavior. This is precisely the
type of problem faced by planning algorithms in prob­
abilistic domains, and may capture important prob­
lems in other domains as well, such as constructing
good Bayes networks from data.
The basic structure of our results is that if plan eval­
uation is complete for some class C, then plan ex­
istence is typically NPc -complete. This same basic
structure holds in deterministic domains: evaluating a
totally ordered plan in a succinct domain is P-complete
(for some typical representations) and determining the
existence of a polynomial-size totally ordered plan is
NPP =NP-complete.
There are several significant plan representations that
we did not explicitly consider in this work. However,
the results we presented do provide a goal deal of in­
sight into complexity results for other representations.
For example, Draper, Hanks, & Weld (1994) devised a
representation for partially ordered conditional plans
for the C-BURIDAN system. In this representation, each
plan step generates an observation label as a function
of the probabilistic outcome of the step. Each step
also has an associated set of context labels dictating
the circumstances under which that step must be ex­
ecuted. A plan step is executed only if its context
labels are consistent with the observation labels pro­
duced in earlier steps. This type of plan can be ex­
pressed as a succinct acyclic plan; Corollary 2.1 can
be used to show that the plan-evaluation and plan­
existence problems for partially ordered conditional
plans in succinct domains are PP-complete and NPPP­
complete, respectively. Other important plan struc­
tures to which our results can be applied include uni­
versal plans or policies (Dearden & Boutilier 1997) and

Complexity of Probabilistic Planning

parallel plans ( Blum

& Furst 1997).

Notice that the results presented here also apply to
partially observable domains

1994;

Kaelbling, Littman,

( Draper,

Hanks,

& Weld

& Cassandra 1995); once

we limit our decision making to following finite-state
plans, it matters very little whether the true state of
the world is observable or not.

In many cases, the

complexity of optimally solving partially observable
Markov decision processes (Papadimitriou
lis

1987)

1992.

Condon, A.

& Tsitsik­

is much higher than that of searching for a

restricted controller or plan, so there is some hope of
building effective algorithms based on these ideas.

189

The complexity of stochastic

games. Information and Computation 96(2):203-224.

1997.

Dearden, R., and Boutilier, C.

Abstraction

and approximate decision-theoretic planning. Artifi­

cial Intelligence 89(1-2):219-283.

1994.

Draper, D.; Hanks, S.; and Weld, D.

Proba­

bilistic planning with information gathering and con­
tingent execution. In Proceedings of the AAAI Spring

Symposium on Decision Theoretic Planning,
Goldsmith, J.;

1997.

Littman, M.;

76-82.

and Mundhenk,

M.

The complexity of plan existence and eval­

uation in probabilistic domains.

Technical Report

The results in this paper support the intuition that

CS-1997-07, Department of Computer Science, Duke

searching for small plans is more efficient than search­

University.

ing for arbitrarily complicated plans.

From a prag­

matic standpoint, this suggests that exact dynamic­
programming algorithms, which are so successful in
flat domains, may not be as effective in succinct do­
mains; they do not focus their efforts on the set of
small plans.

Algorithm development energy, there­

Kaelbling, L. P.; Littman, M. L.; and Cassandra,
A. R.

1995.

Planning and acting in partially observ­

able stochastic domains. Technical Report CS- 96-0 8 ,
Brown University, Providence,

RI.

An algorithm for probabilistic planning.

problems in the class NPPP, as this class captures the

Intelligence 76(1-2):239-286.

essence of searching for small plans for probabilistic
domains. Heuristics for NPPP could lead to powerful
methods for solving a range of important uncertainty­
sensitive combinatorial problems.

1995.

Kushmerick, N.; Hanks, S.; and Weld, D. S.

fore, might fruitfully be spent devising heuristics for

Ladner, R.

1989. Polynomial

space counting prob­

lems. SIAM Journal on Computing
Littman, M. L.

1997.

Artificial

18:1087-1097.

Probabilistic propositional

planning: Representations and complexity. In Pro­

ceedings of the Fourteenth National Conference on

Acknowledgments

Artificial Intelligence. AAAI Press/ The MIT Press.

We gratefully acknowledge Andrew Klapper and Anne

McAllester, D., and Rosenblitt, D.

1991.

Systematic

Condon for helpful conversations on this topic.

nonlinear planning. In Proceedings of the 9th National



We investigate the computational complexity of testing dominance and consistency in CP-nets.
Previously, the complexity of dominance has been determined for restricted classes in which the
dependency graph of the CP-net is acyclic. However, there are preferences of interest that define
cyclic dependency graphs; these are modeled with general CP-nets. In our main results, we show
here that both dominance and consistency for general CP-nets are PSPACE-complete. We then
consider the concept of strong dominance, dominance equivalence and dominance incomparability,
and several notions of optimality, and identify the complexity of the corresponding decision problems. The reductions used in the proofs are from STRIPS planning, and thus reinforce the earlier
established connections between both areas.

1. Introduction
The problems of eliciting, representing and computing with preferences over a multi-attribute domain arise in many fields such as planning, design, and group decision making. However, in a
multi-attribute preference domain, such computations may be nontrivial, as we show here for the
CP-net representation. Natural questions that arise in a preference domain are, “Is this item preferred to that one?”, and “Is this set of preferences consistent?” More formally, a set of preferences
is consistent if and only if no item is preferred to itself. We assume that preferences are transitive,
i.e., if α is preferred to β, and β is preferred to γ, then α is preferred to γ.
An explicit representation of a preference ordering of elements, also called outcomes, of such
multi-variable domains is exponentially large in the number of attributes. Therefore, AI researchers
have developed languages for representing preference orderings in a succinct way. The formalism
of CP-nets (Boutilier, Brafman, Hoos, & Poole, 1999) is among the most popular ones. A CP-net
c 2008 AI Access Foundation. All rights reserved.

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

provides a succinct representation of preference ordering on outcomes in terms of local preference
statements of the form p : xi > x j , where xi , x j are values of a variable X and p is a logical condition.
Informally, a preference statement p : xi > x j means that given p, xi is strictly preferred to x j ceteris
paribus, that is, all other things being equal. The meaning of a CP-net is given by a certain ordering relation, called dominance, on the set of outcomes, derived from such reading of preference
statements. If one outcome dominates another, we say that the dominant one is preferred.
Reasoning about the preference ordering (dominance relation) expressed by a CP-net is far from
easy. The key problems include dominance testing and consistency testing. In the first problem,
given a CP-net and two outcomes α and β, we want to decide whether β dominates α. The second
problem asks whether there is a dominance cycle in the dominance ordering defined by an input
CP-net, that is, whether there is an outcome that dominates (is preferred to) itself.
We study the computational complexity of these two problems. The results obtained prior to this
work concerned only restricted classes of CP-nets, all requiring that the graph of variable dependencies implied by preference statements in the CP-net be acyclic. Under certain assumptions, the
dominance-testing problem is in NP and, under some additional assumptions, even in P (Domshlak
& Brafman, 2002; Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004a). We show that the complexity in the general case is PSPACE-complete, and this holds even for the propositional case, by
exhibiting in Section 4 a PSPACE-hardness proof for dominance testing.
We then turn to consistency testing. While acyclic CP-nets are guaranteed to be consistent, this
is not the case with general CP-nets (Domshlak & Brafman, 2002; Brafman & Dimopoulos, 2004).
In Section 5, we show that consistency testing is as hard as dominance testing.
In the following two sections we study decision problems related to dominance and optimality
in CP-nets. First, we consider the complexity of deciding strict dominance, dominance equivalence
and dominance incomparability of outcomes in a CP-net. Then, we study the complexity of deciding
the optimality of outcomes, and the existence of optimal outcomes, for several notions of optimality.
To prove the hardness part of the results, we first establish the PSPACE-hardness of some problems related to propositional STRIPS planning. We then show that these problems can be reduced
to CP-net dominance and consistency testing by exploiting connections between actions in STRIPS
planning and preference statements in CP-nets.
The complexity results in this paper address CP-nets whose dominance relation may contain
cycles. Most earlier work has concentrated on the acyclic model. However, as argued earlier, for
instance by Domshlak and Brafman (2002), acyclic CP-nets are not sufficiently expressive to capture human preferences on even some simple domains.1 Consider, for instance, a diner who has
to choose either red or white wine, and either fish or meat. Given red wine, they prefer meat, and
conversely, given meat they prefer red wine. On the other hand, given white wine, they prefer fish,
and conversely, given fish they prefer white wine. This gives a consistent cyclic CP-net, and there is
no acyclic CP-net giving rise to the same preferences on outcomes. So, such cyclicity of preference
variables does not necessarily lead to a cyclic order on outcomes.

1. We do not mean to say that cyclic CP-nets are sufficient to capture all possible human preferences on simple domains
– this is obviously not true. However, we note that every preference relation extends the preference relation induced
by some CP-net with possibly cyclic dependencies. Not only is this property no longer true when cyclic dependencies
are precluded but, in the case of binary variables, the number of linear orders that extends some acyclic CP-net is
exponentially smaller than the number of all linear orders (Xia, Conitzer, & Lang, 2008).

404

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

We assume some familiarity with the complexity class PSPACE. We refer to Papadimitriou
(1994) for details. In particular, we later use the identities NPSPACE = PSPACE = coPSPACE.
In several places, we will consider versions of decision problem, in which input instances are
assumed to have some additional property. Such problems are usually formulated in the following
way: “Q, given R”2 . We first note that “Q, given R” is not the same problem as “Q and R”. Let
us recall the definition of a decision problem as presented by Ausiello et al. (1999). A decision
problem is a pair P = hIP ,YP i where IP is a set of strings (formally, a subset of Σ∗ , where Σ is a
finite alphabet), The decision problem P = hIP ,YP i reads as follows: given a string x ∈ IP , decide
whether x ∈ YP . A problem hIP ,YP i is in a complexity class C if the language YP ⊆ Σ∗ is in C (this
does not depend on IP ). A problem hIQ ,YQ i is reducible to hIP ,YP i if there is a polynomial-time
function F such that (1) for every x ∈ IQ , F(x) ∈ IP , and (2) for every x ∈ IQ , x ∈ YQ if and only
if F(x) ∈ YP . Thus, if P is the decision problem “Q, given R”, then IP is the set of all strings
satisfying R, while YP is the set of all strings satisfying R ∩ Q. For all such problems, it is granted
that the input belongs to R; to solve them we do not have to check that the input string is indeed
an element of R. Such problems “Q, given R” are widespread in the literature. However, in most
cases, R is a very simple property, that can be checked in polynomial (and often linear) time, such
as “decide whether a graph possesses a Hamiltonian cycle, given that every vertex has a degree at
most 3”. Here, however, we will consider several problems “Q, given R” where R itself is not in the
class P (unless the polynomial hierarchy collapses). However, as we said above, the complexity of
recognizing whether a given string is in R does not matter. In other words, the complexity of “Q,
given R” is the same, whether R can be recognized in unit time or is PSPACE-complete. We will
come back to this when the first such problem appears in the paper (cf. the proof of Proposition 5).
In no case that we consider is the complexity of R greater than the complexity of Q.
A part of this paper (up to Section 5) is an extended version of our earlier conference publication
(Goldsmith, Lang, Truszczyński, & Wilson, 2005). Sections 6 and 7 are entirely new.

2. Generalized Propositional CP-Nets
Let V = {x1 , . . . , xn } be a finite set of variables. For each variable x ∈ V , we assume a finite domain
Dx of values. An outcome is an n-tuple (d1 , . . . , dn ) of Dx1 × · · · × Dxn .
In this paper, we focus on propositional variables: variables with binary domains. Let V be a
finite set of propositional variables. For every x ∈ V , we set Dx = {x, ¬x} (thus, we overload the
notation and write x both for the variable and for one of its values). We refer to x and ¬x as literals.
Given a literal l we write ¬l to denote the dual literal to l. The focus on binary variables makes the
presentation clearer and has no impact on our complexity results.
We also note that in the case of binary domains, we often identify an outcome with the set of
its values (literals). In fact, we also often identify such sets with the conjunctions of their elements.
Sets (conjunctions) of literals corresponding to outcomes are consistent and complete.
A conditional preference rule (sometimes, a preference rule or just a rule) over V is an expression p : l > ¬l, where l is a literal of some atom x ∈ V and p is a propositional formula over V that
does not involve variable x.
2. In the literature one often finds the following formulation: “Q, even if R”, which does not have exactly the same
meaning as “Q, given R”. Specifically, when saying “Q is NP-complete, even if R”, one means “Q is NP-complete,
and Q, given R is NP-complete as well”.

405

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

In the rest of the paper, we need to refer to two different languages: a conditional preference
language where for every (binary) variable x, the conditional preference table for x needs to specify
a preferred value of x for every possible assignment of its parent variables, and a more general
language where the tables may be incomplete (for some values of its parents, the preferred value of
x may not be specified) and/or locally inconsistent (for some values of its parents, the table may both
contain the information that x is preferred and the information that ¬x is preferred). We call these
languages respectively CP-nets and GCP-nets (for “generalized CP-nets”). Note that GCP-nets are
not new, as similar structures have been discussed before (Domshlak, Rossi, Venable, & Walsh,
2003). The reason why we use this terminology (“CP-nets” and “GCP-nets”) is twofold. First, even
if the assumptions of completeness and local consistency for CP-nets are sometimes relaxed, most
papers on CP-nets do make them. Second, we could have used “CP-nets” and “locally consistent,
complete CP-nets” instead of “GCP-nets” and “CP-nets”, but we felt our notation is simpler and
more transparent.
Definition 1 (Generalized CP-net) A generalized CP-net C (for short, a GCP-net) over V is a
set of conditional preference rules. For x ∈ V we define pC+ (x) and pC− (x), usually written just:
p+ (x) and p− (x), as follows: pC+ (x) is equal to the disjunction of all p such that there exists a rule
p : x > ¬x in C; pC− (x) is the disjunction of all p such that there exists a rule p : ¬x > x in C. We
define the associated directed graph GC (the dependency graph) over V to consist of all pairs (y, x)
of variables such that y appears in either p+ (x) or p− (x).
In our complexity results we will also need the following representation of GCP-nets: a GCPnet C is said to be in conjunctive form if C only contains rules p : l > ¬l such that p is a (possibly
empty) conjunction of literals. In this case all formulas p− (x), p+ (x) are in disjunctive normal form,
that is, a disjunction of conjunctions of literals (including ⊤ – the empty conjunction of literals).
GCP-nets determine a transitive relation on outcomes, interpreted in terms of preference. A
preference rule p : l > ¬l represents the statement “given that p holds, l is preferred to ¬l ceteris
paribus”. Its intended meaning is as follows. If outcome β satisfies p and l, then β is preferred to
the outcome α which differs from β only in that it assigns ¬l to variable x. In this situation we say
that there is an improving flip from α to β sanctioned by the rule p : l > ¬l.
Definition 2 If α0 , . . . , αm is a sequence of outcomes with m ≥ 1 and each next outcome in the
sequence is obtained from the previous one by an improving flip, then we say that α0 , . . . , αm is an
improving sequence from α0 to αm for the GCP-net, and that αm dominates α0 , written α0 ≺ αm .
Finally, a GCP-net is consistent if there is no outcome α which is strictly preferred to itself, that
is, such that α ≺ α.
The main objective of the paper is to establish the complexity of the following two problems
concerning the notion of dominance associated with GCP-nets (sometimes under restrictions on the
class of input GCP-nets).
Definition 3
GCP - DOMINANCE : given a GCP-net C and two outcomes α and β, decide whether α ≺ β in C, that
is, whether β dominates α in C.
GCP - CONSISTENCY : given a GCP-net C, decide whether C is consistent.
406

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

GCP-nets extend the notion of CP-nets (Boutilier et al., 1999). There are two properties of
GCP-nets that are essential in linking the two notions.
Definition 4
A GCP-net C over V is locally consistent if for every x ∈ V , the formula pC− (x) ∧ pC+ (x) is unsatisfiable. It is locally complete if for every x ∈ V , the formula pC− (x) ∨ pC+ (x) is a tautology.
Informally, local consistency means that there is no outcome in which both x is preferred over
¬x and ¬x is preferred over x. Local completeness means that, for every variable x, in every outcome
either x is preferred over ¬x or ¬x is preferred over x.
Definition 5 (Propositional CP-net) A CP-net over the set V of (propositional) variables is a locally consistent and locally complete GCP-net over V .
It is not easy to decide whether a GCP-net is actually a CP-net. In fact, the task is coNPcomplete.
Proposition 1 The problem of deciding, given a GCP-net C, whether C is a CP-net is coNPcomplete.
Proof: Deciding whether a GCP-net C is a CP-net consists of checking local consistency and local
completeness. Each of these tasks amounts to n validity tests (one for each variable). It follows that
deciding whether a GCP-net is a CP-net is the intersection of 2n problems from coNP. Hence, it is
in coNP, itself. Hardness comes from the following reduction from UNSAT. To any propositional
formula ϕ we assign the CP-net C(ϕ), defined by its set of variables Var(ϕ)∪{z}, where z 6∈ Var(ϕ),
and the following tables:
−
+
• for any variable x 6= z: pC(ϕ)
(x) = ⊤; pC(ϕ)
(x) = ⊥;
−
+
(z) = ⊥.
(z) = ¬ϕ; pC(ϕ)
• pC(ϕ)
−
−
+
+
(z) = ⊥. There(z) ∧ pC(ϕ)
(x) = ⊥; moreover, pC(ϕ)
(x) ∧ pC(ϕ)
For any variable x 6= z, we have pC(ϕ)
−
+
fore, C(ϕ) is locally consistent. Now, for any variable x 6= z, we have pC(ϕ) (x) ∨ pC(ϕ)
(x) = ⊤.
−
+
Moreover, pC(ϕ) (z) ∨ pC(ϕ) (z) = ¬ϕ. Thus, C(ϕ) is locally complete if and only if ϕ is unsatisfiable.
It follows that C(ϕ) is a CP-net if and only if ϕ is unsatisfiable.


Many works on CP-nets make use of explicit conditional preference tables that list every combination of values of parent variables (variables on which x depends) exactly once, each such combination designating either x or ¬x as preferred.3 Clearly, CP-nets in this restricted sense can be
regarded as CP-nets in our sense that, for every variable x, satisfy the following condition:
if y1 , . . . , yk are all the atoms appearing in p+ (x) and p− (x) then every complete and
consistent conjunction of literals over {y1 , . . . , yn } appears as a disjunct in exactly one
of p+ (x) and p− (x).
3. There are exceptions. Some are discussed for instance by Boutilier et al. (2004a) in Section 6 of their paper.

407

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Under this embedding, the concepts of dominance and consistency we introduced here for GCP-nets
generalize the ones considered for CP-nets as defined by Boutilier et al. (2004a).
Problems CP - DOMINANCE and CP - CONSISTENCY are defined analogously to Definition 3. In
the paper we are interested in the complexity of dominance and consistency problems for both GCPnets and CP-nets. Therefore, the matter of the way in which these nets (especially CP-nets, as for
GCP-nets there are no alternative proposals) are represented is important. Our representation of
CP-nets is often more compact than the one proposed by Boutilier et al. (2004a), as the formulas
p+ (x) and p− (x) implied by the conditional preference tables can often be given equivalent, but
exponentially smaller, disjunctive normal form representations. Thus, when defining a decision
problem, it is critical to specify the way to represent its input instances, as the representation may
affect the complexity of the problem. Unless stated otherwise, we assume that GCP-nets (and thus,
CP-nets) are represented as a set of preference rules, as described in Definition 1. Therefore, the
size of a GCP-net is given by the total size of the formulas p− (x), p+ (x), x ∈ V .
We now note a key property of consistent GCP-nets, which we will use several times later in the
paper.
Proposition 2 If a GCP-net C is consistent then it is locally consistent.
Proof: If C is not locally consistent then there exists a variable x and an outcome α satisfying
pC− (x) ∧ pC+ (x). Then α ≺ α can be shown by flipping x from its current value in α to the dual value
and then flipping it back: since α satisfies pC− (x) ∧ pC+ (x), and since pC− (x) ∧ pC+ (x) does not involve
any occurrences of x, both flips are allowed.

Finally, we conclude this section with an example illustrating the notions discussed above.
Example 1 Consider a GCP-net C on variables V = {x, y} with four rules, defined as follows:
x : y > ¬y; ¬x : ¬y > y; y : ¬x > x; ¬y : x > ¬x. We have p+ (y) = x, p− (y) = ¬x, p+ (x) = ¬y and
p− (x) = y. Therefore C is locally consistent and locally complete, and so is a CP-net.
There is a cycle of dominance between outcomes: x ∧ y ≺ ¬x ∧ y ≺ ¬x ∧ ¬y ≺ x ∧ ¬y ≺ x ∧ y,
and so C is inconsistent. This shows that consistency is a strictly stronger property than local
consistency.

3. Propositional STRIPS Planning
In this section we derive some technical results on propositional STRIPS planning which form the
basis of our complexity results in Sections 4 and 5. We establish the complexity of plan existence
problems for propositional STRIPS planning under restrictions on input instances that make the
problem of use in the studies of dominance and consistency in GCP-nets.
Let V be a finite set of variables. A state over V is a complete and consistent set of literals over
V , which we often view as the conjunction of its members. A state is therefore equivalent to an
outcome, defined in a CP-nets context.
Definition 6 (Propositional STRIPS planning) By a propositional STRIPS instance we mean a
tuple hV, α0 , γ, ACTi, where
1. V is a finite set of propositional variables;
408

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

2. α0 is a state over V , called the initial state;
3. γ is a state called the goal;4
4. ACT is a finite set of actions, where each action a ∈ ACT is described by a consistent conjunction of literals pre(a) (a precondition) and a consistent conjunction of literals post(a) (a
postcondition, or effect).5
An action a is executable in a state α if α |= pre(a). The effect of a in state α, denoted by eff (a, α),
is the state α′ containing the same literals as α for all variables not mentioned in post(a), and
the literals of post(a). We assume that an action can be applied to any state, but that it does not
change the state if its preconditions do not hold: if α 6|= pre(a) (given that states are complete,
this is equivalent to α |= ¬pre(a)) then eff (a, α) = α. This assumption has no influence as far as
complexity results are concerned.
The PROPOSITIONAL STRIPS PLAN EXISTENCE problem, or STRIPS PLAN for short, is to decide whether for a given propositional STRIPS instance hV, α0 , γ, ACTi there is a finite sequence
of actions leading from the initial state α0 to the final state γ. Each such sequence is a plan for
hV, α0 , γ, ACTi. A plan is irreducible if every one of its actions changes the state.
We assume, without loss of generality, that for any action a, no literal in post(a) appears also
in pre(a); otherwise we can omit the literal from post(a) without changing the effect of the action;
if post(a) then becomes an empty conjunction, the action a can be omitted from ACT as it has no
effect.
We have the following result due to Bylander (1994).
Proposition 3 (Bylander, 1994)

STRIPS PLAN

is PSPACE-complete.

Typically, propositional STRIPS instances do not require that goals be states. Instead, goals are
defined as consistent conjunctions of literals that do not need to be complete. In such a setting, a
plan is a sequence of actions that leads from the start state to a state in which the goal holds. We
restrict consideration to complete goals. This restriction has no effect on the complexity of the plan
existence problem: it remains PSPACE-complete under the goal-completeness restriction (Lang,
2004).
3.1 Acyclic STRIPS
Definition 7 (Acyclic sets of actions) A set of actions ACT (we use the same notation as in Definition 6) is acyclic if there is no state α such that hV, α, α, ACTi has a non-empty irreducible plan,
that is to say, if there are no non-trivial directed cycles in the graph on states induced by ACT.
We will now establish the complexity of the following problem:
ACTION - SET ACYCLICITY :

given a set ACT of actions, decide whether ACT is acyclic.

Proposition 4
ACTION - SET ACYCLICITY is PSPACE-complete.
4. Note that in standard STRIPS the goal can be a partial state. This point is discussed just after Proposition 3.
5. We emphasize that we allow negative literals in preconditions and goals. Some definitions of STRIPS do not allow
this. This particular variant of STRIPS is sometimes called PSN (propositional STRIPS with negation) in the literature.

409

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Proof: The argument for the membership in PSPACE is standard; we nevertheless give some details.
We will omit such details for further proofs of membership in PSPACE. The following nondeterministic algorithm decides that ACT has a cycle:
guess α0 ;
α := α0 ;
repeat
guess an action a ∈ ACT ;
α′ := eff (a, α);
α := α′
until α = α0 .
This algorithm works in nondeterministic polynomial space (because we only need to store α0 ,
α and α′ ), which shows that ACTION - SET ACYCLICITY is in NPSPACE, and therefore in PSPACE,
since NPSPACE = PSPACE. Thus, ACTION - SET ACYCLICITY is in coPSPACE, hence in PSPACE,
since coPSPACE = PSPACE.
We will now show that the complement of the ACTION - SET ACYCLICITY problem is PSPACEhard by reducing the ACYCLIC STRIPS PLAN problem to it.
Let PE = hV, α0 , γ, ACTi be an instance of the ACYCLIC STRIPS PLAN problem. In particular,
we have that ACT is acyclic. Let a be a new action defined by pre(a) = γ and post(a) = α0 . It is easy
to see that ACT ∪ {a} is not acyclic if and only if there exists a plan for PE. Thus, the PSPACEhardness of the complement of the ACTION - SET ACYCLICITY problem follows from Proposition
5. Consequently, the ACTION - SET ACYCLICITY problem is coPSPACE-hard. Since PSPACE =
coPSPACE, the ACTION - SET ACYCLICITY problem is PSPACE-hard, as well.

Next, we consider the STRIPS planning problem restricted to instances that have acyclic sets of
actions. Formally, we consider the following problem:
ACYCLIC STRIPS PLAN : Given a propositional STRIPS instance hV, α0 , γ, ACTi such
that ACT is acyclic and α0 6= γ, decide whether there is a plan for hV, α0 , γ, ACTi

This is the first of our problems of the form “Q, given R” that we encounter and it illustrates
well the concerns we discussed at the end of the introduction. Here, R is the set of all propositional
STRIPS instances hV, α0 , γ, ACTi such that ACT is acyclic, and Q is the set of all such instances for
which there is a plan for hV, α0 , γ, ACTi. Checking whether a given propositional STRIPS instance
is actually acyclic is itself PSPACE-complete (this is what Proposition 4 states), but this does not
matter when it comes to solving ACYCLIC STRIPS PLAN: when considering an instance of ACYCLIC
STRIPS PLAN , we already know that it is acyclic (and this is reflected in the reduction below).
Proposition 5
ACYCLIC STRIPS PLAN

is PSPACE-complete.

Proof: The argument for the membership in PSPACE is standard (cf. the proof of Proposition 4). To
prove PSPACE-hardness, we first exhibit a polynomial-time reduction F from STRIPS PLAN. Let
PE = hV, α0 , γ, ACTi be an instance of STRIPS PLAN. The idea behind the reduction is to introduce
a counter, so that each time an action is executed, the counter is incremented. The counter may
count up to 2n , where n = |V |, making use of n additional variables. The counter is initialized to
410

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

0. Once it reaches 2n − 1 it can no longer be incremented and no action can be executed. Hence,
the set of actions in the resulting instance of STRIPS PLAN is acyclic: we are guaranteed to produce
an instance of R. To describe the reduction, we write V as {x1 , . . . , xn }. We define F(PE) = PE′ =
hV ′ , α′0 , γ′ , ACT ′ i as follows:
• V ′ = {x1 , . . . , xn , z1 , . . . , zn }, where zi are new variables we will use to implement the counter;
• α′0 = α0 ∧ ¬z1 ∧ · · · ∧ ¬zn ;
• γ′ = γ ∧ z1 ∧ · · · ∧ zn ;
• for each action a ∈ ACT, we include in ACT ′ n actions ai , 1 ≤ i ≤ n, such that:

pre(ai ) = pre(a) ∧ ¬zi ∧ zi+1 ∧ · · · ∧ zn
– for i ≤ n − 1 :
post(ai ) = post(a) ∧ zi ∧ ¬zi+1 ∧ · · · ∧ ¬zn , and

pre(an ) = pre(a) ∧ ¬zn
– for i = n :
post(an ) = post(a) ∧ zn .
• Furthermore, we include in ACT ′ n actions bi , 1 ≤ i ≤ n, such that:

pre(bi ) = ¬zi ∧ zi+1 ∧ · · · ∧ zn
– for i ≤ n − 1 :
post(bi ) = zi ∧ ¬zi+1 ∧ · · · ∧ ¬zn , and

pre(bn ) = ¬zn
– for i = n :
post(bn ) = zn .
We will denote states over V ′ by pairs (α, k), where α is a state over V and k is an integer, 0 ≤
k ≤ 2n − 1. We view k as a compact representation of a state over variables z1 , . . . , zn : assuming that
the binary representation of k is d1 . . . dn (with dn being the least significant digit), k represents the
state which contains zi if di = 1 and ¬zi , otherwise. For instance, let V = {x1 , x2 , x3 }. Then we have
V ′ = {x1 , x2 , x3 , z1 , z2 , z3 }, and the state ¬x1 ∧ x2 ∧ x3 ∧ z1 ∧ ¬z2 ∧ z3 is denoted by (¬x1 ∧ x2 ∧ x3 , 5).
We note that the effect of ai or bi on state (α, k) is either void, or increments the counter:
eff (ai , (α, k)) =



(eff (a, α), k + 1) if ai is executable in (α, k)
(α, k)
otherwise

eff (bi , (α, k)) =



(α, k + 1) if bi is executable in (α, k)
(α, k)
otherwise

Next, we remark that at most one ai and at most one bi are executable in a given state (α, k).
More precisely,
• if k < 2n − 1, then exactly one bi is executable in (α, k); denote by i(k) the index such that bi(k)
is executable in (α, k) (this index depends only on k). We also have that ai(k) is executable in
(α, k), provided that a is executable in α.
• if k = 2n − 1, then no ai and no bi is executable in (α, k).
411

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Now we show that PE′ is acyclic. Assume π is an irreducible plan for hV ′ , α′ , α′ , ACT ′ i. Let
= (α, k). If k < 2n − 1, then π is empty, since any action in ACT ′ in any state either is nonexecutable or increments the counter, and an irreducible plan contains only actions whose effect is
non-void. If k = 2n − 1, then no action of ACT ′ is executable in α′ and again π is empty. Thus, there
exists no non-empty irreducible plan for hV ′ , α′ , α′ , ACT ′ i, and this holds for all α′ . Therefore PE′
is acyclic.
We now claim that there is a plan for PE if and only if there is a plan for PE′ . First, assume that
there is a plan in PE. Let π be a shortest plan in PE and let m be its length (the number of actions
used). We have m ≤ 2n − 1, since no state along π repeats (otherwise, shorter plans than π for PE
would exist). Let α0 , α1 , . . . , αm = γ be the sequence of states obtained by executing π. Let a be the
action used in the transition from αk to αk+1 . Since k < 2n − 1 (because m ≤ 2n − 1 and k ≤ m − 1),
there is exactly one i, 1 ≤ i ≤ n, such that the action ai applies at the state (α, k) over V ′ . Replacing
a with ai in π yields a plan that when started at (α0 , 0) leads to (αm , m) = (γ, m). Appending that
plan with appropriate actions bi to increment the counter to 2n − 1 yields a plan for PE′ . Conversely,
if τ is a plan for PE′ , the plan obtained from τ by removing all actions of the form b j and replacing
each action ai with a is a plan for PE, since ai has the same effect on V as a does. Thus, the claim
follows.

α′

We emphasize that this reduction F from STRIPS PLAN to ACYCLIC STRIPS PLAN (or, equivalently, to STRIPS PLAN given ACTION - SET ACYCLICITY) works because it satisfies the following
two conditions:
1. for every instance PE of STRIPS PLAN, F(PE) is an instance of ACYCLIC STRIPS PLAN (this
holds because for every PE, F(PE) is acyclic);
2. for every PE of STRIPS PLAN, F(PE) is a positive instance of ACYCLIC
only if PE is a positive instance of STRIPS PLAN.

STRIPS PLAN

if and

3.2 Mapping STRIPS Plans to Single-Effect STRIPS Plans
Versions of the STRIPS PLAN and ACYCLIC STRIPS PLAN problems that are important for us allow only actions with exactly one literal in their postconditions in their input propositional STRIPS
instances. We call such actions single-effect actions.6 We refer to the restricted problems as SE
STRIPS PLAN and ACYCLIC SE STRIPS PLAN , respectively.
To prove PSPACE-hardness of both problems, we describe a mapping from STRIPS instances to
single-effect STRIPS instances.7
Consider an instance PE = hV, α0 , γ, ACTi of the STRIPS PLAN problem, where ACT is not necessarily acyclic. For each action a ∈ ACT we introduce a new variable xa , whose intuitive meaning
is that action a is currently being executed.
V
We set X = a∈ACT ¬xa . That is, X is the conjunction of negative literals of all the additional
V
variables. In addition, for each a ∈ ACT we set Xa = xa ∧ b∈ACT−{a} ¬xb . We now define an
instance PE′ = hV ′ , α′0 , γ′ , S(ACT)i of the SE STRIPS PLAN problem as follows:
6. Such actions are also called “unary” actions in the planning literature. We stick to the terminology “single-effect”
although it is less commonly used, simply because it is more explicit.
7. PSPACE-completeness of propositional STRIPS planning with single-effect actions was proved already by Bylander
(1994). However, to deal with acyclicity we need to give a different reduction than the one used in that paper.

412

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

• Set of variables: V ′ = V ∪ {xa : a ∈ ACT};
• initial state: α′0 = α0 ∧ X;
• goal state: γ′ = γ ∧ X;
• set of actions: S(ACT) = {ai : a ∈ ACT, i = 1, . . . , 2|post(a)| + 1}.
Let a be an action in ACT such that post(a) = l1 ∧ · · · ∧ lq , where l1 , . . . , lq are literals.
– For i = 1, . . . , q, we define an action ai by setting:
pre(ai ) = pre(a) ∧ X ∧ ¬li ; post(ai ) = xa .
The role of ai is to enforce that Xa holds after ai is successfully applied, and in this
way to enable “starting the execution of a”, provided that no action is currently being
executed, that the ith effect of a is not already true, and that the precondition of a is true.
– For i = q + 1, . . . , 2q, we define action ai by setting:
pre(ai ) = Xa ; post(ai ) = li .
The role of ai is to make the ith effect of a true.
– Finally, we define a2q+1 by setting:
pre(a2q+1 ) = Xa ∧ l1 ∧ · · · ∧ lq ; post(a2q+1 ) = ¬xa .
Thus, a2q+1 is designed so that X holds after a2q+1 is successfully applied; that is, a2q+1
“closes” the execution of a, thus allowing for the next action to be executed.
Let π be a sequence of actions in ACT. We define S(π) to be the sequence of actions in S(ACT)
obtained by replacing each action a in π by a1 , . . . , a2q+1 , where q = |post(a)|. Now consider a
sequence τ of actions from S(ACT). Remove from τ every action ai such that i 6= 2|post(a)| + 1,
and replace actions of the form a2|post(a)|+1 by a. We denote the resulting sequence of actions from
ACT by S′ (τ). We note that S′ (S(π)) = π. The following properties then hold.
Lemma 1 With the above definitions,
(i) if π is a plan for PE then S(π) is a plan for PE′ ;
(ii) if τ is an irreducible plan for PE′ then S′ (τ) is an irreducible plan for PE;
(iii) ACT is acyclic if and only if S(ACT) is acyclic.
Proof: (i) Let a ∈ ACT be an action, let α be a state and let β be the state obtained from α by
applying a. Let θ be the V ′ -state obtained by applying the sequence of actions ha1 , . . . , a2q+1 i
(where q = |post(a)|) to the state α ∧ X of PE′ . We will show that θ = β ∧ X.
We note that if for each i = 1, . . . , q, state α ∧ X does not satisfy pre(ai ) then the sequence of
actions ha1 , . . . , a2q+1 i has no effect, so the state is still α ∧ X. For this to happen, either α doesn’t
satisfy pre(a), or all of l1 , . . . , lq already hold in α so post(a) holds in α. In either case, α = β, and
so θ = β ∧ X.
413

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Suppose now that for some i ∈ {1, . . . , q}, α does satisfy pre(ai ). Then the first such action
causes xa and hence Xa to hold. After applying actions aq+1 , . . . , a2q , l1 ∧ · · · ∧ lq holds, and so
post(a) holds. After applying a2q+1 both post(a) and X hold. No other variable in V has changed,
so θ = β ∧ X, as required.
Applying this result iteratively implies that if π is a plan for PE then S(π) is a plan for PE′ .

ai

(ii) Let τ be an irreducible plan for PE′ , so that every action in τ changes the state, which implies
that every action in τ is performed in a state where its precondition is true. We will show that S′ (τ)
/ When τ = 0,
/ S′ (τ) = 0,
/ too, and the assertion follows.
is a plan for PE. We will assume that τ 6= 0.
j
′
Write the first action in τ as a , where a ∈ ACT, and let τ be the maximal initial subsequence of
τ consisting of all actions of the form ai . We must have j ≤ |post(a)|, since X holds in α′0 (by our
assumption above, action a j does apply) and X is inconsistent with the precondition of ai for each
i > |post(a)|. Also, pre(a j ) and ¬l j hold in α′0 and so, in α0 as well. Thus, α0 satisfies pre(a), and
applying a changes the state, since ¬l j holds in α0 and post(a) |= l j . Let us denote by β the state
resulting from applying a to α0 . As we noted, β 6= α0 ,
Let β′ be the state resulting after applying τ′ to α′0 . If β′ is the goal state γ′ then X holds in β′ . If
β′ is not the goal state then τ 6= τ′ . Let bi be the action in τ directly following the last action in τ′ .
By the definition of τ′ , a 6= b. After applying a j , Xa holds, so in β′ either Xa holds or X holds. Thus,
Xb does not hold, as a 6= b. Since bi changes the state, i must be in {1, . . . , |post(b)|}, so X holds in
β′ in this case, too.
Hence the last action in τ′ is a2q+1 , where q = |post(a)|. Since the only variables in V which can
be affected by actions ai are those that appear in the literals in post(a) and since the action a2q+1
can be executed (otherwise it would not belong to τ), it follows that β′ = β ∧ X.
Applying this reasoning repeatedly, we show that applying S′ (τ) to α0 yields γ, and that each
action in S′ (τ) changes the state, so S′ (τ) is an irreducible plan for PE, which is non-empty if and
only if τ is non-empty.
(iii) Suppose ACT is not acyclic, so that there exists state α and a non-empty irreducible plan π for
PEα = hV, α, α, ACTi. Then, by (i), S(π) is a plan for PE′α = hV ′ , α ∧ X, α ∧ X, S(ACT )i. Because
π is non-empty and irreducible, it changes some state, so S(π) also changes some state, and hence
can be reduced to a non-empty irreducible plan for PE′α . Therefore S(ACT) is not acyclic.
Conversely, suppose that S(ACT) is not acyclic. Then there exists a state α′ and a non-empty
irreducible plan τ for hV ′ , α′ , α′ , S(ACT)i. We will first prove that X holds at some state obtained
during the execution of this plan.
/ By
Suppose that X holds at no such state, and let a j be the first action in τ. We note that τ 6= 0.
our assumption, X does not hold either before or after applying a j . Therefore q + 1 ≤ j ≤ 2q, where
q = |post(a)|. Since τ is irreducible, a j changes the state. Thus, ¬l j holds in α′ and l j holds in the
state resulting from α′ after applying a j .
By our assumption, Xa holds before and after applying a j . Thus, the next action, if there is one,
must also be of the form ai for q + 1 ≤ i ≤ 2q. Repeating this argument implies that all actions in
τ are of the form ai where q + 1 ≤ i ≤ 2q. Since the set of literals in post(a) is consistent, l j is
never reset back to ¬l j . Thus, the state resulting from α′ after applying τ is different from α′ , a
contradiction.
Thus, X holds at some state reached during the execution of τ. Let us consider one such state.
It can be written as β ∧ X, for some state β over V . We can cyclically permute τ to generate a
non-empty irreducible plan τ′ for hV ′ , β ∧ X, β ∧ X, S(ACT)i. By part (ii), S′ (τ′ ) is a non-empty
414

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

irreducible plan for hV, β, β, ACTi. Therefore ACT is not acyclic.



Proposition 6
SE STRIPS PLAN

and ACYCLIC SE STRIPS PLAN are PSPACE-complete.

Proof: Again, the argument for the membership in PSPACE is standard. PSPACE-hardness of
ACYCLIC SE STRIPS PLAN is shown by reduction from ACYCLIC STRIPS PLAN . The same construction shows that STRIPS PLAN is reducible to SE STRIPS PLAN, and thus SE STRIPS PLAN is
PSPACE-complete.
Let us consider an instance PE = hV, α0 , γ, ACTi of ACYCLIC STRIPS PLAN. We define PE′ =
′
hV , α′0 , γ′ , S(ACT)i, which by Lemma 1(iii) is an instance of the ACYCLIC SE STRIPS PLAN problem. By Lemma 1(i) and (ii) there exists a plan for PE if and only if there exists a plan for PE′ . This
implies that ACYCLIC SE STRIPS PLAN is PSPACE-hard.


4. Dominance
The goal of this section is to prove that the GCP - DOMINANCE problem is PSPACE-complete, and
that the complexity does not go down even when we restrict the class of inputs to CP-nets. We
use the results on propositional STRIPS planning from Section 3 to prove that the general GCP DOMINANCE problem is PSPACE-complete. We then show that the complexity does not change if
we require the input GCP-net to be locally consistent and locally complete.
The similarities between dominance testing in CP-nets and propositional STRIPS planning were
first noted by Boutilier et al. (1999). They presented a reduction, discussed later in more detail by
Boutilier et al. (2004a), from the dominance problem to the plan existence problem for a class
of propositional STRIPS planning specifications consisting of unary actions (actions with single
effects). We prove our results for the GCP - DOMINANCE and GCP - CONSISTENCY problems by constructing a reduction in the other direction.
This reduction is much more complex than the one used by Boutilier et al. (1999), due to the
fact that CP-nets impose more restrictions than STRIPS planning. Firstly, STRIPS planning allows
multiple effects, but GCP-nets only allow flips x > ¬x or ¬x > x that change the value of one
variable; this is why we constructed the reduction from STRIPS planning to single-effect STRIPS
planning in the last section. Secondly, CP-nets impose two more restrictions, local consistency and
local completeness, which do not have natural counterparts in the context of STRIPS planning.
For all dominance and consistency problems we consider, the membership in PSPACE can be
demonstrated similarly to the membership proof of Proposition 4, namely by considering nondeterministic polynomial space algorithms consisting of repeatedly guessing appropriate improving flips
and making use of the fact that PSPACE = NPSPACE = coPSPACE. Therefore, from now on we
only provide arguments for the PSPACE-hardness of problems we consider.
4.1 Dominance for Generalized CP-Nets
We will prove that the GCP - DOMINANCE problem is PSPACE-complete by a reduction from the
problem SE STRIPS PLAN, which we now know to be PSPACE-complete.
415

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

4.1.1 M APPING S INGLE -E FFECT STRIPS P ROBLEMS
P ROBLEMS

TO

GCP-N ETS D OMINANCE

Let hV, α0 , γ, ACTi be an instance of the SE STRIPS PLAN problem. For every action a ∈ ACT
we denote by la the unique literal in the postcondition of a, that is, post(a) = la . We denote by
pre′ (a) the conjunction of all literals in pre(a) different from ¬la (we recall that by a convention we
adopted earlier, pre′ (a) does not contain la ). We then define ca to be the conditional preference rule
pre′ (a) : la > ¬la and define M(ACT) to be the GCP-net C = {ca : a ∈ ACT}, which is in conjunctive
form.
A sequence of states in a plan corresponds to an improving sequence from α0 to γ, which leads
to the following result.
Lemma 2 With the above notation,
(i) there is a non-empty irreducible plan for hV, α0 , γ, ACTi if and only if γ dominates α0 in
M(ACT);
(ii) ACT is acyclic if and only if M(ACT) is consistent.
Proof: We first note the following equivalence. Let a be an action in ACT, and let α and β be
different outcomes (or, in the STRIPS setting, states). The action a applied to α yields β if and only
if the rule ca sanctions an improving flip from α to β. This is because a applied to α yields β if and
only if α satisfies pre(a) and α and β differ only on literal la , with β satisfying la and α satisfying
¬la . This is if and only if α satisfies pre′ (a) and α and β differ only on literal la , with β satisfying
la , and α satisfying ¬la . This, in turn, is equivalent to say that rule ca sanctions an improving flip
from α to β.
Proof of (i): Suppose first that there exists a non-empty irreducible plan a1 , . . . , am for hV, α0 , γ, ACTi.
Let α0 , α1 , . . . , αm = γ be the corresponding sequence of outcomes, and, for each i = 1, . . . , m, action ai , when applied in state αi−1 , yields different state αi . By the above equivalence, for each
i = 1, . . . , m, cai sanctions an improving flip from αi−1 to αi , which implies that α0 , α1 , . . . , αm is an
improving flipping sequence in M(ACT), and therefore γ dominates α0 in M(ACT).
Conversely, suppose that γ dominates α0 in M(ACT), so that there exists an improving flipping
sequence α0 , α1 , . . . , αm with αm = γ, and m ≥ 1. For each i = 1, . . . , m, let cai be an element of
M(ACT) which sanctions the improving flip from αi−1 to αi . Then, by the above equivalence,
action ai , when applied to state αi−1 yields αi (which is different from αi−1 ), and so a1 , . . . , am is a
non-empty irreducible plan for hV, α0 , γ, ACTi.
Proof of (ii): ACT is not acyclic if and only if there exists a state α and a non-empty irreducible
plan for hV, α, α, ACTi. By (i) this is if and only if there exists an outcome α which dominates itself
in M(ACT), which is if and only if M(ACT) is not consistent.


Theorem 1 The GCP - DOMINANCE problem is PSPACE-complete. Moreover, this remains so under
the restrictions that the GCP-net is consistent and is in conjunctive form.
Proof: PSPACE-hardness is shown by reduction from ACYCLIC SE STRIPS PLAN (Proposition 6).
Let hV, α0 , γ, ACTi be an instance of the ACYCLIC SE STRIPS PLAN problem. By Lemma 2(ii),
M(ACT) is a consistent GCP-net in conjunctive form. Since α0 6= γ (imposed in the definition of
416

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

the problem ACYCLIC SE STRIPS PLAN), there is a plan for hV, α0 , γ, ACTi if and only if there is a
non-empty irreducible plan for hV, α0 , γ, ACTi, which, by Lemma 2(i), is if and only if γ dominates
α0 in C.

Theorem 1 implies the PSPACE-completeness of dominance in the more general conditional
preference language introduced by Wilson (2004b), where the conditional preference rules are written in conjunctive form.
4.2 Dominance in CP-Nets
In this section we show that GCP - DOMINANCE remains PSPACE-complete under the restriction to
locally consistent and locally complete GCP-nets, that is, CP-nets. We refer to this restriction of
GCP - DOMINANCE as CP - DOMINANCE .
Consistency of a GCP-net implies local consistency (Proposition 2). Therefore, the reduction in the proof of Theorem 1 (from ACYCLIC SE STRIPS PLAN to GCP - DOMINANCE restricted
to consistent GCP-nets) is also a reduction to GCP - DOMINANCE restricted to locally consistent
GCP-nets. PSPACE-hardness of ACYCLIC SE STRIPS PLAN (Proposition 6) then implies that GCP DOMINANCE restricted to locally consistent GCP-nets is PSPACE-hard, and, in fact, PSPACEcomplete since membership in PSPACE is easily obtained with the usual line of argumentation.
We will show PSPACE-hardness for CP - DOMINANCE by a reduction from GCP - DOMINANCE
for consistent GCP-nets.
4.2.1 M APPING L OCALLY C ONSISTENT GCP-N ETS

TO

CP-N ETS

Let C be a locally consistent GCP-net. Let V = {x1 , . . . , xn } be the set of variables of C. We define
/ We define a GCP-net C′ over V ′ , which we
V ′ = V ∪ {y1 , . . . , yn }, where {y1 , . . . , yn } ∩ V = 0.
will show is a CP-net. To this end, for every z ∈ V ′ we will define conditional preference rules
q+ (z) : z > ¬z and q− (z) : ¬z > z to be included in C′ by specifying formulas q+ (z) and q− (z).
First, for each variable xi ∈ V , we set
q+ (xi ) = yi and q− (xi ) = ¬yi .
Thus, xi depends only on yi . We also note that the formulas q+ (xi ) and q− (xi ) satisfy local consistency and local completeness requirements.
Next, for each variable yi , 1 ≤ i ≤ n, we define
ei = (x1 ↔ y1 ) ∧ · · · ∧ (xi−1 ↔ yi−1 ) ∧ (xi+1 ↔ yi+1 ) ∧ · · · ∧ (xn ↔ yn ),
fi+ = ei ∧ p+ (xi ) and fi− = ei ∧ p− (xi ).
Finally, we define
q+ (yi ) = fi+ ∨ (¬ fi− ∧ xi )
and
q− (yi ) = fi− ∨ (¬ fi+ ∧ ¬xi ).
Thus, yi depends on every variable in V ′ but itself.
We note that by the local consistency of C, formulas fi+ ∧ fi− , 1 ≤ i ≤ n, are unsatisfiable.
Consequently, formulas q+ (yi ) ∧ q− (yi ), 1 ≤ i ≤ n, are unsatisfiable. Thus, C′ is locally consistent.
417

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Finally, q+ (yi ) ∨ q− (yi ) is equivalent to fi+ ∨ ¬xi ∨ fi− ∨ xi , so is a tautology. Thus, C′ is locally
complete and hence a CP-net over V ′ .
Let α and β be outcomes over {x1 , . . . , xn } and {y1 , . . . , yn }, respectively. By αβ we denote the
outcome over V ′ obtained by concatenating n-tuples α and β. Conversely, every outcome for C′ can
be written in this way.
Let α be an outcome over V . We define α to be the outcome over {y1 , . . . , yn } obtained by
replacing in α every component of the form xi with yi and every component ¬xi with ¬yi . Then for
every i, 1 ≤ i ≤ n, αα |= ei .
Let s be a sequence α0 , . . . , αm of outcomes over V . Define L(s) to be the sequence of V ′ outcomes: α0 α0 , α0 α1 , α1 α1 , α1 α2 , . . . , αm αm . Further, let t be a sequence ε0 , ε1 , . . . , εm of V ′ outcomes with ε0 = αα and εm = ββ. Define L′ (t) to be the sequence obtained from t by projecting
each element in t to V and iteratively removing elements in the sequence which are the same as their
predecessor (until any two consecutive outcomes are different).
Lemma 3 With the above definitions,
(i) if s is an improving sequence for C from α to β then L(s) is an improving sequence for C′ from
αα to ββ;
(ii) if t is an improving sequence from αα to ββ then L′ (t) is an improving sequence from α to β;
(iii) C is consistent if and only if C′ is consistent.
Proof: Let e = ni=1 (xi ↔ yi ). The definitions have been arranged so that the GCP-net C and the
CP-net C′ have the following properties:
(a) If e does not hold in an outcome γ over V ′ , then every improving flip applicable to γ changes the
value of some variable xi or yi so that xi ↔ yi holds after the flip.
Indeed, let us assume that there is an improving flip from γ to some outcome γ′ over V ′ . If the
flip concerns a variable xi , then xi ↔ ¬yi holds in γ. Consequently, xi ↔ yi holds in γ′ .
Thus, let us assume that the flip concerns a variable yi . If ei holds in γ then, since e does not,
xi ↔ ¬yi holds in γ. Thus, xi ↔ yi holds in γ′ . If ei does not hold in γ then neither fi+ nor fi− does.
Thus, if xi (¬xi , respectively) holds in γ, yi (¬yi , respectively) holds in γ′ . Since the flip concerns yi ,
it follows that xi ↔ yi holds in γ′ .
(b) No improving flip from αα changes any variable xi .
Indeed, for any variable xi , since e holds in αα, xi ↔ yi holds in αα, too. Thus, no improving
flip changes xi .
(c) There is an improving flip in C′ that changes variable yi in an outcome αα if and only if there is
an improving flip for the GCP-net C from outcome α that changes variable xi . After applying the
improving flip (changing variable yi ) to αα, there is exactly one improving flip possible. It changes
xi and results in an outcome ββ, where β is the outcome over V resulting from applying to α the
improving flip changing the variable xi .
To prove (c), let us first assume that ¬yi holds in αα and observe that in such case ¬xi holds in
αα, too. It follows that q+ (yi ) holds in αα if and only if p+ (xi ) holds in α. Consequently, changing
yi in αα is an improving flip in C′ if and only if changing xi in α is an improving flip in C. The
argument in the case when yi holds in αα is analogous (but involves q− (yi ) and p− (xi )). Thus, the
first part of (c) follows.
V

418

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

Let β be the outcome obtained by applying an improving flip to xi in α. It follows that the
improving flip changing the value of yi in αα results in the outcome αβ. In this outcome, by (a),
an improving flip must concern x j or y j such that x j ↔ y j holds after the flip. Since for every j 6= i,
x j ↔ y j holds in αβ, the only improving flips in αβ concern either xi or yi . By the local consistency
of C′ , yi cannot be flipped right back. Clearly, changing xi is an improving flip that can be applied
to αβ. By our discussion, it is the only improving flip applicable in αβ and it results in the outcome
ββ. This proves the second part of (c).
Proof of (i): The assertion follows by iterative application of (c).
Proof of (ii): Suppose that t is an improving sequence ε0 , ε1 , . . . , εm of V ′ -outcomes with ε0 = αα
and εm = ββ. Since e holds in ε0 , (b) implies that the first flip changes some variable yi , and (c)
implies that the second flip changes variable xi to make xi ↔ yi hold again. Hence ε2 can be written
as δδ. By (c) there is an improving flip in C from outcome α changing variable xi , that is, leading
from α to δ. Iterating this process shows that L′ (t) is an improving sequence from α to β.
Proof of (iii): Suppose that C is inconsistent. Then there exists some outcome α and an improving
sequence s in C from α to α. By (i), L(s) is an improving sequence from αα to αα, proving that C′
is inconsistent.
Conversely, suppose that C′ is inconsistent, so there exists an improving sequence t for C′ from
some outcome to itself. By (a), any improving flip applied to an outcome in which e does not hold
increases (by one) the number of i such that xi ↔ yi holds. This implies that e must hold in some
outcome in t, because t is not acyclic. Write this outcome as αα. We can cyclically permute t to
form an improving sequence t2 from αα to itself. Part (ii) then implies that L′ (t2 ) is an improving
flipping sequence for C from α to itself, showing that C is inconsistent.


Theorem 2 CP - DOMINANCE is PSPACE-complete. This holds even if we restrict the CP-nets to
being consistent.
Proof: We use a reduction from PSPACE-hardness of the GCP - DOMINANCE problem when the
GCP-nets are restricted to being consistent (Theorem 1). Let C be a consistent, and hence locally
consistent, GCP-net over V , and let α and β be outcomes over V . Consider the CP-net C′ over
variables V ′ constructed above. Lemma 3(i) and (ii) imply that β dominates α in C if and only if ββ
dominates αα in C′ . Moreover, C′ is consistent by Lemma 3(iii). Consequently, the hardness part
of the assertion follows.

Note that PSPACE-hardness obviously remains if we require input outcomes to be different,
because the reduction for Theorem 1 uses a pair of different outcomes.
Notice the huge complexity gap with the problem of deciding whether there exists a nondominated outcome, which is “only” NP-complete (Domshlak et al., 2003, 2006).

5. Consistency of GCP-Nets
In this section we show that the
from Sections 3 and 4.

GCP - CONSISTENCY

419

problem is PSPACE-complete, using results

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Theorem 3
GCP - CONSISTENCY is PSPACE-complete. This holds even under the restriction to GCP-nets in
conjunctive form.
Proof: PSPACE-hardness is shown by reduction from ACTION - SET ACYCLICITY. We apply function S from Section 3.2 followed by M from Section 4.1. This maps instances of ACTION - SET
ACYCLICITY to instances of GCP - CONSISTENCY in conjunctive form. By Lemma 1(iii) and Lemma
2 (ii), an instance of ACTION - SET ACYCLICITY is acyclic if and only if the corresponding instance
of GCP - CONSISTENCY is consistent, proving the result.

We now show that consistency testing remains PSPACE-complete for CP-nets (GCP-nets that
are both locally consistent and locally complete).
Theorem 4

CP - CONSISTENCY

is PSPACE-complete.

Proof: We use a reduction from GCP - CONSISTENCY under the restriction that the GCP-net is in
conjunctive form. Let C be a GCP-net in conjunctive form. We define a CP-net C′ as follows. Because C is in conjunctive form, local consistency can be decided in polynomial time, as it amounts
to checking the consistency of a conjunction of conjunctions of literals. If C is not locally consistent
we set C′ to be a predetermined inconsistent but locally consistent CP-net, such as in the example
in Section 2. Otherwise, C is locally consistent and for C′ we take the CP-net we constructed in
Section 4.2. The mapping from locally consistent GCP-nets to CP-nets, described in Section 4.2,
preserves consistency (Lemma 3 (iii)). Since local inconsistency implies inconsistency (Proposition 2), we have that the GCP-net C is consistent if and only if the CP-net C′ is consistent. Thus,
PSPACE-hardness of the CP - CONSISTENCY problem follows from Theorem 3.


6. Additional Problems Related to Dominance in GCP-Nets
Having proved our main results on consistency of and dominance in GCP-nets, we move on to
additional questions concerning the dominance relation. Before we state them, we introduce more
terminology.
Let α and β be outcomes in a GCP-net C. We say that α and β are dominance-equivalent in C,
written α ≈C β, if α = β, or α ≺C β and β ≺C α. Next, α and β are dominance-incomparable in C
if α 6= β, α⊀C β and β⊀C α. Finally, α strictly dominates β if β ≺C α and α6≺C β.
Definition 8
We define the following decision problems:
SELF - DOMINANCE : given a GCP-net C and an outcome α, decide whether α ≺C α, that is, whether
α dominates itself in C.
STRICT DOMINANCE : given a GCP-net C and outcomes α and β, decide whether α strictly dominates β in C.
DOMINANCE EQUIVALENCE : given a GCP-net C and outcomes α and β, decide whether α and β
are dominance-equivalent in C.
DOMINANCE INCOMPARABILITY : given a GCP-net C and outcomes α and β, decide whether α
and β are dominance-incomparable in C.
420

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

When establishing the complexity of these problems, we will use polynomial-time reductions
from the problem GCP - DOMINANCE. Let H be a GCP-net with the set of variables V = {x1 , . . . , xn },
and let β be an outcome. We define a GCP-net G = Θ1 (H, β) with the set of variables W = V ∪ {y}
by setting the conditions for flips on variables xi , i = 1, . . . , n, and y as follows:
1. if xi ∈ β:
+
p+
G (xi ) = pH (xi ) ∨ ¬y
−
p−
G (xi ) = pH (xi ) ∧ y
2. if ¬xi ∈ β:
+
p+
G (xi ) = pH (xi ) ∧ y
−
p−
G (xi ) = pH (xi ) ∨ ¬y
3. p+
G (y) = β
4. p−
G (y) = ¬β.
The mapping Θ1 can be computed in polynomial time. Moreover, one can check that if H is a
locally consistent GCP-net, Θ1 (H, β) is also locally consistent. Finally, if H is a CP-net, Θ1 (H, β)
is a CP-net, as well.
For every V -outcome γ, we let γ+ = γ ∧ y and γ− = γ ∧ ¬y. We note that every W -outcome is of
the form γ+ or γ− . To explain the structure of the GCP-net G, we point out that there is an improving
flip in G from γ+ into δ+ if and only if there is an improving flip in H from γ to δ (thus, G restricted
to outcomes of the form γ+ forms a copy of the GCP-net H). Moreover, there is an improving flip
in G from γ− into δ− if and only if δ agrees with β on exactly one more variable xi than γ does.
Finally, an improving flip moves between outcomes of different type if and only if it transforms β−
to β+ , or γ+ to γ− for some γ 6= β.
We now formalize some useful properties of the GCP-net G = Θ1 (H, β). We use the notation
introduced above.
Lemma 4 For every V -outcome γ, γ− ≺G β+ and, if γ 6= β, γ+ ≺G β+ (in other words, β+ dominates
every other W -outcome).
Proof: Consider any V -outcome γ 6= β. Then γ ∧ ¬y ≺C β ∧ ¬y since, given ¬y, changing a literal
to the form it has in β is an improving flip. By the definition, we also have β ∧ ¬y ≺C β ∧ y and
γ ∧ y ≺G γ ∧ ¬y (as γ 6= β). It follows that β− ≺G β+ and γ+ ≺G γ− ≺G β+ . Thus, the assertion
follows.


Lemma 5 For arbitrary V -outcome α different from β, the following statements are equivalent:
1. β ≺H α;
2. β+ ≺G α+ ;
3. β+ ≈G α+ .
421

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Proof: By Lemma 4, α+ ≺G β+ . Thus, the conditions (2) and (3) are equivalent.
[(1)⇒(2)] Clearly (recall our discussion about the structure of G), if there is an improving flip from
γ to δ in H, then there is an improving flip from γ+ to δ+ in G. Thus, if there is an improving
sequence in H from β to α, there is an improving sequence in G from β+ to α+ .
[(2)⇒(1)] Let us assume β+ ≺G α+ , and let us consider an improving sequence of minimum length
from β+ to α+ . By the minimality, no internal element in such a sequence is β+ . Thus, no internal
element equals β− either (as the only improving flip from β− leads to β+ ). Since an improving flip
from γ− to γ+ requires that γ = β, all outcomes in the sequence are of the form γ+ . By dropping
y from each outcome in this sequence, we get an improving flipping sequence from α to β in H.
Thus, β ≺H α.

Lemma 6 Let H be consistent and let α and β be different V -outcomes. Then, α+ ≺G α+ if and
only if β ≺H α.
Proof: Suppose there exists an improving sequence from α+ to itself. There must be an outcome
in the sequence of the form γ ∧ ¬y (otherwise, dropping y in every outcome yields an improving
sequence from α to α in H, contradicting the consistency of H). To perform an improving flip from
¬y to y we need β to hold, which implies that β+ appears in the sequence. Thus, β+ ≺G α+ . By
Lemma 5, β ≺H α.
Conversely, let us assume that β ≺H α. Again by Lemma 5, β+ ≺G α+ . By Lemma 4, α+ ≺G β+ .
Thus, α+ ≺G α+ .

The next construction is similar. Let H be a GCP-net on variables V = {x1 , . . . , xn }, and let α
be an outcome. We define a GCP-net F = Θ2 (H, α) as follows. As before, we set W = V ∪ {y} to
be the set of variables of F. We define the conditions for flips on variables xi , i = 1, . . . , n, and y as
follows:
+
1. p+
G (xi ) = pH (xi ) ∧ y
−
2. p−
G (xi ) = pH (xi ) ∧ y

3. p+
G (y) = ¬α
4. p−
G (y) = α.
Informally, outcomes of the form γ+ form in F a copy of H. There are no improving flips between
outcomes of the form γ− . There is an improving flip from α+ to α− and, for every γ 6= α, from γ− to
γ+ . In particular, if F is consistent then Θ2 (H, α) is consistent, The mapping Θ2 can be computed
in polynomial time and we also have the following property.
Lemma 7 Let β be a V -outcome different from α. Then the following conditions are equivalent:
1. β ≺H α
2. α− strictly dominates β− in F
3. α− and β− are not dominance-incomparable in F.
422

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

Proof: If there exists an improving sequence from β− to α− then the first improving flip in the sequence changes β− to β+ . Moreover, there is an improving flip from γ+ to γ− if and only if γ = α.
Thus, β− ≺F α− if and only if β ≺H α. Since α− ⊀F β− all three conditions are equivalent.


Proposition 7 The following problems are PSPACE-complete: SELF - DOMINANCE, STRICT
INANCE , DOMINANCE EQUIVALENCE , and DOMINANCE INCOMPARABILITY .

DOM -

Proof: For all four problems, membership is proven easily as for the problems in earlier sections.
For the PSPACE-hardness proofs, we use the problem CP - DOMINANCE in a version when we
required that the input CP-net be consistent and the two input outcomes different. The problem is
PSPACE-hard by Theorem 2.
Let H be a consistent CP-net on a set V of variables, and let α and β be two different V -outcomes.
By Lemma 5, β ≺H α can be decided by deciding the problem DOMINANCE EQUIVALENCE for α+
and β+ in the GCP-net Θ1 (H, β). Thus, the PSPACE-hardness of DOMINANCE EQUIVALENCE
follows.
Next, the equivalence of Lemma 6, α+ ≺G α+ ⇔ β ≺H α, which holds due to consistency of H,
shows that the problem SELF - DOMINANCE is PSPACE-hard.
Finally, by Lemma 7, β ≺H α can be decided either by deciding the problem STRICT DOMI NANCE for outcomes α− and β− in Θ2 (H, α), or by deciding the complement of the problem DOM INANCE INCOMPARABILITY for α− and β− in the GCP-net Θ2 (H, α). It follows that STRICT DOM INANCE and DOMINANCE INCOMPARABILITY (the latter by the fact that coPSPACE=PSPACE) are
PSPACE-complete.8


Corollary 1 The problems SELF - DOMINANCE and DOMINANCE EQUIVALENCE are PSPACE-complete under the restriction to CP-nets. The problems STRICT DOMINANCE and DOMINANCE IN COMPARABILITY remain PSPACE-complete under the restriction to consistent CP-nets.
Proof: Since in the proof of Proposition 7 we have that H is a CP-net, the claim for the first two
problems follows by our remarks that the mapping Θ1 preserves the property of being a CP-net.
For the last two problems, we observe that since H in the proof of Proposition 7 is assumed to
be consistent, F = Θ2 (H, α) is consistent, too. Thus, it is also locally consistent and the mapping
F to F ′ we used for the proof of Theorem 2 applies. In particular, F ′ is a consistent CP-net and has
the following properties (implied by Lemma 3):
1. α strictly dominates β in F if and only if αα strictly dominates ββ in F ′
2. α and β are dominance-incomparable in F if and only if αα and ββ are dominance-incomparable in F ′ .
Since F ′ is a consistent CP-net, the claim for the last two problems follows, too.



8. For STRICT DOMINANCE, the result could have been also obtained as a simple corollary of Theorem 2, since in
consistent GCP-nets dominance is equivalent to strict dominance.

423

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

7. Problems Concerning Optimality in GCP-Nets
The dominance relation ≺C of a GCP-net C determines a certain order relation, which gives rise to
several notions of optimality. We will introduce them and study the complexity of corresponding
decision problems.
We first observe that the dominance equivalence relation is indeed an equivalence relation (reflexive, symmetric and transitive). Thus, it partitions the set of all outcomes into non-empty equivalence classes, which we call dominance classes. We denote the dominance class of an outcome α
in a GCP-net C by [α]C .
The relation ≺C induces on the set of dominance classes a strict order relation (a relation that is
irreflexive and transitive). Namely, we define [α]C ≺Cdc [β]C if [α]C 6= [β]C (equivalently, α 6≈C β) and
α ≺C β. One can check that the definition of the relation ≺Cdc on dominance classes is independent
of the choice of representatives of the classes.
Definition 9 (Non-dominated class, optimality in GCP-nets) Let C be a GCP-net. A dominance
class [α]C is non-dominated if it is maximal in the strict order ≺Cdc (there is no dominance class
[β]C such that [α]C ≺Cdc [β]C ). A dominance class is dominating if for every dominance class [β]C ,
[α]C = [β]C or [β]C ≺Cdc [α]C .
An outcome α is weakly non-dominated if it belongs to a non-dominated class. If α is weakly
non-dominated and is the only element in its dominance class, then α is non-dominated.
An outcome α is dominating if it belongs to a dominating class. An outcome α is strongly
dominating if it is dominating and non-dominated.
Outcomes that are weakly non-dominated, non-dominated, dominating and strongly dominating
capture some notions of optimality. In the context of CP-nets, weakly non-dominated and nondominated outcomes were proposed and studied before (Brafman & Dimopoulos, 2004). They were
referred to as weakly and strongly optimal there. Similar notions of optimality were also studied
earlier for the problem of defining winners in partial tournaments (Brandt, Fischer, & Harrenstein,
2007). We will study here the complexity of problems to decide whether a given outcome is optimal
and whether optimal outcomes exist.
First, we note the following general properties (simple consequences of properties of finite strict
orders).
Lemma 8 Let C be a GCP-net.
1. There exist non-dominated classes and so, weakly non-dominated outcomes.
2. Dominating outcomes and nondominated outcomes are weakly non-dominated.
3. A strongly dominating outcome is dominating and non-dominated.
4. The following conditions are equivalent:
(a) C has a unique non-dominated class;
(b) C has a dominating outcome;
(c) weakly non-dominated and dominating outcomes in C coincide.
For consistent GCP-nets only two different notions of optimality remain.
424

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

Lemma 9 Let C be a consistent GCP-net. Then:
1. Each dominance class is a singleton, ≺C is a strict order, and ≺C and ≺Cdc coincide (modulo
the one-to-one and onto correspondence α 7→ [α]C )
2. If α is a weakly non-dominated outcome, α is non-dominated (weakly non-dominated and
non-dominated outcomes coincide)
3. If α is a dominating outcome, α is strongly dominating (strongly dominating and dominating
outcomes coincide).
4. Finally, α is a unique (weakly) non-dominated outcome if and only if α is strongly dominating.
Next, we observe that all concepts of optimality we introduced are different. To this end, we will
show GCP-nets with a single non-dominated class that is a singleton, with multiple non-dominated
classes, each being a singleton, with a single non-dominated class that is not a singleton, and with
multiple non-dominated classes, each containing more than one element. We will also show a GCPnet with two non-dominated classes, one of them a singleton and the other one consisting of several
outcomes.
Example 2 Consider the following GCP-net C with two binary variables a and b
: a > ā
: b > b̄
This GCP-net determines a strict preorder on the dominance classes, in which {ab} is the only
maximal class (in fact, all dominance classes are singletons). Thus, ab is both non-dominated and
dominating and so, it is strongly dominating.
Example 3 Consider the following GCP-net C with two binary variables a and b
b : a > ā
b̄ : ā > a
a : b > b̄
ā : b̄ > b
This GCP-net determines a strict preorder, in which {ab} and {āb̄} are two different non-dominated
classes. Thus, ab and āb̄ are non-dominated and there is no dominating outcome.
Example 4 Consider a GCP-net with variables a, b and c, defined as follows:
a : b > b̄
ā : b̄ > b
b̄ : a > ā
b : ā > a
ab : c > c̄

425

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

There are two dominance classes: Sc = {abc, ab̄c, ābc, āb̄c} and Sc̄ = {abc̄, ab̄c̄, ābc̄, āb̄c̄}. Every
outcome in Sc strictly dominates every outcome in Sc̄ , therefore, Sc is the unique non-dominated
class and every outcome in Sc is dominating. Because Sc is not a singleton, there are no nondominated outcomes (and so, no strongly dominating outcome, either).
Example 5 Let us remove from the GCP-net of Example 4 the preference statement ab : c > c̄. Then
Sc and Sc̄ are still the two dominance classes, but now every outcome is Sc is incomparable with
any outcome in Sc̄ . Thus, Sc and Sc̄ are both non-dominated. Since there are two non-dominated
classes, there is no dominating outcome. Since each class has more than one element, there are no
non-dominated outcomes. All outcomes are weakly non-dominated, though.
Example 6 Let us modify the GCP-net of Example 4 by changing the preference statement b̄ : a > ā
into b̄c : a > ā. The dominance relation ≺ of this GCP-net satisfies the following properties: (i)
the four outcomes in Sc dominate each other; (ii) āb̄c̄ ≻ ābc̄ ≻ abc̄ ≻ ab̄c̄; (iii) any outcome in Sc
dominates abc̄ (and, a fortiori, ab̄c̄). One can check that there are five dominance classes: Sc , {abc̄},
{ābc̄}, {ab̄c̄} and {āb̄c̄}. Two of them are non-dominated: Sc and {āb̄c̄}. Since there are two nondominated classes, there is no dominating outcome. On the other hand, {āb̄c̄} is a non-dominated
outcome (a unique one).
We will consider the following decision problems corresponding to the notions of optimality we
introduced.
Definition 10
For a given GCP-net C:
WEAKLY NON - DOMINATED OUTCOME : given an outcome α, decide whether α is weakly nondominated in C
NON - DOMINATED OUTCOME : given an outcome α, decide whether α is non-dominated in C
DOMINATING OUTCOME : given an outcome α, decide whether α is dominating in C
STRONGLY DOMINATING OUTCOME : given an outcome α, decide whether α is strongly dominating in C
EXISTENCE OF A NON - DOMINATED OUTCOME : decide whether C has a non-dominated outcome
EXISTENCE OF A DOMINATING OUTCOME : decide whether C has a dominating outcome
EXISTENCE OF A STRONGLY DOMINATING OUTCOME : decide whether C has a strongly dominating outcome.
In some of the hardness proofs, we will again use the reductions Θ1 and Θ2 , described in the
previous section. We note the following additional useful properties of the GCP-net G = Θ1 (H, β).
Lemma 10 For arbitrary V -outcome α different from β, the following statements are equivalent:
1. β+ ≺G α+
2. α+ is weakly non-dominated in G
3. α+ is a dominating outcome in G.
426

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

Proof: Since β+ is dominating in G (Lemma 4), weakly non-dominated outcomes and dominating
outcomes coincide (Lemma 8). It follows that the conditions (1)-(3) are equivalent to each other. 

Proposition 8 The following problems are PSPACE-complete: WEAKLY NON - DOMINATED OUTCOME and DOMINATING OUTCOME . The result holds also for the problems restricted to CP-nets.
Proof: The membership is easy to prove by techniques similar to those we used earlier.
For the PSPACE-hardness proofs, we use reductions from CP - DOMINANCE for consistent CPnets (in the version where the two input outcomes are different). Let H be a CP-net, and α and
β two different V -outcomes. By Lemmas 5 and 10, β ≺H α can be decided by deciding either of
the problems WEAKLY NON - DOMINATED OUTCOME and DOMINATING OUTCOME for the GCPnet G = Θ1 (H, β) and the outcome α+ . We observed earlier, that if H is a CP-net, then so is
G = Θ1 (H, β). Thus, the second part of the assertion follows.

Next, we will consider the problem STRONGLY DOMINATING OUTCOME. We will exploit the
reduction F = Θ2 (H, α), which we discussed in the previous section. We observe the following
property of F.
Lemma 11 Let H be a GCP-net and F = Θ2 (H, α). Then α− is strongly dominating in F if and
only if α is dominating in H.
Proof: Let us assume that α is dominating in H. From the definition of F, it follows that for every
V -outcome γ 6= α, γ+ ≺F α+ and γ− ≺F γ+ . Since α+ ≺F α− , α− is dominating in F. Since there
is no improving flip leading out of α− , α− is strongly dominating.
Conversely, let us assume that α− is strongly dominating in F and let γ be a V -outcome different from α. Let us consider an improving sequence from γ+ to α− . All outcomes in the sequence
other than the last one, α− , are of the form δ+ . Moreover, the outcome directly preceding α− is
α+ . Dropping y from every outcome in the segment of the sequence between γ+ and α+ yields an
improving sequence from γ to α in H.

We now have the following consequence of this result.
Proposition 9 The problem STRONGLY
stricted to CP-nets.

DOMINATING OUTCOME

is PSPACE-complete, even if re-

Proof: Let H be a CP-net (over the set V of variables) and α an outcome. By Lemma 11, the problem DOMINATING OUTCOME can be decided by deciding the problem STRONGLY DOMINATING
OUTCOME for F = Θ2 (H, α) and α− . Thus, the PSPACE-hardness of STRONGLY DOMINATING
OUTCOME follows by Proposition 8. The membership in PSPACE is, as in other cases, standard and
is omitted.
Since H is a CP-net, it is locally consistent and so, F is locally consistent, too. As in the proof
of Corollary 1 we use the mapping from GCP-net F to CP-net F ′ defined in Section 4.2. By Lemma
3, α is a strongly dominating outcome in F if and only if αα dominates every outcome of the form
γγ, which is if and only if αα is a strongly dominating outcome in F ′ , since any F ′ -outcome is
dominated by an outcome of the form γγ (using the rules q+ (xi ) = yi and q− (xi ) = ¬yi ). Therefore
427

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

for F and α can be decided by deciding
for F ′ and αα. Thus, the second part of the claim follows.

STRONGLY DOMINATING OUTCOME
NATING OUTCOME

STRONGLY DOMI 

The problem NON - DOMINATED OUTCOME is easier. It is known to be in P for CP-nets (Brafman
& Dimopoulos, 2004). The result extends to GCP-nets. Indeed, if H is a GCP-net and α an outcome,
α is non-dominated if and only if there is no improving flip that applies to α. The latter holds if and
only if for every variable x in H, if x (respectively, ¬x) holds in α, then p− (x) (respectively, p+ (x))
does not hold in α. Since the conditions can be checked in polynomial the claim holds and we have
the following result.
Proposition 10 The problem NON - DOMINATED

OUTCOME

for GCP-nets is in P.

Next, we will consider the problems concerning the existence of optimal outcomes. Let H be a
GCP-net on the set of variables V = {x1 , . . . , xn }, and let α and β be two different V -outcomes. For
every i = 1, 2, . . . , n, we define formulas αi as follows. If xi ∈ α, then αi is the conjunction of all
literals in α, except that instead of xi we take ¬xi . Similarly, if ¬xi ∈ α, then αi is the conjunction of
all literals in α, except that instead of ¬xi we take xi . Thus, αi is the outcome that results in α when
the literal in corresponding to xi is flipped into its dual.
We now define a GCP-net E = Θ3 (H, α, β) by taking W = V ∪ {y} as the set of variables of E
and by defining the flipping conditions as follows:
+
1. p+
E (xi ) = (pH (xi ) ∧ y) ∨ (¬y ∧ ¬α ∧ ¬αi )
−
−
pE (xi ) = pH (xi ) ∧ y

2. p+
E (y) = β
3. p−
E (y) = ¬β.
The GCP-net Θ3 (H, α, β) has the following properties. The outcomes of the form γ+ (= γ ∧ y)
form a copy of H. There is no improving flip for the outcome α− (= α ∧ ¬y). Next, there is no
improving flip into α− from an outcome of the form γ− . To see this, let us assume that such a flip
exists and concerns a variable, say, xi . It follows that γ = αi . By the definition of flipping conditions,
an improving flip for γ− that involves xi is impossible, a contradiction. Thus, the only improving
flip that leads to α− originates in α+ .
We also have that for every outcome γ other than α and β, γ− ≺E β− . It follows from the fact
that for every outcome γ other than α and β, γ− has an improving flip. Indeed, for each such γ there
is a variable xi such that (i) xi is false in γ, and (ii) flipping the literal of xi to its dual does not lead to
α (that is, γ is not αi ). (For even if γ = αi for some i, then, because γ, α 6= β, there exists i′ 6= i such
that γ and β differ on xi′ , so that xi′ satisfies (i) and (ii).) Thus, a flip on that variable is improving.
As all improving flips between outcomes containing ¬y result in one more variable xi assigned to
true, thus having the same status as it has in β, γ− ≺E β− follows.
Finally, we have β− ≺E β+ and, for every outcome γ other than β, γ+ ≺E γ− . This leads to the
following property of E = Θ3 (H, α, β).
Lemma 12 Let H be a GCP-net and let α and β be two different outcomes. Then β ≺H α if and
only if Θ3 (H, α, β) has a (strongly) dominating outcome.
428

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

Proof: (Only if) Based on our earlier remarks, α+ ≺E α− . Moreover, since β ≺H α, we have
β+ ≺E α+ . In addition, for every γ different from α and β, γ+ ≺E γ− ≺E β− ≺E β+ . Thus, α− is
both dominating and strongly dominating (the latter follows from the fact that no improving flips
lead out of α− ).
(If) Let us assume that α− is dominating (and so, the argument applies also when α− is strongly
dominating). Then there is an improving sequence from β+ to α− . Let us consider a shortest such
sequence. Clearly, α+ is the outcome just before α− in that sequence (as we pointed out, no improving flip from an outcome of the form γ− to α− is possible). Moreover, by the definition of
Θ3 (H, α, β) and the fact that we are considering a shortest sequence from β+ to α− , every outcome
in the sequence between β+ and α+ is of the form γ+ . By dropping y from each of these outcomes,
we get an improving sequence from β to α.


Proposition 11 The problem EXISTENCE OF DOMINATING OUTCOME and the problem EXISTENCE
OF STRONGLY DOMINATING OUTCOME are PSPACE-complete, even if restricted to CP-nets.
Proof: We show the hardness part only, as the membership part is straightforward. To prove hardness we notice that by Lemma 12, given a consistent CP-net H and two outcomes α and β, β ≺H α
can be decided by deciding either of the problems EXISTENCE OF DOMINATING OUTCOME and
EXISTENCE OF STRONGLY DOMINATING OUTCOME for Θ3 (H, α, β). To prove the second part of
the assertion, we note that if H is consistent, E = Θ3 (H, α, β) is consistent, too and so, the mapping
from locally consistent GCP nets to CP-nets applies. Let us denote the result of applying the mapping to E by E ′ . Then, using the same argument as in the proof of Proposition 9, E has a (strongly)
dominating outcome if and only if E ′ has a strongly dominating outcome. Thus, one can decide
whether β ≺H α in a consistent CP-net H by deciding either of the problems EXISTENCE OF DOM INATING OUTCOME and EXISTENCE OF STRONGLY DOMINATING OUTCOME for E ′ .

We also note that the problem EXISTENCE
standard complexity theory assumptions).

OF NON - DOMINATED OUTCOME

Proposition 12 The problem EXISTENCE OF NON - DOMINATED

OUTCOME

is easier (under

is NP-complete.

Proof: We note that in the case of GCP-nets in conjunctive form the problem is known to be NP-hard
(Domshlak et al., 2003, 2006). Thus, the problem is NP-hard for GCP-nets. The membership in the
class NP follows from Proposition 10.

If we restrict to consistent GCP-nets, the situation simplifies. First, we recall (Lemma 9) that if
a GCP-net is consistent then weakly non-dominated and non-dominated outcomes coincide, and the
same is true for dominating and strongly dominating outcomes. Moreover, for consistent GCP-nets,
non-dominated outcomes exist (and so, the corresponding decision problem is trivially in P). Thus,
for consistent GCP-nets we will only consider problems DOMINATING OUTCOME and EXISTENCE
OF DOMINATING OUTCOME .
Proposition 13 The problems DOMINATING OUTCOME and
COME restricted to consistent GCP-nets are in coNP.
429

EXISTENCE OF DOMINATING OUT-

G OLDSMITH , L ANG , T RUSZCZY ŃSKI & W ILSON

Proof: Using Lemmas 8 and 9, α is not a dominating outcome if and only if there exists an outcome
β 6= α which is non-dominated. Similarly, there is no dominating outcome in a consistent GCP-net
if and only if there are at least two non-dominated outcomes. Thus, guessing non-deterministically
an outcome β 6= α, and verifying that β is non-dominated, is a non-deterministic polynomial-time
algorithm deciding the complement of the problem DOMINATING OUTCOME. The argument for the
other problem is similar.

We do not know if the bounds in Proposition 13 are tight, that is, whether these two problems
are coNP-complete. We conjecture they are.

8. Concluding Remarks
We have shown that dominance and consistency testing in CP-nets are both PSPACE-complete. Also
several related problems related to dominance and optimality in CP-nets are PSPACE-complete, too.
The repeated use of reductions from planning problems confirms the importance of the structural similarity between STRIPS planning and reasoning with CP-nets. This suggests that the welldeveloped field of planning algorithms for STRIPS representations, especially for unary operators
(Brafman & Domshlak, 2003), could be useful for implementing algorithms for dominance and
consistency in CP-nets.
Our theorems extend to CP-nets with non-binary domains, and to extensions and variations of
CP-nets, such as TCP-nets (Brafman & Domshlak, 2002; Brafman, Domshlak, & Shimony, 2006)
that allow for explicit priority of some variables over others, and the more general language for
conditional preferences (Wilson, 2004a, 2004b), where the conditional preference rules are written
in conjunctive form.
The complexity result for dominance is also relevant for the following constrained optimisation
problem: given a CP-net and a constraint satisfaction problem (CSP), find an optimal solution (a
solution of the CSP which is not dominated by any other solution of the CSP). This is computationally complex, intuitively because a complete algorithm involves many dominance checks when
the definition of dominance under constraints allows for dominance paths to go through outcomes
violating the constraints (Boutilier, Brafman, Domshlak, Hoos, & Poole, 2004b).9 The problem of
checking whether a given solution of a CSP is non-dominated can be seen to be PSPACE-complete
by a reduction from CP-dominance that uses a CSP that has exactly two solutions.
Our results reinforce the need for work on finding special classes of problems where dominance
and consistency can be tested efficiently (Domshlak & Brafman, 2002; Boutilier et al., 2004a),
and for incomplete methods for checking consistency and constrained optimisation (Wilson, 2004a,
2006).
Several open problems remain. We do not know the complexity of deciding whether the preference relation induced by a CP-net is complete. We do not know whether dominance and consistency
testing remain PSPACE-complete when the number of parents in the dependency graph is bounded
by a constant. We also do not know whether these two problems remain PSPACE-complete for
CP-nets in conjunctive form (the reduction used to prove Theorems 2 and 4 yields CP-nets that are
not in conjunctive form). Two additional open problems are listed at the end of Section 7.
9. With another possible definition, where going through outcomes violating the constraints is not allowed (Prestwich,
Rossi, Venable, & Walsh, 2005), dominance testing is not needed to check whether a given solution is non-dominated.

430

T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP-N ETS

Acknowledgments
Jérôme Lang’s new address is: LAMSADE, Université Paris-Dauphine, 75775 Paris Cedex 16,
France. The authors are grateful to the reviewers for their excellent comments, and to Pierre Marquis
for helpful discussions. This work was supported in part by the NSF under Grants ITR-0325063,
IIS-0097278 and KSEF-1036-RDE-008, by the ANR Project ANR–05–BLAN–0384 “Preference
Handling and Aggregation in Combinatorial Domains”, by Science Foundation Ireland under Grants
No. 00/PI.1/C075 and 05/IN/I886, and by Enterprise Ireland Ulysses travel grant FR/2006/36.


