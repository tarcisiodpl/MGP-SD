
Qualitative and infinitesimal probability
schemes are consistent with the axioms of
probability theory, but avoid the need for
precise numerical probabilities. U sing
qualitative probabilities could substantially
reduce the effort for knowledge engineering and
improve the robustness of results. We examine
experimentally how well infinitesimal
probabilities (the kappa-calculus of Goldszmidt
and Pearl) perform a diagnostic task troubleshooting a car that will not start - by
comparison with a conventional numerical belief
network. We found the infinitesimal scheme to
be as good as the numerical scheme in
identifying the true fault. The performance of
the infinitesimal scheme worsens significantly
for prior fault probabilities greater than 0.03.
These results suggest that infinitesimal
probability methods may be of substantial
practical value for machine diagnosis with small
prior fault probabilities.
Keywords:
Bayesian
probabilities, kappa
probabilities, diagnosis.

networks, qualitative
calculus, i nfinitesimal

1 BACKGROUND AND GOALS

Bayesian and decision theoretic methods have long

been criticized for an excessive need for quantification.
They require many numerical probabilities and

Brendan Del Faverol

Gillian Sanders2

1oepartment of Engineering-Economic Systems,
Stanford University, CA 94305
2Section on Medical Informatics
Stanford University, CA 94305

utilities that are difficult to assess and are liable to
judgmental biases. Some people claim that since
human thinking is inherently qualitative, it is
incompatible with quantitative schemes. These
criticisms have fueled interest in alternative
formalisms for reasoning and decision making under
uncertainty that are intended to be easier to use and
more compatible with human cognition. Among these
alternative schemes are: various generalizations of
decision theory [Edwards, 1992]; Dempster-Shafer
belief functions [Shafer, 1976];generalizations of logic,
including default and non-monotonic logics [Ginsberg,
1987]; fuzzy logic [Zadeh, 1983]; possibility theory
[Dubois and Prade, 1988]; and fuzzy probabilities.
If,

however, our goal is simply to provide a qualitative
basis for reasoning and decision making under
uncertainty, there is no need to abandon Bayesian
decision theory. The axioms of decision theory,
indeed, assume only the ability to make qualitative
judgments - that is, to order events by probability or
outcomes by desirability. The quantification of
probabilities and utilities can be based on purely
qualitative judgments. Furthermore, several schemes
have been developed that are purely qualitative, but
are consistent with the axioms of decision theory.
One such scheme is qualitative probabilities, originated
by Wellman [1990; Henrion & Druzdzel 1991;
Wellman & Henrion, 1993]. A second approach to
qualitative probabilities is the kappa-calculus
[Goldszmidt and Pearl, 1992], which represents all
probabilities in a Bayesian belief network by e'K, where
is an integral power of E. The K -calculus is

K

Henrion, Prova n Del Favero, and Sanders

320

,

consistent with the axioms of probability where E---+0.
Events are ranked according to K. Events with larger K
are assumed to be negligible relative to events with
smaller K. The calculus provides a plausible set of
events: those with the smallest (most probable)
consistent with the observed findings. The calculus is
sometimes called

qualitative probability.

To avoid

confusion with other qualitative probability schemes,
we call this representation
Pearl

infinitesimal probabilities.

[1993] has extended this scheme to handle

similar difficulties.
Much current research on
qualitative simulation is directed towards integrating
quantitative information to resolve ambiguities (and
the resultant combinatorial explosions of the search
space).
In this paper, we report the results of an initial
experimental

study

comparing

the

diagnostic

performance on a specific belief network using (1) the
K -calculus or infinitesimal probabilities, and

(2)

qualitative utilities to support decision making.

numerical probabilities. Our goal is to examine how

The K-calculus or infinitesimal probabilities can be

approximation to the numerical representation.

well

the

infinitesimal

scheme performs as

an
We

looked at in two ways: (a) as providing a scheme for

start with a fully assessed numerical representation,

non-monotonic reasoning whose semantics are firmly

convert this into a kappa-representation using finite e

grounded in probability and decision theory; or (b) as

values, and perform inference on a set of test cases.

providing a simplification of belief networks with

We first explain the mappings we used to obtain

numerical probabilities. In this paper, we are focus on

infinitesimal

the second view, and examine the performance of

probabilities, and how we mapped back from the

infinitesimal probabilities as an approximation to
numerical probabilities.

or

K-values

from

the

numerical

pos terior K-values into probabilities for comparison of

From this perspective,

performance. Then, we describe the experimental

proponents of infinitesimal probabilities may claim

design, including the sample network, the set of test

four possible advantages over traditional numerical

cases,

belief networks:

probabilities, the epsilon values used in mapping, and

1. It may be easier to express beliefs by partitioning

and

our

variations

of

the

prior

fault

the number of findings observations per case.

The

number of sets of relative

infinitesimal scheme provides a set of the most

plausibility, that is values, than by assigning

plausible diagnoses for each case. In the results, we

events into a small

each event a precise numerical probabilities.

2. Results from reasoning with infinitesimal

compare these plausible sets with the posterior
probabilities for the diagnoses produced by the

probabilities are more robust and therefore more

numerical

trustworthy since they are based on less specific

implications of these results for the application of the

inputs.

K-calculus as a practical representation.

scheme.

Finally,

we

discuss

the

3. Reasoning with infinitesimal probabilities is
easier to understand and explain.
4. Inference methods with infinitesimal probabilities

can be computationally more efficient.

Initial analysis of the computational complexity of

[1992]

suggests that, in general, it is of the same order as
reasoning with numerical probabilities, that is NP­
hard

[Cooper,

1990].

There

may

be modest

computational savings from doing arithmetic with
small integers instead of floating point numbers.
Most

research

on

qualitative probabilities has

concentrated on developing the formalisms and
efficient algorithms.

AND INFINITESIMAL
PROBABILITIES

Hitherto, these claims have been largely untested.
reasoning infinitesimal probabilities Darwiche

2 MAPPINGS BETWEEN NUMERICAL

There has been little concerted

effort to demonstrate their application to real tasks and
to evaluate their practicality. Initial studies of QPNs
[Henrion and Druzdzel,

1990; Druzdzel and Henrion,
1993; Druzdzel, 1993] suggest that they are often

inconclusive for nontrivial cases. For example, QPNs
give vacuous results in any case with conflicting
evidence. Studies of qualitative simulation have found

In order to be a b le to apply

the

K -calculus to

probabilistic reasoning on a belief network with finite
probabilities, we need to provide a mapping from
probabilities into kappa values. In order to compare
the results we need to map the kappa results back
again into probabilities. Strictly, the K-calculus is only
valid as E---tO.

We use an approximation for finite

values of E. For a finite E, the K-calculus partitions the

real interval

[0,1] into regions identified by integers,

based on the smallest power of in the polynomial. This
mapping is illustrated in Figure 1.
More specifically, consider the real [0,1] interval I,
which is the interval used by probability theory, and a
discretized representation of I, which we call 5. 5 is a
set of non-negative integers which the -calculus uses to
represent probability measures in the interval I.

We

wish to explore the mappings f: I---tS (i.e., from
numerical to infinitesimal probability) and g: S ---t I

Nume rical and Qualitative Probabilistic Reasoning

(i.e., from infinitesimal to

numerical probability).

Note that there is information loss in the mapping f,
since it is not injective. Moreover, the mapping g is
not surjective.

Definition 1

321

[ K"-map] [Spohn 1988] The mapping f

from probability measures to

K"-values takes a

probability 1r and a threshold probability e and

outputs a K"-value K" e S such that

3 APPLICATION DOMAIN: WHY YOUR

CAR DOES NOT START
The task is to troubleshoot why a car is not starting,
given evidence on the status of the lights, battery, fuel,

fan belt, and so on. Figure 2 shows the Bayesian belief

network displaying the causal and conditional
independence relations.

We are grateful to David

Heckerman for providing the original belief network
and to Paul Dagum for lending us his expertise as a
Figure 1 shows an example of a mapping for £

=

0.1.

car mechanic in adjusting some of the probabilities.

All variables are binary (present or absent), except for
battery charge which has three values (high, low,
none). The initial network contains fully quantified,
numerical conditional probability distributions for

Kappa
1C(X)

each influence and prior probabilities for each fault
(source variable).

3

common

effect

Effects of multiple causes of a
are combined

with noisy-ORs,

generalized where necessary.
There are nine explicitly identified faults in this model:
spark plugs bad
distributor bad
fuel line bad
fuel pump bad
gas tank empty

0
0

0.001

0.01

Prd:lability p(X)

0.1

starter bad
battery bad

Figure 1: An example mapping giving kappa as a

fan belt loose

function of probability, for £=0.1.

alternator bad

Figure

2: Bayesian network representing the car diagnosis domain. Leak events represent all the

potential causes of a fault other than those shown explicitly. The number in each origin fault of a leak
node represents its prior probability in the original network. The numbers attached to each influence
arrow represent causal strengths -that is the probability that the successor is broken given that the
predecessor is broken, and all other predecessors are normal.

322

He nrion, Prova n Del Favero, and Sanders
,

We also identified three leaks. Each leak event
represents all possible causes of an event that are not
explicitly identified above. The probability of a leak is
the probability that its associated effect will be
observed even though none of its identified causes are
present.

from 10 to 1000. Table 1 shows the mean and range of

the resulting prior odds we used.

Table 1: The minimum, mean, and maximum prior
fault probabilities. The top line shows the original

engine start other

The

network with larger probabilities. To do this, we
multiplied the prior odds by an odds factor ranging

probabilities. Those below are derived by multiplying

engine tum over other

the odds of each prior by the odds factor and

charging system other

converting back to probabilities.

leaky noisy

or model assigns a probability to each

leak, to handle the fact that the network is inevitably
incomplete. In our adjusted network, the probability

Odds

of each leak was substantially smaller than the sum of

factor

the probabilities of the identified causes for each event.

Minimum

Mean

Maximum

1

0.00001

0.00036

0.00100

10

0.00010

0.00361

0.00991

50

0.00051

0.01750

0.04766

100

0.00103

0.03376

0.09099

300

0.00307

0.08900

0.23095

1000

0 010 17

0.21364

0.50025

There are 10 observable findings in the model_ listed
here in non-decreasing order of expense to test:

1. engine-start
2. gas-gauge
3. engine-tum-over

4. lights
5. radio
6. fan-belt
7. battery-age
8. distributor

.

9. spark-plugs
10. alternator

Note that there are four findings that are also
enumerated faults, namely fan belt, alternator, spark

4.2 Test Cases and quantity of evidence

plugs, and distributor.

We expected that the performance of both numerical

4 EXPERIMENTAL DESIGN

function of the quantity of evidence. We also wished

We wish to investigate the effects of three factors on

relative

the diagnos tic
probabilities:

performance

and infinitesimal schemes would improve as a

of

inf initesimal

to examine the effect of the quantity of evidence on the
performance

of

the

two

schemes.

Accordingly, we needed a representative set of test
cases with varying numbers of findings.

(a) The choice of the value of E on the mapping
between numerical and infinitesimal probabilities.

(b) The range of prior fault probabilities
(c) The quantity of evidence in the test cases.
We have already discussed factor (a). Here, we will
discuss our choice of each of these factors, and the
conduct of the experiment.

We generated a set of 116 test cases, in the following
manner: For each of twelve faults (nine identified
faults plus three leaks), we identified the most likely
(modal) value for each of the ten observable findings.
For each fault, we created a base

case

consisting of all

findings at their modal value. In four cases, the fault is
itself a finding, which we omitted from the base test

case, since including the true fault as observed in the
test case would be trivial. We then generated a second
case for each fault by omitting the most expensive
observation from the base case.

Further cases were

4.1 Range of prior fault probabilities

generated by omitting the next most expensive

The numbers in Figure

finding that the engine does not start. In this way, we
created a series of ten cases for eight faults, and nine

2 are the original prior fault

probabilities. To examine the effect of the magnitude
of the priors on the relative performance of the
infinitesimal calculus, we created versions of the

observation in tum.

In all cases, we retained the

Numerical and Qualitative Probabilistic Reasoning

cases for the four faults that are observable, resulting
in a total of 116 test cases in all.

4.3

323

faults are clearly identifiable, having probabilities at

least an order of magnitude greater than those of all
other faults. We found that this approach, as expected,

gave very similar results to the exact IC-calculus

Computation

inference using CNETS .

To obtain results for the numerical probabilistic

scheme, we employed IDEAL [Srinivas and Breese,

1990], using the clustering algorithm from the I DEAL
library. We applied each of the 116 test cases to the
network using each of the six sets of priors,
performing a total of 696 run. For each run we
computed the posterior probability for each of the
twelve faults resulting in 8352 probabilities.

5 RESULTS
Our first goal was to examine the effect of E values on
the performance of the infinitesimal probability
scheme. We then selected the value of E that gave the
best results and examined the effect of varying the

quantity of evidence on the performance of both

numerical and infinitesimal schemes.

We also converted the original numerical probabilities
into K-values, using the three values e (0.1, 0.01, 0.001),
resulting in a total of 2088 additional runs. We ran

5.1

calculus developed at

we might expect it to perform better for small£, where

each case using CNETS, a full implementation of the K­
the

Rockwell

Palo Alto

Laboratory [Darwiche, 1994], producing posterior K­
values for each fault. For each run, we computed the

plausible set, that is the subset of faults with the
minimal K value.
Definition

[Plausible Set]

2

Consider a set

V:;;{v1,v2, ,vm}representing m possible hypotheses,
•••

Let

vmin

](­

=minvj by the minimum ](-value.
J

probability interval

(0,

1], as shown in Figure 1, and

larger e. To investigate this we analyzed an initial set
of 72 test cases usin g E values of 0.0001, 0.001, 0.01, 0.1,

0.2. Figure 3 shows a graph of average probability
against e. It is interested to note that the average score

identical fore= 0.1 and e

To compare the infinitesimal scheme with the
numerical one, we converted K-values of diagnoses
back to probabilities as follows:
De fi n it ion 3:

original probabilities, with less information lost.

Accordingly, we might expect it to do better with

is identical for E = 0.01 and E

Cll(V)={j:vj =vminl·

[Pro b a bility

setV={v1,v2, ... ,vm}r e presenting
assigned a

the approximation will be mere exact. On the other

hand, a larger E provides rnore partitions to the

score assigned to the true diagnosis for these cases,

The plausible set is given by

hypotheses,

Since the kappa calculus is only strictly correct as E---+0,

consequently, it provides a finer discretization of the

in which each hypothesis has been assigned a
value.

Effect of E values

score]

m

For

=

= 0.001, and also

0.2. Overall, there is an

improvement in performance with increasing E up to

0.2. Accordingly, we selected E

=

0.1 for use in our

remaining experiments.

a

p o s s i b 1 e

in which each hypothes is has been

](-value, the corresponding probability

distribution is given by

ifvj=vmax

(3)

0.3
.,
"'
"' 0.25
..
-<
0.2
I>
., .....
s:: ..
0.15
.. ....
a: "'
.. "
0.1
r;,. ...
.,
"
..
!..
0

��

otherwise

That is, the probability ni= 1/n is assigned to the true
faults if it is in the plausible set of size n. Otherwise,
we assigned p = 0.

�

"

�"'

0.05

0.0001

0.001

0.01

0.1

As an additional test, we also ran IDEAL using the

exact algorithm, but using fault probabilities mapped
to O.OlK for the values obtained from the mapping
using the full set of K values.

subset of 72 test cases.

We applied this to a

In the results, the plausible

Figure 3: Effect of E o n the score (probability

assigned to the true fault) by the infinitesimal scheme

Henrion, Provan, Del Favero, and Sanders

324

5.2 Effect of Number of Findin gs on the

Plausible set

...., 0.5
';
1:1
...

As the quantity of evidence increases, we should
expect the performance of both numerical and
infinitesimal schemes to improve.

Accordingly, we

classified the cases by the number of findings. Figure 4
graphs the average size of the plausible set (number of

Gl
:I
I.
...,
..
Cl
.=

e

Cl,.

0.25

plausible faults) identified by the infinitesimal scheme
as a function of the number of findings. These results
summarize all116 cases fore

=

01
. . As expected, the

average size of the plausible set of faults decreases
with the number of findings, from 7 faults with 1
finding to1. 21 faults for 10 findings. With10 findings,

o �----2
0
6
8
4
10
Number of findings

this scheme provides almost complete specificity that
is, the plausible set usually consists of just a single
diagnosis.
..
.,
Ill

Figure 5: The probability assigned to the true
fault for each scheme as a function of number of
findings

10

.,
...
.Ill
. ..
Ill
:I
"
...
liloo

What is, perhaps, surpnsmg is how closely the
performance of the infinitesimal scheme tracks the
performance of the numerical scheme.

..
0
.,
N

. ..
"'

Indeed the

infinitesimal scheme appears to perform better than
the numerical scheme for intermediate numbers of

5

findings, but this difference is not significant.

Since

the infinitesimal representation is derived from the
numerical one, we could not expect it to do better, on
average.
Note that, even with all ten findings, both schemes

o+-----�----�---r---,--�
0

2

6

Number of fi nd i ngs

8

10

average about 0.5 probability for the true diagnosis.
This relatively poor performance arises because of the
limited scope of the network, which does not provide
the means to differentiate among several classes of

Figure 4: The average size of the plausible set

as a function of the number of findings in each
case.
5.3

Comparing the performance of
infinitesimal and numerical schemes

Next, we compare how the number of findings affects
the diagnostic performance for the infinitesimal and
numerical schemes. Figure 5 graphs the performance
in terms of the average probability each assigns to the
true fault, as a function of the number of findings. For
both schemes, as expected, the average probability
assigned to the true fault increases with increasing
evidence, from about 0.15 with 1 finding, to about 0. 47
with 10 findings.

fault.

5.3 The magnitude of priors and the
performance of infinitesimal

probabilities
The infinitesimal probability scheme appears to
perform very well relative to numerical probabilities
for the original car network, in which the prior fault
probabilities are very small, on average 0.00036

To

examine if it performs equally well for larger priors,
we multiplied the prior odds by five odds factors, as
shown in Table

1.

Figure 6 shows the average

probability assigned to the true diagnosis as a function
of the average priors.

Interestingly, the two schemes

are almost indistinguishable up to an average fault
prior 0. 033. Above that, the performance of the
infinitesimal probability drops off sharply - that is,
for average priors of 0.089 and 0.214.

These results

Numerical and Qualitative Probabilistic Reasoning

confirm our ex pect ation that infinitesimal works well
for small priors, but not so well for large pr i ors.
..
-

=
Cl

...
..
....
c

0.4

ordering of diagnosis. A third, would be to evaluate

even more, the quality of decisions will be less rather
than more sensitive to these differences in
representation.

0.3

While these findings are encouraging for the practical
usefulness of infinitesimal pr oba b il ities, we should

.CI
c
...

a.

them. Another way would be to compare the rank
the quality of decisions based on the diagnosi s. In
general, scoring rules based on ranks of diagnosis or,

....

�
=

325

remember that these initial results are on a single
domain. This car model dom ain is simple, with few

0.2

loops and short chains.

This kind of experiment

should be conducted on a wide range of types of
network to see how far these initial results will hold

0.1-

up.
In the introduction, we distinguished view
infinitesimal

o+-----�----�--+-��o.oo1
0 .01
1
o.oo01
0.1
Aver age prior fault probability
Figure 6: Comparison of the average performance of
infinitesimal and numerical probability schemes as a
function of prior fault probabilities.

probabilities,

as

an

(a)

approach

of
to

nonmonotonic reasoning, from view (b), as an
approximation to numerical probabilities.

We

reiterate that this paper, we focus on (b), and we are
not attempting to evaluate its use as an approach to
nonmonotonic logic.

Conclusions about the former

have limited relevance to the latter.
Infinitesimal pro babi lit ies are quite appealing as an
alternative to numerical probab il ities. They should be

6 CONCLUSIONS

significantly easier to eli ci t from experts. Inference

We find these initial results very encouraging in terms

of the diagnostic performance of the infinitesimal
probability scheme. For this example domain, we

found the best performance occurs using E 0.1 to 0.2.
Performance for E
0.01 was slightly worse.
=

may be more effjcient. And resulting inferences should
be somewhat more robust to changes in probabilities.
Some questions that need further investigation
include:

=

Performance of the infinitesimal scheme relative to the
numerical

scheme

does

not

appear

to

Does the best choice of E vary with the domain?

vary

significantly with the quantity of evi dence. The
performance using infinitesimal probability is not

Does these results hold for larger networks, with
more complex structures?

noticeably worse than the numerical probabilities for
prior fault probabilities up to about 0.03. For larger
average fault probabilities, the relative perform ance of

Can this infinitesimal approximation be extended
to utilities and decision making?

infinitesimal probabilities starts to drop off sharply.

This findings suggests that infinitesimal probabilities

Can we obtain a clearer analytic characterization

are more likely to be reliable for diagnosis tasks with

of when performance

very small prior fault probabilities, such as most
machine and electronic devices. They may also work
for some med ical domains, as long as the
priors are less than

disease

1%.

we have used is very simple.

In

addition,

engineering

The mapping from K-values back to probabilities that
More sophistic ated

mappings are pos sible, making use of higher values.

We should also point out that the scoring methods that
we have used to evaluate performan ce have been
based on posterior probability of the true diagnosis,
which is perhaps the most exacting way to compare

will be or won't be

reliable?
we

methods

need practical knowledge
for

eliciting

infinitesimal

probabilities. We an ticipate that, in the long run, the

best p r actical tools will
quantitative methods.

combine qualitative and

326

Henrion, Provan, Del Favero, and Sanders

Intelligence Conference,
Acknowledgments

M. Goldszmidt and J. Pearl.
causal relations.

This work was supported by the National Science
Institute for Decision Systems Research. We would
like to thank David Beckerman for use of the car

pages 99-110, Vermont, 1992.
entropy approach to nonmonotonic reasoning.

refining some of the probabilities.

M.

Shac�ter,

The Logic of Conditionals.

G.F. Cooper. The Computational Complexity of
Probabilistic Inference Using Belief Networks.

Artificial Intelligence, 42:393-405, 1990.
Darwiche. A symbolic generalization of probability
theory. Ph.D. dissertation, Computer Science Dept.,
Stanford University, Palo Alto, CA, 1992.
M.

&

Goldzmidt.

CNETS:

A

computational environment for generalized causal
networks. 1994, {this volume).

M. Druzdzel and M. Henrion. Efficient reasoning in

Proceedings of
the American Association for Artificial Intelligence
Conference, pages 548-553, Washington D.C., 1993.
J. Druzdzel. Probabilistic Reasoning in Decision
Support Systems: From Computation to Common
Sense. PhD thesis, Department of Engineering and
qualitative probabilistic networks. In

M.

Public

Policy,

Carnegie

Mellon

University,

Pittsburgh, Pa, 1993.

H. Prade. Possibility Theory: an Approach
to Computerized Processing of Uncertainty. Plenum

D. Dubois and

Press, NY, 1988.

Utility Theories: Measurements and
Applications. Kluwer Academic, 1992.
H. A. Geffner. Default Reasoning: Causal and Conditional

W. Edwards.

Theories.
M.

MIT Press,

Henrion.

and

Cambridge, MA, 1992.
M.

Druzdzel

"Qualitative

propagation and scenario-based explanation of
probabilistic reasoning". In M. Henrion and R.
S h achter,

editors,

Intelligence.

6,

Uncertainty in Artificial

Elsevier

Science

B.V.

(North­

Holland), 1991.
M.

Hendon.

"Search-based methods to bound

diagnostic probabilities in very large belief nets".

M.

In Proceedings of Conf on Uncertainty and Artificial
Intelligence, 1991.
Ginsberg. Readings in Nonmonotonic Reasoning.
Morgan Kaufmann, San Mateo, CA, 1987.

M. Goldszmidt and J. Pearl. System Z+ :A formalism
for reasoning with variable strength defaults. In

Proceedings of American Association for Artificial

editors,

Uncertainty in Artificial

Intelhgence, pages 129-138. Elsevier Science B.V.

D. Reidel,

Dordrecht, Netherlands, 1975.

D arwiche

IEEE Transactions on Pattern Analysis and Machine
Intelligence, 15:3:220-232, 1993.
He nrion. An Introduction to Algorithms for
Inference in Belief Networks. In M. Henrion and R.



Backward simulation is an approximate
inference technique for Bayesian belief
networks. It differs from existing simulation
methods in that it starts simulation from the
known evidence and works backward (i.e.,
contrary to the direction of the arcs). The
technique's focus on the evidence leads to
improved convergence in situations where the
posterior beliefs are dominated by the evidence
rather than by the prior probabilities. Since this
class of situations is large, the technique may
make practical the application of approximate
inference in Bayesian belief networks to many
real�world problems.

1

INTRODUCTION AND MOTIVATION

Because of its sound theoretical foundation in probability
theory, the Bayesian belief network technology has
become, in artificial intelligence, an important alternative
architecture for reasoning to logic�based architectures
(e.g., rule�based systems). Although efficient exact
inference techniques (Shachter, 1986; Lauritzen, 1988,
Shachter, 1990) for Bayesian belief networks can and
have provided excellent solutions to many real�world
problems, their applicability is limited, because exact
inference is NP�complete (Cooper, 1990).
Because of this, significant research has been focused on
finding efficient approximate inference methods. Most
previous research has emphasized simulation methods
(Pearl, 1987; Fung, 1989; Shachter, 1989; Chavez, 1990;
Shwe, 1991a), which repeatedly draw sample values from
the network's nodes using a sampling algorithm, and then
use the relative frequencies of the sample values to
estimate the probabilities of interest. Researchers try to
find methods that converge quickly to the exact result, and
to characterize the convergence properties of the
simulation algorithms.
There are two basic classes of simulation methods:
forward-simulation methods (Fung, 1989; Henrion, 1986;
Shachter, 1989) and stochastic�simulation methods
(Chavez, 1990; Pearl, 1987).
Forward�sirnulation

methods start each trial of the simulation by instantiating
the source nodes (i.e., nodes with no predecessors) and
then proceeding forward along the diagram arcs to
instantiate each downstream node in tum. Because the
sample values from one trial to the next are unrelated, the
trials are independent. In stochastic�simulation methods,
on the other hand, each trial begins by modifying the
previous trial's instantiation. Each node's sample is
chosen with respect to the current instantiations of
neighboring nodes.
Because they are driven by the prior probabilities of
upstream nodes, rather than by the likelihood of the
observed evidence, forward�simulation methods converge
slowly when faced with low�likelihood evidence
(evidence that has low prior likelihood). Because of the
way samples depend on the current instantiation,
stochastic�simulation methods as a group are inefficient
when there are deterministic or near�deterministic
relationships in a network.
In this paper, we present the backward�simulation method
for performing approximate probabilistic inference i n
Bayesian belief networks. Our method i s closely related
to forward�simulation methods, and is not susceptible to
slow convergence in the presence of deterministic
relationships as are stochastic simulation methods. In
addition, the method is not as susceptible to slow
convergence with low�likelihood evidence, the main
problem with other methods of its class.
In Section 2, we present the notation used in this paper.
In Section 3, we discuss forward simulation methods in
detail. Section 4 provides the details on the backward �
simulation method. In Section 5, we give a summary of
the paper, and discuss directions for future research.

2

NOTATION

A Bayesian belief network is a directed acyclic graph D
with an associated probability distribution P. The set of
nodes in a network is denoted by N. Individual nodes are
denoted by capital letters, whereas general references to a
node (such as "node i") are in lowercase italics. Each
node i in the network has a corresponding variable X; in P
and a set of parents Pa( i). If S is a set of nodes, then the

228

Fung and Del Favero

set X s is the set of variables corresponding to the nodes in

s.

The variable

Xi has a corresponding set of conditioning
variables X Pa(i)• called the parents of X1. Each variable
xi has a state space nj and an associated probability
distribution P(X 11Xpa ))· The product of node probability
(i

dis tributions in a network is the joint probability
distribution P of the variables associated with the graph D.

4

BACKWARD SIMULATION

The two defining features of backward simulation are the
direction of simulation and the sampling method for
drawing node values. The direction of sampling in the
backward simulation method is outward from the
evidence. In contrast, forward-simulation methods that
work forward from the source nodes, whereas stochastic­
simulation methods that have no particular direction of

We represent evidence in Bayesian belief networks by

simulation.

setting the values of the appropriate nodes to their

methods, backward simulation permits many possible

observed states. The set of nodes whose values have been

orderings of the nodes to be sampled.

observed is denoted by N e· The nodes that are unobserved
(i.e., that are in

N\Ne) are called state nodes.

Backward simulation is a specialization of the
importance-sampling inference method discussed in

The inference task for Bayesian belief networks is to
compute answers to queries of the

Like forward and stochastic simulation

form P(X 11XK), where

Section 3. Like forward simulation, backward simulation
includes a node ordering step and a simulation step. The

all the observed evidence Ne is typically a subset of the

first step computes an ordering of network nodes, starting

nodes in K. Many exact and approximate algorithms have
been developed for addressing such queries.

general, an ordering will contain only a subset of the

Where there is little potential for confusion, the notation

P(A) will be used to mean P(XA)

.

3

nodes in the network. In the second step, the simulation
trials are performed, with network nodes sampled in the
predetermined order.

1981) is a well-known

technique for improving convergence in Monte Carlo
simulation. It has been adapted for use in forward

simulation models (Shachter, 1989).

It provides the

ability to instantiate the network from an arbitrary

distribution Ps instead of just from the joint distribution P
as in logic sampling. To adjust for sampling from P s
instead of from P, the weight Z associated with each trial
is computed to be the ratio of the likelihood of the sample

based on the network distribution to the likelihood of the
sample based on the sampling distribution:

(I)
The network probability P(XN) is always the product of
node probabilities,

A trial weight Z is computed for

4.1 ORDERING
The

thr ee

requirements

for

node

ordering

in

back ward simulation are flexible and allow significant
variation:

1. A node must be instantiated before it is backward
sampled,

2. A node's predecessors must be instantiated before
the node is forward sampled, and
3. Each node in the network must be either (a) a node
in the ordering or (b) a direct predecessor of a node
in the ordering that is backward sampled.

Items 2 and 3(a) are the usual requirements for an or­
dering in forward simulation.

(2)

Because evidence nodes are instantiated, they can always
be backward sampled.

but the sampling distribution can be arbitrary.

In the

simplest form of the algorithm, the sampling distribution
is the joint distribution over the unobserved nodes (the
state nodes). In that case, where P(XN5)=P5(XN5), the
ratio in Equation 1 is just
likelihood of the evidence.

In

each trial, and is used to increment the counts of each
distribution (i.e., query) of interest.

IMPORTANCE SAMPLING

Importance sampling (Rubinstein,

from the evidence nodes and working outward.

P(XN e IXNs ) the overall
,

An informal argument for why this method works is as
follows. If a large number of trials is done, the frequency
of Xi in the accumulated trials should be approximately
Ps(X1). When multiplied by the weight we get the
probability of X;. P(Xi). A formal proof of the conver­
gence of this method is presented in (Geweke, 1989).

Leaf nodes also can always be

backward sampled, because a dummy evidence node with
uniform likelihoods can be attached to a leaf node without
the posterior distribution being changed.
We shall use the simple network in Figure I to illustrate
the ordering and sampling steps. Each node represents a

probabilistic variable that is conditionally dependent on
the nodes at the ends of the arrows pointing into it. Thus,
the network in Figure 1 represents this probabilistic

factorization:

P(ABCDE) = P(A) P(BIA) P(CIA) P(DIBC) P(E).
Node

D is shaded to indicate that it is an evidence node.

Backward Simulation in Bayesian Networks

229

simulation (the process driving the sampling). Indeed, in
forward simulation, they are linked: forward simulation
involves only forward sampling. However, the process of
backward simulation does involve both backward and
forward sampling.

4.2.1

Backward Sampling

Backward sampling from a node's probability distribution
instantiates those of the node's predecessors that are not
already instantiated. We denote the instantiated value of
node i by X;, the parents of i that are uninstantiated by
Pa ll(i) and the instantiated parents by Pa *ci).
Figure 1: Simple Network.
Four different sampling orders for the example network
shown in Figure 1 are {D,B,E}, (D,E,B}, {D,E,C}, and
{ D,C,E}. First, the evidence node D is sampled,
instantiating nodes B and C. We then have two choices
for instantiating node A, namely by backward sampling
from either B or C. Finally, the value of E is determined
by forward sampling from C.
The nodes in the sampling order will be denoted by Ns.
This set is composed of the nodes to backward sampled,
N b• and the nodes to be forward sampled, Nr· In this
example, if we take Ns to be { D,B ,E}, then N b is { D,B}
andNf is {E}.

The backward-sampling procedure instantiates the
uninstantiated parent nodes according to the following
probability distribution:

ps

Backward sampling differs from forward sampling in
each of these three aspects. First, sampling from a node's
probability distribution occurs only after the node itself
has been instantiated. Second, sampling from a node's
probability distribution does not determine the node's
value but rather the values of the node's predecessors.
Third, the sampling is based not on a particular
conditional probability distribution but rather on
normalized likelihoods of the node's conditional
probability distribution.
Which of the two methods is used to sample a node
depends on the network topology. For nodes with an
evidence node as a descendent, sampling from a node's
conditional probability occurs after the node has been
instantiated, and it determines the values for the node's
predecessors. For nodes with no downstream evidence
nodes, forward sampling is used. Any of the algorithms
developed for forward simulation can be used.
We would like to emphasize the distinction between
sampling (a selection from a set of choices) and

I'

::::

P(x;

xp )

I XP ( )
a

"

r

a

'

'(·)
1

Norm (i)

•

'z E

N b·

(3)

The numerator of the preceding expression is the
likelihood of the current state of node i given a particular
state of the parents of node i. The denominator, Norm(i),
is a normalization constant that ensures that the terms in
this distribution sum to 1. Norm(i) is computed as
follows:

(

u(i)l X; I y, XPa

Norrn(i) = LyeXP(Pa

4.2 SAMPLING
Two sampling methods are used in backward simulation:
forward sampling and backward sampling. In forward
sampling, a node's distribution is sampled only after all
the node's predecessors have been sampled. Forward
sampling a node sets the value for the node itself. The
probability distribution on which the random sampling is
based is determined by the values of the node's
predecessors.

(Pa u { ))

J

• (i

The set XP(Pau(i)) is the set of all possible conditioning
cases of the uninstantiated parents of node i. For nodes
with n binary-valued uninstantiated parents, this set is of
size 2n.
Normalization constants can be precomputed if there is a
fixed order, or they can be cached as computation
proceeds.

4.2.2

Forward Sampling

In forward sampling, the sampling distribution for a node
is the same as the node's probability distribution:

(4)
4.3 SCORING
After all of the nodes have been instantiated, the weight
for each trial can therefore be computed by combining
Equations 1 through 4:

Z(x)=

•e

[

](

(
P (xj I XPa(j) )
rrjENb Norm(J)
n.

NP xi lxPa(i)

)

rrjENf p(

x; XPa(j} ))
I

230

Fung and Del Favero

Tills can be simplified to

(

Z(x) =Die N \ N P x1 I xPa(i)
s

Table

)n

j eN b Norm(})

4: Backward Sampling Distribution for A

(5)

4.4 EXAMPLE
Let us step through an example of backward simulation.

Consider the five-node network in Figure l. All of the
nodes are binary-valued: the values for A, for instance,

are taken to be a1 and a2, whereas the possible joint
values (or states) of nodes B and C are htc1, b 1c2, b2 c1,
and b 2c2• The value of the evidence node D is observed to

be d2 . Suppose that the sampling order { D,B,E} is used.

Table 1 is the conditional probability table for node D.
For instance, P(D= d2 I B=b1, C=c2) = p 122 .

As before, the constant

Suppose that the sampling step selects state a2.
Finally, we would use forward sampling to set node E to

one of the states ('1_, e2) according to the distribution
given in Table 6, which is identical to the second column
of Table 5.

Table I: Probability distribution for D givenB and C

Table 5: Probability ofE given C

P( D IBC )
Pm

Pm

P2 11

P 22 1

P112

P122

P2 12

P222

Since D is observed to be

j) normalizes the terms:

P(E I C )

d.z, the sampling distribution for

the parents of D is based on the second row of Table 1.

Table

The sampling distribution, over the states in XP(Pa 0 (OJ),
{b 1c1, b1 c2, b2c1, b2c2}, is shown in Table 2.

cz

6: Sampling Distribution forE

Table 2: Sampling Distribution forB and C
In forward sampling, the sampling distribution is the same
P tt2

Pt22

P 2 12

P 222

a

0:

a

a

The constant a normalizes the terms to sum to 1, namely:
a"' Nonn(D=dz) = P 1 12 + P 122 + P 2 12 + P 22 2
·

as the probability distribution, so no normalization
constant is necessary (the terms already sum to

Suppose that the sampling step setsE to e 1 .

1).

This example trial has instantiated the network to the joint
state a2b1 c2d2 e 1. The trial score that would be added to
the beliefs of the currently-selected states of each node

would be

Suppose that the sampling step chooses joint state b 1c2
and sets the states of B and C to these values.
Next, we would sample nodeB to set node A to one of the

states { a1, a2} according to the distribution over these
states.
Table 3 shows the conditional probability
distribution of B given A, whereas Table 4 shows the
sampling distribution for A.

Table 3: Probability ofB given A
P(B I A)

4.5 CORRECTNESS AND CONVERGENCE
Backward simulation meets the single constraint for a
valid importance sampling procedure: no point in the

joint state space of the prior distribution with positive
probability can have a probability of zero in the sampling
distribution.

As a form of importance sampling with likelihood

weighting, backward simulation inherits the convergence
properties of importance sampling (Shachter, 1989). That

is, the beliefs generated by the simulation are guaranteed

to converge to their true values, with the errors decreasing
in proportion to the square root of the number of trials.

231

Backward Simulation in Bayesian Networks

5

DISCUSSION

S to s2, and would set the trial score Z to e, a relatively
small number. The belief corresponding to

5.1 BENEFITS AND COSTS

1! 8),

remain at zero. After many trials (on average, about

The backward-simulation method is well-suited to
inference in situations with low-likelihood evidence. By
working from the evidence, the method focuses on
instantiating those scenarios that are most compatible with
the observed network state, rather than with the prior
distribution. The effect

� will be

augmented by this score, whereas the belief of s1 will

of the prior distribution is taken

into account by the trial weights. If the prior probabilities
are diffuse, compared to the evidence likelihoods, the

nodeS will be set to s1 and the trial score Z would be 1-e.

Now, because of this one trial, the belief of s 1 will

discovered, after much work, that s 1 is the most likely

explanation for the evidence observed.
Table

7:

ForwardSampling Distribution forS
P(S)

weights also will be diffuse, and the inference method will
converge to the correct solution much faster than would

for low-likelihood evidence is illustrated by the two-node
network in Figure 2. NodeT has been observed at value
t1, and nodeS has two states, s1 and�-

1-8

8

forward-simulation methods.
This benefit of backward sampling over forward sampling

be

much greater than the belief of s 2; we will have

Table

8 shows the backward sampling distribution for S.

If we use backward sampling fromT to S, S will be set to
state s1 in the preponderance of trials. The belief of s 1
will be augmented in each trial by

Z=o, and the belief of

s2 by zero. Thus, from the start, the simulation is more in
line with the most probable diagnosis, s 1.
Table

8:

BackwardSampling Distribution forS

€

1-€

The main cost of backward sampling is the computational
resources required for computing the normalization
Figure

2: Two-node Network With Low-likelihood
Evidence.

Suppose that the prior and conditional probabilities are as
follows, with 0 < £ <<

� << I:

(
P(S

) o
s2 ) = (1-o)
P{T = t1 IS= st ) (t- e)
=

=

=

)

P T =t 11S=s2 =e
Using exact inference (Bayes's rule), we can show that,
although the prior for state

Although in

general

the

costs

grow

exponentially with the number of predecessors, the costs
can be reduced where there are special network structures
such as invertible continuous functions or noisy-or
relationships

P S = st

(

constants.

� is much less than that for

state s2, s1 is the most likely explanation for the evidence:

Backward simulation is related to the method of evidential
integration (Chin,

1987;

Fung,

1989)

that has been

suggested for use with simulation methods. In evidential
integration, arc reversals are used as a pre-processing step
to integrate the evidence into the network, to convert
extremal

likelihoods

to less

extreme

likelihoods.

Evidence integration is computationally expensive;
backward

simulation

does part of what

evidence

integration does (when it computes the normalization
constants), at a fraction of the cost.
For networks in which the conditional probabilities do not
change, the normalization constants can be precomputed
and cached, taking much of the work out of each trial.

�(1-e)+(1-o)e
8
e
=--=1---"'1
o+e
0+£
e
-=0
P(s2/t1)�1:"u+e
Table

7 shows the forward sampling distribution forS. If

we use forward sampling from S toT, most trials will set

5.2 EXPERIMENTS
We have run some preliminary experiments comparing
the performance of forward simulation with backward

1,
1989). The probabilities are given

simulation. They were based on the network in Figure
as described in (Fung,
inTable
state e1.

9.

D is observed in state

q and E is observed in

232

Fung and Del Favero

The test routines were written in Macintosh Common
Lisp. We tested a forward simulation method against the
Both use likelihood

backward simulation method.
weighted scoring.

evidence is not particularly unlikely, thus there is no
particular benefit for backward sampling.
Most
importantly, Figures 3 and 4 show that backward
simulation works as an inference method.

Table 9: Probabilities for the Experimental Network

P(A)

P(a1)

=0,20

P(BIA)

P(b11a1)

=0,80

P(b11�)

=0.20

P(CIA)

P(c11a1)

=0.20

P(c11�)

=

P(DIBC)

P(d 11b 1c1)

=0,80

P(d 11b2c1)

=0.80

P(d lib tC2)

::::0,80

P(d11b2c2)

=0.05

=0,80

P(d 11b1c1)

=0.60

P(d11b 1c1)

P(EIC)

6
I::

LIJ
._
0
>

0. 05

0.2

0

0

'B
Cl)

0.1

0

As was done in the previously cited paper, we perform a
large number (250) of runs. In each run, we measure the

500

1000, and 2000 trials, using the absolute-value error

2000

Trials

accuracy of each simulation method at 100, 200, 500,
function below:

1500

1000

Figure 4: Standard Deviation vs. Trials:

Forward {Diamonds) and Backward (Squares)
Although both simulation methods will converge to the

same answer, they may do so at different speeds. This is
the motivation of the next set of runs, which were

Here, Bk(xii•t) is the belief (probability estimate) for
state j of node i on trial t of the kth run. The error,
averaged over all runs, is presented in Figure 3.

The

standard deviation of the errors in the runs is presented in

Figure 4.

performed on

the

same

network

with

the

same

distributions, with the exception of the modified entries

listed in Table 10. The evidence in these runs is that node

D is set to d1. These modifications make the observed
evidence much less likely than before.
Table 10: Modifications to Probabilities in Table 9
for Extreme-probability Experiment

0.5

g
�
0

�
:>

<

0.4

P{DIBC)

P(d 11b1c1)
P(d11b1c2)

0.3

=

0.001

P(d11b2c1)

=

0.0001

P(d11b2c2)

=

0.0001

=

0.05

We record the performance of each method at 10, 20, 50,
100, and 200 trials. The average error and standard
deviation are presented in Figures 5 and 6.

0.2
0.1

Figures 5 and

0
0

500

1000

1500

2000

The conclusion is that we can expect good performance of

Trials

backward simulation at a low numbers of trials in

Figure 3: Error vs. Trials for Two Simulation Methods:
Forward (Diamonds) and Backward (Squares)
Figures 3 and

4 show that backward and forward

simulation are performing equivalently well, with the
backward s imulation method showing slightly lower

average error values.

This is to be expected:

given a

large enough number of trials, both methods will

converge to the same answer.

6 show that at low trial numbers, backward

simulation is consistently closer to the true probability
than forward simulation.

In this example, the

networks with low-l ikelihood evidence. Of course, much
more work is necessary to characterize and understand the
conditions under which each simulation method performs

better than the other. There are cases in which backward
simulation would perform worse than forward simulation:

backward simulation is subject to the proof of Dagum
(1993) that, in the worst case, all approximate

probabilistic methods are NP-hard.

Backward Simulation in Bayesian Networks

In backward simulation, on the other hand, the sampling
order can affect the sampling distribution. This may have
a significance in convergence properties of the simulation.
For instance, in the example of Section 4.4, two possible
sampling orders are { D,E,B}and {D,E,C}. Using the
former, A is backward sampled from B, whereas using the
latter, A is backward sampled from C. Depending on the
structure of the joint distribution P(ABC), the sampling
distribution for A could be quite different between the two
orders. One ordering may be better than the other in
terms of simulation performance.

0.5
0.4

j
t
:>

<

0.3
0.2
0.1
0
0

50

100

150

200

Trials
Figure 5: Error vs. Trials for Second Experimental Run:
Forward (Diamonds) and Backward (Squares)

0.3
...
0

t::
UJ

......
0

The added flexibility is exciting, in that it provides an
opportunity to develop heuristics governing when to
sample a node backward or forward. The hope is that
with backward and forward simulation in the probabilistic
tool chest, as well as evidence integration and other
approximate methods, a simulation run can be optimized
based on the particulars of the network being considered.
6

0.1

There are many interesting avenues of research for
backward simulation. Dynamic node ordering (i.e.,
changing Ns within a single trial or between trials) is
possible and may provide a way to improve performance.
Also, it is possible to group nodes for sampling. For
example, in Figure 1, B and C could be aggregated
together for the purpose of sampling the value of A

'1)

"E

The ordering {A,B,C,E} presents a different type of
flexibility, or ambiguity: it is valid under this order to
instantiate C by forward sampling from A or by backward
sampling from D. There may be a difference in
simulation performance under the different interpretations
of this ordering.

0.2

>

0

233

�

0
0

50

100

150

200

Trials
Figure 6: Standard Deviation vs. Trials for Second Exper­
imental Run: Forward (Diamonds) and Backward
(Squares)
5.3 THE SIGNIFICANCE OF NODE ORDERING
Backward simulation provides a new flexibility in
devising strategies for instantiating the network during a
simulation triaL One strategy would be to use backward
sampling wherever possible. Another would use forward
sampling everywhere (this is just forward simulation). In
between these extremes, there are many possibilities for
mixing both forward and backward sampling.
There are often multiple possible node ordering in
forward simulation as welL However, node ordering has
no impact on the sampling distribution for a particular
node: the distribution is always based on the node's
predecessors, which are always instantiated before the
node itself is.

FUTURE RESEARCH AND
APPLICATIONS

One of the most promising areas of research is the
combination of the backward-simulation method with its
dual, forward simulation. The combination would
provide a complete probabilistic architecture that allows
both data-driven and causal reasoning.
Such an
architecture might have the promise of attacking such
problems as natural-language understanding or speech
recognition. We are currently testing this architecture on
two-level networks with noisy-or relationships between
the nodes such as the QMR-DT network (Shwe, 199Ib).
This combination may make feasible the application of
Bayesian belief networks to many real-world settings that
current techniques cannot handle. For example, it should
be applicable to situations that have large and dynamic
state spaces, and strong evidence. Many sensory
situations (e.g., vision) seem to have this flavor. It seems
to match well with how people reason under uncertainty
- by reasoning from evidence to conclusions. This has
the promise of making explanation of the results of
backward simulation more intuitive than for exact
inference methods.

234

Fung and Del Favero

Acknowledgments

This work was supported in part by NSF Grant IRI9120330.
This work has benefited greatly from discussions with
Mark Peot and Kuo-Chu Chang and from the comments
of the reviewers of this paper.

