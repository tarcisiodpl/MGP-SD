

This paper addresses the tradeoff's which
need to be considered in reasoning using
probabilistic network representations, such as
Influence Diagrams (IDs). In particular, we
examine the tradeoff's entailed in using Tem­
poral Influence Diagrams (TIDs) which ad­
equately capture the temporal evolution of
a dynamic system without prohibitive data
and computational requirements. Three ap­
proaches for TID construction which make
different tradeoff's are examined: (1) tailor­
ing the network at each time interval to the
data available (rather then just copying the
original Bayes Network for all time intervals);
(2) modeling the evolution of a parsimonious
subset of variables (rather than all variables);
and (3) model selection approaches, which
seek to minimize some measure of the predic­
tive accuracy of the model without introduc­
ing too many parameters, which might cause
"overfitting" of the model. Methods of evalu­
ating the accuracy /efficiency of the tradeoff's
are proposed.
1

INTRODUCTION

This paper examines tradeoff's which need to be con­
sidered for reasoning with Probabilistic Networks such
as Influence Diagrams (IDs) [16, 26]. For large net­
works, both data acquisition and network evaluation
are expensive processes, and some means of controlling
network size is often necessary. In particular, model­
ing time-varying systems with Temporal Influence Di­
agrams (TIDs) or Temporal Bayes Networks (TBNs)
often requires large networks, especially if several time
slices are modeled. We examine three methods of lim­
iting network size, and examine the tradeoff's entailed
in each of these methods. Some formal techniques for
characterizing such tradeoff's are introduced.
*This work was supported by NSF grant #IRI92-10030,
and NLM grant #BLR 3 ROl LM05217-02Sl.

The main network type examined, the TBN, has been
used to model a variety of dynamic processes, includ­
ing applications for planning and control [11, 12] and
medicine (e.g. [2], VPnet [10], and ABDO [24]). In
such applications, the static system structure is mod­
eled using a Bayes Network (BN) or influence diagram
(ID), and the temporal evolution of the system is mod­
eled using a time series process, connecting nodes in
the BN over different time intervals using "temporal
arcs". In other words, if BN1, BN2, ... BNk are a tem­
poral sequence of Bayesian networks (called a tempo­
ral BN or TBN), these systems address a method of
defining the interconnections among these temporally­
indexed BNs. The sequence of Bayesian networks
(which evolve according to the stochastic dynamic pro­
cess) together with a corresponding sequence of man­
agement decisions and values derived from the deci­
sions defines the temporal influence diagram.
In almost all of these approaches, a Markov assump­
tion is made, due primarily to the entailed well-known
theoretical properties and relative computational fea­
sibility. However, this simple form of temporal de­
pendence is violated by many real-world processes.
Higher-order Markov processes can be embedded in
the TBN or TID to capture longer-term stochastic pro­
cesses, but at the expense of adding more temporal
arcs, thereby increasing data requirements and com­
putational demands of network evaluation. 1 Similarly,
other temporal processes, such as dynamic linear mod­
els (DLM) [29], can be embedded into temporal BNs
or IDs [9, 10, 18].
Some difficulties which arise in large, complicated do­
mains, (e.g. for domains in which large TIDs are con­
structed [9, 17, 18, 24]), include:
•

Given that exact network evaluation is NP-hard
[6], and the approximation task is also NP-hard
[8], limiting the size of networks is often the only
way to ensure computational feasibility. Hence,
during model construction, one needs to trade off

1 Modeling time-series processes other then first-order
Markov processes can be computationally infeasible for
large systems [23].

Tradeoffs in Constructing and Evaluating Temporal Influence Diagrams

•

•

a utility-maximizing model for parsimony (and
computational feasibility).
It is difficult to evaluate time-series processes for
models which contain many variables. In addi­
tion, the data collection/storage requirements for
large models can be prohibitive.
Due to certain conditional dependencies among
variables, it may make more sense to model the
temporal evolution of only the subset of variables
which are in fact evolving, and use these processes
to drive the changes in the dependent variables.

This paper addresses the tradeoff's inherent in con­
structing TIDs which adequately capture the tempo­
ral evolution of the system without prohibitive data
and computational requirements. Three approaches
for TID construction which make different tradeoff's
are introduced: (1) knowledge-base construction ap­
proaches, which tailor the network at each time inter­
val to the data available (rather then just copying the
original Bayes Network for all time intervals) [23]; (2)
domain-specific time-series approaches, which model
the evolution of a parsimonious subset of variables
(rather than all variables); and (3) model selection ap­
proaches, which seek to minimize some measure of the
predictive accuracy of the model without introducing
too many parameters, which might cause "overfitting"
of the model. The second and third approaches are the
main contribution of this paper: the second approach
is a new analysis of TIDs, and the third approach is
the first application tb probabilistic networks of trad­
ing predictive accuracy for model parsimony.
The tradeoff's made by these parsimonious approaches
are quantified using various methods, and illustrated
using a medical diagnosis example. In addition, some
Bayesian approaches to model selection are also exam­
ined.
2

TEMPORAL BAYESIAN
NETWORKS

2.1

Static Model Structure

We characterize a BN or TID model M using the pair
(9, 9), where 9 refers to the graphical structure of the
model and IJ refers to the set of parameters associated
with 9, such as conditional probability distributions
assigned to arcs in g.
The qualitative structure Q(V, A) consists of a directed
acyclic graph (DAG) of vertices V and arcs A, where
A � V X V. Each vertex corresponds to a discrete
random variable t/J with finite domain O.p. Arcs in the
BN represent the dependence relationships among the
variables. Arcs into chance nodes represent probabilis­
tic dependence and are called conditioning arcs. The
absence of an arc from node i to j indicates that the
associated variable t/Ji is conditionally independent of
variable t/Ji given t/Ji 's direct predecessors in the DAG

41

Q(V,A).
For a static model (i.e. a single time slice) the quanti­
tative parameter set IJ consists of the conditional prob­
ability distributions necessary to define the joint dis­
tribution P('rh, t/12, ... , '1/Jn)· The required distributions
are given by P(t/J) for every node t/J with no incoming
arcs, and by the P(t/Ji 1'1/Ji) for the nodes t/Ji, t/Ji joined
by an arc in the DAG. Note that the structure g unam­
biguously defines the parameter set 8 which is neces­
sary to specify the joint distribution P(t/11 , t/12, .. . , t/Jn),
and the structure g of a BN is implicit in the para­
metric description.
2.2

Example: Acute Abdominal Pain Model

Provan and Clarke (24, 23] have developed an ID model
for the diagnosis and treatment of acute abdominal
pain (AAP). A common cause of acute abdominal pain
is appendicitis, and in many cases a clear diagnosis
of appendicitis is difficult, since other diseases such
as Non-Specific Abdominal Pain (NSAP) can present
similar signs and symptoms (findings).
Figure 1: Influence diagram for diagnosis and treat­
ment of acute abdominal pain

In this model, a BN models the physiology of the
system, and decision and value nodes represent the
actions taken and corresponding utilities of such ac­
tions respectively. Figure 1 presents an example of
the type of network created for the diagnosis of AAP
for a single time slice. In this figure, chance, deci­
sion and value nodes are represented diagrammati­
cally by ovals, rectangles and diamonds respectively.
For example, the chance node for Inflammation (In­
fiamm) is conditionally dependent on the chance nodes
for Perforated-Appendix (Perf-App) and Appendicial­
Obstruction (A-Obs). Some possible diseases studied
in the model are Appendicitis (App) and NSAP. In
this single time-slice ID there is one decision node d
and one value node V. The shaded nodes in this di­
agram represent observable variables X, e.g. Absent
Bowel Sounds (ABS), Right-Lower-Quadrant Tender­
ness (RLQ-T), Nausea (N), Vomiting (V), etc.
2.3

Dynamic Model Structure

A temporal BN (or ID) consists of a sequence of BNs
(IDs) indexed by time, e.g. 90, 91> ... , 9t, such that

42

Provan

temporal arcs connect gi with gi, with the direction
of the arcs going from ito j if i < j.2 A temporal arc
Ar(t) connecting networks for time slices t- 1 and t
is a subset of the inter-network edge set Ain t(t), given
by

Figure 2: TID for patient X over 2 time intervals, with
new findings of anorexia (A) and muscular guarding
(G) in the second time interval, as shown by shaded
n des
. . .. . .

.. .. .. .... . .....

{(a, ,B) Ia E V(t- 1), ,8 E V(t),
(a, ,8) E V(t- 1) x V(t)}.

Inter-lemp<lral arc

If we index the BN by time, i.e. gt = (V(t), A(t)),
then the full temporal network over N time slices
(which may be intervals or points), is given by gN =
(VN , AN ) , where
N

U V(t),

vN

AN

t=O

=

N

U A(t)

t=O

lntra·temporal arc

and
u

N

U Ar(t).

t=l

Each temporal arc connects a pair of vertices
The temporal node set connected over time slices t- 1
and t is given by

VP(t) = {Vi(t- 1) u Vj(t)IAr(t)
2.4

c

Vi(t- 1)

X

vj(t)}.

Example: Temporal Model for Diagnosis

Temporal reasoning for AAP is important due to the
difficulty of diagnosis and treatment based on data
from just a single time slice. Appendicitis progresses
over a course of hours to days, and one might be
tempted to wait until the complex of signs and symp­
toms is highly characteristic of appendicitis before re­
moving the appendix. However, the inflamed appendix
may perforate during the observation period, causing a
more generalized infection and raising the risk of death
from about 1 in 200 cases to about 1 in 42 [21]. Thus,
the tradeoff is between the possibility of an unneces­
sary operation on someone whose findings are simi­
lar to early appendicitis and a perforation in someone
whose appendicitis is allowed to progress.
Given that data over time can greatly simplify the di­
agnostic process, a TID is used for this domain. As
an example, consider a simple situation in which 2
temporal intervals are modeled for the AAP domain
as shown in Figure 2. Dashed lines indicate the arcs
joining nodes from two different time slices.
2.5

Parametric Specification

The probability distributions to be specified for a TID
can be classified into two types: (1) time-series process
distributions for temporal arcs Ain t(t) ; and (2) distri­
butions for the network for each time slice, g1, g2, ....
For example if Figure 2 represents graphs for two time
2This notation is adapted from [18).

slices, g1 and g2, then a sample of temporal arc distri­
butions includes: P(V(2)IV(1)), P(RLQ(2)IRLQ(1)),
P(ABS(2)IABD(1)), P(App(2)1App(1)), P(Perf­
App(2)1Perf- App(1)), etc. A sample of distribu­
tions within a single time slice includes: P(V(1)1
lnflamm(1)), P(RLQ(1)1Inflamm(1)), P(ABS(1)1
P(App(2)1App(1)), P(Inflamm(1)1
Perit(1)),
NSAP(1)).
3

TID CONSTRUCTION FROM
KNOWLEDGE BASES

TIDs (or TBNs) are typically constructed (e.g. [11])
by replicating the ID for the initial time slice over the
succeeding N- 1 time slices (i.e. gi, i = 0, 1, ... , N are
all the same), and then joining the networks over suc­
cessive time slices using a Markov assumption. This
approach is relatively inflexible, as it does not allow
the network to be altered over time. In addition, if
the network's size changes over time, many redundant
variables will be present as the stati<> network is repli­
cated for future time slices, since the first network will
need to incorporate all potentially relevant structure
over future time slices.
A recent approach to reduce (static) Bayes network
complexity, tailoring networks to data [15, 28], of­
fers the potential to improve network evaluation costs
for such networks. This approach entails construct­
ing a knowledge base (KB) for the domain in ques­
tion. Given a particular set 0 of observations, this
approach does not construct a network corresponding
to the entire KB, but instead tailors a model to the
observations 0 from the KB.
This approach has been extended to the construction

Tradeoffs in Constructing and Evaluating Temporal Influence Diagrams

of TIDs in [24], where a first-order Markov assumption
was made in defining the temporal arcs Ar(t). For
example, Figure 2 represents a TID for two time slices.
Note that even though the KB for the acute abdominal
pain domain covers over 50 findings, 20 intermediate
disease states and 4 diseases [24], the network !h for
the first time slice is significantly simpler, and covers
only 7 findings, 4 intermediate disease states and 2
diseases.3 Evaluating this smaller network can be done
much more efficiently. Note also that this approach
can model how the findings change over time during
the evolution of the underlying disease by altering the
Q;'s over time. For example, in Figure 2, the network
!h for the second time slice introduces variables not
contained in �h, representing findings present in time
slice 2 but absent in time slice 1.
·

For complex domains like the diagnosis of AAP, the re­
duction in network size afforded by the automatic net­
work construction approach improves computational
efficiency, but not enough to allow modeling complex
time-series processes like higher-order Markov pro­
cesses. Some other techniques, such as the one dis­
cussed below, are also necessary.
4

DOMAIN-SPECIFIC
TIME-SERIES MODELS

In this section we propose two new domain-specific
heuristics for cases in which even tailoring the net­
work to the observations does not produce an easily­
evaluated BN or ID. For TIDs, a promising heuristic
is to model the temporal evolution of only a subset
of variables. Two different models for which variables
should evolve are possible: "driving" variables or ob­
servable variables. These are discussed below.
4.1

Parsimonious Modeling of System
Temporal Evolution

Driving Variables: This approach entails a domain­
dependent identification of the system variables which
are actually evolving, driving changes in other system
variables. To this effect, we partition the system vari­
ables tjJ into a set V of dynamic or evolving variables
and a set S of variables ,which are either constant or
whose changes are due to some x E V. For complete­
ness, we assume a set 'Y of variables which are inde­
pendent of the variables x E V. Under this partition,
we have t/J = V U S U 'Y.

Using this partition, an appropriate stochastic process
is associated with each x E V. In a TID, this is repre­
sented by .an appropriate set of temporal arcs for each
such stochastic process.
This partition should be made to trade off model ac­
curacy for computational efficiency. In some domains,
3 A network like this is constructed for a particular case
in which 7 findings are presented.

43

there may be techniques to govern which variables may
be modeled as static, and which must be dynamic.
In other domains, in order to make the appropriate
tradeoffs, heuristics must be used. Section 5 presents
some ways to formally evaluate the tradeoffs which are
made.
Observed Variables: This approach seeks to model
the observables (findings) X which are the evidence of
the internal evolution of the system. Typically, when
one is monitoring the system, there exists data (over
time) for these variables. However, if these variables
are not the ones that are driving the process under
study, then one is estimating the values of the driving
variables V from the observables, using the model to
relate the two classes of variables.

We now present an example of the modeling of acute
abdominal pain to demonstrate this temporal arc se­
lection process.
4.2

Example: Acute Abdominal Pain Model

The AAP model has three variable types: observ­
able, intermediate (latent) and disease variables, de­
noted X, V, W respectively. The current method for
modeling AAP over time is to use a TID in which a
semi-Markov process governs the evolution of all sys­
tem variables [23].4 This entails defining a large num­
ber of temporal arcs. Figure 2 shows a simple situa­
tion in which 2 temporal intervals are modeled. For
just a first-order Markov assumption, the large num­
ber of temporal arcs in Figure 2 is immediately obvi­
ous. Model evaluation is consequently very expensive.
More importantly, the true temporal processes for
this domain are not adequately captured by this first­
order Markov assumption [22]. Hence, a higher-order
Markov model is required to capture this more com­
plex system evolution. However, this should be em­
bedded without introducing significantly more tempo­
ral arcs (with their entailed data and computational­
resource requirements).
One solution is to model the evolution of a subset of
the variables. Two approaches to developing a model
in which only a subset of the variables evolve over time
include:
Driving Variables: This approach models the un­
derlying physiology which is driving the evolution of
the system. Consider the set of causal relationships:
App --+ A-Obs--+ Inflamm--+ V.
If we assume that once a case of appendicitis is initi­
ated by an appendicial obstruction (A-Obs), and that
the obstruction does not change, then the only vari­
able which changes is the inflammation. Vomiting (V)
changes in response to the degree of inflammation.

4In this semi-Markov model, data is available to es­
timate transition distributions for the findings variables,
and transition distributions are estimated based on expert
opinion for the remaining variables. Dr. J.R. Clarke is the
surgeon providing the expert opinion.

44

Provan

A similar analysis can be done to identify the set of
variables 'D which drive the system evolution. This
partitions the variables into static S and dynamic 'D
variables: tf;(t) = S U 'D(t). The set V(t) consists of
latent variables, as shown in Figure 3. The findings,

Figure 4: Reduced version TID for patient X over
2 time intervals with temporal arcs for both findings
(observable variables) and latent variables

•

··················

lnter-tomporol..

Figure 3: Reduced version TID for patient X over 2
time intervals, with just disease and latent variables
evolving temporally

lnln-tomporolac

....................

1--lomporot ..

lnln-tomporot ..

5

MODEL SELECTION
APPROACHES

5.1

which also change over time, are conditionally depen­
dent on the x E 'D(t), and are an observable reflection
of the internal physiological changes over time.
The drawback to this approach is that 'D(t) consists
of latent variables, for many of which detailed tem­
poral physiological models do not exist. For example,
insufficient information about the progressive inflam­
mation of the appendix is known to create a parame­
terized model, nor can direct measures of the degree
of inflammation be made, except possibly using white
blood count (WBC); instead, this process is typically
inferred from the findings which accompany it.
Observable variables: This approach models the
observables (findings) X which are the evidence of the
internal evolution of the system. A large body of data
exists for these variables (24], as data collection is sim­
plest for these variables. An example of such a network
is shown in Figure 4.

The drawback to this approach is that the observables
X(t) may not necessarily predict the underlying dis­
eases W(t) as reliably as the latent variables V(t), if the
latent variables V(t) are assumed to be static.5 A sec­
ond drawback is that there are relatively more observ­
able than finding variables, so this approach is more
computationally expensive than using latent variables
alone.
5 A more accurate model might include both latent and
finding variables as dynamic variables.

Specifying Tradeoffs

If the topology and probabilities of the TID are
changed, then some measure of how the changes affect
the predictive accuracy of the output, or of the "qual­
ity" of the decision-making provided by the network,
needs to be computed. In this analysis, we assume
that there is some utility function which is used as a
measure the network "accuracy" or "decision quality"
for different models. 6
The effectiveness of any decision rule is measured us­
ing a loss function L(8, 8). This is interpreted as mea­
suring the loss L( 8, 8) associated with taking action 8
when the world state is parameterized by 8. Given a
prior probability estimate 1r(8) of the world state 8,
the risk function provides a measure of the expected
loss under varying values of the observable variables
X, and is given by R(8, 8) = E�[L(8, 8(X)).
The Bayes risk of a decision rule 8, with respect to a
prior distribution 11' on the entire parameter space e,
is defined as r(1r, 8) = E.,.-[R( 8, 8)]. This averages over
the risk functions given all priors that can be assigned
to 8.
A decision rule 81 is preferred to a rule 82 if
r(1r, 81) < r(1r, 82). A Bayes rule is a decision rule
which minimizes r(1r, 8), and is thus optimal.
This paper proposes a variety of techniques for ana6We use a loss function, to maintain consistency with
much of the decision theory literature (e.g. [3]); utility and
loss, for the purposes of this paper, are duals to each other.
Hence, one seeks either to maximize the expected utility,
or minimize the expected loss.

Tradeoffs in Constructing and Evaluating Temporal Influence Diagrams

lyzing the tradeoffs made during model selection, in­
cluding risk-based as well as purely probabilistic cri­
teria. Although a utility measure is desired, proba­
bilistic criteria can be used in a variety of situations
(e.g. [4, 27]). Many probabilistic criteria are simpler
to compute, and do not require a prior distribution
11"(8).
For example, in the medical example described earlier,
the utility function measures the utility of the treat­
ment given what disease is actually present. Thus an
unnecessary appendectomy will have low utility, and a
necessary appendectomy will have relatively high util­
ity. So if the loss L(8,, 61) associated with decision 61
under parameter set 8, is less than that under model
82, i.e. L(81, 61) < L(82, 61), this means that model
81 allows you to provide better treatment under the
same decision rule 61 than 9 • For the purposes of
2
medical treatment one needs to determine if the dif­
ference is significant.
In addition to the loss function, one may want to trade
off decreased model utility for increased computational
efficiency. The model parameter penalty g(1) to be in­
troduced in equation 1 can be used to provide a mea­
sure of computational expense based on the number of
model parameters. Alternatively, one can incorporate
into the loss function a computation penalty function
��: (8), which measures the computational resources nec­
essary to evaluate a model with parameters denoted by
8.
5.2

the quality of the model for prediction. The selection
procedure criteria can be defined using the following
equation:
(1)
1(8,/) = !(8,/) + g('Y),
where f(8, 1) is a measure of predictive error, and
g('Y) is a penalty for the number of model parame­
ters. One widely-studied approach is to choose some
In E f that jointly minimizes the sum of predictive
error8 and parametric penalty, setting the predictive
error measure to be the sum of squared error (SSE)
[13]:
arg min[SSE-y + l1lu2II],
(2)
-rer
where II � 0 is a pre-specified constant, Ill is the num­
ber of nonzero components o£1, and SSE= 18-r -8J2.
In the right-hand-side of equation 2, the first term de­
notes the predictive error, and the second term is a
penalty function on the number of parameters in the
model. Hence this equation can capture a wide vari­
eties of approaches which trade off predictive accuracy
and model size. For example, for known u2, the Akaike
Information Criterion (AIC) [1] is the special case of
In when II = 2, and the BIC approach [25] is the
special case of In when II = /ogn. A third approach,
called the risk inflation (RI) approach [13], is defined
with respect to a "correct" model parameter set 1*
(e.g. as determined by an oracle). The risk inflation
measure RI('Y), is
In =

Rl('Y)

Statistical-E�timation Model Selection
Approaches

Consider the case where there are p total observable
parameters (predictors) {fh, 82, •.• , Bp}, of which some
subset q < p is to be selected to estimate a latent
variable y. Possible measures of predictive accuracy
based on a parameter estimate 8 are:
Sum of Squared Error (SSE)
Log likelihood
Predictive Risk

18- 812
log(8- 8)
E8 18- 812

Corresponding to the p parameters, we introduce a set
of p indicator variables given by 1 = {11 , 12, ... , /p},
where 'i'i is defined as follows:
Is .

_

{ 01

if B; is to be estimated by 0
otherwise.

Definer as the set of all p-tuples 'i'· 1 can be thought of
as an indicator vector denoting which parameters are
considered in a model, and r as the set of all possible
models over 8.
The model-selection procedure then consists of select­
ing some 1 E f and then estimating 8 by 8-y.7 Various
criteria for this process have been used to compute
7Details for computing 0-r are given in [22].

45

=

E l8 - 812
sup 9
,
8 E8J8- 8-r·l2

R(8,8)
R(8, 8-r•)

The selection procedure with smallest risk inflation
will be minimax with respect to the ratio function
RI(1) [13]. The risk inflation criterion calibrates the
risk of a model selection estimator against the risk of
an ideal model selection procedure.
5.3

Bayesian Model Selection Approaches

The Bayesian approach to model selection is based on
computing the posterior probabilities of the alternative
models, given the observations. Two Bayesian analy­
ses of the model selection process applied to BNs have
been published recently. One method focuses on av­
eraging over all possible BN models to select a model
with improved predictive ability [20, 19]. Since the
space of all possible models is potentially enormous,
two approximation techniques are proposed: (1) use
Markov chain Monte Carlo simulation to directly ap­
proximate the model selection process [20]; and (2)
select a subset of the set of all models by excluding
all models which receive less support from the data
then their simpler (in terms of number of parameters)
counterparts [19]. Both studies indicate that model
averaging improves predictive performance.
8 u2 denotes the variance of the random predictive error
in the estimation process.

46

Provan

Given a large model space (as denoted by r), the
model space pruning heuristics proposed in [19] can be
crucial to the model selection process, given no prior
knowledge about alternative models. In contrast, here
we present model selection techniques which are useful
when a small set of alternative models is being consid­
ered (i.e. the entire model spa�e is not considered) .
A second approach examines BN structure purely from
the viewpoint of predictive accuracy [7]. This ap­
proach computes a logarithmic score for alternative
models, ignoring the number of parameters in the
model. Given a discrete random variable y whose value
is to be estimated from a model denoted by the pa­
rameter set 8, the scoring rule used is -logP(yj8).
This approach is thus a restriction of equation 1 to
the case where /(8, 1) = -logP(yj8), and g(l) = 0.
In addition, this selection process is sequential, in
that scores are summed over a set of M cases: if
S m = -logPm(yj8) is the score on the mth case, the
total score for a particular model is given by

as follows. The AIC criterion selected the 1•t-order
Markov model. The BIC and Risk Inflation criteria
selected the observable parameter model. The BIC
with II = 0 criterion selected the 2nd-order Markov
model by a narrow margin over the canonical model;
without a penalty for model size this criterion sug­
gests that a 2nd-order model may actually best fit this
data. In contrast, imposing a penalty for model size on
this BIC test selects a simpler model, indicating that
the cost of adding parameters for the 2nd-order model
outweighs the increased predictive accuracy (given the
chosen penalty II).
Although this analysis is informative, further analysis
is clearly necessary. The selection of the observable
parameter model over the driving parameter model
may be due to the availability of better data for the
observable parameters than the latent parameters. 11
Further, this analysis needs to be done for a large nm�­
ber of cases; however, this pilot study has shown the
promise of these model evaluation criteria.

M

S

=

2: -logPm(YI8).

m=l
This approach allows monitoring of the performance
of models as new data becomes available (by updating
the score S), facilitating model adaptation over time.
Several related scoring rules are also analyzed in [7].
6

EVALUATING TRADEOFFS

We now present results from a simple AAP pilot study
which applies these different model selection criteria
to a set of models. In the following, we assume we
know the true state of the world, as represented by
the canonical model 8"'. The goal is to compare to 8"'
alternative models 8i, i = 1, ... , k, where the models
differ by the time-series process parameters for tem­
poral arcs Aint ( t) .
The BN model analysed is a network consisting of
5 copies of the BN portion of the ID presented in
Figure 1, joined together by temporal arcs based on
four temporal models: (1) 1't-order Markov; ( 2) 2nd_
order Markov; (3) driving parameters; (4) observable
parameters.9 The canonical model was assumed to
be the 18t-order Markov model, even though the long­
term nature of the disease evolution may violate this
1'1-order Markov assumption. This choice was made
because this model has been studied most carefully to
date.
Measures for these models were computed using four
different criteria: (1 ) AIC; (2) BIC; (3) Risk Inflation;
(4) BIC with II= 0. 1 0
Due to space limitations, the full details of this pi­
lot analysis are omitted. A summary of the results is
9Data for this AAP domain was briefly discussed in [24].
10This last criterion is similar to the Bayesian criterion
presented in [7].

7

RELATED LITERATURE

The methods of analyzing networks presented here are
orthogonal to the approach proposed by Goldman and
Breese [14]. Goldman and Breese describe methods
of integrating model construction and evaluation dur­
ing the process of automated network construction.
The main thrust of the work presented here is exam­
ining alternative network structures. However, some
of the model selection criteria examined here can be
used during automated network construction to pro­
vide scoring rules for whether nodes and/or arcs should
be added to a partially-constructed network.
Of the work in temporal probabilistic networks, the
most closely associated work is that of Dagum et al.
[10, 9]. The system proposed in [10] is primarily in­
terested in the statistical process underlying temporal
Bayesian networks. To this end, the paper focuses
on computing inter-temporal conditional dependence
relations; in other words, if BN1, BN2, ... BN1c are a
temporal sequence of Bayesian networks, Dagum et
al. address a method of defining the interconnections
among these temporally-indexed BNs. In [9] an addi­
tive BN approximation model is proposed. Parameter­
estimation is done using the Kullback-Liebler measure,
which is a restriction of Equation 1 to g(1) = 0.
Related issues of tradeoffs in belief network construc­
tion are discussed in [5]. These dynamic network refor­
mulation techniques can be used to identify the opti­
mal resources devoted to network evaluation, and may
help define the computation resource measures intro­
duced in Section 5.1. These techniques may also be
pertinent to facilitating the network construction ap­
proaches discussed here.
11

Many latent parameters are rough subjective esti­
mates. Further data collection and analysis is planned to
rectify this problem.

Tradeoffs in Constructing and Evaluating Temporal Influence Diagrams

8

CONCLUSIONS

[11] T. Dean and K. Kanazawa. A Model for Reasoning
about Persistence and Causation. Computational In­
telligence, 5(3):142-150, 1989.
[12] T. Dean and M. Wellman. Planning and Control. Mor­
gan Kaufmann, 1992.
[13] E.I. George and D.P. Foster. The Risk Inflation Cri­
terion for Multiple Regression. Technical Report 95,
University of Chicago, Graduate School of Business,
1992.
[14] R. Goldman and J. Breese. Integrating Model Con­
struction and Evaluation. In Proc. Con/. Uncertainty
in Artificial Intelligence, 1992.
[15] H. Keshavan (guest editor). PAMI special issue on
Model Construction from Databases. IEEE Transac­

This paper has proposed several approaches for con­
structing parsimonious TIDs for systems which evolve
over time, where the state of the system during any
time interval is modeled using a Bayesian network.
Possible approaches to modeling the dynamic struc­
ture of the system have been examined, and the trade­
offs entailed in adopting particular approaches quan­
tified using a variety of metrics. As an example, these
techniques are applied to the medical management of
acute abdominal pain.
In addition, this paper has proposed methods for se­
lecting models with better predictive accuracy, and for
trading off predictive accuracy for simpler models. Es­
pecially for complex domains such as temporal reason­
ing, limiting network size without compromising pre­
dictive accuracy too much can play an important role
in ensuring computational tractability.

tions on Pattern Analysis and Machine Intelligence,

[16]

[17]

Dr. J.R. Clarke provided the
medical expertise necessary for this research. Selecting
a parsimonious subset of parameters for time series
modeling was suggested to me by G. Rutledge. This
work has also been influenced by discussions with D.
Foster and M. Mintz, and by the anonymous referees.
Acknowledgements:

[18]

[19]




A new probabilistic network construction
system, DYNASTY, is proposed for diagnos­
tic reasoning given variables whose probabil­
ities change over time. Diagnostic reason­
ing is formulated as a sequential stochastic
process, and is modeled using influence dia­
grams. Given a set 0 of observations, DY­
NASTY creates an influence diagram in or­
der to devise the best action given 0. Sensi­
tivity analyses are conducted to determine if
the best network has been created, given the
uncertainty in network parameters and topol­
ogy. DYNASTY uses an equivalence class ap­
proach to provide decision thresholds for the
sensitivity analysis. This equivalence-class
approach to diagnostic reasoning differenti­
ates diagnoses only if the required actions are
different. A set of network-topology updat­
ing algorithms are proposed for dynamically
updating the network when necessary.
1

INTRODUCTION

The development of graphical representations for prob­
abilistic models (e.g. belief networks [Pearl, 1988],
influence diagrams (Howard and Matheson, 1981;
Shachter, 1986; Shachter, 1988)) has enabled effi­
cient probabilistic models to be developed for many
tasks, such as diagnostic reasoning (Pearl, 1988; Heck­
erman and Horvitz, 1990], natural language analy­
sis(Goldman and Charniak, 1990], etc. These represen­
tations, by specifying the causal relationships among
variables in a causal graph (and not all possible rela­
tionships), facilitate efficient inference. A great deal of
the recent research in automated probabilistic reason­
ing has focused on developing more efficient and more
general algorithms for causal probabilistic models, and
on methods for incrementally constructing belief net­
works.
However, the application of these techniques and rep-

resentations to complex diagnostic tasks, such as med­
ical diagnosis, have oversimplified such tasks. A com­
mon simplification made in many current approaches
is modeling the diagnostic process as a single-stage,
static process. This is inadequate, as diagnostic rea­
soning is a sequential, dynamic process in which feed­
back is important. Provan and Poole (1991] point out
the necessity of considering this complete process, and
in particular, the effects of feedback.
This paper exteJ;Jds existing diagnostic models to incor­
porate the dynamic and sequential nature of diagnos­
tic reasoning. It proposes techniques for constructing
sequential belief networks, and of dynamically updat­
ing such networks. Many existing techniques for con­
structing belief networks (e.g. (Goldman and Char­
niak, 1990; Heckerman and Horvitz, 1990]) model the
process for one instant of time.1 For certain tasks this
is adequate, but for tasks in which the probabilistic re­
lationships among variables changes over time, it can
be difficult to know when the best model has been con­
structed. This sometimes produces incorrect answers
due to the selection of incorrect probabilities and/or
causal relationships. Hence, both the diagnosis and
the decision taken given this diagnosis may hinge on
whether the best model has been constructed, given
the data at a particular time t. Sensitivity analyses
may be used to test how the data at different times af­
fects the best decision. If the sensitivity analyses show
that a better decision would be made under an alter­
native model, then the model needs to be updated. It
is these sensitivity analyses and model updating tech­
niques that are of interest here. Criteria are proposed
to determine when network topology revisions are nec­
essary given time-varying probabilistic and causal re­
lationships. These criteria are based on examining
the equivalence of outcomes (e.g. treatments for dis­
eases). Algorithms for conducting the necessary revi­
sions are outlined, including refinement and coarsening
techniques (Chang and Fung, 1990], and other network
1This is true even for systems in which the mode], can
be constructed incrementally, e.g. [Goldman and Char­
niak, 1990).

280

Provan

revision algorithms [Pearl, 1988; Srinivas and Breese,
1990]..
This approach makes dynamic network updating pos­
sible, and formalizes the sequential nature of diagnos­
tic reasoning (e.g. to allow feedback into the network).
The explicit introduction of utilities into diagnostic
models2 allows a more realistic formalization of the
diagnostic process. In addition, it is expected that the
techniques developed for diagnostic reasoning m<ty be
applied to other domains, where appropriate.
2

Figure 1: Change over time of likelihood ratio for the
occurrence of Right-Lower-Quadrant pain given a di­
agnosis of appendicitis
P( symptoms !appendicitis)
P( symptoms 1-.appendicttis)

DYNAMICS OF DIAGNOSTIC
REASONING UNDER
UNCERTAINTY

Treating a diagnostic task as being time-independent
can lead to incorrect results in certain domains. Con­
sider medical diagnosis, and in particular the diagnosis
of abdominal pain. Constructing a model for the ob­
servation of abdominal pain should not be done for
a single time interval, since, as noted in [Schwartz et
a/., 1986], many symptoms take on different meanings
as diseases evolve over time, both in terms of their
inter-relationships and the diseases indicated by the
particular symptoms. In a possible case of appendici­
tis, the initial symptoms include non-specific abdom­
inal pain (which could be confused with many other
ailments), and are often accompanied soon thereafter
by gastrointestinal distress and possibly by anorexia
and fever. This pain subsequently becomes localized
to the right lower quadrant (RLQ) of the abdomen
(which then provides a strong indication of appendici­
tis, along with a high white blood count). If the ap­
pendix ruptures, then there are several more symp­
toms; however, a perforated appendix leads to serious
internal complications.3 Given the evolution of a dis­
ease such as appendicitis, the probabilities assigned to
network nodes, and even the topology of the network
itself, must change over time. For example, Figure
1 shows how the likelihood ratio for the diagnosis of
appendicitis might change over time. Clearly, in the
initial stages of appendicitis, many other diagnoses are
equally likely given the symptoms.
A second aspect of this dynamic nature of (diagnostic)
reasoning is the need for modeling the temporal order
of observations. In some cases the temporal sequence
of observations (as opposed to just an unordered list
of the set of observations) can provide strong cues for
a diagnosis. For example, if a woman has abdominal
pain, noting whether this pain is immediately followed
by gastrointestinal distress could help identify a pos2 Utility considerations have been ignored in most formal
models of diagnostic reasoning, except for approaches such
as [Heckerman and Horvitz, 1990].
3Most diagnostic procedures attempt to avoid perfora­
tion and its resulting complications.

Time

sible case of appendicitis, whereas the absence of such
immediate distress would make the presence of a gono­
horreal cyst in the right fallopian tub<' more likely. A
second example is the diagnosis of a car which has
trouble starting. The sequence of events leading to
the inability to start can help identify the problem.
Thus, the inability to start only on mornings after it
has rained may indicate that moisture is getting under
the distributor cap.
A third aspect is the ability to incorporate the effects
of feedback. Feedback can alter not only the proba­
bility assignments to a network, but also the topol­
ogy of the network. For example, consider a network
constructed for a case of RLQ abdominal distress. If
simple stomach upset is diagnosed, and a treatment
of Diovol is administered, the persistence of RLQ ab­
dominal distress will provide feedback to the system
that the diagnosis may be incorrect, and the network
topology and/or probabilities may need to be updated.
This paper proposes extensions to existing network
construction techniques to model diagnostic reasoning
as a sequential, dynamic process using the formalism of
influence diagrams. This proposal is not intended to be
a full temporal calculus based on Bayesian networks, as
discussed in [Kanazawa, 1991], for example. Instead,
it attempts to build simple networks which will real­
istically model the dynamics of diagnostic reasoning
without necessitating the complicated (and computa­
tionally costly) construction and solution of temporal
Bayesian networks.
3

SYSTEM ARCHITECTURE

There are many existing systems and theories for
model construction. Examples of such n<>twork con­
struction frameworks include the proposal of Lf'hmann
[1990], and examples of such systems include Q.\!R­
DT [Shwe and Cooper, 1990] and FRAIL3 [Goldman
and Charniak, 1990]. In each of these proposals, the

Dynamic Network Updating Techniques for Diagnostic Reasoning

goal is to construct a model which completely charac­
terizes the data. However, this goal conflicts with the
need for efficient performance of implemented systems.
Solving Bayesian network models is NP-hard [Cooper,
1990], so the networks constructed must be as small as
possible to ensure efficiency. The proposal presented
in this paper trades off (to some extent) completeness
and accuracy for efficiency, as is done in many other
systems, such as [Heckerman and Horvitz, 1990).4

Figure 2:
NASTY

.�

;
Sensitivity
Analysis

The remainder of the paper discusses the algorithms
used to create an influence diagram from the KB, and
for dynamically altering this influence diagram.

4The appropriate balance of resources between meta­
analysis of model construction and model solution has been
studied by [Horvitz et al., 1989; Breese and Horvitz, 1990].
As an example, the QMR-DT network represents
diseases, 4040 manifestations and 40,740 disease­
manifestation arcs [Heckerman and Horvitz, 1990].
5

534

Heuristics

I

Select
"Best"
Diagnosis

The KB for DYNASTY consists of a network of nodes
and arcs. Nodes represent state variables, and arcs
exist between pairs of nodes related causally and/or
temporally.

Within the general model-construction framework
(such as that described in Lehmann ( 1990)), there is al­
ways uncertainty in choosing the correct model. That
uncertainty may be due to uncertainty in the instru­
ments used to record data, to noise, or to the rela­
tionship between data from observations and causes
for the observations (e.g. the diseases causing the ob­
served symptoms). This paper examines the uncer­
tainty arising from relating observations and causes,
and in particular the temporal uncertainty of this re­
lationship.

l

Influence
Diagram
Model

l

Like several existing network construction methods
(e.g. QMR-DT, FRAIL3), we start with a Knowl­
edge Base (KB) containing (1) causal rules, and (2)
a set of conditional probability tables. From this KB
a network is constructed to solve a given task.

Typically, the complete KB for a given domain is quite
large,5 and given a set 0 of observations, it is necessary
to construct a network containing only the data related
to 0 (and not the entire KB).

DY­

m

KB

A new system architecture proposed to model dynamic
reasoning tasks is depicted in Figure 2. This system is
called DYNASTY, for DYnamic Network Analysis of
System TopologY.

Associated with the network are probability tables for
the conditional probabilities for the network, such as
those required for the construction of a Bayesian net­
work. In addition, utility values are stored for decision­
making.

Network construction methods

4

MODEL CONSTRUCTION
HEURISTICS

4.1

Time Dependence

As noted earlier, diagnostic tasks whose characteristics
change over time have not been modeled in earlier ap­
proaches. The approach taken in DYNASTY is to dis­
cretize the possible times from which the observations
could have occurred. Call 'D,, the network (consisting
of causes and intermediate causes/observations) which
would need to be constructed at time t;. In full gener­
ality, the networks at different times are different, and
they can each be quite large for complicated tasks.
To fully model a diagnostic task, an influence diagram
(ID) containing sub-networks for each time I; would
need to be constructed, given a set 0 of observations.
This is shown in Figure 3.

Figure 3: Most general influence diagram for solving
a stochastic diagnostic task

281

282

Provan

DYNASTY attempts to solve a simplified task: it cre­
ates a network for particular time tj, and then con­
ducts a sensitivity analysis to determine if the action
taken is affected by the choice of time tj. The ID which
would be constructed is shown in Figure 4.
Figure 4: Simplified influence diagram for solving a
stochastic diagnostic task

However, these observations may actually be indica­
tive of the early stages of appendicitis. To make sure
that a possible case of appendicitis might be diag­
nosed, the ID shown in Figure 7 must be constructed.
This ID bears little relation to the ID shown in Fig­
ure 6. The possible treatments include: (1) emetic (for
Figure 7: More complex influence diagram for abdom­
inal pain example

Example 1

Consider the time course of a possible
case of appendicitis. Early in the course of appen­
dicitis, the symptoms could appear to be a simple up­
set stomach. Figure 5 shows the notation necessary
Figure 5: Notation for constructing Abdominal Pain
Influence Diagram
OBSERVATIONS
or

P

N
F

:

HYPOTHESES

=

anorexia
nausea
=: fever
abdominal pain
:

LLQ

_

LLQ pain

RLQ

:

RLQ pain

A
US
FP
GC

::

::

=:

:=

appendicitis
upset stomach
food poisoning

gonohorreal cyst

to construct IDs for this task. If the observations are
nausea and general abdominal pain, then the simple ID
shown in Figure 6 may be constructed. This is an easy
influence diagram to construct and solve. Given an ID

food poisoning), (2) Diovol (for simple upset stomach),
(3) removal of appendix (for appendicitis), or (4) treat­
ment or removal of gonohorreal cyst.
This example shows how, given a set of observations,
uncertainty in the time course of possible diseases may
require entirely different IDs. "'
There are a number of heuristics used in DYNASTY
for network construction. One heuristic is the use of
temporal orderings for probability assignments. This
heuristic is best demonstrated by an example. Con­
sider the diagnosis of a car which infrequently has
problems starting. The two diagnoses under consid­
eration are a distributor cap problem (DC) or an al­
ternator problem (ALT). The weather (Vi') may affect
the diagnosis, as wet conditions can cause condensa­
tion under a distributor....£!!:J>, thereby causing the fail­
ure of the car to start (ST). Other possible causes of
the problems in starting, e.g. the alternator may be
faulty and not recharging the battery, are not affected
by weather conditions. A simple Bayes network for
this problem is shown in Figure 8. Knowledge of the

Figure 6: Simple influence diagram for abdominal pain
example
Figure 8: Bayesian network model for determining the
cause of the failure of a car to start

such as this, the possible treatments are the adminis­
tration of an emetic (for food poisoning) or Diovol (for
simple upset stomach).

history of the correlation between weather conditions

Dynamic Network Updating Techniques for Diagnostic Reasoning

and success in starting the car can significantly affect
the probabilities assigned to the network. For exam­
ple, if the car only gives trouble starting in wet con­
ditions, then the problem is most likely DC; if the car
gives trouble with equal probability in both wet and
dry conditions, then the problem is most likely ALT.
In fact, trouble in a single instance when the weather
is dry will lead to the assignment of a low probabil­
ity to P(DCIST, W). In this case, the history of the
problem is crucial to the probability assignment.
Hence, the history heuristic is the use of temporal his­
tory, whenever possible, in selecting the probabilities
(from the probability tables) to be assigned to the net­
work in consideration. The temporal history is com­
puted simply by tracing the history for a node in the
KB, using revised Truth Maintenance algorithms for
computing the justifications for a node in a depen­
dency network [McAllester, 1990]. The history heuris­
tic also uses triggers to guide probability assignments.
For example, finding a single instance when the car
won't start in dry conditions is a tri� to the assign­
ment of a low probability to P(DCIST, W).
4.2

Sequential Diagnostic Process

The ID framework also allows diagnostic reasoning to
be formulated as a sequential diagnostic process. Us­
ing a result of Tatman and Shachter [ 1990], an ID can
model a sequential process using dynamic program­
ming, provided that the value function Vis separable.
In terms of IDs, a value node is separable if it can
be represented as the sum or product of multiple sub­
value nodes.
Value node separability has been exploited in the de­
sign of a sequential process for image understanding
[Levitt et al., 1990]. In a similar manner, value node
separability is used to model the sequential nature of
diagnostic reasoning. In brief, the decision nodes in
a DYNASTY ID are called treatments, which may be
tests to determine more observations, or actual treat­
ments for hypothesized diseases. In the former case,
given an ID shown in Figure 6, the test T can deter­
mine a new observation 0', creating a new ID with
another decisit>t. node T' (e.g. another test or a treat­
ment) and another value node V'. In this manner,
the sequential nature of tests (or treatments) providing
feedback to the diagnostic process can be modeled. 6
5
5.1

MODEL UPDATING
Overview

In a problem for which probabilities are temporally
dependent, the sensitivity of the computed decisions
6Please refer to [Provan, 1991 ( forthcoming )] for more
details. The presentation here is brief due to space
limitations.

to the temporally-dependent probabilities must be
tested. This provides a threshold for determining when
a better model is warranted. This may require new
probability values (corresponding to a new time t'), or
a new network topology corresponding to time t'.
This sensitivity analysis/model updating in DY­
NASTY occurs in two stages:
F irst, a sensitivity analysis is
conducted to determine if data from time t' pro­
vides a better model than the data from time t.

Sensitivity Analysis

If the network model needs to be
updated, then some of the following processes may
need to be invoked:

Model Updating

I.

New probability values are assigned and
propagated to compute a new network equi­
librium state.
2. Network topology is altered.
3. A new model is built for a different time t'.
These processes are now discussed in greater detail.
5.2

Equivalence Class Sensitivity Analysis

Given the construction of an ID model at time t, a deci­
sion (with accompanying diagnosis) of maximal utility
is computed. For example, in the car diagnosis ex­
ample, the diagnosis might be DC, and the decision
REPLACE-DC. This decision would maximise the re­
quirement of ensuring that the car no longer has trou­
ble starting.
In the process of computing this best decision, the
next-best decision for a different equivalence class is
also recorded. In the car example, this is REPLACE­
ALT. If there is uncertainty concerning which proba­
bilities are correct, then the sensitivity of the decision
to this uncertainty must be determined. This is for­
malised in terms of equivalence classes of decisions as
follows.
5.2.1

Analysis of Equivalence Class es

The equivalence class approach to diagnosis, as origi­
nally formulated in [Provan and Poole, 1991], is sum­
marised here. The rationale is that there is no point in
distinguishing between decision-equivalent diagnoses,
i.e. diagnoses for which the decision taken (e.g. ad­
ministration of drugs to a patient) are the same; as far
as the decision-maker is concerned decision-equivalent
diagnoses should be considered as the same diagnosis.
The aim of diagnostic reasoning is to provide a treat­
ment for a set of observations. From an equivalence­
class point of view, this reduces to refining the set
of use-equivalent possibilities; i.e. one does not care
about distinct diagnoses, but distinct treatments (and
their associated distinct equivalence classes). Thus,

283

284

Provan

use-equivalence induces a partition on the set of diag­
noses, where each partition corresponds to a possible
distinct decision.
Let T be the set of all treatments (or decisions). 7 Let
V be the set of all possible diagnoses.
Definition 5.1 The possible treatment space P
is a subset of Vx T. (D, T) E P means that T is a
possible treatment given that the diagnosis is D E V.

P induces an equivalence relation on the set of diag­
noses. This will be called strong equivalence with re­
spect to P. The idea is that equivalent diagnoses have
the same set of possible treatments.8

and D2 are
to P, written
P if and only if

D1

Definition 5.2 Two diagnoses
strongly equivalent with respect

D1

""P

Dz

if V T

P.

E

T,

(D1,T)

E

(D2, T)

E

5.2.2

Equivalence Class Decision-making

We assume we have a measure p(D,T) of the utility of
treatment T given diagnosis D. We can define the pos­
sible treatment space as the set of diagnoses with the
same utility.9 In this case, "strong use-equivalence"
means having the same utility for each treatment.
Let V be the set of use-diagnoses. For D E V, every
logical model of D has the same utility measure. The
following proposition about the expected value, £(T),
of treatment T was proven in (Provan and Poole, 1991]:
£(T) =

L p(D, T) p(D).
X

(1)

DEV

Under this approach to diagnostic reasoning, diagnoses
are selected such that the expected utility of the treat­
ment is maximised. That is, the goal is to compute 'Yi
such that the expected value of the treatment given by
equation 1 is maximised.
Consider an ID in which the variables are denoted by
X= {x1,.... ,xn}, such that any diagnosis D consists
of a subset of variables X' C X which are not func­
tioning normally (cf. (de J(leer et a/., 1990; Pearl,
1988; Provan and Poole, 1991] for a further descrip­
tion of such diagnostic models). Then equation 1 can
7By a treatment we mean a total prescription of what
to do (i.e., we do not conjoin different treatments - the
conjunction would be one treatment). A treatment may
be a test to distinguish abnormalities, the administration
of drugs, replacement of circuit components, etc.
80ther types of equivalences, e.g. weak equivalence, are
also distinguished in [Provan and Poole, 1991]; such cases
are not discussed here due to space limitations.
9Formally, the treatment in the possible treatment
space would be a pair (T, v) where (D, (T, v)) E P if
I'(D, T) = v.

be rewritten in terms of these variables as
f[TJ=

L LJI.(x,T)xp(x),

(2)

DEV Dl=x

where JI.(x, T) is the value of
true in D.

p(D,T) such

that

x is

The notion behind the sensitivity analysis is as fol­
lows: consider a model constructed at time t, such
that decision T; is the optimal treatment. Call f3 the
expected utility for decision T;. If the probabilities of
certain variables are time-dependent, then these new
probabilities need to be substituted into the model to
check if the decision would change. Note that differ­
ent diagnoses may be computed, but if the decision is
unchanged, then, under this use-equivalent approach,
no network updating is necessary. For network updat­
ing to be necessary, the threshold f3 must be exceeded
by the expected utility of another treatment Tj given
probabilities for timet', i.e.

[

f(Tj] =

]

L L p(x,T)xp(x)

DEV DFX

>

f].

This provides a precise bound on when the treatment
changes. When the threshold is exceeded, then net­
work alterations may be necessary. These updating
methods are now summarised.
5.3

Model Updating Techniques

There are several types of model updating operations,
of which two of the most important are: (1) probability
value updating, and (2) network topology updating.
These are discussed in turn.
5.3.1

Probability Value Updating

This is the simple case of network upd ati n g. If no
changes to the network topology are required when
the model is updated from time t to t', then the re­
quired alterations to the probability values are made,
and these values are propagated to obtain a new net­
work equilibrium state.
For example, during the early stages of appendicitis
diagnosis, probability values may need to be updated
given changes in location of abdominal pain. Possible
changes in probability assignments are shown in Figure
9(b),(c).
5.3.2

Network Topology Updating

Consider the onset of an entirely new set of symptoms
in the observation of a patient with a possible case of
the later stages of appendicitis. These are shown in
F igure 7. If we started with the model in Figure 6,
we see that the topology of the network needs to be
altered.

Dynamic Network Updating Techniques for Diagnostic Reasoning

vides a set of constraints on how M(x) must be
altered. In an analogous manner, constraints can
be defined for the coarsening of the values of the
state space of variable x, flx, where multiple val­
ues of Wx E rlx are combined into a single value
w� E C(wx)·
The coarsening operation is defined similarly
[Chang and Fung, 1990]. The coarsening oper­
ation may lose information during the process
of node aggregation (i.e. the network proba­
bility assignments may be altered). Using the
equivalence-class approach, such information loss
is acceptable if the equivalence class does not
change. Otherwise, approximations may need to
be used [Chang and Fung, 1990].

F igure 9: Early stages of the diagnosis of appendicitis

(a)

(b)

(c)

If changes to the network topology are required when
the model is updated from time t to t', then one of
several algorithms may be used. These algorithms in­
clude:
Refinement/coarsening
operations [Chang and Fung, 1990] are used to
split/merge network nodes respectively. Consider
a network refinement necessary to include new al­
ternatives. For example, in abdominal diagnosis,
the construction of a network which models only
lower abdominal pain may need to be refined to
differentiate right-lower quadrant (RLQ) and left­
lower quadrant (LLQ) pain. Hence, a node mod­
eling lower abdominal pain needs to be split into
nodes for RLQ and LLQ (cf. Figures 9(a),(b)).
Or in the car diagnosis example, the single node
for weather may need to be split into nodes for
wet weather and mixed (wet and dry) weather.
The network changes made for the refine­
ment/coarsening operations are local, and do not
involve all nodes in the network. This is for­
malised as follows. If x is a state node, then
we call lix the predecessors of x in the network,
and I:x the successors of x in the network. The
Markov boundary of x is the minimal set of nodes
which "shield" x from the rest of the network.
The Markov boundary M(x) of node x consists
of lix U I:x U liE,. Hence, ensuring the joint prob­
ability distribution of M(x) is unaffected by the
refinement/coarsening or x ensures that the rest
of the network will be unaffected as well.
For example, it is shown in [Chang and Fung,
1990] that in a refinement of the values of the
state space of variable x, flx, each value Wx E rlx
is refined into multiple values w� E R(wx)· For
each value Wx E rlx which is refined into a value
w� E R(wx),

Refinement/ coarsening

p(I:x lwx, liE, )p(Wx, lix)

2::::

p(I:xlw�, liE.)p(w�, lix) (3)

w�ER(wx)

must be satisfied for all values of lix. This pro-

Instead of splitting and/or
merging existing nodes, completely new nodes
may need to be added to, or particular nodes
deleted from, the network. In such cases a va­
riety of other algorithms are invoked, such as
the reduction and clustering algorithms present
in the IDEAL system algorithm library [Srinivas
and Breese, 1990]. In network addition, the KB
is consulted to determine which nodes must be
added based on causal relationships.
Network Re-instantiation It may turn out that
the network created is inappropriate for the diag­
nostic task. For example, a simple network may
be created which cannot be appropriately aug­
mented to model a more complicated case10 In
such a situation, a completely new network is con­
structed from the KB.
Network additions

5.4

Implementation

The KB is implemented in Common Lisp. Extended
Justification-based TMS (e.g. [McAllester, 1990]) data
structures and algorithms are used for determining
relevant nodes to instantiate given a set of observa­
tions. The inti uence diagrams are implemented using
the IDEAL system [Srinivas and Breese, 1990].
It is hoped that the TraumAID system [\Yeb her et
a/., 1990] will be used as a test-bed for this system.
TraumAID is a decision support tool for the manage­
ment of multiple trauma. Trauma management in­
cludes both diagnosis and treatment, and this diagnos­
tic tool achieves these features using two modules: (1)
a rule-based reasoner which models the relationships
between clinical evidence and diagnostic/therapeutic
goals, and (2) a planner which manages the achieve­
ment of multiple goals. TraumAID is an excellent sys­
tem on which to test the theoretical results because,
unlike most similar systems, it already contains a no101f radical changes must be made to an initial network,
it can be computationally cheaper to create a new net­
work from scratch than to alter the original network using
coarsening/refinement operations.

285

286

Provan

tion of sequential action and change, key elements of
the proposed theory of diagnostic reasoning. Further,
efficient incremental management of action and change
is necessary for trauma management.
6

This paper has described a proposed dynamic network
construction system which can build models for prob­
lems with temporally-dependent probabilities. Heuris­
tics are used to identify the best possible model, and
to test the sensitivity of this model to probability val­
ues over time. Given the network updating capabil­
ities of DYNASTY, the full diagnostic cycle, which
includes feedback from the decisions made, can be in­
corporated into the network. In addition, the ability
to refine/coarsen the network enables different levels
of granularity (i.e. the coarseness of the description of
the system being modeled) to be examined during the
diagnostic process. Most other approaches to diagnos­
tic reasoning (e.g. [de Kleer et a/., 1990]) have no way
of dynamically altering the granularity of the system
description.
Future work includes testing the feasibility of the al­
gorithms in DYNASTY on real-world problems, and
extending and optimising these algorithms. The KB
for the TraumAID system is the first set of real data
for which such tests are proposed.
ACKNOWLEDGEMENTS: The comments of the
anonymous reviewers have led to improvements in the
paper.

[Breese

and Horvitz, 1990] J. Breese and E. Horvitz. Ideal
Reformulation of Belief Networks. In Proc. Con/. Un­
certainty in Artificial Intelligence, pages 64-72, 1990.
Fung,

K.

Chang and R. Fung.

Re­
finement and Coarsening of Bayesian Networks. In

1990]

Proc. Conf. Uncertainty
pages 475-482, 1990.

in Artificial Intelligence,

[Cooper, 1990]

G.F. Cooper. The Computational Com­
plexity of Probabilistic Inference Using Belief Net­
works. Artificial Intelligence,

Kleer et al.,

1990]

(42):393-405, 1990.

J. de Kleer, A. Mackworth, and R.

Reiter. Characterizing Diagnoses.
pages 324-330, 1990.

In Proc. AAAI,

and Charniak, 1990] R. Goldman and E. Char­
niak.
Dynamic Construction of Belief Networks.
In Proc. Conf. Uncertainty in Artificial Intelligence,

90-97, 1990.

[ Heckerman

and Horvitz,

Horvitz.

et a/.,

erman.

720-762,

Strategic Decisions

K. Kanazawa. Logic and Time Nets for

Probabilistic Inference. In Proc. AAAI,

[Lehmann, 1990]

H.P. Lehmann.

A

1991.

Decision-Analytic

Model for Using Scientific Data. In M. Henrion, R.
Shachter, L. Kana!, and J. Lemmer, editors, Un­
certainty in Artificial Intelligence 5, pages
North Holland, 1990.

[Levitt

et a/.,

1990]

309-318,

T. Levitt, J.M. Agosta, and T. Bin­

ford. Model-Based Influence Diagrams for Machine
Vision. In M. Henrion, R. Shachter, L. Kana!, and J.
Lemmer, editors, Uncertainty in Artificial Intelligence

5, North Holland,

[McAllester, 1990]

1990.

D. McAllester. Truth Maintenance. In

Proc. AAAI, pages

[Pearl, 1988]

J. Pearl.

1109-1115, 1990.
Probabilistic Reasoning in Intelli­

gent Systems. Morgan Kaufmann,

1988.

[Provan, 1991 ( forthcoming)]

G.M. Provan. A Decision­
Theoretic Approach to Diagnostic Reasoning. 1991

(forthcoming) .
[Provan and Poole, 1991]

G. M. Provan and D. Poole. A
Utility-Based Analysis of Consistency-Based Diagno­

sis. In Proc. Conf. on Knowledge Representation,
pages 461-472, 1991.

[Schwartz

et al., 1986] S. Schwartz, J. Baron, and J.
Clarke. A Causal Bayesian Model for the Diagno­
sis of Appendicitis. In L. Kana! and Lemmer J., edi­

1990]

D.

Heckerman

and

E.

Problem Formulation as the Reduction of

1989]

[Shachter, 1986]

R. Shachter. Evaluating Influence Dia­
grams. Operati ons Research, 34:871-882, 1986.

[Shachter, 1988]

R. Shachter. Probabilistic Inference and

Influence Diagrams.

Operati ons Research,

36:589-

604, 1988.

[Shwe and

Cooper,

1990]

M. Shwe and G.F. Cooper. An

Empirical Analysis of Likelihood-Weighting Simula­
tion on a Large, Multiply-Connected Belief Network.
In Proc. Conf. Uncertainty in Artificial Intelligence,
pages 498-508, 1990.

[Srinivas

and Breese,

1990]

S.

Srinivas

and

J.

Breese.

IDEAL: A Software Package for Analysis of Influence
Diagrams.

In Proc. Conf. Uncertainly in Artificial

212-219, 1990.

[Tatman and Shachter, 1990]
Dynamic

J. Tatman and R. Shachter.

Programming

and

Influence

Diagrams.

IEEE Trans. Systems, Man and Cybernetics,

20:365-

379, 1990.

a Decision Model. In Proc. Conf. Uncertainty in Ar­
tificial Intelligence, pages 82-89, 1990.

[Horvitz

[Kanazawa, 1991]

Intelligence, pages

[Goldman

pages

and Matheson, 1981] R.A. Howard and J.E.
Matheson. Influence diagrams. In R. Howard and J.
Matheson, editors, T he Principles and Applications of

tors, Proc. Conf. Uncertainty in Artificial Intelligence,
pages 229-236, 1986.



Qualitative and infinitesimal probability
schemes are consistent with the axioms of
probability theory, but avoid the need for
precise numerical probabilities. U sing
qualitative probabilities could substantially
reduce the effort for knowledge engineering and
improve the robustness of results. We examine
experimentally how well infinitesimal
probabilities (the kappa-calculus of Goldszmidt
and Pearl) perform a diagnostic task troubleshooting a car that will not start - by
comparison with a conventional numerical belief
network. We found the infinitesimal scheme to
be as good as the numerical scheme in
identifying the true fault. The performance of
the infinitesimal scheme worsens significantly
for prior fault probabilities greater than 0.03.
These results suggest that infinitesimal
probability methods may be of substantial
practical value for machine diagnosis with small
prior fault probabilities.
Keywords:
Bayesian
probabilities, kappa
probabilities, diagnosis.

networks, qualitative
calculus, i nfinitesimal

1 BACKGROUND AND GOALS

Bayesian and decision theoretic methods have long

been criticized for an excessive need for quantification.
They require many numerical probabilities and

Brendan Del Faverol

Gillian Sanders2

1oepartment of Engineering-Economic Systems,
Stanford University, CA 94305
2Section on Medical Informatics
Stanford University, CA 94305

utilities that are difficult to assess and are liable to
judgmental biases. Some people claim that since
human thinking is inherently qualitative, it is
incompatible with quantitative schemes. These
criticisms have fueled interest in alternative
formalisms for reasoning and decision making under
uncertainty that are intended to be easier to use and
more compatible with human cognition. Among these
alternative schemes are: various generalizations of
decision theory [Edwards, 1992]; Dempster-Shafer
belief functions [Shafer, 1976];generalizations of logic,
including default and non-monotonic logics [Ginsberg,
1987]; fuzzy logic [Zadeh, 1983]; possibility theory
[Dubois and Prade, 1988]; and fuzzy probabilities.
If,

however, our goal is simply to provide a qualitative
basis for reasoning and decision making under
uncertainty, there is no need to abandon Bayesian
decision theory. The axioms of decision theory,
indeed, assume only the ability to make qualitative
judgments - that is, to order events by probability or
outcomes by desirability. The quantification of
probabilities and utilities can be based on purely
qualitative judgments. Furthermore, several schemes
have been developed that are purely qualitative, but
are consistent with the axioms of decision theory.
One such scheme is qualitative probabilities, originated
by Wellman [1990; Henrion & Druzdzel 1991;
Wellman & Henrion, 1993]. A second approach to
qualitative probabilities is the kappa-calculus
[Goldszmidt and Pearl, 1992], which represents all
probabilities in a Bayesian belief network by e'K, where
is an integral power of E. The K -calculus is

K

Henrion, Prova n Del Favero, and Sanders

320

,

consistent with the axioms of probability where E---+0.
Events are ranked according to K. Events with larger K
are assumed to be negligible relative to events with
smaller K. The calculus provides a plausible set of
events: those with the smallest (most probable)
consistent with the observed findings. The calculus is
sometimes called

qualitative probability.

To avoid

confusion with other qualitative probability schemes,
we call this representation
Pearl

infinitesimal probabilities.

[1993] has extended this scheme to handle

similar difficulties.
Much current research on
qualitative simulation is directed towards integrating
quantitative information to resolve ambiguities (and
the resultant combinatorial explosions of the search
space).
In this paper, we report the results of an initial
experimental

study

comparing

the

diagnostic

performance on a specific belief network using (1) the
K -calculus or infinitesimal probabilities, and

(2)

qualitative utilities to support decision making.

numerical probabilities. Our goal is to examine how

The K-calculus or infinitesimal probabilities can be

approximation to the numerical representation.

well

the

infinitesimal

scheme performs as

an
We

looked at in two ways: (a) as providing a scheme for

start with a fully assessed numerical representation,

non-monotonic reasoning whose semantics are firmly

convert this into a kappa-representation using finite e

grounded in probability and decision theory; or (b) as

values, and perform inference on a set of test cases.

providing a simplification of belief networks with

We first explain the mappings we used to obtain

numerical probabilities. In this paper, we are focus on

infinitesimal

the second view, and examine the performance of

probabilities, and how we mapped back from the

infinitesimal probabilities as an approximation to
numerical probabilities.

or

K-values

from

the

numerical

pos terior K-values into probabilities for comparison of

From this perspective,

performance. Then, we describe the experimental

proponents of infinitesimal probabilities may claim

design, including the sample network, the set of test

four possible advantages over traditional numerical

cases,

belief networks:

probabilities, the epsilon values used in mapping, and

1. It may be easier to express beliefs by partitioning

and

our

variations

of

the

prior

fault

the number of findings observations per case.

The

number of sets of relative

infinitesimal scheme provides a set of the most

plausibility, that is values, than by assigning

plausible diagnoses for each case. In the results, we

events into a small

each event a precise numerical probabilities.

2. Results from reasoning with infinitesimal

compare these plausible sets with the posterior
probabilities for the diagnoses produced by the

probabilities are more robust and therefore more

numerical

trustworthy since they are based on less specific

implications of these results for the application of the

inputs.

K-calculus as a practical representation.

scheme.

Finally,

we

discuss

the

3. Reasoning with infinitesimal probabilities is
easier to understand and explain.
4. Inference methods with infinitesimal probabilities

can be computationally more efficient.

Initial analysis of the computational complexity of

[1992]

suggests that, in general, it is of the same order as
reasoning with numerical probabilities, that is NP­
hard

[Cooper,

1990].

There

may

be modest

computational savings from doing arithmetic with
small integers instead of floating point numbers.
Most

research

on

qualitative probabilities has

concentrated on developing the formalisms and
efficient algorithms.

AND INFINITESIMAL
PROBABILITIES

Hitherto, these claims have been largely untested.
reasoning infinitesimal probabilities Darwiche

2 MAPPINGS BETWEEN NUMERICAL

There has been little concerted

effort to demonstrate their application to real tasks and
to evaluate their practicality. Initial studies of QPNs
[Henrion and Druzdzel,

1990; Druzdzel and Henrion,
1993; Druzdzel, 1993] suggest that they are often

inconclusive for nontrivial cases. For example, QPNs
give vacuous results in any case with conflicting
evidence. Studies of qualitative simulation have found

In order to be a b le to apply

the

K -calculus to

probabilistic reasoning on a belief network with finite
probabilities, we need to provide a mapping from
probabilities into kappa values. In order to compare
the results we need to map the kappa results back
again into probabilities. Strictly, the K-calculus is only
valid as E---tO.

We use an approximation for finite

values of E. For a finite E, the K-calculus partitions the

real interval

[0,1] into regions identified by integers,

based on the smallest power of in the polynomial. This
mapping is illustrated in Figure 1.
More specifically, consider the real [0,1] interval I,
which is the interval used by probability theory, and a
discretized representation of I, which we call 5. 5 is a
set of non-negative integers which the -calculus uses to
represent probability measures in the interval I.

We

wish to explore the mappings f: I---tS (i.e., from
numerical to infinitesimal probability) and g: S ---t I

Nume rical and Qualitative Probabilistic Reasoning

(i.e., from infinitesimal to

numerical probability).

Note that there is information loss in the mapping f,
since it is not injective. Moreover, the mapping g is
not surjective.

Definition 1

321

[ K"-map] [Spohn 1988] The mapping f

from probability measures to

K"-values takes a

probability 1r and a threshold probability e and

outputs a K"-value K" e S such that

3 APPLICATION DOMAIN: WHY YOUR

CAR DOES NOT START
The task is to troubleshoot why a car is not starting,
given evidence on the status of the lights, battery, fuel,

fan belt, and so on. Figure 2 shows the Bayesian belief

network displaying the causal and conditional
independence relations.

We are grateful to David

Heckerman for providing the original belief network
and to Paul Dagum for lending us his expertise as a
Figure 1 shows an example of a mapping for £

=

0.1.

car mechanic in adjusting some of the probabilities.

All variables are binary (present or absent), except for
battery charge which has three values (high, low,
none). The initial network contains fully quantified,
numerical conditional probability distributions for

Kappa
1C(X)

each influence and prior probabilities for each fault
(source variable).

3

common

effect

Effects of multiple causes of a
are combined

with noisy-ORs,

generalized where necessary.
There are nine explicitly identified faults in this model:
spark plugs bad
distributor bad
fuel line bad
fuel pump bad
gas tank empty

0
0

0.001

0.01

Prd:lability p(X)

0.1

starter bad
battery bad

Figure 1: An example mapping giving kappa as a

fan belt loose

function of probability, for £=0.1.

alternator bad

Figure

2: Bayesian network representing the car diagnosis domain. Leak events represent all the

potential causes of a fault other than those shown explicitly. The number in each origin fault of a leak
node represents its prior probability in the original network. The numbers attached to each influence
arrow represent causal strengths -that is the probability that the successor is broken given that the
predecessor is broken, and all other predecessors are normal.

322

He nrion, Prova n Del Favero, and Sanders
,

We also identified three leaks. Each leak event
represents all possible causes of an event that are not
explicitly identified above. The probability of a leak is
the probability that its associated effect will be
observed even though none of its identified causes are
present.

from 10 to 1000. Table 1 shows the mean and range of

the resulting prior odds we used.

Table 1: The minimum, mean, and maximum prior
fault probabilities. The top line shows the original

engine start other

The

network with larger probabilities. To do this, we
multiplied the prior odds by an odds factor ranging

probabilities. Those below are derived by multiplying

engine tum over other

the odds of each prior by the odds factor and

charging system other

converting back to probabilities.

leaky noisy

or model assigns a probability to each

leak, to handle the fact that the network is inevitably
incomplete. In our adjusted network, the probability

Odds

of each leak was substantially smaller than the sum of

factor

the probabilities of the identified causes for each event.

Minimum

Mean

Maximum

1

0.00001

0.00036

0.00100

10

0.00010

0.00361

0.00991

50

0.00051

0.01750

0.04766

100

0.00103

0.03376

0.09099

300

0.00307

0.08900

0.23095

1000

0 010 17

0.21364

0.50025

There are 10 observable findings in the model_ listed
here in non-decreasing order of expense to test:

1. engine-start
2. gas-gauge
3. engine-tum-over

4. lights
5. radio
6. fan-belt
7. battery-age
8. distributor

.

9. spark-plugs
10. alternator

Note that there are four findings that are also
enumerated faults, namely fan belt, alternator, spark

4.2 Test Cases and quantity of evidence

plugs, and distributor.

We expected that the performance of both numerical

4 EXPERIMENTAL DESIGN

function of the quantity of evidence. We also wished

We wish to investigate the effects of three factors on

relative

the diagnos tic
probabilities:

performance

and infinitesimal schemes would improve as a

of

inf initesimal

to examine the effect of the quantity of evidence on the
performance

of

the

two

schemes.

Accordingly, we needed a representative set of test
cases with varying numbers of findings.

(a) The choice of the value of E on the mapping
between numerical and infinitesimal probabilities.

(b) The range of prior fault probabilities
(c) The quantity of evidence in the test cases.
We have already discussed factor (a). Here, we will
discuss our choice of each of these factors, and the
conduct of the experiment.

We generated a set of 116 test cases, in the following
manner: For each of twelve faults (nine identified
faults plus three leaks), we identified the most likely
(modal) value for each of the ten observable findings.
For each fault, we created a base

case

consisting of all

findings at their modal value. In four cases, the fault is
itself a finding, which we omitted from the base test

case, since including the true fault as observed in the
test case would be trivial. We then generated a second
case for each fault by omitting the most expensive
observation from the base case.

Further cases were

4.1 Range of prior fault probabilities

generated by omitting the next most expensive

The numbers in Figure

finding that the engine does not start. In this way, we
created a series of ten cases for eight faults, and nine

2 are the original prior fault

probabilities. To examine the effect of the magnitude
of the priors on the relative performance of the
infinitesimal calculus, we created versions of the

observation in tum.

In all cases, we retained the

Numerical and Qualitative Probabilistic Reasoning

cases for the four faults that are observable, resulting
in a total of 116 test cases in all.

4.3

323

faults are clearly identifiable, having probabilities at

least an order of magnitude greater than those of all
other faults. We found that this approach, as expected,

gave very similar results to the exact IC-calculus

Computation

inference using CNETS .

To obtain results for the numerical probabilistic

scheme, we employed IDEAL [Srinivas and Breese,

1990], using the clustering algorithm from the I DEAL
library. We applied each of the 116 test cases to the
network using each of the six sets of priors,
performing a total of 696 run. For each run we
computed the posterior probability for each of the
twelve faults resulting in 8352 probabilities.

5 RESULTS
Our first goal was to examine the effect of E values on
the performance of the infinitesimal probability
scheme. We then selected the value of E that gave the
best results and examined the effect of varying the

quantity of evidence on the performance of both

numerical and infinitesimal schemes.

We also converted the original numerical probabilities
into K-values, using the three values e (0.1, 0.01, 0.001),
resulting in a total of 2088 additional runs. We ran

5.1

calculus developed at

we might expect it to perform better for small£, where

each case using CNETS, a full implementation of the K­
the

Rockwell

Palo Alto

Laboratory [Darwiche, 1994], producing posterior K­
values for each fault. For each run, we computed the

plausible set, that is the subset of faults with the
minimal K value.
Definition

[Plausible Set]

2

Consider a set

V:;;{v1,v2, ,vm}representing m possible hypotheses,
•••

Let

vmin

](­

=minvj by the minimum ](-value.
J

probability interval

(0,

1], as shown in Figure 1, and

larger e. To investigate this we analyzed an initial set
of 72 test cases usin g E values of 0.0001, 0.001, 0.01, 0.1,

0.2. Figure 3 shows a graph of average probability
against e. It is interested to note that the average score

identical fore= 0.1 and e

To compare the infinitesimal scheme with the
numerical one, we converted K-values of diagnoses
back to probabilities as follows:
De fi n it ion 3:

original probabilities, with less information lost.

Accordingly, we might expect it to do better with

is identical for E = 0.01 and E

Cll(V)={j:vj =vminl·

[Pro b a bility

setV={v1,v2, ... ,vm}r e presenting
assigned a

the approximation will be mere exact. On the other

hand, a larger E provides rnore partitions to the

score assigned to the true diagnosis for these cases,

The plausible set is given by

hypotheses,

Since the kappa calculus is only strictly correct as E---+0,

consequently, it provides a finer discretization of the

in which each hypothesis has been assigned a
value.

Effect of E values

score]

m

For

=

= 0.001, and also

0.2. Overall, there is an

improvement in performance with increasing E up to

0.2. Accordingly, we selected E

=

0.1 for use in our

remaining experiments.

a

p o s s i b 1 e

in which each hypothes is has been

](-value, the corresponding probability

distribution is given by

ifvj=vmax

(3)

0.3
.,
"'
"' 0.25
..
-<
0.2
I>
., .....
s:: ..
0.15
.. ....
a: "'
.. "
0.1
r;,. ...
.,
"
..
!..
0

��

otherwise

That is, the probability ni= 1/n is assigned to the true
faults if it is in the plausible set of size n. Otherwise,
we assigned p = 0.

�

"

�"'

0.05

0.0001

0.001

0.01

0.1

As an additional test, we also ran IDEAL using the

exact algorithm, but using fault probabilities mapped
to O.OlK for the values obtained from the mapping
using the full set of K values.

subset of 72 test cases.

We applied this to a

In the results, the plausible

Figure 3: Effect of E o n the score (probability

assigned to the true fault) by the infinitesimal scheme

Henrion, Provan, Del Favero, and Sanders

324

5.2 Effect of Number of Findin gs on the

Plausible set

...., 0.5
';
1:1
...

As the quantity of evidence increases, we should
expect the performance of both numerical and
infinitesimal schemes to improve.

Accordingly, we

classified the cases by the number of findings. Figure 4
graphs the average size of the plausible set (number of

Gl
:I
I.
...,
..
Cl
.=

e

Cl,.

0.25

plausible faults) identified by the infinitesimal scheme
as a function of the number of findings. These results
summarize all116 cases fore

=

01
. . As expected, the

average size of the plausible set of faults decreases
with the number of findings, from 7 faults with 1
finding to1. 21 faults for 10 findings. With10 findings,

o �----2
0
6
8
4
10
Number of findings

this scheme provides almost complete specificity that
is, the plausible set usually consists of just a single
diagnosis.
..
.,
Ill

Figure 5: The probability assigned to the true
fault for each scheme as a function of number of
findings

10

.,
...
.Ill
. ..
Ill
:I
"
...
liloo

What is, perhaps, surpnsmg is how closely the
performance of the infinitesimal scheme tracks the
performance of the numerical scheme.

..
0
.,
N

. ..
"'

Indeed the

infinitesimal scheme appears to perform better than
the numerical scheme for intermediate numbers of

5

findings, but this difference is not significant.

Since

the infinitesimal representation is derived from the
numerical one, we could not expect it to do better, on
average.
Note that, even with all ten findings, both schemes

o+-----�----�---r---,--�
0

2

6

Number of fi nd i ngs

8

10

average about 0.5 probability for the true diagnosis.
This relatively poor performance arises because of the
limited scope of the network, which does not provide
the means to differentiate among several classes of

Figure 4: The average size of the plausible set

as a function of the number of findings in each
case.
5.3

Comparing the performance of
infinitesimal and numerical schemes

Next, we compare how the number of findings affects
the diagnostic performance for the infinitesimal and
numerical schemes. Figure 5 graphs the performance
in terms of the average probability each assigns to the
true fault, as a function of the number of findings. For
both schemes, as expected, the average probability
assigned to the true fault increases with increasing
evidence, from about 0.15 with 1 finding, to about 0. 47
with 10 findings.

fault.

5.3 The magnitude of priors and the
performance of infinitesimal

probabilities
The infinitesimal probability scheme appears to
perform very well relative to numerical probabilities
for the original car network, in which the prior fault
probabilities are very small, on average 0.00036

To

examine if it performs equally well for larger priors,
we multiplied the prior odds by five odds factors, as
shown in Table

1.

Figure 6 shows the average

probability assigned to the true diagnosis as a function
of the average priors.

Interestingly, the two schemes

are almost indistinguishable up to an average fault
prior 0. 033. Above that, the performance of the
infinitesimal probability drops off sharply - that is,
for average priors of 0.089 and 0.214.

These results

Numerical and Qualitative Probabilistic Reasoning

confirm our ex pect ation that infinitesimal works well
for small priors, but not so well for large pr i ors.
..
-

=
Cl

...
..
....
c

0.4

ordering of diagnosis. A third, would be to evaluate

even more, the quality of decisions will be less rather
than more sensitive to these differences in
representation.

0.3

While these findings are encouraging for the practical
usefulness of infinitesimal pr oba b il ities, we should

.CI
c
...

a.

them. Another way would be to compare the rank
the quality of decisions based on the diagnosi s. In
general, scoring rules based on ranks of diagnosis or,

....

�
=

325

remember that these initial results are on a single
domain. This car model dom ain is simple, with few

0.2

loops and short chains.

This kind of experiment

should be conducted on a wide range of types of
network to see how far these initial results will hold

0.1-

up.
In the introduction, we distinguished view
infinitesimal

o+-----�----�--+-��o.oo1
0 .01
1
o.oo01
0.1
Aver age prior fault probability
Figure 6: Comparison of the average performance of
infinitesimal and numerical probability schemes as a
function of prior fault probabilities.

probabilities,

as

an

(a)

approach

of
to

nonmonotonic reasoning, from view (b), as an
approximation to numerical probabilities.

We

reiterate that this paper, we focus on (b), and we are
not attempting to evaluate its use as an approach to
nonmonotonic logic.

Conclusions about the former

have limited relevance to the latter.
Infinitesimal pro babi lit ies are quite appealing as an
alternative to numerical probab il ities. They should be

6 CONCLUSIONS

significantly easier to eli ci t from experts. Inference

We find these initial results very encouraging in terms

of the diagnostic performance of the infinitesimal
probability scheme. For this example domain, we

found the best performance occurs using E 0.1 to 0.2.
Performance for E
0.01 was slightly worse.
=

may be more effjcient. And resulting inferences should
be somewhat more robust to changes in probabilities.
Some questions that need further investigation
include:

=

Performance of the infinitesimal scheme relative to the
numerical

scheme

does

not

appear

to

Does the best choice of E vary with the domain?

vary

significantly with the quantity of evi dence. The
performance using infinitesimal probability is not

Does these results hold for larger networks, with
more complex structures?

noticeably worse than the numerical probabilities for
prior fault probabilities up to about 0.03. For larger
average fault probabilities, the relative perform ance of

Can this infinitesimal approximation be extended
to utilities and decision making?

infinitesimal probabilities starts to drop off sharply.

This findings suggests that infinitesimal probabilities

Can we obtain a clearer analytic characterization

are more likely to be reliable for diagnosis tasks with

of when performance

very small prior fault probabilities, such as most
machine and electronic devices. They may also work
for some med ical domains, as long as the
priors are less than

disease

1%.

we have used is very simple.

In

addition,

engineering

The mapping from K-values back to probabilities that
More sophistic ated

mappings are pos sible, making use of higher values.

We should also point out that the scoring methods that
we have used to evaluate performan ce have been
based on posterior probability of the true diagnosis,
which is perhaps the most exacting way to compare

will be or won't be

reliable?
we

methods

need practical knowledge
for

eliciting

infinitesimal

probabilities. We an ticipate that, in the long run, the

best p r actical tools will
quantitative methods.

combine qualitative and

326

Henrion, Provan, Del Favero, and Sanders

Intelligence Conference,
Acknowledgments

M. Goldszmidt and J. Pearl.
causal relations.

This work was supported by the National Science
Institute for Decision Systems Research. We would
like to thank David Beckerman for use of the car

pages 99-110, Vermont, 1992.
entropy approach to nonmonotonic reasoning.

refining some of the probabilities.

M.

Shac�ter,

The Logic of Conditionals.

G.F. Cooper. The Computational Complexity of
Probabilistic Inference Using Belief Networks.

Artificial Intelligence, 42:393-405, 1990.
Darwiche. A symbolic generalization of probability
theory. Ph.D. dissertation, Computer Science Dept.,
Stanford University, Palo Alto, CA, 1992.
M.

&

Goldzmidt.

CNETS:

A

computational environment for generalized causal
networks. 1994, {this volume).

M. Druzdzel and M. Henrion. Efficient reasoning in

Proceedings of
the American Association for Artificial Intelligence
Conference, pages 548-553, Washington D.C., 1993.
J. Druzdzel. Probabilistic Reasoning in Decision
Support Systems: From Computation to Common
Sense. PhD thesis, Department of Engineering and
qualitative probabilistic networks. In

M.

Public

Policy,

Carnegie

Mellon

University,

Pittsburgh, Pa, 1993.

H. Prade. Possibility Theory: an Approach
to Computerized Processing of Uncertainty. Plenum

D. Dubois and

Press, NY, 1988.

Utility Theories: Measurements and
Applications. Kluwer Academic, 1992.
H. A. Geffner. Default Reasoning: Causal and Conditional

W. Edwards.

Theories.
M.

MIT Press,

Henrion.

and

Cambridge, MA, 1992.
M.

Druzdzel

"Qualitative

propagation and scenario-based explanation of
probabilistic reasoning". In M. Henrion and R.
S h achter,

editors,

Intelligence.

6,

Uncertainty in Artificial

Elsevier

Science

B.V.

(North­

Holland), 1991.
M.

Hendon.

"Search-based methods to bound

diagnostic probabilities in very large belief nets".

M.

In Proceedings of Conf on Uncertainty and Artificial
Intelligence, 1991.
Ginsberg. Readings in Nonmonotonic Reasoning.
Morgan Kaufmann, San Mateo, CA, 1987.

M. Goldszmidt and J. Pearl. System Z+ :A formalism
for reasoning with variable strength defaults. In

Proceedings of American Association for Artificial

editors,

Uncertainty in Artificial

Intelhgence, pages 129-138. Elsevier Science B.V.

D. Reidel,

Dordrecht, Netherlands, 1975.

D arwiche

IEEE Transactions on Pattern Analysis and Machine
Intelligence, 15:3:220-232, 1993.
He nrion. An Introduction to Algorithms for
Inference in Belief Networks. In M. Henrion and R.



This paper proposes a novel, algorithm­
independent approach to optimizing belief
network inference. Rather than designing op­
timizations on an algorithm by algorithm ba­
sis, we argue that one should use an unop­
timized algorithm to generate a Q-DAG, a
compiled graphical representation of the be­
lief network, and then optimize the Q-DAG
and its evaluator instead. We present a set
of Q-DAG optimizations that supplant opti­
mizations designed for traditional inference
algorithms, including zero compression, net­
work pruning and caching. We show that
our Q-DAG optimizations require time linear
in the Q-DAG size, and significantly simplify
the process of designing algorithms for opti­
mizing belief network inference.
1

Introduction

Query DAGs (Q-DAGs) have been introduced recently
to allow the cost-effective implementation of belief
network inference on multiple software and hardware
platforms (1, 2]. According to the Q-DAG approach,
belief network inference is decomposed into two steps
as shown in Figure 1. The first step takes place off­
line and results in the generation of a Q-DAG that can
answer a number of pre-specified probabilistic queries.
The second step takes place on-line and involves the
evaluation of a Q-DAG to compute answers to proba­
bilistic queries in the context of some given evidence.
A Q-DAG evaluator is a very simple piece of software,
which allows one to implement it cost-effectively on
multiple software and hardware platforms.
Our initial discussion of Q-DAGs has focused on three
key points: (a) Q-DAGs can be generated using modi­
fied versions of standard belief network algorithms; (b)
the time and space complexity of Q-DAG generation

Olr-llne

t Q.J>AG�r J
I

On-line

Figure 1: The Query DAG framework.

is the same as the time complexity of the underlying
belief network algorithm; and (c) a Q-DAG evaluator
is a very simple piece of software [1, 2].
Our own experience, however, has revealed another
important property of Q-DAGs that was not origi­
nally intended but that seems to be as crucial as the
multiple-platform feature. In a nutshell, when us­
ing a belief network algorithm to generate a Q-DAG,
one need not worry about optimizing the algorithm
using techniques such as computation-caching, zero­
compression, and network-pruning [3, 4, 5]. Similar, if
not better, efficiency can be expected by simply using
an unoptimized version of the algorithm to generate a
Q-DAG and then optimizing inference at the Q-DAG
level. This involves reducing the Q-DAG before evalu­
ating it and implementing an optimized Q-DAG eval­
uator. The same Q-DAG evaluator can be used with
any generation algorithm and optimizations at the Q­
DAG level seem to be much simpler to understand and
implement since they deal with graphically represented
arithmetic expressions, without having to invoke prob-

Optimizing Belief Network Inference using Query DAGs

ability or belief network theory. Therefore, the merits
of this alternative approach are many, but most im­
portantly: the Q-DAG alternative is systematic, sim­
ple and accessible to a bigger class of algorithms and
developers.
The rest of this paper is structured as follows. First,
we will review Q-DAGs and their semantics in Sec­
tion 2. Next, we will present complete pseudocode for
an optimized Q-DAG evaluator in Section 3 and dis­
cuss its computational complexity. In Section 4, we
present techniques and pseudocode for reducing the
size of a Q-DAG and discuss its computational com­
plexity. Section 5 is then dedicated to how Q-DAG
reduction and evaluation account for many of the stan­
dard optimization techniques that one seeks to realize
in belief network algorithms. Moreover, we will argue
in this section that the Q-DAG approach is not just
an alternative, but a better alternative according to a
number of measures that we shall also discuss. We fi­
nally close in Section 6 with some concluding remarks.

Query DAGs

2

We will review Q-DAGs using an example. Consider
the belief network in Figure 2(a) and suppose we are
interested in queries of the form Pr(b I c ) . Figure 2(c)
depicts a Q-DAG for answering such queries, which
is essentially a parameterized arithmetic expression
where the value of parameters depend on the evidence
obtained. This Q-DAG will actually answer queries
of the form Pr(b, c), but we can use normalization to
compute Pr(b I c ) . This Q-DAG was generated us­
ing the join tree algorithm which builds a join tree as
shown in Figure 2(b). Details of this generation pro­
cess can be found in [1, 2].
A number of observations are in order this Q-DAG:
•

•

It has two leaf nodes labeled (B, ON) and
(B, OFF). These are called query nodes be­
cause their values represent answers to queries
Pr(&ON,e) and Pr(&OFF , e) where e is the
available evidence.
It has two root nodes labeled ( C, 0 N) and
(C, OFF). These are called Evidence-Specific
Nodes {ESNs) since their values depend on the
evidence collected about variable C on-line.

According to the semantics of Q-DAGs, the value of
evidence-specific node (V, v ) is l if variable V is ob­
served to have value v or is unknown, and 0 otherwise.
Once the values of ESNs are determined, we evaluate
the remaining nodes of a Q-DAG using numeric multi­
plication and addition. The numbers that get assigned

117

to query nodes as a result of this evaluation are the an­
swers to queries represented by these nodes.
For example, suppose that the evidence we have is
C=ON. Then the value of ESN (C, ON) is set to 1
and the value of ESN (C, OFF) is set to 0. The Q­
DAG in Figure 2(c) is then evaluated as given in Fig­
ure 3(a), thus leading to Pr(&ON, C=ON) = .3475
and Pr(&OFF, C=ON) = . 2725,. If the evidence
we have is C=OFF, however, then (C, ON) is set
to 0 and (C, OFF) is set to 1. The Q-DAG in
Figure 2(c) will then be evaluated as given in Fig­
ure 3(b), thus leading to Pr(&ON, C=OFF) = . 2875
and Pr(&OFF, O=OFF) = . 0925.
If we have no evidence about variable C (the value of
C is unknown), both evidence-specific nodes (C, ON)
and (C, OFF) will then be set to 1 and the remaining
nodes will be evaluated accordingly.
Formally, a probabilistic Q-DAG is a directed acyclic
graph. Each root node in a Q-DAG is either a nu­
meric node, Num, which is labeled with a number p
in [0, 1], or an evidence-specific node, Esn, which is la­
beled with a pair (V, v ) where V is a variable and v is
a value of the variable. Each non-root node is either
a multiplication n ode , @,which is labeled with a *• or
an addition node, EB, which is labeled with a+.
In the rest of this paper, we assume the following func­
tions for manipulating Q-DAGs: Children(n): the chil­
dren of node n; Parents ( n) : the parents of node n;
Type( n) : the type of node n, which is either 0, EB, Esn
or Num; Label(n): the probability associated with a
numeric node n; Value(n): the value of a Q-DAG node
n. Given Values for evidence-specific nodes, the Value
of nodes can be determined as follows. The Value of
a numeric nodes is its Label; the Value of an addi­
tion node is the addition of its parents' Values; the
Value of a multiplication node is the multiplication of
its parents' Values.
We will also use N to represent the number of nodes
in a Q-DAG and £ to represent the number of edges.
3

A Q-DAG Evaluator

We now discuss an optimized Q-DAG evaluator that
initializes the probabilities (values) of Q-DAG nodes
and updates them as evidence changes. Evidence in
this case is the setting of an evidence-specific node to
either 0 or 1 according to Q-DAG semantics described
in [1, 2) and reviewed in Section 2.
There are two high level procedures for implementing
the evaluator, the goal of which is to keep the function
Value updated. This function assigns a probability
Value(n) to each node n so that if n is a query node

118

Darwiche and Provan

a)

b)

Pr(A�N)=.3

sf.:\

f.:\s2

n

c)

]�

A

__:..:A-+C=:
:;;=O�N
.9
ON

OFF

-�

_A-+_B=O-'-N
ON

.25

OFF

.8

C--QN

ON

.9

OFF

.5

C=OFF
.I
.5

A

SoON

B•OFF

ON

.25 • .3

.75 '.3

OFF

.8 • .7

.

2 •.7

(C.ON)

(C.OFF)

Figure 2: (a) A belief network; (b) a corresponding join tree; and (c) a Q-DAG generated using the join tree.

(b)C=OFF

(a) C=ON

Figure 3: Q-DAG evaluation.
labeled with (V,v), and if Value(n) = p, then we must
have Pr(v,e) = p. The two procedures are:
1.

initialize-qdag (Figure 4): computes probabil­

ities of nodes under the assumption that no evi­
dence is collected (all evidence-specific nodes are
set to 1).

2. set-evidence (Figure 5): sets the value of an
evidence-specific node n to v and updates the
function Value accordingly.

value is 1.1 And if n is a numeric node, then its initial
value is simply the label associated with it. The ini­
tialization algorithm takes 0(£) time and it computes
the prior probability of each query node. 2
Procedure set-evidence works by incrementally up­
dating the probabilistic values of nodes. Specifically,
suppose that the value of node n changes from Vt to
v2 and consider a child m of n:
•

If m is an addition node, then its value will change
by the amount v2 v1, which is also the change
that node n has undergone. Therefore, we can
update the value of node m by simply adding v2 v1 to its previous value. We must also update the
children of m recursively.
-

One would use these procedures by first calling
initialize-qdag to initialize the Q-DAG. As ev­
idence becomes available, corresponding calls to
set-evidence are made.
Procedure initialize-qdag starts by initializing the
probability of each query node. To initialize the prob­
ability of a node n, one first initializes the probabili­
ties of its parents recursively and then combines these
probabilities depending on the type of node n. The
boundary conditions occur when n is a root node (Esn
or Num). If n is an evidence-specific node, its initial

•

If m is a multiplication node, and if v1 f. 0, we can

1 When no evidence is available, all evidence-specific
nodes have the value 1.

2Note that initialization can be done off-line since it
does not depend on any evidence. Therefore, it should
not, in principle, be part of the Q-DAG evaluator but part
of the Q-DAG compiler.

119

Optimizing Belief Network Inference using Query DAGs

initialize-qdag()
for every query node n do initialize-prob(n)
initialize-prob(n)
unless Value( n) is initialized do
for every node m in Pare nt s ( n) do
initialize-prob(m)
case Type(n)

set-evidence( n, NewValue)

OldValue := Value(n)
Value(n) :=NewValue
propagate-change (n, OldValue, NewValue)

propagate-change(n, Old Value, New Value)
unless 0/dValue =New Value do
for each node m in Children(n) do

Num : Value(n) := Label(n)
Esn : Value( n) := 1
0: Value(n) := value-of-mul-node(n)
EB: Va/ue(n) := value-of-add-node(n)

0/dChildValue := Value(m)

if Type(m)
EB
then Value(m) :=
=

Value(m)- Old Value+ New Value

else if Old Value
0
then Value(m) : =
value-of-mul-node(m)
else Value(m) :=
=

value-of-mul-node(n)
Value:= 1
for all m in Paren ts( n) do

Value := Value* Value(m)
Value

Value(m)/ OldValue* NewValue
Old ChildValue, Value( m))

return

propagate-change ( m,

value-of-addition-node(n)

Value:= 0

Figure 5: An optimized Q-DAG evaluator.

Parents(n) do
Value := Value+ Value( m)
return Value

for all m in

Figure 4: Initializing a Q-DAG.
•l

update the value of node m by simply multiplying
v2jv1 by its previous value. If Vt :::: 0, however,
we cannot incrementally update the value of m .
Instead, we have to recompute its value by mul­
tiplying the values of its parent nodes, which is
what function value-of-mul-node does.
Procedure set-evidence takes 0(£) time in the worst
case, but its average performance is better than linear
since it will only visit those nodes that change their
values.

4

Simplifying the Q-DAG

One may reduce a Q-DAG by eliminating some of its
nodes and arcs while maintaining its ability to answer
probabilistic queries correctly. The motivation behind
this simplification or reduction is twofold: faster eval­
uation of Q-DAGs and less space to store them. Inter­
estingly enough, we have observed that a few, simple
reduction techniques tend in certain cases to subsume
optimization techniques that have been influential in
practical implementations of belief network systems.
Therefore, reducing Q-DAGs can be very important
practically.
This section is structured as follows. First, we start
by discussing three simple reduction techniques in the
form of rew rite rules. Next, we provide pseudocode
that implements these reductions and discuss their
computational complexity. Finally, the implications
of these reductions on optimizing belief network infer-

<)

x�-x� x�-x�
x-\>'/ x�-\<
Ql

0

pi

Ql

pl

Fig ure

Ql

0

pi

Q2

pl

h)

d)

I

Ql

Ql

I

0

Ql

Q2

0

.

Ql

�

Ql

Q2

·.

Q2

6: Q-DAG reduction techniques.

ence are discussed at length in Section 5.
The goal of Q-DAG reduction is to reduce the size of
a Q-DAG while maintaining the arithmetic expression
it represents .
Definition 1

Two Q-DAGs are equivalent iff they
have the same set of evidence-specific nodes, the same
set of query nodes, and they agree on the values of
query nodes for all possible values of evidence-specific
nodes.

Figure 6 shows three basic reduction operations on
Q-DAGs. Identity-elimination eliminates a numeric
node if it is an identity element of its child (Fig­
ures 6(a) and 6(b)). Numeric-reduction replaces a
multiplication or addition node with a numeric node if
all its parents are numeric nodes (Figure 6(c)). Zero­
compression replaces a multiplication node by a nu­
meric node if one of its parents is a numeric node with
value zero (Figure 6(d)).
Identity elimination is implemented by the straight­
forward procedures eliminate-identity-zero and
eliminate-identity-one in Figure 7, each of which
takes O(N) time.

120

Darwiche and Provan

eliminate-identity-·zero 0

n do
Type(n) = Num

zero-compression()

for each node
if

for each node
and

then for every node

Label(n) = 0
m in Chi/dren(n)

Type(m) = I'll
then Parents(m)

if

:=

n

do

Value(n) = 0
then Type(n) := Num
Label(n) := 0
Parents(n) := 0

if
do

Parents(m) \ {n}

eliminate-identity-one()
for each node
if

Type(n)

=

n do
Num

and

then for every node

Label(n) = 1
m in Children(n)

Figure 9: Pseudocode for zero compression.
do

Type(m) = 0
then Parents(m) := Parents(m) \ {n}

if

Figure 7: Pseudocode for identity elimination.
numeric-reduction()

initialize queue q

for every node

n

Type(n)
Num : add n to queue q
0: InDegree(n) := I Parents(n) I
I'll: JnDegree(n) := I Parents(n) I

while queue q is not empty do

n

5

Optimization using Q-DAGs

do

case

get

compression as depicted in Figure 6(d) because ev­
ery multiplication node that has a zero parent will
also have the value zero, and, therefore, will be con­
verted to a numeric node. The time complexity of
zero-compression is O(N).

from queue q

m in Children(n) do
InDegree(m) :• InDegree(m) if In Degree(m) = 0
then Type(m) := Num
Labe/(m) := Value(m)
Parents(m) := 0
add m to queue q

for each

Figure 8: Pseudocode for numeric reduction.
Numeric reduction is implemented by procedure
in Figure 8, which maintains a
queue of numeric nodes in the Q-DAG and a counter
for each addition/multiplication node to count its par­
ents. For each (numeric) node on the queue, the pro­
cedure processes the node by decrementing the coun­
ters of its children. If any of these counters reaches
zero, that means all parents of the corresponding
nodes are numeric and, therefore, it can be reduced
into a numeric node. W hen the reduction is per­
formed, the node is added to the queue, which al­
lows the possible reduction of its children. Procedure
numeric-reduction takes 0(&) time.
numeric-reduction

Zero-compression is implemented by the procedure
in Figure 9. Note here that if
any Q-DAG node attains the value zero after call­
ing procedure initialize-qdag, it will maintain
this value under any further evidence.3 Procedure
zero-compression is complete with respect to zerozero-compression

3 Accommodating evidence entails changing the values
of some evidence-specific nodes from 1 to 0. This cannot
increase the value of any Q-DAG node.

The main proposal in this paper is as follows: Instead
of implementing an optimized algorithm for belief net­
work inference, use an unoptimized version ofthe algo­
rithm to generate a Q-DAG, reduce the Q-DAG using
the procedures in Figures 7-9, and evaluate it using
the procedures in Figure 5.
The benefits of the Q-DAG approach are: (1) the
Q-DAG evaluator can be easily and cost-effectively
implemented on various software and hardware plat­
forms; (2) Q-DAG reduction and evaluation are
algorithm-independent; (3) Q-DAG reduction sub­
sumes the technique of zero-compression, and some
forms of network pruning; (4) the Q-DAG evaluator
implements a sophisticated scheme for computation
caching, which is simpler and more refined than any of
the caching schemes that are typically implemented in
algorithms based on message passing; (5) the Q-DAG
evaluator handles the retraction of evidence with mini­
mal computations, while most caching mechanisms we
are aware of seem to have difficulties in handling this
kind of evidence efficiently.
The first two points above are self evident and will
not be discussed further. We focus in the rest of this
section on the last three points, explaining them in
detail and supporting them by examples.
5.1

Zero Compression

Zero compression is an optimization technique that
is typically implemented in algorithms based on join
trees [5]. Zero compression is designed to take advan­
tage of conditional probability tables which contain
zero entries, implying some logical or functional rela­
tionship between network variables. During initializa­
tion of a join tree, each zero conditional probability
is multiplied into some clique entry, which causes the
corresponding entry in the clique to be zero as well.

Optimizing Belief Network Inference using Query DAGs

s1�____f'7"1_

""'o"'�t-'c'?-:'"'-+N t""'c""•.=;:::._FF .:. . .,

A P(a)
ONI .6

r:;)sl

�

OFF

•)

.5

.)

I

A

P(B=ONia)

I
f(C=ONib)
ON
ON
OFF

BoOFF
.,

B

OFF

.9
.5

.8
.3

121

A 1 P(a)
ON .6

A

ON
OFF

I

P(B=ONia)
.9
.5

(b)

(a)

Figure 11: Pruning Node C.
,,

dl
P(A..ON.B-b)

Figure 10: Zero compression at the Q-DAG level.

After performing some message passing to propagate
evidence, some of these zeros will propagate through­
out the entire join tree. As more evidence is ob­
tained and propagated, computational resources are
expended adding and multiplying clique entries by ze­
ros. Zero compression, as presented in [5], addresses
this wasteful propagation by visiting entries in cliques
to identify and annihilate the zero entries. The annihi­
lation step should restructure the internals of cliques to
exclude zero entries from subsequent message passes.
The same optimization can also be implemented in the
context of other algorithms, but the details would dif­
fer.
W hat is common, however, among different algorithms
is that one can save computationally, sometimes signif­

icantly, by avoiding multiplications by zeros whenever
possible. As we demonstrate now, this zero compres­
sion optimization is subsumed by our Q-DAG zero­
compression technique that we discussed in Section 4.
Consider the Q-DAG in Figure 2. Suppose that
Pr(C = OFF I A = ON) :::::: 0 and Pr(B = ON I
A = OFF) = 0 instead. The resulting join tree will
then be as given in Figure lO(a) where each clique has
a zero entry. The technique of zero compression aims
at factoring out these entries so they do not enter into
further computations when propagating messages.
Alternatively, one could use a join tree algorithm that
does not incorporate zero compression to generate the
Q-DAG shown in Figure lO(b). One would then ini­
tialize the Q-DAG to discover that some nodes will
attain the value zero. Procedure zero-compression
can then be applied to generate the Q-DAG in Fig­
ure lO(c), which could further be reduced using Pro­
cedure eliminate-identity-zero leading to the Q­
DAG in Figure lO(d). Therefore, one need not worry
about implementing zero compression in the chosen

(a) Original Q-DA.G

(b) Roducod Q-DAG

Figure 12: Reducing a Q-DAG.
belief network algorithm; one can rely on Q-DAG re­
duction to achieve the same result as illustrated above.
5.2

Network Pruning

Pruning is the process of deleting irrelevant parts of a
belief network before invoking inference. Consider the
network in Figure ll(a) for an example, where B is an
evidence variable and A is a query variable. One can
prune node C from the network, leading to the network
in Figure ll(b). Any query of the form Pr(a I b) will
have the same value with respect to either network, but
working with the smaller network is clearly preferred.
Now, if we generate a Q-DAG for the network in Fig­
ure ll(a) using the polytree algorithm, we obtain the
one in Figure 12(a). On the other hand, if we generate
a Q-DAG for the network in Figure ll(b), we obtain
the one in Figure 12(b), which is smaller as expected.
The key observation, however, is that the optimized
Q-DAG in Figure 12(b) can be obtained from the un­
optimized one in Figure 12(a) using Q-DAG reduction.
In particular, the nodes enclosed in dotted lines can be
collapsed using numeric-reduction into a single node
with value 1. Identity-elimination can then remove
the resulting node, leading to the optimized Q-DAG
in Figure 12(b).

122

Darwiche and Provan

A \ Pr(A)

ON

A Pr(B=ONIA)
I
rC=ONIB)

ON
OFF

o)

.6

B
ON
OFF

A
ON

.9
.5

.8
.3

I

B
ON
OFF

b)

Pr(B)
.74

fr(C=ONIB)

'
'
'
'
'
'

.8
.3

.
.
.

Global Retraction

P("C..ON.B:.b)

1\

1\.
(B.ON}

1\'

(B.OFF)

.H

singly-connected after pruning, thereby, reducing the
complexity of inference. But using Q-DAG reduction,
we still have to generate a Q-DAG using the multiply­
connected network.
5.3

(a) DP1iQd Q-DAO

P(V I e)

Figure 15: Block diagram of the join tree algorithm.

1\

1\

-�-

:Global

; Update

Figure 13: Pruning Node A.
P(C..ON,s..tl)

'
.
.
.

Dynamic Evidence

(b-) RcdliCIId Q.DAG

Figure 14: Reducing a Q-DAG.
To consider another example, suppose that we are in­
terested in computing Pr(C = ON I b) in the net­
work of Figure 13(a). One can prune node A from
the network, leading to the network in Figure 13(b)
where the priors of node B are computed as follows:
Pr(b) = 2:a Pr(b I a)Pr(a). Any query of the form
Pr(c I b) will have the same value with respect to ei­
ther network, but working with the smaller network is
clearly referred.
If we generate a Q-DAG for the network in Fig­
ure 13(a) using the polytree algorithm, we obtain the
one in Figure 14(a). If we generate a Q-DAG for the
network in Figure 13(b), we obtain the one m Fig­
ure 14(b). Note, however, that the Q-DAG m Fig­
ure 14(b) can be obtained from the Q-DAG m Fig­
ure 14(a) using numeric-reduction.
Therefore, some forms of network pruning are a by­
product of Q-DAG reduction and, hence, one can de­
cide to ignore them at the algorithmic level and expect
that their effect will be realized if Q-DAG reduction
is utilized. There are two caveats, however. First, it
is not clear whether all forms of network pruning will
be subsumed by Q-DAG reduction. Second, Q-DAG
reduction will not reduce the computational complex­
ity of inference, although network pruning may. For
example, a multiply-connected network may become

The proper handling of dynamic evidence is an es­
sential property of practical belief network inference.
Inference with dynamic evidence is typically imple­
mented with a computation caching scheme that at­
tempts to maximize the reuse of previous computa­
tions to conduct new ones. Unfortunately, computa­
tion caching is non-trivial, typically undocumented,
and its details vary from one algorithm to another.
The main objective of this section is to show that a Q­
DAG framework allows us to handle dynamic evidence
in a simple, uniform and sophisticated manner. Using
this framework, we can (a) ignore dynamic evidence at
the algorithmic level, (b) use the algorithm to generate
a Q-DAG, and (c) handle dynamic evidence at the Q­
DAG level. But before we substantiate these claims,
we review how dynamic evidence is typically handled
in the join tree algorithm [3, 4, 5].
Figure 15, which is borrowed from [3], depicts the over­
all control of the join tree algorithm. There are two
important points to notice about this figure. First,
the introduction of evidence leads to invalidating cer­
tain computations, which leads to an inconsistent join
tree. The goal is then to recover this consistency (val­
idate probabilities) by doing the least amount of work
possible. Second, there is a distinction between evi­
dence update and evidence retraction, in that evidence
retraction requires more work to accommodate.
We apply evidence update to variable V if its current
value is unknown but evidence suggests a new value v
of V. We apply evidence retraction to variable V if it

123

Optimizing Belief Network Inference using Query DAGs

has a current value v1 but evidence retracts this value
or suggests a different value v2. In the join tree algo­
rithm, evidence update requires recomputing certain
messages which are passed between cliques. Moreover,
the messages to be recomputed are decided upon by
certain flags that indicate the validity of messages as
evidence is collected. Evidence retraction requires in
addition the te-initialization of certain clique poten­
tials. Details of these operations are beyond the scope
of this paper, but see [3] for a relatively comprehen­
sive discussion. The metric we use for determining how
well a system handles dynamic evidence is the amount
of work needed to update probabilities.

what one finds in other frameworks. Specifically, in ev­
idence update, the condition OldValue = 0 will never
be satisfied when calling the procedure set-evidence
and procedure value-of-mul-node will never be in­
voked. This follows since no node will increase its value
given that no evidence-specific node has increased its
value (in evidence update, the value of an evidence­
specific node will never change from 0 to 1). The pro­
cedure value-of-mul-node may only be invoked in
case of evidence retraction, which is the only extra
work needed to handle evidence retraction versus evi­
dence update.

First, we need to define evidence update and retraction
formally in the context of a Q-DAG framework:

6

Definition 2 Evidence update
occurs
when
each evidence-specific node either maintains its value
or changes its value from 1 to 0. Evidence retraction
occurs when some evidence-specific node changes its
value from 0 to 1.

Given the Q-DAG semantics of Section 2, evidence up­
date occurs if and only if each variable either maintains
its observed value or changes from unknown to ob­
served. On the other hand, evidence retraction occurs
if and only if some observed variable either becomes
unknown or changes its observed value to a different
one.
Dynamic evidence is handled in the Q-DAG frame­
work as follows. Both evidence update and retraction
are handled using the same procedure set-evidence
given in Figure 5. As far as simplicity is concerned,
the pseudocode in Figure 5 speaks for itself. As far
as uniformity is concerned, this code is independent of
the algorithm used to generate the Q-DAG; therefore,
it can be used with any Q-DAG generation algorithm.
As far as efficiency is concerned, we have three points
to make. First, set-evidence takes 0(£) time in the
worst case but does much better on average since it
only visits nodes that change their values. Second,
the caching scheme implied by set-evidence is more
refined than schemes based on message passing. Note
that each message pass involves a number of arithmetic
operations which correspond to some Q-DAG nodes. If
a message becomes invalid, all of these operations must
be re-applied although some of them may not lead to
new values. In a Q-DAG framework, only nodes that
change their values are re-evaluated, therefore leading
to a more refined caching scheme. This level of refine­
ment is missed in message passing algorithms since
caching is done at the message level, not at the arith­
metic operation level. Our final point is regarding the
minor difference between evidence update and retrac­
tion in the Q-DAG framework, which is contrary to

Conclusion

The message of this paper is simple: instead of opti­
mizing belief network algorithms, (a) use plain, unopti­
mized versions of the algorithms to generate a Q-DAG,
(b) reduce the Q-DAG according to the procedures
given in Figures 7-9; and (c) evaluate the Q-DAG us­
ing the procedures given in Figure 5. This proposed
alternative is cost-effective, uniform, relatively simple,
and optimized as compared to the standard approach.




that we developed, the dynamic network tool that we
designed and implemented to aid knowledge engineering

We present several techniques for knowledge
engineering of large belief networks (BNs) based

for

CPCS, and the Bayesian network algorithms that we

employed for this large, complex network.

on the our experiences with a network derived
from a large medical knowledge base. The noisy­
MAX, a generalization of the noisy-OR gate, is

used to model causal independence in a BN with

knowledge engineering or evaluation, challenging. The

multivalued variables. We describe the use of leak

development of CPCS necessitated the implementation of
algorithms that could make inference in BNs of this size

probabilities

to

enforce

the

closed-world

assumption in our model. We present Netview, a

more efficient. An example of this is a generalization of the

visualization tool based on causal independence
and the use of leak probabilities. The Netview

noisy-OR gate [Cooper 1986; Peng and Reggia 1987; Pearl

software

model causal independence. The

allows

knowledge

engineers

to

dynamically view subnetworks for knowledge
engineering, and it provides version control for
editing a BN. Netview generates sub-networks in
which leak probabilities are dynamically updated

1

The CPCS is one of the largest BNs in use at the current
time, and its sheer size makes most tasks, such as

1988] that is commonly used in binary valued networks to

CPCS BN contains nodes

that are multivalued, for example, disease nodes may have
four values (absent, mild, moderate, severe), consequently
we use a generalization of the noisy-OR gate called the

noisy-MAX. The specification of a complete conditional
m with sm values and n
predecessors requires the assessment of (sm -l)IJ�=I s;

to reflect the missing portions of the network.

probability matrix for a node

INTRODUCTION

probabilities, where

s;is

the

number

of

values

predecessor i (for a binary network this reduces to

of

2n ) In
.

Given the relative maturity of algorithm development in the

contrast, the causal independence assumption in the form of

Bayesian reasoning community, attention is now starting to
focus on applying these algorithms to real-world

a noisy-gate reduces this assessment task to

probabilities. thereby simplifying knowledge

applications.

and greatly reducing storage requirements.

The Quick Medical Reference-Decision

Ln(sm -l)s;

dcquisition

(QMR-DT) project seeks to develop practical
decision analytic methods for large knowledge-based

To aid in the editing and refinement of the

systems. The first stage of the project converted the

have developed a network visualization tool we named

Theoretic

Internist-1 knowledge base [Miller, Pople et al. 1982]

(QMR 's predecessor) into a binary, two-layered belief

CPCS BN, we

Netview. The Netview tool provides dynamic views of the

BN, and can generate subnetworks by taking advantage of

1991; Shwe,

the noisy-MAX and leak assumptions. For inference, the

Middleton et al. 199 1]. In the second stage of the QMR-DT

network, or subnetworks generated by Netview, are sent to
the IDEAL package [Srinivas and Breese 1989] for

network (BN) [Middleton, Shwe et al.

project we are creating a multilayer belief network with
mu1tiva1ued variables, and developing efficient inference
algorithms for the network. This paper will concentrate on
the knowledge engineering issues we faced when building a
large multilayered BN.
To create a large multilevel, multivalued BN we took
advantage of a rich knowledge base, the Computer-based

inference. Netview is a flexible tool which can be used in
any BN that uses noisy-gates, and is described in section

5.1.
Like the Internist- 1 -derived B N, the CPCS BN uses leak
probabilities [Henrion 1988] to represent the chance of an
event occurring when all of its modeled causes are absent.

We discuss our use of leak probabilities,

and the

Patient Case Simulation system (CPCS-PM), developed
over two years by R. Parker and R Miller [Parker and

modifications to the leak probabilities required by the

Miller 1987] in the mid-1980s as an experimental extension

dynamic network tool, in section 5.2.

of the Internist-! knowledge base.
This paper makes contributions both in knowledge
engineering and in algorithm development and
implementation for large BNs. We describe the CPCS BN

2

KNOWLEDGE BASE TO BELIEF NETWORK

The CPCS-PM system is a knowledge base and simulation
program designed to create patient scenarios in the medical

Knowledge Engineering for Large Belief Networks

sub-domain of hepatobiliary disease, and then evaluate
medical students as they managed the simulated patient's
problem. Unlike that of its predecessor lnternist-1, the
CPCS-PM knowledge base models the pathophysiology of
diseases th e intermediate states causally linked between
diseases and manifestations. The original CPCS-PM system
was developed in FranzLisp. Diseases and intermediate
pathophysiological states (IPSs) were represented as Lisp
frames [Minsky 1975].

485

5

and were mapped to probability values, as described in
next section. Frequency weights from the CPCS-PM
were mapped to probability values based on previous work
in probabilistic interpretations of Internist-1 frequencies.

the

-

To construct the BN we converted the CPCS-PM knowledge
base to CommonLisp and then parsed it to create nodes. We
r e pr esented diseases and IPSs as four levels of severity in
the CPCS BN-absent, mild, moderate, and severe.
Predisposing factors of a disease or IPS node were
represented as that node's predecessors, and findings and
symptoms of a disease or IPS node as the successors for that
node. In addition to the findings, CPCS contained causal
links between disease and IPS frames, we converted these
links into arcs in the BN. Frequency weigh t s [Shwe,
Middleton et al. 1991] from the CPCS-PM ranged from 0 to

We generated the CPCS BN automatically, we did manual
consistency checking using domain knowledge to edit the
network. Because the CPCS-PM knowledge base was not
designed with probabilistic interpretations in mind, we had
to make numerous minor corrections to remove artifactual
nodes, to make node values consistent and to confinn that
only mutually exclusive values were contained within a
node.
The resultant network has 448 nodes and 908 arcs (Figure
1). A t o tal of seventy four of the nodes in the network are
predisposing factors and required prior p robab ilities the
remaining nodes required leak probabilities assessed for
each of their values. We thus had to assess over 560
probabilities to specify the network fully.

Figure I. A small portion of the CPCS BN displayed in the Netview visualization program. The node ascending­
cholangitis in the third row shown in inverse has been selected by the user.

,

486

Pradhan, Provan, Middleton, and Henrion

While the CPCS-PM knowledge base is derived from the
Internist-! knowledge base it has been significantly

3

augmented by inclusion of the IPS states, and multivalued

2

representations of both diseases and manifestations of
disesase. The original

QMR-BN transformation of the

Internist-! knowledge base used only binary valued disease
and manifestation nodes. While conceptually simple, this

0

approach does not adequately reflect the potential variation
in presentation of disease manifestations, or the severity of

3

1

0

diseases.

Figure 2.

A node x with

predecessors D i• n,

NOISY-OR

ordered states

The noisy-OR is a simplified

BN representation that

respectively, or disease and manifestation variables
respectively [Peng and Reggia

1987].

variable

variables or predecessors

X

the

variables, and is typically described for a

which are interpreted as either cause and effect variables

that has

n

cause

•••

( 1)

P(X= 2! VI).

If there are multiple "manifestation" variables

j =1 ,.. .,l,

Consider an effect

D1, ,Dn· The noisy-OR can be used when

\tf having

probabilities required to calculate

probability matrix. The noisy-OR is defined over a set of
two level network partitioned into two sets of variables,

E

{0,1,2,3 }. The

shaded area represents the

requires far fewer parameters than the full conditional­
binary-valued

3

q

GENERALIZATION OF THE NOISY-OR

3.1

2

Aj,

P(Xi =xi I VI)=1- II(l-pii)

each D has

i:D;eV1

an activation probability p; being sufficient to produce the
effect in the absence of all other causes, and

(2)

the

probability of each cause being sufficient is independent of

1988].

the presence of other causes [Henrion

In this paper, we define variables using upper-case letters,

X is
ilx. If variable X is present it is denoted using the letter x;

letters.

The domain of possible values for variable

if it is absent, it is denoted using x .
The activation of a variable

X

by a predecessor variable D;

is independent of the value of D;.
assumption,

X is

conditional probability given by
other

Under the noisy-or

activated when D;

P;

is active,_with a

= P(x I d; {'·dk).
'

In

words, this activation probability deh otes the

probability when
inactive.

where Pij is the link probability on the arc from D; to

lJi is active and all other predecessors are

For a two-level noisy-OR network, we define a set V of
cause or disease variables, and a set W of effect or

manifestation variables. If there is a set VI of V of
predecessors of

X

e

W that are present, then since the D;

X will be false when all D; are false:

P(X=X I VI)= II P(D; =d;)
i:D;eV1

P(X =X I Vj)

=

BN

application, since we need to accommodate n-ary variables.

For example, CPCS BN disease and IPSs can take on values
such as absent, mild, moderate, and severe.
3.2

NOISY- MAX

Consider a generalization of the noisy-OR situation in
which each variable is allowed to have a finite discrete state
space (rather

than just a binary state s pace). This

generalization was first proposed by [Henrion

1988], but he

did not describe the algorithmic details. In developing this
generalization, we assume that we have a set

V of

predecessor variables D1, ... ,Dn. Consider first the case
where we have a variable

in VI are independent,

Xi

The simple noisy-OR is insufficient for the CPCS

and values that variables can take on using lower-case

for

then we obtain

X with a subset

present, with the predecessors indexed by

V1 of V that are

i,j, ,q.
...

The variable domains in CPCS BN are all partially ordered,

for example, {absent, mild, moderate, severe}, and it turns
out that such a partial ordering is necessary for all variable
domains. For the remainder of our work we assume that all
variables have ordered domains.
We now want to compute

II

(1- P;).
i:D;eV1

The value xis given by
In other words,

From this, it is simple to derive

domain values

P(X=xiVI)=l- II(l-p;).
i:D1eV1

x =

max(i,j, .
.

.

,q) [Henrion 1988].

X takes on as its value the maximum of the
of

its predecessors,

predecessors are all independent.

given

that

the

Knowledge Engineering for Large Belief Networks

487

V1)

This computation of P(X ==xI
can be viewed as setting
up a hypercube of dimensions i x j x · · x q and summing
·

the cells, each of which contains a probability value

fljk··q P;jk··q. As an example of the derivation of the general
formula, we consider the case of two predecessors D; and
{}_j. If these variables take on values i,j respectively, then
the

probability P(X =xI V1) ,

where

x = max(i, j) .

For

example, Figure 2 graphically depicts the conditional

probability matrix for D; and Dj, b oth of which have

ordered states {0, 1,2,3}. If x=2, then
consists of the shaded squares of the grid.

P(X=21D;.Dj)

Figure 3. Explicit representation

of the leak probability as a cause
of X.

In this multivalued noisy-MA X situation, the probabilities

that are being calculated in these hypercubes are cumulative

probabilities, that is,

P(X s; xI D s; d) .

For notational

convenience, we define the cumulative probability for a
variable

X that has a s ingle predecessor D with maximum
d as:

domain value

\f(x I d)= P(X s; xI D s; d) .
Under the generalized noisy-OR assumption, for a given
variable

X

with a set of

which each D;

q

D1, ... , Dq
d;, we know that

predecessors

has maximum value

for

4

LEAKS

As in any other knowledge representation scheme, the BN
representation suffers from incompleteness, in that it

typically cannot model every possible case. A leak variable

can be used to enforce the closed-world assumption [Reiter
1978]. The leak variable represents the set of causes that
are not modeled explicitly.

A leak probability is assigned as

the probability that the effect will occur in the absence of

of the cause s

D1 , ...,D n that are explicitly modeled. If
the leak variable is explicitly modeled, then it can be

any

treated like any other cause and can be depicted as such

=

IJ 'P(xld;),
i:D;eV1

In this representation, the leak node is always

assumed to be "on", that is
If

Note that using this transformation, we can define the

probability assigned to

3).

(Figure

i:D;E�

P(L=true) = 1.0.

the leak L with value l is factored into the calculation of

the unconditional probability for variable X, then we obtain

X taking on a particular value Xk :

P(X s; x) = P(L s; l)

TI [p;P(D; s; d;)+(1- P;)],

i:D,�V

Explicitly representing leak nodes in the

The unconditional probability assigned to a variable can be

derived in an analogous fashion. First, we nee d to derive

D;. assuming no
1994], this is given

the unconditional probability of variable
predecessors. As described in [Provan
by

P(X $. x) = P(L s; 1)

IJ[p;P(D; s; d;) +(1- P;)]P(x I V1).

i:D,eV1

P(XS:x) =

conditioning parents. The Netview knowledge engineering

tool, described in section 5, facilitates the maintenance and

editing of leak probabilities. Netview stores leak values

separately, as if they were explicit nodes, and then inserts

the leak values into the appropriate probability
exporting a network for inference in IDEAL.

5

The unconditional probability is given by

IJ[p;P(D; :S:d;)+(l-p;) ].

i:D;EV

The unconditional probability assigned to X taking on a
particular value x is:

CPCS BN would

almost double the size of the network, so leaks are
implicitly represented in the probability tables of a node's

5.1

tables when

TOOLS FOR KNOWLEDGE ENGINEERING
NETVIEW:

A TOOL FOR NETWORK

VISUALIZATION AND EDITING

Verification and refinement of the structure of the CPCS BN
is an important part of the QMR -Df project for two reasons.
First, because the

CPCS BN was generated from a pre­

existing knowledge base. Second, the effect of model
structure on network performance and accuracy is an
important aspect of the QMR -Df project.

During the knowledge engineering process, it became

V1)

Using this approach, the value P(xI
can be computed in
time proportional to the number of predecessors in V1. This
generalized noisy-MAX has been implemented in IDEAL.

obvious

that

available tools were not suitable for

visualizing and editing a network the size of
(Figure

1).

CPCS BN

In particular, most tools only permit a static

488

Pradhan, Provan, Middleton, and Henrion

view of the network, a limitation that made editing the

disease," and so on. A node may have any number of
semantic labels. Semantic labeling is a useful technique for

CPCS network very hard.

filtering nodes to focus attention during knowledge
by allowing knowledge engineers to focus on portions of

engineering. It is possible, say, to focus only on "gastric"
findings and diseases when dealing with the appropriate

the network. The program is implemented in Macintosh

domain expert. In the future we will also use the semantic

Netview was created to help knowledge engineering efforts

CommonLISP 2.01. The main features of Netview are
o

dynamic network layout

o

semantic labeling of nodes

o

version control

•

subnetwork generation and dynamic

o

labels in the dynamic layout algorithm to improve the
appearance of subnetwork views.
It is useful to keep track of modifications while editing the

BN. To facilitate this, Netview includes basic version

leak modification

control to store deleted and added arcs and nodes and

leak value editing

changes to probability tables. Arc and node additions and
removals between versions are displayed through the use of

Because of the causal independence assumptions implied
by the use of the noisy-MAX and noisy-0

different colors.

R gates,

knowledge engineers are can select smaller parts of the

5.2

CPCS BN for viewing. Netview allows the user to view all
ancestors, all predecessors, or all ancestors and
predecessors of selected nodes. For example, in Figure l
while the node

ascending-cholangitis is selected (inverse

color), we can use Netview's ability to show all successors
and predecessors of the selected node or nodes, resulting in
the subnetwork view shown in Figure 4 . Other options
include viewing nodes' Markov blanket, and immediate
successors or predecessors.
Netview uses a dynamic layout algorithm to display the
selected nodes. The knowledge engineer is able to move
rapidly between views by selecting nodes and choosing
viewing options, or by retrieving previously saved views.
Quickly viewing a node's predecessors allows rapid
assessment of leak probabilities.
In addition to subnetwork selection, Netview allows
semantic labeling of nodes, and filtering based on semantic
labels. For example, nodes in CPCS BN are labeled "lab
finding," "symptom," "sign," "disease," "IPS," "liver

5.2.1
The

SUBNETWORK GENERATION AND DYNAMIC
LEAK MODIFICATION

Subnetwork generation
Netview

program

is

used

only

for

network

visualization and editing; Netview saves files in IDEAL
format for inference. Because of the size of the CPCS BN it

is not always desirable to send the entire network to

IDEAL

for inference. If we are only interested in verifying a small
set of diseases we can generate a subnetwork including
only those diseases of interest and their associated findings,
IPSs and predisposing factors. When we run test cases

against a subnetwork we don't require the system to
compute the posterior probabilities of diseases that we are
not interested in.

5.2.2 Dynamic leak modification
Subnetworks we select from the full

CPCS

BN using

Netview can be exported to IDEAL for inference. It is

possible to select subsets of the larger CPCS

BN for

i n f e r e n ce

leaks .

due

to

the

presence

of

Figure 4. A subnetwork of the CPCS BN displayed in Netview. This view comprises all predecessors and
successors of the node ascending-cholangitis.

Knowledge Engineering for Large Belief Networks

Figure 6. Subnetwork creation. Node D3is removed from the network, the value of the leak node
updated to p based on the probability of D3•

489

/, p is
,

'

When a subnetwork is saved Netview updates the leak
probabilities to take into account the missing diseases. In
the CPCS BN the node hepatomegaly has parents shown in
figure 5, The leak probability for hepatomegaly is therefore
calculated based on this set of predecessors. In figure 4 a
subnetwork was selected based on the ancestors and
predecessors of the disease ascending-cholangitis. Conse­
quently, the only parent of hepatomegaly in the subnetwork
is ascending-cholangitis, its other parents are not included.
The transformation of leak probabilities required during
subnetwork creation is shown in Figure 6. The leak
probability must be updated from p to p'. This updating is
done in order to preserve the total probability mass. If the
value I of L is updated to a value l' for new leak L', we can
compute the updated leak node probability as

BN, and we are exploring how much the network
performance changes when the assumption is relaxed.
5.2.3 Information metrics

When subnetworks are created some information is lost as
parts of the network are excluded. A future area of research
is to use Netview to calculate the information Joss of a
subnetwork based on information metrics [Provan 1993],
and to compare differences in posterior probability between
the complete network and the subnetwork which has been
selected.

6

RELATED WORK

The generalization of the noisy-OR was first proposed in
[Henrion 1988], and the derivation and implementation
p' = P(L '5.lA D3 '5.d3)
described here follow that original proposal. Two related
= P(L '5.l)P(D3 '5.d3)
generalizations are described in [Srinivas 1993] and [Diez
1993]. The generalization of the noisy-OR by Srinivas is
=[p3P(D3 '5.d3)+(l- p3)]
different to this proposal, and is intended for a different
application. This generalization is for circuits (or other such
If we want to combine a set of Q nodes into a leak node,
devices) which can be either functional or non-functional.
where each node d1 in Q has link probability, then the new
In the case of medicine, findings can take on values such as
leak node probability is given by:
{absent, mild, moderate, severe}, in which case the binary
generalization of Srinivas is insufficient to deal with
p' =P(L'5.lAD1 '5.d1A···ADq '5.dq)
arbitrary n-ary variables. The noisy-MAX generalization in
D i ez 1993] is virtually identical to the one described here,
[
P(L '5./) fl P(Dt '5. d;)
and
we have derived our noisy-MAX independent of that in
i:D1eQ
[Diez 1993). Also, the proposal in [Diez 1993] is described
=P(L-5./) n[p;P(D;'5.d;)+(l-p;)].
within the context of learning models for OR-gates, and its
i:D1eQ
application to inference in Bayesian networks is not directly
apparent.
We prove in [Provan 1994] that if the network is
To our knowledge, there is no other tool which allows
hierarchical and there are no arcs between nodes at the
dynamic selection of subsets of Bayesian networks. There
same level of the hierarchy, then the leak updating is sound,
are several graphical tools for creating Bayesian networks,
that is, the probability assigned to X given the new set of
including IDEAL Edit, Ergo, Hugin [Andersen, Olesen et al.
predecessors is the same as the probability assigned to X
1989], and Demos [Morgan, Henrion et al. 1987]. But these
with the original predecessors. This proof holds if the
tools do not provide dynamic network layout and do not
subnetwork consists of a Markov blanket of a node, all
have features aimed at knowledge engineering large BNs.
predecessors and successors of a node, or all successors of
a node. The assumption for the proofs holds for the CPCS
7 CONCLUSION
=

��Figure 5. Parents of the node hepatomegaly.

In this paper we have presented several methods for
representing, and a software tool for managing, large BNs
based on our experience with the CPCS BN. The noisy-MAX
is a generalization of the noisy-OR gate for multivalued

490

Pradhan, Provan, Middleton, and Henrion

variables which reduces the complexity of the knowledge
acquisition task and storage requirements for a network.
Leak probabilities are used in the CPCS BN to model causes
other than those explicitly modeled in the network.

Middleton, B., Shwe, M. A., et al. (1991). Probabilistic
diagnosis using a reformulation of the Internist-1/QMR
knowledge base-11. Evaluation of diagnostic performance.
Methods of Information in Medicine, 30:256-67.

Based on the causal independence assumptions of the
noisy-MAX, and the use of leak probabilities we have
developed Netview, a tool for visualizing BNs based on the
dynamic layout of subnetworks, and which also provides
basic version control for editing networks. The creation of
subnetworks allows for more efficient knowledge
engineering, and for easier verification of the B N. We
describe a technique for updating leak probabilities based
on the excluded parents of a node in subnetworks.

Miller, R. A., Pople, H. E. J., et al. (1982). Internist-1: An
experimental computer-based diagnostic consultant for
general internal medicine. N Engl J Med, 307:468-476.

Recent advances in creating BNs from pre-existing data or
knowledge bases will result in networks that are larger and
more complex than those created manually. We believe that
the techniques described in this paper are important to
facilitate the management and verification of such
networks.
Acknowledgments

This work was supported by NSF Grant Project IRI9120330, and by computing resources provided by the
Stanford University CAMIS project, which is funded under
grant number LM05305 from the National Library of
Medicine of the National Institutes of Health.
The authors would like to thank K. C. Chang and R. Fung
for their graph layout algorithm on which NetView's layout
method is based, and R.Miller for access to the CPCS
knowledge base.



Within diagnostic reasoning there have been a numb�r
of proposed definitions of a diagnosis, and of an opti­
mal or most likely diagnosis. These include most prob­
able posterior hypothesis, most probable interpretation,
most probable covering hypothesis, etc. Most of these
approaches assume that the most likely diagnosis must
be computed, and that a definition of what should be
computed can be made a priori, independent of wh�t
.
the diagnosis is used for. We argue that the dtagnosttc
problem, as currently pos.ed! is incomplete: it does .�ot
consider how the diagnosiS IS to be used, or the utility
associated with the treatment of the abnormalities. In
this paper we analyse several well-known .d.efinitions �f
diagnosis, showing that the different defimt10�s of opti­
mal diagnosis have different qualitative meamngs, even
given the same input data. We argue that the most ap­
propriate definition of (optimal) diagnosis needs to �ake
into account the utility of outcomes and what the diag­
nosis is used for.
1

INTRODUCTION

Within diagnostic reasoning there have been a number
of proposals of what constitutes a diagnosis, an� so pre;
.
sumably, what constitutes an optimal or mo�t likely di­
agnosis. These include most probable posterior h�poth­
esis [Pearl 1986], most probable interpretation lPearl,
1987], most probable provable hypothesis [Reiter, 1987,
de Kleer and Williams, 1987, de Kleer et al., 1990],
most probable covering hypothesis [Reggia et al., 1985,
Peng and Reggia, 1987a, Peng and Reggia.' 1987b]. Un­
like earlier logic-based diagnoses that consider what can
be proven about a faulty device [Genes�reth, 1984� , th�e
papers have considered that the quest10� ��at i.s a di­
agnosis?" is important to answer. The mt�itlOn IS �h�t
it is important to characterise the set of "logical possibil­
ities" for a diagnosis, presumably to be able to compare
them. Most of these approaches assume that the most
likely diagnosis must be computed, and that a definition
of the what should be computed can be made a priori,
independently of what the diagnosis is used for.
*This author was supported by NSERC gra.nt
OGP0044121.
tThe author completed this research with the support of
NSERC grant A9281 to A.K. Mackworth.

Once the sets of hypotheses considered as diagnoses
are determined one of the ways we may want to compare
competing diagnoses to give us the most likely diagnosis
is by using probability [de Kleer and Williams, 1987,
Neufeld and Poole, 1987, de Kleer and Williams, 1989,
Pearl, 1987]. In computing the probability of A given B,
p(AIB), Bayesian analysis tells us that the B should be
all of the available evidence [Kyburg, 1988, Pearl, 1988],
but does not give us any hints as to what A should be.
This paper asks the question of what combination of
hypotheses A should be in order to be most usef�l.
In this paper we study six approaches to dia�nos­
tic reasoning, and their associated notions of opt�al­
ity based on probability theory (or another uncertamty
calculus). Each approach considers a conjunction ?f hy­
potheses as a most likely diagnosis. We call the slX ap­
proaches:
1. most likely single-fault hypothesis;
2. most likely posterior hypothesis;
3. most likely interpretation;
4. probability of provability;
5. covering explanations; and
6. utility-based explanation.
We contrast the first five approaches to diagnostic rea­
soning with a classic utility-based approach to diagnostic
reasoning [Ledley and Lusted, 1959].
.
In analysing these proposals, we show that the differ­
ent definitions of optimal diagnosis have different qual­
itative (and quantitative) results, even given �he sa�e
input data. Moreover, we argue that the diagnostic
problem, as currently posed, is incomplete: it does .�ot
consider how the diagnosis is to be used, or the utility
associated with either the diagnosis or the treatment of
the abnormalities. We argue that the most appropri­
ate definition of (optimal) diagnosis should be based on
what the diagnosis is used for. The point of this paper is
to question current approaches to formalising diagnos­
tic reasoning, and hopefully focus attention on crucial
questions not being studied.
The remainder of the paper is organised as follows.
Section 2 introduces the notation and discusses what
the diagnostic problem should entail. Section 3 formally
defines the six approaches to diagnosis studied in this
paper. Section 4 shows examples of how the diagnoses

47

produced by the different approaches are qualitatively
different. Section 5 discusses the proposals, evaluating
their strengths and weaknesses. Finally, Section 6 draws
a few conclusions.
2

Figure 1: A complete diagnostic cycle

I

WHAT IS THE DIAGNOSTIC

I

PROBLEM?
2.1

Notation

We call E the knowledge used to compute a diagnosis.
E can be broken down into a set F of facts which are
unchanging from instance to instance (e.g. F can be a
model of a circuit which is being diagnosed), and a set
0 of observations concerning a particular instance. We
call H = {h1, ..., hm} the set of hypotheses under con­
sideration given E. T = {t1, ..., tl} is the set of possible
treatments.
This diagnostic problem can be formalised in either
probabilistic or logical terminology. In terms of logi­
cal terminology, we use the Theorist framework of hy­
pothetical reasoning [Poole et al., 1987, Poole, 1987], a
formalism well suited to the task as the paradigms can
be naturally represented in the simple formal framework.
Theorist [Poole, 1987] is defined as follows. The user pro­
videsF, a set of closed formulae (called the facts) and
H, a set of open formulae (called the possible hypothe­
ses). A scenario is a set DUF where D is a conjunction
of hypotheses D = 1\i hi for some i = 1, ... , m, such that
D U F is consistent. An explanation of formula g is a
scenario that logically implies g. An extension is the
set of logical consequences of a maximal (with respect to
set inclusion) scenario.
For a given treatment r s;;; T, we define a utility
function u(E, D, r) . Using a standard decision-theoretic
approach (e.g. [Berger, 1985]), the goal of diagnostic
reasoning can be defined as choosing r to maximise
u(E, D, r ) . If there are probability distributions de­
fined over E and D, then the maximum expected utility,
&[ u(E, D, r)], is required. For example, if for diagno­
sis i, i = 1, ... ,k, the utility associated with treating
diagnosis Di is u(E, Di, r) = ai, and diagnosis Di oc­
curs with probability p(Di), the goal is to choose r to
maximise Ei(ai p(Di)). In computing expected utility
values, influence diagrams [Howard and Matheson, 1981,
Shachter, 1986] can be used to find the treatment with
highest utility.
·

2.2

Diagnostic Problem

A complete diagnostic cycle consists of reasoning from
evidence E to hypothesised diagnosis H, and then ad­
ministering a treatment T for the diagnosis (or abnor­
malities). This is shown in Figure 1.
In most current formal theories of diagnosis (e.g.
[Reiter, 1987, Peng and Reggia, 1987a, de Kleer and
Williams, 1987, Pearl, 1987, Pople, 1982]), the treat­
ment phase is not considered at all, and diagnoses are
defined with respect to the evidence-hypothesis phase
only. These approaches ignore utility considerations to­
tally. It is interesting to note that in one of the earli­
est analyses of medical diagnostic reasoning, Ledley and

I

Lusted [1959] described a method of implementing the
full diagnostic cycle.
We argue that diagnostic reasoning must take into ac­
count the complete cycle, and should consider utility
maximisation. In using a utility-based approach, the
definition of a diagnosis is strongly influenced by how
the diagnosis is to be used.
There are a number of possible uses of a diagnosis,
including:
1. to find out the thing (or things) that is wrong; that
is, through testing, to determine the exact state of
the world with respect to the symptoms observed;
2. to give a plausible account (an explanation) for the
symptoms; that is, to give a description of what is
wrong that is understandable to people;
3. to enable a decision as to how to fix something; that
is, to maximise the utility derived from the diagnos­
tic process through the treatment of the abnormal­
ities;
4. to fix the symptoms; in some cases we may be happy
to fix the symptoms without caring about what is
really wrong.
The first of these may be carried out by someone who
is trying to determine what errors occur so that they can
be prevented (for example, by redesigning some compo­
nents). The second and the third are both activities
that an ideal doctor must undertake. As well as giving
optimal treatment they also have to be able to give a ra­
tionale for the treatment. The fourth may be something
that has to be done in an emergency, for example reduc­
ing the temperature of a patient with fever, or restoring
power in a failed power station.
While each of these may seem reasonable, we will see
that different goals will lead to different evaluation cri­
teria. For example, the best decision may involve av­
eraging over many cases, which may not be conducive
to a good explanation. Also there may be no point in
finding the exact causes for a problem if further refine­
ment of the problem will not improve the outcome. In
computing explanations, the most coherent explanation
may not contain all the evidence or hypotheses.
It is important to keep these different goals in mind
when considering different proposals.
3
3.1

DESCRIPTION OF PROPOSALS
Most likely single-fault hypothesis

In this approach, the hypotheses considered are the
unit hypotheses, h1, ..., hm. A single-fault diagnosis is
defined as a conjunction of hypotheses, only one of

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

48
which is true. Hence, if hypothesis hi is the proposed
single-fault hypothesis, the single-fault diagnosis Hi is
7ii 1\7i2 1\ 1\ hi 1\ 1\h,;; = hi 1\ 1\i ¢i 7ij. For example,
if an electrical circuit contains m components, a single­
fault diagnosis is that component i is faulty and all other
components are functioning normally. The most likely
diagnosis is defined as the diagnosis with the highest
probability, p(HiiE), over the set i E {1, ... , m}.
•

3.2

·

•

·

·

·

Most likely posterior hypothesis

As in the single-fault approach, the hypotheses consid­
ered are the unit hypotheses, h1, ... , hm. The most likely
diagnosis is defined as the hypothesis with the highest
posterior probability p(hi IE).
This is the approach taken in MEDAS [Ben-Bassat
et al., 1980], INTERNIST [Pople, 1982], and by
Pearl [1986], for example. Pearl frames his analysis
within Bayesian networks. This entails defining a causal
graph of the problem, where the nodes represent random
variables (or propositions) and directed edges represent
direct causal influences between random variables.
3.3

Most likely interpretation

This approach entails considering the set I = {h, ..., Ik}
of interpretations, the set of truth assignments for the
propositions in H. The interpretation which is most
likely given the evidence must be determined. Pearl
[1987] defines this optimal interpretation as the interpre­
tation which has the highest posterior probability given
the evidence, p(IdE), where there is no Ij such that
p(IdE) < p(Ij IE). Reiter and Mackworth [1990] ad­
vocate considering all visual interpretations for a given
image formalised as a set of logical clauses. Note that
all interpretations need not be computed in order to find
the most likely one [Pearl, 1987].
3.4

Probability of provability

In this case we use a logical axiomatisation of the prob­
lem, as well as a probabilistic model of the domain.
The logical model is used to prove the logical possibili­
ties of the observations 0 (which constitute the set of
hypotheses in which one is interested), and then the
probabilistic model is used to compute the likelihood
of these. This corresponds to finding the most likely
consistency-based diagnosis [Reiter, 1987, Poole, 1989b,
de Kleer et al., 1990].
In terms of normal and abnormal function of system
components, a consistency-based diagnosis is defined as:
Definition 3.1 (Consistency-Based Diagnosis)

A consistency-based diagnosis is a minimal set of
abnormalities such that the observations are consistent
with all other components acting normally [Reiter, 1987].
This approach entails axiomatising the problem as a
logical theory 7 which consists of a set E of clauses rep­
resenting 0 and F. From E a set r of clauses logically
entailed by E can be derived. This set can be defined as
a minimal disjunct of maximal conjuncts of elements of

H that follow from E, 1 i.e.
0 1\F �(hi 1\ ... 1\hj )V (h�; 1\ ... l\h1) V... V (hm 1\... 1\hn)•

Each conjunct is defined to be a diagnosis .
In order to compute the probabilities of the elements
of r, a probability distribution (or some other measure)
must be assigned to E. Then the measure assigned to
the 'Yi E r must be computed.
One method of such a computation is provided by the
ATMS, as described in [de Kleer and Williams, 1987] or
[Provan, 1990, Laskey and Lehner, 1990].2 An assump­
tion can be assigned to each clause Ei E E to symboli­
cally represent the measure assigned to Ei. The ATMS
then computes the set of assumptions assigned to each
literal consistent with E. Consequently, the assumption
set associated with each 'Yi can be computed. Assigning
a measure to each assumption enables the measure for
each 'Yi to be derived.
The causal relationship in this approach has been de­
scribed by Pearl [1988] as evidential, as the direction of
causality proceeds from evidence to cause.
3.5

Covering explanations

In this case the goal is to abduce a causal explanation of
the observations.
Definition 3.2 (Abductive Diagnosis) Given
a
causal axiomatisation of the system, an abductive di­
agnosis is a minimal set of hypotheses which, together
with the background knowledge implies the observations
0 [Poole et al., 1987, Poole, 1989a].
As in the provability approach, a logical axiomatisation
is required. More formally, the hypotheses considered
are the minimal conjunct of elements of H that imply 0
from F (cf. [Poole, 1987]):
F 1\ ((hi 1\... 1\hi )V(hk 1\... 1\h,)V...V(hm 1\... 1\hn))

� 0.

Each conjunct is an explanation or diagnosis.
Abduction is used to compute a causal explanation for
the observations. Note that the background knowledge
F must be axiomatised differently in this ap proach and
the previous one [Poole, 1988, Poole, 1989aj.
Another method of describing this approach using
graph theory is that of a. causal bipartite graph [Reg­
gia et al., 1985]. In such a. graph the bipartite edge sets
consist of cause nodes and observation nodes, with di­
rected edges from cause nodes to observation nodes. A
node covering of causes for a given set of observation
nodes is required.
A probabilistic analysis of this approach can be found
in [Peng and Reggia, 1987a, Peng and Reggia, 1987b] and
in [Neufeld and Poole, 1987]. Peng and Reggia [1987b]
and Neufeld and Poole [1987] describe a method of com­
puting the best diagnoses by evaluating the best partial
diagnoses only.
1See, for example, [Reiter, 1987], [de Kleer and Williams,
1987] or [de Kleer et al., 1990] for details.
2For the purposes of this paper it is irrelevant what type of
measure or combination function is used. What is of interest
here is the measure assigned to r, and what is contained in
r.

49
a

Pearl [Pearl, 1988] describes this u a causal approach,
as the direction of causality proceeds from cause to evi­
dence.

I

c
3.6

Utility-hued explanation

To compute utilities, we can use the definition of a
Bayesian network (as done in the first two approaches
described in the paper) augmented with a set of deci­
sion nodes, a value node and utility values (an influence
diagram [Shachter, 1986]).
This approach makes no commitment as to which set
of hypotheses constitute a diagnosis, unlike the logic­
based approaches (approaches 3 and 4). Bayesian net­
works can also be used to compute the probability of
any conjunction of hypotheses, by creating a new node
that represents the conjunction of the hypotheses of the
nodes it is influenced by.
Dependent on the utilities of a given problem instance,
different combinations of hypotheses will be considered.
In general, utility can be assigned on a problem by prob­
lem basis. Obviously, dependent on the utility func­
tion chosen, this approach can end up computing differ­
ent combinations of hypotheses than for the "diagnosis"
from the first five approaches.
The utility-based approach is influenced by work in
computer vision, planning and in cognitive science in
which a high-level description of the task influences both
the objective function to be evaluated and the method
of solving the task. For example, in computer vision,
model-based object recognition systems use a descrip­
tion of the object to speed recognition of the object by
looking for only image primitives which will most likely
constitute a part of the object [Chin and Dyer, 1986].
We argue that the problem representation must be de­
pendent on the nature of the diagnosis required. Thus,
if distinguishing among diagnoses does not affect the de­
cision made, there is no point to computing the different
diagnoses, or an optimal diagnosis. Or, if the utility
value is indifferent to particular liver diseases or heart
diseases, the problem can be reformulated (e.g. all liver
diseases considered as a "group", and all heart diseases
considered as another "group").

As another example, consider a computer which has
four main circuit boards, each of which can be divided
into groups of components. If the computer goes down
due to hardware failure, then the optimal diagnosis for
a situation in which the computer must be fixed as soon
as possible is to identify which circuit boards need to
be replaced. If there is no time pressure, the optimal
diagnosis may be to identify which group of components,
or which specific components, must be replaced, given
the high cost of replacing entire boards.

I

b

This approach computes not the most probable conjunc­
tion of hypotheses (or diagnosis), but the conjunction of
hypotheses that are most useful for the treatment phase
of diagnosis.

d

Figure

4

2: A

I

circuit

ARE THEY REALLY ALL THE
SAME?

In this section we demonstrate that the approaches do
indeed give different answers.

Example 4.1 Consider the analogue circuit of figure 2.
In this figure a, b, c and d are gates that are faulty if
they are closed (i.e., they are supposed to be open, but
they can be shorted). Let A be the proposition that is
true if a is shorted, and B be the proposition that is true
if b is shorted, etc.
Suppose we have the knowledge that the gates break
independently and we have the priors

p(A)
p(B)
p(C)

=

p(D)

=

=
=

0.016
0.1
0.15
0.1

P2=
Ps=

P4 =

P& =
P6 =

P7=
Ps=
pg =
PlO =
Pu =

P12 =
Pts=
P14 =
Pl& =

p(A" B Ac"DIE)
p(AABACA -.DIE)
p(A" BA ...,c"DIE)
p(AABA ...,cA ..,DIE)
p(A" ...,B "cADIE)
p(AA ...,BACA -.DIE)
p(A" ...,B" ...,c"DIE)
p(AA ...,BA ...,CA-.DIE)
p(...,AABA.CADIE)
p(-.A ABACA -,DIE)
p(-.AA BA -.CADIE)
p(...,AABA ...,CA ..,DIE)
p(-.A" ...,B" c"DIE)
p( -.AA ..., BACA -.DIE)
p ...,A" ...,BA ...,c"DIE)
p ..,AA -.BA ...,cA ..,DIE)

�

I
I
I
I
I
I

Suppose we observe that there is a current flowing
through the circuit. Let E be the proposition that rep­
resents this evidence. The diagnoses computed by each
of the approaches are now examined. We first give the
interpretations as the the probabilities of all interpreta­
tions serves as a generator for all the probabilities.
The 16 possible interpretations are:
Po=
Pt =

I

0.0006
0.0055
= 0.0035
= 0.0313
= 0.0065
= 0.0497
= 0.0313
= 0.2816
= 0.0377
= 0.3395
= 0.2138
= 0.0
= 0.0
= 0.0
= 0.0
= 0.0
=

=

There are a few things to notice about the probabilities
of the interpretations:

I
I
I
I
I
I
I
I
I

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

50

1. All of the other posterior probabilities can be gen­

erated from the Pi· In particular, for any formula
we have
p(wiE) =

w

2. All of the interpretations that are not possible have
probability zero. The last 5 interpretations are not
possible given the circuit, and so must have proba­
bility zero. Note that there was no need to do any
logical pruning before the probability phase. The
logical axiomatisation of the provability and cover­
ing cases ( 4 and 5) was not to remove impossible in­
terpretations (as in [Ledley and Lusted, 1959]) but
to determine what it is that we are getting the prob­
ability of.
The possible single-fault diagnoses are
obtained by saying that all of the interpretations
except P7, Pu, P1s and P14 are impossible. There is
only one possible single fault diagnosis: a is shorted.
This does not depend on any prior probabilities, ex­
cept for the knowledge that the probability is zero
for all of the impossible diagnoses.
Posterior. When computing the most likely posterior,
we compare
p(AIE)
p(BjE)
P (CjE)
p(DIE)

p(AjE)
p(B A OlE)
p(B 1\ DjE)

p(IIE)
{I:w is true in I}

Single-fault.

Numerically, the probabilities are:
=
=
=

0.409
0.383
0. 256.

The most likely diagnosis is that a is shorted.
For the covering hypothesis case we also
need a logical axiomatisation, such as

Covering.

A�E
BI\C�E
BI\D�E
When E is observed, we get the same comparisons
as the previous case, and the same most likely diag­
nosis.
Utility-based. The final case is where we have to take
utilities into account. The next three examples show
how this can interact with the diagnoses.
Example 4.2 Suppose that we can fix up the gates of
example 4.1 independently. In this case the only relevant
probabilities are the posteriors of each of the hypotheses.
We denote byF:: the treatment of fixing gate x. Con­
sider the following utility values:
u(E, D::, r) =

{

=

+$1 ifF:: E r 1\ XED::
-$1 ifF:: E r 1\ X¢ D::
otherwise
0

Po+ Pl + P2 + Ps + P4 + P5 + P6 + P1
Po+ Pl + P2 + Ps + Ps + P9 + Plo+ Pll
In this case, since p(BIE) is greater than 0. 5, we ex­
= Po+ Pl + P4 + Ps + Ps + P9 + P12 + P1s
pect to gain from fixing gate b, but do not gain from
Po+ P2 + P4 + P6 + Ps + P1o+ P12 + Pl4 fixing any of the other gates. Thus it is only worthwhile
fixing gate b.
Numerically, the posterior probabilities are:
If one believes that the aim of the diagnosis is to fix
all of the problems, then this is a peculiar thing to do.
p(AjE) = 0. 409
Based on the logical analysis, it cannot be the case that
p(BjE) = 0.632
only b is shorted.
p(CIE) = 0.439
Example 4.3 Suppose there is a heavy penalty for not
p(DIE) = 0.292
fixing the circuit by replacing a particular gate, as shown
in the following utility function:
The most likely faulty component is b.
ifF:: E r 1\ XE D::
+$1
Interpretation. The highest probability is P9, which
-$1 ifF:: E r /\X¢ D::
indicates that the most likely interpretation is that
u(E, D::, TD,.)=
-$10 ifF:: ¢ r 1\ XED::
b and c are shorted, and a and d are not shorted.3
0
ifF#) rf. r 1\ X rf. D::
Provability. In the fourth case we need to axiomatise
In this case, all gates will be replaced in our example.
the circuit:
All we needed to compute was the posterior probabilities
E�AV(BA(CVD)),
for the individual hypotheses.
Example 4.4 Suppose we can fix up gates b and c in­
and find the probabilities of the resulting diagnoses:
dependently, but that the ways to fix up gates a and
p(AIE) = Po+ Pl + P2 + Ps + P4 + P5
d interact in a complex way. In this case the relevant
probabilities are
+P6 + P1
p(B 1\ CjE) = Po+ Pl + Ps + Ps
p(AjE) = 0.409
=
p(B A DIE)
p(BjE) = 0. 632
Po+ P2 + Ps + Plo·
p(CIE) = 0.439
3Note that this diagnosis just coincidentally corresponds
p(A 1\ DIE) = 0. 041
to the most likely posterior hypothesis (in that they both
have b broken). If we changed the priors slightly to make
p(AA-,DjE) = 0.368
p(C) = 0.12, the most likely interpretation becomes the one
p(...,AADIE) = 0.251
with just A true, but the most likely posterior hypothesis is
p(-,AA-,DIE) = 0.340
unchanged.

{

52

which is not what any of the diagnOiiell computed. Note
that in this case the probabilities that are needed are
not determined by what can explain the observations,
but rather what is needed for the treatment.
It might coincidentally happen that two approaches
compute the best qualitative diagnosis, but this is not
true in general. It is, however, not coincidence that the
provability and covering approaches produce the same
answer. It can be shown that, under certain reasonable
assumptions about how the knowledge is represented,
the propositional versions of the abductive and the de­
ductive systems [Poole, 1988] are identical. This is not,
however, necessarily true for the non-propositional ver­
sions. The difference arises because of the level of detail
of the diagnoses. The more specific the diagnoses, the
less likely it is. The abductive systems require the level of
detail specific enough to imply the observations. In the
deductive system, the level of detail is prescribed, not
by the observation, but by the knowledge base [Poole,
1989a].
ANALYSIS OF PROPOSALS

5

Each of the proposals has good and bad points, some of
which are now discussed.
5.1

Single-fault Diagnosis

The main problem with the most likely single fault hy­
pothesis is that it may be wrong. The real diagnosis may
be a combination of faults.
Another problem is that the single fault definition de­
pends on the representation used. At one level of ab­
straction a single fault may be a very complicated com­
bination of faults at another level of detail. For example,
at one level of abstraction a problem may be that one
power supply is broken. At another level of detail there
may be a number of pwblerns with the one power supply.
5.2

Most Likely Posterior

There are a number of problems with the "most likely
posterior hypothesis" approach:
1. It is the weakest statement about the world. Thus,
if a pigeon is a type of bird, one must have
p(pigeoniE) $ p(birdiE).
2. High (possibly irrelevant) priors may dominate the
relevant hypotheses.
3. Groups of hypotheses are not considered. This ap­
proach cannot compute diagnoses which consist of
sets of hypotheses. Multiple-hypothesis diagnoses
can be determined by heuristics only (e.g. as is done
in INTERNIST [Pople, 1982]). In contrast, the in­
terpretation, consistency and covering methods can
compute multiple-hypothesis diagnoses based on the
underlying theory of the method. Note that this
does not imply we cannot diagnose systems with
multiple faults, but rather that we do not consider
conjunctions in diagnoses.
Note that we can add hypotheses which are con­
junctions of hypotheses, but these will always be
less likely that the original hypotheses.

5 .3

Most Likely Interpretation

In the most likely interpretation approach (# 3) there
can be an exponential number of interpretations, and so
for any reasonable sized problem we do not want to de­
rive all interpretations (as in [Reiter and Mackworth,
1990]). Many interpretations will be highly unlikely,
and computing them will be a waste of computational
resources. However, it is not necessary to enumerate
all interpretations [Pearl, 1987, de Kleer and Williams,
1989]4•
Another drawback of this approach is that the most
likely interpretation does not let us be agnostic about
any proposition; we have to give a truth value to every
hypothesis, no matter how related to the observations.
Changing the space of hypotheses can change the prob­
ability of the most likely composite, and even what the
most likely composite is [Pearl, 1988, p.285). Even more
importantly, for building large knowledge bases adding
"irrelevant" hypotheses can also change the most likely
interpretation. If we imagine a random variable that
is probabilistica.lly independent of the other variables,
then the most likely qualitative conjunct will remain the
same: we will end up with the product of the most likely
prior of the irrelevant hypothesis and the most likely in­
terpretation. If however the new random variable is not
independent, then just by imagining different scenarios
we can change the qualitative diagnosis, as the following
example shows.
Example 5.1 Consider a. patient who has symptoms
which suggest either the flu or yellow fever, the flu be­
ing the more likely diagnosis. Now, suppose we add a
variable that represents where the person was at some
particular time two weeks previously. We partition the
world so that the different places all have equal probabili­
ties (e.g., "Africa" may be one area, and "above the most
northerly fioor tile in their office" may be another). If
these new variables are independent of the disease vari­
able, the most likely interpretation will consist of the
most likely values for each variable. Simply by assuming
that it is much more likely that the patient has yellow
fever if she was in Africa, the most likely composite hy­
pothesis may be that the patient has Yellow fever and
was in Africa5•

One other problem with finding the most likely in­
terpretation is that the most likely interpretation may
have very low probability. Peng and Reggia [1987c] first
pointed this out and suggested that rather than finding
the most likely interpretation, we should find a set of
interpretations that covers some percentage of all of the
cases.
�Note that the phase of removing interpretations inconsis­
tent with the knowledge (i.e., those interpretations that are
not models of the logical constraints) is unnecessary because
p(hi\E) = 0 if h; is inconsistent with evidence E.
&This example is different from the example given by Pearl
[1988, p. 285], in that we are adding a new hypothesis rather
than changing a hypothesis. Just by imagining a new hy­
pothesis, and making no new observations, we can change
the value of the most likely interpretation.

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

53
5.4

Covering Explanations

Approaches 4 and 5 are discussed together because
propositional versions of these approaches have been
shown to produce the same results under certain assump­
tions [Poole, 1988]. These differ from the interpretation
approach in enabling us to be agnostic about the value
of some variables which are irrelevant to the goal.
5.5

Consistency and Covering Approaches

These logic-based approaches are limited to what is prov­
able within the logical theory T. Hence, they are sensi­
tive to the particular logical description. If an observa­
tion is not provable, then nothing can be said about it.
(Similarly, for the Bayesian approach, if the appropri­
ate conditional probabilities are present for an observa­
tion, no �easure c�� be assigned to the observation.) In
contrast, m the utility-based approach considered here
what is computed depends on the goal of the diagnosis :
Both the consistency and covering approaches rely on
making assumptions about the system under examina­
tion. Pearl [1990] has shown that this approach has
two major flaws: (1) independencies among events with
unkn�wn probabilities cannot be represented; and (2)
domam knowledge describing defeasible conditional sen­
tences cannot be represented. Thus, these approaches
are limited to problems in which the domain knowledge
can be defined in categorical terms, e. g. strict taxo­
nomic hierarchies, deterministic systems (electronic cir­
cuits but not medical diagnosis or default reasoning), etc.
If these approaches are misapplied to certain domains '
non-intuitive results can be obtained.
. Pearl [1990] argues that instead of making assump­
tiOns about the hypotheses, examining the logical con­
sequenc;�s of these assumptions, and then assigning a
probability measure over the assumptions a probability
measure should be assigned over the logical clauses :E
and the probabilities assigned to interpretations be ex­
a.mined (as .done in approach 2). If not all clauses are as­
�Igned a weight, then probability bounds (specifically the
mner and outer measure) can be obtained for the mea­
sure assigned to the h�potheses. For example, Nilsson
[1986] presents a techmque which can accept an incom­
plete pr�babilistic specification, and computes ranges for
the reqmred measures for hypotheses. This paper argues
that it is not clear that the approach suggested by Pearl
(i.e. that the most likely interpretation must be evalu­
ated) is always the best one.
However, because these logic-based approaches seem
to be appealing for a number of reasons, it may be impor­
tant to determine subcases of non-categorical domains in
which paradoxes do not arise.
5.6

Utility-based diagnoses

The utility-based approach assumes that utilities are
domain-dependent, which implies that diagnoses must
be domain-dependent as well. In contrast, the other
approaches assume that the definition of diagnosis is
domain-independent. In addition, preferences used to
define best diagnoses cannot be assigned in a domain­
independent manner. Doyle and Wellman [1989] have
proven that there exists no universally-valid preference

set; in other words, preferences are consistent only within
particular domains. Furthermore, Doyle [1989j argues
for a decision-theoretic, and not merely probabilistic
definition of consistency and rationality in decision�
making (and therefore diagnosis).
T�e util.it!-based approa:h is considered the proper
o�e m declSion theory and m several areas of cognitive
science. For example, in visual recognition it has been
shown. how several low-level (and quite primitive) pre­
attentive processes are used to focus attention on the
�ost salient features of a scene [Treisman, 1982], and
simple features are used to guide scene interpretation
[Rose�feld, 1987]. In some cases, results from these pre­
attentive processes are used directly to initiate action.
For example, in the forest if a deer sees motion close by
(the presence of motion in the visual field can be detected
pre-attentively), it will start running without identifying
the cause of the motion, as it might get eaten if it spent
the time trying to identify the cause of the motion. If
the deer is not in danger, motion can trigger a closer
scrutiny for the cause of the motion.
One of the problems of the utility-based approach is
that there is nothing in a diagnosis unless there is a goal
and utilities. There is no ''value free" definition of a
diagnosis. Whether this is desirable or not is left up to
t�e reader. There is also the problem of being able to
g1ve someone an understandable explanation to answer
the question "what is wrong?".
6

CONCLUSIONS

This paper has analysed several definitions of what a
dia�n�sis, an � so, presumably, what a most-likely diag­
?osis Is, showmg them to be mutually incompatible. It
IS not clear that one definition is correct over all domains
and situations, and for all possible uses that there could
be for the diagnosis. Instead, we argue that the notion
of most likely diagnosis cannot be defined a priori, but is
defined based on what the diagnosis is to be used for and
o.n the uitlity of the outcomes of treating the abnor:Oali­
ties. In other words, there may be no a priori ontological
definition of optimal diagnosis; it is epistemological and
situation-dependent.

