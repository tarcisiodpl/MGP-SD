

1

The intelligent reformulation or restructuring of a be­
lief network can greatly increase the efficiency of in­
ference. However, time expended for reformulation
is not available for performing inference. Thus, un­
der time pressure, there is a tradeoff between the
time dedicated to reformulating the network and the
time applied to the implementation of a solution. We
investigate this partition of resources into time ap­
plied to reformulation and time used for inference.
We shall describe first general principles for comput­
ing the ideal partition of resources under uncertainty.
These principles have applicability to a wide variety
of problems that can be divided into interdependent
phases of problem solving. After, we shall present re­
sults of our empirical study of the problem of deter­
mining the ideal amount of time to devote to search­
ing for clusters in belief networks. In this work, we
acquired and made use of probability distributions
that characterize (1) the performance of alternative
heuristic search methods for reformulating a network
instance into a set of cliques, and (2) the time for
executing inference procedures on various belief net­
works. Given a preference model describing the value
of a solution as a function of the delay required for
its computation, the system selects an ideal time to
devote to reformulation.

For a large class of AI problem-solving techniques,
great gains in efficiency can be achieved by expend­
ing effort on a preliminary meta-analysis of a problem
instance before directly executing a solution. Belief­
network algorithms highlight the necessity of refor­
mulating or restructuring problem instances. The re­
formulation of a belief-network can greatly increase
the efficiency of inference. Indeed, many belief­
network algorithms rely on some preliminary refor­
mulation procedure. Our analysis of reformulation is
motivated by our pursuit of techniques for the dy­
namic construction and solution of belief networks
[7, 1].
To date, investigators have made use of offline
analyses for reformulating a small number of net­
works that will be solved many times. Unfortunately,
straightforward offline analyses of reformulation, may
not be effective in systems that must construct and
solve belief-network problems at run time. The com­
putational effort expended for reformulating a newly
constructed belief network is not available for the pri­
mary task of performing inference with the network.
Thus, in time-dependent decision contexts, there is a
tradeoff between the time dedicated to reformulating
the network and the time applied to the implementa­
tion of a solution.
We shall describe the metareasoning-partition
problem and present principles for computing the
ideal partition of resources under uncertainty for sev­
eral prototypical classes of uncertainty and utility. In
Section 3, we shall consider the global optimization
of the apportionment of resources to precursory re-

•This work was su pported by Rockwell International Sci­
ence Center and the National Science Foundation under Grant
IRI-8703710.

65

formulation for the situation where the reformulated
instance is solved once. In Section 4, we will discuss
the inclusion of evidence about the progress of prob­
lem solving, in a formulation of the metareasoning­
partition problem centering on a myopic optimization
policy. Following the presentation of theoretical re­
sults, we shall discuss in Section 5 an empirical study
of the application of these principles to belief net­

I
I
I

works. We focus, in particular, on an empirical anal­
ysis of the ideal amount of time to devote to search­
ing for clusters in belief networks. We acquire and
apply probability distributions that characterize the

I

performance of alternative heuristic search methods
for finding cliques and the time for executing infer­
ence procedures on various belief networks. Given a
preference model, describing the value of a solution

I

as a function of the delay needed for its computa­
tion, the system determines the ideal time to devote
to reformulation.

2

Reformulating

Belief

Figure 1: Reformulation of

Net­

works
Brute-force approaches to the solution of belief­
network inference problems are intractable. In a
brute-force analysis, we generate a joint distribu­
tion by taking the product of all assigned distribu­
tions. Given the joint distribution, we compute the
marginal probability for any value of a variable or
Boolean combination of values, by summing over the
relevant dimensions of the joint distribution. The size
of the joint distribution is exponential in the number
of variables. Thus, although this naive approach is
conceptually simple, it requires computation that is
exponential in the number of variables.
Although the problem of probabilistic inference
with belief networks is .N"P-hard, methods have been
developed for exploiting independence relations to
avoid the explicit calculation of the joint-probability
distribution. A variety of exact methods has been
developed to operate on specific topologies of be­
lief networks [13]. Other recent methods forego exact calculation of probabilities; these approximation
techniques produce partial results as distributions or
bounds over probabilities of interest [4, 14, 8].
Several promising exact and approximate ap­
proaches rely on the reformulation of multiply con­
nected networks. We are studying the ideal control
of reformulation of belief network instances with the
clique-tree approach developed and refined in [11, 9],

method of conditioning [12), and with the
nested-dissection method of Cooper [3]. The clique­

with Pearl's

tree reformulation approach seeks to convert multiply

I

·

a

belief-network instance

I

for the clique-tree approach involves generating and
Individual
evaluating alternative sets of cliques.
cliques are encircled. As highlighted by the graphs,
nodes can be members of several cliques.

I

connected belief networks into a corresponding singly
connected network of cliques. A precursory reformu­
lation of a belief-network instance works to identify
cliques, defined as maximal sets of nodes that are
completely interconnected. An algorithm has been
developed to propagate evidence within this tree of
cliques, which is somewhat analogous to the prop­
agation of belief in a singly connected network of

I

variables. Alternative clique-tree reformulations are
pictured in Figure 1. For the method of condition­
ing, reformulation seeks to break loops in a multiply
connected belief network, by identifying and instan­
tiating a loop cutset. At solution time, each cutset
node must be instantiated with each possible value
(or combination of values). Each instance is solved
as a. separate singly connected belief network prob­
lem. Reformulation methods work by generating and
evaluating cutsets that minimize the number of prob­
lem instances that must be evaluated.
Identifying the best cutset and identifying the
best set of cliques are .N"P-hard problems, since in
general they require searching all sets of subsets of
the nodes in a belief network. However, we can de­

velop heuristic strategies (see for example [10]) and
flexible (or anytime) search strategies that can deliver
increasingly better reformulations as we increase the
amount of reformulation time.

I
I
I
I
I
I
I
I
I
I

66

I

For some inference procedures it may be possi­
ble to determine t e precisely, given the amount of
time spent searching for a solution. In this special
situation, we can characterize computation time in
terms of a deterministic function, te = 'R(tr) . In
this case, the selection of te fully determines the time
that the solution to the problem becomes available.

I
I

In general, we must consider the uncertainty in the
relationship between the search time and the time
required to compute a desired result.
Under uncertainty, the computation time is char­

I

acterized by probability distributions for different val­

I

ues of search time,

t�t + t
r

e

I
I
I
I

Figure 2: A graph showing the value of a computed
result, as a function of the total time required to gen­
erate a result. The total delay t is the sum of the time
needed for reformulating and solving a belief network,

t

=

3

tr + te.

lief networks that are created at run time.

I

3.1

I
I
I
I

that maximizes the

tion of a value function and distributions forte. More

for Belief Networks

I

I

tr

expected value of the computation, given a specifica­

Ideal Partition of Resources

I

I

tem) which may effect these distributions. Our ob­
jective is to choose a value of

formally, we seek to maximize the expected value of
the result, with respect to tr as follows:

We now shall outline the problem of ideally appor­
tioning resources to the reformulation of belief net­

I

where e includes any background knowledge about
the problem and solution methods (e.g., problem size,
hardware parameters, architecture of reasoning sys­

works under conditions of uncertainty and describe
the application of this problem to the solution of be­

max

tr

Deadlin e Models

The class of

We refer to the problem of ideally apportioning re­
sources between a meta-analysis and the solution of a
base problem as the metareasoning-partition problem

[6]. The ideal partition of resources depends on the
architecture of an agent, on the availability and form
of knowledge and metaknowledge about problem­
solving, and on the problem instance at hand. Most
meta-analyses for the reformulation of belief networks
center on ·a search process. Thus, we cast reformula­
tion in terms of search. Let tr be the time the rea­

soner spends on reformulating a problem instance,
and let te be the time required to execute a reformu­
lated instance to generate a final solution. Thus, the
total time required to solve the problem is t = tr +te.
function solely of the time at which it becomes avail­
in Figure 2.

V(t), illustrf!.ted

problems captures situations

deadline

where the cost incurred with delay for a computed re­

sult is 0 or insignificant until a deadline a is reached.
Thus, an analytical result obtained before time a has
value k. If the result is not available by time a, the
result is worthless. We can model a deadline situation
via a stepwise value function

V(t)

_

-

{

k
0

t �a

otherwise.

Through substituting this step-function utility into
our general formulation
value is

Et. (VItr,e)

=

Let us assume that the value of a computed result is a

able. We express this relationship as

(1)

te

Details of a formal analysis of this problem ap­
pear in [2). Here we highlight the central results for
prototypical models of cost.

3.2

General Problem

j V(tr + te)p(teltr,e)dte

=

=

(1), we find that the expected

1 V(tr +te)P(teltr,e)dte
1a-tr kp(teltr,e)dte
t.

kp(te �a- trltr,e)

(2)

·

67

The last term is the probability that the time required
for executing the reformulated solution is less than
the time remaining after the reformulation process.
Thus, for the deadline case, maximizing the expected
value is equivalent to maximizing the probability of
completing the computation before the deadline.
3.2.1

3.3

Polynomial Urgency Models

Let us now explore the general model of reformula­
tion under uncertainty where the overall value of a
computational result is a polynomial function of the
time it becomes available. We consider a model of ur­
gency where the value function V(t) is an nth degree
polynomial:

where the

ai

=

L aiti I: ai(tr + te)i

The class of target problems refers to situations where
the value of a computed result is 0 unless it is available
exactly at time a. That is, a result obtained before
or after time a is worthless. This model is associ­
ated with events that must be coordinated tightly un­
der bounded resources, such as time-dependent com­

senting our value as a delta function

=

i=l

i=l

V(t) = o(a- t) = o(a- (tr + t.))

are constants that are customize the

model to particular contexts. Substituting the poly­

dp(a- irltr)

1, we seek to maximize:

dtr

1 t a (tr +t.)•p(t.ltr,e)dt.
1. �a, t. (J) t!t�-ip(teltr,e)dt.

dictates that, for target models, we should continue
searching until the distribution over the expected ex­
ecution time achieves its mode exactly at time a.

,

i=l

t t. (i)
ai

where

m(n)(zly) =

O

The derivative of a probability distribution is zero
at the mode of a unimodal distribution. This result

Et. (VItr, e)

=

=

4

i
#m( -j)(te ltr)

Incremental

Analysis

of

Metareasoning Partition
We have described how we can characterize the ef­
ficacy of metareasoning processes for different types
of belief networks by acquiring probability density

1 znp(:cly)d:c

is the nth moment of :c given y.1
To maximize the expected value of a computed
result defined by Equation 3, we set the derivative of
this expression to zero. At the optimum we obtain

functions about the relationship between tr and t.
for a large set of instances for each class. Such sam­
pling yields probability distributions p(t.ltr,e) that
we can use to calculate the optimal time to spend on
metareasoning. e includes any background knowledge
about the problem and solution methods which may
effect these distributions. So far, we have assumed
that we do not have additional knowledge about the
problem besides these distributions. If the reasoner

{ 3)
Thus, for any context of urgency, that can be rep­
resented (or approximated) with a polynomial value
function of order n, we can determine an ideal time
to dwell on reformulation tr, given the moments and
1The

first

expectation.

moment

of a

distribution,

m<1),

is

the

I
I
I
I
I
I

At a solution for this functional form, we have

nomial form into our general formulation, Equation

t.

Target Model

munications and datasharing over limited bandwidth
channels. We can model target problems by repre­

n

n

V(t)

derivatives of the probability distribution, p(te ltr, e)
for i = 1, . . . , n. For high-order polynomials, solv­
ing Equation 3 and estimating the derivatives may
be difficult. However, for linear and quadratic forms,
the solution is straightforward.

I

I
I
I
I

I
I
I

is limited to a single-step solution-planning process,
where a single meta-analysis is applied to generate
an ideal reformulation policy, we are indeed forced to

I

make use of a probability distribution that describes
the relationship between tr and t. for an entire class
of problems. However, we may wish to expend addi­

I

tional resource on an incremental meta-analysis, and
make use of detailed information about the relation­
ship between tr and t. that is revealed over time.

I
I
I

68

I

than the value of halting and solving the current

I

formulation of the belief-network problem. We halt
when the expected change in the value of solving the
problem after another

I

t

e

V( t + t )
e

EVhalt

I
I
I
I

=

1t. V(tr +te)p(te!tr,Et.,e)dte

r

If we continue reformulation, there is a spectrum of
evidence
Figure

3:

The incremental metareasoning-partition

decision problem, incorporating the acquisition and
use of information about the progress of reformula­
tion to control the extent of reformulation.

E

which may be observed.

EVeontinue

=

1t. jEf V(tr + L::.tr + te) (t.!tr + Atr,Et.+t:..t.,e)
P

(4)

p(Et.+t:..t.!Et.,e)dEdt.

That is, we can assess probability distributions and

I

I

Expected value of halting

reformulation:

In the incremental approach, we analyze recent

I

Note that we are not solv­

we develop a greedy, hill-climbing procedure for in­

incorporate information about the progress of refor­
mulation as a useful class of evidence for determining

I

4.

cremental reformulation.

I

I

and

ing for the sequence of choices over time, but rather

I

I

Atr

with a new lottery. The incremental decision tree is
displayed in Figure

I

I

is nonpositive. If we de­

again examine a new decision to halt or to continue

I

I

Atr

cide to continue, we reformulate for another

the efficacy of future reformulation efforts.

The further assumption that
independent of

tr

te

is conditionally

given the evidence observed so far

yields

p(te!tr + Atr,Et.+t:..t.,e)

=

p(te!Et.+t:..t., e)

(5)

reformulation behavior to make a decision about the

simplifying the expression for Equation 4. The crite­

value of continuing to p erform reformulation for an

rion for halting is

additional, prespecified increment of reformulation
time.

EVhalt � EVeontinue

We can make use of uncertain knowledge of

the form

(6)

The efficacy of the incremental approach relative

p(t.!tr,Et.,e)

to an

a

priori

reformulation policy depends on the

where E1• refers to evidence observed at time tr in the

structure of the problem and the costs of performing

progression of reformulation of the current instance.

the incremental analysis

Associated w ith each time point and evidence

E

is

the actual data structure which embodies the current
reformulated problem instance. In general,

E1•

ori analysis can

[5].

In some cases, an

a

pri­

prove that an incremental approach

is unnecessary; we show in

[2]

that for certain value

can

function-distribution pairs, dominance relationships

include the complete sequence of evidence or infor­

can determine the ideal reformulation policy in ad­

mation collected during the process of reformulation.
At each time

tr, we must decide

vance. W hen this type of simplification is not possi­

whether to halt

ble, there are other factors to consider. If a reasoner

immediately-and to begin to solve the current prob­

cannot obtain access to evidence (E) about the time­

lem formulation-or to continue the reformulation

dependent behavior of a reformulation method, we

search for another

Atr.

We can express the value

must treat the method as a mysterious "black box,"

priori

of continuing as a lottery over possible results of fur­

and base decisions on an

ther reformulation search; we can sample a large set

summary distributions for large classes of problems.

of cases to acquire probability distributions about

Finally if the cost of evaluating Equation

changes in distributions about

te

as more time is

spent on reformulation.

a

consideration of

6

is high,

then the overhead of metareasoning may overwhelm
potential benefits.

In fact, creation of distinctions

W ith the incremental metareasoning-partition

and models for E1• and its dynamics that are at once

analysis, we must continually determine if the ex­

informative and concise are critical to the value of the

pected value of the lottery of continuing is greater

entire approach.

69

5

Example:

Clique Reformu­

lation
We have applied an incremental analysis of ideal par­
tition of resources to the example of clique reformu­
lation of a belief network. The fundamental cycle
is construction of a belief network, formation of the
clique tree (reformulation), and finally performing in­
ference (calculating the posterior probability of all
unobserved variables). We shall present several de­
tails about the clique identification strategies. After,
we shall describe the procedures used to collect prob­
ability distributions for use in the analysis. Finally,
we shall review the results of using these distributions
in an incremental analysis.
5.1

Clique Reformulation Methods

is generated by varying the initial conditions to pro­
duce a large number of join tree topologies. After
we generate an ordering, we determine the join tree
structure. We then estimate the time required to
solve that configuration with an efficient estimation
procedure [15]. In our study of ideal clique-tree refor­
mulation, we based this time estimate on the sum of
the state-space sizes for the cliques in the tree. These
"generate and test" procedures maintain a record of
the best clique configuration found to that time and
continues to search until the procedure is terminated.
The strategies are flexible in that they generate so­
lutions that are monotonically increasing in quality
(decreasing in te), and make available, at all times,
the best join tree found so far. As the reformulation
time, tr, is increased, the procedure searches addi­
tional join-tree configurations.

The clique formation methods we examine are based
5. 3
Classes of Data about Reformula­
on construction of a join tree. The join tree is contion Efficacy
structed by the following sequence of steps [16, 13]:
1. Create a Markov network from the original net- As we discussed in Sections 3 and 4, we need to
work by interconnecting the parents of each node make use of uncertain knowledge that relates the time
needed for execution of a problem formulation to the
and removing directionality from the arcs.
time spent on generating the reformulation. We have
2. Calculate an ordering for the nodes.
obtained distributions from a frequency analysis of
3. Fill in edges between predecessors of each node in the various reformulation strategies described above.
the graph, using the ordering generated in Step We used IDEAL, a general influence-diagram pro­
gramming environment, to collect this distributional
2.
information [15]. We directed the system to construct
4. Construct the join tree by identifying the cliques random belief networks of different sizes and con­
(subgraphs which are completely connected) in nectedness, and to apply reformulation algorithms to
the filled-in graph.
the networks. We collected data for many networks
Our analysis of reformulation strategies focuses to g�nerate statistics regarding p(Etp+�t.IE,.,e) and
on Step 2, the generation of an ordering. In par­ p(te!E,.,e).
ticular, we examine a method developed by Kjrerulff
[10], which we refer to asK-search. The better-known 5.3.1 Run-Time Estimate and Reformulation
procedure for ordering is maximum cardinality search.
(MCS) [16]. The MCS approach starts with an arbi­ One useful class of knowledge for making decisions
trary node and assigns the next number to the node about the partition of resources focuses on estimated
having the largest set of unnumbered neighbors. K­ run time as a function of reformulation time. As dis­
search generates an ordering by first finding a node cussed above, increasing the time for reformulation
whose neighbors form a clique already. If no such increases the number of cliques that the program has
node exists, the algorithm uses a cost metric, based explored and scored, with E defined as the best esti­
on the size of the state space of the neighbors of a mate encountered so far. To investigate the efficacy
node, to determine which node to index next·.
of the randomized K-search procedure, we generated
a large number of networks and collected data about
the
trajectory of improvement in run-time estimates
5.2
A Flexible Clique-Reformulation
as additional time was spent on reformulation. Sev­
Strategy
eral of these trajectories are displayed in Figure 4.
We implemented flexible versions of the MCS and The trajectories are normalized to show the propor­
K-search reformulation strategies. The MCS and K­ tional decrease in estimated run time as a function
search strategies are both sensitive to the initial or­ of time. Our analysis revealed that the incremental
dering of a belief network. The search state space time used for generating new configurations has only

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I
I
I
I

.tl

I
I
I
I
I
I
I
I
I
I
I
I
I

•••

�

•••

.. ,.

E

0

5
e.>

-

··-

-

"'Cj

...
....
.. �

���

..,

t)
...
C<l

.. ,

II

e.m

�

.......,

p...

··-

.§

•••

"1

··-

.§
...

1.2

&l

••• 1

4:

1.16

1.82

Proportional change in run-time estimate (tr= 1.5)

Reformulation time ( tr)

I
I

70

-

'B

The proportional reduction in run-time es­

Figure 5: The probability of various levels of decrease

timate as a function of reformulation time for the K­

in running time for K-search for an increment of refor­

search reformulation for a set of randomly generated
networks.

mulation search for tr

Figure
'

=

1.5, generated from a sample

of 200 randomly generated belief networks.

modest impact on total execution time.
8'2

For a particular network, the benefits of additional reformulation time are uncertain because of
the interplay between the K-search procedure and he
specific interconnectedness and the state-space size
for individual variables in a networks. Also, the ex­
pected incremental reduction in runtime is a function
of how long the search has progressed. For the in­
cremental algorithm, we therefore need to assess the

1.1,

t

P( Ee)

e.12

1.18

1.&4

probability distribution over the proportional reduction in Etr+A from Et. for various levels of tr. Trajectories such as displayed in Figure

4

were analyzed

Execution time per unit run-time estimate

to generate those probabilities. The actual data sets
were collected for 0.5 and 0.25 second increments and
applied in 0.5 second increments. Figure 5 displays
one of these distributions. The graph shows the prob-

Figure 6: Probability distribution over time per op­
eration for the clustering belief-network algorithm.

ability distribution over various levels of proportional
decrease in estimated run time. The value at the left
(zero) is the probability that the new reformulations
searched in the next period will be no better than
the current best.

Positive probabilities to the right

indicate the chances for improved e.:'Cecution times,

tal state space size, we divided actual execution time
by E to get a measure of execution time per unit
run-time estimate used to generate
distribution is shown in Figure

p(telEtr,{).

This

6.

given additional reformulation time. We found that

The distributions· do not reflect differences in

the K-search technique performs so well, there are

possible configurations of evidence on the network.

usually only minor gains to obtained from additional

The estimator E is based in the sum of the sizes of

reformulation with this technique.

the state spaces for the cliques in the join tree for the
constructed network. Since the problem we are an­

5.3.2

Time of Execution Given Estimate

alyzing consists of network construction, clique tree
reformulation and a single inference cycle, the infer­

The conditional independence assumption of Equa­

ence step we analyze is that of full propagation and

tion 5 allows us to assess a distribution over execution

initialization of the network, including the initial ev­

times, given the values reported by the estimator E,

idence vector. In analyzing clique tree formation for

independent of the particular value tr. We assessed

a net\vork that would be applied to many possible

this distribution by generating E values for a num­

evidence configurations, it would be necessary to ex­

ber of random networks, and then timing the actual
solution of each network.

Since E is based on to-

amine the impact of different classes of evidence on
the execution time.

71

5.4

Applying the Techniques

The criteria of Equation 6 has been implemented in a
recent version of the IDEAL belief-network environ­
ment. Given a specification of a value function and
a belief network, the system uses empirical data to
determine, in real time, whether or not to continue
with reformulation.
We performed an investigation of the value of
metareasoning for optimizing the reformulation time.
Because an analysis of the ideal reformulation of belief networks is sensitive to the efficiencies of the soft­
ware and hardware, as well as to the formulation of
the metareasoning model, it is important to consider
details of the software and hardware. All experiments
were run with IDEAL on a Symbolics 3645 Lisp Ma­
chine with 8 megabytes of physical memory.
The following experimental procedure was un­
dertaken: A series of 30-node belief networks were
constructed by a random belief-network generator in
IDEAL. For each network and value-function pair, we
applied (1) a default policy of halting reformulation
after the first clique tree is identified by the K-search
heuristic and (2) the incremental reformulation policy
presented in Section 4, based on searching through a
series of c lique trees. After applying each technique,
we executed an inference cycle (full propagation and
marginalization of all nodes in the network), given
evidence. The total time (tr + te) was used to score
the computational value of each trial based on the
value function. This procedure was applied to a se­
ries of random belief networks for a given value func­
tion to assess the longterm performance of the default
or incremental strategy. Given the metalevel model
and the classes of probability distributions described
above, we explored the relative efficacy of the default
and incremental analyses for several value functions
and para.rneterizations of these functions. These func­
tions are shown in Figure 7.
Our analysis showed that the use of metareason­
ing to dynamically optimize the amount of time ex­
pended on reformulation frequently is more valuable
than the static policy of halting reformulation after
the first valid clique-tree is discovered. We found
that the preferred approach, in terms of higher ex­
pected value over a number of trials, depended on
the form of the value function and its specific pa­
rameters. The incremental metareasoning procedure
continue to search if the benefit of finding a better
clique formulation is high enough to justify the delay
associated with continuing another time-increment of
search. Since the K-search heuristic provides a very
good initial clique formulation, (see F igures 5) incre­
mental searching does not tend to provide a great deal

I
I
I
I
I

Figure 7: Prototypical value functions used in the
incremental analyses.
of improvement in absolute terms. However when
the costs of incremental delay are substantial, as in
some of the quadratic value functions analyzed, the
benefits of an improved solution can be substantial­
even when these improvements are expected with low
probability.
For the linear and exponential forms with a slow
decay of value with time, the incremental policies
tend to behave like the default policy, as they stop
searching for better cliques immediately after the first
time increment. In these cases, the incremental pol­
icy was just marginally worse than the default policy.
For deadline models, we examined several vari­
ants by changing the severity of the deadline. We
found that both policies performed equally well un­
der a variety of deadlines, indicating that the ability
to make the deadline was more dependent on the vari­
ability in the time required to perform inference on
different networks (due to topology and state space
size) than on differences in metal eve! reasoning policy.

6

Summary

We described the metareasoning-partition problem
and presented principles for calculating the ideal par­
tition of resources under uncertainty for several pro­
totypical classes of uncertainty and utility. We dis­
cussed the global optimization of the apportionment
of resources for the case of a precursory reformula­
tion where the reformulated instance is solved once.
After, we introduced the incremental analyses for in­
cluding evidence gleaned from observations about the
progress of problem solving. Following the presenta-

I
I
I
I
I
I
I
I
I
I
I
I
I
I

72

I
I
I
I
I
I
I
I
I
I
I
I
I
I

tion of our theoretical results, we discussed empirical [8]
study of the performance of a clique-tree reformula­
tion strategy with these principles. We showed how
an incremental reasoner can reason about the value
of apportioning additional time to a search for op­
timal clusters in belief networks versus halting and
solving the current best formulation. We found that
[ 9]
the value of applying metalevel machinery to opti­
mize the partition of resources for metareasoning is
sensitive to the preference model, describing the value
of a solution as a function of the delay needed for its
computation. We hope that other investigators will
find use in the principles we described for the ideal
partition of resources for reformulation under uncer­ [ 10]
tainty. In particular, the techniques hold the promise
for helping us to optimally control the dynamic con­
struction and solution of belief networks.

F. V. Jensen, Lauritzen S. L., and Olesen K. G.
Bayesian updating in recursive graphical mod­
els by local computations. Technical Report Re­
port R 89-15, Institute for Electronic Systems,
Department of Mathematics and Computer Sci­
ence, University of Aalborg, Denmark, 1989.
U. Kjrerulff. Triangulation in graphs- algorithms
giving small total state space. Technical Re­
port R90-09, Institute for Electronic Systems,
Department of Mathematics and Computer Sci­
ence, University of Aalborg, Denmark, 1990.

gent Systems: Networks of Plausible Inference.

[3] G .F. Cooper. Bayesian belief-network inference
Morgan-Kaufmann, San Mateo, CA, 1988.
using nested dis�ection. Technical Report KSL90-05, Stanford University, February 1990.
[14] R.D. Shachter and M. Peot. Simulation ap­
proaches to general probabilistic inference on be­
[4] M. Henrion. Propagation of uncertainty by prob­
lief networks. In Proceedings of Fifth Workshop
abilistic logic sampling in Bayes' networks. In
on Uncertainty in Artificial Intelligence, Wind­
J.F. Lemmer and L.N. Kanal, editors, Uncer­
sor, Canada, August 1989.
tainty in Artificial Intelligence 2, pages 149-164.
North Holland, 1988.
[ 15] S. Srinivas and J .S. Breese. IDEAL: A software
package for the analysis of belief networks. In
[5] E.J. Horvitz. Rational metareasoning and com­
pilation for optimizing decisions under bounded
resources. In Proceedings of Computational In­
telligence 89. Association for Computing Ma­ [ 16]
chinery, September 1989.

I

[7] E.J. Horvitz, G.F. Cooper, and D.E. Beckerman.
Reflection and action under scarce resources:
Theoretical principles and empirical study. In
Proceedings of the Eleventh IJCAI, pages 11211127. AAAI/ International Joint Conferences on
Artificial Intelligence, August 1989.

I

American Association for Artificial Intelligence.

[ 11] S.L. Lauritzen and D.J. Spiegelhalter. Local
computations with probabilities on graphical
[ 1] J.S. Breese. Construction of belief and decision
structures and their application to expert sys­
networks. Technical Report Technical Memoran­
tems. J. Royal Statistical Society B, 50:157-224,
dum 30, Rockwell International Science Center,
1988.
Palo Alto, California, January 1990.
[ 12] J. Pearl. Fusion, propagation, and structuring in
[2] J.S. Breese and E.J. Horvitz. Principles of prob­
belief networks. Artific ial Intelligence, 29:241lem reformulation under uncertainty. Techni­
288, 1986.
cal report, Stanford University, February 1990.
KSL-90-26
[ 13] J. Pearl. Probabilistic Reasoning in Intelli­

I

I

of ·Fifth Workshop on Uncertainty in Artificial
Intelligence, W indsor, Canada, August 1989.

