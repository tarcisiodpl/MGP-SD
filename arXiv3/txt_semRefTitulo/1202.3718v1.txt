
When the information about uncertainty
cannot be quantified in a simple, probabilistic way, the topic of possibilistic decision theory is often a natural one to consider. The
development of possibilistic decision theory
has lead to a series of possibilistic criteria,
e.g pessimistic possibilistic qualitative utility,
possibilistic likely dominance , binary possibilistic utility and possibilistic Choquet integrals. This paper focuses on sequential decision making in possibilistic decision trees. It
proposes a complexity study of the problem
of finding an optimal strategy depending on
the monotonicity property of the optimization criteria which allows the application of
dynamic programming that offers a polytime
reduction of the decision problem. It also
shows that possibilistic Choquet integrals do
not satisfy this property, and that in this case
the optimization problem is N P − hard.

1

Introduction

For several years, there has been a growing interest
in the Artificial Intelligence community towards the
foundations and computational methods of decision
making under uncertainty. This is especially relevant
for applications to sequential decision making under
uncertainty, where a suitable strategy is to be found,
that associate a decision to each state of the world.
Several formalisms can be used for sequential decision
problems, such as decision trees, influence diagrams
or Markov decision processes. A decision tree is an
explicit representation of a sequential decision problem, while influence diagrams or Markov decision processes are compact representations. Even in the simple
and explicit case of decision trees, the set of potential
strategies increases exponentially with the tree size.

Wided Guezguez
LARODEC Laboratory
ISG, University of Tunis
Tunisia, 2000
widedguezguez@gmail.com

A popular criterion to compare decisions under risk is
the expected utility (EU ) model axiomatized by von
Neumann and Morgenstern [12]. This model relies on
a probabilistic representation of uncertainty: an elementary decision (i.e. a one-step decision problem)
is modeled by a probabilistic lottery over its possible
outcomes. The preferences of the decision maker are
supposed to be captured by a utility function assigning
a numerical value to each outcome. The evaluation of
a lottery is then performed through the computation
of its expected utility (the greater is the better). In
sequential decision making, each possible strategy is
viewed as compound lottery. It can be reduced to an
equivalent simple lottery, and thus compared to the
others according to its expected utility. Although the
high combinatorial nature of the set of possible strategies, the selection of an optimal strategy can be performed in polynomial time (polytime) with the size of
the decision tree: the EU model indeed satisfies a property of monotonicity that guarantees completeness of
a polytime algorithm of dynamic programming.
When the information about uncertainty cannot be
quantified in a simple, probabilistic way the topic of
possibilistic decision theory is often a natural one to
consider [1, 2, 4]. Giving up the probabilistic quantification of uncertainty has led to give up the EU criterion as well. The development of possibilistic decision
theory has lead a series of possibilistic counterparts
of the EU criterion. [15] for instance advocates the
use of possibilistic Choquet integrals, which relies on
a numerical interpretation of both possibility and utility degrees. On the contrary, [4] have studied the case
of a qualitative interpretation and propose two criteria
based on possibility theory, an optimistic and a pessimistic one (denoted by Uopt and Upes ), whose definitions only require a finite ordinal, non compensatory,
scale for evaluating both utility and plausibility.
The axiomatization of Uopt and Upes yielded the development of sophisticated qualitative models for sequential decision making, e.g. possibilistic Markov decision

processes [16, 17], possibilistic ordinal decision trees
[5] and even possibilistic ordinal influence diagrams.
One of the most interesting properties of this qualitative model is indeed that it obeys a weak form of the
monotonicity property. As a consequence, dynamic
programming may be used and a strategy optimal with
respect to Upes or Uopt can be built in polytime.
On the contrary general Choquet integrals are incompatible with dynamic programming. Worst, the problem of determining a strategy optimal with respect to
Choquet integrals is NP-Hard in the general case [10].
We show in the present paper that the problem of determining a strategy optimal with respect to a possibilistic Choquet integrals is NP-Hard as well. More
generally, we propose a study of the complexity of the
problem of finding an optimal strategy for possibilistic
decision trees: which criteria obey the monotonicity
property (and then may be solved in polytime thanks
to dynamic programming) and which ones lead to NPHard problems?
This paper is organized as follows: Section 2 presents a
refresher on possibilistic decision making under uncertainty and especially a survey on most common possibilistic decision criteria. Section 3 details possibilistic
decision trees. Section 4 is devoted to the complexity study regarding different decision criteria. Finally,
Section 5 presents an extension to order of magnitude expected utility. Proofs are omitted for space
reasons but are available at ftp://ftp.irit.fr/IRIT/
ADRIA/PapersFargier/uai11.pdf.

2
2.1

Background
Possibilitic lotteries

The basic building block in possibility theory is the
notion of possibility distribution [3]. Let x1 , . . . , xn
be a set of state variables whose value are ill-known,
D1 . . . Dn their respective domains and denote Ω =
D1 × · · · × Dn the joint domain of x1 , . . . , xn . Vectors
ω ∈ Ω are often called realizations or simply ”states”
(of the world). The agent’s knowledge about the value
of xi ’s is by a possibility distribution π : Ω → [0, 1];
π(ω) = 1 means that ω is totally possible and π(ω) = 0
means that ω is an impossible state. It is generally
assumed that there exist at least one state ω which is
totally possible, i.e. that π is normalized.
Extreme cases of knowledge are presented by complete
knowledge i.e. ∃ω0 s.t. π(ω0 ) = 1 and ∀ω 6= ω0 , π(ω) =
0 and total ignorance i.e. ∀ω ∈ Ω, π(ω) = 1 (all values
in Ω are possible). From π, one can compute the possibility Π(A) and necessity N (A) of an event A ⊆ Ω:
Π(A) = sup π(ω).
ω∈A

(1)

N (A) = 1 − Π(Ā) = 1 − sup π(ω).

(2)

ω ∈A
/

Π(A) evaluates to which extend A is consistent with
the knowledge represented by π; N (A) corresponds to
the extent to which ¬A is impossible: it evaluates at
which level A is implied by the knowledge.
In possibility theory, conditioning is defined by the
following counterpart of the Bayesian rule:
∀ω, π(ω) = min(π(ω | ψ), Π(ψ)).

(3)

In this equation, π(ω | ψ) and Π(ψ) are combined
according to a min operation, according to the ordinal
interpretation of the possibilistic scale1 . The following
min-based definition of the conditioning corresponds
to the least specific solution of (3) (see [9]):

if π(ω) = Π(ψ) and ω ∈ ψ
 1
π(ω) if π(ω) < Π(ψ) and ω ∈ ψ
π(ω|ψ) =

0
otherwise
(4)
Following [2, 4], a decision can be seen as a possibility
distribution over its outcomes. In a single stage
problem, a utility function maps each outcome to a
utility value in a totally ordered set U = {u1 , . . . , un }
(we assume without loss of generality that u1 ≤ · · · ≤
un ). This function models the attractiveness of each
outcome for the decision maker. An act can then
be represented by a possibility distribution on U ,
called a (simple) possibilistic lottery, and denoted by
hλ1 /u1 , . . . , λn /un i: λi = π(ui ) is the possibility that
the decision leads to an outcome of utility ui .
In the following, L denotes the set of simple lotteries (i.e. the set of possibility distributions over U ).
A possibilistic compound lottery hλ1 /L1 , . . . , λm /Lm i
(also denoted by (λ1 ∧ L1 ∨ · · · ∨ λm ∧ Lm )) is a possibility distribution over a subset of L. The possibility
πi,j of getting a utility degree uj ∈ U from one of its
sub−lotteries Li depends on the possibility λi of getting Li and on the conditional possibility λij = π(uj |
Li ) of getting uj from Li i.e. πi,j = min(λj , λij ) by
equation (3). Hence, the possibility of getting uj from
a compound lottery hλ1 /L1 , . . . , λm /Lm i is the max,
over all Li , of πi,j . Thus, [2, 4] have proposed to reduce
(λ1 /L1 , . . . , λm /Lm ) into a simple lottery, denoted by
Reduction(hλ1 /L1 , . . . , λm /Lm i), that is considered as
equivalent to the compound one:
Reduction(hλ1 /L1 , . . . , λm /Lm i)
= h max min(λj , λj1 )/u1 , . . . , max min(λj , λjn )/un i.
j=1..m

j=1..m

(5)
1

The other, numerical interpretation of possibility theory is the use a product instead of a min operation, but
this is out the scope of the present study.

Obviously, the reduction of a simple lottery is the
simple lottery itself. Since min and max are polynomial operations, the reduction of a compound lottery
is polynomial in the size of the compound lottery 2 .
We review in the following the different criteria that
have been proposed to evaluate and/or compare (simple) lotteries; thanks to the notion of reduction, they
also apply to compound lotteries: to evaluate/compare
compound lotteries, simply reduce each to an equivalent simple one; then use one of the criteria proposed
for the evaluation/the comparison of simple lotteries.
Formally, any comparison criterion O, i.e. any preference order ≥O defined on simple lotteries can be extended to compound lotteries as follows:
L ≥O L′ ⇐⇒ Reduction(L) ≥O Reduction(L′ ). (6)

totally ordered:

hu, ui b hv, vi ⇐⇒


u = v = 1 and u ≤ v




 or
u ≥ v and u = v = 1


 or


u = v = 1 and v < 1

(9)

Each ui = hui , ui i in the utility scale is thus understood as a small lottery hui /⊤, ui /⊥i. A lottery
hλ1 /u1 , . . . , λn /un i can be viewed as a compound lottery, and its P U utility is computed by reduction:
P U (hλ1 /u1 , . . . , λn /un i)
= Reduction(λ1 /hu1 /⊤, u1 /⊥i, . . . , λn ∧ hun /⊤, un /⊥i)
= h max (min(λj , uj ))/⊤, max (min(λj , uj ))/⊥i
j=1..n

j=1..n

(10)
2.2

Possibilistic qualitative utilities
(Upes , Uopt , P U )

Under the assumption that the utility scale and the
possibility scale are commensurate and purely ordinal,
[4] have proposed the following qualitative pessimistic
and optimistic utility degrees for evaluating any simple
lottery L = hλ1 /u1 , . . . , λn /un i (possibly issued from
the reduction of a compound lottery):
Upes (L) = max min(ui , N (L ≥ ui )).

(7)

Uopt (L) = max min(ui , Π(L ≥ ui )).

(8)

i=1..n

i=1..n

where N (L ≥ ui ) = 1 − Π(L < ui ) = 1 − max λj
j=1,i−1

and Π(L ≥ ui ) = max λj are the necessity and posj=1..n

sibility degree that L reaches at least the utility value
ui . Upes generalizes the Wald criterion and estimates
to what extend it is certain (i.e. necessary according
to measure N ) that L reaches a good utility. Its optimistic counterpart, Uopt , estimates to what extend
it is possible that L reaches a good utility. Because
decision makers are rather cautious than adventurous,
the former is generally preferred to the latter.
Claiming that the lotteries that realize in the best prize
or in the worst prize play an important role in decision
making, Giang and Shenoy [7] have proposed a bipolar
model in which the utility of an outcome is a pair u =
hu, ui where max(u, u) = 1: the utility is binary in
this sense that u is interpreted as the possibility of
getting the ideal, good reward (denoted ⊤) and u is
interpreted as the possibility of getting the anti ideal,
bad reward (denoted ⊥).
Because of the normalization constraint max(u, u) =
1, the set U = {hu, ui ∈ [0, 1]2 , max(λ, µ) = 1} is
2

The size of a simple lottery is the number of its outcomes; the size of a compound lottery is the sum of the sizes
of its sub-lotteries plus the number of its sub-lotteries.

We thus get, for any lottery L a binary utility
P U (L) = hu, ui in U . Lotteries can then be compared
according to Equation (9):
L ≥P U L′ ⇐⇒ Reduction(L) b Reduction(L′ ).
(11)
In [8] Giang and Shenoy show that the order induced by PU collapse with the one induced by Uopt
whenever for any lottery, the possibility u of getting
the worst utility is equal to 1 (any ”compound” lottery λ1 /h0, α1 i, . . . , λn /h0, αn i reduces to the lottery
h1, max min(λi , αi )i : max min(λi , αi ) is precisely
i=1..n

i=1..n

the optimistic utility value). In the same way, Giang
and Shenoy have shown that the order induced on the
lotteries by PU collapse with the one induced by Upes
as soon as for any lottery, the possibility u of getting
the best utility is equal to 1. We shall thus say that
PU captures Uopt and Upes as particular cases.
2.3

Possibilistic likely dominance (LN, LΠ)

When the scales evaluating the utility and the possibility of the outcomes are not commensurate, [1, 6] propose to prefer, among two possibilistic decisions, the
one that is more likely to overtake the other. Such a
rule does not assign a global utility degree to the decisions, but draws a pairwise comparison. Although designed on a Savage-like framework rather than on lotteries, it can be translated on lotteries. This rule states
that given two lotteries L1 = hλ11 /u11 , . . . , λ1n /u1n i and
L2 = hλ21 /u21 , . . . , λ2n /u2n >, L1 is as least as good as
L2 as soon as the likelihood (here, the necessity or the
possibility) of the event the utility of L1 is as least as
good as the utility of L2 is greater or equal to the likelihood of the event the utility of L2 is as least as good
as the utility of L1 . Formally:
L1 ≥LN L2 ⇐⇒ N (L1 ≥ L2 ) ≥ N (L2 ≥ L1 ), (12)

L1 ≥LΠ L2 ⇐⇒ Π(L1 ≥ L2 ) ≥ Π(L2 ≥ L1 )

(13)

where Π(L1 ≥ L2 ) = supu1i ,u2i s.t. u1i ≥u2i min(λ1i , λ2i )
and N (L1 ≥ L2 ) = 1−supu1i ,u2i s.t. u1i <u2i min(λ1i , λ2i ).
The preference order induced on the lotteries is not
transitive, but only quasitransitive: obviously L1 >N
L2 and L2 >LN L3 implies L1 >LN L3 (resp. L1 >LΠ
L2 and L2 >LΠ L3 implies L1 >LΠ L3 ) but it may
happen that L1 ∼LN L2 , L2 ∼LN L3 (resp. L1 ∼LΠ
L2 , L2 ∼LΠ L3 ) and L1 >LN L3 (resp. L1 >LΠ L3 ).
2.4

Proposition 2. Let L1 , L2 be two lotteries such
that
max ui ≤
max ui .
It holds that
ui ∈L2 ,λi >0

ui ∈L1 ,λi >0

ChN (Reduction(h1/L1 , 1/L2 i)) ≤ ChN (L1 ).
No such property holds for ChΠ , as shown by the following counter example:
Counter Example 1. Let U = {0, 1, . . . , 9},
L1 = h0.2/0, 1/2, 0.5/9i, L2 = h0.4/4, 1/7i4
and
L3
=
Reduction(h1/L1 , 1/L2 i)
=
h0.2/0, 1/2, 0.4/4, 1/7, 0.5/9i.
We can check that
ChΠ (L1 ) = 5.5 and ChΠ (L3 ) = 8.

Possibilistic Choquet integrals

In presence of heterogeneous information, i.e. when
the knowledge about the state of the world is possibilistic while the utility degrees are numerical and
compensatory the previous models cannot be applied
anymore. Following [18] Choquet integrals appear as
a right way to extend expected utility to non Bayesian
models. Like the EU model, this model is a numerical,
compensatory, way of aggregating uncertain utilities.
But it does not necessarily resort on a Bayesian modeling of uncertain knowledge. Indeed, this approach
allows the use of any monotonic set function 3 , and
thus of a necessity measure.
As the qualitative case, but assuming that the utility degrees have a richer, cardinal interpretation, the
utility of L is given by a Choquet integrals:
Chµ (L) = Σi=1,n (ui − ui−1 ) . µ(L ≥ ui ).

(14)

If µ is a probability measure then Chµ (L) is simply
the expected utility of L. In the present paper, we are
interested in studying the possibilistic framework for
decision making: for cautious (resp. adventurous) decision makers, the capacity µ is the necessity measure
N (resp. the possibility measure Π):
ChN (L) = Σi=1,n (ui − ui−1 ) . N (L ≥ ui ).

(15)

ChΠ (L) = Σi=1,n (ui − ui−1 ) . Π(L ≥ ui ).

(16)

From Equations (5) and (15), it can be shown that:
Proposition 1.
Given a lottery L = hλ1 /u1 , . . . , λn /un i, an utility ui s.t. ui ≤
max uj and a lottery L′ =
uj ∈L,λj >0
hλ′1 /u1 , . . . , λ′n /un i s.t. λ′i ≥ λi and
it holds that ChN (L′ ) ≤ ChN (L).

∀j 6= i, λ′j = λj ,

This emphasizes the pessimistic character of ChN :
adding to a lottery any consequence that is not better than its best one decreases its evaluation. As a
consequence, we get the following result
3
This kind of set function is often called capacity or
fuzzy measure.

3

Possibilistic decision trees

Decision trees are graphical representations of sequential decision problems under the assumption of full observability. A decision tree is a tree T = (N , E) whose
set of nodes, N , contains three kinds of nodes:
• D = {D0 , . . . , Dm } is the set of decision nodes
(represented by rectangles). The labeling of the
nodes is supposed to be in accordance with the
temporal order i.e. if Di is a descendant of Dj ,
then i > j. The root node of the tree is necessarily
a decision node, denoted by D0 .
• LN = {LN1 , . . . , LNk } is the set of leaves, also
called utility leaves: ∀LNi ∈ LN , u(LNi ) is the
utility of being eventually in node LNi . For the
sake of simplicity we assume that only leave nodes
lead to utilities.
• C = {C1 , . . . , Cn } is the set of chance nodes
represented by circles. For any Xi ∈ N , let
Succ(Xi ) ⊆ N be the set of its children. For
any Di ∈ D, Succ(Di ) ⊆ C: Succ(Di ) is the set of
actions that can be decided when Di is observed.
For any Ci ∈ C, Succ(Ci ) ⊆ LN ∪ D: Succ(Ci ) is
the set of outcomes of the action Ci - either a leaf
node is observed, or a decision node is observed
(and then a new action should be executed).
The size of T is its number of edges (the number of
nodes is equal to the number of edges plus 1).
In classical, probabilistic, decision trees the uncertainty pertaining to the possible outcomes of each
Ci ∈ C, is represented by a conditional probability distribution pi on Succ(Ci ), such that ∀N ∈ Succ(Ci ),
pi (N ) = P (N |path(Ci )) where path(Ci ) denotes all
the value assignments to chance and decision nodes
on the path from the root node to Ci . In this work,
4
For the sake of simplicity, we shall forget about the
utility degrees that receive a possibility degree equal to
0 in a lottery, i.e. we write h0.2/0, 1/2, 0.5/9i instead of
h0.2/0, 1/2, 0/3, 0/4, 0/5, 0/6, 0/7, 0/8, 0.5/9i.






























lottery and can be reduced to an equivalent simple one.
Formally, the composition of lotteries will be applied
from the leafs of the strategy to its root, according to
the following recursive definition for any Ni in N :

L(δ(Ni ), δ) if Ni ∈ D


Reduction(hπi (Xj )/L(Xj , δ)Xj ∈Succ(Ni ) i)
L(Ni , δ) =

 if Ni ∈ C
h1/u(Ni )i if Ni ∈ LN
(17)




























Figure 1: Example of possibilistic decision tree with
C = {C1 , C2 , C3 , C4 , C5 , C6 }, D = {D0 , D1 , D2 } and
LN = U = {0, 1, 2, 3, 4, 5}.

we obviously use a possibilistic labeling (see Figure 1).
The difference with probabilistic decision trees is that
the chance nodes are viewed as possibilistic lotteries.
More precisely, for any Ci ∈ C, the uncertainty pertaining to the more or less possible outcomes of each Ci
is represented by a conditional possibility distribution
πi on Succ(Ci ), such that ∀N ∈ Succ(Ci ), πi (N ) =
Π(N |path(Ci )).
Solving the decision tree amounts at building a strategy
that selects an action (i.e. a chance node) for each
reachable decision node. Formally, we define a strategy
as a function δ from D to C ∪ {⊥}. δ(Di ) is the action
to be executed when a decision node Di is observed.
δ(Di ) = ⊥ means that no action has been selected
for Di (because either Di cannot be reached or the
strategy is partially defined). Admissible strategies
must be:
- sound : ∀Di ∈ D, δ(Di ) ∈ Succ(Di ) ∪ {⊥}.
- complete: (i) δ(D0 ) 6= ⊥ and (ii) ∀Di s.t. δ(Di ) 6=
⊥, ∀N ∈ Succ(δ(Di )), either δ(N ) 6= ⊥ or N ∈ LN .
Let ∆ be the set of sound and complete strategies that
can be built from T . Any strategy in ∆ can be viewed
as a connected subtree of T whose edges are of the
form (Di , δ(Di )). The size of a strategy δ is the sum
of its number of nodes and edges, it is obviously lower
than the size of the decision tree.
Strategies can be evaluated and compared thanks to
the notion of lottery reduction. Recall indeed that leaf
nodes in LN are labeled with utility degrees. Then a
chance node can be seen as a simple lottery (for the
most right chance nodes) or as a compound lottery (for
the inner chance nodes). Each strategy is a compound

Equation (17) is simply the adaptation to strategies of
lottery reduction (Equation (5)). We can then compute Reduction(δ) = L(D0 , δ): Reduction(δ)(ui ) is
simply the possibility of getting utility ui when δ is
applied from D0 . Since, the operators max and min
are polytime Equation (17) define a polytime computation of the reduced lottery.
Proposition 3. For any strategy δ in ∆, an equivalent
simple possibilistic lottery can be computed in polytime.
We are now in position to compare strategies, and thus
to define the notion of optimality. Let O be one of the
criteria defined in Section 2 (i.e. depending on the
application, ≥O is either ≥LΠ , or ≥LN , or the order
induced by Upes , or by Uopt , etc.). A strategy δ ∈ ∆,
is said to be optimal w.r.t. ≥O iff:
∀δ ′ ∈ ∆, Reduction(δ) ≥O Reduction(δ ′ ).

(18)

Notice that this definition does not require the full
transitivity (nor the completeness) of ≥O and is meaningful as soon as the strict part of ≥O , >O , is be transitive. This means that it is applicable to the preference
relations that rely on the comparison of global utilities
(qualitative utilities, binary utility, Choquet integrals)
but also to ≥LN and ≥LΠ . We show in the following
that the complexity of the problem of optimization depends on the criterion at work.

4

On the complexity of decision
making in possibilistic decision trees

Finding optimal strategies via an exhaustive enumeration of ∆ is a highly computational task. For instance,
in a decision tree with n decision nodes and a branching factor√equal to 2, the number of potential strategies
is in O(2 n ). For standard probabilistic decision trees,
where the goal is to maximize expected utility, an optimal strategy can be computed in polytime thanks to
an algorithm of dynamic programming which builds
the best strategy backwards, optimizing the decisions
from the leaves of the tree to its root.
Regarding possibilistic decision trees, [5] shows that
such a method can also be used to get a strategy max-

imizing Upes and Uopt . The reason is that like EU, Upes
satisfies the key property of weak monotonicity. We
formulate it for any criterion O over possibilistic lotteries: ≥O is said to be weakly monotonic iff whatever
L, L′ and L”, whatever (α,β) such that max(α, β) = 1:
L ≥O L′ ⇒ (α ∧ L) ∨ (β ∧ L”) ≥O (α ∧ L′ ) ∨ (β ∧ L”).
(19)
This property states that the combination of L (resp.
L′ ) with L”, does not change the initial order induced
by O between L and L′ - this allows dynamic programming to decide in favor of L or L′ before considering
the compound decision. The principle of backwards
reasoning procedure is depicted in a recursive manner
by Algorithm 1 for any preference order ≥O among
lotteries. When each chance node is reached, an optimal sub-strategy is built for each of its children these sub-strategies are combined w.r.t. their possibility degrees, and the resulting compound strategy
is reduced: we get an equivalent simple lottery, representing the current optimal sub-strategy. When a
decision node X is reached, a decision Y ∗ leading to a
sub-strategy optimal w.r.t. ≥O is selected among all
the possible decisions Y ∈ Succ(X), by comparing the
simple lotteries equivalent to each sub strategies.
This procedure crosses each edge in the tree only once.
When the comparison of simple lotteries by ≥O (Line
(2)) and the reduction operation on a 2-level lottery
(Line (1)) can be performed in polytime, its complexity is polynomial w.r.t. the size of the tree. Then:
Proposition 4. If ≥O satisfies the monotonicity property, then Algorithm 1 computes a strategy optimal
w.r.t. O in polytime.
We will see in the following that, beyond Upes and Uopt
criteria, several other criteria satisfy the monotonicity
property and that their optimization can be managed
in polytime by dynamic programming. The possibilistic Choquet integrals, on the contrary, do not satisfy
weak monotonicity; we will show that they lead to NPComplete decision problems. Formally, for any of the
optimization criteria of Sections 2.2 to 2.4, the corresponding decision problem can be defined as follows:
[DT-OPT-O] (Strategy optimization w.r.t. an optimization criterion O in possibilistic decision trees)
INSTANCE: A possibilistic decision tree T , a level α.
QUESTION: Does there exist a strategy δ ∈ ∆ such
as Reduction(δ) ≥O α?
For instance DT-OPT-ChN corresponds to the optimization of the necessity-based Choquet integrals.
DT-OPT-Upes and DT-OPT-Uopt correspond to the
optimization of the possibilistic qualitative utilities
Upes and Uopt , respectively.

Algorithm 1: Dynamic programming
Data: In: a node X, In/Out: a strategy δ
Result: A lottery L
begin
for i ∈ {1, . . . , n} do L[ui ] ← 0
if N ∈ LN then L[u(N )] ← 1
if N ∈ C then
% Reduce the compound lottery
foreach Y ∈ Succ(N ) do
LY ← P rogDyn(Y, δ)
for i ∈ {1, . . . , n} do
L[ui ] ←
max(L[ui ], min(πN (Y ), Ly [ui ])) (Line (1))
if N ∈ D then
% Choose the best decision
Y ∗ ← Succ(N ).f irst
foreach Y ∈ Succ(N ) do
LY ← P rogDyn(Y, δ)
if LY >O LY ∗ then Y ∗ ← Y (Line (2))
δ(N ) ← Y ∗
L ← LY ∗
return L
end

4.1

Possibilistic qualitative utilities
(Upes , Uopt , P U )

Possibilistic qualitative utilities Upes and Uopt satisfy
the weak monotonicity principle. Although not referring to a classical, real-valued utility scale, but to a 2
dimensional scale, this is also the case of P U .
Proposition 5. ≥Upes , ≥Uopt and ≥P U satisfy the
weak monotonicity property.
As a consequence, dynamic programming applies to
the optimization of these criteria in possibilistic decision trees. Although not explicitly proved in the literature, Proposition 5 is common knowledge in possibilistic decision theory. It is also known that dynamic
programming applies to the optimization of Upes , Uopt
and P U in possibilistic Markov decision processes and
thus to decision trees (see [5, 14, 17]).
Corollary 1. DT-OPT-Upes , DT-OPT- Uopt and
DT-OPT-P U belong to P .
4.2

Possibilistic likely dominance (LN, LΠ)

Fortunately, the optimization of the possibilistic likely
dominance criteria also belongs to P. Indeed:
Proposition 6. ≥LΠ and ≥LN satisfy the weak
monotony principle
Algorithm 1 is thus sound and complete for ≥LΠ and
≥LN , and provides in polytime any possibilistic decision tree with a strategy optimal w.r.t. these criteria.
Corollary 2. DT − OP T − LN and DT − OP T − LΠ
belong to P .

It should be noticed that, contrarily to what can be
done with the three previous rules, the likely dominance comparison of two lotteries will be reduced to
a simple comparison of aggregated values (Line (2))
Anyway, since only one best strategy is looked for, the
transitivity of >LΠ (resp. >LΠ ) guarantees the correctness of the procedure - the non transitivity on the
indifference is not a handicap when only one among
the best strategies is looked for. The difficulty would
be raised if we were looking for all the best strategies.
4.3

Possibilistic Choquet integrals (ChN , ChΠ )

The situation is thus very confortable with qualitative
utilities, binary possibilistic utility and likely dominance. It is much lesser comfortable for the case of
numerical utilities, i.e. when the aim is to optimize
a possibilistic Choquet integral (either ChN or ChΠ ).
The point is that the possibilistic Choquet integrals
(as many other Choquet integrals) do no satisfy the
monotonicity principle:
Counter Example 2 ( From [11] ). Let L =
h0.2/0, 0.5/0.51, 1/1i, L′ = h0.1/0, 0.6/0.5, 1/1i and
L” = h0.01/0, 1/1i.
L1 = (α ∧ L) ∨ (β ∧ L”) and L2 = (α ∧ L′ ) ∨ (β ∧ L”),
with α = 0.55 and β = 1. Using Equation (5)
we have: Reduction(L1 ) = h0.2/0, 0.5/0.51, 1/1i and
Reduction(L2 ) = h0.1/0, 0.55/0.5, 1/1i.
Computing ChN (L) = 0.653 and ChN (L′ ) = 0.650 we
get L ≥ChN L′ . But ChN (Reduction(L1 )) = 0.653 <
ChN (Reduction(L3 )) = 0.675, i.e. (α ∧ L) ∨ (β ∧
L”) <ChN (α ∧ L′ ) ∨ (β ∧ L”): this contradicts the
monotonicity property.
Let L
=
h1/0, 0.5/0.51, 0.2/1i,
L′
=
h1/0, 0.6/0.5, 0.1/1i and L” = h1/0, 0.49/0.51i.
L1 = (α ∧ L) ∨ (β ∧ L”) and L2 = (α ∧ L′ ) ∨ (β ∧ L”),
with α = 1 and β = 0.55. Using Equation (5) we
have: Reduction(L1 ) = h1/0, 0.5/0.51, 0.2/1i and
Reduction(L2 ) = h1/0, 0.6/0.5, 0.49/0.51, 0.1/1i.
Computing ChΠ (L) = 0.353 and ChΠ (L′ ) = 0.350
we get L >ChΠ L′ . But ChΠ (Reduction(L1 )) =
0.3530 < ChΠ (Reduction(L2 )) = 0.3539, i.e.
(α ∧ L) ∨ (β ∧ L”) <ChΠ (α ∧ L′ ) ∨ (β ∧ L”): this
contradicts the monotonicity property.
Proposition 7. DT − OP T − ChN and DT − OP T −
ChΠ are NP-Complete.

5

Extension to Order of Magnitude
Expected Utility

Order of Magnitude Expected Utility theory relies on a
qualitative representation of beliefs, initially proposed
by Spohn [19], via Ordinal Conditional Functions, and
later popularized under the term kappa-rankings. κ :

2Ω → Z + ∪ {+∞} is a kappa-ranking if and only if:
S1 minω∈Ω κ({ω}) = 0
6 A ⊆ A, κ(∅) = +∞
S2 κ(A) = minω∈A κ({ω}) if ∅ =
Note that event A is more likely than event B if
and only if κ(A) < κ(B): kappa-rankings have been
termed as disbelief functions. They receive an interpretation in terms of order of magnitude of small probabilities. κ(A) = i is equivalent to P (A) is of the same
order of εi , for a given fixed infinitesimal ε. There
exists a close link between kappa-rankings and possibility measures, insofar as any kappa-ranking can be
represented by a possibility measure, and vice versa.
Order of magnitude utilities have been defined in the
same way [13, 20]. Namely, an order of magnitude
function µ : X → Z + ∪ {+∞} can be defined in order
to rank outcomes x ∈ X in terms of degrees of “dissatisfaction”. Once again, µ(x) < µ(x′ ) if and only
if x is more desirable than x′ , µ(x) = 0 for the most
desirable consequences, and µ(x) = +∞ for the least
desirable consequences. µ is interpreted as: µ(x) = i
is equivalent to say that the utility of x is of the same
order of εi , for a given fixed infinitesimal ε. An order
of magnitude expected utility (OMEU) model can then
be defined (see [13, 20] among others). Considering
an order of magnitude lottery L = hκ1 /µ1 , . . . , κn /µn i
as representing a some probabilistic lottery, it is possible to compute the order of magnitude of the expected utility of this probabilistic lottery: it is equal to
mini=1,n {κi + µi }. Hence the definition of the OMEU
value of a κ lottery L = hκ1 /µ1 , . . . , κn /µn i:
OM EU (L) = min {κi + ui }.
i=1,n

(20)

The preference relation ≥OM EU is thus defined as:
L ≥OM EU L′ ⇐⇒ OM EU (L) ≤ OM EU (L′ ). (21)
We shall now define kappa decision trees: for any
Ci ∈ C, the uncertainty pertaining to the more or less
possible outcomes of each Ci is represented by a kappa
degree κi (N ) = M agnitude(P (N |past(Ci ))), ∀N ∈
Succ(Ci ) (with the normalization condition that the
degree κ = 0 is given to at least one N in Succ(Ci )).
According to the interpretation of kappa ranking in
terms of order of magnitude of probabilities, the product of infinitesimal the conditional probabilities along
the paths lead to a sum of the kappa levels. Hence the
following principle of reduction of the kappa lotteries:
Reduction(κ1 ∧ L1 ∨ · · · ∨ κm ∧ Lm )
= h min (κj1 + κj )/u1 , . . . , min (κjn + κj )/un i.
j=1..m

(22)

j=1..m

The last result of this paper is that OMEU satisfies
the weak monotonicity principle:

Proposition 8. ∀L, L′ , L” ∈ L,
OM EU (L) ≥ OM EU (L′ )
⇒ OM EU ((α∧L)∨(β ∧L”)) ≥ OM EU ((α∧L′ )∨(β ∧L”))

As a consequence dynamic programming is sound and
complete for the optimization of Order of Magnitude
Expected Utility:
Corollary 3. There exists a polynomial algorithm for
finding a strategy optimal w.r.t. the Order of Magnitude Expected Utility for any kappa decision tree.

6

Conclusion

In this paper, we have shown that the strategy optimization in possibilistic decision trees is tractable
for most of the criteria, extending the results about
the qualitative utility criteria to other criteria, namely
the likely dominance rule. We have also shown that
the problem is intractable for the Choquet-based criteria. Finally, we have extended this work to OMEU,
defining a new model for sequential decision trees, extending the notion of reduction to kappa lotteries and
showing that this models obey the weak monotonicity principle. These results are summarized in Table
1. It should be noticed that the optimization of the
Table 1: Results about the complexity of DT − OP T .
Upes Uopt P U
ChN
ChΠ
LΠ LN OMEU
P
P
P NP-hard NP-hard P P
P
possibilistic Choquet integrals is ”only” NP-hard: the
computation of the Choquet value of a possibilistic
strategy is polynomial, whereas this computation can
be more costly for other capacity measures; for instance computing the Choquet value of a strategy on
the basis of its multi prior expected utility is itself a
NP-hard problem - and the corresponding optimization problem is probably beyond NP. So, it appears
that the use of possibilistic decision criteria does not
lead to an increase in complexity, except for Choquet
integrals. This is good news and allows the extension
of our work to possibilistic decision diagrams. Concerning the Choquet case, further work includes the
development of a direct evaluation algorithm for possibilistic influence diagrams where possibilistic Choquet
integrals are used as a decision criteria inspired by the
variable elimination approach.

