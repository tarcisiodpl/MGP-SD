
This paper investigates the possibility of
performing automated reasoning in probabilistic
logic when probabilities are expressed by means
of linguistic quantifiers. Each linguistic term is
expressed as a prescribed interval of proportions.
Then instead of propagating numbers, qualitative
terms are propagated in accordance with the
numerical interpretation of these terms. The
quantified syllogism, modelling the chaining of
probabilistic rules, is studied in this context. It
is shown that a qualitative counterpart of this
syllogism makes sense, and is relatively
independent of the threshold defining the
linguistically meaningful intervals, provided that
these threshold values remain in accordance with
the intuition. The inference power is less than
that of a full-fledged probabilistic constraint
propagation device but better corresponds to
what could be thought of as commonsense
probabilistic reasoning.
1

INTRODUCTION

Precise values of probabilities are not always available.
Experts often assess probabilities under the form of
intervals (e.g. "between 80 and 90 % of A's are B's") or
even linguistically (e.g. "almost all A's are B's"), or are
only able to rank-order probability values, stating that a
probability is certainly greater than another. Thus it
raises the question of the possibility of reasoning with
probabilities in a qualitative way. The main appeal of a
qualitative approach (when such an approach is feasible),
is that it requires less precision than a pure numerical
representation while still leading to meaningful
conclusions in the reasoning process. Also, the
qualitative approach allows us to have a better interface
with human users, in a way more compatible with their
own reasoning processes. The idea of reasoning
qualitatively with probabilities has been investigated
along different lines by various researchers in Artificial
Intelligence especially in the last five years. A first
family of approaches works with inequalities between
probabilities (e.g.Wellman (1990)). A second type of
approach considers probability-like functions which take

Lluis Godo
Ramon L6pez de Mantaras

Institut d'Investigacio en Intelligencia Artificial
CEAB-CSIC
Cami de Santa Barbara
17300 Blanes, Spain

their values in a finite totally ordered set not related to
[0,1] (e.g.Yang, Beddoes and Poole, 1990). Another kind
of qualitative probability approach is Adams (1975)'
conditional logic (see also Pearl (1988)) which
manipulates infinitesimal probabilities. For the sake of
brevity we do not mention other logical approaches to
probabilities here.
The approach developed in this paper maintains an
interpretation of qualitative (linguistic) probability values
in terms of numerical intervals. Here, linguistic
quantifiers such as most, few, etc ... are viewed as
imprecisely or fuzzily known conditional probabilities,
i.e. terms represented by crisp, or in the most general
case, fuzzy subintervals of [0,1] (Zadeh, 1985 ; Dubois
and Prade, 1988). Here, an ordered set of elementary
labels of quantifiers is chosen in order to provide a
linguistic scale for conditional probabilities (or
proportions) used in default rules like "Q A's are B's",
where Q is viewed as the answer to the question : "how
many A's are B's ?". A qualitative algebra (Q-algebra)
(Trave-Massuyes and Piera, 1989) is defined on the set of
possible labels, built from the elementary labels forming
the scale. Inference rules which are the qualitative
counterparts of numerical formulas for computing bounds
on probabilities in quantified syllogisms or similar
propagation rules, can be proposed for reasoning in
qualitative probability networks.
The next section discusses how to build a set of
linguistic labels to be used in the qualitative probability
computations. Section 3 gives the necessary background
about local patterns of inference used to propagate
constraints on probabilities known to belong to intervals.
Section 4 defines qualitative versions of these rules of
inference. Section 5 discusses the robustness of the
approach, i.e. to what extent the qualitative calculus
remains unchanged when the numerical interpretation of
the linguistic labels is slightly modified. A qualitative
analysis of inference rules in Adams' probabilistic logic
is given in Section 6. Section 7 discusses the problems
encountered when trying to develop a qualitative
constraint propagation rule based on Bayes theorem.
Section 8 gives an example and shows how the constraint
propagation-based strategy, recalled in Section 3, to
answer queries about conditional probabilities can be
adapted to the qualitative setting.

A Sym bo l ic Approach to Reasoning with L in gu is tic Quantifiers

2

LATTICES OF LABELS

Let us consider an ordered set of elementary labels of
linguistic quantifiers that may account for any probability
value. Each label corresponds to a subinterval of the unit
interval, and the set of labelled subintervals completely
covers it. So a linguistic scale will be made of the labels
of a collection of subintervals covering (0,1] of the form
[an-1· an ], [an, 1), 1}. For
{0, (0, a11. (at, a21
•

... ,

convenience we shall call a "partition" such a collection,
although the intervals overlap at their edges, except in 0
and 1 which are dealt with separately due to their
particular meanings corresponding to 'none' and 'all'.

Let fP be a partition of [0,1] in subintervals representing
quantifiers from a linguistic scale. By convention, both
the linguistic scale and the corresponding partition will
be denoted fP. It seems reasonable that this linguistic
scale should be symmetric with respect to 0.5 since the
antonym of each linguistic quantifier in the scale should
also be in the scale. Linguistic antony my, for instance
ANT(Almosr none) =Almost all or ANT(Few) = Most,
is expressed at the numerical level by relations like
ANT([a,b]) = [1 - b, 1 -a], since intervals are used to
represent the meaning of linguistic quantifiers. As a
consequence if P(A) is the probability of event A,
linguistically qualified by X E fP, then P(A) the
probability of the complementary event A should be
ANT(X} E fP.

The universe of description U induced by a partition fP is
defined as the set of intervals that are union of adjacent
elements of fP. The set inclusion relationship (�:;)
provides U with an ordered structure that has a tree
representation. For instance, if we take parameters "a" and
"b" to be smaller than 0.5, then [0,1] can be (non
strictly) symmetrically partitioned as

Fi!Nre 1 :

The set of elementary (most specific) linguistic
quantifiers can also be ordered according to the usual
certainty ordering in the unit interval :

None� Almost none� Few� About half� Most�
Almost all � All
This ordering enables us to consider higher level elements
of the universe U as intervals defined on the partition set,
for instance, [Few Most] = {X E fP I Few s; X :S Most)
and it is fully compatible with the above numerical
interpretation in terms of probability intervals. The
semantics of the higher level elements of the universe
corresponds to the convex hull of the intervals attached to
their edges. For instance, the (numerical} interpretation of
[Few Most}, i.e. 'From few to most', is the interval
[a, 1-a}. The certainty ordering can be partially extended
to the whole universe U as well, by defining for every
[Xt. Y1 ], [X2, Y2] E U
[XI, YI] =:;; [X2, Y2] if, and only if, Xt s; X2 and
Y1 :S Y2,

iP = { 0, (O,a], [a, b], [b, 1-b], [1-b, 1 -a],
[1-a, 1), 1}

corresponding to the following linguistic quantifiers :
0 ::=None
(0, a] ::=Almost none (Al-none for short)
[a, b} ::=Few
[b, 1-b] ::=About half (Ab-half for short)
[1 - b, 1 -a] ::=Most
[1 - a, 1} ::=Almost all (Al-a/1 for short)
1 ::=All
The set fP constitutes the highest meaningful level of
specificity with respect to the language. Between this
level and the least specific one (i.e. the whole interval
[0, 1]), the universe of description U contains several
internal ordered levels of specificity. For example, with
the seven terms defined above we have five levels in
between ; see Figure 1.

Specificityorderinl{

giving rise to a structure which differs from the previous
one. Such a double ordering structure is in accordance
with bilattices as discussed in (Ginsberg, 1988).

3

LOCAL PROPAGATION OF
INTERVAL-VALUED
PROBABILITIES

In (Amarger, Dubois and Prade, 1991b), a local
computation approach which deals with interval-valued
conditional probabilities is presented. In the approach a
basic pattern for local inference is the following so-called
'quantified syllogism' :
P(BIA)E [P* (BIA),P*(BIA)]; P(AIB}E [P*(AIB),P*(AIB)]
P(CIB)e [P*(CIB),P*(CIB)];P(BIC} e [P*(BIC),P*(BIC)]
P(CIA)

=

?

P(AIC) = ?

75

76

Dubois, Prade, Godo, and Lopez de Mantaras

where P• and P* respectively denote lower and upper
bounds, and where we want to compute (the tightest)
bounds which can be deduced for P(CIA) and P(AIC).
The following bounds have been established in (Dubois
and Prade, 1988; Dubois, Prade and Toucas, 1990) and
have been shown to be the tig htes t ones when P(BIA),
P(AIB), P(BIC) and P(CIB) are precisely known (i.e.
P(BIA) = P•(BIA) = P*(BIA), etc.), and are different from
0 or 1:

(

lower bound :
P•(CIA)

==

P•(BIA) max 0, 1 -

l

; ��(��

B)

.

)

upper bound :
P*(CIA);:;
1'
min

l

_

p•(BIA)+

P•(BIA)·P*(CIB)
P•(AIB)

'

P * (BIA) ·P * (CIB)
'
P•(AIB)·P•(BIC)

[1- P•(BIC)] + P"' (BIA)
P•(AIB) P•(BIC)
Related local patterns of inference for interval-valued
conditional probabilities have been independently
developed by Guntzer, KieBling and TMne (1991), Thane
et al. (1991a) and by Heinsohn (1991) in the contexts of
deductive data bases and of terminological languages
respectively. Wh il e the above lower bound is still
optimal when only bounds are known on P(BIA), P(AIB)
and P(CIB), Thline, Gilntzer and KieBling (1991b) have
recently pointed out that the above upper bound can be
improved when only lower and upper bounds on the
probabilities are available in the syllogism. This is
basically due to the fact that the third and fourth tenns are
linearly increasing with respect to P(BIA) while the
second term is linearly decreasing in P(BIA) if P*(CIB) <
P.(AIB). These authors show that the above upper bound
becomes optimal provided that we add the following fifth
term in the above minimum of four terms :
·

P*(CIB)
·

(P •(AIB) - P * (CIB))

This fifth term is simply obtained by computing the
value of P(BIA) that makes the second and third term
equal. This fifth term does improve the upper bound if
and only if P•(AIB) > P*(CIB), and moreover the interval
[P•(BIA),P*(BIA)] contains the quantity
�(BIC) · P.(AIB)
�(BIC) ·�(AlB) + P*(CIB)

·

(1- �(BIC))

The local inference approach proposed in Amarger et al.
(1991b) also takes advantage of an extended form of
Bayes rule expressed in tenns of conditional probabilities
only, namely

=

k-1

P(Ak1A1) fi

i=l

P(AjiAi+l)
P(Ai+tiAi)

(with all involved quantities positive), from which useful
inequalities are obtained in the case where only lower and
upper bounds are available.
The constraint propagation method which is used is the
following : recursively apply the quantified syllogism to
generate upper and lower boWJds of missing probabilities.
This step is performed until the probability intervals can
no longer be improved. Then recursively apply the
extended Bayes rule to improve the bounds thus
generated, and continue the whole procedure until no
improvement takes place. This constraint propagation
method can somet imes give bounds as tight as the best
ones computed by a global optimization method based on
linear programming (see Amarger et al., 1991b).
4
4.1

p * (BIA). p * (CIB)

P * (CIB) + P>�<(BIC)

VA1,... ,Ak, P(A11Ak)

THE QUALITATIVE QUANTIFIED
SYLLOGISM
COMPUTATION OF THE
QUALITATIVE TABLE

In this section we will focus on the qualitative
counterpart of the quantified syllogism inference pattern,
recalled in the preceding section. We use the following
notations, where Qi are linguistic labels.
Ql A's are B's; Q2 B's are A's
Q3 C's are B's ; Q4 B's are C's
QS A's are C's; Q6 C's are A's
This inference rule is interesting from the point of view
of commonsense reasoning since it offers a precise model
of chaining uncertain "if... then ..." statements expressed
by means of imprecise quantifiers or conditional
probabilities. In the following we build the qualitative
functions (Q-fWictions) corresponding to that pattern, i.e.
we build a table giving qualitative values for Q5 and Q6
for any combi na ti on of possible qualitative values for
Ql, Q2, Q3 and Q4.
The process of building the Q-functions is perfonned
according to the following steps :
1. Consider a linguistic scale of linguistic quantifiers
together with a suitable partition of the unit interval
[0,1] that represents them. In what follows we will
use the partition gp defined above with parameters a =
0.2, and b = 0.4, that is, (0,0.2] = Almost none ;
[0.2, 0.4] =Few; [0.4,0.6] ;; About half; [0.6,0.8] =
Most; [0.8,1) =Almost all.
2. Consider all possible combinations of these linguistic
values for P(BIA), P(AIB), P(BIC) and P(CIB).
3. For each of such combinations, compute the lower
and upper bounds of P(CJA) (and P(AIC)) using the
numerical expression of the pattern given in Section

A Symbolic Approach to Reasoning with Linguistic Quantifiers

3. For example if Q1 = Most, Q2 =Almost all, Q3 =
About half, Q4 = Almost all, then :
P*(BIA) = 0.8
P*(AIB) = 1
P*(BIC) = 0.6
P*(CIB) = 1
which gives
P*(CIA) = 1
P*(AIC) 1

P.(BIA) =0.6
P•(AIB) = 0.8
P•(BIC) = 0.4
P•(CIB) = 0.8
P•(CIA) =0.45
P•(AIC) = 0.3.

=

4. These results are then approximated by means of the
most specific element of the universe of description U
(see Figure 1) which contains them. So, the interval
[0.45, 1] for P(CIA) is approximated to the larger
interval [0.4, 1], that is, the resulting Q5 is set to
[About-half, All]. In the same way, Q6 is
approximated to [Few, All].ln this way, we have
partially defined the qualitative functions QS and Q6,
i.e. defined as functions
Q5, Q6 : fP

X

fP

X

fP

X

fP -----> U.

5 . Finally, the complete definition of the qualitative
functions Q5, Q6 : U x U x U x U ------> U can be
easily derived from the above partially defined ones by
simply applying them on the upper and lower bounds
(which are elements of ;?) of the non-elementary
elements of U, and then taking the convex hull. For
instance:
QS([Most, All], All, [None, All], Almost-all) =
= convex_hull_of(QS(Most, All, None, Almost-all),
Q5(All, All, None, Almost-all), QS(Most, All, All,
Almost-all), Q5(All, All, All, Almost-all) )
= convex_hull_of([About-half, All], Almost-all,
[About-half, Most], Almost-all) = [About-half, All]
:

Note that in the above procedure, the
qualitative calculation table for the quantified syllogism
is computed by using the approximation step only at the
end of the computation. Another approach one may think
of would be to have precomputed tables for product and
quotient, and to use them in the calculation of the
bounds. However this latter approach would not be
satisfactory because it yields too imprecise results.
Remark

4. 2

THE 5-QUANTIFIER CASE

In this section we analy se the results obtained on the
most elementary type of qualitative scale of linguistic
quantifiers, i.e. (none, few, about half, most, all) where
few is of the form [E,a] for some positive, infinitesimal
value E, a is some number in (0, 1/2), about half is
interpreted as [a, 1 -a], and most is [1 -a, 1-E] .
Note that the name "about half' is indeed short for
"neither few nor most, but in between", since the interval
[a, 1- a] may be quite imprecise.
Table 1 gives the complete results when a = 0.3 ; the
table is sorted by putting together the 4-tuples (Q1 Q2
Q3 Q4) that lead to the same value of QS. A first remark

is that in many situations when none of the quantifiers
mean "all", no information is obtained on P(CIA). This
is especially true when both P(AIB) and P(BIA) take
small qualitative values. Some lines of the table may
look surprising. For instance we see that nothing can be
inferred from the four statements
"all A's are B's"; "most B's are A's"
"all C's are B's"; "about half of the B's are C's".
Especially, the lower bound P•(CIA) =0 is attained in
this case if pessimistic interpretations of "most" and
"about half' are chosen, say 70% and 30% respectively.
P(BIA)

P(AIB)

P(CIB)

P(CIA)

none

none

[none,most]

[none,all]

[none,all]

few

few

[few,most]

{few,most]

few

half

[few,half]

{few,most]

few

most

[few,halfl

half

[half,all]

most

[few,most]

half

[half,all)

[few,half]

[few,most]

[few,most]
[few,most]

P(BJC)

all

[few,half]

aU

all

most

aU

half

few

[few,aU)

none

none

few

half

most

most

[few,half]

most

few

few

most

[few,half]

all

[few,most]

most

most

aU

half

few

half

most

[few,half]

few

most

half

few

most

most

half

half

[few,half]

all

[few,most]

half

[few,all]

none

none

most

[few,all]

few
-

few

[few,half]

all

[few,most]

few

most

most

few
[few,half]

few

[most,all]

few

most

all

half

most

all

few

most

[few,all]

none

none

none

none

all

[few,all]

[few,all]

none

few

few

none
most

all

few

[few,all]

[few,half]

all

[few,half]

most

[few,half]

most

half

most

most

most

few

half

most

all

few

all

few

all

few

all

half

most

all

[half,most]

half

all

[few,half]
few

few

half

all

most

most

most

all

[few,most]

half

few

[most,all]

most

[most,all]

half

half

all

most

all

half

most

half

all

[non e,half]

[none,few]

(none,none]
[few,all]

[few,most]

[few,most]

half

few

[none, most]

half

few

all

[half,most)

half

all

most

all

[few,most)

few

most

all

all

half

[few,half]

77

78

D ub ois , Prade, Godo, and Lopez de Mantaras

few

[few,all)

all

few

most

all

all
most

half

few

most

[few,half]

all

few

few

all

all

all
[most,all]

[half,most]
few

all

[few,all]

few

all

few
half

all

most
all

all

half

[few,all)

[few,most]

all

most

[few,most]

most

all

most

most

most

all

most

all

most

most

all

[few all]

most

half
all

[few,all]
all

[few,all)

half

most

[few,all)

[few,most]

most
all

[few,all]
all

[few,all]

most

[few,all]

[few,all)

all

all

all

all

P•(CIA)::::max O,l-

all

all

all

[half,all]

[half,most]
[half,half)
[most,all]
[most,most]
fall ,all]

The case P(BIA)
'all' and P(BIC) = 'all' represents a
typical case of statistical inference, when, knowing the
probability P(CIB), and considering some individual in
class B, one tries to say something about its probability
of being a C. Namely B represents a population, C a
subclass of this population for which the proportion or
probability P(CIB) is known. For instance B represents
the inhabitants of some city and C the proportion of
individuals in that population that are older than 60. Now
take an individual xo in B. There are several ways of
=

a

)

( �)

; P"'(CI A)=min l.

itself. Let us consider the situation where P(CIB) > 1/2.
If the degree of typicality t :5 P(CIB) = a then the
probability P(CIA) is no longer upper bounded, but can
be lower than P(CIB) as well. When the typicality t is
low enough, that is t :5 min(P(CIB), 1 - P(CIB)) nothing
can be inferred on P(CIA). It corresponds to the case when
A and C could be disjoint subsets of B. This
phenomenon explains the presence of rows of Table I
where despite the high values of some of the probabilities
the results of the chaining is very imprecise.

S

ROBUS TNES S

=

=

·

few
few
few

half

most

is

viewed as having nothing special). The problem is then:
knowing P(CIB) what is the probability that xo belongs

to C ? This problem can be solved by computing P(CIA)
where A is a maximal subclass of B, of which xo is a
typical element.

This problem corresponds to all rows of Table 1 where
P(BIA)
1 and P(BIC) 1. It can be checked that P(CIA)
can be much more imprecise than P(CIB), since it can be
[none, all] (i.e."unknown") in several cases.
=

This phenomenon can be precisely studied in an
analytical way, letting P(CIB) = a, and P(AIB) = t.
Parameter t can be called a typicality index of set A with
respect to B. It expresses the probability that selecting at
random an individual in B, it lies in A, i.e. it is "like
xo"· The commonsense saying that statistics should be
cautiously used when making decisions about individual
situations can be given a precise form thanks to the
quantified syllogism. When P(AIB) = t, P(BIA) = 1,
P(CIB)=a, P(BIC)= 1, we get the following results on

few
[few, half]

?

?

[few, half]

the choice of the value of a. Namely half
� (0, a] only if

a 2: d, where d

xo

most

few

The question mark '?' indicates some ambiguity due to

xo"·

particular as nobody is like him) to B itself (if

half

few

few

(1 - a )2]

maximal subset of B containing individuals "just like
Note that A can range from [xo} (if xo is so

ANALYSIS

Table 1 is obtained for a specific value of the threshold a
between "few" and "half'. A legitimate question is
whether such results are still valid for other values of the
threshold. Let us start with qualitative tables for product
and quotient, with "few"
(O,a], "most"= [1 -a, I),
"half'
[a, I- a]. The product table is defined as
None Q= None, All · Q= Q, and

considering xo according to its peculiarities. Let A be the

P(CIA):

�

=

Table 1: Compactedtabl e of th e quantifiedsyllogism for
the 5 element Partition ('half means 'about half)

=

1

The only case when P(CIA) can only be equal to P(CIB)
is when t
1, i.e. when the reference class of xo is B

few

[most,all]

(

[few,few]

3

(1 - a )2

- ..[5

•

half= [a2,

::s; a, which requires

"" 0.382 . In that case
2
half * half= few and most • most = [(I - a )2, I) ex.
[a, I) when a > d, so that most * most= [few, most].
The latter equality does not sound natural. On the
contrary if a < d, then half * half = [few, half1 ;
most • most:::: [half, most]. From a commonsense point
of view, it is not very unnatural to require that "few" may
mean a proportion less than .3 or so. Again "half' is here
short for "neither few nor most but in-between". Hence it
is clear that the product of qualitative probabilities is
almost independent of the choice of the threshold a in
(0, I/2). It fits the intuition and is completely threshold­
independent for "a" small enough. The same problem
can be solved for the (bounded) quotient, and it leads to
the following almost-robust table

I
none
few
half
most
all

none
[none, all)
all
all
all
all

few
none
[none, all]
all
all
all

half
none
[few, all)
[half, all]
all
all

most
all
none
none
[few, half) few
half
[half, all]
most
most
all
all

A Symbolic Approach to Reasoning with linguistic Quantifiers

The terms half/half and few/most are given for a< d.
Only these terms change if a is larger. Note that the
subdiagonal part of the table has been truncated to 1 .
In order t o study the robustness o f the quantified
syllogism table, several runs of the program that generate
this table have been done, with a varying between 0.25
and .38. Only a few lines of the qualitative table change
(nine over 625 ""s4 distinct 4-tuples of quantifiers for

.

0 25� a �.35). In order to get a better insight, it is
interesting to consider a significant subpart of the table,
where quantifiers are either "few" or "most", i.e. when
P(AIB), P(BIA), P(CIB), P(BIC) are close to 0 or close to
1. In order to let the p arameter a appear we shall use the
following notation
P(AIB) Vo (a) which means P(AIB) �a
P(AIB) V 1 (a) which means P(AlB) �a.
Then by applying the optimal bounds on P(CIA) as
described in Section 3 on the 16 = 42 4-tuples of
extreme quantifiers, potential instability of the results
was obtained for the 6 following cases only :
P(BIA)
Vrf,a.)

P(AIB)
VJ(I-a)

P(BIC)
Vt(l-a)

P(CIB)
Vrf..a.)

Vrf,a.)

Vt(l-a.)

Vt(l-a)

Vt(l-a)

Vt(l-a)

Vt(l-a)

VrJ..a.)

Vrf..a)

Vt(l-o:)

Vt(l-o:)

VrJ.a)

Vt(l-a)

VJ(l-o:)

VJ(I-o:)

Vt(l-a)

Vrf..a.)

Vt(l-a)

Vt(l-a)

Vt(l-a)

Vt(l-a)

P(CIA)
VrJ.a/-/(1-a)l)
Vo((a.z/(1-a)l)+a.)
Vo(2a.)
VJ(l-2a.)
2 2
Vo(a/((1-a) +a ))
VJ(I-2a.)

most
most
most

most
most
most

few
most
most

most
few
most

[half, all]
[none, half]
[half, all]

When the quantifier "(about) half' is involved in the
inference pattern, the resulting quantifiers P(CIA) may get
more precise (e.g. [few, all] becomes [half, all] when a
becomes smaller). But the table obtained for a = 0.3
remains correct but not optimally precise .

6

A QUALITATIVE ANALYS IS OF
ADAMS' INFERENCE RULES

Adams (1975) has proposed a probabilistic inference
system based on the three inference rules :
triangularity :
Bayes rule:
disjunction :

A � B, A � C � (A " B)� C
A � B, (A " B) � C � A � C
A � C, B � C � (A v B) � C

which are sound when A � B is understood as the
probability P(BIA) � I - £ where e is arbitrarily small.
These rules are used in Pearl (1988) to build a
probabilistic inference-like default logic. It is interesting
to consider finistic semantics for these rules in
relationship with the linguistic probability scale. In this
respect A� B will be interpreted as "most A's are B's".
First it is easy to verify that triangularity and Bayes rule
axioms can be expressed in terms of the quantified
syllogism, of which they are special cases, noticing that

P(BIA)

=

P(AnBIA).

Triangularity : P{A n BIA) = most ; P(AIA n B)
P(CIA) = most; compute P(CIA n B);

=

1 ;

Bayes rule : P(AIA n B) = 1 ; P(A n BIA) = most ;
= most ; compute P(CIA) .

It is easy to verify that for a s; 1/3

P(CIA n B)

a2
�a
--�2;;( 1 - a)

Taking 'most'= [1 - a, 1), we easily get the lower bound
on P(CIA n B) and P(CIA) in each case by using the
quantified syllogism

2a

s;

as;1-2a

1- a

� + a2

(1-a)

$ 1-a (since

�

(1- a) +a 2

(

P(CIA n B) � max 0,1� 2a).

These inequalities guarantee that whatever the v alue of
a $ 1/3 , the value of P(CIA), as shown in Table 2
remains within a given range (e.g. (0, a], (0, 1 -a], [a,
1)) corresponding to a symbolic label, even if there is a
degradation of the result which is less specific than Vo(a)
or V 1( 1 - a) (except in the first line of Table 2). Hence
we get the following robust computation table for the
quantified syllogism (we only give here the 4-tuples that
lead to an informative output) :

few
few
few
most

few
most
few
most
few

few
most
most
few

[none, most]
few
(few, all]
[few, half]
[none, half]

P.(AnBI A)

)

=

l- 2a
1-a

P(CIA) � P*(BIA) P*(CIA n B) = (I -a)2.
·

There is again a degradation of the lower bounds.
However these lower bounds are again greater than a
when a$ d.
The third axiom pertains to another kind of inference that
does not directly relate to the quantified syllogism. In
Amarger et al. (1991a) the following identity was
obtained:

P(CIA)
P(CIAuB)

most
most
most
most
most

1- P.(CIA)

+

P(BI A)

P(CI B)

P(CIA n B)

P(AIB)
1

P(BIA)

+

1

P(AIB)

-1

Hence a lower bound to P(CIA u B) is obtained when
n B) = 1. When P(CIA) � 1-a, P(CIB) � I - a
(both express "most"), we get

P(CIA

79

80

Dubois, Prade, Godo, and Lopez de Mantaras

P(CJA u B)

�

K(1

-

a) - 1

OP * (AIB)old

K-1
1

1

� 2. The right-hand
+
P(AJB)
P(BJA)
term of the inequality is increasing with K. Hence the
lower bound for P(CJAuB) � 2(1 - a) - I = 1 - 2a.
More generally P(CJAuB) � 1 - a- a' when P(CJA) �
1 - a, P(CIB) � 1 - a'. On the whole, we have found
finistic counterparts of Adams' axioms that enable to
quantify how inaccurate we are when we apply these
axioms for commonsense reasoning with high
probabilities.
where K =

The three axioms can be summarized as
A

�

a

�

B,A

a

A� B, An B
A

�

a

a

-

�

C �A

C�AuB

�

�

-

2a

7

)]

k�l
Ili= Q P•(Ai+JIAi)
l

since this operation must be done for all cycles one
might look for the counterpart of a longest path
algorithm, here with qualitative values. But this is
tricky if we want to compute quotients only at the
end of the shortest path procedure, and keep separate
the products of terms along cycles. The maximum
operation (Q1/Q2) v (S 1/S2 ) should be directly
expressed as an operation v' between pairs (QJ,Q2)
and (S 1 ,S 2) that furnishes a new pair of qualitative
values. Moreover, longest path algorithms make an
extensive use of the distributivity of the addition
over the maximum. Here we would require a property
such as

C

In the case of the generalized Bayes theorem (GBT),
described in Section 3, we cannot use the same method as
we did in Section 4 with the quantified syllogism rule
because here the number of arguments, i.e. the length of
the involved cycle, is variable. This prevents us from
having the qualitative inference pattern defined by a table.
Then the only possibility left is to replace in the GBT
expression the product and quotient operations by
qualitative ones defined on the universe of description U.
These more basic qualitative operations can be stored in
tables.

1
rr!<A·1+1
1
- OP * (A·I

ii)

C

THE GENERALIZED BAYES
THEOREM

·

for a given cycle, find a proper ordering for the
computation. Especially, it is not obvious that
(Xl·X2) I (X3-X4) (computing products first) is equal
to (Xt/X2) · (X3/X4) (computing quotients first).
Because of the truncation effect of the quotient table,
it seems better to compute products before quotients.

B reads P(BIA) � 1
a. In terms of
a
linguistic proportions, those rules can be "Written
changing a into "most" and interpreting the resulting
conditional probabilities as "more than few" in the three
cases, provided that a < 1/3. These rules enable
probabilistic reasoning to be performed as a qualitative
non-monotonic logic, but where the validity of
conclusions can be numerically assessed.

where A

QP * (BIA)

i)

-a-4C

- a--.2�>
2-a--

[

A and v denote the min and max operations in the sense
of the certainty ordering. But the computation of these
quantities raises several problems

1-a

�

C.B

C �An B

A

Xl

v

Xz

(

X3 · X4
X s · X6

)

=

X1

·

X3

X I · X4

v

X2 · Xs

X2 · X6

It is not clear that this property holds in the
qualitative algebra.
But the basic question is whether this constraint
propagation rule, which proved useful in the quantitative
case leads to really improve qualitative probability
bounds. This can be precisely studied on the 5 quantifier
case of Section 4.2.
The smallest expression to be computed with non­
extreme probabilities is of the form (Ql Q2 Q3)!(Q4
Qs) with Qi E {few, half, most}. It is easy to check from
the product and quotient tables that
·

i)
ii)

Q 1 Q2 E
most]}
·

0 1 Q2
above
·

·

·

·

{few, [few, most], [few, half], [half,
03 can only belong to the same set as

Given a cyle (At, ... ,Ak, At) with AI =A, Ak B the
qualitative probability QP(AIB), known to lie in the
interval [QP,.(AIB)0ld• QP*(AIB)otdl should be improved
by letting

iii) the only case where a quotient can be significantly
informative is when the operands are [few, most],
[half, most] and [half, half] since few/most= [few,
half] and half/half= [half, all] = half/most.

Q P*(AIB)new

As a consequence (QJ Q2 · 0 3)/(0 4 · Qs) can give
[few, all] at the very best. This is when Q1 0 2 Q3 =
[few, half] and 04 Qs = [half, most]. This is not likely
to be very useful for improving probability bounds. In
the 7-quantifier case, the best informative result can be

=

QP•(AIB)old
QP * (AIB)new

·

=

v

[

=

n"!c_.=-t Q P•(AiiA i+I)

-\ ..
Q P•(BIA) -��-=.!.

;
..;...:_
____;
_____:_

Il i=1 QP * (Ai+tiAi)

l

·

·

·

A Symbolic Approach to Reasoning with Linguistic Quantifiers

shown

to be

Q1 02 Q3
Q4 Q 5
·

·

·

8

[half,

_

all)

corresponding to when

[half, most]

[most, al- all)

[half, most]

[most, at- all]

��--�.�d

.

linguistic partition of the unit interval, can be recursively
applied to any set of linguistic quantified statements of
the form Q A(s are Bi's which form a probabilistic

network. It is then possible to generate new statements of
that kind, and to improve precision for the ones that were
originally stated. Let us consider the following qualitative
counterpart of a 5-predicate example of Amarger et al.
(199la, b):

•

•

•

•

•

•
•

•

•
•

•

Most to almost all students are sportsmen (Q
[most,
al-all]
Almost all students are young (Q = al-all)
Half of the sportsmen are students (Q "' half)
Almost all sportsmen are single (Q = al-all)
At least almost all sportsmen are young (Q = [al-all,
all])
At least most singles are sportsmen (Q "' [most, all])
Most singles are young (Q = most)
Almost no singles have children (Q = al-none)
Few young people are students (Q =few)
Almost all young people are sportsmen (Q"' al-all)
At most almost no young people have children (Q =
[none, al-none]
At most almost no people who have children are single
(Q [none, al-none])
At most almost no people who have children are young
(Q [none, al-none))
=

=

•

=

These statements are but examples and must not be
examined as to their actual truthworthiness.
Let us consider a 7-element partition as follows
partition: (0, 0.2, 0.4, 0.6, 0.8, 1)
� (none, al-none, few, half, most, al-all, all}.
=

The quantified syllogism rule is run until no
improvement of the quantifiers, nor new statements can
be generated. The following results were obtained :
•

•

•

At least few students are single (Q = [few, all])
Not more than few sportsmen have children (Q =[none,
few])
From almost-none to half singles are students (Q = [at­
none, half]).

Let us consider now a 9-element partition as follows
partition: (0, 0. 1 0.2, 0.4, 0.6, 0.8, 0.9,
,

;;>

=

•

•

S YMBOLIC CONSTRAINT
PROPAGATION

The quantified syllogism rule, as precomputed for a given

•

•
•

1)

(none, al-none, v-few, few, half, most, v-many,
al-all, all)

where v =few stands for very-few ([0,1, 0.2)) and v-many
stand for very many ([0.8, 0.9)). Using th e same input
data, more results are obtained:

At least half of the students are single (Q = [half, all))
Not more than half of the students have children (Q =
[none, half])
Not more than very few sportsmen have children (Q =
[none, v-few])
Most to very many singles are sportsmen (Q = [most,
v-many]).

These results are consistent but strong e r than thos e
obtained with the ?-element partition. It is interesting to
compare them with the results of the numerical procedure
that directly handles interval probabilities given below
under the form of incidence matrices giving
P(<column>kroW>):

iltj:J_ut data

student

sp_ort

_young

children

.ro.7oo.o.9oo1
[0.400,0.600] [1.000,1.000
sport
si'!_gle
[0.000,1.000] _10.700,0.900
_y_oung J0.250,0.35Ql _10.800,0.900
children _[0.000,1.0001 [0.000,1.0001
student

input data
student
sport
si'!_gle
young
children

jl.OOO, 1.0001

sin.11;le

[0.000,1.0001
[0.800,0.8501
n .ooo.1.ooo1
[0.900,1.000]
[0.000,0.0501

[0.850,0.9501 .[0.000,1.000)
[0.900,1.000] [O.OOO,l.OOQl
_[0.600,0.800� _10.050,0.80Ql
[1.000,1.000] [0.000,0.050]
J0.000,0.05Ql _ll.OOO,l.OOOJ

Inputdata
saturated
network

student

[1.000,1.000]
_10.400,0.400�
single
[0.222,0.366]
young
[0.350,0.350]
children _10.000,0.099]_
student

SJl.Ort

saturated

y oung

student

[0.850,0.8501
[0.900,0.958]
_10.800,0.8001
[1.000,1.000]
[0.000,0.0441

network

sport
sin_gle
young
children

sport

single

[0.900,0.9001
_[1.000,1.0001
.[0.700,0.7001
[0.834,0.8881
[0.000,0.127]

[0.607 ,1.000]
[0.850,0.850]
r1.ooo.1.ooo1
[0.900,0.9001
[0.000,0.050]

children

[0.000,0.271
[0.000,0.154
_10.050,0.100
[0.000,0.050
[1.000,1.000

Probabilitiesafter constraintpropagation
The main difference between the numerical and the
symbolic results appears on the last row. The symbolic
inference approach was not able to deduce that almost
nobody having children is a student, and very few are
sportsmen. Note that we have tried to develop a
qualitative version of the generalized Bayes rule using
longest path algorithms and the product and quotient
tables of computation. However no improvement of the
results has been observed. More work is to be done along
that line.

81

82

Dubois, Prade, Godo, and Lopez de Mantaras

9 C ONCLUDING REMARKS
We have shown in this paper that a qualitative calculus
for the probabilistic scale 'none', 'few', 'from few to
most', 'most', 'all' can be developed in agreement with a
numerical interpretation of probabilities, provided that the
intended numerical meaning of 'few' is less than 33 % in
any case and the one of 'most' is more than 66 %. These
thresholds are quite in agreement with commonsense
which seems to disagree that "most A's are B's" if less
than 70 % of A's are B's, or that "few A's and B's'' when
there are more than 30 % of A's which are B's. However
it does not mean that humans are currently able to
provide the correct (in the sense of probability calculus)
qualitative values given by the rules derived in this paper.
It is well known (e.g. Kahneman, Slavic and Tversky,
1 980) that humans are often in trouble not only for
correctly assessing probabilities, but also to make
accurrate inference from them.
One might wonder whether fuzzy intervals are useful or
not in the modeling of linguistic quantifiers. Clearly the
use of precise thresholds to delimit the extensions of
"few", "half', "most" has something arbitrary. However
since the linguistic computation tables obtained here are
partially independent of the choice of the threshold, it
turns out that using fuzzy partitions instead of non-fuzzy
ones would not make much difference here, especially if a
fuzzy partition is viewed as an imprecise specification of
the thresholds between the meanings of the basic terms.
Nevertheless fuzzy intervals remain useful in the scope of
feeding numbers in probabilistic networks, from the
knowledge of linguistic values, rather than reasoning
with linguistic values. Indeed, when looking for the
numerical interpretation of linguistic quantifiers, fuzzy
intervals look like a more faithful model than crisp ones.
But then the constraint propagation algorithms must be
adapted to handle fuzzy upper and lower probabilities in
the numerical setting. Applying fuzzy arithmetic to the
quantified syllogism rule (as done by Dubois and Prade
( 1988)) appears to be in total contrast with defining
linguistic counterparts of numerical constraint
propagation rules, as done here.
Acknowledgments : This work is partially supported
by the ESPRIT-Basic Research project n°3085, DRUMS.

