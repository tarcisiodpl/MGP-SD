

Possibilistic logic offers a qualitative frame­
work for representing pieces of information
associated with levels of uncertainty or pri­
ority. The fusion of multiple sources infor­
mation is discussed in this setting. Differ­
ent classes of merging operators are consid­
ered including conjunctive, disjunctive, rein­
forcement, adaptive and averaging operators.
Then we propose to analyse these classes in
terms of postulates. This is done by first ex­
tending the postulates for merging classical
bases to the case where priorities are avail­
able.
1

Introduction

Possibilistic logic (e.g. [8]) offers a framework for rea­
soning with classical logic formulas associated with
weights belonging to a totally ordered scale. Weights,
which technically speaking are lower bounds of neces­
sity measures, can either represent the certainty with
which the associated formula is held for true, or the
expression of a preference under the form of a level of
priority. In this case the formula encodes a goal (rather
than a piece of knowledge) which has to be considered.
The fusion of information expressed in a logical form
has raised an increasing interest in the recent past
years [1, 6, 10, 11, 13, 14]. Indeed this problem nat­
urally occurs when handling multiple sources of infor­
mation, and trying to extract the common, conflict­
free part of the information, or when trying to fuse the
goals expressed by several agents. Clearly possibilis­
tic logic, which offers a representation framework more
expressive than the one of classical logic, by allowing
for an explicit stratification of the sets of formulas, is
well-suited for handling levels of certainty or priority in
the fusion process. In recent works [3, 5], the authors
have on the one hand provided a possibilistic syntactic

counterpart of combination operations defined on pos­
sibility distributions defined on sets of interpretations.
On the other hand, taking advantage of the fact that
a classical logic formula can be always associated with
a stratified set of formulas (using Hamming distance
as suggested by Dalal [7]) which reflects partial levels
of satisfaction of the initial formula, the authors have
shown the agreement of the possibilistic logic-based
approach with the recent proposals on fusion in the
classical logic setting.
In this paper we make a step further by i) distinguish­
ing between different classes of combination operations
capable of coping with redundancy, or with drowning
effects of "inconsistency-free" formulas [2] encountered
in case of conflicts when weights are just combined by
a simple operator like min, and ii) by analysing these
classes firstly in terms of information sets that each
class retains, and secondly in terms of postulates which
are natural extensions of those recently proposed in the
classical framework [10, 11, 12]. After briefly recalling
the necessary background on possibilistic logic in Sec­
tion 2, general classes of combination operators are
introduced and studied in Section 3. The handling of
the global reliability of the sources or of priorities be­
tween agents is also briefly considered in this section.
A discussion with respect to postulates is presented in
Sections 4 and 5.
2

Possibilistic logic and fusion

This section recalls some basic notions of possibilistic
logic. See [8] for more details. Let .C be a finite propo­
sitionnal language. f- denotes the classical consequence
relation and n is the set of classical interpretations.
2.1

Possibility distributions

At the semantic level, possibilistic logic is based on
the notion of a possibility distribution, denoted by 1r,
which is a mapping from n to [0,1] representing the
available information. 1r(w) represents the degree of

25

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

compatibility of the interpretation w with the avail­
able beliefs about the real world if we are representing
uncertain pieces of knowledge (or the degree of satis­
faction of reaching state w if we are modelling pref­
erences). By convention, 1r(w) = 1 means that it is
totally possible for w to be the real world (or that w is
fully satisfactory), 1 > 1r(w) > 0 means that w is only
somewhat possible (or satisfactory), while 1r(w) = 0
means that w is certainly not the real world (or not
satisfactory at all). Associated with a possibility dis­
tribution 1r is the necessity degree of any formula ¢:
N (¢;) 1- II( •¢) which evaluates to what extent ¢; is
entailed by the available beliefs, and defined from the
consistency degree of a formula ¢; w.r.t. the available
information, II(¢) = max{1r(w) : w E [¢]}, where [¢]
denotes the set of all the models of ¢;.
In the rest of the paper, a,b, c, ... reflect the possibility
degrees of the interpretations.
=

2.2

Possibilistic logic bases

At the syntactic level, uncertain information is repre­
sented by means of a possibilistic knowledge base which
is a set of weighted formulas B {( ¢;;, a;) : i 1, n }
where ¢;; is a classical formula and a; belongs to a
totally ordered scale such as [0,1]. (¢;;, a ;) means
that the certainty degree of ¢;; is at least equal to a;
(N (¢;) 2: a;). We denote by B* the classical base as­
sociated with B obtained by forgetting the weights. A
possibilistic base B is consistent iff its classical base
B* is consistent.
In the following, a, /3, 1, ... reflect the necessity degrees
associated with formulas.
Given B, we can generate a unique possibility distribu­
tion, denoted by 1TB, such that all the interpretations
satisfying all the beliefs in B will have the highest pos­
sibility degree, namely 1, and the other interpretations
will be ranked w.r.t. the highest belief that they fal­
sify, namely we get [8]:
=

Definition 1

1TB

=

Vw E n,

( ) = { 11
iJ V (c/J; , a ) E B , w E [ c/J;]
max{a;: w rf. [¢;]} othe ise .
W

;

rw

Inc( B) = max{a; : B?_a; is inconsistent} denotes
the inconsistency degree of B. When B is consistent,
we have Inc(B) = 0.
Subsumption can now be defined:
Definition 4 Let (¢;, a) be a belief in B. Then, (¢;,a)
is said to be subsumed by B if (B- { (¢, a )})> a 1-¢.
(¢,a) is said to be strictly subsumed by B if B>a 1- ¢.

It can be checked that if (¢;, a) is subsumed, then B
and B' = B- { (¢, a )} are equivalent [8].
Lastly, weights are propagated in the inference process:
possibilistic formula (¢;,a), with a >
Inc(B), is said to be a consequence of B, denoted by
B l-1r (¢, a), iffB?_a 1-¢;.
Definition 5 A

2.3

Syntactic fusion

We first recall a general result underlying the fusion
process in possibilistic logic [5].
Let B1, B2 be two possibilistic bases, and 1T1 and 1r2
be their associated possibility distributions. Let EB be
a two place function whose domain is [0,1] [0,1] (to
be used for aggregating 1r1 (w) and 1r2(w)). The only
requirements for EB are the following properties:
i. 1 EB 1= 1,
ii. If a 2: c, b 2: d then a EBb 2: c EB d (monotonicity).
The first one acknowledges the fact that if two sources
agree that w is fully possible (or satisfactory), then
the result should confirm it. The second one expresses
that a degree resulting from a combination cannot de­
crease if the combined degrees increase.
In [5], it has been shown that the syntactic counterpart
of the fusion of 1T1 and 1r2 is the following possibilistic
base, denoted by B$ (and sometimes by B1 EB B2) and
which is made of the union of:
- the initial bases with new weights defined by:
x

{(¢; ,1-( 1-a;)EIH): (¢;,a;)EB1}u
{('1/>j, 1-1EB(1-.61)):(,Pj ,.6j)EB2} ( 1)

- and the knowledge common to B1 and B2 defined by:
{(</l;V'I/>1 ,1-( 1-a;)EB( 1-.6j)):(¢; , a;)EB! and ('l/>1,.61)EB2}

It has been shown that 1TBal(w) = 1T1(w) EB1r2(w) where
is the possibility distribution associated to B$ us­
ing Definition 1.
In the case of n sources, the syntactic computation
of the resulting base can be easily applied when EB is
associative. Note that it is also possible to provide
syntactic counterpart for non-associative fusion oper­
ator. In this case EB is no longer a binary operator,
but a n-ary operator applied to vectors of possibil­
ity distributions. The syntactic counterpart is as fol­
lows: Let B= (B1 , ... , Bn) be a vector of possibilistic
bases. Let (
, 7rn) be their associated possibil­
ity distributions and 1TBa:J be the result of combining
7rBal

Further definitions used in the paper are now given:
Definition 2 Let B be a possibilistic kno wledge base,
and a E [0,1]. We call the a-cut (resp. strict a-cut)
of B, denoted by B?_a (resp. B>a), the set of classical
formulas in B having a certainty degree at least equal
to a (resp. strictly greater than a ).
Definition 3 B and B' are said to be equivalent, de­
noted by B =• B', iffVa E [0,1], B?.a = B�-a'
where = is the classical equivalence.

rr1,

·

·

·

26

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

( ... ) with Ef). Then, the base associated to 1l"l3Ell
is: B!JJ ={(Dj,1- x1 Ef) ... Ef) ) j =1, n}, where Dj
are disjunctions of size j between formulas taken from
different B; 's ( i = 1, n) and x; is either equal to 1-o:;
or to 1 depending if c/J; belongs to Dj or not.
7rt,

,?Tn

Xn

3

:

Possibilistic merging operators

This section analyses several classes of Ef) which cope
with different issues met in merging multiple sources
information. In the rest of this paper, we assume that
Ef) is associative.
3.1

Conjunctive operators

One of the important aims in merging uncertain in­
formation is to exploit complementarities between the
sources in order to get a more complete and precise
global point of view. Since we deal with prioritized
information, two kinds of complementarities can be
considered depending on whether we refer to formulas
only, or to priorities attached to formulas. In this sub­
section, we introduce conjunctive operators which ex­
ploit the symbolic complementarities between sources.
Definition 6

Va E

Ef) is said to be a conjunctive operator if

[0, 1], a EB 1 = 1 Ef) a =a.

The following proposition shows indeed that conjunc­
tive operators, in case of consistent sources of infor­
mation, exploit their complementarities by recovering
all the symbolic information.
Proposition 1 Let B1 and B2 be such that Bi 1\ B2
is consistent. Let Ef) be a conjunctive operator. Then,
B$= Bi 1\ B2 .

An important feature of a conjunctive operator is its
ability to give preference to more specific information.
Namely, if an information source S1 contains all the
information provided by S2, then combining St and
S2 with a conjunctive operator leads simply to St:
Proposition 2 Let B1 and B2 be such that V ( 'lj;, (3) E
B2,B1 f-rr (¢,(3). Then, B(B:= Bi.

An example of a conjunctive operator is the minimum
(for short min), for which we can easily check that
B!JJ = B1 U B2. Other examples are the product, and
the geometric average defined by a Ef) b = ..fCib.
3.2

Disjunctive operators

Another important issue in fusion information is how
to deal with conflicts. When all the sources are equally
reliable and conflicting, then one should avoid arbi­
trary choice by inferring all information provided by

one of the sources. Namely, if B1 U B2 is inconsistent,
then one can require that B!JJ neither infers B1 nor
B2. Such a behaviour cannot be captured by any con­
junctive operator (See Section 5). This requirement is
captured by the disjunctive operators defined by:
Definition 7

Va E

Ef) is said to be a disjunctive operator if

[0, 1], a EB 1 = 1 Ef) a = 1.

Then, we have:
Proposition 3 Let B1 and B2 be such that Bi 1\ B2
is inconsistent. Then, there exist (c/J, o:) E B1 and
(1j;, (3) E B2 such that B!JJiirr (c/J,o:) and B!JJiirr (¢,(3).

Note that if Ef) is a disjunctive operator then B!JJ is of
the form: B!JJ = {(c/J; V 1/Jj, 1- (1- o:;) Ef) (1- {3j))}.
Now, a second natural requirement that one may ask
for, in case of conflicts, is to recover the disjunction of
all the symbolic information provided by the sources.
Clearly, it is easy to find a disjunctive operator which
does not satisfy this second requirement. A trivial case
is to take the "vacuous" disjunctive operator defined
by: Va, Vb,a Ef) b = 1.
To satisfy this second requirement we define the notion
of regular disjunctive operator:
Definition 8 A

regular if Va

disjunctive operator Ef) is said to be

-=F 1, Vb -=F 1, a Ef) b -=F 1.

Then, we have:
Proposition 4 Let B1 and B2 be two bases and Ef) be
a regular disjunctive operator. Then, B$= Bi V B2 .

Examples of regular disjunctive operators are the max,
the so-called "probabilistic sum" defined by:
a Ef) b = a+ b- ab, and the dual of the geometric av­
erage defined by a Ef) b = 1- J(l- a) (l- b).
Lastly, note that regular disjunctive operators are not
appropriate in the case of consistency between sources;
in particular they give preference to less specific infor­
mation.
3.3

Idempotent operators

Another important problem in fusing multiple sources
information is how to deal with redundant informa­
tion. There are two different situations: either we
ignore the redundancies, which is suitable when the
sources are not independent, or we view redundancy
as a confirmation of the same information provided by
independent sources. Idempotent operations are de­
fined by:
Definition 9 EB

if "'a E

is said to be an idempotent operator

[0, 1], a Ef) a = a.

27

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

Idempotent operators aim to ignore direct redundan­
cies. Namely, if two sources of information entail the
same formula ¢ to a degree a, then one may require
that the fused base should not entail ¢ with a degree
higher than a. However, such a requirement is strong
since ¢ can be obtained from another path exploiting
complementarities between higher level formulas pro­
vided by the two sources. This is illustrated by the
following example:
Let B1 == { (,P, .9); (¢, .2)} and
B2 == {(¢ V • 'If , .8); (¢, .2)}.
Clearly B1 f-rr (¢, .2) and B2 f-rr (¢, .2). Now let EB be
an ide mpotent operator defined by: a EB b == �.
Then, B4 == { (,P, .45); (¢ V ,P, .55); (¢ V • 'If , .5)} after
re moving subsumed for mulas. We can easily check that
B4f-rr (¢, .5) with .5 ?: .2. This is mainly due to the
two pieces of information (,P, .9) and (¢ V • 'If , .8), pro­
vided separately by the sources.
Example 1

Now, the following proposition shows the cases where
idempotent operators indeed ignore redundancies:
Proposition 5 Let B1 and B2 be two bases, and EB
be an ide mpotent operator. Let ¢ be such that B1 f-rr
(¢,a); B2 f-rr (¢, (3) with (3::; a. Let r == Bl>a UB2>a·
Then, iff If¢ then B4f-rr (¢, !'), with I'::; max (a,(J).

Note that I' may be equal to 0 in case of inconsistency.
r in this proposition is the set of classical formulas
in B1 and B2 having a weight strictly greater than a.
If ¢ cannot be deduced from r then the idempotent
property only guarantees that the repeated informa­
tion will not be inferred with a priority higher than
the one with which it can be individually obtained
from the different sources.
3.4

Reinforcement operators

The aim of reinforcement operators is to view redun­
dancy of information as a confirmation of this infor­
mation. Namely, if the same piece of information is
supported by two different sources, then the priority
attached to this piece of information should be strictly
greater than the one provided by the sources. A first
formal class of reinforcement operators can be defined
as follows:
Definition 10 EB is said to be a reinforcement opera­
tor if'Va, b# 1 and a, b# 0, a EBb< min( a, b).

We can easily check that if we aggregate the two pieces
of information (¢,a) and (¢,(3), then the resulting
base is: {(¢, f (a, ,B))} where f (a, (3) == 1- (1- a) EB
(1- (3)> max(a, (3) for a, (3 E (0, 1).
Besides, one can require that reinforcement opera­
tions recover all the common information with a higher

weight. Namely if the same formula is a plausible con­
sequence of each base, then this formula should be
accepted in the fused base with a higher priority. The
following proposition shows a first case where this re­
sult holds:
Proposition 6 Let B1 and B2 be such that Bt 1\ B2
is consistent. Let ¢ be such that B1 f-rr (¢,a) and
B2 f-" (¢, (3) where a and ,B are strictly positive. Let
EB be a reinforce ment operator. Then, Btf!f-rr (¢, f'),
with I'> max(a,(J) if a, (J E (0, 1), and/'== 1 if a== 1
or (3== 1.

Now, in case of conflicts, and more precisely, in case of
a strong conflict, namely Inc(B1 U B2) == 1, then the
above proposition does not hold.
Indeed, let B1
{(¢, 1), (,P,a)} and B2
{(•¢, 1), (,P,(J)}. Then we can check that Inc(B4) ==
1, so we cannot infer ,P from B4 since Inc(B1 UB2) 1.
Even if we add (,P, 1) to B1 U B2 explicitly then ,P can­
not be recovered. In possibilistic logic, when there is a
strong conflict then only tautologies are plausible con­
sequences. In this case it is better to use a regular
disjunctive operation.
So the first condition is to avoid that Inc(B1 UB2) 1.
But this is not enough since even if Inc(B1 U B2) < 1
one can have Inc(B4)= 1 due to the reinforcement
effect which can push the priority of conflicting infor­
mation to the maximal priority allowed. For instance
let us consider the excessively optimistic reinforcement
operator defined by:
\Ia,'Vb, a# 1, b# 1, a EBb = b EB a== 0.
Then we can check that as soon as there is a conflict
between the bases to be merged, the inconsistency de­
gree of the fuses base will reach the maximal value.
The following definition focuses on a more interesting
class of reinforcement operations:
==

=

Definition 11 A reinforce ment operation EB is said to
be progressive if \Ia, b# 0, a EBb# 0.

The progressive operation guarantees that if some for­
mula (¢, a) with a> 0 is inferred by the sources then
this formula belongs to B4 with a weight (3 such that
a < ,B < 1. However, this new weight (3 can be less
than the inconsistency degree of B4 and therefore ¢
will be drowned by the inconsistency of the database.
This situation is illustrated by the following example:
Example 2

Let B1 = { (¢ V ,P, .9); (¢, .5); (,P, .5); (�, .1)} and B2 =
{(•¢ v • 'If , .9); (•¢, .5); ( 'If .5); (�, .1)}.
Clearly, each base entails � which is largely belo w the
inconsistency degree of B1 U B2. Now, let us compute
B1 EB B2 with the product operator which is a progres­
sive operator. We get: B1 EB B2 = B1 U B2 U { (¢ V ,P V
�' .91); ( •¢V • '!fV� , .91); (¢V•,P, .75); (•¢V,P, .75); (¢V
•

,

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

28

�,.55); ('1/JV �,.55); (•¢V �,.55); (•1/J V �,.55); (�, .19)}.
Note that there is a reinforce ment on � since its ne w
weight is .55 (which can be obtained for instance fro m
(¢V�, .55) and (•¢V�, .55)). However, this ne w weight
is less than the inconsistency degree of Btf! which is of
.75, higher than Inc(B1 U B2)= .5.

The following proposition generalizes Proposition 6,
and shows that if the inconsistency degree does not
increase, then the common knowledge is entailed.
Proposition 7 Let B 1 and B2 be such that Inc(B1 U
B2) -=f 1. Let ¢ be such that B1 f-rr (¢, a) and
B2 f-rr (¢, {3) with a > 0, f3 > 0. Let EB be a pro­
gressive reinforce ment operation. Then,
if Inc(Btf!)= Inc(B1 U B2) then, Btf!f-rr (¢,1)
with 1 > max( a, {3), and 1= 1 if a = 1 or f3= 1.

3.5

Adaptive merging operators

The regular disjunctive operators appear to be ap­
propriate when the sources are completely conflicting.
However, in the case of consistency, or of a low level
of inconsistency regular disjunctive operators are very
cautious. Besides, reinforcement is not appropriate in
the case of complete conflicts.
The aim of adaptive operators is to have a disjunctive
behaviour in a case of complete contradiction and the
progressive reinforcement behaviour in the other case.
Let EBd and EBr be respectively a regular disjunctive
and progressive reinforcement operators. Let h be ei­
ther equal to 1 or to 0. Then we define an adaptive
operation, denoted by EBh, as follows:
a EBh b = max(min( h, (a EBd b)),min(1- h, (a EBr b))).

Then we have the following result:
Proposition 8 Let B1 and B2 be two possibilistic
bases. Let h be equal to 1 if Inc(B1 UB2)= 1 and equal
to 0 otherwise. Let EBh be an adaptive operator. If
Inc(Btf!) = lnc(Bl U B2) then, V¢, if B1 f-rr (¢, a) and
B2 f-rr (¢, {3) then we have: Btf!hf- (¢,1) with 1 > 0.

3.6

Averaging operators

A last class of merging operators which is worth
considering is the so-called averaging operation, well
known for aggregating preferences, and defined by:
is called an averaging operator if
max( a,b)�a EBb�min( a, b),
with EB -=f max and EB -=f min.

Definition 12 EB

One example of averaging operators is the arithmetic
mean a EBb= �- In this case, at the syntactic level,
the result of combining B1 and B2 writes:
{(¢;, Y)} U {('1/Jj, 13{)} U {(¢; V '1/Jj, a;�f3i )}.
From this writing, in case of consistency we can check

3. 7

Accounting for reliabilities of the sources

The possibilistic logic framework enables us to take
also into account priorities between sources (or
agents). Here priority may mean either that the
sources are decreasingly ordered according to their re­
liability, or that a reliability degree is attached to each
source. When we have just a reliability ordering and
no commensurability assumption is made between the
scales used for stratifying each source, the approach
which can be used is known in social choice theory un­
der the name of "dictatorship". The idea is to refine
one ranking by the other. More precisely, let rr1 and rr2
be two possibility distributions. Assume that 1r1 has
priority over 1r2. The result of combination defined by:
i. If 1r1(w) > 1r1(w') then 11"fll(w) > 11"fll(w')
ii. If 1r1(w) 11"1(w') then 11"fll(w) � 11"fll(w') iff 1r2(w) � 11"2 (w').
Clearly the combination result is simply the refinement
of 1r1 (the dictator) by 1r2. Syntactic counterpart of
this combination can be found in [5].
When a reliability degree is associated with each
source, we may use weighted counterparts of oper­
ations EB. However in practice, it amounts to per­
forming a preliminary modification of the degrees at­
tached to formulas provided by each source and then
to performing a non-weighted combination operation
on the modified possibilistic bases. For instance, using
the weighted min conjunction defined by Vw, 1rtf!(w) =
mini=l,nmax(nj(w), 1 - Aj) (for Aj
1, V j, the
min combination is recovered). It amounts to per­
forming the union of discounted bases of the form
=

=

Discount(B;, >.;) = {(¢, >.;)1(¢,{3) E B; and f3 � >.;}
U{(¢, /3)1(¢,{3) E B; and f3 < >.;}. It is worth point­

ing out that discounting sources help solve conflicts
between sources in a natural way.
4

Postulates for classical merging

Let us first introduce some additional notations.
Let E
{K1, ... , Kn} (n � 1) be a multi-set of
propositional bases to be merged. E is called an infor­
mation set. 1\E (resp. VE) denotes the conjunction
(resp. disjunction) of the propositional bases of E.
The symbol U denotes the union on multi-sets.
For the sake of simplicity, if [{ and /{1 are proposi­
tional bases and E an information set we simply write
EU[{ and KUK' instead of EU{K} and {K}U{K'} re­
spectively. We will denote [{n the multi-set {K, ..., K}
of size n. A classical merging operator .6. is a function
applied on E and which returns a classical base denoted by .6. (E).
Koniesczny and Pino Perez [10] have proposed a set of
=

n

'

29

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

basic properties that a merging operator has to satisfy:
(At) D. (E) is consistent;
(A2) If E is consistent, then D.(E) = 1\E;
(A3) If E1 t+ E2, then 1-D. (E1) =: D.(E2);
(A4) If K 1\ K' is inconsistent, then D.(K UK') If K;
(A5) D.(E1) 1\ D.(E2) 1-D. (E1 U E2);
(A6) If D. (E1) 1\ D. (E2) is consistent, then

D.(E1 U E2) 1- D. (El) 1\ D. (E2);
where E1 t+ E2 means that there exists a bijection
f from E1 = {Kt, ...,K�} to E2 = {I<[, ...,Kn such
that VK E E1, ::JK' E E2, f (K) =: K'.

Liberatore [12], in the context of commutative belief
revision, does not impose A1. He allows the result to
be inconsistent if the bases to merge are individually
inconsistent. Moreover, he gives another postulate in
the same spirit as A4, namely:
(A7) D.(I< U I<')

1-

I< V K'.

Two classes of merging operators have been partic­
ulary analysed in the literature: majority operators
defined by: (Maj) VK, ::In, D. (E U K n) 1- I<,
and arbitration operators defined by:
(Arb) VK, Vn,D.(E UI< n) = D.(E U K).

5

Postulates for possibilistic merging

This section relates the general classes of possibilis­
tic merging operations to the rational postulates re­
called in the previous section. But first we need an
adaptation of these postulates in order to take into
account the priorities attached to the information. A
first immediate way of adapting the classical postu­
lates is to require that the result of the merging be
a classical base. If BtiJ denotes the result of merging
B= {B1, ...,Bn} with EB, then the classical base result­
ing from merging B; 's with EB is simply:
D.tiJ (B)= {¢ : (¢,a) E BtiJ, a > Inc (BtiJ)}.
However, restricting the result of merging prioritized
bases to a classical base is not satisfactory. Indeed
it leads to lose the associativity property of associa­
tive operators. The natural question is how to de­
fine D.tiJ (B1,D.tiJ (B2,B3)) since B1 is a stratified base,
while D.tiJ(B2, B3) is a classical one. One way of en­
forcing the iteration is to give to formulas of the result­
ing classical base a weight equal to 1. However, this
may violate the reliability of the formulas since formu­
las in D. til (B1,B2) which were very uncertain become
fully reliable. The loss of associativity property is il­
lustrated by the following example:
Let B= {B1, B2,B3} such that B1 =
{ (¢,.8)}, B2 = { (•¢,.5); (�, .4)} and B3 = { (�,.3)}.
Let EB = min. We have D.tiJ (B1,B2) = {¢}. To be able
to merge this result with B3 we associate to ¢ a weight
equal to 1, and we get D.tiJ (D.tiJ (Bl, B2), B3) = {¢,�}.
We also have D.tiJ(B2,B3)
{•¢, �} and
Example 3

D.tiJ (Bl,D.tiJ (B2,B3)) = {•¢, �}. Then,
D.tiJ (D.tiJ(Bl,B2), B3) ;/= D.tiJ(B1, D.tiJ(B2, B3)).
5.1

Adapting classical postulates

We focus on the approach where the result of the merg­
ing operation is a stratified base. Therefore, the pro­
cess of merging can be iterated. Let us now adapt the
classical postulates recalled in Section 4.
Let us adapt (A!). Possibilistic logic, contrary to clas­
sical logic, does not infer anything in the presence of
inconsistency. Hence a partially inconsistent base BtiJ
(with Inc (BtiJ)< 1) can be still meaningful, since plau­
sible conclusions can be inferred from it, by taking its
consistent part, i.e. the set of formulas having a weight
greater than Inc (BtiJ). Thus, the adaptation of (A!)
can be weakened as follows:
(Pi) BtiJ is not fully inconsistent,i.e., I nc(BtiJ) < 1.
Note that if one insists on providing a consistent and
stratified base as a result of fusion, then the associa­
tivity can be lost for associative operations.
Let us adapt the second postulate (A2). Requiring
an equivalence between BtiJ and B1 U U Bn in the
second postulate is very strong with stratified bases.
For instance, assume that two identical formulas (¢,a)
have to be aggregated. We have already seen that with
a reinforcement operator we get ( ¢, j3) (j3 > a) as a re­
sult of the merging. So, we do not recover the initial
weight of ¢. We propose to weaken A2 as follow:
(P2) If B1 U U Bn is consistent, then BtiJI-,. ( ¢, j3) iff
B1 U
U Bn 1-,. (¢,1), with j3 > 0 and 1 > 0.
This postulate implies that if Bi 1\ ... 1\B� is consistent,
then Bffi=: Bi 1\ 1\ B�.
·

·

·

·

·

·

·

·

·

·

·

·

Postulates A3 and A4 have immediate counterparts:
Let B= {B1, , Bn} and B'= {B�, , B�}.
(P3) If B t+ B', then BtiJ=s B'tiJ,
where B t+ B' means that there exists a bijection f
from B to B' such that VB E B, ::IB' E B',f (B) B'.
(P4) If B1 U B2 is inconsistent, then BtiJif,. B1 and
·

·

·

·

·

·

=•

BtiJif,. B2.

Concerning postulates A5 and A6, notice that in clas­
sical logic, when D. (E1) 1\ D. (E2) is inconsistent then
A5 is trivially satisfied. Hence A5 is only meaningful
when there is no conflict between the sources. There­
fore A5 and A6 are adapted as follows:
(P5) If BtiJ is consistent with B'tiJ, then
(P6)

BtiJUB'tiJI-,.(BUB')tiJ.

If BtiJ is consistent with B'tiJ, then
(BUB')tiJI-,. BtiJUB'tiJ

·

Let us now see how to adapt the postulate A7.
The common knowledge in the prioritized case can be
defined as follows: If B1 1-,. (¢ ,a) and B2 1-,. (¢, j3) ,
then BtiJI-,. ( ¢,1 ) , with 1 > 0.
Now, the question is how to fix the value of I Ob·

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

30

viously 1 should not be greater than min (o:,{3). In­
deed assume that c > a 2: b, and B1 = { (c/>,o:)} and
B2 = { (c/>,{3)} . Then it can be checked that (c/>,1) is
not a consequence of B2, which means that (c/>,1) can­
not be considered as a common information of B1 and
B2. Therefore the adaptation of A1 is as follows:
(P7) Vc/>, if B1 f-rr (c/>, ) and B2 f-rr (c/>,{3) then
BEJ)f-rr (c/>, 1) with 0 < 1:::; min (o:,{3).
Lastly, arbitration and majority have immediate ex­
tensions: (Arb) VB, Vn, (BuB n )4 '=s (BUB)4, and

Let Bt = {(•¢,.6);(¢,.5)} and B2 = {(¢,.7)} .
Since In c ( BEB)= .6, the useful information of BEB is

{(¢,.7)} = B2. Then, ?4 is not satisfied.
Let now B2 = {(¢,.7);(¢,.5)}. Then, (¢, .5) cannot
be inferred from BEB, and P1 is not satisfied.
min is idempotent, then it cannot be a majority op­
erator.

o:

•

Let B=

{Bt} and B'= {B2} s.t. Bt = {(¢,.5)} and
B2 = {(¢,.6)} . We have BEBUB'EB= {(¢,.5);(¢,.6)}
and (BuB')EB= {(¢,.5);(¢,.6); (¢v¢, .8)}. (4>V¢,.8)
cannot be inferred from BEBU B' EB. Then, Ps is not
satisfied. We also have Bt EB B2 = {(¢, .5);(¢,.6);(4>V
¢,.8)} and Bt EB B� = {(¢,.5);(¢,.84); (4> v ¢,.92)},
then Arb is not satisfied.

(Maj) VB,3n, (BuB n)4 f-rr B.

5.2

Properties of the fusion operations

This section gives the properties of the classes of pos­
sibilistic operators introduced in Section 3.
Proposition 9 shows that EEl is syntax independent.
Proposition 9

satisfies P3.

Any possibilistic merging operation

The next proposition relates the property of idempo­
tency to the idea of arbitration:
Proposition 10 Any idempotent operation is an ar­
bitration operation.

The following proposition gives the properties of the
regular disjunctive operations.
Proposition 11 Let EEl be a regular disjunctive oper­
ator. Then, EEl satisfies P1,P4,P5,P1 but may fail to
satisfy P2,P6,Maj,Arb.
: For P2, Ps and Maj we use the
max which is a regular disjunctive operation:

Counter-examples

operator EB
•

•

=

P2, Ps: Let B= {Bt,B2} with Bt
{(¢,.8)} and
B2 = {(¢, .3}. Although BtU B2 is consistent, we
have BEB = {(¢Vtjl,.3)} and we recover neither B; nor
B;. Then, EB does not satisfy P2. It does not satisfy
Ps for the same reason.
=

Maj: max is an idempotent operator, hence it is an
arbitration operation, and cannot be a majority op­
erator.

The following proposition relates the property of ma­
jority to the reinforcement property.
Proposition 13 Let B1 be a possibilistic base, and B2
another possibilistic base which is not conflicting with
completely certain formulas of B1. Let EEl be a progres­
sive reinforcement operator. Denote by B� the combi­
nation of B2 n times with E£). Then, 3n,V ('1/J, {3) E B2,
B1 EEl B� f-rr ('1/J, 1) with 1 > {3, (t = 1 if {3 = 1}.

This proposition means that reinforcement operators
are majority operators, in the sense that if the same
piece of information is repeated enough times then this
piece of information will be believed.
This proposition does not hold if we only use rein­
forcement operations which are not progressive. For
instance, consider the Luckasie wicz t-norm defined by:
a EEl b = max(O,a+ b- 1).
Then, for instance consider the bases B1 { (c/>,.8)},
B2 = { (c/>,.8)} and B = { (•c/>,.7)} which are not
completely conflicting. Then, we can easily check
that Inc (B1 EEl B2 EEl B 2)
1 and hence B cannot
be deduced. Indeed, we have B1 EEl B2 = { (c/>, 1)},
B 2 = B EEl B = { (•c/>,1)} .
We now give the properties of progressive reinforce­
ment operators:
=

=

Proposition 14 Let EEl be a progressive reinforcement
operator. Then, EEl satisfies P1 (provided that Inc (B1 U
U Bn) < 1}, P2,P6,P1 (provided that Inc(BEJ))=
Inc (B1 U
U Bn) and Inc (B1 U
U Bn) < 1}, Maj
but may fail to satisfy P4,P5,Arb.
·

Arb, consider the probabilistic sum defined by: a EBb=
a+ b- ab.
Let B
{ (¢,a)}. Then, one can easily check that B EBB
2
{(¢,2a - a )} which is different from B ={(¢,a)}.
For

=

=

Let EEl be a conjunctive operator.
Then, EEl satisfies P2,P6 but may fail to satisfy
P4,P5, P1, Arb,Maj.
Proposition 12

Counter-examples:
•

For P4 and P1, let us use the
junctive operator.

·

·

·

since it is a con­

·

·

·

·

·

Counter-example: Let us use the product which is a
progressive reinforcement operator.
•

?4: Let Bt = {(¢,.6) } and B2 = {(•¢,.5)} . The
useful information (above the level of inconsistency)
of BEB is

•

min

For P5 and Arb, let us consider the product which is
a conjunctive operator.

Ps,

Arb:

{(¢,.6)} = Bt.

Then, ?4 is not satisfied.

see the counter-example of Proposition 12.

The following proposition summarizes the properties
of averaging operators:

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

Proposition 15 The Averaging operator satisfies
P2,P4, P5,P6 and Arb but may fail to satisfy P7 and
Maj.

Lastly, the following tree summarizes the considered
operators, with the associated satisfied postulates:
General operator {P3}
./
Conjunctive {P2, P6}
./
'\t
Idempotent Progressive
{Pt2, Arb} reinforcement
{P [,P 13,Maj 4 }

'\t
Regular disjunctive
{P1 1 ,P4, P5, P7}
+

Idempotent{Arb}

P2

P3

P4

in the possibilistic setting provides a basis for design­
ing fusion systems able to propose a synthesis of par­
tially conflicting goals on the basis of some chosen type
of combination, possibly taking into account priori­
ties between agents or sources. Lastly, this paper has
analysed the possibilistic merging operators in terms
of postulates. A message from Table 1 is that some
postulates which make sense in classical fusion, like
A4, are not appropriate for merging prioritized bases.
Clearly, future work is to study new postulates proper
for prioritized bases.
