443

I
I

Rules, Belief Functions
and Default Logic*

I

Nic Wilson
Department of Computer Science
Queen Mary and Westfield College
Mile End Rd., London El 4NS, UK

I

A b st ra ct

I

This paper describes a natural framework for rules ,
bas ed on belief functions , which includes a repre­
s entation of numerical rules, default rules and rules
allowing and rules not allowing contraposition. In
particular it jus tifies th e us e of th e Demps ter-Sh afer
Th eory for repres enting a particular class of rules ,
Belief calculated being a lower probability given cer­
tain independence assumptions on an underlying
s pace. It s h ows h ow a belief function framework can
be generalised to other logics, including a general
Monte-Car lo algorithm for calculating belief, and
h ow a version of Reiter's Default Logic can be s een
as a limiting case of a belief function formalism.

I
I
I
I

1.

Rules used by people are often not completely re­
liable so any attempt to represent them must cope
with the conclusion of the rule sometimes being in­
correct. Numerical approaches do this by giving
some kind of weighting to the conclusion of an un­
certain rule; non-monotonic reasoning, a symbolic
approach, ensures that these rules are defeasible, so
that their conclusions could later be retracted if nec­
essary.
There has been little work done, however, on relat­
ing numerical and symbolic techniques, an exception
being the work of Adams [Adams, 66] further devel­
oped by Geffner and Pearl [Geffner, 89; Pearl, 88]
where a. logic is produced from probability theory,
by tending the probabilities to 1.
This paper shows how a belief function approach can
represent numerical rules, both those allowing con­
traposition and those not allowing contra.position,
and how default rules may be viewed as the lim­
iting case of such rules, when the certainty of the
rule tends to 1. This allows the integration of the
Dempster-Shafer Theory (DST) [Shafer, 76] and Re­
iter's Default Logic [Reiter, 80], hence enhancing the
understanding of both.

I
I
I
I
I
I
I
I
I

Introduct ion

*

This research was carried out as part of
t he ESPRlT basic research action DRUMS
(3085)

Section 2 deals with the representation of numeri­
cal rules within DST, 2.1 giving an interpretation
of the type of rule that DST typically represents;
2.2 presents a belief function framework that allows
the theory to be generalised to other logics, and 2.3
shows how the framework can be applied to include
rules which don't allow contraposition. Section 3
deals with the representation of default rules within
the framework: 3.1 reformulates Reiter's Default
Logic and defines a modified extension (equivalent
to Lukaszewicz's); 3.2 shows how the belief function
framework can be turned into a logic and 3.3 shows
how to represent default rules within this logic. Sec­
tion 4 indicates how priorities between rules can be
represented, and Section 5 suggests how numerical
and default rules could be used together within the
framework.
2. Numerical Rule s

Expert Systems like MYCIN [Buchanan and Short­
liffe, 84) use uncertain rules of the form If a then c
: (a-), where a- is the some measure of how reliable
the rule is. There are many ways of interpreting such
a rule. We consider a natural interpretation which
leads to the standard Dempster-Shafer representa­
tion of rules.
2.1 J u stifyin g

DST Representation of Rules

The standard way of representing ·the rules If a;
then c; : (a-;) (for i= 1, . . . , m) with the Dempster­
Shafer Theory is, for each rule to produce a simple
support function with mass a-; allocated to the ma­
terial implication a; _. c; and the remaining mass
1 - o; allocated to the tautology, and then to com­
bine these simple support functions by repeated ap­
plication of Dempster's Rule. Pearl has criticised
this representation for its behaviour under chaining
and reasoning by cases. However it turns out that
this DST approach represents a very natural type of
rule.
The uncertain rule may in fact be an approximation
to the certain rule n/\a -+ c where n is an unknown
antecedent or one too complicated to be easily ex­
pressed by the expert but which they judge to be
true with probability o. After all '. . . uncertainty
measures characterise invisible facts, i.e., exceptions
not covered in the formulas' [Pearl, 88, p2].
Since n 1\ a -+ c is logically equivalent to n 1\ ...,c -+
...,a, such a rule allows contraposition, an d since it's
also logically equivalent to n _. (a -+ c) , this rule
may also be interpreted
In a proportion o o f worlds (or situations ) we know
th e material implication a -+ c is true.

444

If we represent such a rule by a simple support func­
tion, as described above, Belief is just the probability
that we know a -+ c to be true, so that it's a lower
probability for a -+ c. Similarly if we have a num­
ber of such rules, a; -+ c; (i = 1, ... , m) , represent
them as simple support functions and combine these
with Dempster's Rule, Belief is a lower probability,
given certain independence assumptions on the n;s.
Consider now the typical Reasoning by Cases situa­
tion: we're given two rules If a then c: {Ql) and If
-.a then c : (Q2) which we'll interpret as uncertain
material implications n1 1\ a -+ c and n2 1\ -.a -+ c
with Pr(n;) = Q;, i = 1, 2.
Pearl argues that any reasonable measure of belief
should obey the Sandwich Principle: deducing from
those two rules that belief in c should be between
Q1 and Q2; the Dempster-Shafer approach however
gives that Bel(c) = Ql Q2.
But it is clear why the Sandwich Principle is violated
for this approach: knowing either a or -.a increases
our knowledge and hence our belief. In worlds where
n1 1\ -.n2 is true, c may be always false if a is always
false; in the event -.n1/\ n2, c may be always false if
a is always true, and in the event -m1 1\ -.n2 there
is no constraint on c so c may again always be false.
Only in the event n1 1\ n2 can we be sure that c
is true, so making the assumption of independence
of n1 and n2 (which is reasonable without contrary
knowledge) we get Bel( c) , the probability that we're
in a world where we know c to be true, is Q1a2.
This type of rule can also be chained:
n1 1\ a -+ b and n2 1\ b -+ c with Pr(n;) = a;,
(i = 1, 2) leads to (n1 1\ n2) 1\ a -+ c, and again
assuming independence of n1 and n2 this gives
Pr(n 1 /\ n2) = a1a2. If we now learn that a is true we
get Pr(c) � a1 a2 and so Bel(c) = a1 a2, the result
given by application of Dempster's Rule.
Of course the assumption of independence of the n;s
will not always be valid-if correlations between the
rules are known they should be (and can be) incor­
porated.
The Dempster-Shafer approach is thus a natural,
formally justified as well as a computationally ef­
ficient way (see [Wilson, 89] and section 2.2) to rep­
resent If-Then rules.

logic of knowledge). A natural way to extend Demp­
ster's multi-valued mapping [Dempster, 67] is as fol­
lows:
We have a mutually exclusive and exhaustive set 0
with a probability function P on it, and we're inter­
ested in the truth of formulae in L, where L is the
language of some logic. With each 7] E n is associ­
ated a set K'1 (� L): the set of all formulae known
to be true given that '7 is true. For a formula dE L,
Bel(d) is defined to be the probability that we know
d to be true i.e.,
Bel(d) =

L

P(77)
'1"1:=>d

=

L

P(77).
!7=K�3d

Justifying Dempster's Rule for general belief func­
tions is problematic* so we restrict ourselves to the
combination of a finite number of simple support
functions and, to justify this, use the Sources of Ev­
idence framework (based on Shafer's random sources
canonical example [Shafer, 87]; see [Wilson, 89] for
details).
Suppose we have distinct propositions n;, i =
1, ... , m, (not in L) and for each we have a prior
probability Q;. Suppose also that we know that if n;
is true, some evidence Evd; is also true, where Evd;
is a statement about the logic (it might for example
be that the material implication a; -+ c; is true, as
in section 2.1). If n; is not true we know nothing
about the truth of Evd;.
We also allow there to be a set of facts W which are
known certainly to be true.
n; may, as the name of the framework suggests, rep­
resent the event that a source of evidence, which tells
us evidence Evd;, is reliable. Alternatively n; may
be an unknown antecedent of a rule, as described in
the last section; or ni may just be some event for
which, when it occurs, we are sure that the evidence
Evd; is true.
Let 'lu be the elementary event

1\ n; A 1\ -.n;

iEu

if"

and let n be the mutually exclusive and exhaus­
tive set of elementary events { T/u : u � {1, . . . m } } .
Take some probability function P on 0.

* For example there is the problem of the collaps­
ing of the Belief-Plausibility interval, e.g., [Pearl,
We will be interested in extending DST to other log­
89]; see also Shafer's presentations of his random
ics (see [Saffioti, 90] for other work on this, and see
codes canonical example, with discussion [Shafer,
[Ruspini, 87] for a justification of DST using a modal
82a, 82b].
2.2 The Sources of Evidence Framework

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

445

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

If we think ofP as saying, for each 1]11, the probability
that we are in a world in which f111 is true, then Bel(d)
is the probability that we are in a world in which we
know d is true.
Bel maybe viewed as a lower probability given the
probability function P on the underlying space n.
It is argued in [Wilson, 89] that, in the absence of
correlation information on the n;s, certain assump­
tions (A) and (B) are entirely reasonable. (A) is
roughly that, since an unreliable source/rule doesn't
give us any information, it shouldn't affect the prob­
abilities (an example of the application of this as­
sumption is given below in 2.3); (B) is that, if the
sources are not contradictory (i.e., /\';' n; is not
known to be impossible) then we take, for each i,
P(n;) to be a;, its prior value. These assumptions
determine a unique probability function P08 given
by
pDS(c:.,) =

where
and

{ 0, jk
p .,

k

p.,

'

if K., inconsistent,
otherwise,
p.,

=

I:
K.consistent

=IT a; ITC1- a; ) .
iEo

i�11

This is, in fact, the probability function that leads to
Dempster-Shafer belief when each Evd; is that some
proposition p; is true: the belief as defined above will
be the same as that calculated by using Dempster's
Rule to combine simple support functions with mass
a; attributed to the proposition p;, i = 1, ... , m.
Since Belief, as defined here, is just 'randomised
logic' the calculation of Belief inherits its compu­
tational efficiency from that of the underlying logic:
Bel( d) can be calculated, using the following Monte­
Carlo algorithm:
For each trial:-

(i) Pick u with probability P(q.,)
(ii) If K., 3 d then trial succeeds else trial fails.
The proportion of successful trials then converges to
Bel(d).
Given that P( '1u ) is not too hard to calculate, the
calculation takes time proportional to the time it
takes to check if d E Kt!, but with a fairly large
constant term corresponding to the number of trials
needed to get reasonable accuracy.
With the probability function P = P05, step (i) can
be performed very easily. Since any sensible measure

of belief should collapse to the logic for the extreme
case, its computational efficiency cannot hope to be
better than that of the underlying logic. Thus the
calculation of Dempster-Shafer belief is as fast, up to
a constant, as the calculation of a measure of belief
could possibly be. In particular it is shown in [Wil­
son, 89] that (up to arbitrary accuracy) Dempster­
Shafer Belief on a mutually exclusive and exhaustive
frame of discernment can be calculated in time ap­
proximately linear in the number of evidences and
size of the frame of discernment.
2.3 Rules Not Allowing Contraposition

Some rules do not allow contraposition. For exam­
ple the rule Typically males don't have long beards
seems reasonable, and even mildly informative, but
on meeting someone with a long beard, it would be
unreasonable to deduce that they were female. In
order to represent rules not allowing contraposition,
inference rules such as a / c will be used which, like
the rules used in many Expert Systems, given a, al­
low the deduction of c, but given -.c, do not allow
-.a to be deduced.
Suppose we have a set of rules If a; then c; :
(a;) for i = 1, . . . , m, (a; s and c;s closed wffs in
first order logic) for which we do not wish to allow
contraposition. Let I = { a; / c; : i = 1, ... , m}
where the (certain) inference rule a; I c; means 'if
we know a; we can deduce c/, and let I., = {a; I c; :
ieu}.

For some set U of closed wffs and set of inference
rules J we define Th1 (U) to be the logical closure of
U when all the inference rules in J are added to the
logic i.e., the set of formulae obtained by applying
all the inference rules in J repeatedly to U, so that
Th1 (U) is the smallest set r such that
(i) r 2 u,
(ii) Th(r) = r and
(iii) if a I c E J and a E r then c E r'

where Th(r) means the logical closure of r within
first order logic.

Abbreviate Th1.. (W) to Th17(W).
To represent this set of rules within the sources of
evidence framework we make the ith evidence be
that the inference rule ai I c; is added to the logic
(so that whenever a; is known, c; may be deduced).
To be precise, we set K., to be Tht! (W).
This includes the uncertain material implications,
described in 2.1, as a special case: make, for all i,
the ith inference rule equal T I (a; - c; ) .

44·6

I

Example

3. Default Rules

Whilst attempting to deduce information about our
acquaintance Nixon we learn that he is a quaker and
a republican, so that W = {quaker,republican}.
Two rules, If quaker then pacifist : Ca-1) and
(a-2) are also
If republican then -,pacifist :
known.
To represent these we take Evd1 to be that the first
rule is correct and that the corresponding inference
rule quaker /pacifist should be added to the logic,
and similarly for Evd2.
Thus if n1 then, if at any time we learn quaker, we
will deduce pacifist. This gives

An alternative to rules with numerical uncertainty
are default rules-in the absence of information in­
dicating that the circumstances are exceptional, the
rule is fired, though the consequence of the rule may
later have to be retracted, if it's discovered that cir­
cumstances are in fact exceptional.

Ke = Th(W) = Th( {quaker, republican})
K{l} = Th(W U {pacifist})
K{2} = Th(W u {-,pacifist})
K{l,2} = Th(W U {pacifist, ...,pacifist}).

Since K{1,2} is inconsistent, P(nt /\n2) must be 0. In
order to come up with a probability function P we
make certain independence assumptions. Knowing
only about one rule, the first, we would obviously
take P(n1) = a-1; adding an unreliable second rule
doesn't give us any information so shouldn't change
this probability i.e., we make the assumption that
P(n1l..,n2) = O't. Symmetrically we make the as­
sumption P(n2j-.nt) = a-2. Both these assumptions
are instances of assumption (A) mentioned above in
2.2. Only in worlds when n1 1\ -.n2 is true (when
u = {1}) do we know pacifist, and only in worlds
-.nl 1\ n2 ( u = {2}) do we know -.pacifist, so

3.1 Default Logic

Reiter's Default Logic [Reiter, 80) is a logic for rea­
soning with default rules. A default rule is a rule of
the form 'If we know a then deduce c, as long as b
is consistent', or a : b I c for short.
Let � = (D, W) be a closed default theory where L
is the language of a first order logic, W � L, a set of
closed wffs, are the facts and D is the set of default
rules
a; : b; .
;
: '= 1, . .. ,m
-c--

{

}

where a;, b; and c; are closed formulae, for each i.
It turns out that Reiter's default logic can be ex­
pressed in terms of inference rules. Let I = {a; I c; :
i = 1, . . . , m}. The behaviour of the defaults in D
will be mimicked by use of the corresponding infer­
ence rule in I.
Let S = {Th"Y(W): -y � {l, ... m}}. S contains all
the sets of formulae produced by applying different
subsets of the inference rules to W.
For some K E S an inference rule a; I c; may have
been applied even though b; is inconsistent (i.e.,
-.b; e K), in which case the inference rule was not
behaving like the corresponding Default rule. Then
we say that K is A-inconsistent. Formally this prop­
erty can be defined as follows:

I
I
I
I
I
I
I
I
I
I

K E S is �-consistent if and only if there exists a
� {1, ... m} with K = Th"Y(W) and K � -.b; for
all i e 1'·

I

In default logic the extensions are intended to be
the different possible completions, using the default
rules, of an incomplete set of facts about the world.

I

-y

If the reliabilities of the two rules are the same then
Bel(pac ifist) = Be l(-.pacif iat) . If, on the other
hand, the first rule is very reliable, but the second
isn't so reliable then Bel(pacifist) will be close to
1 and Bel(-.pacifist) will be close to 0.

I

Theorem 1:

Th"Y(W) where

E is an extension if and only if E
i = { i : -.b; fl. E }.

=

This shows that extensions are �-consistent sets in

S. In fact we have

If E is an extension of A then E is a
maximal �-consistent set in S.

Theorem 2:

E is said to be

M-extension of
if E is a maximal .6.-consistent set inS.
Definition:

an

.0.

I
I
I
I
I

447

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

M-extensions are formed by applying 8S many in­
ference rules as possible without contradicting �­
consistency. Theorem 2 showed that extensions are
always M-extensions.

to infinity, and given £ > 0 there exists N, such that
for all z > N, and for all p E L
Bel(g:(z),p)
Bel(g:(z),p)

Let � be a closed normal default
theory. Then E is an extension of Ll if and only if
E is a maximally �-consistent set in S.

Theorem 3:

Thus for closed normal default theories E is an ex­
tension if and only if E is an M-extension.
M-extensions have for general closed default theories
the nice properties extensions only have for closed
normal default theories:
Theorem 4:
M-extension.

Every closed default theory has an

Let Ll =
(D, W), �' = (D', W) be closed default theories
with D � D'. If E is an M-extension of � then
there exists an M-extension E' of�' with E' ;;2 E.

Theorem 5 (Semi-monotonicity):

We ca.n also define

an M-default proof, in a.n obvious
way, which is complete, that is for any dosed wff p
there is an M-default proof of p if and only if p E E
for some M-extension E.
It might be suggested that any M-extension of a de­
fault theory which is not an extension is not a sen­
sible completion of one's knowledge: this however
is not the case e.g., there are apparently coherent
default theories that allow no extension (see [Wil­
son, 90] for an example, and also for proofs of the
above results) but which, by Theorem 4, allow M­
extensions.
M-extensions turn out to be the modified extensions
defined in [Lukaszewicz, 84] (also see [Besnard, 89]).

3.2 The Sources of Evidence Framework
as

a Logic

To turn the Sources of Evidence Framework into a
Logic, we tend the reliabilities of the sources (the
a is) to 1. B-extensions are the sets of formulae
whose belief can be made to tend to 1. We can
consider Bel as a function Bel(g:,p) where .9: =
(at. a2, ... , am) is the vector consisting of the re­
liabilities of all the sources.
To use the Sources of Evidence framework to pro­
duce a logic we require that for any closed wff p,
Bel(p) tends to either 0 or 1. A B-extension is then
the set of formulae whose belief tends to 1.
Formally E is a B-extension if and only if
for i = 1, .. . , m there exist monotonic functions ai :
[1, oo) - [0,1) with ai ( z) tending to 1 as z tends

>

1- £ if pEE
if p �E.

< £

Example Co ntinued

In the case of Nixon we have 2 B-extensions. When
the reliability of the first rule tends to 1 much
faster than that of the second rule we get that
Bel(pacit ist) tends to 1, and Bel(-.paci:f ist)
tends to 0 so K{l} = Th(W U {pacifist}) is a B­
extension.
Similarly K{2} = Th(W U {-.pacifist}) is a B­
extension.
Theorem

for some

u.

6:

If E is a B-extension then E

=

Ku

If we don't have information about correlations be­
tween the sources we can reasonably make assump­
tions (A) and (B) giving p = p08 .
Theorem 7: With P = P08 , E is a B-extension
if and only if E = K17 for some u maximal with K17
consistent.
3.3 Representation of Default Rules in
Sources of Evidence Framework

Default rules will be represented in the Sources of
Evidence framework by treating them rather like nu­
merical rules with a high, but unknown, certainty:
roughly speaking we make the ith evidence Evd; be
that the inference rule ai I Ci is a correct rule, as we
did in 2.3, and take the limit as the reliabilities of
the sources (that is, the certainties of the rules) tend
to 1, to produce the B-extensions.
In the example we found that the B-extensions were
just the same as Reiter's extensions. This was no co­
incidence: when the probability function pDS on 0 is
used the B-extensions are exactly the M-extensions
of the default theory.
3.3.1 Closed Normal Default Theories

Let� be a closed normal default theory. We want
the ith evidence to be that the inference rule ai I Ci
17
is a correct rule, so, formally, we set Kt? = Th (W),
08
and also set P = P .
Theorem 8: Let� be a closed normal default the­

ory. With the above representation of Closed Nor­
mal Default rules within the Sources of Evidence
framework

448

E is a B-extension <=> E is an M-extension of .6.
is an extension of .6..

<=> E

condition

b;

P05. To represent the consistency

=

we have to be a little trickier. We first

add new distinct symbols q1, ... , qm to the alphabet
of the language to get a new language

L'.

We want the statement of the ith source to be that

inferences rules a; / q;, q; / c;, -.b; /-.q; are correct
rules. The idea is that knowing a; will enable us to
deduce c; unless

known, in which case we will

-.b; is

get an inconsistency since we'll know both q; and
-.q;.

To be precise we let

be the theorems of

K� � L'

when the inference rules

Ju

a;

q;

{-,

=

-

C;

q;

,

-.b;

-

:

-.q;

.
aE

W

K�

n

L,

so that

Ku

mentioning some q;.

is

u}

9:

rule), and

P(n2l....,n1)

sumption to make.
This gives P(n1

=

02

=

0,

A n2)

tent, P(n1 A -.n2)

o1 (since P(n1)

is still an intuitive

since

K{l,2}

01, P(-.nl A n2)

as­

is inconsis­

(1 - ol)a2,
P(-.nlA-.n2) = (1-ol)(l-o2), and Bel( -.:flies) =
o1, Bel(:fli es ) = (1- al)o2.
Here Th( {penguin, bird, -.flies}) is the only B­
=

=

extension.

5. Combining Numerical and Default Rules
It has been shown how the Sources of Evidence

to

1, default

rules. The next step is to combine both

within this framework.

Suppose that our knowledge includes both default

K� �rTh'"' (W).
wffs in L so let Ku

be

rules and numerical rules. F irst we represent both

as evidences, which add an inference rule to the logic,

in the sources of evidence framework (which includes
the contrapositioning rules as a special case).

This gives the following result:

Theorem

=

framework can represent either numerical rules, or,

stripped of all formulae

K�

In this case we specify P(nl)

reflect that pref­

taking the limit as the reliabilities of the rules tend

are added to the logic, that is,

We're only interested in the

P that

should be unaffected by the addition of a second

3.3.2 General Closed Default Theories
We again set P

on the probability function
erence.

I

W ith the representation of Default

rules in the Sources of Evidence framework described
above, for any set of closed wffs E

We

first consider only the default rules, and produce the

B-extensions. Then we add the other rules/sources
to get a belief function in each B-extension.

E is a B-extension if and only if E is an M-extension.

BEL (d) is defined to be the minimum
.
value of Bel(d) over the extensions, a rather conser­

4. Expressing Preferences between Rules

mum value of Bel(d). If BEL.(d) is high this gives

Suppose we have two rules,

-.:flies :

(al),

and

Co2), and two facts,

If penguin then

If bird then :flie1

:

W ={penguin, bird}.

Expressing these as inference rules gives, as in the
Nixon example,

For dE

L,

vative measure; BEL.(d) is defined to be the maxi­

at least some reason for believing d: there is some
combination of default rules which if correct lend

high support to d.

extensions could also be a useful measure.

Another way of looking at this is to consider Bel

as a function of the unknown, but high reliabilities

g_

BEL (d) is then info-1Bel(g_,p),
- .
and BEL.(d) is sup _1Bel(g_,p).
g_

= (alJ ..., am)·

6.

ansmg

from

Some average of Bel over the

assumptions

P(n21-.nl) = a2.

P(n1l....,n2)

=

o1,

But since we know that penguins are a subclass of

Concluding Comments

We have given counter-arguments to some of Pearl's
criticisms of the use of belief functions to represent

rules and argued that the Dempster-Shafer Theory

is a natural way to represent a type of If-Then rule.

birds it seems that the first rule should override the

If it is known that the rules are correlated, then the

get Bel(-.:flies)

which should not be changed

and so a more general belief function approach such

The preference of some sets of rules over others are

allow the dependencies between the rules to be in­

second: if we only knew about the first rule we would

= 01

on learning the second rule.

represented by making some different assumptions

independence assumptions may well not be justified,

as the sources of evidence framework is needed to

corporated in the underlying probability function P.

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

449

I
I
I
I
I
I
I
I
I
I

Dependencies must also be used, as described in sec­
tion 4, to represent dominance of certain rules (or
chains of rules) over others. We have shown that
this belief function approach also enables the repre­
sentation of default rules.
Another very natural type of rule H a then c :
( a) related to that described in 2.1 is where, again,
there is an unknown antecedent n with n 1\ a - c,
but instead of knowing the prior probability of n,
we know the conditional probability P ( n l a) = a.
With a number of such rules we can take, as before,
Belief as a lower probability, tend the a;s to 1 and
see which Beliefs tend to 1. This is effectively the
approach taken by Adams, Geffner and Pearl. It
would be interesting to explore whether progress can
be made by making independence assumptions on
the n; s, as we did for the type of rule described in
2.1.

It is clear that there is no single correct way of rep­
resenting numerical If-Then rules. Future research
in this area should attempt to clarify wha.t different
types of numerical rule there are, a.nd to represent
them within a single framework.

I
I
I
I
I
I
I

Pearl, Judea, 89, Reasoning with Belief Functions: An
Analysis of Compatibility, Technical Report R-136,
Computer Science Department, UCLA, Los Angeles,
CA. 90024-1596, November 1989.

e i

Ruspini, E. H., 87, Epist m c Logics, Probability and
the Calculus of Evidence,

Conf. on AI

Proc., lOth Inti. Joint

(IJCAI-87), Milan, 924-931.

Saffioti, A., 90, A Hybrid Framework for Representing
Uncertain Knowledge,

AI

Proc., 9th Nat/.

Con/ on

(AAAI-90), Boston, USA.

Shafer, G., 76,

A Mat hematical Theory of Evidence

(Princeton University Press, Princeton, NJ).

Shafer, G. 1982a, Belief Functions and Parametric Mod­
els (with discussion),

tical Society,

Journal of th e R oyal Statis­

series B, 44, No. 3, 322-352.

Shafer, G. 1982b, Lindley's paradox (with discussion),

Journal of the American Statistical Ass oc iation ,

Vol 7, No. 378, 325-351.

Shafer, G., 87, Probability Judgment in Artificial Intelli­
gence and Expert Systems,

Statistical

Science, Vol

2, No. 1, 3-44.

Acknowledgements

Reiter, R., 80, A Logic for Default Reasoning,

I am greatly indebted to Mike Clarke, for numerous use­
ful and interesting discussions, and without whom this
paper could not have been written. I have also enjoyed
many productive conversations with Mike Hopkins and
my colleagues on the DRUMS project.

I
I

Morgan Kaufmann Publishers Inc. 1988, Chapter 9,
in particular 455-457.

ed. J. Hintikka and

Default Logic,

Springer-Verlag,

Berlin, Heidelberg, r-;ew York.
Buchanan, B. G., and Shortliffe, E. H., 84.

expert systems.

Rule-based

Reading, Mass.: Addison Wesley.

Dempster, A. P., 67, Upper and Lower Probabilities In­

Ann. Math.
Statistics 38: 325-39.
Geffner, H., 89, Default Reasoning: Causal and Con­
ditional Theories, PhD thesis, Computer Science
duced by a Multi-valued Mapping.

Department, UCLA, Los Angeles, CA, November
1989.
Lukacewicz,
Proc.

84,

Considerations on Default Logic,

Non Monotonic Reasoning Workshop, New

also, 1988, Computational
Intelligence -1, pp1-16.
Pearl, Judea, 88, Probabilistic Reasoning in Intelli­
gent Systems: Networks of Plausible Inference,
Paltz NY, pp165-193;

Research Report no. 15, June 1989, Dept. of Com­
puting and Mathematical Sciences, Oxford Polytech­

Logic, Research Report, Dept.

P. Suppes. Amsterdam: North Holland.
Besnard, Philippe, 89,

and Generalisation of the Dempster-Shafer Theory,

W ilson, Nic, 90, Rules, Belief Functions and Default

Adams, E., 66, Probability and the logic of conditionals.

Aspects of inductive logic,

13 {1, 2), pp81-132.

Wilson, Nic, 89, Justification, Computational Efficiency

nic.

