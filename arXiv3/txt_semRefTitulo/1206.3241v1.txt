
We propose an approach for approximating
the partition function which is based on two
steps: (1) computing the partition function of
a simplified model which is obtained by deleting model edges, and (2) rectifying the result
by applying an edge-by-edge correction. The
approach leads to an intuitive framework in
which one can trade-off the quality of an approximation with the complexity of computing it. It also includes the Bethe free energy
approximation as a degenerate case. We develop the approach theoretically in this paper and provide a number of empirical results
that reveal its practical utility.

1

INTRODUCTION

We presented in prior work an approach to approximate inference which is based on performing exact
inference on a simplified model (Choi & Darwiche,
2006a, 2006b). We proposed obtaining the simplified model by deleting enough edges to render its
treewidth manageable under the current computational resources. Interestingly enough, the approach
subsumes iterative belief propagation (IBP) as a degenerate case, and provides an intuitive framework
for capturing a class of Generalized Belief Propagation (GBP) approximations (Choi & Darwiche, 2006a;
Yedidia, Freeman, & Weiss, 2005).
We show in this paper that the simplified models can
also be used to approximate the partition function if
one applies a correction for each deleted edge. We
propose two edge-correction schemes, each of which
is capable of perfectly correcting the partition function when a single edge has been deleted. The first
scheme will have this property only when a particular condition holds in the simplified model, and gives

rise to the Bethe free energy approximation when applied to a tree-structured approximation (see Yedidia
et al., 2005, for more on the Bethe approximation and
its relationship to IBP). The second correction scheme
does not require such a condition and is shown empirically to lead to more accurate approximations. Both
schemes can be applied to the whole spectrum of simplified models and can therefore be used to trade-off
the quality of obtained approximations with the complexity of computing them.
This new edge-correction perspective on approximating the partition function has a number of consequences. First, it provides a new perspective on the
Bethe free energy approximation, and may serve as a
tool to help identify situations when Bethe approximations may be exact or accurate in practice. Next, it
suggests that we do not necessarily need to seek good
approximations, but instead seek approximations that
are accurately correctable. To this end, we propose a
heuristic for finding simplified models that is specific
to the task of correction. Finally, it provides the opportunity to improve on edge-deletion approximations
(and certain GBP approximations), with only a modest amount of computational effort. In particular, we
show empirically how it is possible to correct only for
a small number of edges that have the most impact on
an approximation.
Proofs of results appear in the Appendix.

2

EDGE DELETION

We first review our edge deletion framework in probabilistic graphical models. For simplicity, we consider
pairwise Markov random fields, although our framework can easily be extended to general Markov networks as well as to factor graphs. For an application
to directed models, see (Choi & Darwiche, 2006a).
Let a pairwise Markov random field (MRF) M have
a graph (E, V) with edges (i, j) ∈ E and nodes i ∈ V,

function will be denoted by Z 0 (Θ) and its distribution
will be denoted by Pr 0 (.; Θ). When choosing a particular value for edge parameters Θ, we will drop reference
to Θ, using only M0 , Z 0 and Pr 0 (.).

Figure 1: An MRF (left); after edge deletion (right).

ψ(Xi , X j )

i

φ(Xi , Xk )

i

j

ψ(Xk , X j )
k

ψ(Xk , X j )

i

k

θ(Xi )

θ(Xk )

j
j

Figure 2: To delete edge (i, j) (top), we introduce auxiliary node k (middle), and delete equivalence edge
(i, k), adding edge parameters (bottom).
where each node i of the graph is associated with a
variable Xi taking on values xi . Edges (i, j) are associated with edge potentials ψ(xi , xj ) and nodes i with
node potentials ψ(xi ). The (strictly positive) distribution Pr induced by M is defined as follows:
Pr (x)

def

=

Y
1 Y
ψ(xi , xj )
ψ(xi ),
Z
(i,j)∈E

i∈V

where x is an instantiation x1 , . . . , xn of network variables, and where Z is the partition function:
Z

def

=

X Y
x (i,j)∈E

ψ(xi , xj )

Y

ψ(xi ).

i∈V

The basic idea behind our framework is to delete
enough edges from the pairwise MRF to render it
tractable for exact inference.
Definition 1 Let M be a pairwise MRF. To delete
edge (i, j) from M we remove the edge (i, j) from M
and then introduce the auxiliary potentials θ(Xi ) and
θ(Xj ) for variables Xi and Xj .

Note that while the distribution Pr (.) and partition
function Z of the original pairwise MRF M may be
hard to compute, the distribution Pr 0 (.; Θ) and partition function Z 0 (Θ) of M0 (Θ) should be easily computable due to edge deletion. Note also that before
we can use Pr 0 (.; Θ) and Z 0 (Θ) to approximate Pr (.)
and Z, we must first specify the edge parameters Θ. In
fact, it is the values of these parameters which will control the quality of approximations Pr 0 (.; Θ) and Z 0 (Θ).
Without loss of generality, we will assume that we are
only deleting equivalence edges (i, j), which connect
two variables Xi and Xj with the same domain, and
have a potential φ(xi , xj ) that denotes an equivalence
constraint: φ(xi , xj ) = 1 if xi = xj , and φ(xi , xj ) = 0
otherwise. The deletion of any edge in an MRF can
be formulated as the deletion of an equivalence edge.1
As for the values of the edge parameters, we proposed
(and justified) in (Choi & Darwiche, 2006a) the following conditions on θ(xi ) and θ(xj ):
θ(xi ) = α

and

θ(xj ) = α

∂Z 0
∂θ(xi )

(1)

where α is a normalizing constant. Note that the partial derivatives of Equation 1 can be computed efficiently in traditional inference frameworks (Darwiche,
2003; Park & Darwiche, 2004).
Equation 1 can also be viewed as update equations,
suggesting an iterative method that searches for edge
parameters, which we called ed-bp (Choi & Darwiche,
2006a). Starting with an initial approximation M00 at
iteration t = 0 (say, with uniform parameters), we
can compute edge parameters θt (xi ) and θt (xj ) for an
iteration t > 0 by performing exact inference in the
approximate network M0t−1 . We repeat this process
until we observe that all parameters converge to a fixed
point satisfying Equation 1 (if ever).
Note that Equation 1 does not specify a unique value
of edge parameters, due to the constants α. That is,
each value of these constants will lead to a different
set of edge parameters. Yet, independent of which
constants we use, the resulting pairwise MRF M0 will
1

Figure 1 provides an example of deleting an edge.
When deleting multiple edges, note that we may introduce multiple, yet distinct, potentials θ(Xi ) for the
same node Xi . We shall refer to auxiliary potentials
θ(Xi ) and θ(Xj ) as edge parameters and use Θ to denote the set of all edges parameters. The resulting
pairwise MRF will be denoted by M0 (Θ), its partition

∂Z 0
∂θ(xj )

To delete an MRF edge (i, j) that is not an equivalence
edge, we use the technique illustrated in Figure 2: we introduce an auxiliary node k between i and j; introduce an
equivalence constraint on the edge (i, k); copy the original
potential of edge (i, j) to (k, j); and delete the equivalence
edge (i, k). Note that the original model and the extended
one will: (1) have the same treewidth, (2) agree on the
distribution over their common variables, and (3) have the
same partition function values.

have an invariant distribution Pr 0 (.) that satisfies the
following properties. First,
Pr 0 (xi ) = Pr 0 (xj ) =

1
· θ(xi )θ(xj ),
zij

(2)

P
where zij = xi =xj θ(xi )θ(xj ). Next, if the pairwise
MRF M0 has a tree structure, the node and edge
marginals of distribution Pr 0 (.) will correspond precisely to the marginals obtained by running IBP on
the original model M. Moreover, if the pairwise MRF
M0 has loops, the node marginals of distribution Pr 0
will correspond to node marginals obtained by running
generalized belief propagation (GBP) using a particular joingraph for the original model M (Yedidia et al.,
2005; Choi & Darwiche, 2006a).

3

EDGE CORRECTION

the exact partition function Z. Moreover, the result
of this correction is invariant to the constants α used
in Equation 1.
From now on, we will use MI (Xi ; Xj ) to denote the
mutual information between two variables Xi and Xj ,
computed in the simplified MRF M0 . Moreover, when
MI (Xi ; Xj ) = 0, we will say that the deleted edge
(i, j) is a zero-MI edge. Note that while an edge may
be zero-MI in M0 , the mutual information between Xi
and Xj in the original MRF M may still be high.
Let us now consider the more realistic situation where
we delete multiple edges, say E ? , from M to yield the
model M0 . We propose to accumulate the above correction for each of the deleted edges, leading to a corrected partition function Z 0 · z1 , where
z=

Y
(i,j)∈E ?

While the edge parameters specified by Equation 1 are
guaranteed to yield an invariant distribution Pr 0 (.),
they are not guaranteed to yield an invariant partition
function Z 0 as this function is sensitive to the choice of
constants α. Hence, while these edge parameters will
yield an interesting approximation of node marginals,
they do not yield a meaningful approximation of the
partition function.
We will show in this section, however, that one can apply an edge-by-edge correction to the partition function Z 0 , leading to a corrected partition function that
is invariant to the choice of constants α. This seemingly subtle approach leads to two important consequences. First, it results in a semantics for the Bethe
free energy approximation as a corrected partition
function. Second, it allows for an improved class of
approximations based on improved corrections.
3.1

ZERO EDGE-CORRECTION

We will now propose a correction to the partition function Z 0 , which gives rise to the Bethe free energy and
some of its generalizations.
Proposition 1 Let M0 be the result of deleting a single equivalence edge (i, j) from a pairwise MRF M. If
the parameters of edge (i, j) satisfy Equation 1, and if
the mutual information between Xi and Xj in M0 is
zero, then:
Z = Z0 ·

1
,
zij

where

zij =

X

θ(xi )θ(xj ).

xi =xj

That is, if we delete a single edge (i, j) and find that Xi
and Xj are independent in the resulting model M0 , we
can correct the partition function Z 0 by zij and recover

zij =

Y

X

(i,j)∈E ?

xi =xj

θ(xi )θ(xj ).

(3)

We will refer to this correction as a zero-MI edge correction, or ec-z. This correction is no longer guaranteed to recover the exact partition function Z, even if
each of the deleted edges is a zero-MI edge. Yet, if the
pairwise MRF M0 has a tree structure, applying this
correction to the partition function Z 0 gives rise to the
Bethe free energy approximation.
To review, the Bethe free energy Fβ , is an approximation of the true free energy F of a pairwise MRF M,
and is exact when M has a tree structure (Yedidia
et al., 2005). In this case, F = − log Z, so we can
in principle use Fβ as an approximation of the partition function Z, even when M does not have a tree
structure, i.e., we can use Zβ = exp{−Fβ }.
Theorem 1 Let M0 be the result of deleting equivalence edges from a pairwise MRF M. If M0 has a
tree structure and its edge parameters are as given by
Equation 1, we have Zβ = Z 0 · z1 .
Hence, the Bethe approximation of Z is a degenerate
case of the ec-z correction. Thus, IBP and the closely
related Bethe approximation, which are exact when an
MRF M is a tree, are naturally characterized by treestructured ed-bp approximations M0 . In particular,
exact inference in the simplified network M0 yields:
(1) node and edge marginals that are precisely the approximate marginals given by IBP (Choi & Darwiche,
2006a), and now (2) a rectified partition function that
is precisely the Bethe approximation; cf. (Wainwright,
Jaakkola, & Willsky, 2003).2
2
Wainwright et al. proposed tree-based reparametrization (TRP), an algorithm that iteratively reparameterizes
the node and edge potentials of a pairwise MRF. At convergence, the node and edge potentials of a tree (any tree)

Since the ec-z correction is specified purely in quantities available in the model M0 , it will be easily computable as long as the model M0 is sparse enough (i.e.,
it has a treewidth that is manageable under the given
computational resources). Hence, this correction can
be practically applicable even if M0 does not have a
tree structure. In such a case, the correction will lead
to an approximation of the partition function which is
superior to the one obtained by the Bethe free energy.
We will illustrate this point empirically in Section 6.
3.2

GENERAL EDGE-CORRECTION

Proposition 1 gives us a condition that allows us to
correct the partition function exactly, but under the
assumption that the single edge deleted is zero-MI.
The following result allows us, in fact, to correct the
partition function when deleting any single edge.
Proposition 2 Let M0 be the result of deleting a single equivalence edge (i, j) from a pairwise MRF M. If
the parameters of edge (i, j) satisfy Equation 1, then:
Z = Z0 ·

yij
,
zij

where

yij =

X

Pr 0 (xi | xj ).

xi =xj

Note that when the deleted edge (i, j) happens to be
zero-MI, factor yij is 1, and thus Proposition 2 reduces
to Proposition 1.
We can also use this proposition as a basis for correcting the partition function when multiple edges are
deleted, just as we did in Equation 3. In particular,
we now propose using the correction Z 0 · yz , where z is
the same factor given in Equation 3, and
Y X
Y
Pr 0 (xi | xj ), (4)
yij =
y=
(i,j)∈E ?

(i,j)∈E ? xi =xj

which we refer to as a general edge correction, or ec-g.
We note that when every edge is deleted in an ed-bp
network M0 , every deleted edge becomes a zero-MI
edge. Thus, in this case, ec-g reduces to ec-z, and
both yield the Bethe free energy, as in Theorem 1. As
we recover more edges, we may expect ec-g to offer
embedded in the reparametrized MRF induces a distribution whose exact node and edge marginals are consistent
with the corresponding marginals given by IBP. In contrast
to ed-bp, TRP’s embedded-tree distributions are already
normalized, i.e., their partition function is 1. Moreover,
generalizations of TRP appeal to auxiliary representations,
via reparametrization in joingraphs and hypergraphs. In
contrast, the semantics of ed-bp suggest that we simply
delete fewer edges. As we shall see in Section 5, the semantics of edge correction further suggest intuitive edge
recovery heuristics for choosing more structured approximations.

θ (X1)

1

θ (X
(X'1)

2

1

1'

2

3

3

Figure 3: An MRF (left); after deleting edge (1, 2), as
in Figure 2 (right).
improved approximations over ec-z, as it relaxes the
zero-MI assumption for deleted edges. Accordingly, we
may want to delete different edges for ec-g than we
would for ec-z.

4

AN EXAMPLE

We provide here an illustrative example of our edge
correction techniques. Consider a network of three
nodes X1 , X2 and X3 that form a clique, with the following edge potentials:
Xi
xi
xi
x̄i
x̄i

Xj
xj
x̄j
xj
x̄j

ψ(X1 , X2 )
.9
.1
.1
.9

ψ(X1 , X3 )
.1
.9
.9
.1

ψ(X2 , X3 )
.081
.810
.090
.900

Suppose now that we delete the edge (1, 2) by replacing (1, 2) with a chain {(1, 10 ), (10 , 2)} and deleting the
equivalence edge (1, 10 ); see Figure 3. Using ed-bp to
parameterize this deleted edge, we have (to 4 digits):
Xi
xi
x̄i

θ(X1 )
.4789
.5211

θ(X10 )
.8273
.1727

and we compute Z 0 ≈ 0.4447. In this example, edge
(1, 10 ) happens to be a zero-MI edge, so yij = 1 and
zij ≈ 0.4862. Further, we know that both Propositions 1 and 2 allow us to recover the true partition
function Z = Z 0 · z1ij ≈ 0.9146.
Now, suppose that we replace the potential on edge
(2, 3) with 1 − ψ(X2 , X3 ). In this case, ed-bp gives us
edge parameters (to 4 digits):
Xi
xi
x̄i

θ(X1 )
.5196
.4804

θ(X10 )
.1951
.8049

and we compute Z 0 ≈ 0.5053. In this case, edge (1, 10 )
is not a zero-MI edge. Here, we find that yij ≈ 1.0484
and zij ≈ 0.4880. Since we only delete a single edge,
Proposition 2 recovers the true partition function Z =
yij
= 1.08542 whereas Proposition 1 gives only an
Z 0 · zij
approximation Z 0 · z1ij ≈ 1.0353.

5

EDGE RECOVERY

noisy−or: EC−Z
0.12 k=11−20

Suppose we already have a tree-structured approximation M0 of the original model M, but are afforded
more computational resources. We can then improve
the approximation by recovering some of the deleted
edges. However, which edge’s recovery would have the
most impact on the quality of the approximation?
Edge Recovery for EC-Z. Since ec-z is exact for
a single deleted edge when MI (Xi ; Xj ) = 0, one may
want to recover those edges (i, j) with the highest mutual information MI (Xi ; Xj ). In fact, this is the same
heuristic proposed by (Choi & Darwiche, 2006a) for
improving marginal approximations. We will indeed
show the promise of this heuristic for ec-z corrections,
in Section 6. On the other hand, we also show that it
turns out to be a poor heuristic for ec-g corrections.
Edge Recovery for EC-G. Consider the situation
when two equivalence edges are deleted, (i, j) and
(s, t). In this case, we use the approximate correction:
Z0 ·

yij yst
y
= Z0 ·
,
z
zij zst

y

ij
where zij
is the single-edge correction for edge (i, j)
yst
and zst is the single-edge correction for edge (s, t).

The question now is: When is this double-edge correction exact? Intuitively, we want to identify a situation
where each edge can be corrected, independently of the
other. Consider then the case where variables Xi , Xj
are independent of variables Xs , Xt in M0 .
0

Proposition 3 Let M be the result of deleting two
equivalence edges, (i, j) and (s, t), from a pairwise
MRF M. If the edge parameters of M0 satisfy Equation 1, and if MI (Xi Xj ; Xs Xt ) = 0 in M0 , then:
Z = Z0 ·

yij yst
.
zij zst

This suggests a new edge recovery heuristic for ec-g
approximations to the partition function. Initially, we
start with a tree-structured network M0 . We assign
each deleted edge (i, j) a score:
X
MI (Xi Xj ; Xs Xt ).
(s,t)∈E ? \(i,j)

We then prefer to recover the top k edges with the
highest mutual information scores.

6

EXPERIMENTS

Our goal here is to highlight different aspects of edgecorrection, edge-recovery, and further a notion of partial correction. Starting from a random spanning tree

relative error

0.1 k=6−10
0.08
0.06
0.04 k=1−5
0.02
0

k=0−0

0

39

edges recovered

79 80

Figure 4: Edge correction in noisy-or networks.
(dropping instances where ed-bp and hence IBP, do
not converge), we rank each deleted edge, and recover
edges k at a time until all edges are recovered. At
each point, we evaluate the quality of the approximab − Z|/Z, where
tion by the average relative error |Z
b
Z denotes the designated approximation. Remember
that in a tree-structured approximation, when no edge
is recovered, ec-z corresponds to the Bethe approximation. Likewise, when every edge is recovered, both
ec-z and ec-g are exact. Although, for simplicity, we
presented our edge-correction framework in the context of pairwise MRFs, some of our experiments are
run on Bayesian networks, to which all of our results
also apply.3 In these cases, observations are generated
from the joint distribution over all leaves, unless otherwise specified.
Noisy-or. We consider first random two-layer noisyor networks. Deleting an edge in this network effectively disconnects a cause variable C from an effect
variable E, where a clone Ĉ replaces C as a a cause
of E.4 In this situation, we may use edge-correction
to reason how well ec-z and the Bethe approximation
may perform. With no positive findings, for example,
we know that all causes are pairwise mutually independent, including a cause C and its clone Ĉ in a noisy-or
network where edges have been deleted. Starting from
a tree-structured approximation, corresponding to the
Bethe approximation, every recoverable edge is zeroMI and will remain zero-MI up to the point where all
edges are recovered. Thus we may infer ec-z to be
exact throughout, and thus also that the Bethe approximation is exact.
Consider now Figure 4, which compares the quality of
ec-z corrections as edges are recovered randomly. We
generated over 400 random noisy-or networks,5 where
3

Most of the Bayesian networks used here are available
at http://www.cs.huji.ac.il/labs/compbio/Repository.
4
As in Section 2, we replace edge C → E with a chain
C → Ĉ → E, and delete the equivalence edge C → Ĉ.
5
Each network was given 20 roots and 20 sinks, where

for each network, we randomly chose k of 20 effect
variables as positive findings and the remaining effect
variables as negative findings. We have 4 cases here
measuring the quality of the ec-z approximation, each
an average over a range of positive findings: 0, 1–5,
6–10, 11–20. As predicted, the ec-z and Bethe approximations are exact with 0 positive findings. Given
this, we expect, and observe, that with more positive
findings, and fewer zero-MI edges, the ec-z and Bethe
approximations tend to be less accurate.
Edge recovery. Consider now Figure 5, where we
compare ec-z corrections to ec-g corrections, but also
the impact that different edge recovery heuristics can
have on an approximation. Here, plots are averages of
over 50 instances. In the first plot, we took random
6×6 grid networks, where pairwise couplings were randomly given parameters in [0.0, 0.1) or (0.9, 1.0]. First,
when we compare ec-z and ec-g by random edge recovery, we see that ec-g is a notable improvement
over ec-z, even when no edges are recovered. When
we use the mutual information heuristic (MI) designed
for ec-z, the ec-z approximations also improve considerably. However, ec-g approximations are worse than
when we randomly recovered edges! Although ec-g
approximations still dominate the ec-z ones, this example illustrates that ec-z approximations (based on
the Bethe approximation) and ec-g approximations
(based on exact corrections for a single edge) are of a
different nature, and suggest that an alternative approach to recovery may be needed. Indeed, when we
use the mutual information heuristic (MI2) designed
for ec-g, we find that ec-g easily dominates the first
four approximations. We see similar results in the
win95pts and water networks.
Partial corrections. Although the individual edgecorrections for ec-z are trivial to compute, the corrections for ec-g require joint marginals. In the case
where we need to correct for many deleted edges, the
ec-g corrections of Equation 4 may become expensive
to compute. We may then ask: Can we effectively
improve an approximation, by correcting for only a
subset of the edges?
Consider then Figure 6, where we plot how the quality of our approximation evolves over time (averaged
over 50 instances), over two steps: (1) the ed-bp
parametrization algorithm, and after convergence (2)
ec-g edge correction. On the first half of each plot,
we start with a tree-structured approximate network,
and compute the ec-z approximation as ed-bp (and
equivalently, IBP, in this case) runs for a fixed number
of iterations. Eventually, the edge-corrected partition
function converges (to the Bethe approximation), at
sinks are given 4 random parents. Network parameters
were also chosen randomly.

which point we want to compute the edge corrections
for ec-g. We can compute the corrections for an edge,
one-by-one, applying them to the ec-z approximation
as they are computed. Since edge corrections are invariant to the order in which they are computed, we
can then examine a notion of a partial ec-g approximation that accumulates only the correction factors
for a given subset of deleted edges.
On the right half of each plot, we compute the error
in a partial ec-g approximation given two separate
orderings of deleted edges. The first ordering, which
we consider to be “optimal”, pre-computes corrections
for all edges and sorts them from largest to smallest.
In the win95pts network, we find that in fact, most
of the edges have very little impact on the final ec-g
approximation! Moreover, the time it took to compute the most important corrections required only as
much time as it took ed-bp (IBP) to converge. This
suggests that it is possible to improve on the Bethe approximation, with only a modest amount of additional
computation (in the time to compute corrections for
the important edges).
Of course, such an approach would require a way to
identify the most important corrections, without actually computing them. In (Choi & Darwiche, 2008), we
proposed a soft extension of d-separation in polytree
Bayesian networks that was shown to be effective in
ranking edges for the process of edge recovery (as in
ec-z). Applying it here to the task of ranking edgecorrections, we find that it is also effective at identifying important edges for correction. For example, in the
win95pts network, soft d-separation (sd-sep) is nearly
as competitive with the “optimal” at producing partial ec-g approximations. Moreover, soft d-separation
is much more efficient, requiring only node and edge
marginals to rank all deleted edges.
We see a similar story in the pigs and mildew network. In the mildew network, where many deleted
edges have an impact on the approximation, the quality of the approximation tends to improve monotonically (on average), so we may still desire to perform as
many individual corrections as resources allow.

7

EDGE CORRECTIONS AND
FREE ENERGIES

As the Bethe free energy is an edge-corrected partition
function, ec-z and ec-g approximations can be viewed
also from the perspective of free energies.
When the model M0 is a tree, ec-z yields the influential Bethe free energy approximation (Yedidia et al.,
2005). When the model M0 has cycles, it can be
shown that ec-z corresponds more generally to jo-

0.05

EC−Z,rand
EC−G,rand
EC−Z,MI
EC−G,MI
EC−G,MI2

0.3
relative error

relative error

0.06

water

win95pts

0.4

EC−Z,rand
EC−G,rand
EC−Z,MI
EC−G,MI
EC−G,MI2

0.04
0.03
0.02

0.025

0.2

0.02
0.015
0.01

0.1

0.005

0.01
0
0

EC−Z,rand
EC−G,rand
EC−Z,MI
EC−G,MI
EC−G,MI2

0.03

relative error

6x6 grid
0.07

edges recovered

0
0

25

edges recovered

0

37

edges recovered

35

Figure 5: ec-z versus ec-g, and edge recovery.
win95pts

0.6
0.4
0.2
0
0

mildew
ED−BP
EC−G,opt
EC−G,sd−sep

0.8
relative error

relative error

0.8

pigs

1

ED−BP
EC−G,opt
EC−G,sd−sep

0.6
0.4

100

0
0

150

0.3

0.2

0.1

0.2

50

ED−BP
EC−G,opt
EC−G,sd−sep

0.4

relative error

1

500

1000

time (ms)

1500 2000
time (ms)

2500

3000

0
0

5000

10000
time (ms)

15000

Figure 6: Time to parametrize by ed-bp, and compute ec-g corrections.
ingraph free energy approximations (Aji & McEliece,
2001; Dechter, Kask, & Mateescu, 2002); see (Choi &
Darwiche, 2006a) for the connection to iterative joingraph propagation.
The ec-g correction can also take the form of another
free energy approximation. Note first that when multiple equivalence edges are deleted, we can compute the
0
partition function Zij
of a model M0ij where the single
edge (i, j) has been recovered (keeping edge parameyij
0
. Therefore,
ters for all other edges fixed): Zij
= Z 0 · zij
we have that:
0
Y yij
Y Zij
y
.
= Z0 ·
Z0 · = Z0 ·
z
zij
Z0
?
?
(i,j)∈E

(i,j)∈E

0 y
This yields a (dual)
P energy of0 the form − log(Z · z ) =
0
(n−1) log Z − (i,j)∈E ? log Zij , where n is the number
of equivalence edges (i, j) deleted. Whereas we fixed,
somewhat arbitrarily, our edge parameters to satisfy
Equation 1, we could in principle seek edge parameters optimizing the above free energy directly, giving
rise to EP and GBP free energy approximations with
higher-order structure (Welling, Minka, & Teh, 2005).
On the other hand, edge recovery heuristics for ec-g
could possibly serve as a heuristic for identifying improved EP and GBP free energies, directly. This is a
perspective that is currently being investigated.

While we are concerned mostly with IBP and the
closely related Bethe free energy approximation, we
expect that an edge-correction perspective may be use-

ful in improving other reasoning algorithms, particularly those that can be formulated as exact inference
in simplified models. These include, as we have shown
here, IBP and some of its generalizations (Yedidia
et al., 2005), but also numerous variational methods (Jordan, Ghahramani, Jaakkola, & Saul, 1999;
Wiegerinck, 2000; Geiger, Meek, & Wexler, 2006) and
their corresponding free energy approximations. Also
related, is tree-reweighted belief propagation (TRW)
(Wainwright, Jaakkola, & Willsky, 2005), which provides upper bounds on the log partition function, and
can be thought of as a convexified form of the Bethe
free energy. Mean field methods and its generalizations are another well-known class of approximations
that provide lower bounds on the partition function
(e.g., Saul & Jordan, 1995; Jaakkola, 2001). Although
the latter have been found to be useful, others have
found that the Bethe free energy can often provide better quality approximations, (e.g., Weiss, 2001). Similarly, comparing ec-z approximations and mean-field
bounds derived from approximations with the same
structure, we find that ec-z, which does not guarantee bounds, offers better approximations.

8

CONCLUSION

We proposed an approach for approximating the partition function which is based on two steps: (1) computing the partition function of a simplified model which
is obtained by deleting model edges, and (2) rectifying

the result by applying an edge-by-edge correction. The
approach leads to an intuitive framework in which one
can trade-off the quality of an approximation with the
complexity of computing it through a simple process
of edge recovery. We provided two concrete instantiations of the proposed framework by proposing two
edge correction schemes with corresponding heuristics
for edge recovery. The first of these instantiations captures the well known Bethe free energy approximation
as a degenerate case. The second instantiation has
been shown to lead to more accurate approximations,
more so when edge recovery is targeted towards accurate correction. We further highlighted, in our experiments, how edge correction could be used as a conceptual tool to help identify situations where the Bethe
approximation may be exact, or accurate. Finally, we
suggested a notion of partial correction, that can improve on the Bethe approximation with only a modest
amount of computational effort.

This work has been partially supported by Air Force
grant #FA9550-05-1-0075 and by NSF grant #IIS0713166.

PROOFS

Note that Proposition 1 follows from Proposition 2.
Proof of Theorem 1 When a given model is a tree,
the Bethe free energy is exact. We then consider
the exact energy of a tree-structured M0 where F 0 =
− log Z 0 . Our goal then is to show that Zβ = Z 0 · z1 ,
or equivalently, F 0 = Fβ − log z.
Let E[ . ] denote expectations and H (.) denote entropies with respect to IBP beliefs, and equivalently,
ed-bp marginals in M0 (Choi & Darwiche, 2006a).
First, note that Fβ = Uβ − Hβ where Uβ is the Bethe
average energy
X
X
Uβ = −
E[ log ψ(Xi , Xj ) ] −
E[ log ψ(Xi ) ]
i∈V

(i,j)∈E

and where Hβ is the Bethe approximate entropy
Hβ =

X
(i,j)∈E

H (Xi , Xj ) −

The average energy U 0 and the entropy H 0 for M0 is
X

U0 = −

E[ log ψ(Xi , Xj ) ] −

X

−

X

H =

X

(ni − 1)H (Xi )

i∈V

where ni is the number of neighbors of node i in M
(for details, see Yedidia et al., 2005).
It will be convenient to start with the case where every
edge (i, j) in the unextended model is replaced with a
chain {(i, i0 ), (i0 , j 0 ), (j 0 , j)}. We then delete all equivalence edges (i, i0 ), (j 0 , j) ∈ E ? . Note that the resulting

E[ log ψ(Xi ) ]

E[ log θ(Xi )θ(Xi0 ) ]

(i,i0 )∈E ?
0

X
i∈V

(i0 ,j 0 )∈E

H (Xi , Xj ) +

X

H (Xi ).

i∈V

(i0 ,j 0 )∈E ?

Since θ(xi )θ(xj ) = zij Pr (xi ) (see Equation 2), we have
E[ log θ(Xi )θ(Xi0 ) ] = log zij − H (Xi ).

(5)

We can show through further manipulations that
X

E[ log θ(Xi )θ(Xi0 ) ] = log z −

X

ni H (Xi ).

i∈V

(i,i0 )∈E ?

Acknowledgments

A

network M0 has n + 2m nodes: n nodes i ∈ V, and 2
clone nodes i0 , j 0 for each of the m edges (i0 , j 0 ) ∈ E.

After substituting into Uβ0 , and some rearrangement:
F 0 = U 0 − H 0 = Uβ − Hβ − log z = Fβ − log z
as desired. To show this correspondence continues to
hold for any tree-structured M0 , we note first that
IBP beliefs continue to be node and edge marginals for
any tree-structured ed-bp approximation M0 . Next,
when we recover an edge into a tree approximation
that yields another tree approximation, we lose an
expectation over edge parameters (Equation 5). The
corresponding node entropy H (Xi ) that is lost in the
average energy U 0 is canceled out by a node entropy
gained in the entropy H 0 . Finally, the term log zij
that is lost is no longer needed in the correction factor z after recovery. Thus, we can recover edges into
our fully disconnected approximation, and conclude
that F 0 = Fβ − log z continues to hold for any treestructured approximation M0 .

Proof of Proposition 2 In an extended network M
with equivalence edge (i, j) and potential φ(xi , xj ):
Z=

X
xi =xj

X
∂2Z 0
∂Z
=
∂φ(xi , xj ) x =x ∂θ(xi )∂θ(xj )
i

j

X Z 0 Pr 0 (xi , xj )
X Z 0 Pr 0 (xi , xj )
=
=
θ(xi )θ(xj )
zij Pr 0 (xj )
x =x
x =x
i

j

0

=

Z
zij

X

i

j

Pr 0 (xi | xj )

xi =xj
y

ij
which is simply Z 0 · zij
. Note that the fourth equality
follows from Equation 2.


Proof of Proposition 3 In an extended network M
with equivalence edges (i, j) and (s, t) and edge potentials φ(xi , xj ) and φ(xs , xt ):
X
∂2Z
Z=
xi =xj ∂φ(xi , xj )∂φ(xs , xt )
xs =xt

=

X
xi =xj
xs =xt

=

∂4Z 0
∂θ(xi )∂θ(xj )∂θ(xs )∂θ(xt )

X Z 0 Pr 0 (xi , xj , xs , xt )
xi =xj θ(xi )θ(xj )θ(xs )θ(xt )
X Z 0 Pr 0 (xi , xj , xs , xt )
0
0
xi =xj zij Pr (xj )zst Pr (xt )

Saul, L. K., & Jordan, M. I. (1995). Exploiting
tractable substructures in intractable networks. In
Advances in Neural Information Processing Systems
(NIPS), pp. 486–492.

by Eq. 2

xs =xt

=

Wainwright, M. J., Jaakkola, T., & Willsky, A. S.
(2003). Tree-based reparameterization framework
for analysis of sum-product and related algorithms.
IEEE Transactions on Information Theory, 49 (5),
1120–1146.

Z 0 X Pr 0 (xi , xj )Pr 0 (xs , xt )
zij zst xi =xj
Pr 0 (xj )Pr 0 (xt )
xs =xt

X
Z0 X
Pr 0 (xs |xt )
Pr 0 (xi |xj )
=
zij zst x =x
x =x
i

j

0

yij yst
zij zst .

which is simply Z ·

s

Jordan, M. I., Ghahramani, Z., Jaakkola, T., & Saul,
L. K. (1999). An introduction to variational methods for graphical models. Machine Learning, 37 (2),
183–233.
Park, J., & Darwiche, A. (2004). A differential semantics for jointree algorithms. Artificial Intelligence,
156, 197–216.

xs =xt

=

Jaakkola, T. (2001). Tutorial on variational approximation methods. In Saad, D., & Opper, M. (Eds.),
Advanced Mean Field Methods. MIT Press.

t



