
In previous work
studied the

[BGHK92, BGHK93], we have
random-worlds approach�a particul ar

(and quite powerful) method for generating degrees

of belief (i.e., subjective probabilities) from a knowl­
edge base consisting of objective (first-order, slalisti­

cal, and defaull) infonnation. But all owing a k n ow l
edge base to contain only objective in form ation is

­

sometimes limiting. We occa<;ionally wish to include
infonnation about d egrees of belief in the knowledge
base as well, because there are contex t s in which old

be1iefs represent importan t information that should
influence new beliefs. In this paper, we describe three
quite general techniques for extending a method that
generates degrees of belief from objective informa­
tion to one that can make use of d egrees of belief as
well. All of our techniques

are

ha<;ed on well-known

approaches, such a5 cross-emropy. We di sc uss gen­

eral connections between the techniques and in partic

­

ular show that, although concept u ally and technically
quite different, all of the t echniques give the same
answer when applied to the random-worlds method.

1

halpern@almaden.ihm.com

Daphne Koller

Computer Science Division
University of California, Berkeley
Berkeley, CA 94720
daphne@cs.berkeley.edu

principle determine if the agent's objective information is
cmTect (by ex amin ing what is actually the case in its envi­
ronment), we cannot so ea<;ily say that its subjective beliefs
are '-Xmcct. The truth or falsity of these pieces of informa­
tion is not detc nni n ed by the state of the environment.
Although su b j ecti ve infonnation could take many differ­

ent l(mns. we will concentrate here on

degrees of belief

arc probabilities that are assigned to fonnulas ex­
pressing objective a sse rti ons. For example, the assertion
"the weather is warm in New York" is an objective one: it

These

is either true or false in the agent's environment. But when

we <L..; sig n a degree of belief to this assertion, as above, we

obtain

a

subjective a�sertion: it becomes a statement about

the state of the agent's be l ie fs. In tl1e context of probability

d is tinction between subjective and objective can

theory the

appear somewhat subtle. be cau se some form of objective
information (such <L<; proportions

or frequencies) obey the

laws of probahility,j ust a<; d o degr ees of belief. Yet the dis­

tincrion can be a significant one if we want to use or interpret

a pmbahilistic theory conectly. Camap's work

[Car50]

is

notewort11y for its care ful distinction between, and study
of, both st at i s tical

degree of belief

probabilities, which are objective, and
probabil it ies, which are subjective.

In order to und erstand

Introduction

vide

a

this distinction, it is useful to pro­

formal semantics for degrees of belief that captures

the difference between them and objective information. As

When we examine the knowledge or information possessed
by an agent, it is useful to distinguish between

subjective

objective information. Objective information is infor­
mation about me environment, whcrca� su�iective informa­
and

tion is infonnation about the state of the agen t s hcliefs. For
example, we might c hara ct erize the infonnation of an agent
'

travelling from San Francisco

to New York as con�isting of
the objective infonnation tlmt the weather is warm in San
Francisco, and the subjecti ve infotmation that the proba­

bility rhat the weather is wann in New York is 0.2. The
important thing to notice here i s tlmt altl10ugh we can in
*This research has been supported in p art by the Canadian

Government through their NSERC nnd IRIS programs, by the

Air Force Office of Scientific Research (AFSC) under Contract
F49620-91-C-0080, and by a University of California President's

Postdoctoral Fellowship. The United States Government is au­
thorized to reproduce nnd distribute reprints for govemmentJI
purposes.

,Joseph Y. Halpern
IDM Almaden Research Center
650 Han·y Road
San Jose, CA 95120-6099

dcmonstraled by Halpern [Hal90], a natural, and very gen­

eral . way to give a
d efi nin g
worlds.1

semantics

to degrees of belief is by

probabi li ty distribution over a set of possible
The degree of bel ie f in a fonnul a r.p is then the

a

probab il it y of the set of worlds where r.p is true. In this
framework we can characterize o�j ective infonnation as
consisting of assertions ( ex pressed as fmmulas} that can
he assi gned a truth value by a single world. For example,
in any given world Tweety the bird does or does not fly.
Hence, the fonnula Fly(Tweety) is objective. Statistical
assertions such as IIFly(x)IBird(J:)II'"

i m atel y

80% of

�

0.8, read "approx­

birds fly", are also objective. On the other

hand, Pr( Fly(Tweety))

=

0.8, expressing the assertion that

1Conceptually. this notion of world is just as in classical
··possibl�-worlds semantics": a complete picture or description
of tht! way the world might he. Formally, we take a world to be
an intcrprctntion (model) for first-order logic.

Bacchus, Grove, Halpern, and Koller

38

the agent's degree of belief in Tweety !l yi ng

is 0.8, is n ot

objective, as its truth is determined by whether or not tlle
pr obability of the set of worlds where Tweety flies is

0.8.

Although we cannot easily characterize an agent's degr ees
of beliefs as being correct or incorrect, it is nevertlleless
clear that these beliefs should have some rel ation to objec­
tive reality. One way of guaranteeing this is to actually

generate them from the objective information available to
the agent. Several ways of doing this h ave been consid­
ered in the literature; for example, [BGHK92, PV92] each

discuss several possibilities. The appr oach es in {BGHK92)
are based in a very natural way on tlle semantics des cr ib e d
above. Assume we have a (prior) probability distribution
over some set of worlds.

We cru1 t11e n generate degr ees

of belief from an objective know ledge ba�e KB by u sin g
standard Bayesian conditioning: to t11e formul a 'P we a�­
sign as its degree of belief the conditional prob ab i lity

of

r.p given KB. In [BGHK92] we considered three particu­
lar choices for a prior, and i nve stigat ed the properties of
the resulting inductive inference sy stem s.

In

[BGHK93]

we concentrated on the simp lest of these methods-the
choice of prior is essen­

random-worlds m eth od-whose

tially the uniform prior over the se t of possible worlds.

More precisely, suppose we re strict our attention to worlds
(i.e., interpretations of ru1 appropriate vocabul ary for first­

order logic) with t11e domain

{ I, . . . , N}.

Assumin g we

have a finite vocabulary, there will be only finitely many

such worlds. Random worlds ta kes a'> the set of worlds all

of these worlds, and uses p erh ap s the s i mpl e st probability
distribution over them-the uniform distribution�thus as­
suming that each of t11e worlds is eq u ally likely. This gi ves
a prior distribution on the set of pos sibl e worlds. We can
now induce a degree of belief i n 'P gi ven KB by using the
conditional probability of 'P

given Kll with respect to this
of

uniform distribution. II is ea-;y to see that the degree

belief in r.p given KB is then s i mply tJ1e fraction of possible
worlds satisfying KB that also sati s fy 'P· In general . how­

ever, we do not know the domai n size N; we know only
that it is typically large. We cm1 therefore appro x i mate the

degree

of belief for the true but unknown

N

by computing

the limiting value of this degree of be l ief as N g rows large.
This limiting value (if it exists, which it may not) is denoted

�( r.piKB), and it is what the rando m -w orld method takes

to be the degree of belief in 'P given

KB. In [BGHK93], we

showed that U1is method posse ss es a number of anractive
properties,

such. as a prefe renc e for more

specific infonna­

tion and the ab i lity to ignore inelevant information.
The random-worlds method Clli1 generate degrees of be­
Iief from rich k nowledge b ases that may contain first-order.
statistical , and default information. However, w; with any

conditioning process, is limited to deal ing

with objective

information. When we add subje cti ve formulas to

KB. we

can no longer simply c ond iti o n on KB: the conditioning
process eliminates those worlds inconsistent with our infor­

mation, while U1e truth of a subjective formula cannot be
determined by a single world.2

Hence, we would like to

2
In the context of random worlds (and in other cases where
the degrees of belief are de termined using

a

prior

on

the

set

of

extend the nmdom-worlds method so as to enable it to deal
with both objective and subjective information.
Why do we wrun to take into account subjective beliefs?
There are a number of situations where this seems to make
sense. For example, suppose a birdwa tcher is interested
in a domain of birds, m1d has an obj ective knowledge base
KBbird con si sting of t11e statistical inf ormation

IICardinal(x)i-.Red(.1�)11x � 0.1
IICardina/(;t)IRed(x)llx � 0.7.

1\

Now the b irdw at cher catches a glimpse of a bird

b flying by

that seems to be r ed. The birdwatcher is trying to decide

if b is a cru·dinal.

By the results of [BGHK93], if the

birdwatcher assumes U1at U1e bird is n ot red, random-worlds

gi ves

1\

Prr�(Cardinal(b)IKBbird

-.Red(b))

::::: 0.1. On the

other hand, if she assumes tlmt the bird is red, we get

Red( b))::::: 0.7.

But it does not

to he able to generate a d eg ree of b eli ef

in Cardinal( b)

P•J.:::(Conlinal(b)IKB,;,-rJ

1\

seem ap prop riate for her to do either; rather we would like
that takes into acco u nt the birdwatcher's degree of belief in

Red( b).

For example, if this degree of

be lief is 0.8, then

we would like to use a kn owled ge ba<>e such as KBb;rd 1\
Pr ( Red( b ) ) = O.R. It seems re asonable to expect that the

resul t ing degree of oclief in

Cardinal(b)

somewhere bet wee n the two e xtremes of

would then be

0. 7 and 0.1.

As ano ther example, suppose we have reason to believe

that two sensors are independent. For simplicity, suppose

the sensors measure temperature, and report it to be either

high, h. or low. I. We can imagine t11ree unary predicates:
S/(.r), indica ting that sensor 1 reports the value x; S2(x),

and Actual ( x ) , i ndi cating
That the sensors are inde­
pen d ent (given the actual value) can be represented by the
:11
co nj unct i o n over all choices for .r:, .1J, and J
i n {I, h} of:

a similar predicate for s ensor
that the act u al

Pr(S/(:t')
=

2;

temperature is ;r:.

1\ S2(.r")IActual(;r))

Pr(Sl(:t')IActua/(;r))

x

Pr(S2(x")IActual(x)).

It co u ld he tha t we h ave dctennined that ilie sensors are
independent through the observation
readings.

of a n umber

of test

Such e mpirical evidence c oul d be summarized

by a stati s t ical assertion �md thus added to our knowledge

base without req u i ring a degree of be lie f statement like ilie

ab ove. However. this is not the normal situation. Rather, we

arc more likely to have based our belief in independence

on other i n form ation. such a'>

our

beliefs

about causality.

For example, the sensors may h ave been built by different
manufacturers.

In this ca�e. it seems most reasonable to

represent this kind of informa tion using an assertion about
degrees of belief.

How, t hen , can we incorp or at e information about degrees of
belief into the ran d om -worlds framework? More generally,
3
given any inference proce,u -i.e., a method for generat­
ing degrees of belief from objective infonnat i on-we would
worlds). this problem can be v iewed as an instance of the general
problem of conditioning a distribution on uncertain evidence.
3The term ··inference process" is taken hom Paris and Vencov­

sko I PVX91. Our framework is slightly different from theirs, but
we think t h i s usage of the term is consistent with their intent.

Generating New Beliefs from Old

like to extend it so that it can also deal with subjective infor­
mation. This is an issue that has received some attention re­
cently [PV92, Jae94b, Jae94a]. We discuss lhree techniques

39

by us in g cross-entropy [KL51]. Given two probability dis­
tributions p and p', the cross-entropy of p1 relative to J.l,
denoted C(1/, 1•), is a meao;;ure of how "far" J.t1 is from J.l

here, and consider their application in the specific context
of random worlds. As we shall see, all of our techniques

a p rior

are very closely based on well-known ideas in the litera­
ture. Two make use of cross-entropy, while the t11ird is a

can t11en find the distribution on worlds satisfying the con­
s train ts tllat minimizes cross-entropy relative to the prior,

generalization of a method considered by Paris and Vencov­

ska [PV92]. They are conceptually and

formally d istin ct

,

yet there are some interesting connections between them.
In particular, in the context of random-worlds they gener­
ally yield the same answers (where the compruison makes
sense; the various methods have different nmges of applica­
bility). Many of the results we discuss are, in general terms

if not in specific details, already known. Nevertlleless, th eir
combination is quite interesting.
We now describe the three methods in a lillie more detail.
The first method we exrunin e is

perhaps the simplest to ex­
t1Je context of random worlds.
Fix N. Random worlds considers all of the worlds that have
domain { 1, ... , N}, ru1d assumes they are equal ly likely,
which seems reasonable in the ab sence of information to
the contrary. But now suppose that we have a degree of
belief such as Pr(Red(b)) = 0.8. In thi s case it is no longer
reasonable to assume that all worlds are equally likely; our
knowledge base tells us that the worlds where b is red are
plain. We consider it first in

[SJ80, Sho86]. Given an inference method that generates

and

and a set of constraints determined by the KB, we

then use t11is new distribution to compute degrees of
We call this method CEW (for cross-entropy on

belief.

worlds).
The next method we consider also uses cross-entropy, but
in

a completely different way. Suppose we have the (ob­

KBbird given above, and a separate
(Pr(Red(b)) = 0.8). As we sug­
gested, if the birdwatcher were sure Umt b was red, random
worlds would give a degree of belief of 0.7 in Cardinal( b);
similarly, if she were sure that b was not red, random worlds
would give 0.1. Given that her degree of belief in Red{b)
jective) knowledge base

."

beli e f

ha<;e" BBbird

is O.R. it seems reasonable to a�sign a degree of belief of
O.R x 0.7 + 0.2 x 0.1 to Cardinal(b). In fact, if we consider
any inference process I ( not necessarily one that generates
a prior prnhahility on possihle worlds), it seems reasonable
to ddine
I (Cardinal( b) I KBhird 1\
=

he equally likely, we
divide the worlds into two sets: those which satisfy Red(b)
and those which satisfy -.Red( b). Our beliefs require that
the first set have probability 0.8 �md the second probability
0.2. But otherwise we can make the worlds within each set
equally likely. This is consi ste nt with the random worlds
approach of making all worlds equally likely. Intuitively,
we are considering the probability dis t ibut ion on the worlds
that is as close as possible to our ori g i nal uniform distribu­
tion subject to the constraint that the set of worlds where
Red( b) holds should have probability 0.8.
tion. Rather than taking all worlds to

r

What do we do if we have ru1 inference

process other than

random worlds? As long as it also proceeds by generating
a prior on a set of possible worlds and then conditioning,
we can deal with at least tl1i s examp le.

We simply use the
ao;;sign relative weights to
the worlds in the sets determined hy Red(b) and -.Red( b),
and then scale these weights wi thin each set so that the sets
are assigned probabi l i ty 0.8 ru1d 0.2 respectively (Readers
familiar with Jeffrey s rule [Jer92] will realize that this is es
sentially an application of that rule.) Again, intuitively, we
are considering the distribution closest to Ute original prior
that gives the set of worlds satisfying Red(b) probabi l ity
prior generated by the method to

.

­

'

0.8.
Unfortunately, the knowledge bao;;e is rarely this simple.
Our degrees of belief often place co mple x constraints on
the probability distribution

over possihle worlds. Never­

theless, we would like to maintain the intuition that we are
considering the distribution closest to the original prior
"

"

that satisfies the constnunts imposed by the KB. But how
do we determine the "closest" distribution? One way is

0.8

x

+

more likely than the worlds where b is not red. Nevenheless,

there is a straightforward way of incorporating this informa­

=

BBbird)
I(Cardinal(b)JKBbirdi\Red(b))
0.2 x I(Cardinal(b)JKBbird A -.Red( b)).

More

generally, we might hope that given an inference
and a knowledge bao;;e of t11e form KB A BB,
we can gen erate from i t a collection of objective knowl­
edge hase� KD i, .. , KB,. suc h tlmr I( 'PIKB /\ BB) is a
weighted average of I(;pJKBI), ..., I(lf'IKBm). as in the
example. In general. ho wever achieving this in a reasonable
fas h ion is not so easy. Consider t11e belief base BB�;rd =
(Pr(Red(b)) = 0.8) 1\ (Pr(.'inw/!(b)) = 0.6). In this case,
we would like to d efi ne 1 (Cardinal( b )JKBbird 1\ BB�;rd) us­
ing a weighted average of I(Cardinal(b)JKBbird /\Red(b) 1\
Snwll(b)), I(Cardinal(b)IKBbint 1\ Red(b) 1\ --,Smnll(b)),
etc. As in the simple example, it seems reasonable to take
the we i ght of the tenn l(Cardinal(b)JKBbird 1\ Red(b) 1\
Small( b)) to he the degree of belief in Red( b) 1\ Smnll(b).
Unfortunately, while ss;,;rd tells us t11e degree of belief in
Red( /1) and Small( b) separately, it does not give us a degree
of hel ief for their conjunction. A superficially plausible
heu ri sti c would he to ao;; sume that Red( b) and Smnll(b) are
independent. and thus assi gn degree of belief 0.8 x 0.6 to
their conjunction. While this seems reasonable in this case,
at other times it is completely inapp rop riate For example,
if our knowledge base asser ts that all small things are red,
then Red( b) and Snwll( b) cannot be independent, and we
should dearly take the degree of belief in Red(b) 1\ Smnll( b)
to he the same a� the degree of belief in Small( b), namely,
0.6. In general, our new degre e of belief for the formula
Red(b) 1\ Small(b) may depend not only on the new de­
grees of be lief for the two conjuncts, but also on our old
process I

.

,

.

degree of belief

!(Red( b)

1\

Small(b )JKBb;rd).

One reason­

to computing t11ese degrees of belief is to
make the smaflesr c hange possible to achieve consistency
with the hclief hase. Here, as before, cross-entropy is a
u seful tool. Indeed, a� we shall show, there is a way of
able approach

40

Bacchus, Grove, Halpern, and Koller

applying cross-entropy in this context to gi ve us a general
approach. We call Ibis method CEF, for cross-entropy on
formulas. Altbough both CEW and CEF use cross-entropy,
they use it in conceptually d i fferen t ways. As the names
suggest, CEW uses cross-entropy to compare two probabil­
ity distributions over possible worlds, while CEF uses it to
compare two probability distributions over formulas. On
the other hand, any probability distribution on worlds gen­
erates a probability distribution on formulas in th e obvious
way (tbe probability of a formula is the p rob abil i ty of the set
of worlds where it is true), and so we can use a well-known
property of the cross-entropy function to observe that the
two approaches are in fact equiv ale nt when they can hmh

be applied.

It is worth noting that the two approach es are actua.lly in­
comparable in their scope of application. Because CEF is
not restricted to inference processes tlJat generate a pri or
probability on a set of possible worlds, it can be app lied
to more inference processes than CEW. On the other hand,
CEW is applicable to arbitrary KB's while, as we shall see,
for CEF to apply we need to make mo re restrictions on the
form of the KB.

the metho ds also agree when appli ed to our version of the
ME process and when applied to random worlds. Putting
t11e results together, we can show that all these metbods­
CEW, CEF, and RS-agree when applied to random worlds
and in fact, CEW and CEF agree in general. In addition,
,

t11e r esu lt ing extension of random worlds agrees with the
approach obtained when we apply CEF and RS to the ME

process.

The rest of this paper is organi zed as follows. In the next

sect i on we r evi ew the formal model of [Ha190] for degrees

of belief and statistical information, and some material from
[13GHK93] regarding the random-worlds method. We give
the formal definitions of t11e three metbods we consider in
S ecti on 3, and discuss their equivalence. In passing, we
also d i sc uss the conn ecti on to Jeffrey's rule, which is an­
other very well known met11od of updating by uncertain
infonnation. We conclude in Section 4 witb some discus­
sion or computational issues and possible generalizations
of lhesc approaches.

2

Technical preliminaries

In Ibis paper, we focus on two instantiations of CEF. The
first applies it to the random-worlds method. The seco n d

2.1

used by Paris and Venco vska [PV89] ( an d simililr in spirit to
the metbod used by Jaeger [Jae94b)). which we henceforth
call the ME (inference) process. Using results of [GHK92,
PV89], we prove that t11ese two instm ll ia l ions are equivalent.

and reaso n with hoth statistical information and degrees of
belief. We hriclly review the relevant mmerial here. We
sta rt with a standard first-order la ngu a ge over a finite vo­
cabulary <�, and a u gment it with proportion expressions
and belief expressions. A basic proportion expression has
the form 1!1/•(;r)!O(J:)IIx and denotes the proportion of do­

applies it to a variant of the maximum-entropy approach

The third method we consider also app l i es only to certain
types of in ference processes. In panicu1ar, it take� a.<. its
basic intuition that all degrees of belief must ultimately he
the result of some statistical process. Hence, it re q u ires an
inference process tlmt cm1 gene rate degrees of belief from
statistics, like random-worlds. S uppo se we have the belief
Pr(Red(b)) = 0.8. If we view th is belief as havin g arisen
from some statistical sampling process, then we can regard
it as an abbreviation for statistical information ahout the
class of individuals who are '�just li ke b". For example, say
that we get only a quick glm1ce at b, so we are not certain
it is red. The above asser ti on could be con strued as being
an abbreviated way of saying that 80% of the objects that
give a similar sense perception are red. To capture this
idea formally we can view b as a membe r of a small set
of (possibly fictional) ind ividual s S that are "'just like b" to

the best of our knowledge, and ass u me that our degrees of
belief about b actually represents the statistical information
aboutS: IIRed(x)IS(x)llr � 0.8. Once all degree ofhelief
assertions have been convert e d into statistical assertions.
we can tben apply any method for in fer r in g degn:es of
belief from statistical knowledge bases. We call this the
RS method (for representative set). The general intuition
for this metbod goes back to s tatistical mechanics [Lan80J.
It was also defined (independently it seems) by Paris and
Vencovska [PV 92); we follow their presentation here.
Paris and Vencovska showed t11 a t the RS method and the
CEF metbod agree when app li ed to their version of the ME
process. Using results of[GHK92, PV89], we can show that

A fit·st-ol'<ler

logic of probahility

In [Hal90), a l o g ic is presente d that allows us to represent

main elements s atis fyin g 1j; from among those elements
satisfyin g B. (We take 111/;(.1:)11., to be an abbreviation for
11�1·( ;r) lmw(.r )11., . ) On the other hm1d, a basic beliefexpres­
.

.l.ion has

the form

Pr( 1/J IO) m1d denotes tbe agent's degree
0. The set of p roport ion (resp. belief)

or belief in 11• g i ven

expressions is formed by ad din g the rational numbers to the
set of basic proportion (resp. belief) expressions and then
closing off und er addition m1d mu lt ip lica tio n
.

We compm·e two pro por ti on expression s using the approx­

( ap pro xim at ely less than or equal");
the result is a proportion formu l a. We use { � {' as an
abbreviation for ({ ::5 e) 1\ ({' ::5 0· Thus, for example,
we can express the stateme nt "90% of birds fly" using the
proportion formula IIFly(x)IBird(x)llx � 0.9.4 We com­
pa re two belief expressions using standard �; the result is
a basic belief{ormula. For example, Pr(Re d(b)) � 0.8 is a
ba�ic belief form ula . (Of course Pr(Red(b))
0.8 can be
expressed as the o hv io us c onjunct ion ) In the full language
£ we allow arbitrary llrst-order qu ant i fication and nesting
of belief and proportion formula'>. For example, complex
imate connective ::5

"

,

=

.

fonnulas like

in£.

Pr{V:t(I!Knmvs(:r., y)IIY ::5

0.3 ))

� 0.5

are

4We remark that in [Hal90] there was no use of approximate
equality

(�).

We use it here since, as argued in [BGHK93], its

use is crucial in our intended applications. On the other hand, in

[DGI !K93], we used a whole family of approxima te equality func­

tions of the form�;. i
we use only one here.

=

1, 2, 3, . .

..

To simplify the presentation,

Generating New Beliefs from Old

We will also be interested in various sublanguages of £ . A
fonn ul a in which the "Pr" operator does not appear is m1
objective formula. Such fonnulas are assigned truth values
by single worlds. The sublanguage restricted to objective
fonnulas is den oted by c obj . The standard rand om- worl ds
method is restricted to knowledge bases expressed in cobj .
l
The set of belief formulas, c oe is fanned by starting with
,
basic belief formulas and closing off under conju nction ,
n eg ati on , and first-order quantification. In contra<;t to ob­
j ective fonnulas, the truth value of a be l ief fonnula is com­
pletely i ndepen dent of the world where it is evaluat ed . A
flat formula is a B ool ean combination of belief formulas,
such that in each belief expression Pr( 'P ) , the formula 'P is a
closed (i.e., con taining no free variables) obj ective form u la.
(Hence we have no nesti nr, of "Pr" in nat formulas nor any
"quantifying in".) Let £! at be the language consisting of
the fiat fonnulas.
give semantics to botl1 proportion form u l a-; and belief
formulas, we use a special case of what were called in
[Hal90] type-3 structures. In part i cu l ar, we consider type-:�
structures of the fonn (WN , p.), where WN co n si s t s of al l
worlds (first-order models) with domain { I , . . . , A' } over
the vocabu l ary <ll , and Jl is a probabi l i t y distribution over
WN .5 Given a structure and a world i n that structure. we
eval uate a proportion expression 1 1 1/•( :�: ) IO ( .r ) I I .,· as the frac­
tion of domain el emen ts sat isfying 1,1>( ;I' ) among those sat­
isfying O(x ) . We evaluate a belief form u l a us i n g our proha­
bi1ity distribution over tl1e set of possib l e worlds. More pre­
cisely, given a structure M = (WN , 11), a world w E WN ,
a tolerance r E (0, I] (u sed to i n te rpre t ::::::: and ::S ) , and a
val u ati on V (used to i n terpret the free variables), we asso­
ciate with each fonnula a tru tll value and with each belief
expression or proportion expression ( a numher [(j M , ,v, r .
We give a few representative clauses here:

To

w

•

•

If ( is tlle proporti on expression I I \0( .1:) I �{1:) I I ,. , then
[(]M,w , v , r is the num ber of domai n elements i n w sat i s­
fy i ng \0 1\ 1/; d i v i de d hy the numher sat i s fyi n g ''' · (Note
that these n u m bers may depend on w . ) We take this
fraction to be 1 if n o domain elements sat i s fies ·� · .
I f ( is

the belief expression Pr( 'P I I/' ) , then
_

[(] M,w ,V,r Again,
•

p { tv1 : ( M , w' , V, r ) )= 'P 1\ !}• }
p { w' : ( M, w1 , V, r ) )= 1}1}

·

we take this to he 1 i f the denominator is 0.

( m1d ( ' are two proportion
( M , w , T , V) I= ( ::S (' iff

If

expressions.

[(]M,w , r , V :S [(1] M , w , r ,V

+

th e n

T.

That is, approximate less than or eq ual allows a tolerance
of r .

( is a belief expression, th en i t s value i s
in dependen t of the world w. Moreover, i f it is cl osed then
its value is in dep enden t of the val u a t i on V. Thus, we can
write [(]M,, in tllis ca..o;e. Similarly, if <p E £11'1 is a cl o sed

Notice that if

5

In general, type-3 structures

addition a lly allow for a distribu­
{ l , . . . , N} ) . Here, we always

tion over the domain (in this case,

use the unifonn d isui b u ti on over the doma in.

belief form u l a,

its truth depends only on M and r,
)= cp i n this ca<;e.

can write ( M, r )
2.2

41

so we

The random-worlds method

Given these semantics, tlle random-worlds method is now
easy to describe. S uppose we have a KB of objective for­
mula�. and we wrull to a<;sign a degree of belief to a fonnula
tp . Let p'f.v be the uniform distribution over WN , and let
w
M!V = (WN , Jlf.r ). Let Pr»r (cpi K B) = [Pr(cpjKB)]MN , r ·
Typically, we know on l y tl1at N i s large and that r is small.
Hence. we approximate the value for the true N and r by
ddining

P1-: ( 10lKB)

=

lim lim Pr»rw(cpjKB),
N -+-CXJ

-r - 0

a-;suming the limit exists. P1-: ( cpiKB) is the degree ofbelief
in 'P given KI3 acc ord i ng to the random-worlds method.
2.3

Maxi m u m entl'Opy and cross-entropy

The entropy or a probab i l i t y d is tribu ti on Jl over a finite space

n

Lw E n /l ( w ) ln(,l(w ) ) . It ha� been argued [Jay78]
the amou n t of "information" i n a
probabi l i t y di stri b u t i on, i n t h e sense of information tlleory.
The uniform distri bution has the maximum possible en­
t rop y. I n general, g i ven som e constraints on the probability
is -

that entropy measures

with maximum entropy that
viewed as the one that i ncor­
i nfonnation above and beyond

distributions, the distri b u t i o n

satisfies t h e c onst rai n ts cllil be
porates the least addi t i onal
the constrai nts.

The related cross-entropy function measures the additional
information gained by mov i n g from one di stribu ti on Jl to
another uistri hu t ion Jl1:
( ' ( I' , , Jt )
.. ·

=

'\"" '
tl (w)
)
-.
L 1'· ( w In p (w )

wEn

Various arguments have been pre sent ed showing that cross­
meas u res how close one probability distribution is
to ano t he r [S.TRO, S ho86) . Thus, given a prior distribution
I' and a set S' of add i tio nal constraints, we are typically
i n t ere st c u i n th e unique distribution 1/ tllat satisfies S and
minimizes C(p' , p ) . It is well -known tlmt a su fficient con­
dition for such a u n i q u e distribution to exist is that the set
of di stribu tions sat i sfyi n g S form a convex set, and that
t here be at le<L<;t one d i stribution p" sati sfying S such that
C(IJ'' , I ' ) is fi n i te . These conditions often h old in practice.

entropy

3
3.1

The three methods
CEW

As w e ment ioned in

the introduction, our first metllod,

CEW, assumes as input an inference process I that proceeds
by generati ng a pri or Jl f on a se t of possible worlds W1 and
t h e n conditioning on th e objective i n formati on . Given such
an inference process I , a k n owl ed ge base KB (that can con­
tain subjective infonnation) and an objective formula cp, we
wish t o co m p u te CEIV ( I)(<piKB), where CEW(I) i s a

42

Bacchus, Grove, Halpern, and Koller

new degree of belief generator that can handle knowledge
bases that can include subjective infmmation.

We say that an inference process I is world-based if there is
some structure M1 = (Wr , llt )and a tolerance r such that

l(�PIKB) = [Pr(lf'IKB)]M 1,T . Notice that Pr;_;rw is world­
based for each N (where the structure corresponding to
Pr;_;rw is MjV ). �, on the other hand, is not world-ba<;ed;
we return to this point shortly.

Given a world-based inference process I, we define
as follows: Given a knowledge base KB which
can be an arbitrary formula in the full language .C, let Jt.}8
be the probability distribution o n WI su ch t11at C(Jl}8, JlJ )
is minimized (if a unique such distribution exists) among all
distributions tl such that (WI , p' , T ) I= Pr(KB) = l. Intu­
itively, pf8 is the probability distribution closest to t he prior
Jli that gives KB probability l . Let Mf8 = ( WI , JLf8). We
can then define CEW(I)( c.oiKB ) = [Pr( cp)J.�1Ks ' T .

CEW(I)

I

The first thing to observe is that i f KB is objective, then
standard properties of cross-entropy can he used to show
that pf8 is t11e condilional distri b u t i o n I'· I C l KI3 ) . We thus
immediately get:
Proposition 3.1: lfKB is objective, then CEW( I ) ( <.p j K I3 )
l(lf' I KB ) . Thus, CEW(I) is a true extension of !.

=

Another important property of CEW fo llow s from the wel l ­
known fact that cross-entropy generalizes Jeffrey 's rule
[Jef92]. Standard probability theory tells us that if we
start with a probability function p an d observe that event
E holds, we should update to the conditional probabi lity
function Jl. ( · I E). Jeffrey's rule is mean t to ueal w i th the
possibility that rather than get ting certain i n formation. we
only get partial information, such a<; that E hold s with proh­
ability o:. Jeffrey's rule suggests that in tl1 i s case. we should
update to the probability function p' such that

tt'(A)

=

o:JI.( A I E ) + ( I - rr )p ( A IE) .

where E denotes the complement of E. 111 i s rul e uniformly
rescales the probabilities within E and (separately) those
within E so as to satisfy the constrain t Pr( E) = a. Clearly,
if o: = 1 , then Jl1 is j ust the conditional prohab i l i t y p( · I E ) .
This rule can be generalized i n a strai ght forward fashion .
If we are given a family of mutually ex c l u si ve and ex­
haustive events £1 ,
, Ek with de si red new prohahi l i t ies
0: 1 , . .
, ak (necessarily L:i c.r; = 1 ) , t h en we can define:
.

.

•

.

p'(A)

=

a , lt(A I El )

+

·

·

·

+

ni\ I'·( A I Ek) .

Suppose our knowledge base ha�; t he form ( Pr( 'PI ) = n 1 ) A
· · · A (Pr( lf'k ) = a k ) , where the If'; 's are mu tually exclusive
and exhaustive objective fonnulas and c.r 1 + · · + cr., = I .
The formulas lf' l , . . . , lf't.: conespond to mu tually ex clu sive
and exhaustive events. Tilus, Jeffrey's rule would suggest
that to compute the degree of belief in If' g i ven this knowl­
edge base, we should compute tile degree of belief in 'P
given each of the If'; separately, and then take th e linear
combination. Using t11e fact Umt cross-entropy generalizes
Jeffrey's rule, it is immediate that CEW i n fact docs t h i s .
·

Pr·oposition 3.2: Suppose that I is a world-based inference
process and that KB ' is of the form KB A BB, where KB
is objective and B B has the form (Pr( 1;? 1 ) = o: t ) A · A
(Pr( lf'k ) = a t.: ) , where the lf'i 's are mutually exclusive and
exhaustive objective formulas and cq + · · · + o:k = 1. Then
·

·

k

CEW( I )(c,oi KB ' )

=

L o:; I ( If'I KB 1\ cp; ) .
i=l

As we observed above, CEW as stated does not apply di­
rectly t o U1e random-worlds method Pr:. since it is not
wor l d - based . It is, however, the limit of world-based meth­
ods . (This is also true for the ot11er methods considered in
[BGH K92].) We can ea<;ily extend CEW so that it applies
to limits of world-ba<;ed methods by taking limits in the
obvious way. In particular, we define
CEW( Pr':;;;; H 'f' I K B )

=

l i m lim
r - 0 N - oo

CEW(Pr;,;rw)(�PIKB ) ,

provided t he limit exists. For convenience, we abbreviate
CEW ( Pr:; ) as Pr�w .

note that the distribution defined by
d i s tri bu t i on of maximum entropy that
sati sfies the constraint Pr( KB) = l . 1l1is follows from the
observation that the distri bution that minimizes the cross­
entropy from the u n i form distribution among those distri­
butions sa t i s fy i ng some constraints S', is exactly the distri­
bution or max i m um entropy satisfying 5.6 This maximum­
entropy characterization demonstrates Umt Pr�w extends
ran dom worlds by making the probabilities of the possible
worlds "<t<; equal as possi b l e" given the constraints.
It is i n teresting to

CEW( Prrt\� )

3.2

is the

CEF

Paris and Vencovska [PV89] consider inferences processes
that arc n o t world-based, so CEW cannot be applied to
them. The method CEF we now define applies to arbitrary

but requ i res that the knowledge base
form. For the remainder of this section,
we assume that the knowledge ba..;e has the fonn KB 1\ BB,
where KB i s an objective formula and B B (which we call
the hclicr base) is in £11" ' .
inference processes.
be or a re st ri c t ed

BB is of UJe form Pr( th ) =
U1e t/J; 's were mutually exclu­
sive, then we could define C E F ( I)( lf'IBB) so that Propo­
si t io n 3 . 2 he l d . B u t what i f the �;; 's are not mutually exclu­

First. suppose for simplicity that

d1

!\

·

·

·

A

Pr( V-'d

=

Pk · If

sive?

2 !' atoms over �!J ,

, 1/Jt.:. i .e., those
where each 1/J: is
ei t her ·rJ>; or · ·I/J1 • Atoms are always mutually exclusive
and ex h au s t i ve ; so, if we could find appropriate degrees
of helier for these at om s, we could again define things so
that Propo s i t i o n 3.2 holds. A simple way of doing this
Consider the r\·

conj u nct ions o r

=

the form '1/•;

1\

. . .

. . . A l/JI, ,

6We remark that in [GHK92, PV89] a connection was es­
lahlished between random worlds and maximum entropy. Here
maximum entropy is playing a different role. It is being used here
to extend rnndom worlds rather than to characterize properties of
random worlds as in [GHK92, PV89).

Generating New Beliefs from Old

would be to assume that, after conditioning, the a<>sertions
'if;; are independent. But, as we observed in the i ntroduction,
assuming independence is inappropriate in general .
Our solution is to first employ cross-en trop y to find appro­
priate probabi l i ti es for these atoms. We proceed as follows.
Suppose I is an arbitrary i n feren c e process, 1313 E C f1a t ,
and 1/J1 , . . . , 1/Jk are the formulas that appear in subexpres­
sions of the form Pr( 'if;) in B B . We form the K = 2k at oms
generated by the 'if;; , de no ting them by A 1 , . . . , A K . Con ­
sider the probab i l ity Jl defin ed on the space of atoms via
t-t(Aj ) = I(Aj [ KB ) .7 There is an obvious way of defining
whether the formula B B is satisfied by a probability distri­
bution on the atoms A 1 , . . . , Ak (we defer t11e formal details
to the full paper), but i n gen eral B B will not be sat isfied by
the distribu tion 11. For a si mpl e example, if we take the
in ference procedure to be random worlds and consider the
knowledge base KBb;nJA(Pr(Red(b)) = 0 . 8 ) from the intro­
duction, it turns out that P1-: ( Red ( b ) [ K B ,;,-d ) is around 0 . 5 7 .
Clearly, the di stri bu tio n 11 such that p.(Red( b ) ) i s around
0.57 does not satisfy t11e constraint Pr(Red( b ) ) = 0 . 8 . Let
Jl' be the probability d i stribution over the atoms that mini­
mizes cross-entropy relative to p among those t hat satisfy
BB, provided tl1ere is a unique such distribution. We then
define

CEF(I) ( <p[KB A B B )

=

1-" ( A l )I( 'P [ KB A A ! )

+ · · ·+

JJ.' ( A K ) ! ( <p [ KB A A g )

It is immediate from the definition that CEF( I )
Formally, w e h ave
Proposition 3.3:

I('P [ KB).

lf KB, 'P

E

_

extends

/.

c�<j , then CEF( / ) ( ;p [ K B )

=

Both CEW and CEF use cross-entropy. However, t h e two
applicatio ns are quite different. In the cm;e of CEW, we
apply cro ss- en trop y witl1 respect to probabi lity di s t ri bu ­
tions over pos si ble worlds, whereas with CEE we apply i t
to probabi lity distributions over formulas. Nevert hel e ss , as
we mentioned in the i n trod u c ti o n , there is a tight connection

between the approaches, since any probahi l i t y distri bution
over worlds defines a proba bi l i t y distribution over fonn u ­
las. In fact the following eq u i val e n c e can be proved, usi n g
simple properties of tJJe cross-emropy fu nct i on.
Theorem 3.4 :
Suppose I i s a world-based i�[erence
process, KB , <p E co"i , and B B E [fl•< � .
Then
CEW(I)(�P I KB A B B ) = CEF( / ) ( 'P [ KB A B B ).

Thus, CEF and CEW agree
defined.

i n contexts w h ere both are

By analogy to tl1e defin iti on for CEW, we define
Pr��' (cp!KB A BB)

=

lim

lim

r-O N - ro

CEF( Pr�rw ) ( <p [ KB A BB ) .

It immediately follows from Theorem 3 .4 that
7

S ince

BB

Pr cunnot be nested in
1/J'S are necessa1ily objective, an d �o are the

E c,Jlat by assumption, an d

a flat b e lief base, the

atoms they generate. Thus,

l( A1 [KB)

is well defined.

43

Corollary 3.5: {[ KB , IP E Co"i , and BB E [flat, then

Pr�w ( 'P [ K B A B B )

=

Pr;;r(�t?[KB A BB).

As the no t at i on suggests, we view
of rr: obt ai n ed by applying CEF.

Pr�F as the extension

Why did we not define
Pr�F as CEF(Pr: )? Cl earl y CEF(rr,:; ) and Pr�" are
closely related. Indeed, if both are defined, then they are
equal .

ff both CEF(Pr: )(<piKB A BB) and
Pr�r ( 'P I KB A B B ) are defined then they are equal.

Theon:m 3.6 :

It is q u i te p o ssi ble , in ge n e ral , that eitller one of Pr�" and
defmed while the other is not. The fo l l owin g

CEF( Pr� ) is

example demonstrates one type of situation where Pr�"
is dell ned and CEF( PrC: ) is no t. The converse situation
typical ly ru·ises only in pathological examples. In fact, as
we show in Theorem 3 .8, there is an i mportan t class of cases
where the existence of CEF(Pr:; ) g u arant ees that of Pr�F.
Suppose KB is [[Fly( x ) [Bird(x)[[ r �
I A Rird ( Tweety) and B B is Pr(Fly(Tweety) = 0) A
Pr(Red( Tweety) = 1 ) . Then , just as we would expect,
Pr�,"'(Red( lll'eet v) [ KB 1\ BB) = 1 . On the other hand,
CEF( P1�.,: ) (Red( 1\veety ) [ KB A BB) is undefined. To see
why, let ;t be the probabi lity distribution on the four atoms
ucfineu by Fly( 7\veery) and Red ( Tweety) determined by
Pts-:;:: ( · I K B ) . S i nce Pts� ( Fly( Tweety)IKB) = I , it must
he t he case that 11( Fly( Tweety) ) = 1 (or, more accu­
rately, ; t ( Fiy(7iveety) A Red( Tweety ) ) + p(Fly(Tweety) A
-.Red( liveetv) ) = l ) . On th e other hand, any distri­
but ion 1/ over the four atoms defined by Fly(Tweety)
and Red( 7iveety) that sati s fi es BB mu st be s uch that
it' ( Fiy( 7iveety ) ) = 0. It ea<;ily fo l low s that if p' sat­
isfies B B , then C ( p ' , I') = oo .
Thus, there is not a
unique u i st ri h u t i o n over the atom s that satisfies BB and
mi n i m i zes cross-entropy relative to p . This means that
CEI,.( Prr;: ) ( Red( 7\veety ) I KB 1\ B B ) i s undefined. I
Example 3.7 :

We nex t consider what happen s

when we instantiate CEF
process considered by Paris and
VL:ncovska that u ses max i mum e nt rop y [PV89]. Paris and
Vcncovsk a restrict at t e n t i on to rather simple lang u ag es , cor­
respond ing to the notion of " ess e n tial l y propositional" for­
m u l as de f i n ed below. When co ns i dering (our variant) of
the i r method we shal l make the same restriction.
w i th a p art i c ul a r inference

We say that 1/• ( :r ) is an essentially propositional formula
if it i s a quantifier-free fi rst - ord e r formula that mentions
only u nary predicates (and no con stan t or function sym­
bols), whose onl y free variable is x . A simple kno wl ­
edge base K B abollt c ha<> t he form ll'Pt ( x ) IO, ( x ) ll r ::S
o ,

1\

.,_., , , .

. .

. .

- A [ [ <p k ( :r ) [ fh ( x ) [ [ x ::S O:k 1\ 1/;(c), where
. . . , Ok , .,_;, are all essen t ial ly propositional.8

, 'P k , O , ,

The M E i n fe re nce process

is only defined for

a

simple

M Nolice that II'P( x ) fB ( 1: )f[.
t o- is expressible as
11-.'P{-" ) [ B ( :r: ) f l x :::: I - a ; th is means we can also express :::::: .
I Iowcvcr. because of the fact that we disallow negations in a sim­
ple KB . we cannot ex press s trict i ne qu al i ty. This is an important

rcstric lion.

44

Bacchus, Grove, Halpern, and Koller

knowledge base about c and an essen t i al l y propositional
query <p( c) about c. Let KB :::: KB' 1\ ¢ ( c ) be �m essen t ial l y
propositional knowledge base abou t c (where KB' is the
part of the knowledge base that does not mention c). I f the
unary predicates that appear in KB are P = { Pt , . . . , Pk } ,
then KB' can be viewed as pu tti ng constraints on the 21:
atoms over P .9 The fonn of KB' en s ures that U1ere will
be a unique distribution llme over Ulese atoms Ulat maxi­
mizes entropy and sati sfies the constraints. We then de­
fine ME( <p (c) I KB' 1\ Jj;(c)) to be P me ( lf' l 1/! ) . I n t u i t ively, we
are choosing the d istribution of maximum entropy over the
atoms that satisfies KB' , and treating c a<; a "nmdom" ele ­
ment of Ule domain, assuming i t satisfies each at om over P
wiili Ule probabil i ty dictated by Jlme ·
To apply CEF to ME, we also need to put restrictions
on tlle belief base. We say that D B E .c Jra t is an es·

sentially propositional belief base about c i f every basic
proportion expressi on has the fo nn Pr( y( c ) I O ( c ) ) , w here
<p and B are essen t ial ly p roposi t ional (In p art icu lar, this
.

disallows statistical fotmul a<;
simp le belief base about c is

Pr(<pt (c)IBt (c)) ::;

O'J

in the

a

scope
conjunction

1\ · · · Pr( <pl: ( c) I Ok { c) )

of

Pr.)

o f the

::;

ok.

A

form

w h ere

all of tlle fonnulas th at appear are essential l y proposi tional.
We can only apply CEF to ME if the knowledge ba�e has
the fonn KB 1\ BB, where KB is a simple knowledge hase
about c and B B i s a simp l e belief ba�e abou t c. It fo l lows
from results of [GHK92, PV89] that random worlds and
ME give the same results on th ei r common domain. Hence,
they are also equal after we appl y tl1e CEF transformation.
Moreover, on Ulis domain, if CEF(Pr� ) is de fi ned , then
so is Pr�F. (The con verse docs not hold, as shown hy
Example 3 .7.) Thus, we get
Theorem 3.8: If KB is a simple knowledge base about (
BB is a simple belief base about c, and '-P is on essenTially
propositionalformu!a, then
",

CEF(ME)(<p(c) I KB A B B ) :::: CEF( Prr,.: ) ( '-P ( c ) I K D A I3 I3 ) .
Moreover, ifCEF(ME)( <p ( c ) I KB
CEF(ME) (<p(c) IKB A BB)

=

A

B B ) is defined, then

Pr�F('-P( c ) I KB A B B ) .

3.3 RS
The last method we consider, RS, i s based on t he intu­
ition that degree of belief a�sertions must u l timately ari se
from statistical statements. This general idea goes hack to
work in Ule field of statistical mechanics [LanRO), whe re
it has been applied to the problem of reasoning abou t the
total energy of physical systems. If the system consi sts of
many particles then what is, in essence, a random-worlds
analysis can be appropriate. If the energy of the system is
known exactly no conceptual problem arises: some possibl e
configurations have the specified energy, while others are
impossible because they do not. H owever it turns out that i t
is frequently more appropriate to assume that all we know i s
the expected energy. Unfortunately, i t questionable whether
,

9 An

mulas

atom over P is an atom (as de fi ned ahove ) over the for­

P1 ( x ) . . . . , Pk ( x ) .

this i s real l y an "objective" a-;sertion about th e system in
que.� tion , 1 0 and in fact the physicist<; encounter a problem

analogous to that which motivated our paper. Like us, one
response they have con si dered is to modify the assump­
t i o n of unifonn probability and move to maximum entropy
(thus u si n g essent i al l y, an in st ance of our CEW applied to
a uniform prior). But another response is the fol lowing.
Ph ysi cal l y, expected energy is appropriate for systems in
th ermal equilibrium (i e , at a con stant temperature). But
in practice this means Ulat Ule s yste m is in Ulennal contact
with a (general l y much larger) system, sometimes called a
heat bath. So another approach is to model the system of
i n teres t a> being part of a much larger system, including
the h e a t bath, whose total energy is truly fixed. On Ulis
l arger scale, random-worlds is on ce again applicable. B y
ch oosi ng the energy for the total system appropriately, Ule
ex pec t ed energy of the sm all subsystem will be as speci­
fied . Hence. we have converted s u bjective statements into
objective ones, so that we are able to u se our standard tech­
niques. In this domain, there is a clear physical intuition
for the con nec t i on between t11e objective infonnation (Ule
,

.

energy of the

exp ec t ed

.

heat bat h ) and the subjective infonnation (the

energy of the

small system).

A more recent, and q u i t e

di fferent, appearance of Ulis intu­

ition is in t he work of Paris and Vencovska [PV92) . They
dell ned t h ei r method so that i t ha<> the same restricted scope

ME method. We presen t a more general version
here, that can handle a somewhat richer set of knowledge

as th e

bases. al though i t s scope

is still more restricted than CEF. It

can deal with arbitrary inference proces ses,

but Ule knowl­
BE, where KB is
o bj ec ti ve and D B is an essentially p ro po s i ti onal belief base
ah o u t some co n s tant c . The first step in the method is to
transform 13 I3 in t o an objective formula. Let S be a new
unary predicate, representing the set of individuals ·�ust
l i ke c" . We transform BD to KBnn by replacing all tenus
of the form Pr( 1/J( c)ID(c)) by 1 1 1/! ( x ) IB(x) 1\ S(x)ll:t-. and
rep l aci n g all occmTences of ::; by � . We then add Ule
cnnj u ncts I I S( :r l l l, ::::: 0 <md S(c), s ince S is assumed
For example,
to he a small set and c must be in S.
if D B is Pr(Red(c)) ::; 0.8 A Pr(Small(c)) :::: 0.6, then
the nmcsponding KBnn is ( I I Red(x) I S(x)llx � 0.8) 1\
( /ISmu//( :r J IS(:r ) ll, � 0.6) 1\ ( / I S(.z: ) l /�· ::::: 0) I\ S(c). We
then define R S ( ! ) ( <p( c ) IKB A B B ) = I( IP ( c) I KB A KB aa ) .
I t is al most imme d ia t e from the d efin i ti ons that if B B is
a si mple belief base ahout c , then RS(Pr,: )(<p(c) I KB A
D B ) = li mr o limN - = RS(Pr;r)(<piKB). We abbrevi­
a t e R S ( Prr;;: ) as Pr� .
e d g e hase must have the form

KB

1\

-

RS and

CEF are distinct.

This observa­
of [PV92) concerning an infer­
ence process CM, show i ng that RS(CM) cannot be equal
to CEF( CM ) . On th e other hand, Uley show Ulat, in
the restricted setting in which ME applies, RS(ME)
CEF( ME ) . S i nce ME = Pt� in this se t t ing we have:
In

general,

tion fol l ows from results

,

if'lf it is objective. it is most plausibly a statement about the
average energy over time. While this is a reasonable viewpoint, it

does not rea l l y escape from philosophical or technical problems

either.

Generating New Beliefs from Old

Theorem 3.9: If KB

is a simple knowledge base about

c,

tiona! Conference on Artificial Intelligence
(AAA! '92), pages 602-608, 1 992.

B B is an essentially propositional knowledge base about c,
and tf; is an essentially propositional formula, then

CEF(rc:)(<p(c) IKB /\ B B ) "" CEF(ME)(<p(c) ! KB II B B )
= RS(ME)(<p(c) ! KB II B B ) = Pr� (<p(c) I KB II B B ) .
4

Discussion

A . .T. Grove, J . Y. Halpern, and
D. Koller. Statistical foundations for default
rea<;oning. In Proc. Thirteenth International
Joint Conference on Artificial Intelligence (!J­
CA! '93), 1 993.

[BGHK93] F. B acchus ,

[Car50]

that they can deal with degrees of belief. We

view the fact that the three methods essentially agree when

[GHK92]

�Uld RS a;;su m e cert ain res t ri c ­
tions on the form of the knowl e d ge base, which are not
assumed in CEW. Is it possible to ex t en d these methods
so that they apply to more gen eral knowledge bas e s ? In

M . J aeger. A

350,

facts to KB

[Jac1J4b1

prevents

appl icatio n of

U1is idea

belief bases about some const an t
lems we have found trying to

that

prob­
do this seem dirtlcult but

be viewed as
U1ru1 seq ue ntial updat ing here. Sup­
pose our knowledge base co ntains two constraints:
Pr(<pt ) = u 1 1\ Pr(<p2 ) = o·2 · Although we cannot u s u ­
a l l y apply Jeffrey's rule to such a conj unction, we can a p ­
ply the rule seq uentially, first u pdating by Pr( <p1 )
and then by

Pr( <p2)

=

et 2 • We have

= n1 ,

described o u r meth­

ods in ilie context of u p d a t i ng by any set of constrai n t s
at once, but they can also b e defined

to update b y con­
straints one at a time. TI1e two possibilitie.� usual ly give
different results. Sequential updating may not p reserve
any but the last constraint used, and in general is order
dependent. Whether this should be seen

a-; a problem

doing

is wh y this issue can

be

ig nored when

B ayesian condi tionin g in general, and in ordinary

[ KL5 1 l

S . K u l lback and R . A. Leibler. On informa·
t i o n and su fficiency. Annals of Mathematical

bridge, 1992.

Swtistics, 22: 76-86, 195 1 .

[LanXO]

[BGHK92]

F. B acchus,

Physics, volume 1.

.1 . B . Paris and A. Yencovska. On the appli­
ca bi l i t y of max i m u m entropy to inexact rea­
son i n g . International Jo urn a l of Approximate

[PY02]

J.

[ S ho86 ]

J.

Reasoning, 3 : 1 -34, 1 989.

B. Paris and A . Vencovska. A method for up­
dat ing j u st i fy ing minimum cross entropy. In­
ternational Journal qf Approxi mate Reason·
ing, 1 -2: 1 - 1 8, 1 99 2.

E. Shore. R el ative entropy, probabilistic in­
ference, and AI. In L. N . Kanal and J . F. Lem·

mer, edi tors, Uncertainty in Artificial intelli­
gence. North -Holland, Amsterdam, 1 986.

[S.I80]

