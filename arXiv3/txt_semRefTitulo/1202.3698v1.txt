
The First-Order Variable Elimination (FOVE) algorithm allows exact inference to be applied directly to probabilistic relational models, and has
proven to be vastly superior to the application
of standard inference methods on a grounded
propositional model. Still, FOVE operators can
be applied under restricted conditions, often forcing one to resort to propositional inference. This
paper aims to extend the applicability of FOVE
by providing two new model conversion operators: the first and the primary is joint formula
conversion and the second is just-different counting conversion. These new operations allow efficient inference methods to be applied directly
on relational models, where no existing efficient
method could be applied hitherto. In addition,
aided by these capabilities, we show how to adapt
FOVE to provide exact solutions to Maximum
Expected Utility (MEU) queries over relational
models for decision under uncertainty. Experimental evaluations show our algorithms to provide significant speedup over the alternatives.

1

Introduction

Probabilistic graphical models have been widely used over
the last two decades in real-world and research applications. One of their sought after features is the ability to
compactly represent a set of interdependencies among random variables, providing a platform for efficient inference
methods for both exact [1] and approximate [16] inference.
Probabilistic Relational Models (PRM) extend the propositional models by introducing the concept of domain entities, along with a richer language which depicts the properties of each entity and the various interactions which they
exhibit. Naturally, it is desirable, and often much more efficient, to apply inference directly to the relational model,

thus avoiding an explicit extraction of the propositional
model. The act of exploiting the high level structure in
relational models is called lifted inference. This task can
be carried out by a family of exact lifted inference algorithms, which are based on the idea of First-Order Variable
Elimination (FOVE) [12, 3, 9].
An important task which is closely related to probabilistic
inference, is decision making under uncertainty. The tight
connection between the two tasks is exemplified in the influence diagram model [7], a popular model for decision
making. Influence diagrams extend probabilistic models
by adding decision and utility components to probabilistic
graphical models. The quality of a decision, a set of assignments to decision variables in the influence diagram,
is measured by its Expected Utility (EU). Under this principle, the best decision is achieved by maximizing the expected utility, a task that has been studied for both exact
resolution [5] and approximation [11]. In the relational
models realm, the study of decision making in influence
diagrams has focused mainly on first-order MDP [14].
The goal of this paper is to extend the applicability of
FOVE in two directions. First, we enrich the set of operators used by FOVE, by (a) introducing a novel model
conversion method called joint formula conversion, and (b)
generalizing the known counting conversion [9] operator
to support the conversion of just-different atoms [4]. Joint
formula conversion is a procedure which couples together
pairs of atomic formulas, by replacing all their occurrences
in the model with a new formula, whose range is a Cartesian product of the original pair. As we explain and demonstrate empirically, the conversion allows a subsequent use
of efficient inference operators: counting conversion [9]
and inversion [3], where previously one would resort to
grounding. Additionally, the combination of (a) and (b)
allows further lifting in cases that were previously considered hard for lifted inference.
Second, we present a solution to decision making in firstorder influence diagrams [7] based on the FOVE algorithm,
the first lifted solution to the best of our knowledge. Our
method applies a variation of C-FOVE [9] that computes

maximum expected utility (MEU) [5]. We show that variations of counting conversion and inversion can lift the MEU
computation, much like in the belief assessment and MPE
tasks. Similarly to other FOVE variations, experimental
evaluations show our lifted method to be substantially more
efficient than the propositional alternative.
We note that recent works [6, 8, 15] demonstrate the advantage of exploiting the logical structure of first-order formulas (e.g. MLN features [13], preference rules [2]) for
the benefit of efficient lifted inference. FOVE, on the other
hand, operates under no assumption on the logical structure
of the first-order formulas which compose the relational
model. A comprehensive comparison study between these
different approaches has yet to be conducted.

2

Model Representation

Based on Markov Logic Decision Network (MLDN) [10]
and the work of Milch et al. [9], we present a first-order
model which depicts two types of variables: random variables and decision variables, and two types of factors –
probability factors and utility factors.
2.1

Atoms, Constraints and Parfactors

Each variable induced by the model corresponds to a
ground atom of the form p(c1 , . . . , cn ), where p is a predicate of finite range, range(p), and c1 , . . . , cn are constant
symbols. An atomic formula p(t1 , . . . , tn ) where ti is a
constant or a logical variable, is called an atom. Each logical variable X is bound by a domain dom(X) with cardinality |dom(X)|, or |X|. LV (α) is the set of logical
variables referred by α, where α is a formula or a set of
formulas. Under a set of assignments v, the notation α(v)
is used to depict the values assigned to α.
A factor f is a pair (A, η), consisting!of a set of ground
formulas and a potential function η : α∈A range(α) →
R. Under a set of assignments v, the weight of factor f is wf (v) = η(α1 (v), . . . , αm (v)), where A =
{α1 , . . . , αm }. A substitution θ over a set of logical variables L maps each variable in L to a constant symbol or a
logical variable. αθ depicts the result of applying a substitution θ on α.
A constraint C is a pair (F, L), where F is an equational
formula on logical variables set L. gr(L : C) is a set of
substitutions on L under constraint C, where all logical
variables of L are substituted with a constant. Similarly to
previous work [9], we require the constraints to be in some
normal form, where for each logical variable X, |X : C|
has a fixed value regardless of the binding of other logical
variables in C. We use var(α) to depict the set of variables
specified by α under the set of substitutions gr(L : C), and
in-order to distinguish between the two types of variables
in var(α), rv(α) is used to depict the set of random vari-

ables in α, and dv(α) depicts the set of decision variables.
A parfactor g is a tuple (L, C, A, η), comprised of a set of
logical variables, a constraint on L, a set of formulas and a
potential, respectively. Applying a substitution θ over parfactor g results in g " = (L" , C " , Aθ, η), where L" and C " are
obtained by applying substitution on its logical variables,
and dropping those mapped to constants. A ground substitution of a parfactor is a factor which was generated by a
substitution over all the logical variables. The model contains two types of parfactors, probability and utility, which
depict a set of probability and utility factors upon grounding. As a convention, φ depicts a potential of a probability
parfactor, and µ depicts a potential of a utility parfactor.
The weight of parfactor g, depicted by wg (v), is determined according to its type.!The weight of a probability parfactor is wg (v) =
wf (v), and the
f ∈gr(g)"
weight of a utility parfactor is wg (v) = f ∈gr(g) wf (v).
For convenience and clarity, we use the abbreviation
η(α1 (L1 ), . . . , αi (Li ), C) to represent a parfactor constrained by C, which contains a set of formulas α1 , . . . , αi
with their respective variable scopes L1 , . . . , Li . For instance, the notation φ1 (s(X), t(Y, X), {X "= Y }) represents a probability parfactor whose properties are L =
{X, Y }, C = ({X "= Y }, {X, Y }), A = {s, t}, and
η = φ1 . An alternative notation for constraint C is CX#=Y .
2.2

Counting Formulas and Histograms

Counting formulas express a numerical distribution of values on a portion of a formula’s groundings, by counting
the number of groundings that are assigned each possible
value. Instead of covering each possible assignment, the
counting formulas are oblivious to the specific permutations which conform to the count formation. The notation
of counting formulas is #X:C [α] where α is the counted
atom, X is the counted logical variable, and C is the parfactor’s constraint over the counted population. For example, formula #Y :{X#=Y } [f riends(X, Y )] counts the Y
population of any given X in atom f riends(X, Y ), under constraint X "= Y . The range of a counting formula
γ = #X:C [α], depicted by range(γ), is a set of all possible histograms. A histogram is a set of non-negative integer counters, each corresponding to a specific assignment
in range(α), where the sum of all counters is |X : C|.

3
3.1

Joint Formula Conversion
Definition

A joint formula is a composite of two formulas (atoms or
counting formulas), whose range of assignments is a Cartesian product of the range of its components. For example, j(X, Y ) = #a(X, Y ), b(Y, X)$ depicts a joint formula
of atoms a(X, Y ) and b(Y, X), over logical variables X

Table 1: Joint formula j(X, Y ) = !a(X, Y ), b(Y, X)"
a(X, Y )
0
0
1
1

b(Y, X)
0
1
0
1

j(X, Y )
!0, 0"
!0, 1"
!1, 0"
!1, 1"

φ!!
0.2
0.3
0.7
0.7

φ
0.2
0.3
0.7
0.7

p(Z)
0
0
1
1
p(Z)
0
0
0
0
1
1
1
1

a(X, Y )
0
1
0
1
j(X, Y )
!0, 0"
!0, 1"
!1, 0"
!1, 1"
!0, 0"
!0, 1"
!1, 0"
!1, 1"

µ
7
3
2
5
µ!
7
7
3
3
2
2
5
5

and Y . If a and b are boolean atoms with range(a) =
range(b) = {0, 1}, then range(j) = {0, 1} × {0, 1}. The
joined formulas must be of the same type. Namely, both
must be decision formulas or random variable formulas.
Joint formula conversion is the replacement of all instances of a joint formula’s components with the joint
formula itself. Similarly to shattering [3], it can be applied at the beginning or during the inference task. The
conversion conserves the assignment space of the original model, such that each assignment to ground atoms in
the original model is mapped to a single respective assignment in the converted model, and vise versa. Both
assignments, in the original model and in the converted
model, yield the same results in all parfactors. For example, in a two parfactor model φ(a(X, Y ), b(Y, X))
and µ(p(Z), a(X, Y )), a joint formula conversion for
j(X, Y ) = #a(X, Y ), b(Y, X)$ converts the model to
φ" (j(X, Y ), j(X, Y )) and µ" (p(Z), j(X, Y )), such that
under each assignment #va , vb $ to a ground of j, the converted potentials yield the same values as their original
counterparts under assignments va and vb to grounds of a
and b, respectively. Parfactor φ" is compressed further to
φ"" (j(X, Y )), since it contains two identical instances of j.
The example is illustrated in Table 1.
3.2

Motivation and Example Applications

In a sense, joint formula conversion is counter-intuitive.
Most lifting operators aim to reduce the variable assignment space, or to restructure the model without introducing unnecessary dependencies between variables. Joint formula conversion does the opposite – it deliberately introduces dependencies between formulas. However, this modification in structure may allow the inference task to benefit from lifting operators that would not be used otherwise.
More specifically, joint formula conversion is highly efficient in cases where lifting operators are well defined on
the joint formula, but not applicable on the separate components of the joint formula.

sportsFan(X)
friends(X,Y)
drinks(Y)

X != Y

cohesive
X != Y

Figure 1: A Markov logic network for the group cohesiveness
problem: X and Y represent individuals of the same
group, friendships are defined on pairs of individuals
s.t. X #= Y .

Let us demonstrate this with the task of summingout all the random variables from a given parfactor,
φ(a(X, Y ), b(Y, X), c(X, Z), d(Z)). Since both counting
conversion and inversion are inapplicable in this case, some
grounding operation must be applied. However, this overhead can be avoided by applying a joint formula conversion, for which j(X, Y ) = #a(X, Y ), b(Y, X)$. The
conversion yields parfactor φ" (j(X, Y ), c(X, Z), d(Z)),
which in turn can be resolved by a sequence of lifting operators: (a) Applying counting conversion over j(X, Y )
w.r.t. Y . (b) Eliminating c(X, Z) by inversion. (c) Applying counting conversion over d(Z) w.r.t. Z. (d) Eliminating #Y [j(X, Y )] by inversion. (e) Eliminating #Z [d(Z)]
by inversion. The amount of work that was invested in the
joint formula conversion is therefore negligible compared
with the overall computational benefit.
In Section 4, we introduce a variant of counting conversion which allows the conversion of just-different
atoms. This newly introduced variation, combined with
joint formulas, extends the scope of lifted inference in
FOVE even further. For example, Figure 1 presents
the group cohesiveness problem, where each member
of a given group is examined according to two characteristics: affinity to sports and affinity to alcohol.
The problem can be represented by two parfactors:
φ1 (sportsF an(X), drinks(Y ), f riends(X, Y ), CX#=Y )
– the chance of two individuals being friends, and
φ2 (f riends(X, Y ), cohesive, CX#=Y ) – the chance of a
group being cohesive.
In order to find out what are the chances of a group being
cohesive, all variables but cohesive need to be summedout from the model. We start by fusing φ1 and φ2 into
φ(sportsF an(X), drinks(Y ), f riends(X, Y ), cohesive,
CX#=Y ), and eliminating f riends(X, Y ) by inversion,
resulting in φ" (sportsF an(X), drinks(Y ), cohesive,
CX#=Y ).
Since counting conversion and inversion are both inapplicable in the model’s current
form, we apply a joint formula conversion with
j(X) = #sportsF an(X), drinks(X)$. The conversion results in φ"" (j(X), j(Y ), cohesive, CX#=Y ), and can
be followed by a counting conversion of the j instances,
which are just-different atoms. Hence, the model is
converted to φ""" (#X [j(X)], cohesive), and the inference
task resumes without resorting to grounding.

3.3

Logical Variables Mapping

A logical variables mapping (or simply, mapping) between two formulas α and β, depicted by Mα,β , is an
isomorphism from the ordered set of logical variables of
α, LV'(α) = #α[1] , . . . , α[|LV (α)|] $, to the ordered set of
logical variables of β, LV'(β) = #β[1] , . . . , β[|LV (β)|] $,
where α[i] and β[j] depict the i-th and j-th logical variables of α and β under argument list ordering, respectively. Pairing of logical variables from α and β is allowed only in cases where they have the same domain.
For example, a possible mapping between a(X, Y ) and
b(W, Z) is Ma,b = {a[1] ↔ b[2] , a[2] ↔ b[1] }, provided
that dom(X) = dom(Z) and dom(Y ) = dom(W ). We
' to depict a permutation of L
' according to
use Mα→β : L
the mapping from α variables to β variables. In the given
example, Ma→b : #Z, M $ = #M, Z$.
A full mapping between α and β is a mapping over all the
logical variables of both formulas, and a joint formula conversion is defined according to such a mapping. For example, in model φ(a(X, Y ), b(Y, X)), a joint formula conversion over mapping Ma,b = {a[1] ↔ b[2] , a[2] ↔ b[1] }
results in the joint formula j(X, Y ) = #a(X, Y ), b(Y, X)$,
and in a following conversion φ" (j(X, Y ), j(X, Y )),
which can be simplified further to φ"" (j(X, Y )). On the
other hand, a joint formula conversion of the same model
over a different mapping, Ma,b = {a[1] ↔ b[1] , a[2] ↔
b[2] }, results in the conversion φ" (j(X, Y ), j(Y, X)), yielding no computational gain. Hence, joint formula conversions do not necessarily result in a more efficient inference,
and their use should be considered only in cases where
computational gain is guaranteed.
3.4

Usage and Computational Complexity

In the context of current C-FOVE implementations, where
a greedy algorithm is used to determine which operator to
apply next, joint formulas can simply be used when (a) all
other lifting attempts fail, and (b) their placement allows
subsequent counting conversions and inversions. However,
given the proper heuristics, joint formula conversion can be
applied at any phase of the inference task.
The computational complexity of joint formula conversion
is bounded by O(k·rn+1 ), where r is the maximum assignment range of any formula in the model, k is the number of
parfactors which consist of the joint formulas components,
and n is the maximum number of formulas in any of the
subject parfactors.
3.5

Joint Shattering

Before applying a joint formula conversion, a joint shattering has to be carried-out. Joint shattering is identical
to the already known shattering [3] process, only that the

formulas which are about to be joined, α and β, are shattered w.r.t. their instances under the joint formula. Namely,
the joint shattering splits the set of parfactors in the model,
such that parfactors which contain α(L'α ) are treated as if
they contained β(L'β ) as well, where L'β = Mα→β : L'α .
Similarly, parfactors which contain β(L'β ) are treated as
if they contained α(L'α ). Let us demonstrate this with an
example. Assume a model φ(a(X, Y ), b(X, Z), CX#=Z )
which is about to be applied with a joint formula conversion over mapping Ma,b = {a[1] ↔ b[1] , a[2] ↔ b[2] },
where dom(X) = dom(Y ) = dom(Z) = {x1 , x2 }. A
joint formula j(X, Y ) = #a(X, Y ), b(X, Y )$ cannot be
placed in the model’s current form, for two reasons. The
first, is that there are no constraints which prevent an equality between X and Y , hence j(x1 , x1 ) is a possible ground
of j in one of the converted parfactor’s grounding. However, j(x1 , x1 ) implies that the set of random variables in
the original model includes b(x1 , x1 ), which is untrue. A
second reason is that the placement of j would result in
parfactor φj (j(X, Y ), j(X, Z), CX#=Z ), where the two instances of j entail two sets of ground variables which are
neither disjoint nor equal.
A joint shattering of φ(a(X, Y ), b(X, Z), CX#=Z ) treats the
parfactor as if it contained both a(X, Z) and b(X, Y ). In
this case, the parfactor is split on substitution Y /X, where
two parfactors are created: φ1 (a(X, X), b(X, Z), CX#=Z ),
and φ2 (a(X, Y ), b(X, Z)), C{X#=Y,X#=Z} ). a(X, X) here
is practically a different formula than a(X, Y ) where
X "= Y , since the sets of grounds for both are disjoint. Placing the joint formula in the model’s current form
should yield parfactors φ1j (a(X, X), j(X, Z), CX#=Z ) and
φ2j (j(X, Y ), j(X, Z)), C{X#=Y,X#=Z} ).

4

Just-Different Counting Conversion

The notion of just-different atoms was introduced by Braz
et al. [4] for the purpose of counting elimination, but has
yet to be exploited for the purpose of counting conversion.
As mentioned earlier, the combination of counting conversion of just-different atoms with joint formulas, extends the
scope of lifted inference and provides motivation to explore
this variation of counting conversion. For the purpose of
simplicity and clarity, we present a version which converts
pairs of just-different atoms. Note that the procedure can be
generalized to any number of just-different atom. The simple case of counting conversion, where a single formula is
converted, is directly derived from this more general case.
Let parfactor gη contain two instances of formula α: α1 =
α(X, L) and α2 = α(Y, L), where X and Y are logical variables, L is a set of logical variables, X "∈ L and
Y "∈ L. Let any ground substitution of L produce a set
of just-different atoms, namely: for each given substitution
of L, choosing one substitution of X restricts Y in only
one substitution, and vice versa. An example of such a par-

features(X)

revenue(Y)

price(X)

demand(Y,X)

5.1

Formally, G = Gφ ∪Gµ , where Gφ contains a set of probability parfactors, and Gµ contains a set of utility parfactors.
The expected utility (EU) of model G under assignment vd
to (all) its decision variables is given by:

profit

Figure 2: An MLDN for product planning, depicting decision
nodes (rectangles), uncertainty nodes (ellipses), and
value nodes (diamonds).

factor is φ(α(Z, X), α(Z, Y ), CX#=Y ). Finally, let both X
and Y be owned exclusively by their α instances, such that
no other formula in g contains neither X nor Y .
A counting conversion of formulas α1 and α2 over logical variables X and Y in parfactor gη is a conversion of
gη = (Lη , Cη , Aη , η) to gη! = (Lη! , Cη! , Aη! , η " ), by replacing the two α instances with an arity-reduced counting
formula #X:Cη [α], and defining a potential η " , such that in
probability parfactors
η ! (N, b1 , . . . , bk ) =

!

η(a1 , a2 , b1 , . . . , bk )#(N,a1 ,a2 )

a1 ,a2 ∈range(α)

(1)

and in utility parfactors
η ! (N, b1 , . . . , bk ) =

"

η(a1 , a2 , b1 , . . . , bk ) · #(N, a1 , a2 )

a1 ,a2 ∈range(α)

(2)

Where
#(N, a1 , a2 ) =

#

$
%
#(N, a1 ) · #(N, a2 ) − 1
#(N, a1 ) · #(N, a2 )

a1 = a2
a1 #= a2
(3)

a1 and a2 are assignments to grounds of α1 and α2 ,
b1 , . . . , bk are assignments to grounds of all other formulas, and histogram N = {n1 , . . . , nr } is a set of counters for each possible assignment of"
a ground of α under
r
the conditions r = |range(α)| and i=1 ni = |X : C|.
#(N, a) depicts the value of the entry which counts assignment a. The rest of gη! properties are obtained by Lη! =
Lη \ {X, Y }, Aη! = Aη \ {α1 , α2 }, and Cη! = Cη ↓Lη! (the
projection of the remaining logical variables). A number
comb(N ) is then attributed to each histogram N
comb(N ) = &

|X : C|!
a∈range(α) #(N, a)!

(4)

Where comb(#χ1 , χ2 $) = comb(χ1 ) · comb(χ2 ) in joint
formulas, and comb(χ) = 1 in atoms.

5

MEU

FOVE for MEU

To capture relational decision making settings, we use
a model based on Markov Logic Decision Network
(MLDN) [10]. The model includes probability and utility parfactors, and two types of formulas: random variable
formulas and decision formulas.

eu[G](vd ) =

#
1 # $
wg (vd ) ·
wg (vd )
Z

(5)

g∈Gµ

rv(G) g∈Gφ

In our setting, we can ignore Z, which is the normalizing constant of the MLDN. The maximum expected utility
(MEU) of model G is given by
%
&
meu[G] = argmax eu[G](vd ) , max eu[G](vd ) (6)
vd

vd

To illustrate this model, consider Figure 2 which depicts
a first-order decision problem, where a product planner
has to decide on a line of products for the enterprise
market. We seek a decision that maximizes the expect
profit, i.e., one with maximum expected utility. The
planner needs to determine each product’s set of features and market price, and does so by examining the
profile of each of the potential buyers – their yearly revenue and their demand for each of the expected products.
In our model, the problem is represented by two parfactors:
φ(f eatures(X), price(X), revenue(Y ), demand(Y, X))
and µ(price(X), demand(Y, X)). φ depicts probability
weights of various interactions between variables, and
µ depicts the utility portion (profit). The set of decision
variables is represented by atoms f eatures(X) and
price(X), and the set of random variables is represented
by revenue(Y ) and demand(Y, X).
5.2

Challenges in Lifted MEU Computation

Lifted MEU introduces several challenges which do not exist in ”normal” lifted inference. The first challenge stems
from the presence of two types of formulas, decision and
random variables, for which separate elimination procedures are defined. Notably, random variable atoms are
eliminated by summing-out their effect on the network,
whereas decision atoms are maximized-out from the network [5]. Consequently, the number comb(N ) which is
typically attributed to each histogram N , serves no part in
the elimination process of decision formulas. Additionally,
decision formulas can be eliminated only from parfactors
which contain no random variable formulas.
The second challenge arises from the two separate parts
of the MEU expression, which depict the weights of two
type of parfactors: probability and utility. The complex
structure forces the inversion procedure to be more complicated than in belief assessment, but most importantly – it
poses a significant restriction on the inversion of decision
formulas: decision formulas can be eliminated by inversion

only when contained in one type of parfactors. This restriction increases the importance of joint formula conversion,
which allows counting conversion to be applied where normally such a use would not be allowed. Joint formulas are
in no way a panacea for this inherent nature of the problem,
however, without joint formulas many MEU computation
tasks unnecessarily resort to propositionalization.
5.3

Framework

Given a model G, we begin by choosing which operator to
apply. We have three lifting operators at our disposal: inversion elimination, counting conversion and joint formula
conversion. We also have two grounding operators: propositionalization and counting expansion, which are carriedout identically to C-FOVE. After applying the operator of
choice, we are left with a transformed model, G" , whose
MEU solution entails the original model’s MEU.
We continue to apply some operator of choice, repeatedly,
until all remaining formulas are (a) decision formulas, and
(b) ground formulas. Counting formulas with no active logical variables are considered to be ground formulas as well.
Lastly, an exhaustive search is issued on the assignment
space, in-order to find the maximizing assignments of the
remaining ground formulas. A final backward phase, similar to the one used in lifted MPE [4], resolves the assignments of the eliminated decision formulas.
5.4

Inversion Elimination

Let Gα denote the set of parfactors which contain formula
α in model G. Inversion elimination [3] of formula α can
be applied to model G under three conditions: (a) Model G
is shattered w.r.t. α. (b) For each g ∈ Gα , α contains all
the logical variables of g. (c) The set of formulas in each
g ∈ Gα contains only one instance of α. Inversion eliminates α from the model and produces a residual model G" .
During the elimination procedure, product fusion and summation fusion are repeatedly used, forming a parfactor with
a single instance of α which contains all the logical variables of its container parfactor. Product fusion is defined
in [3], and summation fusion is a similar procedure, with
the distinction of summing potentials instead of applying
multiplication. We now define formally, the procedure for
eliminating random variable formulas, and the procedure
for the elimination of decision formulas.
5.4.1

Eliminating Random Variable Formulas

We assume formula α to reside in both probability and utility parfactors1 . We start by merging all probability parfac-

tors which contain α into gφ = (Lφ , Cφ , Aφ , φ), using a
product fusion. Let gµ = (Lµ , Cµ , Aµ , µ) be some utility
parfactor which contains α, and let gσ = (Lσ , Cσ , Aσ , σ)
α
be a product fusion of gφ with gµ . Let Lα
φ and Lσ denote the set of logical variables which are unique to α
in parfactors gφ and gσ , respectively. A parfactor gφ! =
(Lφ! , Cφ! , Aφ! , φ" ) is obtained by calculating
φsum (b1 , . . . , bk ) =

"

comb(a) · φ(a, b1 , . . . , bk )

(7)

a∈range(α)

Followed by
α

φ! (b1 , . . . , bk ) = φsum (b1 , . . . , bk )|Lφ :Cφ |

(8)

Where Aφ! = Aφ \ {α}, Lφ! = Lφ \ Lα
φ , and Cφ! =
↓
Cφ Lφ! . As a convention, b1 , . . . , bk depict k assignments
to all formulas in the subject parfactor, except formula α.
Next, for each of the gµ parfactors, a respective gµ! =
(Lµ! , Cµ! , Aµ! , µ" ) is obtained by calculating
σ sum (b1 , . . . , bn ) =

"

comb(a) · σ(a, b1 , . . . , bn )

(9)

a∈range(α)

Followed by
µ! (b1 , . . . , bn ) =

σ sum (b1 , . . . , bn )
· |Lα
σ : Cσ |
φsum (b1 , . . . , bk )

(10)

↓
Where Aµ! = Aµ \{α}, Lµ! = Lµ \Lα
σ , and Cµ! = Cµ Lµ! .
Note that k ≤ n, since Aφ ⊆ Aσ as a result of gσ being
a fusion of gφ with gµ . Finally, a residual model G" is
obtained by replacing gφ with gφ! , and replacing each of
the gµ parfactors with its respective gµ! .

Equations 8 and 10 instruct of exponentiation and multiplication in the combined domain sizes of the removed
logical variables. In effect, these operations express the
nature of inversion, where numerous variables are eliminated simultaneously. We demonstrate this with a two parfactor model φ(p(X), q(X, Y )) and µ(r(Y ), q(X, Y )), for
which we aim to eliminate random variable atom q(X, Y ).
The elimination of q(X, Y ) is conducted
"in several steps.
First, φsum is obtained by φsum =
q φ. Since the
elimination of q removes logical variable Y from parfac|Y |
tor φ(p(X), q(X, Y )), φ" is obtained by φ" = (φsum ) .
Next, we fuse φ(p(X), q(X, Y )) with µ(r(Y ), q(X, Y ),
sum
resulting in σ(p(X),
is then ob"r(Y ), q(X, Y )). σ
sum
tained by σ
=
φ
·
µ.
Here,
a
removal
of q from
q
σ(p(X), r(Y ), q(X, Y )) does not reduce the set of logical
sum
variables. Hence, µ" is obtained by µ" = σφsum , without
multiplication. A numerical example is given in Table 2.
5.4.2

Eliminating Decision Formulas

1

If this is not the case, a ”stub” parfactor η(α) is added to
the model, such that α will then be contained in both types of
parfactors. All table entries in a stub probability parfactor are 1,
and all table entries in a stub utility parfactor are 0.

Here, two additional precondition are required: (a) formula
α is contained exclusively in utility parfactors or probability parfactors, but not in both. (b) All formulas which share

Table 2: Eliminating rv formula q(X, Y ) by inversion
p(X)
0
0
1
1

q(X, Y )
0
1
0
1

φ
0.2
0.3
0.7
0.7

φ!
0.5|Y |
1.4|Y |

p(X)
0
1

r(Y ) q(X, Y )
0
0
0
1
1
0
1
1
p(X) r(Y )
0
0
0
1
1
0
1
1

µ
5
7
1
3
µ!
6.2
2.2
6
2

Table 3: Eliminating decision formula d(X, Y ) by inversion
e(X)
0
0
1
1

d(X, Y )
0
1
0
1

φ
0.3
0.6
0.8
0.1

e(X)
0
1

dmax (X, Y )
1
0

φ!
0.6|Y |
0.8|Y |

a parfactor with α are decision formulas. Next, all parfactors which contain α are fused into gη = (Lη , Cη , Aη , η).
gη is obtained by a product fusion if α is contained in probability parfactors, and by a summation fusion otherwise.
A parfactor gη! = (Lη! , Cη! , Aη! , η " ) is then calculated by
maximizing-out the entries of α, as follows
%
&|Lα :C|
η " = max η η
in probability parfactors (11)
α
%
&
η " = max η · |Lα
(12)
η : C| in utility parfactors
α

Lα
η depicts the set of logical variables which are unique to
α in gη , Aη! = Aη \ {α}, Lη! = Lη \ Lα
η , and Cη ! =
↓
Cη Lη! . The assignment to α which formed each entry in η "
is recorded for a backward phase. Finally, a residual model
G" is obtained by replacing gη with gη! .
Let us examine model φ(e(X), d(X, Y )), where both e and
d are decision atoms. d(X, Y ) is eliminated from the model
by calculating φ" = maxd φ|Y | , and recording the assignments to d which yield the result entries. The exponentiation in |Y | is the result of logical variable Y being removed
from the parfactor. The example is illustrated in Table 3.

6

Experimental Evaluation

We present results of three sets of experiments, all conducted on a E7400 Intel duo core machine, with 2.8GHz
CPU speed and 3Gb of RAM. The propositional variable elimination for MEU was implemented in Java, with
emphasis on performance, using a minimum deficiency
heuristics [1] for variable ordering. Our lifted inference
implementation is based on the Bayesian Logic Inference
(BLOG) Engine, as found in http://people.csail.
mit.edu/milch/blog/index.html, and was implemented in Java as well. Joint formula conversions were
injected manually, prior to running the inference task.

Figure 3 depicts the results of lifted probabilistic inference in model φ(p(X), q(X), r(Y ), s(Y )). As can
be seen, without joint formulas the model resorts to
propositional inference and the problem becomes intractable. By introducing the joint formula j(X) =
#p(X), q(X)$, the problem is quickly solved.
Figure 4 compares the results of propositional MEU
vs. lifted MEU, in model φ1 (p(Y ), q(X, Y ), d(Z)),
φ2 (e(X), r(X)), µ(e(X), q(X, Y )), where d and e are decision atoms. Here, as in other FOVE variants, computation time is polynomial in the varying sizes of the domain,
whereas computation time for the propositional algorithm
is exponential in the size of the domain.
In Figure 5, three inference methods are compared: propositional inference, lifted inference, and lifted inference with
joint formulas. Here, the propositional algorithm outperforms the lifted algorithm, but with the addition of joint formulas, the lifted algorithm outperforms the propositional
algorithm, similarly to previous figures. A closer examination reveals the reason. The input model contains parfactors φ(d(X), e(X), p(X)), µ1 (q(X, Y1 ), q(X, Y2 ), p(X))
and µ2 (e(X), r(X), f (X)), where d, e and f are decision atoms. Elimination of r(X) by inversion, followed by
the elimination of f (X) by inversion, results in parfactor
µ"2 (e(X)). Two counting conversions of q instances over
Y1 and Y2 , result in parfactor µ"1 (#Y1 [q(X, Y1 )], p(X)),
where #Y1 [q(X, Y1 )] is then eliminated by inversion to
construct parfactor µ""1 (p(X)). Since p(X) is included in
both φ and µ""1 , its elimination by inversion converts both
parfactors into φ" (d(X), e(X)), and µ"""
1 (d(X), e(X)).
At this phase, the decision atoms d(X) and e(X) cannot
be eliminated by inversion, since they both reside in probability parfactors as well as in utility parfactors. Moreover, the fact that d(X) appears with e(X) in the same
parfactor, prevents a counting conversion of both d(X) and
e(X). The lifted algorithm resolves this conflict by grounding all the instances of the decision atoms, and continuing
with a propositional model. However, the propositional algorithm was implemented much more efficiently than the
lifted algorithm, which accounts for the performance gap
between the two implementations. Once a joint formula
j(X) = #d(X), e(X)$ replaces all instances of d and e,
the X logical variable could be counted out, resulting in
instances of #X [j(X)], and in an efficient lifted inference.

7

Conclusion

We introduced a novel contribution to the field of lifted inference, a model conversion method called joint formula
conversion, and a following contribution which extends the
counting conversion procedure. We then demonstrated how
the new methods accelerates the task of lifted inference in
some models. The use of joint formulas need not be limited to exact inference. In fact, we believe that the notion

4

5000

5

4

x 10

10

lifted inference
lifted inference with joint formulas

propositional inference
lifted inference

2000

1000

milliseconds

3000

3

2

4
6
8
Domain sizes of X and Y

10

Figure 3: Inference in model
φ(p(X), q(X), r(Y ), s(Y ))

0
0

6

4

2

1

2

propositional inference
lifted inference
lifted inference with joint formulas

8

4
milliseconds

milliseconds

4000

0
0

x 10

2

4
6
8
Domain sizes of X, Y and Z

Figure 4: MEU in model
φ1 (p(Y ), q(X, Y ), d∗ (Z))
φ2 (e∗ (X), r(X))
µ(e∗ (X), q(X, Y ))
(decision atoms in asterisk)

of joint formulas is generic enough to be adopted by some
other relational models, such as relational MDP.
Our second contribution, the C-FOVE adaptation for MEU,
is the first algorithm, to the best of our knowledge, to lift
MEU computation. One interesting aspect of lifted MEU
is that it generalizes many common probabilistic inference
tasks. MPE and belief assessment, for instance, are both
private cases of MEU computation, but more importantly
– lifted MAP estimation, which has yet to be introduced,
can be defined as a private case of lifted MEU, where the
computational model contains only probability parfactors.
Acknowledgements
We thank the anonymous reviewers for their comments and
useful suggestions. The authors were partly supported by
ISF Grant 1101/07, the Paul Ivanier Center for Robotics
Research and Production Management, and the Lynn and
William Frankel Center for Computer Science.

