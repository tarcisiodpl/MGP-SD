Accelerating EM Empirical Study applications require learn parameters model data EM method learn parameters probabilistic models data variables models missing hidden instances method slow converge accelerations proposed improve method proposed acceleration methods theoretically dominant experimental comparisons lacking paper proposed accelerations try compare experimentally experiments argue acceleration EM acceleration superior depends properties Adaptive Sampling Estimation Structured Domains Sampling tool estimating complex sums integrals dimensional spaces instance sampling alternative exact methods inference belief networks Ideally sampling distribution optimal-variance estimators paper methods improve sampling distribution systematically adapting samples stochastic-gradient-descent method sequentially updating sampling distribution based direct minization variance stochastic-gradient-descent methods based minimizationof typical notions distance current sampling distribution approximations target optimal distribution finally validate compare methods empirically applying action evaluation influence diagrams Value-Directed Sampling Methods POMDPs consider approximate belief-state monitoring using particle filtering purposes implementing policy partially-observable Markov decision process POMDP particle filtering widely-used tool AI monitoring dynamical systems scant attention paid context decision Assuming existence value function derive error bounds decision quality associated filtering using sampling describe adaptive procedure dynamically determine samples required meet specific error bounds Empirical evidence offered supporting technique profitable directing sampling effort distinguish policies