Active Learning Matching Effective learning user preferences critical easing user burden various types matching Equally active query selection reduce amount preference users provide address active learning user preferences matching introducing novel method determining probabilistic matchings developing active learning strategies sensitive specific matching objective Experiments real-world data sets spanning diverse domains demonstrate matching-sensitive active learning Regret-based Reward Elicitation Markov Decision Processes specification aMarkov decision process MDP difficult Reward function specification problematic practice cognitively complex time-consuming users precisely rewards casts rewards preference elicitation aims minimize degree precision reward function allowing optimal near-optimal policies produced discuss robust policies computed MDPs partial reward using minimax regret criterion demonstrate regret reduced efficiently eliciting reward using bound queries using regret-reduction choosing suitable queries Empirical demonstrate regret-based reward elicitation offers effective produce near-optimal policies resorting precise specification entire reward function Approximate Linear Programming First-order MDPs introduce approximate solution technique first-order Markov decision processes FOMDPs Representing value function linearly w.r.t. set first-order basis functions compute suitable weights casting corresponding optimization first-order linear program off-the-shelf theorem prover LP software effectively technique allows solve FOMDPs independent specific domain instantiation allows determine bounds approximation error apply equally domain instantiations apply solution technique task elevator scheduling rich feature space multi-criteria additive reward demonstrate outperforms intuitive heuristicallyguided policies Modal Logics Qualitative Possibility Beliefs Possibilistic logic proposed numerical formalism reasoning uncertainty developing qualitative accounts possibility explanation relationship possibility modal logics modal logics represent reason qualitative statements possibility necessity modal framework identify relationships possibilistic logic beliefs conditionals natural conditional definable possibilistic default reasoning identical Pearl 's conditional e-semantics Probability Possibility Adding Uncertainty Default Rules semantics adding uncertainty conditional logics default reasoning belief revision treat conditional sentences statements conditional probability express rules revision believed believed degree p. method revision extends conditionalization allowing meaningful revision sentences probability achieved counterfactual probabilities system accounts properties qualitative methods update AGM theory revision probabilistic methods system viewed unification probability theory possibility theory highlighting orthogonality providing expressing probability possibility demonstrate connection Lewis 's method imaging Structured Arc Reversal Simulation Dynamic Probabilistic Networks algorithm arc reversal Bayesian networks tree-structured conditional probability tables consider advantages simulation dynamic probabilistic networks method allows produce CPTs nodes involved reversal exploit regularities conditional distributions argue approach alleviates overhead associated arc reversal plays role evidence integration restrict sampling variables DPNs provide algorithm detects dynamic irrelevance variables forward simulation algorithm exploits structured CPTs reversed network determine time-independent fashion conditions variable sampled Framework Optimizing Paper Matching heart scientific conferences matching submitted papers suitable reviewers Arriving assignment major challenge conference organizer paper propose framework optimize paper-to-reviewer assignments framework suitability scores measure pairwise affinity papers reviewers learning infer suitability scores set provided scores thereby reducing burden reviewers organizers frame assignment integer program propose variations paper-to-reviewer matching domain explore learning matching interact Experiments conference data sets examine performance learning methods effectiveness matching formulations Correlated Action Effects Decision Theoretic Regression decision theoretic planning adopted Markov decision processes MDPs model choice attempted solution tractable exploiting structure algorithm structured policy construction achieves decision theoretic analog goal regression using action descriptions based Bayesian networks tree-structured conditional probability tables algorithm deal actions correlated effects describe decision theoretic regression operator corrects weakness conceptually straightforward extension requires complicated technical approach Optimal Monitoring Plan Preconditions Monitoring plan preconditions allow replanning precondition fails advance plan precondition relevant monitoring costly precondition failures impact plan quality formulate model optimal precondition monitoring using partially-observable Markov decisions processes describe methods solving model efficitively single-precondition monitoring tractable multiple-precondition monitoring policies efficitively approximated using single-precondition soultions UCP-Networks Directed Graphical Representation Conditional Utilities propose directed graphical representation utility functions called UCP-networks combines aspects existing graphical models generalized additive models CP-networks network decomposes utility function additive factors directionality arcs reflecting conditional dependence preference statements underlying qualitative preference em ceteris paribus equal interpretation representation arguably natural settings strong CP-semantics ensures computation optimization dominance queries efficient demonstrate value representation decision Finally describe interactive elicitation procedure takes advantage linear nature constraints tradeoff weights imposed UCP-network procedure allows network refined regret decision minimax regret respect incompletely utility function falls threshold e.g. cost questioning Experiential Utility Elicitation Interface Customization User preferences automated assistance vary widely depending situation quality presentation help Developing effectivemodels learn individual preferences online requires domain models associate observations user behavior utility functions constructed using utility elicitation techniques elicitation methods users predicted utilities based hypothetical scenarios realistic experienced utilities true interface customization users assess novel interface designs propose experiential utility elicitation methods customization compare predictivemethods experienced utilities argued reflect true preferences behavioral decision purpose investigate accurate efficient procedures suitable software domains conventional elicitation indicate experiential approach helps people understand stochastic outcomes appreciate sequential utility intelligent assistance Integrating Planning Execution Stochastic Domains investigate planning time-critical domains represented Markov Decision Processes search based techniques powerful method finding close optimal plans reduce computational cost planning domains execute actions construct plan sacrifice optimality searching fixed depth using heuristic function estimate value paper concentrates search algorithm discuss constructing heuristic functions suitable approach interleaving search execution close optimal policies computational requirements approaches Vector-space Analysis Belief-state Approximation POMDPs propose approach value-directed belief approximation POMDPs value-directed model allows choose approximation methods belief monitoring impact decision quality Using vector space analysis devise search procedures selecting approximation scheme computational properties existing methods provide looser error bounds empirically impact decision quality practice magnitude Practical Linear Value-approximation Techniques First-order MDPs approximate linear programming ALP techniques first-order Markov Decision Processes FOMDPs represents value function linearly w.r.t. set first-order basis functions linear programming techniques determine suitable weights approach offers advantage require simplification first-order value function allows solve FOMDPs independent specific domain instantiation paper address questions enhance applicability extend first-order ALP framework approximate policy iteration address performance deficiencies previous approaches automatically generate basis functions evaluate impact value function quality decompose intractable universally quantified rewards tractable subproblems propose answers questions novel optimizations provide comparative empirical evaluation logistics ICAPS Probabilistic Planning Competition Value-Directed Sampling Methods POMDPs consider approximate belief-state monitoring using particle filtering purposes implementing policy partially-observable Markov decision process POMDP particle filtering widely-used tool AI monitoring dynamical systems scant attention paid context decision Assuming existence value function derive error bounds decision quality associated filtering using sampling describe adaptive procedure dynamically determine samples required meet specific error bounds Empirical evidence offered supporting technique profitable directing sampling effort distinguish policies Minimax regret based elicitation generalized additive utilities describe semantic foundations elicitation generalized additively independent GAI utilities using minimax regret criterion propose query types strategies purpose Computational feasibility exploiting local GAI structure model provide practical approach implementing preference-based constrained configuration optimization effective search multiattribute product databases Value-Directed Belief Approximation POMDPs consider belief-state monitoring purposes implementing policy partially-observable Markov decision process POMDP approximate belief schemes belief-state approximation e.g. based minimixing measures KL-diveregence true estimated appropriate POMDPs propose framework analyzing value-directed approximation schemes approximation quality determined expected error utility error belief propose heuristic methods finding projection schemes belief estimation exhibiting anytime characteristics POMDP value fucntion describe algorithms constructing bounds error decision quality expected utility associated acting belief approximation