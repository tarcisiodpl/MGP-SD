Accelerating EM Empirical Study applications require learn parameters model data EM method learn parameters probabilistic models data variables models missing hidden instances method slow converge accelerations proposed improve method proposed acceleration methods theoretically dominant experimental comparisons lacking paper proposed accelerations try compare experimentally experiments argue acceleration EM acceleration superior depends properties CAPIR Collaborative Action Planning Intention Recognition apply decision theoretic techniques construct non-player characters assist human player collaborative games method based solving Markov decision processes difficult game described variables scale complex games method allows decomposition game task subtasks modelled Markov decision process Intention recognition infer subtask human currently performing allowing helper assist human performing correct task Experiments method effective near-human level performance helping human collaborative game Learning Probabilistic Relational Dynamics Multiple Tasks agent 's actions affect world modeled compactly using set relational probabilistic planning rules paper addresses learning rule sets multiple tasks hierarchical Bayesian approach system learns prior distribution rule sets class prior distributions parameterized rule set prototype stochastically modified produce task-specific rule set describe coordinate ascent algorithm iteratively optimizes task-specific rule sets prior distribution Experiments using algorithm transferring tasks reduces amount training data required predict action effects blocks-world domains Adaptive Sampling Estimation Structured Domains Sampling tool estimating complex sums integrals dimensional spaces instance sampling alternative exact methods inference belief networks Ideally sampling distribution optimal-variance estimators paper methods improve sampling distribution systematically adapting samples stochastic-gradient-descent method sequentially updating sampling distribution based direct minization variance stochastic-gradient-descent methods based minimizationof typical notions distance current sampling distribution approximations target optimal distribution finally validate compare methods empirically applying action evaluation influence diagrams Deliberation Scheduling Time-Critical Sequential Decision describe method time-critical decision involving sequential tasks stochastic processes method employs iterative refinement routines solving aspects decision paper concentrates meta-level control deliberation scheduling allocating computational resources routines provide models corresponding optimization capture circumstances computational strategies decision time constraints consider precursor models decision performed prior execution recurrent models decision performed parallel execution accounting observed execution anticipating future describe algorithms precursor recurrent models provide empirical investigations