Resourceful Contextual Bandits study contextual bandits ancillary constraints resources common real-world applications choosing ads dynamic pricing items design algorithm solving handles constrained resources time improves trivial reduction non-contextual consider settings contextual bandits arbitrary policy sets e.g. Dudik al. UAI bandits resource constraints bandits knapsacks Badanidiyuru al. FOCS prove regret guarantee near-optimal statistical properties Taming Monster Fast Simple Algorithm Contextual Bandits algorithm contextual bandit learning learner repeatedly takes K$ actions response observed context observes reward chosen action method assumes access oracle solving supervised cost-sensitive classification achieves statistically optimal regret guarantee tilde sqrt KT log oracle calls rounds policies policy class compete practical contextual bandit learning algorithm approaches policy classes conduct proof-of-concept experiment demonstrates excellent computational prediction performance online variant algorithm relative baselines Logarithmic Time Online Multiclass prediction study multiclass classification extremely classes goal obtaining train test time complexity logarithmic classes develop top-down tree construction approaches constructing logarithmic depth trees theoretical front formulate objective function optimized node tree creates dynamic partitions data pure terms class labels balanced demonstrate favorable conditions construct logarithmic depth trees leaves low label entropy objective function nodes challenging optimize computationally address empirical online decision tree construction procedure Experiments demonstrate online algorithm achieves improvement test error compared common logarithmic training time approaches plausible method computationally constrained large-k applications Proceedings 29th International Conference Machine Learning ICML-12 papers appear Proceedings 29th International Conference Machine Learning ICML-12 conference held Edinburgh Scotland June 27th July Predicting Conditional Quantiles Reduction Classification reduce process predicting statistics median solving classification accompanying theoretical statement regret classifier bounds regret quantile regression quantile loss test reduction empirically existing quantile regression methods real-world datasets discover state-of-the-art performance Learning Performance Prediction Markets Kelly Bettors evaluating prediction markets crowd-prediction mechanisms investigators repeatedly observed so-called wisdom crowds roughly average participants performs average participant market price average aggregate traders beliefs offers estimate individual trader 's opinion paper stronger question market price compare trader 's belief average trader measure market 's worst-case log regret notion common machine learning theory arrive meaningful answer assume traders behave suppose trader optimizes Kelly criteria strategy provably maximizes compound growth wealth infinite sequence market interactions consequences market prediction wealth-weighted average individual participants beliefs market learns optimal rate market price reacts exactly updating Bayes Law market prediction low worst-case log regret individual participant simulate sequence markets underlying true probability exists market converges true objective frequency updating Beta distribution theory predicts agents adopt fractional Kelly criteria common practical variant agents behave full-Kelly agents beliefs weighted market 's market price converges time-discounted frequency analysis justification fractional Kelly betting strategy widely practice ad-hoc reasons Finally propose method agent learn optimal Kelly fraction Efficient programmable learning search improve learning search approaches structured prediction search space defined arbitrary imperative program reducing lines code required develop structured prediction tasks magnitude structured prediction magnitude faster various algorithmic improvements demonstrate feasibility approach structured prediction tasks variants sequence labeling entity-relation resolution accuracies alternative approaches drastically reduced execution programming time Contextual Bandit Learning Predictable Rewards Contextual bandit learning reinforcement learning learner repeatedly receives set features context takes action receives reward based action context consider realizability assumption exists function function class capable predicting expected reward action context assumption algorithm Regressor Elimination regret agnostic setting i.e. absence realizability assumption prove lower bound algorithm achieve superior performance worst realizability assumption set policies mapping contexts actions distribution rewards context algorithm constant regret previous approaches