Optimizing Memory-Bounded Controllers Decentralized POMDPs memory-bounded optimization approach solving infinite-horizon decentralized POMDPs Policies agent represented stochastic finite controllers formulate optimizing policies nonlinear program leveraging powerful existing nonlinear optimization techniques solving existing solvers guarantee locally optimal solutions formulation produces quality controllers state-of-the-art approach incorporate shared source randomness form correlation device increase solution quality limited increase space time experimental nonlinear optimization provide quality concise solutions decentralized decision uncertainty Incremental Clustering Expansion Faster Optimal Planning Dec-POMDPs article state-of-the-art optimal solution methods decentralized partially observable Markov decision processes Dec-POMDPs models collaborative multiagent planning uncertainty Building generalized multiagent GMAA algorithm reduces tree one-shot collaborative Bayesian games CBGs describe advances greatly expand range Dec-POMDPs solved optimally introduce lossless incremental clustering CBGs solved GMAA achieves exponential speedups sacrificing optimality introduce incremental expansion nodes GMAA search tree avoids expand children worst doubly exponential nodes depth beneficial clustering addition introduce hybrid heuristic representations compact thereby enable solution larger Dec-POMDPs provide theoretical guarantees suitable heuristic incremental clustering incremental expansion yield algorithms complete search equivalent Finally extensive empirical demonstrating GMAA ICE algorithm synthesizes advances optimally solve Dec-POMDPs unprecedented size Scalable Planning Learning Multiagent POMDPs Extended Version Online sample-based planning algorithms POMDPs promise scaling spaces intractable action observation spaces problematic multiagent POMDPs action observation space grows exponentially agents combat intractability propose novel scalable approach based sample-based planning factored value functions exploits structure multiagent settings approach applies planning Bayesian reinforcement learning setting Experimental provide quality solutions multiagent planning learning Policy Iteration Decentralized Control Markov Decision Processes Coordination distributed agents required arising including multi-robot systems networking e-commerce formal framework decentralized partially observable Markov decision process DEC-POMDP optimal dynamic programming algorithms single-agent version optimal algorithms multiagent elusive main contribution paper optimal policy iteration algorithm solving DEC-POMDPs algorithm stochastic finite-state controllers represent policies solution include correlation device allows agents correlate actions communicating approach alternates expanding controller performing value-preserving transformations modify controller sacrificing value efficient value-preserving transformations reduce size controller improve value keeping size fixed Empirical demonstrate usefulness value-preserving transformations increasing value keeping controller size minimum broaden applicability approach heuristic version policy iteration algorithm sacrifices convergence optimality algorithm reduces size controllers step assuming probability distributions agents actions assumption hold helps produce quality solutions test