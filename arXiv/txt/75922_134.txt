Optimizing Memory-Bounded Controllers Decentralized POMDPs memory-bounded optimization approach solving infinite-horizon decentralized POMDPs Policies agent represented stochastic finite controllers formulate optimizing policies nonlinear program leveraging powerful existing nonlinear optimization techniques solving existing solvers guarantee locally optimal solutions formulation produces quality controllers state-of-the-art approach incorporate shared source randomness form correlation device increase solution quality limited increase space time experimental nonlinear optimization provide quality concise solutions decentralized decision uncertainty Complexity Decentralized Control Markov Decision Processes Planning distributed agents partial considered decision theoretic perspective describe generalizations MDP POMDP models allow decentralized control agents finite-horizon corresponding models complete nondeterministic exponential time complexity illustrate fundamental difference centralized decentralized control Markov processes contrast MDP POMDP consider provably admit polynomial-time algorithms require doubly exponential time solve worst provided mathematical evidence corresponding intuition decentralized planning easily reduced centralized solved exactly using established techniques