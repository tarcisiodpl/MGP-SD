

Many AI synthesis problems such as planning
or scheduling may be modelized as constraint
satisfaction problems (CSP). A CSP is typically
defined as the problem of finding any consis­
tent labeling for a fixed set of variables satisfy­
ing all given constraints between these variables.
However, for many real tasks such as job-shop
scheduling, time-table scheduling, design ... , all
these constraints have not the same significance
and have not to be necessarily satisfied. A first
distinction can be made between hard constraints,
which every solution should satisfy and soft con­
straints, whose satisfaction has not to be certain.
In this paper, we formalize the notion of possi­
bilistic constraint satisfaction problems that al­
lows the modeling of uncertainly satisfied con­
straints. We use a possibility distribution over
labelings to represent respective possibilities of
each labeling. Necessity-valued constraints al­
low a simple expression of the respective cer­
tainty degrees of each constraint.
The main advantage of our approach is its integra­
tion in the CSP technical framework. Most clas­
sical techniques, such as Backtracking (BT}, arc­
consistency enforcing (AC) or Forward Checking
have been extended to handle possibilistics CSP
and are effectively implemented. The utility of
our approach is demonstrated on a simple design
problem.
1

Introduction

There are a lot of publications about constraints, and more
specifically in the CSP framework, but most of these papers
try to tackle the higly combinatorial nature (NP-Hard) of
such problems only considerin g hard constraints.
,

This paper gives a clear meaning to what could be a soft
constraint, how it may be expressed and how soft constraint
satisfaction problems may be solved. Our aim is not to
*e-mail: schiex@cert. fr

or

schiex@ir it. fr

give a "general" theoretical framework for expressing soft
constraints (such approaches may be found in [Satoh90]
using first and second order logic to express preferences or
in [Freuder89], relying on a problem space and a general
measure on this space}, but to give a specific (and hopefully
useful) meaning to such constraints leading to "efficient"
solving techniques.
Non standard logics are manyfold that allows the expression
of probabilities [Nilsson85], orpreferences [Shoham87]. In
particular, zadeh 's possibility theory [zadeh78] has already
been successfully used for modeling uncertainty and pref­
erences in the frame of propositional and first-order logic
by Dubois, Prade and Lang leading to the so-called "pos­
sibilistic logic" [Lang91b]. One of the desirable feature
of possibilistic semantics is the tolerance to "partial" con­
sistency, which allows a sort of paraconsistent reasoning.
Another interesting feature of possibilistic logic is the close
relationships between necessity measures and Gardenfors
"epistemic entrechment" relation [Gardenfors et al.88].
The main idea is to encapsulate preferences (or respective
certainty degree) among labelings in a "possibility distribu­
tion" over labelings. Such a distribution naturally induces
two (possibility and necessity) measures over constraints.
However, it is not clear how to simply express such a dis­
tribution.
A possible answer is to express bounds on necessity (or
possibility) measures of constraints, defining a set of possi­
bility distribution among labelings. One can then define a
set of "most possible" Iabelings satisfying these bounds.
The structure of the paper is as follows : the section 2.1 re­
calls how a Constraint Satisfaction Problem may be defined
and which objects are involved ; the section 2.2 presents
how a possibility distribution implicitly defines measures
on constraints ; the section 2.3 show s how bounds on ne­
cessity measures over constraints define "best" labelings.
The next section rapidly presents algorithmic issues for pos­
sibilistic CSP solving and shows how specific satisfaction
(Backtrack) and consistency enforcing (Arc-consistency
[Mackworth77]) techniques may be built, taking into ac­
count the induced possibility distribution.
In section 3, we give an example of application of possibilis-

Possibilistic Constraint Satisfaction Problems
and k1 are satisfied. k; 1\ ki is simply defined as the
set of every labeling 1 over v; U Vj such that I f= k;
and IF= k1;

tic CSP to a simple design problem. Both representation
and solving issues are addressed. Section 4 compares our
results with related works and is followed by a presentation
of further possible researchs.

2

•

Possibilistic constraint satisfaction
problems

2.1

IF kj;

An informal meaning

Let us breafty recall the definition of a classical Constraint
Satisfaction Problem as definitions may change among au­
thors.

The usual problem is then to find a labeling of the domain­
variables in V that satisfies the conjunction of every con­
straint in C. Cryptograms (such as SEND+MORE=MONEY,

LYNDON*B=JOHNSON ) , then queens problem, ...are typ­

ical instances of CSP.

A typical CSP involves a set X= {xi, ... , x.,} of n vari­
ables and a set D of n associated domains. Each variable x;
takes its value in its associated domain d;. In the following,
we shall restrict ourself to finite domains.

Domains and variables are intrinsically bound together to
form what we will call a domain-variable. The domain­
variable i is defined as a pair ( x;, d;) where x; is a variable
and d; its associated domain. We will call V the set of
domain-variables defined by X and D.
The fact that some domain-variables take some specific
values in their domains will be represented by a labeling.
A labeling lw of a set W of domain-variables is simply
defined as an application on W such that :

ViEW, lw(i) Ed;
Alternatively, a labeling lw wil l be considered as its map
(the set {( x, lw(x))/x E W}).
Further, a set of constraints C is considered. Each con­
straint k;(it,... , i.,.) on the set of domain-variables v; =
{it, ... , inJ is a set of labelings of v;.

lw of W satisfies a
lw F= k;) iff v; c W

We will say that a labeling

k;(it I .
k;(ij . .
.

1

. 1

• 1

i.,;) (noted
i.,;)fl c lw

2.2

Let

Let I\ be the set of every possible constraints on any non­
empty subset of V. The possibility distribution 11' on Lv
induces two functions on K called possibility and necessity
measures respectively noted n,. and N.. defined as follows:
: K ---. [o, 1]
Vk E K1
n,.(k) = Sup({1r(l),/ E Lv,l f= k}

n,,.

E

Let us consider lA and IB two partiallabe/­
ings (A C V, B c V). We will say that IA is more defined
than IB (noted /A � IB) iff IB C IA.
partial labeling

I

typically represents the set of every

•

For any given constraint

k;(i1, ... , in;), we will note

Lv).
•

•

1

Given two constraints

k; and k1, we will note k; 1\ kJ
Vj that is satisfied when both k;

N,.(T) is obviously equal to 1 i.e., ever satisfied constraints
are satisfied ;

N" ( .1.) = SN ( 1r) which is generally not equalto 0 l This
means that unsatisfiable constraint may be somewhat re­
quired to be satisfied. This is dependant upon the fact that
the possibility distribution 1r is not required to be nonnalized.
This choice has been made to cope with partial inconsisten­

1

the constraint on v; u

{0})

Let us denote by .1. any unsatisfi.able constraint (there is no I E
Lv /1 f= .li.e, .lis a constraint that contains no labeling) and by
T the ever satisfied constraint (i.e, the set of alllabelings on V,

-.k;( i1, ... i.,.) the constraint on V; that is unsatisfied
when k; is satisfied. -.k;( it .. . , in.) is simply the
complement of k;(i1, ... , in.) in the set Lv, of every
labelings over v; ;

•

u

N" : K---. [0, I]
Vk E K,
N"(k) = Inf({1-?r(l),/ E Lv,l f= -.k} U {l})
N"(k) = 1- n,.(-.k)

complete labeling that are more defined than/.
We finally define the following algebra over constraints :

be the finite set of all possible labeling of the

malized if and only if 3/ E Lv such that 1r(l) = I. We
define the sub-normalization degree of 1r as the quantity
SN(?r) = 1- Sup({7r(/)f/ E L}). Obviously,SN(?r) = 0
iff ?r is normalized.

•

Definition 2.1

Lv

domain-variables in V. A possibility distribution on Lv
is a function 1r from Lv to [0, 1). 1r is said to be nor­

constraint
and 3/

Modeling soft constraint with possibility and
necessity measures

In classical first order logic, soft constraint may be formal­
ized through interpretation ordering [Satoh90]. P ossibilis­
tic CSP, as indicated by their name, relies on a possibility
distribution over labelings.

We will say that a labeling is complete iff it is defined on
V, it will be partial otherwise.

A

Given two constraints k; and k1, we will note k, V ki
the constraint on V; u Vi that is satisfied when one of
k; or ki are satisfied. k, V ki is simply defined as the
set of every labeling I over V; u Vj such that I f= k; or

cies.

•

Yk1,k2 E K,
N,.(k1/\k2)= Inf({l-11'(1),1 E

Lv,l

� ktl\kz}

u

{1})

269

270

Schiex

1r (l), l E Lv,l Vo k1}
U{l- 1r(l),l E Lv,l � kz} U {1})
::= Inf({N,.(kJ), N,.(kz)}).

=

Inf ({l -

The possibility n .. ( k) represents what its name suggests
i.e., the possibility for the constraint k to be satisfied accord­
ing to the knowledge of reference. The necessity N.. (k)
tends towards 1 when the possibility that k being unsatisfied
tends toward 0, measuring to what extent the satisfaction of
k is entailed by the knowledge of reference (given by 1r).
Clearly, possibilisticCSP, as
ssibilistic logic, is not meant
to express fuzzy cons
n
as measures are attached to
precise constraints. The statement "It is 0.7 necessary that
the product be delivered before the 21th" may be translated
in possibilistic CSP to something like N.. ( D :5 21 ) = 0.7
where Dis the variable corresponding to the delivering day.
Possibilistic CSP is not intended to modelize a statement
such as 'The product should be delivered not too late after
the 2lth"2•

r,
trai ts

Because of the min and max operators, the precise values
of neces sity or possibility is not so important. The essen­
tial is the total pre order induced by them. Thus, necessity
degrees express preference degrees, N.. (k) > N.. (k') ex­
pressing that the satisfaction of k is preferred to the satisfac­
tion of k'. Therefore, possibilistic CSP are closely related
to Hierarchical CSP as described in the frame of Constraint
Logic Programming in (Boming et al.89].

The notion of "constraint satisfaction will now depend on
a possibility distribution 1r on Lv. Let us consider ( k, a) a
necessity-valued constraint.
"

We will say
(k, a) is satisfied by 1r (noted 1r F (k, a )
itT the necessity measure Nf( induced by 1r on K verifies
N.-(k) ;::: a. Considering the whole constraint set C, we
will say that the CSP ( V, C) is satisfied by a possibility
measure 1r iff the necessity measure induced by 1r verifies :

that

V'(k, a) E C, N.-(k) 2::

Possibilistic CSP : definition and semantics

•

•

where ki (it,

.

.

.

.

.

ti

-

1

.,

Vague relations seen

as

a fu:u.y set of authaurized labeling.

See [MC92,Dubois et al.89,Rosenfeld et al.76J.

2In fact, such a predicate may be decomposed in a set of

crisp predicates (a-cuts of the vague constraint). In our case,
the domains being finite, the set of a-cuts is finite and a given
fuzzy constraint may be decomposed in a finite set of possibilistic
constraints. However, this (possibly automatic) conversion may
be heavy and the result is (from an expressive view-point) quite
distant from the original knowledge.

C(V, C) = Sup*c(Sup1eLv ( 1r( l)))
Sup.-Fc(l- SN(1r))
Sup iELv(rt(l));

=
=

II(V,C)

1- C(V,C)
Inf.-�:=c(SN(7r))
= Inf .-�:= c ( N.- ( 1. ) )
= nf
I reLv(J ( l) ) ;

=

=

(0, 1].

A typical possibilistic CSP is then defined by a finite set
X of variables, a finite set D of associated finite domains
(defining a set V of domain-variables) and by a fi nite set
C of necessity valued constraints . It will be noted either
(X, D, C) or (V, C).
The necessity-valued constraint (k, a ) ex pres ses that
N.. ( k) ;::: a i e that the satisfaction of k is at least a­
necessary. The necessity-valued constraint (k, 1) expresses
that k should absolutely be satisfied, and therefore takes the
usual meaning of a constraint in classical CSP ; (k, 0 ) is
totally useless as it expresses that the necessity measure of
k should be at least 0, which is always true.
.

•

)

te

degree:

•

E

On another hand, if we consider a specific (complete)
labeling 1, its compatibility with the knowledge of
reference (noted rt( /))will be the maximum of 1r ( l) for

Thus the degree of consistency of the possibilis c CSP or
qv, C) may be defined as the maximum of 1 SN ( 1r for
every 1r which satisfies C or, equivalently, as the compat­
ibility of the most compatible labeling. Its inconsistency
degree ll(V,C) will be the complement to I of its consis ncy

, in.), a)

, in,) is a classical constraint and a

If we consider a specific distribution 1r, the most
possible labeling will have a possibility equal to
(1- SN(1r));

every 1r which satisfies C. Its incompatibility (noted
J(/)) will be its complement to I.

The only difference between a classical and a possibilistic
CSP is the introduction of necessity-valued constraint in­
stead of simple constraint. A necessity valued constraint is
a pair:

(ki(il, .

a

Thus a possibilistic CSP has not a set of consistent labeling,
but a set of possibility distributions on the set of all labelings
on V.

-

2.3

)

Thus, the inconsistency degree of a possibilistic CSP is
equal to the smallest necessity degree of the unsatisfiable
constraint l. for all possibility distribution satisfying C.

ti

The computa on of the inconsistency degree of a possi­
bilistic CSP is made easier by the fact that one can define a
maximal possibility distribution among all possibility dis­
tribution satisfying (V, C).
Theorem 2.1 Let 'P = (V, C) be a possibilistic CSP, we
define the possibility distribution 1r:p on Lv by :

V'l E

Lv,

7rp(l)

=

lnf(l,,a;)ec({( 1

-

a ;)/1 F •ki} U { 1})

Thenfor any possibility distribution 1r on Lv,
if/11" s 'll"p.
Proof:
ll'

satisfies 1'

iff 'v'( k;,ai) E C,

iff'v'(k;, a; ) E

C,

ll'

satisfies

N,.(k;);:::

( k;, a;)
a;

1r

satisfies 'P

Possibilistic Constraint Satisfaction Problems

obtained by extending the labeling lon ( 1, . .. , i) with a new
variable i + 1 and every possible label in di+l· The leafs
of the trees are complete labelings that may (or not) satisfy
every constraint. In a depth first exploration of the tree the
first labeling that satisfies every constraint is retained.

iff'v'(k;,a;) E C, Inf({1- 7r:(l)Jll= -.k;} U {1});::: a;
iff'v'(k;,a;) E C,V'll= -.k;,7r(l) $1- a;
iff'v'l E Lv, 'll'(l) $1nf(k;,<>;)€c({1- a;/ll= -.k;} U {1 })
iff'v'l E Lv,'ll'(l) $ 'll'p(l).D
Corollary 2.1

We simply conclude that :

•

It(/)

=

11"p (l) ;

•

J(l)

=

(1 - 11";,(1));

•

,

C(P)= SupiELv(1Tp(l))
= 1- SN(1ri>)
= Su plE L v ({/1!/(k;,cri)Ec({(1 - O:i)/1 F -.k t}
U{1})})

Proo f: The two first points are immediate.
According to theorem

2.1, we know that :

"11r that satisfies P, 1r $ "Kp, i.e.,
'v'1r that satisfies P, '11 E Lv, (1- 1r(l));:::
'v''ll' that satisfies P, SN(lr) ;::: SN( ll"p ).

So:

The

corresponding

result

for

the

U

degree

Test and Generate

The next step towards sophistication (and efficiency) is the
"test and generate" approach, often referred as the "Back­
track" algorithm (BT). The obvious idea is to cut each
branch that will necessarily lead to complete labelings that
do not satisfy every constraint. Each non-terminal node
corresponds to a partial labeling I. To possibly lead to a
complete labeling that satisfies every constraint, a partial
labeling should be consistent :

If a partial labeling /looses its consistency property, every
labeling I' more defined than I will also be non-consistent.
In the case of complete labeling, non-consistency is equiv­
alent with non-satisfaction.

{0})} ).

consistency

2.4.2

Definition 2.2 Given a classical CSP (V, C), a partial la­
beling lA on the set of domain-variables A C V will be
consistenti.ffVki E C such that V; C A, lA f: kj.

(1- 1rp(l))

II(P)= Inf,.l=c(SN(7r))
= SN('ll'p)
= lnf1eLv (Sup(k; ,ai)ec( {a; /I f= -.k;}

The corresponding approach in possibilistic CSP will be an
optimization problem on the same tree. For each leaf of the
tree, we may compute the value of 1Tp on the corresponding
complete labeling. In a depth first exploration of the tree,
we will retain the set of the labelings that maximize 1Tp (l).

is

immediate.O

Then, computing the inconsistency degree of a CSP means
computing the sub-nonnalization degree of the distribu­
tion 1r;,. The set of all labeling Lv being finite, we
can define the set Lv of all Jabelings of V such that
VI* E Ly,1rp(l) = 1-SN(7r;,). Thiswill be called the set
of the best labelings of 'P. Its elements are the most com­
patible labelings with the CSP 'P = (V, C) among every
labeling. The problem of finding a "best labeling" may be
reduced to find a labeling r that solve any of the following
equivalent Min-Max optimisation problems :

<l depth first tree exploration, the property
of consistency is simply checked at each node. Backtrack
occurs when it is not verified. One should note that if a
labeling I on { 1 , ... , i} is consistent, each labelings I' on
{1, . . . , i, i + 1} is consistent iff it satisfies the constraints
k1 such that V; c {1, . .. , i, i + 1} and V; rt {1, ... , i} .

In t!1e case of

In the framework of possibilistic CSP, we extend the notion
of compatibility to partial labelings.
Definition 2.3

The compatibility ofa partiallabeling l A on
A is defined as the maximum of the compatibility of every
complete labeling more defined than /A :

C(V,C) =SUPIELv(Inf(k;,a;)EC({1- o:ifl F -.ki} U {I}))
II(V,C) = InfleLv(Sup(k,.a;)EC( {ad I F -,k;} U {0}))
Such problems may be tackled through many classical tree­
search algorithms, namely Depth first Branch and Bound
(DFBB), a - {3, or SSS•...
2.4
2.4.1

Our aim will be to compute, for each node (i.e. each partial
labeling) an upper bound on the compatibility of the partial
labeling. An easily computed upper bound of this value is
given by:

Extending classical CSP algorithms
Generate and Test

The more obvious algorithm to solve classical CSP is the
"generate and test" algorithm. It traverses the domain­
variables in a predetermined order (1 , . .. , n). In the tree
explored, each node corresponds to a labeling. The root
of the tree is the empty labeling, the sons of a node l are

Infc.c .. cr ; ) e c ({ ( l - ai)/Vi

C

A, lA F ...,k,} U {1})

This bound is exact for complete labelings. Moreover,
it may be incrementally computed as the tree is traversed
downwards : if a labeling I on A has been granted an upper­
bound f3, each labeling [I on A u {( :ci , di )}, more defined
than l is granted the upper-bound {3' :

271

272

Schiex

!3'

=

lnf( {/3}

E C,
C AU {(xj,dj)},

A classical n-ary CSP is said to be arc-consistent iff for
every domain-variable j, the domain d; is not empty, and
for every label v E di, for every constraint k; such that
j E V;, there is a labeling I on V;, more defined than the
labeling {(j, v ) } , that satisfies k,.

U {(1 - a;)/ (k;, a;)
V;

V; q: A,
I' I== •k;})

For the sake of clarity, given an explicit ordering 0

=

(1, . .. , n) on the domain-variables, we will note cf+1 the
set of the necessity valued constraints (k;, a;) such that
V; c {1, . . .,j,j + 1} and V; ct. {1, ... ,j}. If we note
{3 the upper-bound previously computed on a labeling I
on { 1 , ... , j} and l' a labeling on {1 , ... , j + 1}, more
defined than I, we may compute the upper-bound !3' on the
compatibility of I' via :
{3' = Inf({iJ} U {(1-a;)/(k;,a;)

E

'+

CJ

I

,I' I== •k;})

'lllis decreasing bound is used in a DFBB algorithm to
compute one (or every) best labeling. The algorithm sim­
ply stans with the empty labeling and extends it according
to the vertical ordering 0. It maintains two parameters of
importance : the number a under which a cutoff should
take place (increased each time a complete labeling with
an augmented compatibility has been found. It should be
initially set to zero to ensure optimality, a cutoff takes place
as soon as /3 � a) and the number {3 over which no im­
provement is possible (the bound on the compatibility of
the current partial labeling. It should initially be set to 1).
These two bounds offer a great deal of flexibility :
•

•

Typically, if a labeling whose possibility is lower than
a is considered as useless, the algorithm should be
called with a set to a, allowing a more efficient pruning
of the tree;
On the opposite side, if a labeling of possibility b is
considered as enough, the algorithm should be called
with f3 set to b, allowing the algorithm to stop as soon
as a {3 consistent labeling has been found.

Naturally, in the first case we may fail to find a best labeling
if its consistency degree is lower than a ; in the second case,
we have no garantee that the best labeling has been found.
Alternatively, one may stop the algorithm execution upon
any event (time exhausted,... ) and get the best labeling
found up to the occurrence of the event (getting closer to an
"anytime algorithm" [Dean et al.88]).

The algorithm that converts a CSP in an equivalent3 arc­
consistent CSP (if it exists) is usually embodied in a single
procedure Revise, apply ing to a domain-variable j and a
constraint k; (j E V;), that suppresses every label in the
domain di that does not satisfy the previous property. This
procedure is applied repetedly on the whole CSP until sta­
bilization (ACl to AC3).
In our case, such a label may stil l be possible if the constraint
k; is not 1-necessary. In general, the knowledge we may
extract is an upper bound on the compatibility of the partial
labelings that maps a single variable to a label.
If we consider a variable

k, such that j

E

b( {(j, v)}, k;)

=

V;

and

j and a (non-unary) constraint
if we note Uv, the set of unary

constraint on any of the variables in V;, the upper bound4
on the compatibility of the partial labeling { (j, v ) }, v E d;,
taking into account k; and every unary constraint in Uv; is
equal to:
Supi'ELv, ,l't{(j,v)}

(Inf(k, ,a, }E(Vv, u{ ( l:.,ao)})

({(1- an)/f' F -,kn} U {1}))

A possibilistic CSP will be said arc-consistent if for every
domain-variable j, the domain di is not empty,and for every
label v E di, the compatibility of {(j, v ) } with respect to
the possibilistic CSP ( {j}, U{j}) is strictly positive and
equal to the minimum of the
such that j E V;.

b( { (j, v)}, k;)

for every

k;

More precisely, if we note Pi the CSP defined by
( {j}, U{j} ), a possibilistic CSP is 8-arc-consistent if it is
arc-consistent, and :

8

=

InfjEv(SupvEdj(ll'j,i( {(j, v)})) )

It may be shown that 6 is an upper-bound on the overall
consistency <C(V, C).
The main idea to convert a possibilistic CSP into an
equivalent5 arc-consistent possibilistic CSP is then to add
unary necessity-valued constraints (rather than suppressing
labels) reflecting this bound and to take these new unary
constraints in account when the process is repetedly ap­

Every usual vertical heuristic ordering (max. cardinality,
max. degree, ... ), may be applied to this tree search. An
horizontal heuristic is given by the current bounds obtained
for the various labels, but its efficiency is y et to be evalu­
ated (it is welllrnown that horizontal ordering has a strong
influence on the efficiency of Min-Max problems solving,
e.g. in Alpha-Beta algorithm applied to games [Pearl85]).

The Revise"' procedure we have defined not only filters out
necessarily inconsistent labels, but also compute for each
label v Edithe upper bound b( {(j, v ) }, k;) on the compat­
ibility of the partial labeling I that maps the variable j being

2.4.3

:J.rwo CSP 1'1 and 1'2 are equivalent if they have the same set
of solutions, i,e, VI, ll= 1'1 '¢> II= 1'z.

Consistency enforcing

A further step is to extend the various local consis­
tency notions (node, arc, path and k consistency [Mack­
worth77,Montanari?4]) and their corresponding filtering al­
gorithms[Mohr et al.86,Deville et al.91].

plied.

•rt is precisely the compatibility of the labeling { (j, v)} in the
CSP ({j} U V,, {k;} u Uv;).
5Two possibilistic CSP 1'1 and 1'2 are equivalent if they have
the same set of satisfying possibility distributions, i.e. V1r, 1r I=
p1 # 'II' 1= 1'2, or equivalently 'll'p1 = ll'p1·

Possibilistic Constraint Satisfaction Problems

filtered to this label v taking into account the constraint k,.
This bound b may be simply encoded in the CSP by adding
a simple unary constraint6 on j indicating that this label is
forbidden with a necessity 1 - b(l, ki)·

,
I
I
I
\
'

,..•o·

._

..

\
I
I
,
,

The additionnal information obtained is taken into account
in the tree search algorithm and may greatly enhance the
performances of the algorithm (tighter bounds on partial in­
consistencies are obtained earlier). The termination (which
is quite trivial) and complexity of the algorithm, the unicity
of the problem obtained are yet to be formaly determined.
Limited applications of the Reviser procedure during the
tree search exploration (so-called Forward Checking, or
Partial Look-Ahead) that are usual in CSP are immediately
usable in possibilistic CSP and have been implemented.

b

should be noted that a possibilistic CSP containing
only HARD constraints is strictly equivalent to a classi­
cal CSP and that extended algorithms (tree exploration,
arc-consistency) behave exactly as corresponding classical
CSP algorithms. Therefore "softness" costs (almost) noth­
ing when left unused. The only overhead is due to the
manipulation of the floating point numbers 1.0 and 0.0 and
the operators min/max instead of boolean true and false and
logical operators and/or.

It

3

appJe.pie
ice
fruit

Figure 1: Gastronomic CSP hypergraph

A design problem

A great restaurant want to offer to its clients a computer
aided menu designer. The system should integrate "know­
how" knowledge and customer desires to compose a "best
menu"composed of a drink (white or red wine, beer or
water), an entrance (smoked salmon, caviar, "foie gras",
oysters or nothing), a main dish (fish of the day, leg of wild
boar, sauerkraut) and a dessert (apple-pie, strawberry ice,
fruit or nothing}.

The sauerkraut should be accompanied by a beer

(a,

0.8),

white whine may be possibly considered (b, 0.3), or even
water (c, 0.2);
•

Fish may not be eaten twice in the menu (caviar and oys­

ters will be considered

as

"fishes") (d, 0.7), and should be

•

•

I would like to eat some fish (n,

1.0);

0.8);

I would like to taste the sauerkraut (o, 0.2);

ate (Cf. figure 1). The basic constraints are represented by
the continuous arcs, the client constraints are represented
by dotted arcs). The tree explored with the previously out­
lined "DFBB" algorithm using the ordering (Dish, Drink,
is given figure 2. Labels are given by
their capitals, cutoffs are indicated by thick lines. The first
"best menu" found (compatibility 0.8) is as follows:
•

main dish : Fish of the day ;

Foie gras should be accompanied by a soft white wine (h,

•

drink : White wine ;

0.9);

•

entrance : Foie gras ;

•

dessert : Apple-pie ;

Meat should (almost) certainly be eaten with a red wine (g,
0.9);

•

•

I surely do not want any oysters in my menu (m,

Entrance, Dessert)

accompanied with white wine (e, 0.9) or water (f, 0.2);
•

•

The encoding in a 4 variables possibilistic CSP is immedi­

We shall first consider the following knowledge:
•

Our client now integrate its preferences :

After the leg of wild boar, a strawbeny ice

as

very good

digestive effects (i, 0.5);
•

No entrance or no dessert is not appreciated (by the restau­
rant) (j, 0.4), having both no entrance and dessert is even

•

less appreciated

(k, 0.6);

Having water

a drink is no good (1, 0.5);

as

6

0ne may also define 1-weak arc-consistency enforcing by
limiting the Revise1r to the inference of unary constraints whose

necessity is greater or equal than "Y· 1-weak arc-consistency leads
to label suppression. 0-weak arc-consistency is possibilistic arc­

consistency.

The overall consistency degree of the CSP is therefore equal
to 0.8. As the knowledge introduced makes no difference
between a soft and a dry white wine, our customer will
either drink its "foie gras" with a dry wine or its fish with a
soft wine. Nobody is perfect ...
The size of this problem makes arc-consistency enforcing
and forward-checking useless. Nevertheless, one may note
that the problem is actually 0.8 arc-consistent. As an exam­
ple, one of the unary constraint infered by arc-consistency

273

274

Schiex

been extended to take in account fuzzy antagonist temporal
constraints.
F

�

A·
;1/� ~
I I I I I
�

aooO.l WW
RW B
�

-o.2s
�

WB

o-0.2
p.oAP

s

aoo0.8
ww
p.o.2

W

CFG

a::-�

I

a:-11

0

N

=0.3
�.2 AP

Further researchs

We are currentl y working on the conversion of the possi­
bilistic AC1 like algorithm to more sophisticated schemes
as AC4 [Mohr et al.86]. A matter of study is also the fix­
point semantics of the possibilisticarc-consistency as is has
been done for classical CSP [Gusgen et al.88].
Several extension of possibilistic CSPs may be considered :

;:l''
a::-P

5

•

a::o-P

AP

=0.8
�.J

Figure 2: DFBB search

•

•

enforcing is a constraint that forbids the label "white vine"
with a 0.2 necessity (as b( { (drink, white wine ) }, a) = 0.8).
We are currently trying to apply these techniques in the
frame of job-shop scheduling. It is clear that the particular
nature of the constraints that appears in this framework
could (and should) be taken into account in the propagation
process, as it may be done in the AC-5 [Deville et al.91]
algorithm in classical CSP.
4

Related works

The obviously related work is ..possibilistic logic"
[Lang91b] which has been a fundamental basis for pos­
sibilistic CSP definition. J. Lang [Lang91a] has applied
propositional possibilistic logic to constraint satisfaction
problems. In our opinion, our approach offers greater
expressive power (let us recall that the encoding of the
SEND+MORE=MONEY problem in propositional logic leads
to no more than 2060 clauses and 88 propositional vari­
ables) and more varied and powerful techniques (the only
resolution technique used in propositional possibilistic logic
being essentialy a "backjumping-Iike" algorithm [Oxusoff
et al.89,Gashnig79]).
Other related works include Hierarchical Constraint Logic
Programming [Boming et al.89] that allows the expression
of prioritized constraints in the body of an Hom clause.
Satoh [Satoh90] proposes a formalisation of soft constraints
based on an interpretations ordering but does not provide
any algorithmic issue.
The system GARI [Descottes et al.85] which is more ori­
ented towards production rules is very close to ours as it
compute a solution that is the best compromise under a
set of antagonist constraints. It is also close to the OPAL
scheduling system [Bel et al.89,Bel et al.88] which has

•

•

Many CSP techniques (AC-n, path or k-consistency,
backjumping, learning, tree clustering, cycle cutset)
and useful properties (Freuder theorems [Freuder82])
should be adapted or extended to possibilistic CSP ;
The integration of fuzzy constraints (defined as a fuzzy
set of authorized labelings) is almost immediate and
leads to an even greater expressive power.
As is has been shown for possibilistic logic [Dubois
et al.91b], the pre-order induced by necessity-valued
constraints is a numerical "epistemic entrenchment"
relation [Gardenfors et al.88]. The consistency degree
of a possibilistic CSP may be considered as an indica­
tor of the constraints that should be suppressed for the
"contraction" of a CSP upon revision. However, as an
anonymous referee pointed out, that means excluding
every constraint below the inconsistency degree. This
is somewhat too drastic, for some of these constraints
may be not "involved" in inconsistencies. This could
be corrected by an adequate redefinition of the label­
ing compatibility, or by complete redefinition of the
mesure used. However, algorithmic issues will have
to be reconsidered.
Possibility and necessity measures may be seen as spe­
cific decomposable measures [Dubois et a1.82]. We
think that most of this work could be easily extended
to such measures (including probabilistic measures).
Algorithmic issues will again have to be reconsidered.
Possibilistic logic programming as been experimented
in [Dubois et al.91a]. The integration of Possibilistic
logic programming and possibilistic CSP is a first step
toward Possibilistic Constraint Logic Programming.

Acknowledgements

The author wants to thank Helene Fargier, Jerome Lang
and the anonymous referees for their fruitful comments on
previous releases of this paper.
