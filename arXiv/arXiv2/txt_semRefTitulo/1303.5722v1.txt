

We discuss representing and reasoning with
knowledge about the time-dependent util­
ity of an agent's actions. Time-dependent
utility plays a crucial role in the interac­
tion between computation and action under
bounded resources. We present a semantics
for time-dependent utility and describe the
use of time-dependent information in deci­
sion contexts. We illustrate our discussion
with examples of time-pressured reasoning in
Protos, a system constructed to explore the
ideal control of inference by reasoners with
limited abilities.
1

INTRODUCTION

Decision-theoretic methods have been considered inap­
plicable for general problem solving because they re­
quire agents to possess a utility function that provides
a preference ordering over outcomes of action, and to
have access to a probability distribution over outcomes
associated with each decision (Simon et al., 1987). We
have investigated methods for maximizing utility in
reasoning systems, given limitations in computational
abilities and information. In particular, we have ex­
plored the problem of computing probability distribu­
tions under resource constraints. To a lesser extent,
we have studied the assessment and custom-tailoring
of utility models for time-dependent action.
Performing inference to determine a probability distri­
bution can delay an agent's action. Inference-related
delays can lead to losses stemming from competition
for limited resources, decay of physiological states, and
problems with coordination among independent deci­
sion makers. Endowing an agent with the ability to
trade off the accuracy or precision of an analysis for
more timely responses can increase the expected value
of that agent's behavior. Growing interest and re­
cent work by several investigators have addressed such
tradeoffs in reasoning systems (Doyle, 1988; Horvitz,

1988; Boddy and Dean, 1989; Russell and Wefald,
1989; Breese and Horvitz, 1990).
We constructed the Protos system to experiment with
the use of metareasoning procedures to control infer­
ence approximation methods (Horvitz et al., 1989a).
Protos determines the length of time it should dwell
on an inference problem before taking action in the
world. Protos iteratively computes a myopic estimate
of the expected value of computation (EVC) by bal­
ancing the cost of delay with the benefits expected
from additional refinement of the probabilities used in
a decision problem. The system makes use of informa­
tion about the convergence of approximate results to
exact answers, and about the time-dependent change
of the utility of outcomes.
We discuss several aspects of our work on the con­
sideration of time-dependent utility of outcomes. We
review background on the Protos system, describe
the semantics and assessment procedures for time­
dependent utility, and discuss the custom-tailoring of
default time-dependent utility models given observa­
tions. Finally, we describe the operation of Protos by
presenting examples of the system's behavior.
2

A LIMITED REASONER

Determining the expected value of alternate actions
under uncertainty requires the assignment of belief,
p(HJE,�), to one or more relevant hypotheses, H,
given observations, E, and background information,
�- Inference approximation algorithms produce partial
results in the form of bounds or second-order probabil­
ity distributions on relevant probabilities. Let us refer
to relevant probabilities as rj;. If we are forced to act
immediately, we should take an action D that max­
imizes our expected utility, given the mean of p(rj;),
< p(rj;) > (Howard, 1970). The utility of this action
is equal to the utility of the decision we would make
had belief in q, been a point probability at the mean
of p(rj;). That is,
arg maxu(D, p(rj;))
D

=

arg maxu(D, <p(r/;)>)
D

152

Horvitz and Rutledge

Observations

Future

Value-of·computation
metareasoner

life lottery
at timet

Pre-incident
future
life lottery

Inference base

Die

Problem-specific
decision model

Figure 1: Protos' four components include (1) a metar­
easoner that considers the benefits of continuing to
compute, (2) an inference base containing probabilistic
inference procedures, (3) belief networks representing
domain domain; and (4) a problem-specific decision
model. Inference and time-dependent utility depend
on observations.
Additional computation can tighten a second-order
distribution. However, the utility of outcomes can di­
minish with time. Thus, there is a tradeoff between
the benefits of making a decision based on a more pre­
cise result and the costs associated with delay. An
EVC analysis compares the expected utility of instan­
taneous action with the expected utility of action that
might be taken following future computation, includ­
ing the costs of that computation.
An exact EVC analysis can consume a significant por­
tion of the total computational cost of solving an in­
ference problem. Our investigation on the control
of belief-network inference has focused on the use of
tractable EVC approximations. Approximate EVC
analyses include single-step or myopic analyses. In my­
opic analyses, the EVC is computed under the assump­
tion that an agent will take an action in the world after
reasoning for a predetermined increment of time; we
undertake a myopic analysis to determine if additional
analysis is more valuable than immediate action. One
approach to computing the expected utility delaying
action is to consider the set of second-order distribu­
tions expected with additional computation. For each
feasible future distribution, we consider the value of
the best action, given that distribution, and weight
that utility by the probability of the future distribu­
tion.
Protos makes use of myopic EVC analyses. Protos
has four major components, pictured schematically in
Figure 1: (1) a metareasoner; (2) an inference base
containing inference procedures; (3) a domain-specific
knowledge base in the form of belief networks; and
(4) a problem-specific decision model. At run time,

Figure 2: Lottery for assessing time-dependent utili­
ties. We query a decision maker for the probability p
of instant, painless death that would make him indif­
ferent between his future life lottery when treated at
timet, and having a 1- p chance at continuing his life
as if the challenge facing him had not occurred.

a decision problem containing alternate actions, out­
comes, and utilities is passed to Protos. Given a de­
cision problem, Protos initiates an iterative cycle of
reasoning and metareasoning. Object-level inference
is interleaved with metareasoning about the value of
continuing to perform additional inference.
At the start of each cycle, Protos computes the EVC
associated with continuing object-level computation
for an additional increment of time. If the metarea­
soner indicates that the EVC associated with the next
increment of reasoning is zero or negative computation
ceases and the system takes an action indicated by the
mean of the second-order probability distribution. De­
pending on the computational hardware, the structure
of the time-dependent utility model, and the expected
refinement of the second-order probability distribution
by an inference algorithm, Protos may (1) take an im­
mediate reflex action, (2) dictate a best action after
some partial inference, or (3) take an action it proves
to be dominant. Decision dominance can be proved
before inference is completed with the use of a proba­
bility bounding algorithm. A decision dominates oth­
ers when a single action is indicated for the range of
probabilities in the interval bordered by an upper and
lower bound on the probability.
We have experimented with a tractable myopic ap­
proximation named EVC/BC (for EVC-bounds cate­
goricaD to control probabilistic bounding. With this
form of EVC, we compute the value of tightening
categorical upper and lower bounds on a probabil­
ity. EVC/BC hinges on interpreting upper and lower
bounds as a second-order probability distribution. The
measure is based on a least-commitment interpretation
of bounds as a uniform distribution between the upper
and lower bounds, with a mean at the midpoint of the
bounds interval. The small amount of time required
for the EVC/BC analysis is included in the EVC anal­
ysis itself. Details about the nature, limitations, and
use of EVC/BC are described in (Horvitz, 1990).

Time-Dependent Utility and Action Under Uncertainty

3

TIME-DEPENDENT UTILITY

Let us consider the use of Protos to solve time­
pressured medical problems. We have worked to repre­
sent in Protos the cost of delaying treatment as a func­
tion of the time a patient has remained in an untreated
acute pathophysiological state. Physicians delivering
emergency medical care often rely on knowledge about
the cost of delay in treating a patient.
3.1

L--- --L--�-- ---__;;:::j U(A:fll.to)
---:o
=
o

Semantics and Representation of
Time-Dependency

In answer to a query for assistance Protos propa­
gates observations about a patient's symptomatology
through a belief network. The system deliberates
about whether to make a treatment recommendation
immediately, based on a partial analysis, or to defer its
action and to continue inference, given its knowledge
about the costs of delay.
We represent time-dependent action by considering a
continuum of decisions, each defined by initiating an
action at a progressively later time, and by assessing
the change in utility of the outcome as a function of
this time. We use A ;H j, t to refer to an action, A;,
taken at time t when state Hj is true. We define t in
terms of an initial time, t0, the time a physiological
challenge begins. We define the utility of u(A; H j, t) at
different times t, with an acute-challenge lottery. To
assess the cost of delaying a treatment, we ask a deci­
sion maker to consider a time-pressured problem that
he might face in a decision context. Next, we imagine
that there is a treatment that can rid him instantly of
the acute affliction with probability 1 -p. Unfortu­
nately, with probability p, the treatment will kill him,
immediately and painlessly. We assume that, if a pa­
tient wins this lottery, he will continue his life as if
the acute incident had not occurred; that is, he faces
his preincident future life lottery. To assess the utility,
u(A ;Hj, t), at progressively later times t for action, we
ask a decision maker for the probability p of instant,
painless death that would make him in different to ac­
cepting the uncertain outcome of being treated for an
acute illness at time t or having a 1- p chance of con­
tinuing his life as if the acute incident facing him had
never occurred. We take the difference in the probabil­
ities of death for action at time t and at a later time t'
as the loss in utility. We can measure the cost of delay
in terms of micromorts. A micromort is a 10-6 chance
of immediate, painless death. Alternatively we can
assign dollar values to the risks incurred with delay.
We can use the worth-numeraire model introduced by
Howard (Howard, 1980) to convert small probabilities
of death to dollars in terms of dollars per micromort.
Beyond assessing utilities for each moment of action,
we can model the utility of action at progressively later
times with functions that encode a micromort flux for
each outcome. The micromort flux is the number of

f

p(H�Ei.�)

p*

=?

p(H�

1

Figure 3: A graphical representation of the utility of
two actions under uncertainty. The lines indicate the
utilities of action A1 and action A2 as a function of
the probability of hypothesis H1. The lines cross at a
threshold probability of hypothesis H1 called p*.
micromorts we incur with each second of delay. We
experimented with parametric utility equations and
found several to be useful for summarizing the time
dependency of alternate outcomes. Two functions we
used to model losses with time, are the linear and ex­
ponential forms,
u(A;Hj, t) = u(A;Hj,to)e-k.t
u(A;Hj, t) = u(A;Hj,to)-cbt where u(A;Hj,t) 2:0
where ka and Cb are parameter constants derived
through fitting a series of micromort assessments to a
functional form or are assessed directly. Our language
for assessing and representing mathematical models
of time-dependence allows decision makers to encode
lower bounds on utility over time, and to make state­
ments about the chaining of sequences of functional
forms.
3.2

Utility of Action in Time-Pressured
Contexts

Given time-dependent utilities, we can compute the
expected value of different actions, A;, in terms of the
likelihood of alternative outcomes, Hj. The expected
utility (eu) of taking action A; at timet is
n

eu(A;, t)

_L p(HjJE,�)u(A;Hi,t)
j=l

Consider the simple case of a binary time-dependent
decision problem. We have two states of the world
(e.g., diseases) H1 and H2 and two best actions (treat­
ments) A1 and A2 to address each state. As an exam­
ple, the states can be the presence and absence of a
disease, and the ideal actions can be treating and not
treating for the disease. Under uncertainty, we must
consider the utilities of four outcomes: u (A2H2, t),
u(A1H2,t), u(A1H1,t), and u(A2H1,t). If H1 and H2

153

154

Horvitz and Rutledge

In a time-pressured computational setting the utility
of one or more outcomes decay with delay. At the
same time, inferential processes may be underway to
refine bounds or a second-order distribution over prob­
abilities of interest. Figure 4 shows the concurrent
tightening of upper and lower bounds by a bounding
algorithm. As the utility lines pivot or sweep down
at rates dictated by the decay functions for each out­
come approximate inference continues to tighten the
bounds, yielding a time-dependent dynamics of belief
and action.
Figure 4: This graph displays how the utility of an
outcome can decay as a function of time. In this case,
the utility of taking action A1, in the context of H1,
diminishes with delay. The utility associated with im­
mediate action (broken line) and delaying action (ad­
jacent solid line) is displayed. Note that the decision
threshold, p•, is also a function of time; in this case,
p* increases as the utility of A1H1,t decreases.
are mutually exclusive states, the expected utilities of
the actions eu(A1, t) and eu(A2, t) are:
eu (A1, t)
e u(A 2, t)

p(H1jE, �) ( u(A1 H1, t)- u(A1H2, t))
+u(A1H2,t)
p(HtiE, 0 (( u(A2H1,t)- u(A2H2,t))
+u(A2H2,t)

The expected utilities of actions A1 and A2, as a func­
tion of the probability of H1, are graphed in Figure 3.
Note that the equations specify the expected utility of
two action as lines intersecting at a threshold probabil­
ity of H1, denoted p•. As we increase the probability
of p(Ht) from zero to 1, the decision with the great­
est expected utility shifts, at p•, from A1 to A2. If
we must act immediately, we take an action dictated
by the mean of the second-order distribution: We take
action At if the mean of the second-order distribution
over p(Ht iE, �) is greater than p•. Otherwise it is best
to take action A2.
A computational agent rarely is forced to act imme­
diately. An agent can pause to continue inference, or
to reflect about the costs and benefits of delaying an
action to compute a better decision. The dynamics
of reasoning about belief and action under bounded
resources is highlighted in Figure 4. The figure shows
how the utility of outcome A1 H1, t might diminish
with delay. The dashed line shows the expected utility
of taking At in the context of H1 at an initial time,
i0• The adjacent solid line indicates the diminished
expected utility of taking the action at a later time
t, given the truth of H1. Note that, as the utility of
taking action A1 falls, the decision threshold, p•, in­
creases.

3.3

Run-Time Modification of Criticality

Most of the work on Protos has relied on the use of
files of utilities assessed for prototypical situations.
The utility information is represented in tuples which
contain the utility of immediate action, and time de­
pendent decay, indexed by A;HJ pairs. However, we
also have explored the construction of models of time­
dependent utility. W ith the modeling approach, we
assess utilities that represent preferences for canoni­
cal situations and apply a mathematical model to cus­
tomize "average case" utilities and time-dependencies
to a specific decision maker and situation. To handle
time-pressured medical decisions, we elicit from an ex­
pert decision maker-in our case, an emergency-room
physician1-functions that modify the micromort flux
of relevant outcomes, in response to arguments of dis­
crete and real-valued patient vital signs. We experi­
mented with functions that provide time-dependency
parameters as a function of the patient's age, heart
rate, blood pressure, and partial pressure of oxygen in
the blood (Pa02). In practice, Protos makes use of
default time-dependent utility models if no vital signs
are observed. Given the observation of vital signs,
and the availability of information about the specific
class of decision problem, the initial utility and time­
dependence are customized.
Our work on customizing time-dependent utility
through constructing models of criticality parallels
work in the medical decision analysis community on
tools for assisting physicians to induce the utility func­
tions of patients by identifying key features of their
personalities (McNeil et a!., 1982; Jimison, 1990). Our
experimentation with deterministic functions for mod­
ifying utility models is a modest initial approach to
customizing default time-dependent models. In the
general case, modeling the utility of decision makers,
such as patients receiving time-critical therapy, is a
problem of diagnosis under uncertainty.

1

0ne of the authors

(G.R.)

emergency-medicine expertise.

has served as the source of

Time-Dependent Utility and Action Under Uncertainty

'"'" l•l"''l•rollllrlol, '

U!rlrltl '"' rlrl'" "'

1•1>'

rl I ••11< <!ron

..

••

"'

'�-;���"���--�.�.-.��� ··

(a)

Tl•(--)

(b)

Figure 5: Time-dependent inference and ideal action.
(a) Protos displays the convergence of the upper and
lower bounds (ub, lb) on a probability of interest
and the time-dependent decision threshold (p'). The
vertical line indicates the time for action. (b) The
time-dependent utilities for four possible outcomes.
4

Figure 6: Graphical analysis of action. The util­
ity (crossing solid lines) of treating for hypothesis H1
(Util(A1)) and for H2 (Util(A2)) as a function of the
probability of H1. Broken lines indicates the utilities
of acting at t0• The vertical line (p) displays the value
of the exact probability, computed after the decision
to take action A2 was made.

PROTOS IN ACTION
4.1

We now examine the behavior of Protos in solving
several simplified time-dependent decision problems in
medicine. In the examples we determine the ideal time
to perform inference with the bounded-conditioning
approximation strategy (Horvitz et a!., 1989b), given
time-dependent changes in the utility of outcomes.
Bounded conditioning is based on the method of con­
ditioning (Pearl, 1988). The method works by de­
composing a belief-network inference problem into a
set of simpler, singly connected belief-networks and
solving these subproblems in order of their contri­
bution to upper and lower bounds on a probability
of interest. The more subproblems that are solved,
the tighter the bounds. We shall examine decisions
based on inference with Dxnet and Alarm, multiply
connected belief networks that were assessed for rea­
soning about acute medical problems (Beinlich et al.,
2
1989; Rutledge et a!., 1989) We note that several
approximation algorithms and exact algorithms (such
as the clique-tree method of Lauritzen and Spiegel­
halter (Lauritzen and Spiegelhalter, 1988)) can solve
inference problems with these networks faster than
bounded conditioning can perform a complete anal­
ysis. However, the incremental and well-characterized
convergence of bounds by bounded conditioning gives
us the opportunity to explore fundamental interactions
between time-dependent belief and utility, and more
generally, to develop principles for optimizing the value
of actions taken by an agent with limited inferential
abilities. Principles of utility-directed control promise
to be most valuable for controlling probabilistic infer­
ence in larger belief networks, such as the evolving
QMR-DT network for internal medicine (Shwe et al.,
1990).
2 Alarm

is a

37

node belief network; DxNet has 81 nodes.

Case Analyses

Figure 5(a) displays the time-dependent decision
threshold, p• and the convergence of the upper and
lower bounds (ub,lb) on a probability computed by
bounded-conditioning with the Alarm network. As­
sume we are employing inference to determine the
probability of a life-threatening respiratory pathophys­
iology (H1), requiring dangerous ventilation therapy,
versus a minor acute respiratory reaction that resolves
in most cases with minor treatment. We assume that
we shall not gather additional information; we shall
base our action only on information already collected.
A vertical line through the bounds in Figure 5(a) in­
dicates Protos' decision to halt inference after 20 sec­
onds. At this time, the EVC becomes nonpositive.
Figure 5(b) displays the time-dependent utilities of
four outcomes, constructed as the product of actions
and states of the world: We treat (A!) or do not treat
(A2) the patient with an invasive treatment, and the
patient either has (H1) or does not have the severe
respiratory problem (H2). The time-dependent p' is a
function of the utilities, which were assessed from an
expert. In this case, the utility of outcome A1H1 ,t­
the utility of acting to treat the patient for the severe
respiratory problem-decays significantly with delay.
Figure 6 displays a graph of the utility of actions A1
and A2 at the time action was recommended, as a
function of the probability of H1. The broken line,
adjacent to the solid utility lines, indicates the util­
ity of A1 at to, allowing us to inspect the effect that
delay has had on the value of the time-dependent out­
come. The graph displays the upper and lower bounds
(ub, lb) at halting time, the mean value between these
bounds, and the decision threshold p' at the time Pro­
tos recommended action A2. The graph also displays
the final point probability of H1, computed after the

155

156

Horvitz and Rutledge

. ..

I�

v

·

''""

utlllt�("zH2't)

�11-/lr..tiiM.

n..,,,,,,.,llll•lllu'

..

(•)

(b)

(o)

P·::1 :111:� :• II

Figure 7: A less critical situation. (a) Here, decision
dominance is proved as the upper bound moves below
the decision threshold. (b) The time-dependent util­
ities for the four outcomes. (c) Graphical analysis of
the bounds and utility at halting time.

the entire inference problem is solved. The value of
the point probability indicates that an instantaneous
complete analysis would have recommended the same
action. This is not always the case.
To demonstrate the sensitivity of Protos' analysis to
changes in time-dependent utilities, we consider the
same decision problem with a smaller micromort flux
for the utility of outcome, A1H1,t. Figure 7(a) displays
the convergence of bounds on belief and the trajectory
of the decision threshold for the revised problem. The
reduced time-dependence of utilities of the outcome
are displayed in Figure 7(b). With the revised utility
model, which represents a less critical situation, Protos
now reasons for 40 seconds before making a recommen­
dation not to treat for H1. The EVC/BC remains pos­
itive until the upper bound passes beneath p*, proving
the dominance of A2. Figure 7(c) displays graphs of
the utilities and bounds at the time action was taken.
Let us now examine Protos' performance on a car­
diac decision problem with a focus on the use of de­
fault and customized utility models. Consider the case
where Protos is challenged with recommending action
for a patient who suddenly demonstrates extremely
low blood pressure and tachycardia (an extremely fast

heart rate). Assume the problem has been narrowed
to two mutually exclusive syndromes: congestive heart
failure (H!) and hypovolemia (H2). Hypovolemia is
a dangerous state of decreased blood volume caused,
for example, by dehydration or bleeding. Congestive
heart failure (CHF) is a serious condition in which the
pumping ability of the heart is weakened; like hypo­
volemia, it causes low blood pressure and poor oxy­
genation of tissues. Although hypovolemia and CHF
share salient symptomatology, the treatments for these
pathophysiological states conflict with each other. The
treatment for hypovolemia (A2) is to give the patient
fluids to restore them to a normal level. In contrast,
the primary treatment for CHF (AI) is to reduce the
quantity of liquids in the body with a diuretic. Er­
roneously treating a patient who has CHF with fluid­
replacement therapy, or treating a patient who has hy­
povolemia with diuretic therapy, is life-threatening.
In Protos' default time-dependent utility model for the
average case situation, the cost of delaying the treat­
ment of CHF is described by an exponential decay con­
stant that is ten times larger than the constant used
to characterize the cost of delay in treating hypov­
olemia. Protos computes the probability of CHF by
propagating observations in the Dxnet belief network.
Figure S(a) shows a trace of the update of the probabil­
ity of CHF. Here, Protos is considering a new finding
that a patient's pulmonary capillary wedge pressure is
normal. (Protos was previously informed that the pa­
tient displayed low stroke volume and had low central
venous pressure.) The vertical line indicates Protos'
decision to halt in 115 seconds. At this point, the sys­
tem recommends that the patient should be treated for
CHF. The dominance of this decision is proved when
the lower bound crosses the decision threshold p*.
For this decision problem the micromort flux assoc­
iated with delaying treatment for CIIF is represented
as a function of the patient's blood pressure. Let us
lower the blood pressure and reevaluate the case. In
response to a significant drop in blood pressure, Pro­
tos increases the exponential decay of the value for
the outcome of treating for CHF, when CHF is in­
deed present. In this case, the decay of u(A1H1t
, ) is
increased from c·0011 to e- oost Figure S(b) shows
the same probabilistic analysis with the use of the re­
vised time-dependent utility model. Protos now rec­
ommends that the patient should be treated for CHF
after only 30 seconds of computation. In the more crit­
ical case, action is indicated before a decision threshold
is reached because the EVC becomes nonpositive be­
fore a probability bound crosses the decision threshold.
4.2

Discussion

We have made several observations about Protos' be­
havior. We have found that, in many cases, a utility­
directed analysis of probabilistic inference dictates
that actions should be taken after a small fraction of

Time-Dependent Utility and Action Under Uncertainty

(•)

(b)

Figure 8: (a) Bounds convergence and decision thresh­
old for decision dilemma involving treatment for CHF
(AI) versus for hypovolemia (A2). (b) Same decision
problem with increased decay of the outcome of treat­
ing for CHF when CHF is present.
an analysis has been performed. Thus, even approxi­
mation methods with relatively slow convergence can
be more valuable than faster exact algorithms. Two
salient examples of this phenomena are displayed in
Figure 9. In such cases the ideal decision is determined
in the first few seconds of an analysis. More generally,
we have found that decisions about the ideal length of
time to deliberate and the ideal action to take are sen­
sitive to the details of the time-dependent utilities of
outcomes, the information about the convergence of an
approximation strategy, and the trajectory of partial
results generated by approximate inference.
We have observed behaviors that highlight the com­
plexity of the interplay between time-dependent utility
and time-consuming inferential processes. Some of the
behaviors are explained by the limitations associated
with the use of a myopic measure of EVC. We found
that dependencies between time-dependent utility and
inferential processes can make computation time and
recommended actions sensitive to small changes in a
time-dependent utility model. In some cases small
changes in the time-dependencies in a utility model
change the ideal recommended action a We found that
increasing the time-dependent decay of the utility of
an outcome can increase the duration of reflection. In
these cases the trajectory of converging bounds sur­
rounds and "keeps step" with an increasing or decreas­
mg p*. We observed situations where an agent apply­
ing a myopic EVC estimate may be in the unlucky
situation of continuing, for several steps, to observe
a positive EVC, yet see its expected utility continue
to diminish with delay. We identified cases where the
EVC/BC returns to a positive value after it has been
zero or negative. Such nonmonotonicity in the EVC
motivated us to implement lookahcad analyses that
3
Related problems with an optimal decision changing
.
With delay for analysis have been identified previously

m

the context of decision analysis (McNutt and Pauker,

1987).

(•)

(b)

Figure 9: (a) Bounds convergence and decision
threshold in the Alarm network for treating possible
left-ventricular failure. (b) Bounds convergence and
decision threshold in reasoning within the Dxnet be­
lief network to support a decision about treating for a
pulmonary embolism.
consider two or more future steps of computation. We
are experimenting with more advanced lookahead tech­
niques. More generally, we are pursuing the develop­
ment of methods to monitor and modify behavioral
patterns that have roots in the myopic EVC evalua­
tion, and for identifying cases where the results of an
analysis are sensitive to small fluctuations in the tra­
jectory of time-dependent utilities or probabilities.
Before concluding, we stress that we have addressed
the assignment of belief and utilities by limited agents;
we have not discussed the automated construction of
decision models. In the current version of Protos, pre­
constructed decision problems are passed to the sys­
tem, in reaction to salient observations. We foresee
that ongoing work on procedures for constructing de­
cision models (Wellman, 1988; Breese, 1990; Hecker­
man and Horvitz, 1990) will foster the development of
more comprehensive agents that can build as well as
solve decision problems under bounded resources.
5

SUMMARY

We described the assessment and use of time­
dependent utility in limited computational agents that
are charged with taking ideal action in time-critical
contexts. Analyses with Protos have demonstrated
that the duration of computational analysis and the
ideal decisions to make in the world can be sensitive
to the time-dependent utilities of relevant outcomes.
We discussed the generalization of lottery-based as­
sessment techniques to mathematical models which
represent the decay of utility of outcomes with delay.
After describing the problem of customizing the time­
dependency of default utility models in response to ob­
servations, we presented examples of Protos' behavior
on time-pressured medical decision problems. Finally,
we discussed some of Protos' behaviors and described

157

158

Horvitz and Rutledge

ongoing work on the development of nonmyopic infer­
ence monitoring and control procedures.
Acknowledgments

This work was supported by NASA under Grant NCC220-51, by the NSF under Grant IRI-8703710, and by
the Palo Alto Laboratory of the Rockwell International
Science Center.
