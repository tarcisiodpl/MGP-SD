
Tackling the problem of ordinal preference
revelation and reasoning, we propose a novel
methodology for generating an ordinal utility function from a set of qualitative preference statements. To the best of our knowledge, our proposal constitutes the first nonparametric solution for this problem that is
both efficient and semantically sound. Our
initial experiments provide strong evidence
for practical effectiveness of our approach.

1

INTRODUCTION

Human preferences are a key concept in decision theory, and as such have been studied extensively in philosophy, psychology, and economics (e.g., [10, 12, 14]).
The central goals have been to provide logical, cognitive, and mathematical models of human decision
making. More recently this research effort was joined
by AI researchers, motivated by the goal of automating
the process of decision support. To illustrate the need
for automated decision support, consider the nowadays common task of searching for some goods in a
database of an online vendor such as Amazon.com or
eBay. Such databases are too large for a user to search
exhaustively. Using the purchase of a used car as an
example, a decision support system might allow a user
to state preferences like “I like ecologically friendly
cars”, “I prefer Mercedes to Lada”, or “For a sport
car, I prefer red color to black color”. The system
should then use these preference statements to guide
the user to the relevant parts of the database.
Various logics of preference, graphical preference representation models, preference learning and reasoning
algorithms have been proposed in AI in the last three
decades [4, 8, 9]. While these works have made significant contributions, there is still a substantial gap between theory and practice of decision support. In par-

Thorsten Joachims
Computer Science Dept.
Cornell University
Ithaca, NY 14853

ticular, so far there is no single framework for revealing
user preferences and reasoning about them that is both
generically scalable and generically robust, i.e. both efficient and effective for any set of decision alternatives
and any form of preference information. It is clear
nowadays that getting closer to such a universal framework requires new insights into the problem [8, 21].
In this paper, we tackle this challenge in the scope
of revelation and reasoning about ordinal preferences
(i.e., as in the database search example above), and
develop a robust solution for this problem that is both
efficient and effective. Specifically, we propose a novel
methodology for generating an ordinal utility function from a set of qualitative preference statements.
Our proposal is based on a somewhat surprising mixture of techniques from knowledge representation and
machine learning. We show formally that it leads to
a flexible and unprecedentedly powerful tool for reasoning about ordinal preference statements. Furthermore, we present experiments that provide initial evidence for practical applicability and effectiveness of
our method, making it promising for a wide spectrum
of decision-support applications.
1.1

PROBLEM STATEMENT AND
BACKGROUND

Using the used-car database search as our running example, the content of the database constitutes the relevant subset of all possible choice alternatives Ω. The
ordinal preferences of a user who wants to buy a car
can be viewed as a (possibly weak, possibly partial)
binary preference relation P over Ω [12]. A decision
support system should allow its user to state her preferences, use these statements to approximate P , and
present the database content in a way that enables the
user to quickly home in on desirable alternatives.
The choice alternatives in such scenarios are typically described in terms of some attribution X =
{X1 , . . . , Xn } abstracting Ω to X = ×Dom(Xi ) (e.g.,
attributes of the database schema), and the user can

express her preferences in terms of X. Now, what preference information can we expect the users to provide?
As suggested in the used-car example (and supported
by multi-disciplinary literature [8, 12]), typically users
should be expected to provide only qualitative preference statements that either compare between pairs of
complete alternatives (e.g., “I prefer this alternative
to that alternative”), or generalize user’s preference
over some properties of Ω (e.g., “In a minivan, I prefer automatic transmission to manual transmission.”)
Formally, this means that the user provides us with a
qualitative preference expression

lead to restricting user expressions S to simplified languages that incorporate this prior assumption.
In
summary, computationally efficient schemes for multiattribute utility revelation proposed in economics and
AI are parametrized by the structure that user preferences induce on X, and thus are applicable only when
such structure exists and is known to the system.

S = {s1 , . . . , sm } = {hϕ1 =1 ψ1 i, · · · , hϕm =m ψm i}, (1)

Having in mind these limitations, let us return back
to the needs of decision-support application, and list
the challenges these applications pose to the research
on OUR. The vision here is threefold. First, the
user should be able to provide preference expressions
S while being as little constrained in her language
as possible. Second, the utility revelation machinery should be completely non-parametric, i.e., free of
any explicit assumptions about the structure of user
preferences. Third, both utility revelation (i.e., generating U from S) and using the revealed utility function should be computationally efficient, including the
case where user preferences pose no significant independence structure on X whatsoever.

consisting of a set of such preference statements
{s1 , . . . , sm }, where ϕi , ψi are logical formulas, =i ∈
{, , ∼}, and , , and ∼ have the standard semantics of strong preference, weak preference, and preferential equivalence, respectively. For ease of presentation, we assume attributes X are boolean1 (denoting Dom(Xi ) = {xi , xi }), and ϕi , ψi are propositional
logic formulas over X.
Given such a preference expression S, one has to interpret what information S conveys about P , decide
on a representation for this information, and decide on
the actual reasoning machinery. Several proposals for
direct logical reasoning about S have been made, yet
all these proposals are limited by (this or another) efficiency/expressiveness tradeoff. In attempt to escape
this tradeoff as much as possible, several works in AI
(e.g., see [5, 18]) proposed to compile information carried by S into an ordinal utility function
U : X 7→ R

(2)

consistent with (what we believe S tells us about) P ,
that is requiring
∀x, x0 ∈ X . U (x) ≥ U (x0 ) ⇒ P 6|= x0  x .

(3)

In what follows, we refer to the task of constructing
such a utility function U from S as ordinal utility revelation (OUR). Observe that specifying a utility function U as in (2) can be expensive due to the fact that
|X | = O(2n ). Hence, previous works on OUR searched
for special conditions under which U can be represented compactly (e.g., see [1, 3, 5, 11, 17, 18]). The
general scheme followed by these works (which we refer
to as independence-based methodology) is as follows.
First, one defines certain “independence conditions”
on X, and provides a “representation theorem” stating that under these conditions U can be compactly
specified. Second, one possibly defines some additional
conditions under which U can also be efficiently generated from S. Finally, assuming all these conditions
1

Extending our framework to arbitrary finite-domain
variables is straightforward, yet requires a more involved
notation that we decided to avoid here.

1.2

CHALLENGES AND OUR RESULTS

In this paper, we present the first approach that fulfills these goals. Combining ideas from knowledge representation, machine learning, and philosophical logic
we provide a concrete mathematical setting in which
all the above desiderata can be successfully achieved,
and formally show that this setting is appealing both
semantically and computationally. The mathematical framework we propose is based on a novel highdimensional structure for preference decomposition,
and a specific adaptation of certain standard techniques for high-dimensional continuous optimization,
frequently used in machine learning in the context of
Support Vector Machines (SVMs) [22].

2

HIGH-DIMENSIONAL
PREFERENCE
DECOMPOSITION

Considering our vision for preference revelation, one
can certainly be somewhat skeptical. Indeed, how can
OUR be efficient if the user preferences pose no significant independence structure on X, or, if they do,
the system is not provided with this independence information? The basic idea underlying our proposal is
simple: Since we are not provided with a sufficiently
useful independence information in the original space
X , maybe we should move to a different space in which
no independence information is required?
Specifically, let us schematically map the alternatives

X into a new, higher dimensional space F using
n

Φ : X 7→ F = R4 .

(4)

As one would expect, the mapping Φ is not arbitrary.
Let FS= {f1 , · · · , f4n } be the dimensions of F, and
D = Dom(Xi ) be the union of attribute domains
in X. Let val : F → 2D be a bijective mapping from
the dimensions of F onto the power set of D, uniquely
associating each dimension fi with a subset val(fi ) ⊆
{x1 , x1 , · · · , xn , xn }. In what follows, by Var(fi ) ⊆ X
we denote the subset of attributes “instantiated” by
val(fi ). Given that, for each x ∈ X and fi ∈ F, we set:
(
1, val(fi ) ⊆ x
Φ(x)[i] =
(5)
0, otherwise
From (5) it is easy to see that dimensions fi with val(fi )
containing both a literal and its negation are effectively
redundant. Indeed, later we show that we actually use
only the (3n − 1)-dimensional subspace of F, dimensions of which correspond to all the non-empty partial
assignments on X. Hence, for ease of presentation,
in what follows we discuss F as if ignoring its redundant dimensions. However, for some technical reasons
important for our computational machinery, the structure of F and Φ has to be defined as in (4)-(5).
To illustrate our mapping Φ, if X = {X1 , X2 } and
x = x1 x2 , we have Φ(x)[i] = 1 if and only if val(fi ) ∈
{x1 , x2 , x1 x2 }, that is
0 1
B 0
B 0
B
B 1
Φ(x) = B
B 0
B
B 1
@
0
0

1 val(f ) = x
1
1
C val(f2 ) = x1
C val(f3 ) = x2
C
C val(f4 ) = x2
C
C val(f5 ) = x1 x2
C
C val(f6 ) = x1 x2
A
val(f7 ) = x1 x2
val(f8 ) = x1 x2

(6)

where (6) addresses only the non-redundant dimensions of F.
Geometrically, Φ maps each n-dimensional vector x ∈
X to the 4n -dimensional vector in F that uniquely encodes the set of all projections of x onto the subspaces
of X . But is F semantically intuitive? After all, why
should we adopt this and not some another dimensional structure for Ω? To answer this question, recall
that X is just an attribution of Ω (induced by some
application-dependent considerations), and as such it
does not necessarily correspond to the criteria affecting
preference of the user over the actual physical alternatives. However, if the user provides us with some preference statements in terms of X, the implicit criteria
behind these statements obviously have some encoding in terms of X. Given that, the semantic attractiveness of F is apparent: it is not hard to see that

evaluation of any such implicit, preference-related criterion on x ∈ X necessarily corresponds to a single
dimension of F. In addition, Theorem 1 shows that
F is not only semantically intuitive, but also satisfies
our requirement of “no need for independence information”.
Theorem 1 Any preference ordering P over X is additively decomposable in F, that is, the existence of a
linear function
n

U (Φ(x)) =

4
X

wi Φ(x)[i]

(7)

i=1

satisfying (3) is guaranteed for any such P over X .
The proof of Theorem 1 is straightforward since we can
always specify weights wi associated with all complete
assignments to X such that (3) is satisfied. It is important to note, however, that this explicit “construction”
of U only serves the existential proof of Theorem 1, and
does not reflect whatsoever the machinery of our proposal.
Since, by Theorem 1, dimensions F can successfully
“linearize” any preference ordering P over X , in what
follows we can focus only on linear utility functions as
in (7). Of course, the reader may rightfully wonder
whether this linearization in a space of dimension 4n
can be of any practical use, and not just a syntactic
sugar. However, at this stage we ask the reader to
postpone the computational concerns, and focus on the
interpretation of preference expressions in the scope of
our new high dimensional space F.
There are two major categories of preference statements one would certainly like to allow in S [12],
notably dyadic (comparative) statements (indicating
a relation between two referents using the concepts
such as ‘better’, ‘worse’, and ‘equal in value to’), and
monadic (classificatory) statements (evaluating a single referent using ordinal language concepts such as
‘good’, ‘very bad’, and ‘worst’.)2 For ease of presentation, let us focus on dyadic statements for now. In
particular, consider an ”instance comparison” statement ”x is better than x0 ”, where x, x0 ∈ X . The
interpretation of this statement poses no serious difficulties because it explicitly compares between complete descriptions of two alternatives. However, this is
the exception, rather than the rule. Most of the preference statements that we use in our everyday activities
(e.g., “I prefer compact cars to SUVs”) have this or another generalizing nature. As such, these statements
2
This classification does not cover more ”higher order”
preferences, such as ”x is preferred to y more than z is
preferred to w” [19]. Although here we do not discuss such
statements, they as well can be processed in our framework.

typically mention only a subset of attributes. This
creates an ambiguity with respect to their actual referents. Several proposals on how to interpret preference
statements have been made both in philosophy and
AI, but there is no (and cannot be?) an agreed-upon
solution to this problem [12]. However, all the proposals suggest to interpret generalizing preference statements as comparing between complete descriptions X
of the alternatives, while disagreeing on what complete
descriptions are actually compared by each statement
separately, and/or by a multi-statement preference expression as a whole.
Considering interpretation of qualitative preference
expressions in F, observe that each parameter wi of U
as in (7) can be seen as capturing the marginal value
of the interaction between Var(fi ) when these take the
value val(fi ). Note that wi corresponds to this specific
interaction only; all the syntactically related interactions of subsets and supersets of val(fi ) are captured
by other parameters w, and the dimensional structure
of F allows such an independent bookkeeping of all
possible value-related criteria.
Now, consider an arbitrary dyadic statement ϕ  ψ.
Let Xϕ ⊆ X (and similarly Xψ ) be the variables involved in ϕ, and M (ϕ) ⊆ Dom(Xϕ ) be the set of ϕ’s
models. Following the most standard (if not the only)
interpretation scheme for OUR, we compile ϕ  ψ into
a set of constraints on the space of candidate utility
functions [15]. In our case, however, these constraints
are posed on the functions of form (7), which are linear, real-valued functions from the feature space F,
and not from the original attribute space X as in previous works. Specifically, we compile ϕ  ψ into a set
of |M (ϕ)| × |M (ψ)| constraints 3
∀m ∈ M (ϕ), ∀m0 ∈ M (ψ).

X

X

wi >

fi :val(fi )∈2m

wj (8)

fj :val(fj )∈2m

0

where 2m denotes the set of all value subsets of m.
For example, statement (X1 ∨ X2 )  (¬X3 ) (e.g., “It
is more important that the car is powerful or fast than
not having had an accident”) is compiled into
wx1 + wx2 + wx1 x2 > wx3
wx1 + wx2 + wx1 x2 > wx3
wx1 + wx2 + wx1 x2 > wx3

In first view, we clearly have some complexity issues
here. First, while the constraint system C is linear,
n
it is linear in the exponential space R4 . Second, the
summations in each constraint as in (8) are exponential in the arity of ϕ and ψ (i.e., in |Xϕ | and |Xψ |).
Finally, the number of constraints generated for each
preference statement can be exponential in the arity
of ϕ and ψ as well.
While exponential dimensionality of F is inherit in our
framework (and we promised to do something about
it later), the description complexity of C deserves a
closer look. First, the description size of each constraint is clearly something to worry about. For instance, each “instance comparison” between a pair of
complete alternatives in X is translated into a constraint with up to 2n+1 summation terms, and this is
a very natural form of everyday preference statements.
Fortunately, in Section 3 we efficiently overcome this
obstacle. On the other hand, the number of constraints
per preference statement seems to be less problematic
in practice, because the number of constraints equals
the number of models of ϕ and ψ, and explicit simultaneous preferential comparison between large sets of
models are rarely natural.

3

COMPUTATIONAL MACHINERY

At this point, we hope to have convinced the reader
that semantically our construction is appealing. What
still remains to be shown is that it is computationally
realistic. We begin with summarizing the complexity
issues that we have to resolve.
(a) Our target utility function U is a linear, real-valued
function from a 4n dimensional space F. Thus, not
only generating U, but even keeping and evaluating this function explicitly might be infeasible.

(9)

The constraint system C resulting from such compilation of a user expression S defines the space of solutions for our formulation of OUR. On the side of the
semantics, we argue that C corresponds to a least committing interpretation of preference statements. This
3

encodes the principle that, if there is no reason for a
bias towards certain explanations for ϕ  ψ, a most
general explanation should be preferred. In Section 3
we describe how we pick a particular assignment to wi
for a given set of constraints, and justify this choice in
Section 3.1.

The constraints for dyadic statements of the form ϕ 
ψ and ϕ ∼ ψ are similar to (8) with > being replaced by
≥ and =, respectively.

(b) The space of all suitable functions U is defined by
n
a set of linear constraints C in R4 . In addition to
the dimensionality of this satisfiability problem,
even the description of each constraint can be exponential in n = |X| for many natural preference
statements.
In the following we show that both these complexity
issues can be overcome. For ease of presentation and
without loss of generality, we introduce our machinery on preference expressions consisting only of strict

”instance comparisons” x  x0 , where x, x0 ∈ X. Our
translation of each such dyadic preference statement
x  x0 leads to a linear constraint of the form:
n

`
´
U (Φ(x)) > U Φ(x0 )

⇔

4
X

n

wi Φ(x)[i] >

i=1

⇔

4
X

wi Φ(x0 )[i]

i=1

w · Φ(x) > w · Φ(x0 )

(10)

According to this formulation, the set of utility functions consistent with a set of k such preference statements is defined by the solutions of the linear system
C:
∀1 ≤ i ≤ k. w · Φ(xi ) > w · Φ(x0i ),

(11)

4n

consisting of k constraints in R . Clearly, naive approaches to solving such systems will be computationally intractable for interesting n. In what follows, we
will exploit duality techniques from optimization theory (see [2]) and Mercer kernels (see [22]) as used in
machine learning to solve such systems in time that is
linear in n and polynomial in k.
At the first step, we reformulate our task of satisfying
C as an optimization problem. Since the solution of
(11) is typically not unique, we select a particular solution by adding an objective function and a “margin”
by which the inequality constraints should be fulfilled.
Specifically, similar to an ordinal regression SVM [13],
we search for the smallest L2 weight vector w that fulfills all constraints with margin 1. The corresponding
constrained optimization problem is:
1
Minimize (w .r .t. w) : w · w
2
subject to :
∀1 ≤ i ≤ k. w · Φ(xi ) ≥ w ·

many kinds of mappings Φ, inner products can be computed efficiently using a Mercer kernel (see [22]), even
if Φ maps into a high-dimensional (or infinite dimensional) space. Our task, thus, is to find such a kernel
for the specific mapping Φ that we use in our construction (4)-(5).
Let us define an injective representation of attribute
vectors x by projecting them to indicator vectors
~x ∈ R2n . Each attribute value is mapped onto a single
dimension. If an attribute value is present in x, the
corresponding component of ~x is 1, otherwise 0. If an
attribute is unspecified, all corresponding components
of ~x are set to 0. Using this construction, inner products for an (effectively equivalent) variant Φλ of our
mapping Φ can be computed as follows.
Theorem 2 For the mapping Φλ : X 7→ F = R4
(p
cλ (|val(fi )|),
Φλ (x)[i] =
0,

cλ (k) =

n
X

X

λl

l=k

l1 ≥ 1, ..., lk ≥ 1
l1 + ... + lk = l

l!
,
l1 !...lk !

(15)

and any x, x0 ∈ X and λ1 , ..., λn ≥ 0, the kernel
K(x, x ) =

n
X

λl (~x · ~x0 )l

(16)

l=1

(12)

computes the inner product Φλ (x) · Φλ (x0 ) = K(x, x0 ).

+1

Note that this reformulation of the problem does not
affect its satisfiability, and that the solution of (12) is
unique, since it is a strictly convex quadratic program.

Proof The following chain of equalities holds.
K(x, x0 ) =

In the second step we consider the Wolfe dual [2] of
(12):
(13)

k
X

k
k
1 XX
αi −
αi αj ((Φ(xi ) − Φ(x0i )) · (Φ(xj ) − Φ(x0j )))
2
i=1
i=1 j=1

=

n
X
l=1

=

The third and final step is based on the observation
that the dual (13) can be expressed in terms of inner
products in the high-dimensional feature space. For

n
X

λl (x · x0 )l

n
X
k=1

(xi1 x0i1 xi2 x0i2 ...xil x0il )

X

λl

l=1

subject to : α ≥ 0

This is a standard technique frequently used in the
context of SVMs [22, 13]. The Wolfe dual (13) has
the same optimum value as the primal (12). From the
parameter vector α∗ that solves the dual one can derive
P
∗
the solution w∗ of the primal as w∗ = m
i=1 αi (Φ(xi ) −
0
Φ(xi )).

n
X
l=1

=
Maximize (w .r .t. α) :

(14)

where

0

Φ(x0i )

val(fi ) ⊆ x
otherwise

n

(i1 ,...,il

)∈{1,..,2n}l

(xi1 xi2 ...xil )(x0i1 x0i2 ...x0il ))

X

λl
(i1 ,...,il

)∈{1,..,2n}l

X

cλ (k)

(xi1 xi2 ...xik )(x0i1 x0i2 ...x0ik )

{i1 ,...,ik }⊆{1,..,2n}

= Φλ (x) · Φλ (x0 )

cλ (k) is the multiplicity with which a monomial of
size k occurs. The multiplicity is influenced by two
factors. First, different orderings of the index sequence
(i1 , ..., il ) lead to the same term. This is counted by the
l!
, where l1 , ..., lk are the
multinomial coefficient l1 !...l
k!
powers of each factor. Second, all positive powers of
any xi x0i are equal. We therefore sum over all such

equivalent terms
X
l1 ≥ 1, ..., lk ≥ 1
l1 + ... + lk = l

l!
l1 !...lk !

Note that many of the monomials always evaluate to
zero under our encoding ~x of x. Specifically, monomials corresponding to expressions (xi ∧ xi ∧ · · · ) will
always be nullified. In particular, it is therefore sufficient to consider only those monomials of size less or
equal to n, since all others will always evaluate to zero.

The kernel (16), which is similar to a polynomial kernel
[22], allows us to compute inner products in the highdimensional space in linear time, and, for strictly positive λ1 , ..., λn , moving from Φ to Φλ does not change
the satisfiability of our constraint system C. To see
the latter, observe that any solution wλ of (11) for Φλ
corresponds to a solution w of (11) for Φ via
w[i]

wλ [i] = p

cλ (|val(fi )|)

.

The difference between the mappings Φλ and Φ is that
the former biases the inference’s prior towards smaller
size monomials, “preferring” more general explanations for user preference statements. On the other
hand, this bias can be controlled to a large degree via
the kernel parameters λ1 , ..., λn .
Now, using the kernel inside of the dual leads to the
following equivalent optimization problem.
Maximize (w .r .t. α) :
k
X
i=1

αi −

k
k
1 XX
αi αj (K(xi , xj ) − K(xi , x0j )−
2 i=1 j=1

(17)

K(x0i , xj ) + K(x0i , x0j ))

As a final comment on the mechanics of our inference
procedure, note that it would be unreasonable to expect that a user’s preference statements will always
be consistent. In case of inconsistent preference specification, one can use the standard soft-margin technique [7], trading-off constraint violations against margin size.
3.1

INFERENCE SEMANTICS

Since the user’s statements typically provide only partial information about her preferences, the constraint
system in (11) is underconstrained, and thus the utility revelation takes the form of inductive reasoning.
If the system has access to a prior P r(U) over utility
functions, a reasonable inductive inference procedure
would be to pick the most likely utility function U that
fulfills all constraints. In particular, for the Gaussian
2
prior P r(U) ∼ e||w|| this procedure results in finding
the weight vector with minimum L2 -norm that fulfills
the constraints. This is exactly our objective in (12).
To illustrate the behavior arising from this prior, consider the statements
s1
s2
s3

= (X1 ∨ X2 )  (¬X3 ),
= (X3 )  (X4 ),
= (X1 )  (X2 ).

For this small set of constraints, we can compute the
solution without the use of kernel and get the following
weights.
wx1 = 0.75
wx2 = −0.25 wx3 = 0.5
wx4 = −0.5
wx2 = 0
wx3 = −0.45 wx4 = 0
wx1 = 0.4
wx1 x2 = 0.05 wx1 x2 = 0.4
All other weights are set to zero. Below is an illustrative excerpt of the ordering induced by the utility
function generated in our framework:

subject to : α ≥ 0

It is known that such convex quadratic programs can
be solved in polynomial time [2]. To compute the value
of U for a given alternative x00 ∈ X , it is sufficient to
know only the dual solution and the kernel:
k
X
`
´
U Φ(x00 ) = w∗·Φλ (x00 ) =
αi (K(xi ,x00 )−K(x0i ,x00 ))
i=1

(18)

Hence, neither computing the solutions of the constraint system C, nor computing the values of U on X
n
requires any explicit computations in R4 . Through
the use of kernels, all computations can be done efficiently in the low-dimensional input space.4
4
We have extended SV M light to solve this type of
quadratic optimization problem. The implementation is
available at http://svmlight.joachims.org/. It can efficiently
handle large-scale problems with n, m ≈ 10, 000.

U (Φ(x1 x2 x3 x4 ))
U (Φ(x1 x2 x3 x4 ))
U (Φ(x1 x2 x3 x4 ))
U (Φ(x1 x2 x3 x4 ))
U (Φ(x1 x2 x3 x4 ))
U (Φ(x1 x2 x3 x4 ))
U (Φ(x1 x2 x3 x4 ))

=
=
=
=
=
=
=

1.25
1.05
0.9
0.55
0.1
−0.4
−0.55

We believe that this ordering reflects a natural interpretation of the statements. Furthermore, alternatives
for which the statements give no clear judgment receive utility values closer to zero than those for which
a statement clearly applies. In general, the Gaussian
prior appears reasonable in situations where we expect
the utility function to have a compact form (i.e. the
weights in w are small).

Now, recall that (i) each wi is devoted to capture
the marginal value of the event val(fi ), and that (ii)
we strive to a least committing interpretation of preference expressions. Observe that our inference procedure implicitly provides us with a reference point
n
0 ∈ R4 . In short, we have wi = 0 in case there
is no reason to believe the user associates some (positive/negative) value with val(fi ). Thus, consistent with
standard logics of monadic preference concepts [6],
utility U(Φ(x)) = 0 indicates that a user is either indifferent about x (i.e., has no reason to like it or dislike it), or neutral about it (user’s reasons to like x
somehow “balance” her reasons to dislike it). Moreover, this reference point provides us with an intuitive
encoding of monadic preference statements. For instance, a statement ”ϕ isP
good” is translated into a
set of |M (ϕ)| constraints fi :val(fi )∈2m wi > 0, which
can be seen as a special case of (8).

4

EVALUATION OF EMPIRICAL
EFFECTIVENESS

To demonstrate practical effectiveness of our approach,
we conducted experiments on the EachMovie dataset5 .
The dataset consists of six-point-scale movie ratings
collected from 72916 users on a corpus of 1628 movies.
Each movie is described by a set of attributes, out
of which we use the decade of the movie, whether it
is currently in the movie theaters, and a binary classification according to ten (non-disjoint) genre categories. In our experiments we generate one ordinal
utility function for each user.
The EachMovie dataset contains ratings for individual
movies, but no generalizing preference statements. To
simulate generalizing preference statements, we generated such statements using the C4.5 decision trees
learning algorithm [20] on the following binary classification problem. As training examples, we form all
pairs of movies by concatenating their attribute vectors. For each user we generate a separate training
set. If the first movie was rated higher (lower) than
the second movie, the pair is labeled positive (negative). No pair is generated if at least one of the movies
was not rated or if both movies have the same rating,
since it was unclear how to translate such cases into
training examples for the classification task. On this
data, we run the C4.5 decision tree learner6 . Using
the c45rules software included in the C4.5 package we
then convert the resulting decision tree into a set of
rules ordered by their level of confidence, and interpret each of these learned rules as a single preference
statement. For example, the highest ranked rule for
5
6

http://research.compaq.com/SRC/eachmovie/
http://www.cse.unsw.edu.au/∼quinlan/

the user that rated the largest number of movies was
the rule (a) below.

(a)

B_decade = 90s
B_Art_Foreign = 1
B_Family = 0
B_Romance = 0
-> A preferred to B

(b)

A_decade = 80s
A_Thriller = 1
B_Classic = 0
B_Horror = 1
-> A preferred to B

This rule can be interpreted as the monadic preference
statement “the user does not like foreign films from the
90s that are not Romance or Family movies”. For the
same user, the highest ranked dyadic rule is rule (b),
meaning “the user prefers thrillers from the 80s over
non-classic horror movies”.
The quality of the orderings induced by the generated
utility functions is measured in terms of ordering error, that is the fraction of times where the user rating
and the utility function disagree on the ordering of two
movies. For this error measure we consider only movie
pairs unequally rated by the user. Ties in the ordering
induced by the utility function are broken randomly.
Note that random performance according to this error
measure is a score of 0.5, and that a score of 0.0 indicates a perfect ordering. All results that follow are
averaged over the 45 users that provided the largest
number of movie ratings. To normalize for different
numbers of ratings, for each user we consider exactly
500 movie ratings randomly selected from her rating
list.
The left-hand panel of Figure 1 shows how well the
utility function orders the movies depending on the
number of preference statements used to generate this
function. In this analysis we use the top k preference
statements as returned by c45rules. Each curve in
Figure 1 gives the performance for a different choice
of kernel degree, i.e., different choice of kernel parameters λ1 , ..., λn . The “degree” d indicates that all λi
with i > d are set to zero, while all others are one.
This eliminates all monomials of size greater then d.
For small numbers of preference statements, all degrees perform roughly equivalently, but for larger sets
of preference statements, high-degree kernels substantially outperform low-degree kernels. It appears that
low-degree kernels cannot capture the dependencies in
the preference statements used in the evaluation, and
thus the ability to handle large-degree monomials (i.e.,
non-linear interactions between attributes X) is beneficial.
Since we are using a very coarse description of the
movies, the attributes do not suffice to produce a perfect ordering from a small number of preference statements. In particular, the average error rate of the complete set of C4.5 rules is 0.24. Note that this pairwise
classification performed by C4.5 is potentially easier
than the utility revelation problem, since the rules do

0.5

0.45

0.45

0.4

0.4

Error

Error

0.5

degree 1
degree 2
degree 3
degree 4
degree 5
degree 6
degree 7
degree 8
degree 9

0.35

0.3

1

2
4
8
16
32
Number of Preference Statements

degree 1
degree 2
degree 3
degree 4
degree 5
degree 6
degree 7
degree 8
degree 9

0.35

0.3

64

1

2
4
8
16
32
Number of Instance Preference Statements

64

Figure 1: Average error rate as a function of the number of statements in S, where S contains unrestricted
generalizing (left), or (right) only instance level statements.
not have to form an ordering. Comparing the C4.5
performance against the error rates of around 0.27
achieved by the ordinal utility function for the highdegree kernels, we conclude that our method performs
the translation into a consistent ordering effectively
and with good accuracy.
The right-hand panel shows an analog plot for using
only instance-level statements. Compared to the generalizing statements, the error rates here are worse,
and this indicates the beneficial expressive power of
generalizing statements. For both instance and generalizing statements we performed additional experiments using a soft-margin approach. This reduced
error rates, but gave qualitatively similar results. Regarding computational efficiency, the average CPUtime of SV M light for solving the quadratic program
for a set of 64 generalizing statements was less than
0.1 seconds.

5

RELATED WORK AND
CONCLUSIONS

We have described a novel approach to ordinal utility
revelation from a set of qualitative preference statements. To the best of our knowledge, our proposal
constitutes the first solution to this problem that can
handle heterogeneous preference statements both efficiently and effectively. The key technical contribution
is a computationally tractable, non-parametric transformation into a space where ordinal utility functions
decompose linearly and where dimensions have clear
and intuitive semantics. As such, our approach addresses a long-standing open question in the area of
preference representation, formulated by Doyle [8] as:
“Can one recast the underlying set [of attributed alternatives] in terms of a different [from the original
attribution] span of dimensions such that the utility

function becomes linear? If so, can one find new linearizing dimensions that also mean something to human interpreters?”
We have found in the literature only one work directly attempting to shed some light on this question, namely the work of Shoham on utility distributions [21]. Specifically, Shoham shows that a set of
linearizing dimensions exists for any utility function,
and that this set of dimensions may have to be exponentially larger than the original set of attributes. The
result of Shoham, however, is more foundational than
operational. First, the connection between the original attribution and the particular set of dimensions
proposed in [21] is not generally natural, and thus it
is rather unclear how to perform preference elicitation
with respect to this set of dimensions. Second, no efficient computational scheme for reasoning about this
set of dimensions has been proposed so far. Thus, we
believe that our work is the first to provide an affirmative, practically usable, answer to the question of
generic existence of an intuitive linearizing space of
dimensions.
Our ongoing and future work builds upon the foundations laid in this paper in several directions. First, we
would like to provide some informative upper bounds
on the number of preference statements that a user
will have to specify before the inferred utility function
approximates her preferences sufficiently well. Furthermore, we would like to study applicability and efficiency of standard active learning techniques to mixedinitiated preference elicitation in our framework. Finally, we would like to perform a deeper analysis of
the semantics of our inference procedure, connecting
it, for instance, with the recent axiomatic approaches
for preference revelation such as [16].

This work was funded in part under NSF CAREER
Award IIS-0237381.

[14] R. L. Keeney and H. Raiffa. Decision with Multiple Objectives. Wiley, 1976.

