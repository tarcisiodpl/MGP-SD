

We propose an integration of possibility the­
ory into non-classical logics. We obtain many
formal results that generalize the case where
possibility and necessity functions are based
on classical logic. We show how useful such
an approach is by applying it to reasoning un­
der uncertain and inconsistent information.
1

IRIT
Paul Sabatier
118 route de Narbonne
3 1062 Toulouse Cedex
France

U niversite

Now, possibility theory brings in something more that
should be fruitfully exploited as complementary to
such aspects of reasoning. Hence, we study how to
integrate possibility theory with non-classical logics.
Our work comes from the following two facts:
•

even when the involved uncertainty has a possi­
bilistic nature, "classical" possibility theory may
not be well-suited to the addressed problem, due
to shortcomings, not of possibility theory itself
but of classical logic, on which possibility theory
is defined. For example, some problems require a
formalization with a local view of inconsistency:
this is impossible with classical possibility theory
(we need a paraconsistent approach, cfSection 3).

•

on the ot.her hand, non-standard logics su ch as
intuitionistic logic, paraconsistent logics,. . . are
not expressive enough to express uncertainty in
a gradual way.

Introduction

Possibility theory has been widely used in Artificial In­
telligence to represent uncertain knowledge in a more
qualitative way than, for example, probability theory:
indeed, it is equivalent to work with "quantitative"
possibility theory (which means using possibility and
necessity measures and possibility distributions, which
map formulas or worlds to [0, 1]) or with its qualitative
counterpart (where qualitative necessity and possibil­
ity relations are preorders on the logical language and
qualitative possibility distributions are just preorders
on the set of worlds). Besides, its connection to vari­
ous qualitative formalisms in logic and Artificial Intel­
ligence has been established, notably with epistemic
entrenchment relations in [DP 9la], conditional logics
in [Bou 92] [F HL 94], System Z in [BDP 92]. The use of
possibility theory in Artificial Intelligence covers non­
monotonic reasoning [DP 91b], belief revision, incon­
sistency handling, inheritance and default rules han­
dling, temporal reasoning, constraint satisfaction, . . .
In Knowledge Representation, many non-classical log­
ics have been used (note that in this paper we consider
only non-classical logics sharing the same language as
classical logic). Each of them was intended for some
particular focus, a specific aspect of reasoning: E.g.
paraconsistent logics have been used to deal with con­
tradictory knowledge bases. Or, intuitionistic logic has
been used to take into account some subtle distinctions
between statements involving double negation for ex­
ample. Or, Kleene's 3-valued logic {and other many­
valued logics) has been used to cope with statements
for which neither truth nor falsity make sense.

These arguments show that it is generally valuable to
integrate non-classical logics with a numerical theory
of uncertainty. Now, the reason why we focus in this
paper on possibility theory rather than another theory
of uncertainty, is its qualitative nature (as it amounts
to a "numerical account" of preordering relations over
formulas or worlds), which should make it a priori sim­
pler to generalize than more quantitative approaches
such as probability theory or belief functions.
The methodology we follow in this paper consists of
going from the general case to the particular case:
•

in Section 2, we investigate whether, and under
which conditions, important properties of possi­
bility theory remain valid when generalized. We
state the results in the most general case to make
the study "reusable", though the applications de­
veloped in Section 3 focus on paraconsistency.

•

in Section 3, we take a case study, that is, we
choose a paraconsistent logic (namely Ct) and dis­
cuss more practical applications to reasoning with
uncertain and inconsistent information.

*Research supported by CNRS in proj ect "Gestion de
l'evolutif et l'incertain dans une ba.$e de connaissances".

Besnard and Lang

70

Non-classical necessity and

2

possibility functions
2.1

Necessity /possibility functions

The natural presentation of necessity and possibility
functions (see [Zad 78] for instance) shows that pos­
sibility theory consists in meta-level definitions over
classical logic, which respect completely the structure
of classical logic.
This suggests that similar functions could be defined
on other logics than classical logic; so, replacing (.C,I-)
by (.C, f---L) where L is a given non-classical logic, we can
look for a definition of possibility/necessity functions
on the logic L. We deal with classical propositional1
languages, built from a list of propositional variables
- sometimes required to be finite -, and the connec­
tives -., 1\, V, �, <-> (where 1-L 9 <--> t/; is a shorthand
for 1-L 9 -+ t/; and 1-L t/; -+ ¥') . The only vary­
ing parameter is then the consequence relation f-L.
We now give a generic definition of non-classical ne­
cessity /possibility functions, of which the usual ne­
cessity /possibility functions correspond to the special
case where L is classical logic (Section 3 deals with the
special case where L is the paraconsistent logic Cr).

Definition: let .C be a classical propositional language
and 1-L a consequence relation, L being a given (maybe
non-classical) logic. A L-necessity function is a map­
ping N from .C to [0, 1] satisfying the following axioms2
(Taut) if

f---L 9

N (9)

then

=

1

The dual functions of necessity functions are called
possibility functions. They can be defined by 3 axioms
about contradiction, equivalence and disjunction:

Definition: A L-possibility
from C to [0, 1] such that

function is a mapping II

(Contr) if 1-L •({) then II(¥=')= 0
(Eqn) if l- L 9 +-+ t/; then II(If') = II(t/;)
(Disj) II(9 V ¢) = max(II(If'), II(t/;))
Whatever the logic L, the next property entails (Eq n):
(Domn) iff-L

9--+

t/; then II('P)::; II(t/;)

Proposition 2: (Domrr) is entailed by (Eqrr) and
(Disj) on condition that f- L satisfies:
1-L

2.2

(/)-+

Some properties of non-classical
necessity /possibility functions

W hen L is classical logic, (L-)possibility functions can
be defined from (L-)necessity functions by means of
\lip E £, ll(lf') = 1- N(...,r.p) and (L-)necessity func­
tions can be defined from (L-)possibility functions by
V'(J E .C,N(¥') = 1-II(-.¥')· That is, "classical" neces­
sity and possibility functions enjoy the (double) dual­
ity property:
(Dl} II is a possibility function iff d n : £ -+ [0, 1]
defined by drr (r.p) 1 -II( -,'P) is a necessity func­
tion.
(D2) N is a necessity function iff dN : C -+ [0, 1] de­
fined by dN(9) = 1- N(-.9) is a possibility func­
tion.
=

(Eq) if 1-L 9 <--> t/; then N('P) = N(t/;)
(Conj) N(¥' 1\ t/;) = min(N(¥'), N(t/;))
When L is classical logic, we recover the classical ne­
cessity functions. Whatever the logic L is, the follow­
ing property always entails (Eq):
(Dom) if f---L 'P-+ t/; then N('P)::; N (t/;)

Some questions we may ask are: how can (D1) and
(D2) carry over to L-necessity and L-possibility func­
tions? When are (Dl) and (D2) equivalent?

Proposition 1: (Dom) is entailed by (Eq) and (Conj)

Proposition 3: if 1-L

on condition that l-L satisfies:

Proposition 4: if L satisfies

f-L\;'�1/J
Hence, for all logics

L

fulfilling the latter condition, a
as a func­
tion N: .C----> [0, 1] satisfying (Taut), (Conj), (Dom).

necessity function can then be characterized

1 For

the sake of simplicity, we

consid er

( <p)

tra axiom (Contr) if f- •<p then N
for example, in
the quantity

0 but not all:
N{) > 0, reflects
=

a degree of (partial) inconsistency.
Note that requiring
(Contr) or not -and the same for (Taut)- does not make
much difference since (Dam) ensures that contradictions
(resp. tautologies) have anyway the lowest (resp. highest)
necessity degree. Now, the reason why we require (Taut)
and not (Contr) concerns the characterization of necessity
functions in terms of possibility distributions.

-.-.r.p

<-->¥' then (D1)

{::}

(D2).

1. 1-L r.p +-+ ...,-,'(J
2. 1- L -.(91\ t/;) � ( -.9 V -.'ljJ)
3 . f-L (tp V '1/J) � (-.r.p 1\ -,.,p)
-.

and the following inference rules

1-L(/)

only the propo­

sitional level throughout the paper.
2
Many definitions of necessity functions include the ex­

[DLP 94]

'1/J

1-Llp-+tj;
'1/J

j- L

f---L({)--"1/J
1-L -.'ljJ -+ -.r.p

then (D1) and (D2) hold.
Note that among non-classical logics admitting (1)-(3)
and the above two inference rules (modus ponens and
contraposition), there are various relevant logics such
as the logic E [AB 75]. Let us now have a look on
necessary conditions for having (D1) (or (D2)).

Proposition 5: if there exists 9 such that f-L r.p and
r.p then (Dl) does not hold.
IfL
-.-.

Possibility and Necessity Functions over Non-Classical Logics

Proposition

and lfL

6: if there exists I{) such that rL
(D2) does not hold.

1p then

--,---,1{)

Next, we investigate a few issues related to the con­
dition under which a function from C to [0, 1] can be
both a necessity and a possibility function.
a truth-functional valuation is a fun c­
tion f from C to [0, 1] such that there exist two non­

Definition:

decreasing operators EB and® from (0, 1]2 to (0, 1] such
that 'V1p, t/J, f('P V t/J) = f(cp) ffi f(t/J) and /('P 1\ t/J) =
f(cp) 0 f(,P).
Definition: a logic L is said to admit trivialisation
of truth-functional valuations iff any truth-functional
valuation f satisfying (Dom), i.e. f-L 1p -+ t/J implies
f( 1p) � f( t/J) (we will also say that f is monotonic
w.r.t. 1-L) is a classical valuation, i.e. there are two
values O" and 1* such that Vip,/(IP) E {o•,l*} and
f(-.IP) f= f(IP)It is well-know n that trivialisation of truth-functional
va luations holds in the case of classical propositional
logic ([Wes 87] (DP 88] - see also [DP 94] for a discus­
sion on the implications of this result). To study the
condition under which this property also holds in the
case of non-classical logics, Je t us consider the follow­
ing assumptions:
1. 'r-Lip-+ipVt/J
2.

f-.LI{)I\1/J-1{)

3.

f-L

'P

1\

2.3

Semantics of L-necessity /possibility
functions

With the assumption that C is built from a finite
number of propositional variables, "classic al " neces­
sity /possibility functions can be semantically defined
by means of possibility distributions: a possibility dis­
tribution 7r is simply a fun cti on from the set n of all in­

terpretations for L to (0, 1]. The necessity function in­
duced by 1r is defined by N ( 'P) = inf{1-7r(w) /w f= ''P}
(with the convention inf 0 = 1 th at we take in all the
paper as well as sup 0 = 0). It can then be proved
that N is a necessity measure, and that any necessity
measure is induced by a possibility distribution.
We now turn to the general case of a logic L f or which
the class of L-m ode ls is wri tten nL .
a L-possibility distribution is a mapping
from �h to [0, 1 ] . It is said to be normalized iff
sup v E: i1L 7r(v) = 1.
Definition:
1r

In classical logic, due to the equivalence between v li: 'P
-.cp, the two following defini ti ons for inducing
a C-necessity function from a C-possibility distribution
a re e qui valent:

and v f=

N(cp)
N(cp)

V cp +->I{)

5. 'rL

'P

1\ '1j;

+-+

'1j; 1\ 'P

6. f-. L

cp V 1/J

+->

t/J V cp

II(cp)
ll(cp)

let L be a logic satisfying (1) to (8)
and f a truth-functional valuation mon otonic w .r .t.
f-L. Then we have ffi = max and ® = min.

Proposition 7:

8: let L be a logic satisfying (1) to (8)
and excluded middle, and f a truth-functional valua­
tion on L mo notonic w.r.t. f-.L· Then, Vcp,f(<p) = 1*
or f(-,cp) = 1•, where 1• = sup{ /('P) , cp E C}.
Proposition

Proposition 9: let L be a logic satisfying (1)-(8) and
non-contradiction and f a truth-functional valuation
monotonic w.r.t. 1-£. Then Vcp,/(cp) = 0* or f(-,IP) =
o• where 0* = inf{f(cp),ip E £}.
Corollary 10: any logic satisfying (1) to {8), excluded
middle and non-contradi c tion admits trivialisation of
truth-functional valuations.

=

sup{7r(v)/v � 'P}
sup{7r(v)/v f= ''P}

JI{1r), /2{1r), /a(7r), /4(1r) are the map­
pings from ,C to (0, 1] induced from 1r by:

Definition:

7. 'r-L (cpl\t/J)I\ � +-+cpi\(1/J/\0
8. 'rL('P Vt/J)Y�+-+cp V(t/JY�)
9. f-.L cp V -.cp (exc luded middle)
10. f-.L -.(cp/\-.cp) (non-contradiction)
Again, an example of a logic satisfying these properties
is the logic E [AB 75]. On the other hand, intuitionistic
logic and paraconsistent logics do not.

1- sup{1r(v)/v li: cp}
1- sup{7r(v)/v F ''P}

Analogously, for p ossibitity functions:

'P +->I{)

4. 'r-L I{)

71

ft(7r)(cp)
f2(7r)(cp)
/a(7r)('P)
/4(7r)(cp)

=

1- sup{7r(v)/v
1- sup{7r(v)lv
sup{1r(v)/v FL
::: sup { 1r( v ) I v � L

�L cp}
FL •'P}
cp}
-.cp}

It is straightforward from these definitions that the
following duality properties hold:
•
•

/4 ( 7r)('P) = 1- ft(7r)(-,cp)
f2(7r) {'P) = 1- fa(7r)(•cp)

Proposition 11: if L is such that v !i=L cp =? v FL
-.cp (or equivalent1y, v �L ''P =? v f= L 'P )3 then
/2(1r)(cp) � fl(7r)(cp), and /4(1r)(cp) � /3(1r)(cp).
Proposition 12: ft is a L-necessity function, pro­
vided that the following conditions hold:
•

if

•

V

•

V

then v FL cp for all v (Soundness)
FL 'P +-+ t/J iff ( V F L 'P) {::> ( V F tj;)
F L 'P 1\ 1/J iff V FL I{) and V F L 1/J
f-L cp

3Either (v �L cp =? v I=L -.cp) or (v �L •cp =? v FL cp)
basically amounts to the validity of cp V •cp in the logic L.

72

Besnard and Lang

Proposition 13: h is a 1-necessity function, pro­
vided that the following conditions hold:

rp then v �L -.rp for all v
v FL rp <c-t 1/; iff (v FL -.rp) <:? (v FL -.'lj;)
• v FL -.( rp 1\ '1/J) i ff v FL -.rp or v FL -.tf
Proposition 14: h is a 1-possibility function,
•

if I-L

•

pro­

vided that the following conditions hold:
•
•
•

v �L -.rp for all v
v FL rp <c-t 1/; iff (v FL 'P) <:? (v FL '1/J)
v F=L rp V '1/J iff v F= L cp or v F= L tP
if I- L cp then

Proposition 15: J4 is a 1-possibility function, pro­
vided that the following conditions hold:
•
•
•

f= L 'P for all v (Soundness)
v FL 'P <c-t 1/; iff (v FL -.'P) <:? (v FL -,'lj;)
v FL --.(cp V tf) iff v FL ''P and v FL •1/;
if I-L

2.4

rp

then

v

L-necessity orderings

It has been shown [Dub 86] that necessity and possi­
bility functions can be equivalently expressed in purely
qualitative terms, with preordering relations.
We
briefly give a generalization of this result, for the case
of necessities (the case for possibilities is similar).
Definition: A 1-necessity ordering is a relation on .C
satisfying the following properties:

rp 2:: 1/;

1/; 2:: � then rp 2:: � (transitivity)
1/; 2:: rp (dominance)
or rp 1\ tjJ � '1/J (conjunctiveness)

•

if

•

if I- L 'P -+ '1/J then

and

•

rp 1\ tP

� rp

[Dub 86]: a relation 2:: on C is said to
agree strictly with a mapping f from C to [0, 1] iff
Vrp, 1/; E .C, we have 'P 2:: tP <:? !(rp) 2:: f('1/J ).
Definition

Proposition 16 (correspondence between 1-necessity
functions and 1-necessity orderings): the only map­
pings from .C to [0, 1] agreeing strictly with 1-necessity
orderings and also satisfying (Taut) are 1-necessity
functions.

3

Application to reasoning with
uncertain and inconsistent
information

3.1

Motivations

Possibility theory, as well as its qualitative counter­
parts such as epistemic entrenchment relations [GM
88], ranked knowledge bases [Pea 90] or rational clo­
sure [1eh 89] provide a relativized treatment of incon­
sistency, since the latter becomes a gradual notion.
I.e., a possibilistic knowledge base [D1P 94] consists
of a set of constraints KB = {(cp; ai),i = l..n}, where
(cp; a;) is a syntactic notation for the semantical con­
straint N(rp;) 2:: a;.

A possibilistic knowledge base is partially inconsis­
tent if it leads to enforce N(.l) > 0; stated oth­
erwise, the inconsistency degree of K B is defined
by Incons(KB) = maxs£;KB,S�l_ min(<p;a,)es a; =
min{N(.l), N satisfies KB}. Any formula below this
level, i.e. any rp; where a;:::; Incons(KB), is then in­
hibited (it is "drown" by the inconsistency [BCD1P
93]). This shows that the notion of inconsistency
in possibilistic logic and its qualitative counterpart is
gradual but global. The inconsistency level measures
to what extent the knowledge base is inconsistent, but
do not locate the inconsistency. The aforementioned
"drowning effect" is a consequence of this global treat­
ment of inconsistency. One way to cope with it is
to consider the knowledge base syntactically [Bre 89]
[Neb 91] [BCD1P 93], by selecting among maximal
sub-bases of KB using a criterion involving the a;'s.
However, these syntactical approaches do not have
(yet) any semantics in terms of uncertainty measures.
Now, using paraconsistent logics for handling incon­
sistent knowledge bases enables a local treatment of
inconsistency, by locating the inconsistency on some
formulas. Yet, these paraconsistent approaches do not
allow for any graduality in the inconsistency, which im­
plies some loss of information if the initial knowledge
was pertained with uncertainty.
While possibilistic logic allows for a gradual but global
treatment of inconsistency, where conflicts are solved
only by comparing the uncertainty level of the pieces of
information with the inconsistency level of the knowl­
edge base, the pure paraconsistent approach localizes
inconsistency, but conflicts cannot be ranked accord­
ing to uncertainty, importance, priority, normality as
done in rank-based systems. Thus paraconsistency is
not able to "solve" the conflicts. What we propose
here is to apply the results of Section 2 to a given
paraconsistent logic, namely C1 [daC 74], to handle
both uncertain and inconsistent knowledge, and with
a local treatment of inconsistency. We now give two
motivating examples, one about fusion of uncertain
information (multi-source reasoning) and one about
reasoning with default rules.
Example 1 (multi�source reasoning)
This example is borrowed from [Cho 94].
Two witnesses report their observations about a mur­
derer. Witness 1 (noted W1) is certain that the mur­
derer was a woman with blond hair, and believes (with
some uncertainty) that she was wearing a Chanel suit,
glasses, and was driving a BMW. Witness 2 (noted
W2) is certain that the murderer was a woman with
brown hair and that she was not wearing glasses, and
believes (with some uncertainty) that she was driving
a Fiat.

W1 female (sure), blond-hair (sure), drives-BMW
(unsure), wear-glasses (unsure), wear-Chanel­
sui t (unsure)
W2 female (sure), brown-hair (sure), drives-Fiat
(unsure), •wear-glasses (sure)

Possibility and Necessity Functions over Non-Classical Logics

What would we like to conclude about the following
statements?
•

Both witnesses agree that the murderer was fe­
male and are completely sure; so we want to con­
clude the murderer was female.

•

No contradiction either about wear-Chanel-suit
since witness 2 does not know anything.

•

Strong contradiction about the colour of the mur­
derer's hair; we wish to conclude neither blond
nor brown but we want to keep in mind that
these literals are "strongly subject to inconsis­
tency" (knowing the constraint •(blond-hair 1\
brown-hair)).

•

•

Contradiction about wear-glasses: the contradic­
tion is weaker than the one above since witness 1
is unsure; moreover, since witness 2's information
is prioritary to witness 1 's we would like to solve
the conflict (by concluding •wear-glasses).
Weak contradiction again, about the car; however,
since both witnesses are equally certain, we do not
want to conclude anything.

Example 2

(drowning effect)
Here, applying Pearl's ranking procedure of default
rules to
.6.

=

{penguin ......,. bird, penguin
bird fly, b ird ___. wings}

---->

•fly,

___.

3.2

A case study: C1-necessity functions

3.2.1

The paraconsistent logic C1

C1 [daC 7 4] is a paraconsistent logic, that is, a logic
in which a contradiction <p 1\ -,IP fails to entail other
arbitrary contradictions 1/J 1\ -,'ljJ cl retains all infer­
ence patterns of classical logic that are not based on
negation. For instance,
,

IP

1/J

<pi\¢
is valid in C1. By contrast, some inference patterns
of classical logic that do appeal to negation are not
preserved. For instance,
•1/J
'IP
-.(<p V 'I/J)
is not valid in C1. The idea is that positive informa­
tion is fundamental: positive formulas and inferences
contribute to state what the facts are whereas negative
formulas and inferences are merely constraints (in the
sense of integrity constraints for databases). Accord­
ingly, cl allows us to elicit all and only the formulas
responsible for a given contradiction ([CL 92] (BL 941).
A valuation-based semantics for C1 (Alv 84] is given
in Section 3.2.3 as we now reproduce the original ax­
iomatic presentation of C1 that consists of the next
ten axioms
1. <p---+(1/J----><p)
2. (<p----> 1/J)----> [(10---+ (1/J--->

g1ves
.6. 1

=

.6.0

=

{penguin ......,. bird, penguin ---> •fly} ;
{bird ---. fly, bird ---+ wings}.

Adding the fact penguin to .6. enables us to infer •fly
but wings is not deduced (it is "drown" by the incon­
sistency appearing at rank 1). This particular case of
the drowning effect is known as the property of "in­
heritance blocking".
Considering .6. as a set of formulas for the logic C1, we
obtain
AU

{penguin} f-c, {fly, •fly, wings}.

Thus, we avoid the drowning effect but we do not take
into account priorities (induced by specificity) such as
penguin ......,. •fly over bird ......,. fly and we conclude
that fly is not well-behaved.
What we would like is to take advantage of the lo­
calisation of inconsistency, as done by paraconsistent
entailment, and the priority between formulas, which
would lead us to infer {fly, wings} but not •fly.
Note that prioritized syntax-based approaches based
on the selection of maximal consistent subsets of the
knowledge base guided by the priorities solve the
drowning effect but do not tell anything about where
the contradictions are localized; so, for instance, the
conclusion •wear-glasses is not relativised by the
fact that it is (weakly) subject to inconsistency.

73

u

))

---->

(10---+ u)]

3.
4.

\0

5.

<p-->(1/J----><p/\tf;)
<p ---> <p V 7./J
<p---->1/JV<p
(IP----> CT)--> [(1/J----> 0')......,. (<p V tf;---+ 0')]

6.

7.

8.

1\ 1/J ......,.

\0 1\

'P

1/J -1/J

9. 'P v --,'P
10. --,--,1{)-+<p

together with the single inference rule

'f r..!f

C1 has the following basic features.

First, the con­
nectives are not interdefinable. For instance, <p V 7./J
cannot be defined as • ( •<p 1\ •7./J). Second, the re­
placement of equivalent formulas does not hold. For
instance, (<p v 7./J) +--+ [(<p ---+ 1jJ) ......,. 7./J] is valid in C1 but
•(<p V 1/J) ......, -.[('P--> 1/J) ---+ 1/J] is not. Third , neither
modus tollens
•<p
nor disjunctive syllogism
\0

are valid in C1.

--,\0

v 1/J
1/J

Regarding notation, we use <p0 as an abbreviation for
--, (<p 1\ •<p) . In the next two sections, we also use # to
denote any of 1\, V, ---+.

74

Besnard and Lang

3.2.2

C1 Mnecessity functions: definition and

basic properties
Definition: like for L-necessity functions, replacing
1--L by 1--c,.
Some properties enjoyed by C1-necessity functions are:
Dam: If

1--c, t.p -+

(P1) N(t.p)

=

.,P then N(t.p) � N(.,P)

N(•t.p0) or N(•t.p)

=

3.3

N(• t.p0 )

(P2) N(.,P);::: min(N(t.p), N(t.p-+ .,P))

3.3.1

::::} N(1/J) ;::: min;=l..n N('Pi)
(P4) N(-.t.p);::: min(N(t.p0), N(t.p--+ '1/J), N(t.p- + •if))
(P5) N(t.p v '1/J);::: max(N(t.p), N(.,P))
(P6) N(-,-,t.p) = N('P)

(P3) 'Pl,... , 'Pn 1--c, 1/J

(P7) N{t.p00) = 1
(P8) N(('P# 1/J)0) � min(N(t.p0), N(.,P0))
(P9) N is a classical necessity function if and only if
N(t.p0) = 1 for all t.p
min(N('P) ,N(-.t.p)) is the necessity of t.p
N(-,t.p0)
"behaving badly"; it can be seen as a measure of the
inconsistency inherent in t.p. C1-necessity functions en­
able us to rank the formulas not only with respect to
their certainty, but also with respect to their inherent
inconsistency: N( ''Po) gives a notion of inconsistency
which is both local and gradual. We recover of course
as particular cases:
=

•

•

Classical necessity functions, so that N (''Po) =
N(.l) for all t.p. The notion of inconsistency is
still gradual but global.
Classical C1-valuations, which verify N( -.t.p0) = 0
or N(...,t.p") = 1, for all t.p. The notion of inconsis­
tency is still local but not gradual.

3.2.3

C1-necessity functions: semantics

At first, a (paraconsistent) Ct-valuation [Alv 84] is a
mapping from .C to {0, 1} such that:
•
•
•
•
•
•
•

0::::} v(..,IP) 1
v(-.-,'P) = 1 {:} v(t.p) = 1
v('l/!0) = v(t.p---+ '1/J) = v(tp- + •1/J) = I::::} v(IP)
v(lf' -+ '1/J) = 1 {:} v(lf') = 0 or v(.,P) = 1
v(t.p 1\ '1/!) = 1 {::} v(tp) = 1 and v('I/J) ::::= 1
v(tpV.,P) = 1 {:} v(lf') = 1 or v('!j!) = 1
v(tp0) = v('l/!0) = 1::::} v((!f'#'l/!)0) = 1
v(t.p)

=

=

=

0

from the set of all C1-valuations to [0, 1].

Due to Proposition 12, the function fi (1r) defined

fl(7r)(1;?)

=

1- sup{11'(v)\v(1;?)

=

Reasoning with C1 Mnecessity functions
Generalizing the principle of minimum
specificity

The principle of minimum specificity [DP 86] or equiv­
alently,minimum compact ranking [Pea 90] and ratio­
nal closure [Leh 8 9] (all these being equivalent, up to
the language on which they are defined) induces, from
a possibilistic knowledge base, a particular necessity
function i.e. the smallest among all necessity functions
satisfying the knowledge base. Thanks to the prop­
erty (P3), we are able to generalize the principle of
minimum specificity to C1-necessity functions:

Definition: a C1-possibilistic knowledge base is a fi­
nite set KB = {(tp; a; ) , 1 � i � n} where if'; E .C and
a; E [0, l]. A C1-necessity function N is said to satisfy
KB iff Vi
l..n, N(lf'i) ;::: a;.
=

Definition: the minimum specificity closure NKB of a

C1-possibilistic knowledge base KB is the C1-necessity
function defined by

Vtj;
where KB13

E

=

.C, Nxs (,P)
{lf';\(!f'; ai)

=

E

sup{,BIKB11I--c1 '1/J}

KB and a;;:=: ,8}.

Proposition 17 (principle of minimum specificity for
C1-necessities): For any Ct-necessity function N, N
satisfies KB iff N;::: NxsMore generally, the minimum specificity closure could
be extended to any logic L satisfying the property
(P3). Applying the principle of minimum specificity
enables us to draw conclusions that taking into account
the uncertainty and the inconsistency of the knowledge
base. We propose the following definition of a conse­
quence relation:

Definition: KB f--- '1/J iff Nxs ( .,P)

>

Nxs(-.'1/!0).

Proposition 18: KB f--- 'rP iff Nxs(t/;)

Definition: a C1-possibility distribution is a mapping
1r

We could have also defined C1-possibility functions,
C1-necessity and possibility orderings, that we do not
discuss for the sake of brevity. C1-necessity functions
are sufficient to deal with the next section, devoted to
the application to reasoning with uncertain and incon­
sistent knowledge.

as

0}

is a Ct-necessity function (since Ct obeys the condi­
tion stated in Proposition 12 - the soundness of the
semantics coming from the soundness and complete­
ness of C1 established in [Alv 84]).

>

Nxs(-,'!j!).

Intuitively, we deduce '1/J from KB iff the certainty of
'1/J is higher than the inconsistency inherent to '1/J, or
equivalently, iff the certainty of 'lj; is higher than the
certainty of •¢. The binary version of f--- would be
defined by if' f'--KB '1/J iff Nxs(t.p -+ ¢) > Nxs(l;? -+
•if0), or equivalently iff Nxs(t.p--+ ¢) > Nxs(IP -+
-,'CjJ). Note that f-- is nonmonotonic; a more complete
study of the properties of f--- a Ia Kraus, Lehmann
and Magidor [KLM 90], is possible with respect to the
(monotonic) logic cl instead of classical logic.
Note that when N collapses to a classical necessity
measure, we haveVt/;Nx8(-.,P0) = N(..L) and f--- is the
classi cal possibilistic consequence relation [DP 91 b].

Possibility and Necessity Functions over Non-Classical Logics

(multi-source reasoning): let us return to
the example of Section 3.1. Taking some a E (0, 1 ) :

Example

•

•

W1 (witness 1):
N(female) = 1; N(brown) = 1; N(BMW) = a;
N(Chanel) = a ; N(glasses) = u:.
W2 (witness 2):
N(female) = 1; N(-.brown) = 1; N(-.BMW) =a;
N(-. glasses)= 1.

The fusion K B of these two knowledge bases gives the
following minimum specificity closure:
•

NKB(female) = 1; NKB(-.female) = 0;
NxB(-.female0) = 0;

•

NxB(brown) = 1; NKs(-.brown)= 1;
NxB(-.brown°) = 1;
NxB(BMW) u:; NxB(-.BMW) =a;
NxB(Chanel) =a; NKB(•Chanel) = 0;
NxB(•Chanel0) = 0;
NxB(glasses) = a; NKB(-.glasses)
1;
NxB(-.glasses0) = a.

•
•

•

=

=

Therefore, we have K B f--- female, K B f--- Chanel,
KB f--- -.glasses; however, KB lt- BMW, KB lt- •BMW,
K B lt- brown, K B lt- -,brown.

75

Therefore, we have
K B f--- •fly (which is intended);
K B f--- -,wings (which is intended);
f--- avoids the drowning effect, contrarily to
the classical minimum specificity closure,
System Z, and similar systems.
but also
K B f--- •live-in-Antarctica

which is not intended! (Due to NKB(fly) = /3, the
rule fly--+ •live-in-Antarctica applies).
Here is a revised definition, more suited to handling
default rules:
Definition: Let K B = FULl, where F is a set of
facts and Ll = {'Pi --+ 1/;i, i = l..n} a set of default
rules, where each rule is assigned a necessity degree
corresponding to its Z-ranking. We define

G0(Ll) =FuLl
and Vk 2': 0,

ck+l(Ll)
F u {.:p;--+ 1/;; E Gk(Ll) I NGk(f!.)('Pi) > NGk(f!.)(•.:pi)}
F u {'Pi--+ 1/;; E Gk{Ll) I Gk(Ll ) r- <:;';}.
k(Ll). Then Ll f---• 1/; iff
Lastly, let G00(Ll) = n >oG
kG00(Ll ) r- 1/;.
=

=

3.3.2

Handling default rules

Example:

Consider the fact penguin and the rules

� = {penguin---+ bird, penguin---+ •fly,
bird ---+ fly, bird ---+ wings,
fly--+ -.live-in-Antarctica}.
Applying the Z ranking procedure to Ll (written with
the possibilistic ranking convention) gives the ranking:
(for any a:, j3 such that 0 < j3 < a < 1)
{penguin--+ bird, penguin---+ --,fly,
fly---+ -.live-in-Antarctica};
�f3 = {bird ---+ fly, bird---+ wings}.

Lla

=

Then, taking the C1-minimum specificity closure of
K B = {penguin} U � leads to
•
•

•

NxB(penguin) = 1;
NxB(bird) u:;
NxB(•fly) =a;
NKB(fly--+ •live-in-Antarctica) =a;
NxB(fly) = /3;
NxB(•fly0) = /3;
NxB(wings) j3;
NxB(-.live-in-Antarctica) = /3;
NKB(-.bird)= 0;
NxB(-.bird0) = 0;
NxB(-.penguin) = 0;
NxB(--,penguin°) = 0;
NxB(-.wings) 0;
NxB(•wings0) = 0;
NxB(live-in-Antarctica)= 0;
NKB(--,live-in-Antarctica0) = 0.
=

=

•

=

Example:

We apply the usual ranking procedure:

� = {bird --+ fly, bird ---+ wings,
penguin ---+ bird, penguin ---+ -.fly,
fly---+ •live-in-Antarctica}.

G 1(Ll) = {penguin, bird---+ fly, bird--+ wings,
penguin ---+ bird, penguin --+ --,fly}.
Clearly, G00(Ll) = G1(6.). Therefore, Ll f---• •fly.
Also, Ll r-• bird and 6. f---1 wings. Contrastedly,
Ll �· •live-in-Antarctica.
4

Conclusion

We have given some basic results describing what re­
mains and what changes when switching from classi­
cal possibility theory to possibility theory over a non­
classical logic. We have then focused on a case study,
namely the paraconsistent logic C1, and showed how to
use it to reason with inconsistent and uncertain infor­
mation. W hat has been left aside in this paper is the
other possible applications of possibility theory over
non-classical logics: first, one could think of applying
the general results of Section 2 to other non-classical
logics: for instance, introducing possibility and ne­
cessity valuations into intuitionistic logic could model
gradual strengths of proofs; or, introducing them to
Kleene's logic (or more generally to a multi-valued
logic) would enable us to handle both uncertainty and
partial truth.

76

Besnard and Lang

Another topic for further research would be a parallel
study for other numerical theories of uncertainty. For
instance, paraconsistent probabilities would lead to a
more quantitative framework for reasoning with un­
certain and conflictual information; in this framework,
noticing that Prob( <p) + Prob( -.�.p) = Pro b( <p v -,<p) +
Prob( <pi\ -.�.p) = 1 + Prob( -.�.p0),relaxing the constraint
Prob( -.�.p0) = 0 would make P r ob( <p) + Prob( -.�.p) > 1
possible for some formulas; then one could think of
searching for the "least inconsistent" probability dis­
tribution satisfying a set of constraints, which could be
useful for instance when rectifying a set of inconsistent
probabilistic data.
5

