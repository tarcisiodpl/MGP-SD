
Bayesian optimization techniques have been successfully applied to robotics, planning,
sensor placement, recommendation, advertising, intelligent user interfaces and automatic
algorithm configuration. Despite these successes, the approach is restricted to problems of
moderate dimension, and several workshops on Bayesian optimization have identified its
scaling to high-dimensions as one of the holy grails of the field. In this paper, we introduce
a novel random embedding idea to attack this problem. The resulting Random EMbedding
Bayesian Optimization (REMBO) algorithm is very simple, has important invariance properties, and applies to domains with both categorical and continuous variables. We present
a thorough theoretical analysis of REMBO. Empirical results confirm that REMBO can
effectively solve problems with billions of dimensions, provided the intrinsic dimensionality
is low. They also show that REMBO achieves state-of-the-art performance in optimizing
the 47 discrete parameters of a popular mixed integer linear programming solver.

1. Introduction
Let f : X â†’ R be a function on a compact subset X âŠ† RD . We address the following global
optimization problem
x? = arg max f (x).
xâˆˆX

We are particularly interested in objective functions f that may satisfy one or more of the
following criteria: they do not have a closed-form expression, are expensive to evaluate, do
not have easily available derivatives, or are non-convex. We treat f as a blackbox function
that only allows us to query its function value at arbitrary x âˆˆ X . To address objectives of
this challenging nature, we adopt the Bayesian optimization framework.
In a nutshell, in order to optimize a blackbox function f , Bayesian optimization uses a
prior distribution that captures our beliefs about the behavior of f , and updates this prior
with sequentially acquired data. Specifically, it iterates the following phases: (1) use the
1

Wang, Hutter, Zoghi, Matheson, & de Freitas

t=2
objective fn (f( Â·))

observation (x)

acquisition max
acquisition function (u( Â·))

t=3

new observation (xt )

t=4

posterior mean (Âµ( Â·))

posterior uncertainty
(Âµ( Â·) Â± Ïƒ( Â·))

Figure 1: Three consecutive iterations of Bayesian optimization for a toy one-dimensional
problem. The unknown objective function is approximated with at Gaussian process (GP) at each iteration. The figure shows the mean and confidence intervals
for this process. It also shows the acquisition function in the lower green shaded
plots. The acquisition is high where the GP predicts a high objective (exploitation) and where the prediction uncertainty is high (exploration). Note that the
area on the far left remains under-sampled, as (despite having high uncertainty)
it is correctly predicted to be unlikely to improve over the highest observation.

prior to decide at which input x âˆˆ X to query f next; (2) evaluate f (x); and (3) update
the prior based on the new data hx, f (x)i. Step 1 uses a so-called acquisition function that
quantifies the expected value of learning the value of f (x) for each x âˆˆ X . This procedure
is illustrated in Figure 1.
2

Bayesian Optimization in a Billion Dimensions

The role of the acquisition function is to trade off exploration and exploitation; popular
choices include Thompson sampling (Thompson, 1933; Hoffman, Shahriari, & de Freitas,
2014), probability of improvement (Jones, 2001), expected improvement (MocÌŒkus, 1994),
upper-confidence-bounds (Srinivas, Krause, Kakade, & Seeger, 2010), and online portfolios
of these (Hoffman, Brochu, & de Freitas, 2011). These are typically optimized by choosing
points where the predictive mean is high (exploitation) and where the variance is large
(exploration). Since they typically have an analytical expression that is easy to evaluate,
they are much easier to optimize than the original objective function, using off-the-shelf
numerical optimization algorithms.1
The term Bayesian optimization was coined several decades ago by Jonas MocÌŒkus (1982).
A popular version of the method is known as efficient global optimization in the experimental
design literature since the 1990s (Jones, Schonlau, & Welch, 1998). Often, the approximation of the objective function is obtained using Gaussian process (GP) priors. For this
reason, the technique is also referred to as GP bandits (Srinivas et al., 2010). However,
many other approximations of the objective have been proposed, including Parzen estimators (Bergstra, Bardenet, Bengio, & KeÌgl, 2011), Bayesian parametric models (Wang
& de Freitas, 2011), treed GPs (Gramacy, Lee, & Macready, 2004) and random forests
(Brochu, Cora, & de Freitas, 2009; Hutter, 2009; Hutter, Hoos, & Leyton-Brown, 2011).
These may be more suitable than GPs when the number of iterations grows without bound,
or when the objective function is believed to have discontinuities. We also note that often
assumptions on the smoothness of the objective function are encoded without use of the
Bayesian paradigm, while leading to similar algorithms and theoretical guarantees (see, for
example, Bubeck, Munos, Stoltz, & Szepesvari, 2011, and the references therein). There is
a rich literature on Bayesian optimization, and for further details we refer readers to more
tutorial treatments (Brochu et al., 2009; Jones et al., 1998; Jones, 2001; Lizotte, Greiner,
& Schuurmans, 2011; MocÌŒkus, 1994; Osborne, Garnett, & Roberts, 2009) and recent theoretical results (Srinivas et al., 2010; Bull, 2011; de Freitas, Smola, & Zoghi, 2012).
Bayesian optimization has been demonstrated to outperform other state-of-the-art blackbox optimization techniques when function evaluations are expensive and the number of
allowed function evaluations is therefore low (Hutter, Hoos, & Leyton-Brown, 2013). In
recent years, it has found increasing use in the machine learning community (Rasmussen,
2003; Brochu, de Freitas, & Ghosh, 2007; Martinez-Cantin, de Freitas, Doucet, & Castellanos, 2007; Lizotte, Wang, Bowling, & Schuurmans, 2007; Frazier, Powell, & Dayanik,
2009; Azimi, Fern, & Fern, 2010; Hamze, Wang, & de Freitas, 2013; Azimi, Fern, & Fern,
2011; Hutter et al., 2011; Bergstra et al., 2011; Gramacy & Polson, 2011; Denil, Bazzani,
Larochelle, & de Freitas, 2012; Mahendran, Wang, Hamze, & de Freitas, 2012; Azimi, Jalali,
& Fern, 2012; Hennig & Schuler, 2012; Marchant & Ramos, 2012; Snoek, Larochelle, &
Adams, 2012; Swersky, Snoek, & Adams, 2013; Thornton, Hutter, Hoos, & Leyton-Brown,
1. This optimization step can in fact be circumvented when using treed multi-scale optimistic optimization
as recently demonstrated by Wang and de Freitas (2014). There also exist several more involved Bayesian
non-linear experimental design approaches for constructing the acquisition function, where the utility to
be optimized involves an entropy of an aspect of the posterior. This includes the work of Hennig and
Schuler (2012) for finding maxima of functions, the works of Kueck, de Freitas, and Doucet (2006) and
Kueck, Hoffman, Doucet, and de Freitas (2009) for learning functions, and the work of Hoffman, Kueck,
de Freitas, and Doucet (2009) for estimating Markov decision processes. These works rely on expensive
approximate inference methods for computing intractable integrals.

3

Wang, Hutter, Zoghi, Matheson, & de Freitas

2013). Despite many success stories, the approach is restricted to problems of moderate
dimension, typically up to about 10. Of course, for a great many problems this is all that
is needed. However, to advance the state of the art, we need to scale the methodology to
high-dimensional parameter spaces. This is the goal of this paper.
It is difficult to scale Bayesian optimization to high dimensions. To ensure that a global
optimum is found, we require good coverage of X , but as the dimensionality increases, the
number of evaluations needed to cover X increases exponentially. As a result, there has been
little progress on this challenging problem, with a few exceptions. Bergstra et al. (2011) introduced a non-standard Bayesian optimization method based on a tree of one-dimensional
density estimators and applied it successfully to optimize the 238 parameters of a complex vision architecture (Bergstra, Yamins, & Cox, 2013). Hutter et al. (2011) used random forests
models in Bayesian optimization to achieve state-of-the-art performance in optimizing up
to 76 mixed discrete/continuous parameters of algorithms for solving hard combinatorial
problems, and to successfully carry out combined model selection and hyperparameter optimization for the 768 parameters of the Auto-WEKA framework (Thornton et al., 2013).
Eggensperger, Feurer, Hutter, Bergstra, Snoek, Hoos, and Leyton-Brown (2013) showed
that these two methods indeed yielded the best performance for high-dimensional hyperparameter optimization (e.g., in deep belief networks). However, both are based on weak
uncertainty estimates that can fail even for the optimization of very simple functions and
lack theoretical guarantees.
In the linear bandits case, Carpentier and Munos (2012) recently proposed a compressed
sensing strategy to attack problems with a high degree of sparsity. Also recently, Chen,
Castro, and Krause (2012) made significant progress by introducing a two stage strategy
for optimization and variable selection of high-dimensional GPs. In the first stage, sequential
likelihood ratio tests, with a couple of tuning parameters, are used to select the relevant
dimensions. This, however, requires the relevant dimensions to be axis-aligned with an
ARD kernel. Chen and colleagues provide empirical results only for synthetic examples (of
up to 400 dimensions), but they provide key theoretical guarantees.
Many researchers have noted that for certain classes of problems most dimensions do not
change the objective function significantly; examples include hyper-parameter optimization
for neural networks and deep belief networks (Bergstra & Bengio, 2012), as well as other
machine learning algorithms and various state-of-the-art algorithms for solving N P-hard
problems (Hutter, Hoos, & Leyton-Brown, 2014). That is to say these problems have â€œlow
effective dimensionalityâ€. To take advantage of this property, Bergstra and Bengio (2012)
proposed to simply use random search for optimization â€“ the rationale being that points
sampled uniformly at random in each dimension can densely cover each low-dimensional
subspace. As such, random search can exploit low effective dimensionality without knowing
which dimensions are important. In this paper, we exploit the same property in a new
Bayesian optimization variant based on random embeddings.
Figure 2 illustrates the idea behind random embeddings in a nutshell. Assume we know
that a given D = 2 dimensional black-box function f (x1 , x2 ) only has d = 1 important
dimensions, but we do not know which of the two dimensions is the important one. We
can then perform optimization in the embedded 1-dimensional subspace defined by x1 = x2
since this is guaranteed to include the optimum.
4

Bayesian Optimization in a Billion Dimensions

x1

x1

g
in
dd
be
Em

x2

x*

Important

x*

Unimportant

x2

Figure 2: This function in D=2 dimesions only has d=1 effective dimension: the vertical
axis indicated with the word important on the right hand side figure. Hence,
the 1-dimensional embedding includes the 2-dimensional functionâ€™s optimizer.
It is more efficient to search for the optimum along the 1-dimensional random
embedding than in the original 2-dimensional space.

As we first demonstrated in a recent IJCAI conference paper (Wang, Zoghi, Hutter,
Matheson, & de Freitas, 2013), random embeddings enable us to scale Bayesian optimization
to arbitrary D provided the objective function has low intrinsic dimensionality. Importantly,
the algorithm associated with this idea, which we called REMBO, is not restricted to cases
with axis-aligned intrinsic dimensions but applies to any d-dimensional linear subspace.
Djolonga, Krause, and Cevher (2013) recently proposed an adaptive, but more expensive,
variant of REMBO with theoretical guarantees.
In this journal version of our work, we expand the presentation to provide more details throughout. In particular, we expand our description of the strategy for selecting the
boundaries of the low-dimensional space and for setting the kernel length scale parameter;
we show by means of an additional application (automatic configuration of random forest
body-part classifiers) that the performance of our technique does not collapse when the
problem does not have an obvious low effective dimensionality. Our experiments (Section
4) also show that REMBO can solve problems of previously untenable high extrinsic dimensions, and that REMBO can achieve state-of-the-art performance for optimizing the 47
discrete parameters of a popular mixed integer linear programming solver.

2. Bayesian Optimization
As mentioned in the introduction, Bayesian optimization has two ingredients that need to
be specified: The prior and the acquisition function. In this work, we adopt GP priors.
We review GPs very briefly and refer the interested reader to the book by Rasmussen and
Williams (2006). A GP is a distribution over functions specified by its mean function m(Â·)
5

Wang, Hutter, Zoghi, Matheson, & de Freitas

and covariance k(Â·, Â·). More specifically, given a set of points x1:t , with xi âˆˆ RD , we have
f (x1:t ) âˆ¼ N (m(x1:t ), K(x1:t , x1:t )),
where K(x1:t , x1:t )i,j = k(xi , xj ) serves as the covariance matrix. A common choice of k is
the squared exponential function (see Definition 7 on page 11), but many other choices are
possible depending on our degree of belief about the smoothness of the objective function.
An advantage of using GPs lies in their analytical tractability. In particular, given
observations x1:t with corresponding values f1:t , where fi = f (xi ), and a new point xâˆ— , the
joint distribution is given by:
 

 

f1:t
m(x1:t )
K(x1:t , x1:t ) k(x1:t , xâˆ— )
âˆ¼N
,
.
fâˆ—
mâˆ—
k(xâˆ— , x1:t )
k(xâˆ— , xâˆ— )
For simplicity, we assume that m(x1:t ) = 0 and mâˆ— = 0. Using the Sherman-MorrisonWoodbury formula, one can easily arrive at the posterior predictive distribution:
f âˆ— |Dt , xâˆ— âˆ¼ N (Âµ(xâˆ— |Dt ), Ïƒ(xâˆ— |Dt )),
with data Dt = {x1:t , f1:t }, and mean and variance
Âµ(xâˆ— |Dt ) = k(xâˆ— , x1:t )K(x1:t , x1:t )âˆ’1 f1:t
Ïƒ(xâˆ— |Dt ) = k(xâˆ— , xâˆ— ) âˆ’ k(xâˆ— , x1:t )K(x1:t , x1:t )âˆ’1 k(x1:t , xâˆ— ).
That is, we can compute the posterior predictive mean Âµ(Â·) and variance Ïƒ(Â·) exactly for
any point xâˆ— .
At each iteration of Bayesian optimization, one has to re-compute the predictive mean
and variance. These two quantities are used to construct the second ingredient of Bayesian
optimization: The acquisition function. In this work, we report results for the expected
improvement acquisition function (MocÌŒkus, 1982; Vazquez & Bect, 2010; Bull, 2011):
u(x|Dt ) = E(max{0, ft+1 (x) âˆ’ f (x+ )}|Dt ).
In this definition, x+ = arg maxxâˆˆ{x1:t } f (x) is the element with the best objective value in
the first t steps of the optimization process. The next query is:
xt+1 = arg max u(x|Dt ).
xâˆˆX

Note that this utility favors the selection of points with high variance (points in regions
not well explored) and points with high mean value (points worth exploiting). We also
experimented with the UCB acquisition function (Srinivas et al., 2010; de Freitas et al.,
2012) and found it to yield similar results. The optimization of the closed-form acquisition
function can be carried out by off-the-shelf numerical optimization procedures, such as DIRECT (Jones, Perttunen, & Stuckman, 1993) and CMA-ES (Hansen & Ostermeier, 2001);
it is only based on the GP model of the blackbox function f and does not require additional
evaluations of f .
The Bayesian optimization procedure is shown in Algorithm 1.
6

Bayesian Optimization in a Billion Dimensions

Algorithm 1 Bayesian Optimization
1: Initialize D0 as âˆ….
2: for t = 1, 2, . . . do
3:
Find xt+1 âˆˆ RD by optimizing the acquisition function u: xt+1 = arg maxxâˆˆX u(x|Dt ).
4:
Augment the data Dt+1 = Dt âˆª {(xt+1 , f (xt+1 ))}.
5:
Update the kernel hyper-parameters.
6: end for

3. Random Embedding for Bayesian Optimization
Before introducing our new algorithm and its theoretical properties, we need to define what
we mean by effective dimensionality formally.
Definition 1. A function f : RD â†’ R is said to have effective dimensionality de , with
de â‰¤ D, if
â€¢ there exists a linear subspace T of dimension de such that for all x> âˆˆ T âŠ‚ RD and
xâŠ¥ âˆˆ T âŠ¥ âŠ‚ RD , we have f (x> + xâŠ¥ ) = f (x> ), where T âŠ¥ denotes the orthogonal
complement of T ; and
â€¢ de is the smallest integer with this property.
We call T the effective subspace of f and T âŠ¥ the constant subspace.
This definition simply states that the function does not change along the coordinates
xâŠ¥ , and this is why we refer to T âŠ¥ as the constant subspace. Given this definition, the
following theorem shows that problems of low effective dimensionality can be solved via
random embedding.
Theorem 2. Assume we are given a function f : RD â†’ R with effective dimensionality
de and a random matrix A âˆˆ RDÃ—d with independent entries sampled according to N (0, 1)
and d â‰¥ de . Then, with probability 1, for any x âˆˆ RD , there exists a y âˆˆ Rd such that
f (x) = f (Ay).
Proof. Please refer to the appendix.
Theorem 2 says that given any x âˆˆ RD and a random matrix A âˆˆ RDÃ—d , with probability
1, there is a point y âˆˆ Rd such that f (x) = f (Ay). This implies that for any optimizer x? âˆˆ
RD , there is a point y? âˆˆ Rd with f (x? ) = f (Ay? ). Therefore, instead of optimizing in the
high dimensional space, we can optimize the function g(y) = f (Ay) in the lower dimensional
space. This observation gives rise to our new Random EMbedding Bayesian Optimization
(REMBO) algorithm (see Algorithm 2). REMBO first draws a random embedding (given
by A) and then performs Bayesian optimization in this embedded space.
In many practical optimization tasks, the goal is to optimize f over a compact subset
X âŠ‚ RD (typically a box), and f can often not be evaluated outside of X . Therefore, when
REMBO selects a point y such that Ay is outside the box X , it projects Ay onto X before
evaluating f . That is, g(y) = f (pX (Ay)), where pX : RD â†’ RD is the standard projection
operator for our box-constraint: pX (y) = arg minzâˆˆX kz âˆ’ yk2 ; see Figure 3. We still need
to describe how REMBO chooses the bounded region Y âŠ‚ Rd , inside which it performs
7

Wang, Hutter, Zoghi, Matheson, & de Freitas

y

d=1

Algorithm 2 REMBO: Bayesian Optimization with Random Embedding. Blue text denotes parts that are changed compared to standard Bayesian Optimization.
1: Generate a random matrix A âˆˆ RDÃ—d
2: Choose the bounded region set Y âŠ‚ Rd
3: Initialize D0 as âˆ….
4: for t = 1, 2, . . . do
5:
Find yt+1 âˆˆ Rd by optimizing the acquisition function u: yt+1 = arg maxyâˆˆY u(y|Dt ).
6:
Augment the data Dt+1 = Dt âˆª {(yt+1 , f (Ayt+1 ))}.
7:
Update the kernel hyper-parameters.
8: end for

D=2

Convex projection

d
be

din

g

Em

of

to

Figure 3: Embedding from d = 1 into D = 2. The box illustrates the 2D constrained space
X , while the thicker red line illustrates the 1D constrained space Y. Note that if
Ay is outside X , it is projected onto X . The set Y must be chosen large enough
so that the projection of its image, AY, onto the effective subspace (vertical axis
in this diagram) covers the vertical side of the box.

Bayesian optimization. This is important because REMBOâ€™s effectiveness depends on the
size of Y. Locating the optimum within Y is easier if Y is small, but if we set Y too small it
may not actually contain the global optimizer. In the following theorem, we show that we
can choose Y in a way that only depends on the effective dimensionality de such that the
optimizer of the original problem is contained in the low dimensional space with constant
probability.
Theorem 3. Suppose we want to optimize a function f : RD â†’ R with effective dimension
de â‰¤ d subject to the box constraint X âŠ‚ RD , where X is centered around 0. Suppose
further that the effective subspace T of f is such that T is the span of de basis vectors,
and let x?> âˆˆ T âˆ© X be an optimizer of f inside T . If A is a D Ã— d random matrix
with independent standard Gaussian
entries, there exists an optimizer y? âˆˆ Rd such that
âˆš
de
?
?
?
?
f (Ay ) = f (x> ) and ky k2 â‰¤  kx> k2 with probability at least 1 âˆ’ .
Proof. Please refer to the appendix.
8

Bayesian Optimization in a Billion Dimensions

Theorem 3 says that if the set X in the original space is a box constraint, then there
exists anâˆšoptimizer x?> âˆˆ X that is de -sparse such that with probability at least 1 âˆ’ ,
ky? k2 â‰¤ de kx?> k2 where f (Ay? ) = f (x?> ). If the box constraint is X = [âˆ’1, 1]D (which is
always achievable through rescaling), we have with probability at least 1 âˆ’  that
âˆš
âˆš
de ?
de p
?
de .
ky k2 â‰¤
kx> k2 â‰¤


Hence, to choose Y, we must ensure that the ball of radius de /, centred at the origin, lies
inside Y.
In practice, we have found that it is very
âˆš unlikely that the optimizer falls on the corner of
?
the box constraint, implying that kx> k < de . Thus setting Y too big may be unnecessarily
wasteful. To improve our understanding of this effect, we developed a simulation study, in
which we drew random Gaussian matrices, used them to map various potential optimizers
? âˆˆ Y, and studied the norms of y? .
x?> to their corresponding points y>
>
Assume for simplicity of presentation that Y is axis-aligned and de -dimensional (the
argument applies when d > de ). The section of the random matrix A that maps points
in Y to T is a random Gaussian matrix of dimension de Ã— de . Let us call this section of
the matrix B. Since random Gaussian matrices are rotationally invariant in distribution,
d
we have for any orthonormal matrix O and a random Gaussian matrix B, OB = B. That

âˆ’1 d
is, OB and B are equal in distribution. Similarly, for Bâˆ’1 , OBâˆ’1 = BOT
= Bâˆ’1 .
d

Therefore, Bâˆ’1 is also rotationally invariant. Hence, kBâˆ’1 x> kâˆž = kBâˆ’1 x0> kâˆž as long as
kx> k2 = kx0> k2 . Following this equivalence for the supremum norm of projected vectors, it
suffices to choose a point with the largest norm in [âˆ’1, 1]de in our simulations. We chose
x> = [1, 1, Â· Â· Â· , 1].
We conducted simulations for several embedding dimensions, de âˆˆ {1, 2, Â· Â· Â· , 50}, by
drawing 10000 random Gaussian matrices and computing kBâˆ’1 xkâˆž . We found that with
empirical probability above 1 âˆ’  (for decreasing values of ), it was the case that
1
max{log(de ), 1}.


d
These simulations indicate that we could set Y = âˆ’ 1 max{log(de ), 1}, 1 max{log(de ), 1} e .
âˆš
Weâˆšdidâˆš this in our experiments and in particular chose  = log(d)/ d, so that Y was
[âˆ’ d, d]d . Note that Theorem 3 is not useful for this choice, which suggests that there is
room to improve this aspect of our theory.
Some careful readers may wonder about the effect of the extrinsic dimensionality D.
In the following theorem, we show that given the same intrinsic dimensions, the extrinsic
dimensionality does not have an effect at all; in other words, REMBO is invariant to the
addition of unimportant dimensions.
kBâˆ’1 xkâˆž <

Theorem 4 (Invariance to addition of unimportant dimensions). Let f : Rde â†’ R and for
any D âˆˆ N, D â‰¥ de , define fD : RD â†’ R such that fD adds D âˆ’ de truly unimportant
(D2 âˆ’D1 )Ã—d be random
dimensions to f : fD (z) = f (z1:de ). Let A1 âˆˆ RD1 Ã—d
 and
 A0 âˆˆ R
A1
Gaussian matrices with D2 â‰¥ D1 â‰¥ d and let A2 =
. Then, REMBO run using the
A0
9

Wang, Hutter, Zoghi, Matheson, & de Freitas

same dimension d â‰¥ de and bounded region Y yields exactly the same function values when
run with A1 on fD1 as when run with A2 on fD2 .
Proof. We only need to show that for each y âˆˆ Rd , we have fD1 (A1 y) = fD2 (A2 y) since
this step of REMBO (line 6 of Algorithm 2) is the only one that differs between the two
algorithm runs. When this function evaluation step yields the same results for every y âˆˆ Rd ,
then the two REMBO runs behave identically since the algorithm
 is otherwise identical
 and

A1
A1 y
deterministic after the selection of A in Step 1. Since A2 =
, we have A2 y =
.
A0
A0 y
Since D2 â‰¥ D1 â‰¥ de , the first de entries of this D2 Ã— 1 vector A2 y are the first de entries of
A1 y. We thus have fD1 (A1 y) = f ([A1 y]1:de ) = f ([A2 y]1:de ) = fD2 (A2 y).
Finally, we show that REMBO is also invariant to rotations in the sense that given different rotation matrices, running REMBO would result in the same distributions of observed
function values. The argument is made concise in the following results.
Lemma 5. Consider function f : RD â†’ R. Let fR : RD â†’ R be such that fR (x) = f (Rx)
for some orthonormal matrix R âˆˆ RDÃ—D . Then, REMBO run in bounded region Y yields
exactly the same sequence of function values when run with A on f as when run with Râˆ’1 A
on fR for a matrix A âˆˆ RDÃ—d .
Proof. REMBO uses f and A (resp. fR and Râˆ’1 A) only in one spot (in line 6). Thus, the
proof is trivial by showing that f (Ayt+1 ) = fR (Râˆ’1 Ayt+1 ) through simple algebra:
fR (Râˆ’1 Ayt+1 ) = f (RRâˆ’1 Ayt+1 ) = f (Ayt+1 ).

Theorem 6 (Invariance to rotations). Consider function f : RD â†’ R. Let fR : RD â†’ R
be such that fR (x) = f (Rx) for some orthonormal matrix R âˆˆ RDÃ—D . Then, given random
Gaussian matrices A1 âˆˆ RDÃ—d and A2 âˆˆ RDÃ—d , REMBO run in bounded region Y yields
in distribution the same sequence of function values when run with A1 on f as when run
with A2 on fR .
d

Proof. Since R is orthonormal, we have Râˆ’1 A1 = A2 . Therefore, REMBO run in bounded
region Y yields in distribution the same sequence of function values when run with Râˆ’1 A1
on fR as when run with A2 on fR . We have also by Lemma 5 that REMBO run in bounded
region Y yields exactly the same sequence of function values when run with A1 on f as when
run with Râˆ’1 A1 on fR . The conclusion follows from combining the previous arguments.
3.1 Increasing the Success Rate of REMBO
Theorem 3 only guarantees that Y contains the optimum with probability at least 1âˆ’; with
probability Î´ â‰¤  the optimizer lies outside of Y. There are several ways to guard against
this problem. One is to simply run REMBO multiple times with different independently
drawn random embeddings. Since the probability of failure with each embedding is Î´, the
probability of the optimizer not being included in the considered space of k independently
drawn embeddings is Î´ k . Thus, the failure probability vanishes exponentially quickly in
10

Bayesian Optimization in a Billion Dimensions

the number of REMBO runs, k. Note also that these independent runs can be trivially
parallelized to harness the power of modern multi-core machines and large compute clusters.
Another way of increasing REMBOâ€™s success rate is to increase
the dimensionality d

it uses internally. When d > de , with probability 1 we have dde different embeddings of
dimensionality de . That is, we only need to select de columns of A âˆˆ RDÃ—d to represent
the de relevant dimensions of x. The algorithm can achieve this by setting the remaining
d âˆ’ de sub-components of the d-dimensional vector y to zero. Informally, since we have
more embeddings, it is more likely that one of these will include the optimizer. In our
experiments, we will assess the merits and shortcomings of these two strategies.
3.2 Choice of Kernel
Since REMBO uses GP-based Bayesian optimization to search in the region Y âŠ‚ Rd , we
need to define a kernel between two points y(1) , y(2) âˆˆ Y. We begin with the standard
definition of the squared exponential kernel:
Definition 7. Let KSE (y) = exp(âˆ’kyk2 /2). Given a length scale ` > 0, we define the
corresponding squared exponential kernel as
!
y(1) âˆ’ y(2)
(2)
d (1)
k` (y , y ) = KSE
`
It is possible to work with two variants of this kernel. First, we can use k`d (y1 , y2 ) as in
Definition 7. We refer to this kernel as the low-dimensional kernel. We can also adopt an
implicitly defined high-dimensional kernel on X :
!
(1) ) âˆ’ p (Ay(2) )
p
(Ay
X
X
k`D (y(1) , y(2) ) = KSE
,
`
where pX : RD â†’ RD is the projection operator for our box-constraint as above (see
Figure 3).
Note that when using this high-dimensional kernel, we are fitting the GP in D dimensions. However, the search space is no longer the box X , but it is instead given by the much
smaller subspace {pX (Ay) : y âˆˆ Y}. Importantly, in practice it is easier to maximize the
acquisition function in this subspace.
Both kernel choices have strengths and weaknesses. The low-dimensional kernel has the
benefit of only requiring the construction of a GP in the space of intrinsic dimensionality
d, whereas the high-dimensional kernel requires the GP to be constructed in a space of
extrinsic dimensionality D. However, the low-dimensional kernel may waste time exploring
in the region of the embedding outside of X (see Figure 2) because two points far apart
in this region may be projected via pX to nearby points on the boundary of X . The highdimensional kernel is not affected by this problem because the search is conducted directly
on {pX (Ay) : y âˆˆ Y} with distances calculated in X and not in Y.
The choice of kernel also depends on whether our variables are continuous, integer or
categorical. The categorical case is important because we often encounter optimization
11

Wang, Hutter, Zoghi, Matheson, & de Freitas

Algorithm 3 Bayesian Optimization with Hyper-parameter Optimization.
input Threshold tÏƒ .
input Upper and lower bounds U > L > 0 for hyper-parameter.
input Initial length scale hyper-parameter ` âˆˆ [L, U ].
1: Initialize C = 0
2: for t = 1, 2, . . . do
3:
Find
p xt+1 by optimizing the acquisition function u: xt+1 = arg maxxâˆˆX u(x|Dt ).
4:
if Ïƒ 2 (xt+1 ) < tÏƒ then
5:
C =C +1
6:
else
7:
C=0
8:
end if
9:
Augment the data Dt+1 = {Dt , (xt+1 , f (xt+1 ))}
10:
if t mod 20 = 0 or C = 5 then
11:
if C = 5 then
12:
U = max{0.9`, L}
13:
C=0
14:
end if
15:
Learn the hyper-parameter by optimizing the log marginal likelihood by using
DIRECT and CMA-ES: ` = arg maxlâˆˆ[L,U ] log p(f1:t+1 |x1:t+1 , l)
16:
end if
17: end for
problems that contain discrete choices. We define our kernel for categorical variables as:


Î»
D (1)
(2)
(1)
(2) 2
kÎ» (y , y ) = exp âˆ’ h(s(Ay ), s(Ay )) ,
2
where y(1) , y(2) âˆˆ Y âŠ‚ Rd , the function s maps continuous d-dimensional vectors to discrete
D-dimensional vectors, and h defines the distance between two discrete vectors. In more
detail, s(x) first uses pX to project x to xÌ„ âˆˆ [âˆ’1, 1]D . For each dimension xÌ„i of xÌ„, s then
maps xÌ„i to a discrete value by scaling and rounding. In our experiments, following Hutter
(1)
(2)
(2009), we defined h(x(1) , x(2) ) = |{i : xi 6= xi }| so as not to impose an artificial ordering
between the values of categorical parameters. In essence, we measure the distance between
two points in the low-dimensional space as the Hamming distance between their mappings
in the high-dimensional space.
3.3 Hyper-parameter Optimization
For Bayesian optimization (and therefore REMBO), it is difficult to manually estimate
the true length scale hyper-parameter of a problem at hand. To avoid any manual steps and
to achieve robust performance across diverse sets of objective functions, in this paper we
adopted an adaptive hyper-parameter optimization scheme. The length scale of GPs is often
set by maximizing marginal likelihood (Rasmussen & Williams, 2006; Jones et al., 1998).
However, as demonstrated by Bull (2011), this approach, when implemented naively, may
not guarantee convergence. This is not only true of approaches that maximize the marginal
12

Bayesian Optimization in a Billion Dimensions

likelihood, but also of approaches that rely on Monte Carlo sampling from the posterior
distribution (Brochu, Brochu, & de Freitas, 2010; Snoek et al., 2012) when the number of
data is very small, unless the prior is very informative.
Here, we propose to optimize the length scale parameter ` by maximizing the marginal
likelihood subject to an upper bound U which is decreased when the algorithm starts
exploiting too much. Full details are given in Algorithm 3. We say that the algorithm
is
p exploiting when the standard deviation at the maximizer of the acquisition function
Ïƒ(xt+1 ) is less than some threshold tÏƒ for 5 consecutive iterations. Intuitively, this means
that the algorithm did not emphasize exploration (searching in new parts of the space,
where the predictive uncertainty is high) for 5 consecutive iterations. When this criterion
is met, the algorithm decreases its upper bound U multiplicatively and re-optimizes the
hyper-parameter subject to the new bound. Even when the criterion is not met the hyperparameter is re-optimized every 20 iterations. For each optimization of the acquisition
function, the algorithm runs both DIRECT (Jones et al., 1993) and CMA-ES (Hansen &
Ostermeier, 2001) and uses the result of the best of the two options. The astute reader may
wonder about the difficulty of optimizing the acquisition functions. For REMBO, however,
we have not found the optimization of the acquisition function to be a problem since we only
need to optimize it in the low-dimensional space and our acquisition function evaluations
are cheap, allowing us tens of thousands of evaluations in seconds that (empirically) suffice
to cover the low-dimensional space well.
The motivation of this algorithm is to rather err on the side of having too small a length
scale: given a squared exponential kernel k` , with a smaller length scale than another kernel
k, one can show that any function f in the RKHS characterized by k is also an element of the
RKHS characterized by k` . Thus, when running expected improvement, one can safely use
k` instead of k as the kernel of the GP and still preserve convergence (Bull, 2011). We argue
that (with a small enough lower bound L) the algorithm would eventually reduce the upper
bound enough to allow convergence. Also, the algorithm would not explore indefinitely as
L is required to be positive. In our experiments, we set the initial constraint [L, U ] to be
[0.01, 50] and set tÏƒ = 0.002.
We want to stress the fact that the above argument is only known to hold for a class
of kernels over continuous domains (e.g. squared exponential and MateÌrn class kernels).
Although we believe that a similar argument could be made for integer and categorical
kernels, rigorous arguments concerning convergence under these kernels remain a challenge
in Bayesian optimization.

4. Experiments
We now study REMBO empirically. We first use synthetic functions of small intrinsic dimensionality de = 2 but extrinsic dimension D up to 1 billion to demonstrate REMBOâ€™s
independence of D. Then, we apply REMBO to automatically optimize the 47 parameters of a widely-used mixed integer linear programming solver and demonstrate that it
achieves state-of-the-art performance. However, we also warn against the blind application
of REMBO. To illustrate this, we study REMBOâ€™s performance for tuning the 14 parameters of a random forest body part classifier used by Kinect. In this application, all the
D = 14 parameters appear to be important, and while REMBO (based on d = 3) finds
13

Wang, Hutter, Zoghi, Matheson, & de Freitas

reasonable solutions (better than random search and comparable to what domain experts
achieve), standard Bayesian optimization can outperform REMBO (and the domain experts) in such moderate-dimensional spaces. More optimistically, this random forest tuning
application shows that REMBO does not fail catastrophically when it is not clear that the
optimization problem has low effective dimensionality.
4.1 Experimental Setup
For all our experiments, we used a single robust version of REMBO that automatically sets
its GPâ€™s length scale parameter as described in Section 3.3. The code for REMBO, as well as
all data used in our experiments is publicly available at https://github.com/ziyuw/rembo.
Some of our experiments required substantial computational resources, with the computational expense of each experiment depending mostly on the cost of evaluating the
respective black-box function. While the synthetic experiments in Section 4.2 only required
minutes for each run of each method, optimizing the mixed integer programming solver
in Section 4.4 required 4-5 hours per run, and optimizing the random forest classifier in
Section 4.5 required 4-5 days per run. In total, we used over half a year of CPU time for
the experiments in this paper. In the first two experiments, we study the effect of our
two methods for increasing REMBOâ€™s success rate (see Section 3.1) by running different
numbers of independent REMBO runs with different settings of its internal dimensionality
d.
4.2 Bayesian Optimization in a Billion Dimensions
The experiments in this section employ a standard de = 2-dimensional benchmark function
for Bayesian optimization, embedded in a D-dimensional space. That is, we add D âˆ’ 2
additional dimensions which do not affect the function at all. More precisely, the function
whose optimum we seek is f (x1:D ) = g(xi , xj ), where g is the Branin function
g(x1 , x2 ) = (x2 âˆ’

5.1 2 5
1
x1 + x1 âˆ’ 6)2 + 10(1 âˆ’
) cos(x1 ) + 10
2
4Ï€
Ï€
8Ï€

and where i and j are selected once using a random permutation. To measure the performance of each optimization method, we used the optimality gap: the difference of the best
function value it found and the optimal function value.
We evaluate REMBO using a fixed budget of 500 function evaluations that is spread
across multiple interleaved runs â€” for example, when using k = 4 interleaved REMBO runs,
each of them was only allowed 125 function evaluations. We study the choices of k and d by
considering several combinations of these values. The results in Table 1 demonstrate that
interleaved runs helped improve REMBOâ€™s performance. We note that in 13/50 REMBO
runs, the global optimum was indeed not contained in the box Y REMBO searched with
d = 2; this is the reason for the poor mean performance of REMBO with d = 2 and k = 1.
However, the remaining 37 runs performed very well, and REMBO thus performed well
when using multiple interleaved runs: with a failure rate of 13/50=0.26 per independent
run, the failure rate using k = 4 interleaved runs is only 0.264 â‰ˆ 0.005. One could easily
achieve an arbitrarily small failure rate by using many independent parallel runs. Using a
larger d is also effective in increasing the probability of the optimizer falling into REMBOâ€™s
14

Bayesian Optimization in a Billion Dimensions

Figure 4: Comparison of random search (RANDOM), Bayesian optimization (BO), method
by Chen et al. (2012) (HD BO), and REMBO. Left: D = 25 extrinsic dimensions;
Right: D = 25, with a rotated objective function; Bottom: D = 109 extrinsic
dimensions. We plot means and 1/4 standard deviation confidence intervals of
the optimality gap across 50 trials.

box Y but at the same time slows down REMBOâ€™s convergence (such that interleaving
several short runs loses its effectiveness).
Next, we compared REMBO to standard Bayesian optimization (BO) and to random
search, for an extrinsic dimensionality of D = 25. Standard BO is well known to perform
well in low dimensions, but to degrade above a tipping point of about 15-20 dimensions.
Our results for D = 25 (see Figure 4, left) confirm that BO performed rather poorly just
above this critical dimensionality (merely tying with random search). REMBO, on the
other hand, still performed very well in 25 dimensions.
One important advantage of REMBO is that â€” in contrast to the approach of Chen
et al. (2012) â€” it does not require the effective dimension to be coordinate aligned. To
demonstrate this fact empirically, we rotated the embedded Branin function by an orthogonal rotation matrix R âˆˆ RDÃ—D . That is, we replaced f (x) by f (Rx). Figure 4 (middle)
shows that REMBOâ€™s performance is not affected by this rotation.
Finally, since REMBO is independent of the extrinsic dimensionality D as long as the
intrinsic dimensionality de is small, it performed just as well in D = 1 000 000 000 dimensions
15

Wang, Hutter, Zoghi, Matheson, & de Freitas

k
10
5
4
2
1

d=2
0.0022 Â± 0.0035
0.0004 Â± 0.0011
0.0001 Â± 0.0003
0.1514 Â± 0.9154
0.7406 Â± 1.8996

d=4
0.1553 Â± 0.1601
0.0908 Â± 0.1252
0.0654 Â± 0.0877
0.0309 Â± 0.0687
0.0143 Â± 0.0406

d=6
0.4865 Â± 0.4769
0.2586 Â± 0.3702
0.3379 Â± 0.3170
0.1643 Â± 0.1877
0.1137 Â± 0.1202

Table 1: Optimality gap for de = 2-dimensional Branin function embedded in D = 25
dimensions, for REMBO variants using a total of 500 function evaluations. The
variants differed in the internal dimensionality d and in the number of interleaved
runs k (each such run was only allowed 500/k function evaluations). We show
mean and standard deviations of the optimality gap achieved after 500 function
evaluations.

(see Figure 4, right). To the best of our knowledge, the only other existing method that
can be run in such high dimensionality is random search.
For reference, we also evaluated the method of Chen et al. (2012) for these functions,
confirming that it does not handle rotation gracefully: while it performed best in the nonrotated case for D = 25, it performed worst in the rotated case. It could not be used
efficiently for more than D = 1, 000. Based on a Mann-Whitney U test with Bonferroni
multiple-test correction, all performance differences were statistically significant, except
Random vs. standard BO. Finally, comparing REMBO to the method of Chen et al. (2012),
we also note that REMBO is much simpler to implement and that its results are very reliable
(with interleaved runs).
4.3 Synthetic Discrete Experiment
In this section, we test the high-dimensional kernel with a synthetic experiment. Specifically,
we again optimize the Branin function, but restrict its domain to 225 discrete points on a
regular grid. As above, we added 23 additional irrelevant dimensions to make the problem
25-dimensional in total.
We used a small fixed budget of 100 function evaluations for all algorithms involved
as the problem would require no more than 225 evaluations to be solved completely. We
used k = 4 interleaved runs for REMBO. We again compare REMBO to random search
and standard BO. For REMBO, we use the high-dimensional kernel to handle the discrete
nature of the problem. The result of the comparison is summarized in Figure 5. Standard
BO again suffered from the high extrinsic dimensionality and performed slightly worse than
random search. REMBO, on the other hand, performed well in this setting.
4.4 Automatic Configuration of a Mixed Integer Linear Programming Solver
State-of-the-art algorithms for solving hard computational problems tend to parameterize
several design choices in order to allow a customization of the algorithm to new problem domains. Automated methods for algorithm configuration have recently demonstrated
that substantial performance gains of state-of-the-art algorithms can be achieved in a fully
16

Bayesian Optimization in a Billion Dimensions

Figure 5: Comparison of random search (RANDOM), Bayesian optimization (BO), and
REMBO. D = 25 extrinsic dimensions. We plot means and 1/4 standard deviation confidence intervals of the optimality gap across 50 trials.

automated fashion (MocÌŒkus, MocÌŒkus, & MocÌŒkus, 1999; Hutter, Hoos, Leyton-Brown, &
StuÌˆtzle, 2009; Hutter, Hoos, & Leyton-Brown, 2010; Vallati, Fawcett, Gerevini, Hoos, &
Saetti, 2011; Bergstra et al., 2011; Wang & de Freitas, 2011). These successes have led
to a paradigm shift in algorithm development towards the active design of highly parameterized frameworks that can be automatically customized to particular problem domains
using optimization (Hoos, 2012; Bergstra et al., 2013; Thornton et al., 2013). The resulting algorithm configuration problems have been shown to have low dimensionality (Hutter
et al., 2014), and here, we demonstrate that REMBO can exploit this low dimensionality
even in the discrete spaces typically encountered in algorithm configuration. We use a configuration problem obtained from Hutter et al. (2010), aiming to configure the 40 binary
and 7 categorical parameters of lpsolve (Berkelaar, Eikland, & Notebaert, 2016) , a popular
mixed integer programming (MIP) solver that has been downloaded over 40 000 times in
the last year. The objective is to minimize the optimality gap lpsolve can obtain in a time
limit of five seconds for a MIP encoding of a wildlife corridor problem from computational
sustainability (Gomes, van Hoeve, & Sabharwal, 2008). Algorithm configuration usually
aims to improve performance for a representative set of problem instances, and effective
methods need to solve two orthogonal problems: searching the parameter space effectively
and deciding how many instances to use in each evaluation (to trade off computational overhead and over-fitting). Our contribution is for the first of these problems; to focus on how
effectively the different methods search the parameter space, we only consider configuration
on a single problem instance.
Due to the discrete nature of this optimization problem, we could only apply REMBO
using the high-dimensional kernel for categorical variables kÎ»D (y(1) , y(2) ) described in Section 3.2. While we have not proven any theoretical guarantees for discrete optimization
17

Wang, Hutter, Zoghi, Matheson, & de Freitas

Figure 6: Performance of various methods for configuration of lpsolve; we show the optimality gap lpsolve achieved with the configurations found by the various methods (lower is better). Left: a single run of each method; Right: performance with
k = 4 interleaved runs.

problems, REMBO appears to effectively exploit the low effective dimensionality of at least
this particular optimization problem.
Figure 6 (left) compares BO, REMBO, and the baseline random search against ParamILS
(Hutter et al., 2009) and SMAC (Hutter et al., 2011). ParamILS and SMAC were specifically
designed for the configuration of algorithms with many discrete parameters and define the
current state of the art for this problem. Nevertheless, here SMAC and our vanilla REMBO
method performed best. Based on a Mann-Whitney U test with Bonferroni multiple-test
correction, they both yielded statistically significantly better results than both Random
and standard BO; no other performance differences were significant. The figure only shows
REMBO with d = 5 to avoid clutter, but we did not optimize this parameter; the only
other value we tried (d = 3) resulted in indistinguishable .
As in the synthetic experiment, REMBOâ€™s performance could be further improved by
using multiple interleaved runs. However, as shown by Hutter, Hoos, and Leyton-Brown
(2012), multiple independent runs can also improve the performance of SMAC and especially
ParamILS. Thus, to be fair, we re-evaluated all approaches using interleaved runs. Figure
6 (right) shows that ParamILS and REMBO benefitted most from interleaving k = 4 runs.
However, the statistical test results did not change, still showing that SMAC and REMBO
outperformed Random and BO, with no other significant performance differences.
4.5 Automatic Configuration of Random Forest Kinect Body Part Classifier
We now evaluate REMBOâ€™s performance for optimizing the 14 parameters of a random
forest body part classifier. This classifier closely follows the proprietary system used in the
Microsoft Kinect (Shotton, Fitzgibbon, Cook, Sharp, Finocchio, Moore, Kipman, & Blake,
2011) and is available at https://github.com/david-matheson/rftk.
18

Bayesian Optimization in a Billion Dimensions

Figure 7: Left: ground truth depth, ground truth body parts and predicted body parts;
Right: features specified by offsets u and v.

We begin by describing some details of the dataset and classifier in order to build
intuition for the objective function and the parameters being optimized. The data we
used consists of pairs of depth images and ground truth body part labels. Specifically,
we used 1 500 pairs of 320x240 resolution depth and body part images, each of which was
synthesized from a random pose of the CMU mocap dataset. Depth, ground truth body
parts and predicted body parts (as predicted by the classifier described below) are visualized
for one pose in Figure 7 (left). There are 19 body parts plus one background class. For each
of these 20 possible labels, the training data contained 25 000 pixels, randomly selected from
500 training images. Both validation and test data contained all pixels in the 500 validation
and test images, respectively.
The random forest classifier is applied to one pixel P at a time. At each node of each of
its decision trees, it computes the depth difference between two pixels described by offsets
from P and compares this to a threshold. At training time, many possible pairs of offsets
are generated at random, and the pair yielding highest information gain for the training
data points is selected. Figure 7 (right) visualizes a potential feature for the pixel in the
green box: it computes the depth difference between the pixels in the red box and the white
box, specified by respective offsets u and v. At training time, u and v are drawn from two
independent 2-dimensional Gaussian distributions, each of which is parameterized by its
two mean parameters Âµ1 and Âµ2 and three covariance terms Î£11 , Î£12 , and Î£22 (Î£21 = Î£12
because of symmetry). These constitute 10 of the parameters that need to be optimized,
with range [-50,50] for the mean components and [1, 200] for the covariance terms. Low
covariance terms yield local features, while high terms yield global features. Next to these
ten parameters, the random forest classifier has four other standard parameters, outlined
in Table 2. It is well known in computer vision that many of the parameters described here
are important. Much research has been devoted to identifying their best values, but results
are dataset specific, without definitive general answers.
The objective in optimizing these RF classifier parameters is to find a parameter setting
that learns the best classifier in a given time budget of five minutes. To enable competitive
performance in this short amount of time, at each node of the tree only a random subset of
19

Wang, Hutter, Zoghi, Matheson, & de Freitas

Table 2: Parameter ranges for random forest classifier. For the purpose of optimization,
the maximum tree depth and the number of potential offsets were transformed to
log space.
Parameter

Range

Max. tree depth
Min. No. samples for non leaf nodes
No. potential offsets to evaluate
Bootstrap for per tree sampling

[1 60]
[1 100]
[1 5000]
[T F]

data points is considered. Also note that the above parameters do not include the number
of trees T in the random forest; since performance improves monotonically in T , we created
as many trees as possible in the time budget. Trees are constructed depth first and returned
in their current state when the time budget is exceeded. Using a fixed budget results in
a subtle optimization problem because of the complex interactions between the various
parameters (maximum depth, number of potential offsets, number of trees and accuracy).
It is unclear a priori whether a low-dimensional subspace of these 14 interacting parameters exists that captures the classification accuracy of the resulting random forests.
We performed large-scale computational experiments with REMBO, random search, and
standard Bayesian optimization (BO) to study this question. In this experiment, we used
the high-dimensional kernel for REMBO to avoid the potential over-exploration problems
of the low-dimensional kernel described in Section 3.2. We believed that D = 14 dimensions
would be small enough to avoid inefficiencies in fitting the GP in D dimensions. This belief
was confirmed by the observation that standard BO (which operates in D = 14 dimensions)
performed well for this problem.
Figure 8 (left) shows the results that can be obtained by a single run of random search,
BO, and REMBO. Remarkably, REMBO clearly outperformed random search, even based
on as few as d = 3 dimensions.2 However, since the extrinsic dimensionality was â€œonlyâ€
a moderate D = 14, standard Bayesian optimization performed well, and since it was
not limited to a low-dimensional subspace it outperformed REMBO. Nevertheless, several
REMBO runs actually performed very well, comparably with the best runs of BO. Consequently, when running k = 4 interleaved runs of each method, REMBO performed almost
as well as BO, matching its performance up to about 450 function evaluations (see Figure
8, right).
We conclude that the parameter space of this RF classifier does not appear to have a
clear low effective dimensionality; since the extrinsic dimensionality is only moderate, this
leads REMBO to perform somewhat worse than standard Bayesian optimization, but it is
still possible to achieve reasonable performance based on as little as d = 3 dimensions.
2. Due to the large computational expense of this experiment (in total over half a year of CPU time), we
only performed conclusive experiments with d = 3; preliminary runs of REMBO with d = 4 performed
somewhat worse than those with d = 3 for a budget of 200 function evaluations, but were still improving
at that point.

20

Bayesian Optimization in a Billion Dimensions

Figure 8: Performance of various methods for optimizing RF parameters for body part
classification. For all methods, we show RF accuracy (mean Â± 1/4 standard
deviation across 10 runs) for all 2.2 million non background pixels in the 500pose validation set, using the RF parameters identified by the method. The
results on the test set were within 1% of the results on the validation set. Left:
performance with a single run of each method; Right: performance with k = 4
interleaved runs.

5. Conclusion
We have demonstrated that it is possible to use random embeddings in Bayesian optimization to optimize functions of extremely high extrinsic dimensionality D provided that
they have low intrinsic dimensionality de . Moreover, our resulting REMBO algorithm is
coordinate independent and it only requires a simple modification of the original Bayesian
optimization algorithm; namely multiplication by a random matrix. We proved REMBOâ€™s
independence of D theoretically and empirically validated it by optimizing low-dimensional
functions embedded in previously untenable extrinsic dimensionalities of up to 1 billion.
We also theoretically and empirically showed REMBOâ€™s rotational invariance. Finally, we
demonstrated that REMBO achieves state-of-the-art performance for optimizing the 47 discrete parameters of a popular mixed integer programming solver, thereby providing further
evidence for the observation (already put forward by Bergstra, Hutter and colleagues) that,
for many problems of great practical interest, the number of important dimensions indeed
appears to be much lower than their extrinsic dimensionality.
We note that the central idea of our work â€“ using an otherwise unmodified optimization procedure in a randomly embedded space â€“ in principle could be applied to arbitrary
optimization procedures. Evaluating the effciency of this technique for other procedures is
an interesting topic for future work.

Acknowledgements
We thank Christof SchoÌˆtz for proofreading a draft of this article.
21

Wang, Hutter, Zoghi, Matheson, & de Freitas

