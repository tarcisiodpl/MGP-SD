Incorporating Expressive Graphical Models Variational Approximations Chain-Graphs Hidden Variables Global variational approximation methods graphical models allow efficient approximate inference complex posterior distributions using simpler model choice approximating model determines tradeoff complexity approximation procedure quality approximation paper consider variational approximations based classes models richer standard Bayesian networks Markov networks mixture models classes allow tradeoffs spectrum approximations class models chain graphs capture distributions partially directed class models directed graphs Bayesian networks additional latent variables classes allow representation multi-variable dependencies easily represented Bayesian network Image Segmentation Video Sequences Probabilistic Approach Background subtraction technique finding moving objects video sequence example cars driving freeway idea subtracting current image timeaveraged background image leave nonstationary objects crude approximation task classifying pixel current image fails slow-moving objects distinguish shadows moving objects basic idea paper classify pixel using model pixel classes learn mixture-of-Gaussians classification model pixel using unsupervised technique efficient incremental version EM standard image-averaging approach automatically updates mixture component class likelihood membership slow-moving objects handled perfectly approach identifies eliminates shadows effectively techniques thresholding Application method Roadwatch traffic surveillance project expected result improvements vehicle identification tracking Template Based Inference Symmetric Relational Markov Random Fields Relational Markov Random Fields flexible framework reasoning joint distribution attributes interacting entities main computational difficulty learning models inference dealing complete data summarize domain sufficient statistics learning requires compute expectation sufficient statistics parameter choices typical solution resort approximate inference procedures loopy belief propagation procedures efficient require computation interactions features model learning relational model complex domain approximations require unrealistic running time paper class relational MRFs inherent symmetry perform inference learning procedures using template-level belief propagation procedure 's running time proportional size relational model size domain computational procedure equivalent sychronous loopy belief propagation enables dramatic speedup inference learning time procedure learn relational MRFs capturing joint distribution protein-protein interaction networks Sequential Update Bayesian Network Structure obvious improving performance accuracy Bayesian network data observed errors model construction changes dynamics domains afford ignore data sequential update parameters fixed structure accomplished using standard techniques sequential update network structure paper investigate sequential update Bayesian networks parameters structure expected change introduce approach allows flexible manipulation tradeoff quality learned networks amount maintained observations formally describe approach including modifications scoring functions learning Bayesian networks evaluate effectiveness empirical study extend missing data Convexifying Bethe Free Energy introduction loopy belief propagation LBP revitalized application graphical models domains improvements basic LBP algorithm attempt overcome convergence local optima Notable convexified free energy approximations lead inference procedures provable convergence quality properties empirically LBP outperforms convex variants variety settings demonstrate Motivated seek convexified free energies directly approximate Bethe free energy proposed approximations compare favorably state-of-the art convex free energy approximations Field Variational Approximation Continuous-Time Bayesian Networks Continuous-time Bayesian networks natural structured representation language multicomponent stochastic processes evolve continuously time compact representation inference models intractable simple structured networks introduce field variational approximation product inhomogeneous Markov processes approximate distribution trajectories variational approach leads globally consistent distribution efficiently queried Additionally lower bound probability observations attractive learning tasks provide theoretical foundations approximation efficient implementation exploits wide range highly optimized ordinary differential equations ODE solvers experimentally explore characterizations processes approximation suitable applications large-scale realworld inference Multivariate Bottleneck bottleneck method unsupervised non-parametric data organization technique joint distribution method constructs variable extracts partitions clusters values informative bottleneck applied document classification gene expression neural code spectral analysis paper introduce principled framework multivariate extensions bottleneck method allows consider multiple systems data partitions inter-related approach utilizes Bayesian networks systems clusters captures construction insight bottleneck variations enables characterize solutions variations framework iterative algorithms constructing solutions apply examples Continuous Time Markov Networks central task applications reasoning processes change continuous time mathematical framework Continuous Time Markov Processes basic foundations modeling systems Nodelman al introduced continuous time Bayesian networks CTBNs allow compact representation continuous-time processes factored space paper introduce continuous time Markov networks CTMNs alternative representation language represents type continuous-time dynamics real life processes biological chemical systems dynamics process naturally described interplay forces tendency entity change fitness energy function entire system model force described continuous-time proposal process suggests local changes system rates force represented Markov network encodes fitness desirability proposed local change accepted probability function change fitness distribution fitness distribution stationary distribution Markov process representation characterization temporal process stationary distribution compact graphical representation allows naturally capture type structure complex dynamical processes evolving biological sequences describe semantics representation basic properties compares CTBNs provide algorithms learning models data discuss applicability biological sequence evolution Gaussian Process Networks paper address learning structure Bayesian network domains continuous variables task requires procedure comparing candidate structures Bayesian framework evaluating em marginal likelihood data candidate structure term computed closed-form standard parametric families e.g. Gaussians approximated computational cost semi-parametric families e.g. mixtures Gaussians family continuous variable probabilistic networks based em Gaussian Process priors priors semi-parametric nature learn arbitrary noisy functional relations Using priors directly compute marginal likelihoods structure learning method discover wide range functional dependencies multivariate data develop Bayesian score Gaussian Process Networks describe learn data empirical artificial data real-life domains non-linear dependencies Gibbs Sampling Factorized Continuous-Time Markov Processes central task applications reasoning processes change continuous time Continuous-Time Bayesian Networks compact representation language multi-component continuous-time processes exact inference processes exponential components infeasible models develop novel Gibbs sampling procedure multi-component processes procedure iteratively samples trajectory components remaining perform exact sampling adapts natural time scale sampled process sampling procedure naturally exploits structure network reduce computational cost step procedure provide asymptotically unbiased approximation processes Learning Dimensionality Hidden Variables serious learning probabilistic models presence hidden variables variables observed interact observed variables Detecting hidden variables poses determining relations variables model determining hidden variable paper address context Bayesian networks describe approach utilizes score-based agglomerative state-clustering approach allows efficiently evaluate models range cardinalities hidden variable extend procedure deal multiple interacting hidden variables demonstrate effectiveness approach evaluating synthetic real-life data approach learns models hidden variables generalize structure previous approaches Bayesian Network Structure domains analyzing structure underlying distribution e.g. variable direct parent Bayesian model-selection attempts MAP model structure answer questions amount data modest models non-negligible posterior compute Bayesian posterior feature i.e. total posterior probability models paper propose approach task efficiently compute sum exponential networks consistent fixed network variables allows compute marginal probability data posterior feature result basis algorithm approximates Bayesian posterior feature approach Markov Chain Monte Carlo MCMC method orderings network structures space orderings regular space structures smoother posterior landscape empirical synthetic real-life datasets compare approach model averaging MCMC network structures non-Bayesian bootstrap approach Dimension Reduction Singularly Perturbed Continuous-Time Bayesian Networks Continuous-time Bayesian networks CTBNs graphical representations multi-component continuous-time Markov processes directed graphs edges network represent direct influences components joint rate matrix multi-component process conditional rate matrices component separately paper addresses situation components evolve time scale shorter compared time scale components paper prove limit separation scales infinite Markov process converges distribution weakly reduced effective Markov process involves slow components demonstrate reasonable separation scale magnitude reduced process approximation marginal process slow components provide simple procedure building reduced CTBN effective process conditional rate matrices directly calculated original CTBN discuss implications approximate reasoning systems Likelihood Computations Using Value Abstractions paper evidence-specific value abstraction speeding Bayesian networks inference variable values treating combined values single entity abstractions exploit regularities conditional probability distributions specific values observed variables formally justify value abstraction define notion safe value abstraction devise inference algorithms reduce cost inference procedure useful learning complex networks hidden variables repeated likelihood computations required EM parameter optimization techniques computations repeated respect evidence set methods provide speedup learning procedure demonstrate algorithm genetic linkage value abstraction differentiates feasible non-feasible solution