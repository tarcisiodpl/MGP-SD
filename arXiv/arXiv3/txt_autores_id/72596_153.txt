 The paper introduces a generalization for known probabilistic models such as log linear and graphical models  called here multiplicative models  These models  that express probabilities via product of parameters are shown to capture multiple forms of contextual independence between variables  including decision graphs and noisy OR functions  An inference algorithm for multiplicative models is provided and its correctness is proved  The complexity analysis of the inference algorithm uses a more refined parameter than the tree width of the underlying graph  and shows the computational cost does not exceed that of the variable elimination algorithm in graphical models  The paper ends with examples where using the new models and algorithm is computationally beneficial      Introduction  Probabilistic models that represent associations and or interactions among random variables have been heavily applied in the past century in various fields of science and engineering  The statistical methods originating with the work of Fisher                     culminated in the log linear models which describe the association patterns among a set of categorical variables without specifying any variable as a response  dependent  variable      A specific type of probabilistic models  probabilistic graphical models  can be visually described as an interaction graph  and embody independence assumptions in the domain of interest       Their main attraction is that the independences encoded in the structure of the model allow to indirectly specify the join distribution as a product of functions i  Di    each depends only on a limited set of variables Di   Algorithms that compute the posterior distribution conditioned on ev   idence  called inference algorithms  exploit this structure  avoiding a direct computation of the join probabilities          The complexity of such algorithms depends on the topology of the model  and is exponential in the tree width of the underlying graph  The common distinction within graphical models is between undirected graphical models       a subset of log linear models  where there are no restrictions on the functions   and Bayesian networks  BNs       in which every function is a conditional distribution i  Di     P  Xi  i   where i is the set of parent variables of Xi in the model  Another type of probabilistic models that can be represented visually  called factor graphs  extends undirected graphical models and incorporates many of the desired properties of graphical modes       Aside of the independences that are imposed by the models structure  often there exist additional independences stemming from the specific values of the functions  These independences are not systematically exploited by the traditional inference algorithms  resulting in an unnecessary computational cost  For such non structural independences we use the name context specific independence  CSI   which was suggested in previous studies          We note that the term CSI takes here a more general meaning as it is not restricted to any specific type of independence  Several studies have suggested changes in the traditional representation of graphical models in order to capture context specific independences  These include similarity networks suggested by Heckerman              multinets  Geiger   Heckerman            asymmetric influence diagrams  Fung and Shachter            and structured representations of the functions  based on decision trees  Boutilier et al            Poole  Zhang             Other studies resorted to revised representations for specific functions  e g  Quickscore algorithm by Heckerman      for noisy OR functions          Although the new representations proved useful from an empirical view point  they lack the ability to encompass a wide variety of CSI  In addition  the theoretical complexity of inference using these representation remained a function only of the topology of the graph underlying the model  In this paper we approach the problem of inference from a more general perspective  We introduce a set of models called multiplicative models in which the functions  that account for the dependency of variables are in a multiplicative representation  where a value of an instance is a product over a set of parameters  We show that multiplicative models generalize over loglinear models  factor graphs  and graphical models  In addition  we show that multiplicative models can capture multiple forms of CSI  including CSIs captured via decision trees  decision graphs  and via noisy OR functions  This leads to the question whether an inference algorithm that takes advantage of these independences can be constructed without additional cost  We provide such an algorithm  and show how different types of independences are utilized in this procedure to reduce the needed computations  The inference algorithm provided herein simplifies over the inference algorithm suggested by Poole   Zhang             when applied to Bayesian networks  by avoiding the use of tables and tables splitting operations  The more general nature of the algorithm also enables it to deal with different representations  and thus account for CSI that can not be represented by decision trees and decision graphs  We prove the correctness of the inference procedure and give a new notion of complexity instead of the exponent of the tree width which is commonly used to describe the complexity of inference in graphical models  The new time complexity is shown to be less than or equal to the standard complexity      Multiplicative models  We propose a generalization of graphical models  factor graphs and log linear models which represents the dependency of variables in the model via the notion of multiplicative models  In these models a value of an instance in the dependency function is a product over a specific set of parameters  The definition relies on the concept of a lattice  A lattice  L  E      is a partially ordered set  poset  with respect to some relation E  in which for every two elements l    l   L their least upper bound is denoted as l   l  and their greatest lower bound is denoted as l   l    We usually use upper case letters to denote random variables and sets of random variables  and lower case letters to denote their values  For a variable V we  denote its domain  or the set of possible values it can get  by dom V    For a set of variables D    Vi  ni     the notation dom D  corresponds to the cross product of the domains dom Vi    i              n  Let D    Vi  ni   be a set of n multivalued variables  and let the function  D    dom D   R specify the values in a full table for the set D  then the following is a definition for a mapping function of D  Definition    Mapping function  A function f is called a mapping function of D with respect to the lattice L  if it is defined as f   dom Z   L for every Z  D  and maps partial instances Z   z onto L  We use this definition to define a lattice multiplicative model of  D   Definition    Lattice multiplicative model  A model     S      of a function  D  is called a lattice multiplicative model with respect to a lattice  L  E      and a mapping function f   if S  L  Q    s  R   s  S   and  D   d    s   sEf  d  sS  The set S is called the structure of the model  and the set  is called the parameters of the model  In multiplicative models elements s  S for which s     can be removed from S  Here we focus on a lattice L which is a set of propositional clauses over the variables and their values  and call this model a propositional multiplicative model  or simply a multiplicative model  In this model  the operators on the lattice are  and   The mapping function used for this model is called the propositional mapping function  and is defined as follows  Definition    Propositional mapping function  A mapping function f is called a propositional mapping function of D with respect to the lattice L  if for every set Z  D the function mapsVevery partial instance Z   z into the conjunction  Vi   vi    Vi Z  where vi is the projection of z onto the variable Vi   Definition    Propositional multiplicative model  A lattice multiplicative model     S      of a function  D  is called a propositional multiplicative model with respect to a lattice  L         and a propositional mapping function f   if the elements of L are propositional clauses over the variables in D and for two clauses c and c  we denote c   c  if c is implied by c    Example   Consider a set D which contains two ternary variables A and B  The corresponding lattice   contains propositional clauses over A and B  and for the two clauses c    A      and c     A      B      we denote c   c    The corresponding mapping function maps the instance A      B     into the propositional clause  A        B       and the partial instance A     into the clause  A       In this definition  the standard model which uses fulltable representations of the functions  D   such as graphical models  and handles each instance separately  is also a multiplicative model with the set S containing all mapping f  d  of instances D   d  and with values d    d   Another well known model that falls into Definition   is the log linear model       Log linear models  Log linear models are usually used to analyze categorical data  and are a direct generalization of undirected graphical models  These models that have been heavily used for statistical analysis for the past four decades describe the association patterns among a set of categorical variables without specifying any variable as a response  dependent  variable  treating all variables symmetrically      Formally  a log linear model specifies the natural log of the expected frequency of values d for a set of variables D as a linear combination of the main effect Vvii of every variable Vi  D  and if  D      interaction effects Ss of every subset of variables S  D  where the instances s are consistent with d  For example  suppose that we want to investigate relationships between three categorical variables  A  B and C  then the full log linear model is B C AB AC BC ABC ln Fa b c      A a  b  c  ab  ac  bc  abc  where  is the overall mean of the natural log of the expected frequencies  Clearly in the log linear models instances are partially ordered by inclusion of their sets and by consistency of instantiations  To formalize log linear models as a multiplicative models  for every subset Z  D and for Z every instantiation Z   z such that V z       the set S contains all clauses of the form  V   v   where v  els that can potentially reduce the amount of work needed for inference          The notion of ContextSpecific Independence  CSI  was then introduced by Smith et al              and Boutilier et al              Context specific independence corresponds to regularities within probabilistic models based on the values assigned in the model  Formally  we say that the sets of variables X and Y are contextually independent in the context of C   c given Z if     P  X  Y  Z   z  C   c    P  X Z   z  C   c   P  Y  Z   z  C   c  for every value Z   z  One aspect of this equation is that if X and Y are contextually independent given Z  then P  X Y   y    Z   z  C   c    P  X Y   y    Z   z  C   c      for any two values y    y  of Y   which appear as repetitive values in conditional probability tables  such as those used in BNs  These repetition which are the basis of compact representations like decision trees and graphs were exploited for inference in BN          Another kind of CSI which was exploited for enhanced inference in BNs is the independence in noisy OR functions  A noisy OR function is a conditional probability function of a binary effect variable E given a set of m binary cause variables C    C            Cm    The conditional probabilities Q of the function are P  E     C            Cm     c  P  E     Ci    where c  is a i Ci     constant  and the values P  E     Ci   are some real numbers  For any particular CSI of the sets of variables X and Y in the context C   c given the set Z  as in Eq     there exists a multiplicative model that captures this independence  Such a model is any multiplicative model where the structure does not contain elements s that involve variables from X and Y   such that there exists an instance Z   z for which s   Z   z     and s   C   c       We now define two types of multiplicative models that capture two different types of common CSIs   V Z  is the projection of z onto the variable V   In addition  we set the parameters of the model to     e and S f  s    es        Context specific independence  With the introduction of graphical models and in particular Bayesian Networks  BNs   and the proof that inference in these models is NP hard      several studies looked for further independences encoded in mod          Positive models  Representing the dependency of variables using loglinear models has some desirable properties  such as being general while ensuring the existence of a maximum likelihood without enforcing dependencies to be strictly positive  However  in the representation discussed in Section     the log linear models use more parameters than necessary          Take for example the log linear model for two binary variables A and B    Assuming all possible effects exist  the corresponding log linear model uses eight parameters rather than the four parameters in a standard representation as a full A B B AB AB AB AB table  A                                     Another representation of the log linear models that accounts for these redundancies uses only parameters which involve non zero instantiations of variables       In the above example the only parameters used in B AB this representation are  A              We describe this representation of log linear models as a multiplicative model  which we call here the positive model  Definition    Positive model  A positive model  of a function  D  is a multiplicative model wrt to the lattice  L         and a  propositional  mapping function f in which S contains only elements s   f  z  where Z  D and no variable in Z   z is set to zero  Log linear models  and thus positive models  are known to capture conditional and contextual independences       Example   An example is a function  over two binary variables A and B where                                  This implies that A is independent of B and the function can be written as  A  B     A    B   In the corresponding positive model the parameter  A    B                                 Thus  this independence is captured in the model   of  d   v  v     vm vm      vn    where Vj   vj for m   j  n is any possible value of Vj   We note that in a decision tree every instance D   d is mapped to a single path in the tree  An example of a decision tree that encodes a function over the variables A  B  C  D is shown in Figure    One can choose to use decision graphs      instead of decision trees  These are more compact structures that can encode for more distributions  For a function  D  over a set of variables D  a decision graph G that represents  D  is a directed graph with sets of variables from D at internal nodes and values from  D  at the leaves  Similar to decision trees  every edge from a set of variables W to a child Z corresponds to a different set of values H  dom W    and can be represented W as a set of clauses  W   w   A value at the end wH  of a path p equals to the value of  d   where d is an instance of D consistence with the sets of values encoded by p  Again  as in decision trees  we note that in a decision graph every instance D   d is mapped to a single path in the graph  Definition    Decision graph model  A decision graph model  of a function  D  is a multiplicative model wrt to the lattice  L         and a mapping function f where everyWtwo elements s    s   S satisfy s   s      and s      where    f alse and sS      true  Example   In a more complex function with three binary variables A  B and C  every pair of variables is independent whenever the third variable is set to zero  For this function the corresponding positive model assigns  V     U         for every pair of variables V  U   A  B  C  and where V    U          Decision trees and graphs as multiplicative models  Common structures for representing functions with contextual independence are decision trees  DTs  and decision graphs  DGs            These structures capture contextual independences that are the result of repetitive values  as specified in Eq     Several studies have used decision trees to enhance inference in graphical models          We show how DTs and DGs fall into the category of multiplicative models  For a function  D  over a set of variables D  a decision tree T that represents  D  is a tree with variables from D at internal nodes and values from  D  at the leaves  Every edge from a variable V to a child in T corresponds to a different set of values H W  dom V    and can be represented as a set of clauses  V   v   vH  A value at the end of a path p   v   v       vm   where vi is some value of Vi   equals to the value  For a specific decision graph G that represents  D   the decision graph model of G is  G  in which the structure contains one clause for every path from the root to a leaf in G  which is a conjunction of the clauses on the edges  For every such path s  we set s to the value at the end of the path  We note that in this model for every instance D   d there is only one element s  S such that s   f  d       Inference for multiplicative models  Consider a model that Q encodes for the probability distribution P  x    i i  di    with sets Di    Xi          Ximi    and multiplicative models i    Si   i   over all the functions i  Di   wrt a lattice  L          We first show how to perform inference  and compute a probability of a set of query variables Q using a multiplicative model  In particular we perform inference for a multiplicative model via the variable elimination scheme  Zhang   Poole            Dechter           which was originally suggested for inference in BNs  Then  we prove the correctness of the algorithm and analyze its time complexity  We define an operation M  V   i     which given a variable V  X and a set of models  i    i              m over X returns a model   over the variables X   V   This   A                                  B                                  C                                  D                                   A  B  C  D                                                                        Figure     left  A full table over the binary variables A  B  C  D that specifies the value of the function  for each instance   right  A decision tree corresponding to the function  on left  Under every node in the tree appears the corresponding proposition in the decision tree representation  and below the corresponding proposition in a positive representation of the propositions in the decision tree  Algorithm    VE for multiplicative models Input  A model with n variables Xi  i              n  and m functions i  Di  X   that encodes for the distribution P  X   A set of multiplicative models i    Si   i   wrt a mapping function f   where i model i  Di    and a set of k query variables Q    Xi   i  k  Output  The distribution P  Q    operator is analogous to marginalization in standard inference algorithms  In addition  for a model  we define a relevance indicator Is  V   for each element s  S and each variable V in D  which is set to   if there exists a pair of instances d    d  of D that differ only by the value of V and for which s   f  d    but s   f  d     Otherwise  Is  V   is set to    These operations allow us to write an inference procedure which computes the probability of a set of query variables in a multiplicative model as in Algorithm    The algorithm operates like the bucket elimination algorithm      where given an order on the variables we iterate over them  Line     and marginalize out one variable at a time  Line     Only elements that include terms that involve the current variable are considered in the marginalization                  Note that for graphical models  in which the elements   of Si are a mapping of instances of the functions Di     this algorithm is exactly the known variable elimi     nation algorithm  in its implementation as bucket     elimination      where the sets Si  j  are the tables in the bucket of the variable Xj       t   m      for j   k     to n do for i     to t    do Si  j    s   s  Si   Is  Xj         i  j    s   s  Si  j   s  i    Si  Si   Si  j   i  i   i  j   end for   St   t    M  V   Si  j   i  j     t   t      end for      Q P  Q   P  q    si   Q   q  si  Si   si  f  q   A general algorithm for computing M  V   i    is given    return P  Q   as Algorithm    We use there the notation s  V W for an element s  S and a variable V to denote s  V   Figure    Algorithm for variable elimination with a mulV  v tiplicative model v   This operation removes all terms that specify a value for V   For example  if s    V        U      then s  V    U       of R is chosen  and selects those elements r with paThe algorithm has two main parts  upto Line   the alrameters r       gorithm generates the set R of possible new elements To compute the possible new elements  Lines   and   in the model  From Line   it computes the new paramfirst create a closure under the operator  of each eters r   where at each iteration a minimal element structure Si   Then  in Line   all conjunctions of terms   Algorithm    M  V   i    Input  A variable V and a set of representations i    Si   i    i              t  wrt a lattice  L          where Isi  V       for every i and si  Si   Output  A representation      S                     S        for i     to t do V   Ri     s   Si   Si        s  Si      end for  V R  ri   ri  Ri          Assume that after removing the set of variable U we are left with the set X     X   U   and now wish to eliminate a variable V  X     We write the probability of an instance x v of X     V which is the projection of an instance X     x  onto X     V via the parameters   P  x v      X  P  x       XY  Y  i s  V  v i s f  x    sSi  V  v  We can decompose the product into terms that involve theQ variable V Q and those which do not  Denoting  x v     i s   we get i s f  x    sSi  Is  V       it  P  x v      x v     while R     do  XY  Y  i s         V  v i s f  x    sSi  Is  V            r is a minimal element in R       r   R    r    R s t  r    r     r  MP in R     rQ Q s  r    V  v i s  r V  v   sSi                       Q r   S    r    r  r       R  R    r   if r      then S    S     r          r    end while  return  S          Figure     Now  lets examine what the algorithm encodes for after removing variable V   and show that it equals Eq     While the elements that do not involve variable V are not changed  the elements that do involve V are removed and the elements st  St are added  Therefore  after applying Algorithm   for V the remaining sets encode for P  x v      x v     x v   where Q  x v     st   To express  x v   in the st  f  x    st St  terms of Algorithm    recall that St  R and if an element s  R and s    St then s      Thus  we can rewrite  x v   using elements of R as  Algorithm for computing the operation  M  V   i       x v      Y  r    r f  x    rR  from the different closures consist of the set of possible new elements  In analogy to inference in graphical models  this operation is equivalent to the operation of tables multiplication  often denoted as   In these models the set R is the set of instances in the table after marginalization  We note that for some models  like graphical models  lines     are trivial  and are executed implicitly  since the elements in R are known S to be all instances of a full table over variables in Si        Correctness of the inference procedure  We prove the correctness of Algorithm   by showing that the algorithm maintains the property that after iterating over the set of variables U   the models i    Si   i   encode to the probability distribution P  X   U    At the beginning of the algorithm every model i represents the corresponding function i  Di    Thus  P  X   x     Y i  i  Di   di      Y  Y  i s f  di   sSi  i s    From lines     in Algorithm    there is one element r   f  x    in R for which r  R such that r   f  x    also satisfies r   r   First  to show there is such an element r we recall from Line V   that all elements in R can be written as r   ri   where ri  Ri   and  it  Ri is the closure of Si under the operator   Consider the set of elements ri   f  x     i              t  for which   all other elements ri  Ri such that rV i   f  x   satisfy  ri   ri   Then  every element r   ri such that  it  r   f  x    also satisfies r   r   Now  assume by contradiction that there were two such elements  r    r   R  Then from the definition of r  and r  we get r    r  and r    r    yielding r    r    Thus  from line   in Algorithm   Y XY Y  x v     r  r   s r r   rR  V  v i s  r   V  v   sSi  where the last equality is due to the fact that Q the denominator in the computation of r is r   In r r   rR  the terms of Algorithm   the set  s   s    r   V     v    s  Si   can be rewritten as  s   s   f  x     s  Si   Is  V         Thus  we can write Y Y s  x v     i s f  x    sSi  Is  V      and from Eq    we get P  x v     P  x v    Namely  the new models encode for P  X     V         Incorporating evidence  In many practical scenarios we observe the value of some of the variables in the model  and wish to incorporate this evidence  The multiplicative models allow us to do so in a most natural way  Consider a set E of evidence nodes for which we observed the values E   e  and a multiplicative model     S       Then  in order to incorporate the evidence into   we adjust V  V   v   where v is the the elements in S by s   s V E  projection of e onto the variable V  E  Then  we remove every element not consistent with the evidence  s          Complexity of inference  It is well known that the complexity of inference in graphical models is NP hard and its cost exponential in the tree width of the underlying graph      We analyze the time complexity of the inference procedure for multiplicative models given in Algorithm    As a by product we refine the standard complexity and provide a new complexity bound which is based on the representation used  One can then say that the complexity of the problem is the minimum complexity among all possible representations         Diameter of multiplicative models  The structure of a multiplicative model determines the amount of computations needed to obtain the value  d  of a single instantiation of values to variables in a set D  Although at first glance it seems that for a model     S    of a function  D  the number of operations needed to obtain Pvalues of all instances D   d amounts to a total of   s   s   d    the real D d  number of operations can be dramatically lower and we denote it by     For hierarchical models  in which if an element s is not in the structure of the model then all elements s   s  are also not in the model  Good        provides a method that computes all such values in time  S  log  S        We denote the ratio between the number of computations and the number of elements in S  which is the size of the model  by diam         S  and name it the diameter of   From a computational perspective  it is clearly beneficial to use models with a small diameter  as this  directly leads to fewer operations whenever we want to either obtain a value of  or update the values s   Examples of models with a diameter of   are graphical models and decision graph models  in which for every element s  S  the only element s  such that s    s  is s itself  On the other hand  the diameter of a positive model can be as high as log  S    This maximum is achieved for a positive model of m binary variables  when all  m parameters do not equal one  and hence all possible elements are in S  In this scenario the diameter is exactly m    Although in the worst scenario the diameter of a positive model can be large  often this is not the case  and the diameter is typically bounded to be very small  Example   Consider as an example the Potts model      in which a function  D  over a set DQ    Vi  ni   decomposes according to  D   d    c   vi   vj    where vi and vj are projections of d i j  onto the variables Vi and Vj respectively  and c  is a constant  Although in general a positive model over n binary variables has a diameter of n    in this example  the structure of the positive model includes only elements that involve at most two variables  Therefore  the diameter of the model is bounded by two  Similarly  in a more complex scenario where the function  decomposes to functions of k tuples of variables  the diameter will be bounded by k  Consider a tree decomposition of the graph in which there is an edge between a pair of variables V  U if there exists an element s in one of the models for which Is  V    Is  U        We denote by S W      s   X   Z    s  Si   the set of parts of elements in the models i that involve variables from the set of graph vertices Z which is mapped onto the tree node W   Further denoting as S   W   the closure of S W   under the operator   we say that complexity of the algorithm for this tree decomposition is the maximum over the nodes W in the tree of  S   W     diam S   W     as described in Section        Then  the overall complexity of the algorithm is the complexity for the tree decomposition that yields the minimum for this term  To see that this is indeed the time complexity of the algorithm  consider the elements in a set R in Algorithm    The number of elements there does not exceed the number of elements in S   W   for the corresponding tree decomposition and where W maps onto the variables that appear in R  Most of the computation stems from computing the products in Line    and these can be done for the entire set of elements of R in time proportional to  R   diam R   Therefore  having the ability to choose an elimination order  the complexity of the algorithm is  S   W   diam S   W      maximized over all nodes W in a tree decomposition and minimized over all possible such decompositions       Benefits of inference for multiplicative models  Different multiplicative models capture different contextual independences  hence specifying different number of parameters  Take for example the function over four binary variables A  B  C  D with values according to the table in Figure    The structure of the corresponding decision tree model contains six elements while the structure of the corresponding positive model contains eight elements  In this latter model  the CSI captured in the decision tree  yielding the value of  to be independent of B given that A  C and D are set to one  does not have any effect  This variation and the structure of the model affect the run time of the inference algorithm       C  Boutilier and et al  Context specific independence in Bayesian networks  In Uncertainty in Artificial Intelligence  pages                   R  Christensen  Log Linear Models and Logistic Regression  Springer            G  Cooper  The computational complexity of probabilistic inference using bayesian belief networks  Artificial Intelligence                       R  Dechter  Bucket elimination  A unifying framework for reasoning  Artificial Intelligence                       R  Fisher  Statistical Methods for Research Workers  Macmillan Pub Co            R  Fisher  Statistical Methods and Scientific Inference  Oliver and Boyd            R  Fung and R  Shachter  Contingent influence diagrams  Working Paper  Dept  of EngineeringEconomic Systems  Stanford University            D  Geiger and D  Heckerman  Knowledge representation and inference in similarity networks and bayesian multinets  Artificial Intelligence                      I  Good  Maximum entropy for hypothesis formulation  especially for multidimensional contingency taAn example where there are substantial computational bles  The Annals of Math  Stat                    savings when using the inference algorithm proposed      D  Heckerman  A tractable inference algorithm for can be found in a model such as the QMR DT netdiagnosing multiple diseases  UAI                    work       which is comprised of noisy OR functions       D  Heckerman  Probabilistic Similarity Networks  mentioned in Section      The QMR DT network is MIT Press        a two level or bipartite BN where all variables are bi     D  Knoke and P  Burke  Log Linear Models  Sage nary  The top level of the graph contains nodes for Publications Inc             F  R  Kschischang  B  Frey  and H  Loeliger  Factor the diseases C  and the bottom level contains nodes graphs and the sum product algorithm  IEEE Trans  for the findings E  The conditional probabilities in Inform  Theory                      the network P  Ei   ei  i    where i are the parents      S  Lauritzen  Graphical Models  Oxford University of finding Ei in the network  are represented by noisyPress        OR functions       J  Lindsey  Conditional independence and log linear models for multi dimensional contingency tables  Heckerman        has developed an algorithm  called Quality and Quantity                     Quickscore  which takes advantage of the indepen     B  Middleton and et al  Probabilistic diagnosis using a dence of the cause variables in the context of a negative reformulation of the INTERNIST   QMR knowledge finding Ei     and uses it to speed up inference in the base  Part II  Evaluation of diagnostic performance  SIAM Journal on Computing                   QMR DT network            J  J  Oliver  Decision graphs   an extension of decision For every noisy OR function P  E C            Cm   a structrees  Proceedings of the Fourth International Workture of a multiplicative model that captures the inshop on Artificial Intelligence and Statistics  pages               dependence does not contain elements s such that      J  Pearl  Probabilistic Reasoning in Intelligent Syss   E          for which Is  Ci       and Is  Cj        tems  Networks of Plausible Inference  Morgan Kauffor all i  j  m  mann             D  Poole and N  Zhang  Exploiting contextual indeIn addition  running Algorithm   using multiplicative pendence in probabilistic inference  JAIR             models with structures         Si     Ei       Ci   ci     Ci   ci        R  Potts  Some generalized order disorder transforCi i mations  Proceedings of the Cambridge Philosophical   Society                     Ei      Ci        Ci  i    Ei       Ci            S  Safavian and D  Landgrebe  A survey of decision Ci i tree classifier methodology  IEEE transactions on systems  man  and cybernetics                      is identical to the Quickscore algorithm and gains the      J  Smith  S  Holtzman  and J  Matheson  Structuring same savings automatically  conditional relationships in influence diagrams  Oper  Res                       
  Recently several researchers have investigated techniques for using data to learn Bayesian networks containing compact representations for the conditional probability distributions  CPDs  stored at each node  The majority of this work has concentrated on using decision tree representations for the CPDs  In addition  researchers typically apply non Bayesian  or asymptotically Bayesian  scoring functions such as MDL to evaluate the goodness of fit of networks to the data  In this paper we investigate a Bayesian approach to learning Bayesian networks that contain the more general decision graph representations of the CPDs  First  we describe how to evaluate the posterior probability that is  the Bayesian scoreof such a network  given a database of observed cases  Second  we describe various search spaces that can be used  in conjunction with a scoring function and a search procedure  to identify one or more high scoring networks  Finally  we present an experimental evaluation of the search spaces  using a greedy algorithm and a Bayesian scoring function      INTRODUCTION  Given a set of observations in some domain  a common problem that a data analyst faces is to build one or more models of the process that generated the data  In the last few years  researchers in the UAI community have contributed an enormous body of work to this problem  using Bayesian networks as the model of choice  Recent works include Cooper and Herskovits          Buntine         Spiegelhalter et  al         and Heckerman et al          A substantial amount of the early work on learning Bayesian networks has used observed data to infer global independence constraints that hold in the domain of interest  Global independences are precisely those that follow from the missing edges within a Bayesian network structure  More recently  researchers  including Boutilier et al        and Friedman and Goldszmidt        have extended the classical definition of a Bayesian network to include efficient representations of local constraints that can hold among the parameters stored in the nodes of the network  Two notable features about the this recent work are     the majority of effort has concentrated on inferring decision trees  which are structures that can explicitly represent some parameter equality constraints and     researchers typically apply non Bayesian  or asymptotically Bayesian  scoring functions such as MDL as to evaluate the goodness of fit of networks to the data  In this paper  we apply a Bayesian approach to learning Bayesian networks that contain decision graphs generalizations of decision trees that can encode arbitrary equality constraintsto represent the conditional probability distributions in the nodes  In Section    we introduce notation and previous relevant work  In Section   we describe how to evaluate the Bayesian score of a Bayesian network that contains decision graphs  In Section    we investigate how a search algorithm can be used  in conjunction with a scoring function  to identify these networks from data  In Section    we use data from various domains to evaluate the learning accuracy of a greedy search algorithm applied the search spaces defined in Section    Finally  in Section    we conclude with a discussion of future extensions to this work       BACKGROUND  In this section  we describe our notation and discuss previous relevant work  Throughout the remainder of this paper  we use lower case letters to refer to variables  and upper case letters to refer to sets of variables  We write xi   k when we observe that variable xi is in state k  When we observe the state of every variable in a set X  we call the set of observations a state of X  Although arguably an abuse of notation  we find it convenient to index the states of a set of variables with a single integer  For example  if X    x    x    is a set containing two binary variables  we may write X     to denote  x       x        In Section      we define a Bayesian network  In Section     we describe decision trees and how they can be used to represent the probabilities within a Bayesian network  In Section      we describe decision graphs  which are generalizations of decision trees       BAYESIAN NETWORKS  Consider a domain U of n discrete variables x            xn   where each xi has a finite number of states  A Bayesian network for U represents a joint probability distribution over U by encoding     assertions of conditional independence and     a collection of probability distributions  Specifically  a Bayesian network B is the pair  BS      where BS is the structure of the network  and  is a set of parameters that encode local probability distributions  The structure BS has two components  the global structure G and a set of local structures M   G is an acyclic  directed graphdag for shortthat contains a node for each variable xi  U   The edges in G denote probabilistic dependences among the variables in U   We use P ar xi   to denote the set of parent nodes of xi in G  We use xi to refer to both the variable in U and the corresponding node in G  The set of local structures M    M            Mn   is a set of n mappings  one for each variable xi   such that Mi maps each value of  xi   P ar xi    to a parameter in   The assertions of conditional independence implied by the global structure G in a Bayesian network B impose the following decomposition of the joint probability distribution over U   Y p xi  P ar xi      Mi   G      p U  B    i  The set of parameters  containsfor each node xi   for each state k of xi   and for each parent state j a single parameter   i  j  k  that encodes the condiP   Because the sum  k  p xi   k P ar xi      Mi   G  must  x  y z  Figure    Bayesian network for U    x  y  z  tional probabilities given in Equation    That is  p xi   k P ar xi     j    Mi   G     i  j  k        Note that the function  i  j  k  depends on both Mi and G  For notational simplicity we leave this dependency implicit  Let ri denote the number of states of variable xi   and let qi denote the number of states of the set P ar xi    We use ij to denote the set of parameters characterizing the distribution p xi  P ar xi     j    Mi   G   i ij   rk    i  j  k   We use i to denote the set of parameters characterizing all of the conditional distributions p xi  P ar xi      Mi   G   i ij i   qj    In the classical implementation of a Bayesian network  each node xi stores  ri      qi distinct parameters in a large table  That is  Mi is simply a lookup into a table  Note that the size of this table grows exponentially with the number of parents qi        DECISION TREES  There are often equality constraints that hold among the parameters in i   and researchers have used mappings other than complete tables to more efficiently represent these parameters  For example  consider the global structure G depicted in Figure    and assume that all nodes are binary  Furthermore  assume that if x      then the value of z does not depend on y  That is  p z x      y        Mz   G    p z x      y        Mz   G   Using the decision tree shown in Figure   to implement the mapping Mz   we can represent p z x      y    MZ   using a single distribution for both p z x      y        Mz   G  and p z x      y        Mz   G   be one   will actually only contain ri    distinct parameters for this distribution  For simplicity  we leave this implicit for the remainder of the paper    ditional distributions  Furthermore  many researchers have developed methods for learning these local structures from data   x       y   p z x    y        p z x    y      p z x    y     p z x    y     Figure    Decision tree for node z  Decision trees  described in detail by Breiman         can be used to represent sets of parameters in a Bayesian network  Each tree is a dag containing exactly one root node  and every node other than the root node has exactly one parent  Each leaf node contains a table of k    distinct parameters that collectively define a conditional probability distribution p xi  P ar xi      Mi   D   Each non leaf node in the tree is annotated with the name of one of the parent variables   P ar xi    Out going edges from a node  in the tree are annotated with mutually exclusive and collectively exhaustive sets of values for the variable   When a node v in a decision tree is annotated with the name   we say that v splits   If the edge from v  to child v  is annotated with the value k  we say that v  is the child of v  corresponding to k  Note that by definition of the edge annotations  the child of a node corresponding to any value is unique  We traverse the decision tree to find the parameter  i  j  k  as follows  First  initialize v to be the root node in the decision tree  Then  as long as v is not a leaf  let  be the node in P ar xi   that v splits  and reset v to be the child of v corresponding to the value of determined by P ar xi     jand repeat  If v is a leaf  we we return the parameter in the table corresponding to state k of xi   Decision tree are more expressive mappings than complete tables  as we can represent all of the parameters from a complete table using a complete decision tree  A complete decision tree Ti for a node xi is a tree of depth  P ar xi     such that every node vl at level l in Ti splits on the lth parent l  P ar xi   and has exactly rl children  one for each value of   It follows by this definition that if Ti is a complete tree  then  i  j  k  will map to a distinct parameter for each distinct  i  j   which is precisely the behavior of a complete table  Researchers have found that decision trees are useful for eliciting probability distributions  as experts often have extensive knowledge about equality of con        DECISION GRAPHS  In this section we describe a generalization of the decision tree  known as a decision graph  that can represent a much richer set of equality constraints among the local parameters  A decision graph is identical to a decision tree except that  in a decision graph  the nonroot nodes can have more than one parent  Consider  for example  the decision graph depicted in Figure    This decision graph represents a conditional probability distribution p z x  y    for the node z in Figure   that has different equality constraints than the tree shown in Figure    Specifically  the decision graph encodes the equality p z x      y          p z x      y         x       y    p z x    y     y       p z x    y      p z x    y       p z x    y     Figure    Decision graph for node z We use Di to denote a decision graph for node xi   If the mapping in a node xi is implemented with Di   we use Di instead of Mi to denote the mapping  A decision graph Di can explicitly represent an arbitrary set of equality constraints of the form ij   ij         for j    j     To demonstrate this  consider a complete tree Ti for node xi   We can transform Ti into a decision graph that represents all of the desired constraints by simply merging together any leaf nodes that contain sets that are equal  It is interesting to note that any equality constraint of the form given in Equation   can also be interpreted as the following independence constraint  xi  P ar xi     P ar xi     j or P ar xi     j   If we allow nodes in a decision graph Di to split on node xi as well as the nodes in P ar xi    we can represent an arbitrary set of equality constraints among   the parameters i   We return to this issue in Section    and assume for now that nodes in Di do not split on xi       LEARNING DECISION GRAPHS  As we showed in Section    if the local structure for a node xi is a decision graph Di   then sets of parameters ij and ij   can be identical for j    j     For the derivations to follow  we find it useful to enumerate the distinct parameter sets in i   Equivalently  we find it useful to enumerate the leaves in a decision graph   Many researchers have derived the Bayesian measureof fitherein called the Bayesian scorefor a network  assuming that there are no equalities among the parameters  Friedman and Goldszmidt        derive the Bayesian score for a structure containing decision trees  In this section  we show how to evaluate the Bayesian score for a structure containing decision graphs   For the remainder of this section  we adopt the following syntactic convention  When referring to a parameter set stored in the leaf of a decision graph  we use a to denote the node index  and b to denote the parent state index  When referring to a parameter set in the context of a specific parent state of a node  we use i to denote the node index and j to denote the parent state index   To derive the Bayesian score  we first need to make an assumption about the process that generated the database D  In particular  we assume that the database D is a random  exchangeable  sample from some unknown distribution U   and that all of the constraints in U can be represented using a network structure BS containing decision graphs   To enumerate the set of leaves in a decision graph D a   we define a set of leaf set indices La   The idea is that La contains exactly one parent state index for each leaf in the graph  More precisely  let l denote the number of leaves in Da   Then La    b            bl   is defined as a set with the following properties   As we saw in the previous section  the structure BS    G  M   imposes a set of independence constraints that must hold in any distribution represented using a Bayesian network with that structure  We define BSh to be the hypothesis that     the independence constraints imposed by structure BS hold in the joint distribution U from which the database D was generated  and     U contains no other independence constraints  We refer the reader to Heckerman et al         for a more detailed discussion of structure hypotheses  The Bayesian score for a structure BS is the posterior probability of BSh   given the observed database D  p BSh  D    c  p D BSh  p BSh       If we are only concerned with the relwhere c   p D  ative scores of various structures  as is almost always the case  then the constant c can be ignored  Consequently  we extend our definition of the Bayesian score to be any function proportional to p D BSh  p BSh     For now  we assume that there is an efficient method for assessing p BSh    assuming this distribution is uniform  for example   and concentrate on how to derive the marginal likelihood term p D BSh    By integrating over all of the unknown parameters  we have  Z h p  BSh  p D   BSh       p D BS       Researchers typically make a number of simplifying assumptions that collectively allow Equation   to be expressed in closed form  Before introducing these assumptions  we need the following notation      For all  b  b     La   b    b   a b    a b     bLa a b   a The first property ensures that each index in L corresponds to a different leaf  and the second property ensures that every leaf is included  One assumption used to derive Equation   in closed form is the parameter independence assumption  Simply stated  this assumption says that given the hypothesis BSh   knowledge about any distinct parameter set ab does not give us any information about any other distinct parameter set  Assumption    Parameter Independence  p  BSh      n Y Y  p ab  BSh    a   bLa  Another assumption that researchers make is the Dirichlet assumption  This assumption restricts the prior distributions over the distinct parameter sets to be Dirichlet  Assumption    Dirichlet  For all a and for all b  La   p ab  BSh     ra Y  abc    abc  c    where abc     for    c  ra Recall that ra denotes the number of states for node xa   The hyperparameters abc characterize our prior   knowledge about the parameters in   Heckerman et al         describe how to derive these exponents from a prior Bayesian network  We return to this issue later  Using these assumptions  we can derive the Bayesian score for a structure that contains decision graphs by following a completely analogous method as Heckerman et al          Before showing the result  we must define the inverse function of  i  j  k   Let  denote an arbitrary parameter in   The function      denotes the set of index triples that    maps into   That is          i  j  k  i  j  k      Let Dijk denote the number of cases in D for which xi   k and P ar xi     j  We define Nabc as follows  X Dijk Nabc   ijk   abc    Intuitively  Nabc is the number of cases in D that provide information about thePparameter abc   Letting P Nab   c Nabc and ab   c abc   we can write the Bayesian score as follows  p D  BSh      p BSh    n Y Y  a   bLa   ab    Nab   ab    Y  Nabc   abc    abc   c    ra           We can determine all of the counts Nabc for each node xa as follows  First  initialize all the counts Nabc to zero  Then  for each case C in the database  let kC and jC denote the value for xi and P ar xi   in the case  respectively  and increment by one the count Nabc corresponding to the parameter abc   p xi   kC  P ar xi     jC     Da    Each such parameter can be found efficiently by traversing Da from the root  We say a scoring function is node decomposable if it can be factored into a product of functions that depend only a node and its parents  Node decomposability is useful for efficiently searching through the space of global network structures  Note that Equation   is node decomposable as long as p BSh   is node decomposable  We now consider some node decomposable distributions for p BSh    Perhaps the simplest distribution is to assume a uniform prior over network structures  That is  we set p BSh   to a constant in Equation    We use this simple prior for the experiments described in Section    Another approach is to  a priori  favor networks with fewer parameters  For example  we can use n Y p BSh          a       a    where            Note that      corresponds to the uniform prior over all structure hypotheses  A simple prior for the parameters in  is to assume abc     for all a  b  c  This choice of values corresponds to a uniform prior over the parameters  and was explored by Cooper and Herskovits        in the context of Bayesian networks containing complete tables  We call the Bayesian scoring function the uniform scoring function if all the hyperparameters are set to one  We have found that this prior works well in practice and is easy to implement  Using two additional assumptions  Heckerman et al         show that each abc can be derived from a prior Bayesian network  The idea is that abc is proportional to the prior probability  obtained from the prior network  of all states of  xi   k  P ar xi     j  that map to the parameter abc   Specifically  if B P is our prior Bayesian network  we set X abc    p xi   k  P ar xi     j B P   ijk   abc    where  is a single equivalent sample size used to asses all of the exponents  and P ar xi   denotes the parents of xi in G  as opposed to the parents in the prior network    can be understood as a measure of confidence that we have for the parameters in B P   We call the Bayesian scoring function the PN scoring function  P rior N etwork scoring function  if the exponents are assessed this way  Heckerman et al         derive these constraints in the context of Bayesian networks with complete tables  In the full version of this paper  we show that these constraints follow when using decision graphs as well  with only slight modifications to the additional assumptions  Although we do not provide the details here  we can use the decision graph structure to efficiently compute the exponents abc from the prior network in much the same way we computed the Nabc values from the database      SEARCH  Given a scoring function that evaluates the merit of a Bayesian network structure BS   learning Bayesian networks from data reduces to a search for one or more structures that have a high score  Chickering        shows that finding the optimal structure containing complete tables for the mappings M is NP hard when using a Bayesian scoring function  Given this result  it seems reasonable to assume that by allowing  the more general  decision graph mappings  the problem remains hard  and consequently it is appropriate to apply heuristic search techniques    In Section      we define a search space over decisiongraph structures within a single node xi   assuming that the parent set P ar xi   is fixed  Once such a space is defined  we can apply to that space any number of well known search algorithms  For the experiments described in Section    for example  we apply greedy search     v      There are three operators we define  and each operator is a modification to the current set of leaves in a decision graph  Definition  Complete Split  Let v be a leaf node in the decision graph  and let   P ar xi   be a parent of xi   A complete split C v    adds ri new leaf nodes as children to v  where each child of v corresponds to a distinct value of   Definition  Binary Split  Let v be a leaf node in the decision graph  and let   P ar xi   be a parent of xi   A binary split B v    k  adds   new leaf nodes as children to v  where the first child corresponds to state k of   and the other child corresponds to all other states of   Definition  Merge  Let v  and v  be two distinct leaf nodes in the decision graph  A Merge M  v    v    merges the v  and v  into a single node  That is  the resulting node inherits all parents from both v  and v    In Figure    we show the result of each type of operator to a decision graph for a node z with parents x and y  where x and y both have three states  We add the pre condition that the operator must change the parameter constraints implied by the decision graph  We would not allow  for example  a complete split C v    y  in Figure  a  two of v  s new children would correspond to impossible states of y   y     and y      and  y     and y        and the third child would correspond to the original constraints at v    y     and y        Note that starting from a decision graph containing a  y      DECISION GRAPH SEARCH  In this section  we assume that the states of our search space correspond to all of the possible decision graphs for some node xi   In order for a search algorithm to traverse this space  we must define a set of operators that transform one state into another      v   v    a   In Section     we describe a greedy algorithm that combines local structure search over all the decision graphs in the nodes with a global structure search over the edges in G       y     b        x    y    y       x        c              d   Figure    Example of the application of each type of operator   a  the original decision graph   b  the result of applying C v    x    c  the result of applying B v    x      and  d  the result of applying M  v    v    single node  both the root and a leaf node   we can generate a complete decision tree by repeatedly applying complete splits  As discussed in the previous section  we can represent any parameter set equalities by merging the leaves of a complete decision tree  Consequently  starting from a graph containing one node there exists a series of operators that result in any set of possible parameter set equalities  Note also that if we repeatedly merge the leaves of a decision graph until there is a single parameter set  the resulting graph is equivalent  in terms of parameter equalities  to the graph containing a single node  Therefore  our operators are sufficient for moving from any set of parameter constraints to any other set of parameter constraints  Although we do not discuss them here  there are methods that can simplify  in terms of the number of nodes  some decision graphs such that they represent the same set of parameter constraints  The complete split operator is actually not needed to ensure that all parameter equalities can be reached  any complete split can be replaced by a series of binary splits such that the resulting parameter set constraints are identical  We included the complete split operator in the hopes that it would help lead the search algorithm to better structures  In Section    we compare greedy search performance in various search spaces defined by including only subsets of the above operators       COMBINING GLOBAL AND LOCAL SEARCH  In this section we describe a greedy algorithm that combines global structure search over the edges in G   with local structure search over the decision graphs in all of the nodes of G  Suppose that in the decision graph Di for node xi   there is no non leaf node annotated with some parent   P ar xi    In this case  xi is independent of  given its other parents  and we can remove  from P ar xi   without violating the decomposition given in Equation    Thus given a fixed structure  we can learn all the local decision graphs for all of the nodes  and then delete those parents that are independent  We can also consider adding edges as follows  For each node xi   add to P ar xi   all non descendants of xi in G  learn a decision graph for xi   and then delete all parents that are not contained in the decision graph  Figure   shows a greedy algorithm that uses combines these two ideas  In our experiments  we started the algorithm with a structure for which G contains no edges  and each graph Di consists of a single root node      Score the current network structure BS      For each node xi in G            Add every non descendant that is not a parent of xi to P ar xi   For every possible operator O to the decision graph Di Apply O to BS      Score the resulting structure      Unapply O                              Remove any parent that was added to xi in step   If the best score from step   is better than the current score Let O be the operator that resulted in the best score If O is a split operator  either complete or binary  on a node xj that is not in P ar xi    then add xj to P ar xi   Apply O to BS Goto   Otherwise  return BS  Figure    Greedy algorithm that combines local and global structure search Note that as a result of a merge operator in a decision graph D i   xi may be rendered independent from one of its parents   P ar xi    even if D i contains a node annotated with   For a simple example  we could repeatedly merge all leaves into a single leaf node  and the resulting graph implies that xi does not depend on any of its parents  We found experimentally thatwhen using the algorithm from Figure  this phenomenon is rare  Because testing for these parent deletions is expensive  we chose to not check for them  in the experiments described in Section    Another greedy approach for learning structures containing decision trees has been explored by Friedman and Goldszmidt         The idea is to score edge operations in G  adding  deleting  or reversing edges  by applying the operation and then greedily learning the local decision trees for any nodes whos parents have changed as a result of the operation  In the full version of the paper  we compare our approach to theirs      EXPERIMENTAL RESULTS  In this section we investigate how varying the set of allowed operators affects the performance of greedy search  By disallowing the merge operator  the search algorithms will identify decision tree local structures in the Bayesian network  Consequently  we can see how learning accuracy changes  in the context of greedy search  when we generalize the local structures from decision trees to decision graphs  In all of the experiments described in this section  we measure learning accuracy by the posterior probability of the identified structure hypotheses  Researchers often use other criteria  such as predictive accuracy on a holdout set or structural difference from some generative model  The reason that we do not use any of these criteria is that we are evaluating how well the search algorithm performs in various search spaces  and the goal of the search algorithm is to maximize the scoring function  We are not evaluating how well the Bayesian scoring functions approximate some other criteria  In our first experiment  we consider the Promoter Gene Sequences database from the UC Irvine collection  consisting of     cases  There are    variables in this domain     of these variables   x            x     represent the base pair values in a DNA sequence  and each has four possible values  The other variable  promoter  is binary and indicates whether or not the sequence has promoter activity  The goal of learning in this domain is to build an accurate model of the distribution p promoter x            x      and consequently it is reasonable to consider a static graphical structure for which P ar promoter     x            x      and search for a decision graph in node promoter  Table   shows the relative Bayesian scores for the best decision graph learned  using a greedy search with various parameter priors and search spaces  All searches started with a decision graph containing a single node  and the current best operator was applied at each step until no operator increased the score of the current state  Each column corresponds to a different restriction of the search space described in Section      the labels indicate what operators the greedy search was   Table    Greedy search performance for various Bayesian scoring functions  using different sets of operators  in the P romoter domain   uniform U PN    U PN    U PN    U PN    U PN     C              B                                 CB                                CM                                   BM                                      CBM                                      allowed to use  where C denotes complete splits  B denotes binary splits  and M denotes merges  The column labeled BM  for example  shows the results when a greedy search used binary splits and merges  but not complete splits  Each row corresponds to a different parameter prior for the Bayesian scoring function  The U PN scoring function is a special case of the PN scoring function for which the prior network imposes a uniform distribution over all variables  The number following the U PN in the row labels indicates the equivalent sample size   All results use a uniform prior over structure hypotheses  A value of zero in a row of the table denotes the hypothesis with lowest probability out of all those identified using the given parameter prior  All other values denote the natural logarithm of how many times more likely the identified hypothesis is than the one with lowest probability  By comparing the relative values between searches that use merges and searches that dont use merges  we see that without exception  adding the merge operator results in a significantly more probable structure hypothesis  We can therefore conclude that a greedy search over decision graphs results in better solutions than a greedy search over decision trees  An interesting observation is that complete split operator actually reduces solution quality when we restrict the search to decision trees  We performed an identical experiment to another classification problem  but for simplicity we only present the results for the uniform scoring function  Recall from Section   that the uniform scoring function has all of the hyperparameters abc set to one  This second experiment was run with the Splice junction Gene Sequences database  again from the UC Irvine repository  This database also contains a DNA sequence  and the problem is to predict whether the position in the middle of the sequence is an intron exon boundary  an exon intron boundary  or neither  The results are given in Table    We used the same uniform prior for structure hypotheses   Table    Greedy search performance for the uniform scoring function  using different sets of operators  in the Splice domain  C    B      CB      CM      BM      CBM      Table    Greedy search performance for the uniform scoring function for each node in the ALARM network  Also included is the uniform score for the completetable model COMP C B CB CM BM CBM                            Table   again supports the claim that we get a significant improvement by using decision graphs instead of decision trees  Our final set of experiments were done in the ALARM domain  a well known benchmark for Bayesiannetwork learning algorithms  The ALARM network  described by Beinlich et al          is a handconstructed Bayesian network used for diagnosis in a medical domain  The parameters of this network are stored using complete tables  In the first experiment for the ALARM domain  we demonstrate that for a fixed global structure G  the hypothesis identified by searching for local decision graphs in all the nodes can be significantly better than the hypothesis corresponding to complete tables in the nodes  We first generated      cases from the ALARM network  and then computed the uniform Bayesian score for the ALARM network  assuming that the parameter mappings M are complete tables  We expect the posterior of this model to be quite good  because were evaluating the generative model structure  Next  using the uniform scoring function  we applied the six greedy searches as in the previous experiments to identify good decision graphs for all of the nodes in the network  We kept the global structure G fixed to be identical to the global structure of the ALARM network  The results are shown in Table    and the values have the same semantics as in the previous two tables  The score given in the first column labeled COMP is the score for the complete table model  Table   demonstrates that search performance using decision graphs can identify significantly better models than when just using decision trees  The fact that the complete table model attains such a low score  the best hypothesis we found is e    times more probable than the complete table hypothesis   is not surprising upon examination of the probability tables stored   Table    Performance of greedy algorithm that combines local and global structure search  using different sets of operators  in the ALARM domain  Also included is the result of a greedy algorithm that searches for global structure assuming complete tables  COMP      C    B      CB      CM      BM      CBM       in the ALARM network  most of the tables contain parameter set equalities  In the next experiment  we used the ALARM domain to test the structure learning algorithm given in Section      We again generated a database of      cases  and used the uniform scoring function with a uniform prior over structure hypotheses  We ran six versions of our algorithm  corresponding to the six possible sets of local structure operators as in the previous experiments  We also ran a greedy structure search algorithm that assumes complete tables in the nodes  We initialized this search with a global network structure with no edges  and the operators were single edge modifications to the graph  deletion  addition and reversal  In Table   we show the results  The column labeled COMP corresponds to the greedy search over structures with complete tables  Once again  we note that when we allow nodes to contain decision graphs  we get a significant improvement in solution quality  Note that the search over complete table structures out performed our algorithm when we restricted the algorithm to search for decision trees containing either     only complete splits or     complete splits and binary splits  In our final experiment  we repeated the previous experiment  except that we only allowed our algorithm to add parents that are not descendants in the generative model  That is  we restricted the global search over G to those dags that did not violate the partial ordering in the ALARM network  We also ran the same greedy structure search algorithm that searches over structures with complete tables  except we initialized the search with the ALARM network  The results of this experiment are shown in Table    From the table  we see that the constrained searches exhibit the same relative behavior as the unconstrained searches  For each experiment in the ALARM domain  Tables       and    the values presented measure the performance of search relative to the worst performance in that experiment  In Table    we compare search performance across all experiments in the ALARM domain  That is  a value of zero in the table corresponds to the experiment and set of operators that led to the  Table    Performance of a restricted version of our greedy algorithm  using different sets of operators  in the ALARM domain  Also included is the result of a greedy algorithm  initialized with the global structure of the ALARM network  that searches for global structure assuming complete tables  COMP    C      B      CB      CM      BM      CBM      Table    Comparison of Bayesian scores for all experiments in the ALARM domain  S U C  COMP              C            B              CB              CM              BM               CBM                learned hypothesis with lowest posterior probability  out of all experiments and operator restrictions we considered in the ALARM domain  All other values given in the table are relative to this  lowest  posterior probability  The row labels correspond to the experiment  S denotes the first experiment that performed local searches in a static global structure  U denotes the second experiment that performed unconstrained structural searches  and C denotes the final experiment that performed constrained structural search  Rather surprising  each hypothesis learned using global structure search with decision graphs had a higher posterior than every hypothesis learned using the generative static structures      DISCUSSION  In this paper we showed how to derive the Bayesian score of a network structure that contains parameter maps implemented as decision graphs  We defined a search space for learning individual decision graphs within a static global structure  and defined a greedy algorithm that searches for both global and local structure simultaneously  We demonstrated experimentally that greedy search over structures containing decision graphs significantly outperforms greedy search over both     structures containing complete tables and     structures containing decision trees  We now consider an extension to the decision graph that we mentioned in Section      Recall that in a decision graph  the parameter sets are stored in a table within the leaves  When decision graphs are implemented this way  any parameter abc must belong to exactly one  distinct  parameter set  An important   consequence of this property is that if the priors for the parameter sets are Dirichlet  Assumption     then the posterior distributions are Dirichlet as well  That is  the Dirichlet distribution is conjugate with respect to the likelihood of the observed data  As a result  it is easy to derive the Bayesian scoring function in closed form  If we allow nodes within a decision graph Di to split on node xi   we can represent an arbitrary set of parameter constraints of the form  i  j  k     i  j     k     for j    j   and k    k     For example  consider a Baysian network for the two variable domain  x  y   where x is a parent of y  We can use a decision graph for y that splits on y to represent the constraint p y     x        Dy   G    p y     x        Dy   G  Unfortunately  when we allow these types of constraints  the Dirichlet distribution is no longer conjugate with respect to the likelihood of the data  and the parameter independence assumption is violated  Consequently  the derivation described in Section   will not apply  Conjugate priors for a decision graph Di that splits on node xi do exist  however  and in the full version of this paper we use a weaker version of parameter independence to derive the Bayesian score for these graphs in closed form  We conclude by noting that it is easy to extend the definition of a network structure to represent constraints between the parameters of different nodes in the network  e g  ij   i  j   for i    i    Both Buntine        and Thiesson        consider these types of constraints  The Bayesian score for such structures can be derived by simple modifications to the approach described in this paper   
  explored by Breese  Beckerman and Kadie           have not relied on the order in which users express We treat collaborative filtering as a univari ate time series problem  given a user s previ ous votes  predict the next vote  We describe two families of methods for transforming data to encode time order in ways amenable to off the shelf classification and density estima tion tools  Using a decision tree learning tool and two real world data sets  we compare the results of these approaches to the results of collaborative filtering without ordering infor mation   The improvements in both predic  tive accuracy and in recommendation quality that we realize advocate the use of predictive algorithms exploiting the temporal order of data   their preferences   Vector space methods draw heav  ily on work in the information retrieval literature  see  e g   Baeza Yates and Ribeiro Neto           where in  dividual documents are treated as a  bag of words   Likewise  probabilistic techniques  e g  Hofmann and Puzicha         and Beckerman   Rounthwaite and Kadie          Chickering   Meek   have computed proba  bility distributions over recommendations conditioned on the entire vote history without regard to time or der  In the CF literature  a  bag of votes   i e  atem poral  assumption prevails  and the collaborative fil tering problem is cast as classification  with classes  relevant  and  irrelevant   or density estimation  of the probability that a document is relevant  given a user s votes   We instead consider collaborative filtering as a univari  Keywords  Dependency networks  probabilistic deci sion trees  language models  collaborative filtering  rec ommendation systems      Introduction  The collaborative filtering problem arose in response to the availability of large volumes of information to a variety of users  Such information delivery mecha nisms as  Usenet and  online catalogs have created large  stores of data  and it has become the users  task to dis cover the most relevant items in those stores  Rather than requiring that users manually sift through the full space of available items  trusting that authors respect the available system of topics  CF tools rec ommend items of immediate or future interest based on all users  expressed preferences   votes    suggest ing those items of interest to other users with similar tastes   These votes may be either explicit  as in re  sponse to a direct inquiry  or implicit  as by the choice to follow one hyperlink instead of others  In general  algorithms for the CF task  such as those  ate time series prediction problem  and represent the time order of a user s votes explicitly when learning a recommendation model  Further  we encode time or der by transforming the data in such a way that stan dard atemporallearning algorithms can be applied di rectly to the problem  Other authors  cf  Mozer          have applied atemporal learning techniques to tempo ral data  we describe here two successful generic tech niques  As a result  researchers can simply transform their data as we describe and apply existing tools  in stead of having to re implement various collaborative filtering algorithms for awareness of vote order  Our approach allows CF models to encode changes in a user s preferences over time  It also allows models to represent  indirectly  structure built into the feature space that would be lost in a bag of votes representa tion  For example  Web page viewing histories ordered by page request can express the link structure of a Web site because a user is most likely to follow links from his current page  Similarly  television viewing histories encode the weekly schedule of shows  a viewer cannot hop from  Buffy  the  Vampire Slayer to Dawson s Creek  if the two are not contemporaneous    ZIMDARS ET AL   UAI      For simplicity  we assume for the remainder of this paper that user preferences are expressed as implicit votes  see  e g   Breese et al          That is  a users  vote history is a list of items that the user preferred  as opposed to an explicit ranking of the items  In a movie domain  for example  this means that a user s vote history is simply a list of movies that he watched  and we assume that he preferred those movies to the ones he did not watch  We note  however  that the transformations we describe are easily generalized to explicit voting  In Section    we present two methods for transform ing user vote histories that encode time order infor mation in ways that traditional atemporal modeling algorithms can use  In Section    we discuss three candidate models that can be learned from standard algorithms applied to the transformed data  In Sec tion    we describe the data sets and criteria by which we will compare our approaches  and in Section   we present our experimental results from using decision tree learning algorithms        age  and G is a binary variable that denotes the per son s gender  Under the iid assumption a learning al gorithm can use observed values of S  A  and G for other people in the population to estimate the distri bution p SIA  G   then make a prediction about the particular person of interest with that distribution  In the following sections  we describe how data that contains vote histories can be transformed  using var ious assumptions  into the case representation so that standard machine learning algorithms can be used to predict the next vote in a sequence  First  we need some notation  We use item to denote an entity for which users ex press preferences by voting  and we use   to denote the total number of such items   For example  in a  scenario    is the total num ber of movies considered by the collaborative filtering system  For simplicity we refer to each item by a one based integer index  That is  the items in the system are mapped to the indices  movie recommendation                 Data Transformations  In this section  we describe two methods that trans form time ordered vote histories into a representation that traditional atemporal modeling algorithms can use  we call this representation the case representation  In the case representation  the data D consists of a set of cases  or records   C        Cm   where each case Ci     x       Xn  consists of a value for zero or more of the variables in the domain X    X         Xn         The important  sometimes implicit  assumption of modeling algorithms that use the case representation is that the observed cases are independent and identi cally distributed  iid  from some joint probability dis tribution p X         Xn    an equivalent Bayesian as sumption is that the cases are infinitely exchangeable  meaning that any permutation of a set of cases has the same probability  The learning algorithms use the observed case values in D to identify various models of the generative distribution  As an example  consider the problem of predicting whether or not a particular person will watch some television show based on that person s age and gen der  Using the case representation  we might assume that all people are drawn from some joint probability distribution p  S A  G   where S is a binary variable that indicates whether or not a person watches the show  A is a continuous variable denoting a person s  In fact  if we are interested in learning a conditional  model for Y C X  we often need only assume that the  values for the variables in Y are independent samples from some p YIX   Y   We use Vi to denote the i h vote history  i e  user s votes   In particular  Vi is an ordered list of votes   V             vt    where V  denotes the item index of the j h vote in the list  and Ni is the total number of votes made by user     As an example  suppose there are four movies The Ma trix  Star Wars  A Fish Called Wanda and Pulp Fic tion having indices       and    respectively  Suppose there are two movie watchers in the domain  User   watched The Matrix and then watched Pulp Fiction  and user   watched Star Wars  then watched Pulp Fic tion  and then watched The Matrix  Then we would have V          and V               For each of the transformations below  we show how convert from a set of vote histories into     a set of domain variables X   Xl  Xn   and     a set of cases  C        Cm   where each case Ci contains a set of values   x       Xn  for the variables in X  We also describe what assumptions are made in the original domain in order for the resulting cases to be iid  to            The  Bag of votes  Transformation  The first transformation we consider disregards the or der of previous votes  corresponding to the assumption that vote order does not help predict the next vote  As noted above  this  bag of votes  approach is the ap proach taken by many collaborative filtering learning algorithms    ZIMDARS ET AL        For each item k  where       k        there is a binary variable Xj E X  whose states x  and x correspond to preferred and not preferred  respectively  There are no other variables in X  For each vote history V   we create a single case Ci with the following values  if item j occurs at least once anywhere in the sequence vi  then the value Xj in ci is equal to x    Otherwise  the value of Xj in Ci is equal to x    The assumption that the cases are iid corresponds to assuming that the  unordered  votes of all vote histo ries  i e  users  are all drawn from the same distribu tion  Under this assumption  we can use an atemporal learning algorithm with the cases from previous vote histories learn a model for p XJIX XJ  for all XJ EX  and then use these models to predict the next vote  for any vote history       The Binning Transformation  The second transformation we consider can be help ful when user preferences change over time  Although the transformation does not explicitly use the order of the votes  it can exploit temporal structure  The idea is to     separate vote histories into bins by their size      transform the histories from each bin into the case representation using the  bag of votes  trans formation described above  and     learn a separate model from the data in each such bin  W hen it comes time to predict the next vote in a sequence of size k  we use the model that was learned on the cases derived from the vote histories in the bin corresponding to k  Suppose  for example  that we would like to train one or more models in order to recommend movies to peo ple  It might be reasonable to assume that the op timal model for predicting the third movie for some one may not be a very good model for predicting the    th movie  W ith binning  we divide up the range of the number of movies that have previously been seen into separate bins  and learn a recommendation model for each  Thus  we might end up with three mod els      a simple model that predicts popular movies for people who do not go to the movies much      a model that perhaps identifies general viewing prefer ences  e g  comedies  for the typical viewer  and     a model that identifies subtle preference trends for heavy movie watchers  In order to perform binning  there are a number of parameters that need to be set  First  we need to decide how many bins to use  Second  we need to decide  for each bin  what history lengths should be included in that bin     There are some subtleties  addressed below  about how  this prediction is made   UAI      For the experiments that we present in Section    we tried both two and four bins  For each bin  we set a minimum and maximum value for the length of the contained histories  We chose this minimum and max imum such that the total number of votes in each bin are roughly the same  As described above  the binning approach assigns each vote history to exactly one bin  An alternative ap proach  which we call the prefix approach  is to allow a single vote history to contribute to multiple bins by adding an appropriate prefix to all of the  previous  bins  As an example  suppose there are three bins that accommodate histories of length up to        and      In the prefix approach  a vote history of length    will have     the first five votes added to the first bin      the first ten votes added to the second bin  and     the whole history added to the third bin  The choice of whether or not to use the prefix approach to binning will depend on user behavior and domain structure  We identify the following two hypotheses that can help determine which method is most appro priate    The  expert novice  hypothesis  Users with long vote histories   experts  in the domain  have fun damentally different preferences than users with short vote histories   novices    As a result  we expect that omitting prefixes of longer vote histo ries from bins for shorter vote histories will result in better predictive accuracy than the prefix ap proach  The expert novice hypothesis might hold when predicting preferences for television viewing  where couch potatoes might have different view ing habits than occasional viewers  On a Web site  heavy users tend to navigate very differently than  shallow browsers   cf  Huberman et al             The  everyone learns  hypothesis  Users with long vote histories once expressed similar prefer ences to users with short vote histories  Under this hypothesis  we expect that prefixes of long vote histories will be distributed similarly to short vote histories  and therefore their inclusion in the corresponding bins will provide useful data for the model building algorithm  as a result  we hope that the resulting models will be more accurate  One can also interpret this hypothesis from the perspective of domain structure constraining user behavior  For users of a Web portal  initial votes may be restricted to the home page and top level categories linked from that page  For subsequent page hits  available links may constrain possible user votes  In this domain  we would expect users to have similarly distributed vote prefixes because site structure does not allow much room for inno    UA       ZIMDARS ET AL   vation  For the domains we consider in Section    the latter hy pothesis seems more appropriate  although we ideally should have compared the two  in the interest of time we only used the prefix approach in our experiments  We chose the bin boundaries so that the total number of votes of the original  i e  non prefix  histories in each bin were roughly the same  W hether or not we use the prefix approach  the addi tional computational overhead of binning over no bin ning is proportional to a constant factor  the number of bins   because each bin will contain no more votes   and no more vote histories  than would a single model computed using the entire vote set   Structural aspects of some prediction domains can make difficult the choice of vote sub histories to aug ment data for binning  Web sites tend to have a hierar chical structure with a home page at the root  but the same cannot be said for television programming sched ules  which reflect periodic structure  When predicting television viewing habits given a  snapshot  of user viewing histories  prefixes may not reflect the periodic nature of the program schedule  In such domains  dif ferent choices of contiguous vote sub histories may be appropriate  but the resulting profusion of data might render binning impractical  We should point out that binning can be applied to collaborative filtering problems in which the temporal order of the votes is unknown  Although the prefix ap proach may not be appropriate  binning based on the number of votes can potentially lead to significantly better accuracy in atemporal domains  Consider  for example  the problem of recommending items in a gro cery store based on the products bought  the recom mendation may appear as a targeted coupon on a re ceipt   It might turn out that  regardless of the order in which people put groceries in their shopping cart  the number of items in their cart may indicate very different shopping behavior  consequently the binning approach might yield significantly better models than a system that ignores the number of votes       Data Expansion  The final data transformation we consider  which we call data expansion  finds inspiration in the language modeling literature  see  e g   Chen and Goodman         This method of data expansion distinguishes the most recent n votes from the entire vote history  as well as identifying the order of the most recent votes  All of the variables that we create in the transforma tion are binary  and have states x  and xO correspond to preferred and not preferred  respectively        In the case representation  we create one binary vari able for each of the I items in the domain  xT    X        X   The  T  superscript in X   is meant to indicate that this is a  target variable  that repre sents whether or not the next vote is for item k  The data expansion transformation is parameterized by a history length l  this parameter  which corre sponds to the  n  parameter in an n gram language model  determines how far back in the vote history to look when predicting the next vote  For each in teger history    j  l  we again create one bi nary  variable for each of the   items in the domain   X         X     i   The   j  superscript in Xf j is meant to indicate that this variable represents whether or not Ph previous vote  from the one we re predicting  is for item k  We use XL to denote the set of all lagged variables  e g   X         X         X          X         There is a final set of   variables consisting of  for each item  an indicator of whether or not that item was voted for at least once previously in the given vote history  We use xc    Xf        X   to denote these variables  In language modeling p rlance  these vari ables are known as cache variables  In contrast to the  bag of words  approach  where each vote history was transformed into a single case  in the data expansion transformation  each vote in every history  gets a corresponding case  In particular  for vote V   which is the lh vote in the ith vote history  we define the values for all of the variables as follows  For simplicity  let v   V   We set the value of target variable XJ to xl  and we set the value of all other target variables to xO  For each history variable x j k   where    j  l  we set the corresponding value to ei ther x  if the lh previous vote in history i has value k  or xO otherwise  Finally  we set the value of each cache variable Xf to either xl if item k occurs as a  vote  at least once  previous to V  in Vi  or xO otherwise  We should point out that in order to feasibly learn a model using the cases that result from the data expansion transformation  the learning algorithm s  need to use a sparse representation for the cases  See  e g   Chickering and Heckerman        for a discus sion   Consider our movie example again  For simplicity  we use M  S  F  and P to label all variables we create corresponding to movie items The Matrix  Star Wars  A Fish Called Wanda and Pulp Fiction  Furthermore  we use   and   to denote the values preferred and not preferred  respectively  Suppose we want to transform a vote history con taining The Matrix  Pulp Fiction  and Star Wars  in that order  into the case representation with a history        ZIMDARS ET AL   length of one  First we define the variables  x     for this model is expressed as follows   r r r r   M  s  F  P   M        p    p    MC   SC   pC   pC   n  P C     shows the case values that  result  The learning algorithm we use should build a model for each of the target variables  using all non target variables as predictor variables   That is  we would  like the model to estimate  for each target variable  XJ E XT  the distribution p XJIXL  xc    The iid assumption in the case representation after performing the data expansion transformation with history length l implies that each vote is a distribution that depends on previous  l  votes and            drawn from  the values of the  the presence or absence of at  least one vote for previous items   v          vn       P C  Models  that can be used for collaborative filtering applica tions  when learned from data that is transformed as described in the previous section  these models can exploit the vote order to improve recommendation ac curacy   Cheeseman and Stutz                       provide details of  In this setting  prediction for collaborative filtering follows from the density estimation problem  as the model predict the item s  most  likely to receive an af  firmative vote given the user s vote history   Other latent class models  Hofmann and Puzicha          for collaborative filtering  have been proposed  which place user and item on an equal footing  These permit construction of a two sided clustering model with preference values  but they depend on multino mial sampling of  user  item  pairs  and as such do not generalize naturally to new users   Decision tree models  v ious work  cf   Beckerman et al           constructs  a forest of probabilistic decision trees  one for each item in the database  using a Bayesian scoring crite rion  Chickering  Beckerman  and Meek           This  provides a compact encoding of conditional probabil ities of recommendations  given previous votes   use this approach in Section  We    to evaluate our data  Memory based algorithms  Memory based collaborative filtering algorithms pre dict the votes of the active user based on some partial information about the active user and a set of weights calculated from the user database  Memory based al gorithms do not provide the probability that the active user will vote for a particular item  Instead  the active user s predicted vote an item is a weighted sum of the votes of the other users  See Breese et  al         for  a  more detailed discussion   A      c  i l  a specific implementation of the learning algorithm   transformations          IT P vi I C  The approach that has proven most effective in pre  In this section  we describe some well known models        c  the EM algorithm  see Dempster  Laird and Rubin            c   The parameters of this model can be learned using  Next  we consider each vote in the history  and create a case for each one  Table  UAI      Cluster models  standard probabilistic model is the naive Bayes  model with a hidden root node one where the prob abilities of votes are conditionally independent given membership in an unobserved class variable C  where C ranges over a fairly small set of discrete values  This  corresponds to the intuition that users may be clus  tered into certain groups expressing common prefer ences and tastes   The joint probability distribution       Alternative models  The data expansion technique discussed in Section       suggests the application of language modeling algo rithms to collaborative filtering  We have conducted  limited experiments with variants of n gram language models  and the results are promising  although we do not present them here   Hidden Markov models themselves in this setting    HMMs   also  recommend  but in our experience they  are ill suited to a na ive representation of the data   where each possible vote corresponds to exactly one feature  This reflects in part the number of parame ters that must be estimated when running EM for an HMM  if the model admits are  me     c      c  c  hidden states  then there  parameters to estimate for the poste  rior probabilities of states  the state transitions  and  It also permits the construction of a family of graphical as dependency networks  which have expres  models known  sive strength similar to Markov networks    ZIMDARS ET AL   UAI      Table       Case values created for the movie example with the data expansion method       M     Vote  The Matrix Pulp Fiction Star Wars  sl  FJ  p l  M                                         s     F    p                           Me  se  Fe  p  u                               Moreover  models are slow to con  We used probabilistic decision tree models for our ex  verge because collaborative filtering data tend to be  periments  and compared both binning and data ex  very sparse  in that few users vote on ariy one item  As  pansion to the default  bag of votes  approach of ig  the state priors   a result  evidence for estimating a particular variable  noring the data order   is rarely presented in training  This sparsity is  we learned a single decision tree per page  integral  For all of the experiments  to predict  to the collaborative filtering problem  but lethal to ac  whether the user requests that page  based on the  curate estimation  Finally  HMMs discard much of a  transformed data available at that time   user s history in making predictions  and our experi  greedy tree growing algorithm in conjunction with the  ments indicate that a long history can be informative   Bayesian score described by Chickering et  al          We used a  In particular  the score evaluated the posterior model     probability using a flat parameter prior  and a model  Experiments  prior of the form r  f  where  In this section  we describe the experiments we per formed to demonstrate that using vote order can im prove the accuracy of models  We conducted our experiments using two real world data sets  both of which are Web user traces  In each   the notion  of   user  corresponds  to a  server  session   and a page request was interpreted as an affirmative vote  The first data set consists of session traces from data encompassed          The training  page requests from         users over three days in late August       and the test data included        requests  from         users on      September of the same year  The requests span a to tal  of      URLs  roughly     of which correspond to     errors for invalid URLs  The average length of a session trace was       votes  with a median length of    and the longest trace was    votes  second  data  set  uses  session  traces from http   www  msnbc  com   corresponding to an           split of users on  The training data include roughly from     December            million requests data include                users  while the test requests from       users   The requests in these two data sets span      URLs  it is unclear whether any of these represent invalid URLS  The average length of a session trace was     experiments          for all of the  In all of the data transformations described in the pre vious section  we created a separate binary variable for each item that denoted whether or not the next vote will be for that item  Defining the variables this way can be problematic for any learning algorithm using finite data that does not enforce the constraint that the next vote will be for exactly one item  In particu  http    research  microsoft  com    T he  f is the number of free  parameters in the tree  We used r           and a longest trace of  vote  with a median length of      votes   Unfortunately  we did not identify other publicly available data that records user preferences in time or der  The authors  experience with other data suggests that the techniques outlined here may prove fruitful with other types of sequential data   lar  the algorithm we used to learn a forest of decision trees did not enforce this constraint   We solved this  problem by using the decision trees to calculate the posterior probability that each item would be the next  vote  then renormalizing   We applied two evaluation criteria in our experiments  For all prediction algorithms  we adopted the  CF ac curacy  score outlined by Heckerman et a             and specialized it to compute the CF score with re spect to the next item in the user s history only  The CF accuracy score attempts to measure the probabil ity that a user will view a recommendation presented in a ranked list with other recommendations  To ap proximate this probability  let p k        k a  denote  the probability that the user views the kth item on his list  where k counts from        For the experiments  presented here  we chose a half life of  a          We  computed for each user i  and for each vote vii in his vote history  a ranked list of recommendations given  Vil          Vi j       One may compute the CF accuracy of a general list L  of test items spanning n users  Suppose the model rec  ommends R  items to each user  and the users actually  prefer sets of M  items  Let O k denote the indicator        ZIMDARS ET AL   UAI      that user i prefers the kth recommendation  Then accuracy CF  L      n           n  i     R lJ   L   k o  kP  k      M    p  k    l L   k O       Let kii be the ranking assigned by our model to vote  Vij  Scoring one vote at a time  CF accuracy simplifies  to      Baseline    Bins     Bins  DE   DE   DES  One may compute CF accuracy for any CF algorithm that generates a ranked list of recommendations  but  Figure  it provides a criterion specific to the collaborative fil  constructed for the MSNBC domain       Collaborative filtering scores of the models  tering task  For the probability models we evaluated  we also computed the mean log probability assigned to each of the user s actual votes  given the preced ing vote history   This log probability was normalized over all items in dependency network models to com pensate for potential inconsistencies    Baseline    Bins    Bins  DE   DE   DES                Note that CF accuracy is a function of the relative  magnitude of density estimates  while the log score depends on the absolute magnitude of the estimates                                Results          The results presented below correspond to three fam ilies of models   The  Baseline  results derive from  a forest of decision trees trained on bag of votes data  shown to be a one of the best models for CF  Breese et al               Bins  and    Bins  experiments applied  the binning method described in section        Two or  four decision trees are constructed for each Web page   Figure      Log probability scores of the models con  structed for the MSNBC domain   increase as a function of history length   This might  suggest that Web page requests depend more strongly  but only one is chosen  according to the partial his  on immediate links than on the short term history  and  tory at hand  to make a prediction  The  DE   exper  that data expansion mainly embodies this structural  iments expand data as in section      with histories of  element of the Web surfing domain   One should not  length       and     interpret this  Figure   and Figure     scores   for all of the models in the  respectively   show the CF scores and log  MSNBC domain   as  a Markov assumption  in our expe  rience  the cache variables strongly influence predic tion    The higher CF accuracy results suggest that  the relative magnitude of density estimates is more of  ten accurate for data expanded models than binned  There are some interesting observations to make about  models  and these relative estimates determine which  these results  F irst  we see that for the collaborative  pages show up in a recommendation list   filtering score  the score got worse as we increased the  number of bins  This may be an artifact of the sparsity  of long traces in Web surfing data  a phenomenon that has been observed elsewhere  e g   Huberman et al          This may not impair work in other domains   our experience with data suggests that other frequency functions for user history length can have thicker tails   Our results show that unlike for the CF score  the bin ning approach dominated both the baseline and the data expansion models for log probability predictive accuracy   For this score  the data expansion models  improved as the history length increased  but only the model with the longest history  five  was competitive with the baseline model   We suspect that the data  Second  we see that all of the data expansion models  were too sparse to permit accurate parameter esti  performed significantly better than the baseline with  mates for the models learned under data expansion   respect to CF accuracy  but that performance did not  In particular  there were roughly    percent more pa    ZIMDARS ET AL   UA            rameters to train in each of the data expansion models  the log score  However  binning models do not indicate  than in the other models  which leads us to suspect  a steep fall off in CF accuracy relative to the baseline   that the learning algorithm over fit for these models  as for the MSNBC data set  We hypothesize that typi  to some degree  In retrospect  we regret the choice of  cal MSR visitors leave longer page traces than MSNBC  a single value of the model prior parameter    for all  users   data transformations  We expect that if we had tuned this parameter by splitting up the training data and maximizing a hold out prediction accuracy  we would have identified a smaller   for the data expansion mod els that yielded better results for both criteria on the tests set  Improvements in log score as history length increase demonstrate the value of the additional in formation encoded by the expanded data  which com pensates in part for having too few data points per parameter      Conclusion  We have presented two techniques for transforming data that allow the collaborative filtering problem to be treated as a time series prediction task   Both of  these techniques allow state of the art collaborative filtering methods to model a richer representation of data when vote sequence information is available  We have evaluated these techniques  using probabilistic  Figure   and Figure     show the CF scores and log  scores  respectively  for all of the models in the MSR domain   decision tree models  with two data sets for which the  order of user votes were known  Results indicate mixed gains for each approach  Binning user data by history length improved log probability scores with respect to       a bag of votes model in our test cases  while data ex pansion to introduce history variables improved the       collaborative filtering accuracy score over baseline        
 We begin by discussing causal independence models and generalize these models to causal interaction models  Causal interaction models are models that have independent mechanisms where mechanisms can have several causes  In addition to introducing several particular types of causal interaction models  we show how we can apply the Bayesian approach to learning causal interaction models obtaining approximate posterior distributions for the models and obtain MAP and ML estimates for the parameters  We illustrate the approach with a simulation study of learning model posteriors     Introduction Models of causal independence  such as the Noisy or  Good       Kim and Pearl        and Noisy Max  Henrion        have proved to be useful for probabilistic assessment  Pearl       Henrion       Heckerman and Breese         In addition to easier assessment  there are techniques for performing inference e ciently in models with causal independence  e g   Heckerman and Breese       Zhang and Poole        and techniques to e ciently calculate upper and lower bounds for likelihoods where exact inference is intractable  Jaakkola and Jordan         The essential idea of causal independence models is that the causes lead to the e ect through independent mechanisms  If this type of model is assumed then one only needs to separately assess the probability distributions that describes a mechanism and give a rule for combining the results of the mechanisms  On the other hand  when using full probability tables to represent the conditional distribution of the e ect given its   Causal independence is sometimes referred to as intercausal independence   causes  we are essentially allowing for complete causal interactions between the causes  The  rst part of this paper introduces causal interaction models  Like the causal independence model  a causal interaction model is a set of mechanisms  a set of causes  and an e ect  Unlike the causal independence model  a cause need not be associated with a single mechanism and multiple causes can be associated with a single mechanism  Allowing several causes to be associated with a single mechanism allows for partial causal interaction between a set of causes  thus  causal interaction models generalize both the causal independence model and the complete causal interaction model  In Section    we show how to represent causal interaction models as directed acyclic graphical  DAG  models  a k a   Bayesian networks  belief networks  causal networks  with hidden variables  In addition we introduce a special type of causal interaction model  the exponential causal interaction model  Examples of exponential causal interaction models are given in Section    In the second part of the paper we turn our attention from representation to learning the structure and parameters of exponential causal interaction models  In much of the initial work on learning  discrete  DAG models  the focus was on learning the structure of the network assuming there were full conditional probability tables for each variable in the network  The conditional probability table for a variable represented the conditional probability of the variable given every possible combination of the values of its parents in the DAG model structure  In this representation  the number of parameters associated with a variable is exponential in the number of parents of the variable  This exponential explosion can restrict the set of network structures that can be learned by some methods  e g   MDL methods  Boukaert        In part  because of these limitations  there has been interest in learning DAG models with more parsimonious representations for the conditional probability of variables given their   parents  For instance in Friedman and Goldszmidt        and Chickering et al          the authors consider using decision trees and a generalization of decision trees to represent the conditional probability of the variable given its parents  These representations of local structure allows for dramatic reductions in the dimension of the parameter space  Causal interaction models provide an alternative representation for the local structure in a DAG model  We illustrate the fact that there are Noisy Max Interaction models that can not be parsimoniously represented by decision trees and that decision trees and other types of local structures can be embedded in causal interaction models  Thus  causal interaction models are rich set of models for parsimoniously representing local structure  Since causal interaction models are DAG models with hidden variables and hidden variables are just the extreme case of missing data we discuss learning DAG models with missing data in Section    We also discuss how one can use the EM algorithm to obtain ML and MAP estimates for hidden variable models  Finally  in Section    we illustrate the fact that one can learn the structure of causal interaction models in a small simulation study  In addition  Section   illustrates the importance of correctly calculating the dimension of hidden variable models when learning structure     Causal Independence and Causal Interaction models When constructing a parameterized DAG models  one must specify the conditional probability of each variable given each possible con guration of the parents  Figure  a shows a variable E with several parents  causes   It is often not feasible to specify a complete probability table to represent the required probabilities  because the number of probabilities grows exponentially in the number of parents  In addition  several authors have argued that this model is inaccurate because it fails to represent the independence of causal interactions  To overcome both of these inadequacies  researchers have used DAG models such as the one shown in Figure  b to represent causal independence  e g   Good       Kim and Pearl       Henrion       Srinivas         We shall call the Ci s the causes  E the effect  and the Xi  s the noisy mechanism variables  The  noisy  mechanism variable Xi represents the contribution of the ith mechanism to the e ect E where the value of E is a deterministic function  indicated by the double circle in the graph  of the values of the mechanism variables  The independence of the causal mechanisms is captured by     the conditional independence of the mechanism variables given the causes   C   C   C   C   Cn  X   X   Xn  C   C   Cn  Cn X   Xm  E E   a  belief network for multiple causes   b  causal independence model  E   c  a causal interaction model  Figure    Di erent types of local structure  and     the independence between the set of mechanism variables for E and other variables in the network  not depicted in Figure  b  given the causes and the e ect  A causal interaction model relaxes the restrictions that each cause has a unique mechanism variable and that each mechanism variable has a unique cause  Figure  c shows an example of a causal interaction model  With a causal interaction model  it is possible to model relationships in which some of the causes interact to cause the e ect and some of the causes act independently  Example of interactions are often found in medicine  For instance  in some studies smoking and estrogen level have been found to have a synergistic e ect on the rate of stroke in females  There is no reason to stop the modeling of the causal process at this level  The ith mechanism described by the conditional distribution of Xi given the parent of Xi could be modeled as a decision tree  or a model with additional hidden variables  Roughly  a mechanism describes one  path  through which a set of causes lead to an e ect  A mechanism for causes C        Cn and e ect E are a set of nodes M which are not observed  hidden  such that     there is a distinguished variable called the noisy mechanism variable  or  simply  the mechanism variable       only members of the mechanism M and causes can point to members of M      the nodes in M form a directed acyclic graph      the only variable in M that points to a non member of M is the mechanism variable which only points to E  The Figure  b illustrates and example of a mechanism  Note that a cause can point to multiple nodes in a mechanism  A causal interaction model is roughly a DAG model of mechanisms which describes the conditional distribution of the e ect given its causes  More precisely  a causal interaction model is a     a set of causes C        Cn      an e ect variable E      a set of mechanisms for C        Cn and e ect E  which we denote by M        Mm       where the value of the e ect variable is a deterministic function of the mechanism variables X        Xm   which we call the combination function    C   C   Ck  Cn  Cl  E   a  general causal interaction model  X i    Xi  mechanism m  mechanism    mechanism    mechanism m  X i    E   b  example mechanism  Figure    Causal interaction models  Let M be the set of all of the variables in mechanisms for causes C        Cn and e ect E  As in the case of causal independence models  the independence of the causal mechanisms is captured by     the conditional independence of the set of variables in each mechanism given the causes  i e   for i    j  Mi is independent of Mj given C        Cn   and     the independence between the set of all mechanism variables  M  and other variables in the DAG model given the causes Ci and e ect E  It is common to add a leak term to the noisy or and noisy max models  A leak term is added to model mechanisms not associated with other variables in the model  A leak term corresponds to a mechanism variable  and thus a mechanism  which does not have any causes that are in the DAG model  Finally  an exponential causal interaction model is a causal interaction model in which the conditional likelihood for each variable in each mechanism is in the exponential family  In Section    we discuss a variety of speci c exponential causal interaction models  We focus on exponential causal interaction models because with these models we can often  nd tractable algorithms for inference and with tractable models for inference we can apply the EM algorithm     Examples of Exponential Causal Interaction models In this section we give a few examples of exponential causal interaction models       Noisy Max Interaction models A noisy max interaction  NMI  model is a causal interaction model in which      each mechanism consists of a single mechanism variable which has a domain that is a subset of the domain of the e ect variable      the  domain of the e ect variable can be ordered by a binary relation        the likelihood of each mechanism variable given the values of its parents is in the exponential family  and     the combination function is max  x        xm    Note that the e ect and the mechanism variables need not be discrete  It follows from the combination function that m Y p E   ejC     c     p Xi   ejC     c    i    An NMI model in which there is only one cause per mechanism variable is a generalization of the Noisyor and Noisy max models  These NMI models are noisy max models without a distinguished state  e g    absent  or  normal    Of course  one can create a Noisy Max Interaction model with distinguished states  by simply distinguishing one parent con guration for each mechanism variable and forcing the associated parameters to   and    Clearly  when one  xes parameters one is reducing the number of free parameters in the model  One bene t of models without distinguished states is that they can be easier to learn  In the case where one does not know the distinguished states for each of the mechanism variables  we have an additional learning problem namely we need to identify which parent con gurations are the distinguished states  Of course  if we do know which parent con guration is the distinguished state then we can force the parameter restrictions and use the EM algorithm to calculate the ML or MAP estimate of the parameters and approximate the posteriors on the models  As a special case we consider a discrete NMI model  an NMI in which     E is a discrete random variable  not necessarily  nite   and     each mechanism contains only a mechanism variable  Let  ijk   p Xi   kjC     c     p Xi   kjPaXi   j    Where PaXi is the set of Xi   Thus p Xi   xi jC     c     P of parents k xi  ijk   Let ji be the instantiation of causes for the ith mechanism variable  As discussed in Section      to use the EM algorithm we will need to calculate p Xi   k PaXi   j jC     c E   e     I j   ji  p Xi   kjC     c E   e    where I j   ji   is an indicator function that is one if and only if j   ji   p Xi       kjC     c E   e        Q Q  iji k   i  j p Xi ejC    c     i  j p Xi  ejC    c     n p X ejC    c     n p X  ejC    c    i i i   i    Q    QP     l k p Xi   ljC     c E   e    k e k e k e  Note that for each mechanism variable we only need to calculate p Xi jC     c    If the conditional distribution is in the exponential family then it is easy to   apply the EM algorithm  e g   if the conditional distribution p Xi jC     c   is distributed according to a Poisson or multinomial distribution  In addition  we do not need to have a unique conditional distribution for each instantiation of the parents of the mechanism variable  Rather  one can use a decision tree or a decision graph to reduce the number of conditional distributions and thus reduce the number of parameters needed for specifying the conditional distribution of the mechanism variable  This can even be done when the conditional distribution function is the Poisson distribution  Since the conditional distribution of a mechanism variable can be represented with a decision tree  the NMI model is at least as representationally rich as decision trees  A noisy or model  a special case of an NMI model  with n binary causes and a binary e ect has n parameters  However  for almost all values of the parameters  all but a set of Lebesgue measure zero  a full probability table  i e   a complete decision tree  must be used to represent the distribution exactly  Thus  causal interaction models provide a rich representation for modeling conditional distributions  Causal interaction models can be viewed as an alternative to decision trees or decision graphs for parsimonious local representations  however  since decision trees and graphs can be embedded in causal interaction models  they are strictly richer representation  The caveat  as we shall see in Section    is that one must use iterative methods in approximating several quantities of interest when using causal interaction models  Under suitable assumptions  this is not the case for decision trees and decision graphs  Finally  in Noisy or and Noisy Max models it is common to add a leak term to model mechanisms not associated with the other variables in the model  As discussed in Section    we can add leaks to NMI models  however  the extra degrees of freedom in a NMI model as compared to a Noisy Max can act somewhat like a leak term in a Noisy max model       Noisy Additive Interaction models A Noisy Additive interaction  NAI  model is a causal interaction model in which      each mechanism consists of a single mechanism variable which has a domain that is a subset of the domain of the e ect variable      the domain of the e ect variable is closed under addition      the likelihood of each mechanism variable given the values of its parents is in the exponential P family  and     the combination function is addition  mi   Xi   As a special case of an NAI model in which the effect is not continuous  we consider a Poisson NAI  model  A Poisson NAI model is an NAI model in which     p Xi jPaXi   j     Poisson    i j     that  x i j  is p Xi   xjPaXi   j     exp    i j     x    and     each mechanism contains only a mechanism variable    is called the rate parameter for the Poisson  In this case   i j   is a conditional rate parameter  Let   i j   be the parameter for the ith mechanism variable when the parents of the ith mechanism variable are in the j th state  Let ji be the instantiation of parents of the ith mechanism variable  Using the theorem that the sum of n independent random variables having Poisson distributions with parameters           n is distributed as a Poisson random variable with parameter            n we can characterize the Poisson NAI P model with the equation p E jC     c     Poisson  mi     i ji      Poisson random variables are useful in analyzing rates  e g   number of web page hits per week or number of headaches per week  Thus  the Poisson NAI model has potential for modeling conditional rates even in cases where the causes of the rate can interact  As with Noisy Max Interaction models  for a given mechanism variable  one need not have a unique parameter for each instantiation of the parents of the mechanism variable  Rather  one can use decision trees and decision graphs to reduce the number of parameters needed for specifying the conditional distribution of the mechanism variable  One interesting feature of the Poisson NAI model is that it is possible to run inference using a cliquetree type inference algorithm despite the fact that the clique potentials are in nite  The trick is to form the clique potentials only after the value of E is known  With the value of E known we can bound the values of the Xi  s and thus bound the size of the clique potential  Let ji be the instantiation of causes for the ith mechanism variable  As discussed in Section      to use the EM algorithm we will need to calculate p Xi   k PaXi   j jC     c E   e     I j   ji  p Xi   kjC     c E   e    where I j   ji   is an indicator function that is one if and only if j   ji   Below is the equation for p X    kjC     c E   e   where there are m mechanism variables  Let  ijk   p Xi   kjPaXi   j    The inferences for other mechanism variables are analogous  p X    kjC     c E   e          k e P    Pe k     Pe k  i li Qn oj l      Pe l    Pe lkm   Pi li Qn o   i i k   e l        lm    o   oji li iji k       A case where inference is even easier are Gaussian NAI   C   C   X   C   C   X   C   C   X   E    a  Model A  C   C   X   X   C   X   C   X   X   E   E   X   X   C   C   X   X   E    b  Expanded version of Model A  Figure    Interaction model with nested structure and conditional clique tree  models  A Gaussian NAI model is a causal interaction model in which the conditional distribution of each of the mechanism variables is Gaussian  By including a discrete  nite state hidden variable inside a mechanism it is possible to have conditional distribution for the mechanism variables which are mixtures of Gaussians  In other types of NAI models  e g   where some of the conditional distribution are Gaussian and some Poisson  inference is more di cult       Other models Both the NMI and NAI models have fairly simple structure  Figure  b illustrates a causal interaction model with a more complicated nested structure  As with any causal interaction model  there is a layer of mechanism nodes followed by a deterministic combination function  The expanded version of Model A in Figure  b illustrates that the conditional distribution of the mechanism nodes given its parent causes can have nested structure  In this case  the mechanisms associated mechanism variables X  and X  have nested causal interaction models and the mechanism associated with mechanism variable X  has a nested hidden variable X    It is important to note that when the values of E and the Ci s are observed all of hidden variables in the interaction model are d separated from other variables in the model  i e   variables not in the interaction model  and thus inference for EM can be localized to the interaction model  One might think that inference and thus using EM would be computationally hopeless in the expanded version of Model A in Figure  b or more complicated causal interaction models  This is not always the case  For the expanded version of Model A the interaction structure conditional on the Ci s forms a polytree  Thus the polynomial time algorithm of Kim and Pearl         can be used for inference  More generally  the independence of the mechanisms in a causal interaction model lead to computational e ciencies in inference because  in the clique tree conditional on the Ci  s  the nodes from di erent mechanism are only connected by paths through mechanism variables  This point is illustrated by the conditional clique tree in Figure  b  In addition to allowing for nested structure  causal interaction models also allow for other types of combination functions  For instance  an  N of  combination function is the combination function for a binary e ect variable which is equal to   if and only if N or more binary mechanism variables are equal to    Clearly this can be generalized to handle continuous variables  By using such an additive threshold combination function one can capture threshholding e ects in a causal interaction model  Another combination function is the X or or parity combination function in which the binary e ect variable is equal to   if and only if an even number of the binary mechanism variables are equal to    Causal interaction models with this combination function where the causes are jointly independent lead to a parameterized version of the pseudo independence model of Xiang et al             Learning the Structure and Parameters In this section  we investigate how to learn the parameters and the structure for exponential causal interaction models  In Section      we show how to use the EM algorithm  Dempster et al         to compute the ML and MAP estimate of the parameters  In Section      we investigate asymptotic approximations of the marginal likelihood  in particular  the CheesemanStutz approximation              Learning Parameters We can write the causal interaction model as a DAG model  In particular  this means that we assume that the true  or physical  joint probability distribution for the set of variables X   fX        Xn g in the DAG model can be encoded in some DAG model S  In this section  X        Xn are all of the variables in the model an not just the mechanism variables of a causal interaction model  We write p xj s S     Yn  i    p xi jpai i S        where i is the vector of parameters for the distribution p xi jpai i S   s is the vector of parameters           n    In addition  we assume that we have a random sample D   fx        xN g from the true joint   probability distribution of X  We refer to an element xl of D as a case  Finally  we have a prior probability density function p  s jS  over the parameters of the DAG model  The problem of learning probabilities in a Bayesian network can now be stated simply  Given a random sample D  compute the posterior distribution p  sjD S   We refer to the conditional distribution p xi jpai i S  as a local  conditional  distribution function  In this section  we illustrate the use of the EM algorithm in the case where each local distribution function is collection of multinomial distributions  one distribution for each con guration of Pai   Namely  we assume p xki jpaji i S     ijk         Q where pa i       paqi i  qi   Xi  Pai ri   denote the con gurations of Pai  and i      ijk  rki    qji   are the P parameters   The parameter  ij   is given by     rki    ijk    For convenience  we de ne the vector of parameters ij     ij          ijri   for all i and j  We assume that each vector ij has the prior distribution Dir  ij j ij          ijri    Nijk is the number of cases in D in which Xi   xki and Pai   paji   De ne  s to be the con guration of s that maximizes g  s    g  s     log p Dj s S    p  sjS       This con guration also maximizes p  s jD S   and is known as the maximum a posteriori  MAP  con guration of s   Also de ne  s to be the con guration of s that maximizes p Dj s S   This con guration is known as the maximum likelihood  ML  con guration of s   In the case of causal interaction models  we need to compute the posterior given incomplete data  Unlike the complete data case  we need to use approximation techniques  For more details see  for instance  Heckerman         These techniques include Monte Carlo approaches such as Gibbs sampling and importance sampling  Neal       Madigan and Raftery         asymptotic approximations  Kass et al          and sequential updating methods  Spiegelhalter and Lauritzen       Cowell et al          The asymptotic approximations are based on the observation that  as the number of cases increases  the posterior on the parameters will be distributed according to a multivariate Gaussian distribution  As we continue to get more cases the Gaussian peak will become sharper  tending to a delta function at the MAP con guration  s   In this limit  we can use the MAP con guration to approximate the distribution   A further approximation is based on the observation that  as the sample size increases  the e ect of the prior p  sjS  diminishes  Thus  we can approximate  s by the maximum maximum likelihood  ML  con guration of s   One class of techniques for  nding a ML or MAP is gradient based optimization  For example  we can use gradient ascent  where we follow the derivatives of g  s   or the likelihood p Dj s S  to a local maximum  Russell et al         and Thiesson        show how to compute the derivatives of the likelihood for a Bayesian network with unrestricted multinomial distributions  Buntine        discusses the more general case where the likelihood function comes from the exponential family  Of course  these gradient based methods  nd only local maxima  Another technique for  nding a local ML or MAP is the expectation maximization  EM  algorithm  Dempster et al          To  nd a local MAP or ML  we begin by assigning a con guration to s somehow  e g   at random   Next  we compute the expected suf cient statistics for a complete data set  where expectation is taken with respect to the joint distribution for X conditioned on the assigned con guration of s and the known data D  In our discrete example  we compute Ep xjD  s  S    Nijk      N X l    p xki paji jyl s S        where yl is the possibly incomplete lth case in D  When Xi and all the variables in Pai are observed in case xl   the term for this case requires a trivial computation  it is either zero or one  Otherwise  we can use any Bayesian network inference algorithm to evaluate the term  This computation is called the expectation step of the EM algorithm  Next  we use the expected su cient statistics as if they were actual su cient statistics from a complete random sample Dc   If we are doing an ML calculation  then we determine the con guration of s that maximize p Dc j s S   In our discrete example  we have E  N    ijk   Pri p ExjD  s  S   ijk k   p xjD  s  S   Nijk   If we are doing a MAP calculation  then we determine the con guration of s that maximizes p  s jDc S   In our discrete example  we have      Ep xjD  s  S    Nijk    ijk   Pri ijk k     ijk   Ep xjD  s  S   Nijk      The MAP con guration   depends on the coordinate s system in which the parameter variables are expressed    This assignment is called the maximization step of the EM algorithm  Dempster et al         showed that  under certain regularity conditions  iteration of the expectation and maximization steps will converge to a local maximum  The EM algorithm is typically applied when su cient statistics exist  i e   when local distribution functions are in the exponential family   although generalizations of the EM have been used for more complicated local distributions  see  e g   Saul et al               Learning Structure A key step in the Bayesian approach to learning graphical models is the computation of the marginal likelihood of a data set given a model p DjS   Given a complete data set that is a data set in which each sample contains observations for every variable in the model  the marginal likelihood can be computed exactly and e ciently under certain assumptions  Cooper and Herskovits         In contrast  when observations are missing  including situations where some variables are hidden or never observed  the exact determination of the marginal likelihood is typically intractable  Consequently  we will use approximation techniques for computing the marginal likelihood of exponential causal interaction models  In this section  we focus attentions on an asymptotic approximation called the Cheeseman Stutz approximation  which use in the simulation study described in Section    It was chosen for the simulation study because of its computational and performance features  See Chickering and Heckerman        for a discussion of other approximations and experimental results  When computing most asymptotic approximations  we must determine the dimension of each of the model  The dimension of a model can be interpreted in two equivalent ways  First  it is the number of free parameters needed to represent the parameter space near the maximum likelihood value  Second  it is the rank of the Jacobian matrix of the transformation between the parameters of the network and the parameters of the observable  non hidden  variables  In either case  the dimension depends on the value of  s space  In our simulation study we use a mathematicalsoftware package to calculate the rank of the Jacobian matrix of the transformation between the parameters of the network and the parameters of the observable variables  For more details and motivation see Geiger et al          Now we turn our attention the the Cheeseman Stutz approximation         Recall that in the EM algorithm we treat expected su cient statistics as if they are actual su cient statistics  This use suggests an  approximation for the marginal likelihood  log p DjS    logp D  jS      where D  is an imaginary data set that is consistent with the expected su cient statistics computed using an E step at a local ML value for s   Equation   has two desirable properties  One  because it computes a marginal likelihood  it punishes model complexity  Two  because D  is a complete  albeit imaginary  data set  the computation of the criterion is e cient  One problem with this scoring criterion is that it may not be asymptotically correct  Consider the asymptotically correct  Bayesian Information Criterion  BIC   Schwarz       Haughton          log p D  jS    logp D  j  s S    d  logN   O    where d  is the dimension of the model S given data D  in the region around  s that is  the number of parameters of S  As N increases  the di erence between p Dj  s S  and p D  j  s S  may increase  Also  as we have discussed  it may be that d    d  In either case  Equation   will not be asymptotically correct  A simple modi cation to Equation   addresses these problems  log p DjS    log p D  jS        d   log p D  j  s S      log N   log p Dj  s S     d log N Equation    without the correction to dimension  was  rst proposed by Cheeseman and Stutz        as a scoring criterion for AutoClass  an algorithm for data clustering  We shall refer to Equation   as the Cheeseman Stutz scoring criterion  We note that the scoring crireria given in Equation   and Equation   can be applied if one can compute the marginal likelihood of complete data given the model and obtain a MAP estimate  Buntine        shows how to compute the marginal likelihood for complete data given a DAG model in which the local likelihoods are from the exponential family and we will use the EM algorithm to obtain a MAP estimate     Simulation Study In this section we describe a small simulation study which highlights some of the important features of the approach that we described in Section    The structure of the  ve models that we used in the simulation study are given in Figure    All of the variables are   C   C   C   X   X   X   C   C   X   C   X   C   C   X   C   X   C   C   C   X   X   X   C   C   C   X   E  E  E  E  E  F   F   F   F   F   Model F  F  F  F  F  Dimension             Unadjusted dim               Table    The dimension of the NMI models   Figure    Noisy Max Interaction models used in simulation study   model F  over model F  when F  is the generating model  Using the correct penalty for the dimension is also important for other approaches such as MDL   binary and the conditional distributions of the Xi  s given the Ci s are complete probability tables  Model F  could also be represented without a deterministic combination function as a complete probability table of E given the Ci  s  For each model we chose parameter values for the parameters and then used the parameterized model as the generating model to generate a dataset of      cases  Parameter values were chosen by hand  however  similar results would be expected for parameters chosen at random  We approximated the model posteriors using the adjusted Cheeseman Stutz score for di erent sized initial segments of the      cases  The dimension of the models is calculated using Mathematica and the techniques described by Geiger et al          Although not done for our study  it is easy to automatically generate the equations for Mathematica to calculate the dimension and thus automate the calculation of dimension  The results of the simulation study are summarized in Figure    Model posteriors are presented only for initial segments of size                     and      cases  Not surprisingly  mass continues to accumulate on the generating model as the sample size increases  The one exception is when model F  is the generating model  The reason for the behavior of the posterior when F  is the generating model is that the set of distributions that can be parameterized by F  is a strict subset of the distributions that can be parameterized by F  and  surprisingly  the dimension of the two models is identical  This unusual relationship between F  and F  only occurs only when the Ci  s and E are binary  Finally  we would like to draw attention to the importance of using the correct dimension when calculating the Bayesian approximation to the posterior  The unadjusted dimension of a DAG model is the number of parameters in the model  including the parameters for the hidden variables  Table   describes the dimension of each of the models used in the simulation study  Consider models F  and F   Clearly every distribution over the Ci  s and E that can be represented in F  can be represented in F   If our asymptotic approximation used the unadjusted dimension then  at least asymptotically  it would be impossible to choose    Related and Future Work There has be little work done on parameter learning for causal interaction models  The notable exception is the work of Neal         Neal showed that one could learn the parameters of a noisy or network using a local learning rule  However  his particular gradient ascent procedure must be constrained to avoid entering an invalid region of the parameter space  Since we are using EM we are guaranteed to stay within the valid region of the parameter space and guaranteed to  nd a local maximum  We plan on investigating the representational power of causal interaction models as compared to other local structures  e g   decision graphs and compare the ease of assessment for various models In addition  we will consider automating the learning of causal interaction models  i e   de ning a search space  and search operators   and compare the result of such an algorithm to other approaches for learning local structure  Also of interest  is how to best combine a search for local structure with a search for global structure   Acknowledgments We thank Bo Thiesson  Jack Breese  and Max Chickering for helpful discussion on this material   
  W hen performing regression or classification  we are interested in the conditional probabil ity distribution for an outcome or class vari able Y given a set of explanatory or input variables X  We consider Bayesian models for this task  In particular  we examine a spe cial class of models  which we call Bayesian regression classification  BRC  models  that can be factored into independent conditional  ylx  and input   x   models  These mod els are convenient  because the conditional model  the portion of the full model that we care about  can be analyzed by itself  We examine the practice of transforming arbi trary Bayesian models to BRC models  and argue that this practice is often inappropri ate because it ignores prior knowledge that may be important for learning  In addition  we examine Bayesian methods for learning models from data  We discuss two criteria for Bayesian model selection that are appro priate for repression classification  one de scribed by Spiegelhalter et al           and an other by Buntine         We contrast these two criteria using the prequential framework of Dawid         and give sufficient condi tions under which the criteria agree   Keywords  Bayesian networks  regression  classifica tion  model averaging  model selection  prequential cri teria    Introduction  Most work on learning Bayesian networks from data has concentrated on the determination of relationships among a set of variables  This task  which we call Joint    analysis    has applications in causal discovery and the prediction of a set of observations  Another important task is regression classification  the determination of a conditional probability distribution for an outcome or class variable Y given a set of explanatory or input variables X  When Y has a finite number of states we refer to the task as classification  Otherwise we refer to the task as regression  In this paper  we examine parametric models for the regression classification task  In Section    we exam ine a special class of models  which we call Bayesian re gression classification  BRC  models  that can be fac tored into independent conditional  ylx  and input  x  models  These models are convenient  because the con ditional model  the portion of the full model that we care about  can be analyzed alone  In Section    we ex amine the practice of transforming arbitrary Bayesian models to BRC models  and argue that this practice is often inappropriate because it ignores prior knowledge that may be important for learning  Also in this paper  we discuss Bayesian methods for learning models from data  In Section    we compare Bayesian model averaging and model selection  In Sec tion    we discuss two criteria for Bayesian model selec tion that are appropriate for regression  classification  one described by Spiegelhalter et al          and an other by Buntine         We contrast these two crite ria using the prequential framework of Dawid         and give sufficient conditions under which the criteria agree  The terminology and notation we need is as follows  We denote a variable by an upper case letter  e g   X  Y  X       and the state or value of a correspond by that same letter in lower case  e g   We denote a set of variables by a bold face upper case letter  e g    X  Y  X    We use a cor responding bold face lower case letter  e g   x  y  x   to denote an assignment of state or value to each vari   ing variable  x  y  x            This task is sometimes called density estimation         Beckerman and Meek  able in a given set  VvTe say that variable set X is in configuration x  We use p X   xJY   y   or p xly  as a shorthand  to denote the probability or probability density that X   x g ive n Y y  We also use p xjy  to denote the probability distribution  both mass functions and density functions  for X given Y   y  Whether p xjy  refers to a probabil ity  a probability density  or a probability distribution will be clear from context        We use m and Bm to denote the structure and pa rameters of a model  respectively  When  m  B m  is a Bayesian network for variables Z  we write the usual factorization as  N           p zt    ZNIOrn  m  rrp z  Jpa   Bm  m  i l       Figure      a  A naive Bayes model for classification   b  A linear soft max regression model that has the same conditional distribution for Y   I xl  is the indicator variable that is equal to   if and only if x    xl  Consequently  we have  where  where Pa  are the variables corresponding to the par ents of Z  in m  We refer to p z  Jpa   B m m  as the local distribution function for Z      Regression  Classification  In this section  we examine various parametric mod els for the task of regression  classification  Mod els for this task are of two main types  conditional models and joint models  A conditional model is of the form p yjx  em  m   A joint model is of the form p y  xJe m  m   We use a joint model for re gression  classification by performing probabilistic in ference to obatin p yjx  em  m   Examples of joint models include Bayesian networks  F igure la shows the structure of a naive Bayes model in which the variables X are mutually independent given Y  Suppose Y has r states y          yr  each X  is binary with states x  and xl  and each local distri bution function is a collection of multinomial distribu tions  one distribution for each parent configuration   For this example  it is not difficult to derive the corre sponding conditional model  see  for example  Bishop   Akx       Chapter     Namely  we have p yklx  Bm  m   log   l   P Y jx  em  m            eAix         J    softmax  Atx        A x   k  where each Akx is a linear function of I  xi           I x    Models for          b    a      Ox  B yk   log    jyk  loge    Y     L    O x  J Y    i l       for k              r  After some algebra  Equation   be comes       This conditional model p yix  em  m  is a type of generalized linear model known as a linear softmax   regression  We can display the structure of this con ditional model as a Bayesian n etwork  as shown in Fig ure lb  In the figure  the input nodes X are shaded to indicate that we observe them and hence do not care about their joint distribution  Now let us specialize our discussion to Bayesian mod els for regression classification  In the Bayesian ap proach  we encode our uncertainty about Om and m using probability distributions p emlm  and p m   re spectively  Thus  the Bayesian variant of a joint model takes the form  p y x em m   p m  p emjm  p y xJ m m        We refer to this model as a Bayesian joint  BJ  model  We define a Bayesian analogue to a conditional model as follows  Suppose that em can be decomposed into parameters  Bx  eYI x  such that  p y xJem m   p xJBx m  p yjx eyJx m            p em Jm    p exJm  p  yJxlm  In this case  given data D     Yt xt         yN XN    assumed to be a random sample from the true distri bution of Y and X  we have  p em IY  x  m    Although   p xJ x m p  xJm      p yjx eyJx  m  p eyJxlm    Y has a finite number of states  this model  is commonly referred to  as a  regression    Models   Selection Criteria for Regression  Consequently  we can analyze the marginal conditional   ylx    x   and        B    m    terms independently  In particular  if  we care only about the conditional distribution  we can analyze it on its own  We call this model defined by Equations    and   BRC  model     a Bayesian regression classification  Simple examples of BRC models in  clude ordinary linear regression  e g   Gelman et al           ChapterS   and generalized linear models  e g    Bishop          Chapter        Note that our Bayesian analogue to the conditional model is a special case of a BJ model   One could  imagine using a Bayesian model that encodes only the conditional likelihood tribution for  Bm  and  p ylx  Bm m  m  However   and a joint dis this approach is  flawed  because it may miss important relationships among the domain variables or their parameters that are important for learning  In the following section  we consider an example of this point      Figure model  to to  A BERC model obtained from a naive Bayes  Y is an ancestor Xn    l         Xn   as follows   p ylpay Om m    IT p xdpai fJm m   o   n  l  where  lowing observation   X         Xn  p y xiOm m       p x lpa  Bm m    Y does  Pa  in the p ylx   Om  m     not appear in any parent set  first product  A special class of BRC models is suggested by the fol  of each of the nodes corresponding Given this ordering  we can factor  the joint distribution for Y   Embedded Regression Classification Models      Normalizing to obtain  taking a ratio  and canceling like terms  we obtain  For many BJ models  the con  ditional likelihood p y lx  Om  m  is a simple function  x  whereas the expression for the input likelihood p xiOm  m  is more complicated  For example  given a       of  naive Bayes model in which the variables  X are  mutu  where    pa             r   ally independent given Y  the conditional likelihood is  k  lihood is a mixture distribution  Thus  assuming we  Equation  a simple generalized linear model  but the input like  is a configuration of  Depending on  m   Pa    in which  y   yk   some of the terms in  the sum may cancel as well   We can trivially rewrite    as  are interested in the task of regression classification  we can imagine extracting the conditional likelihood from a B J model  and embedding it in a BRC model  In particular  given a BJ model ate a BRC model  p ylx Om m     B n  m      Bm m    we can cre  in which p ylx   We say that     n m    e n  m      is a Bayesian  embedded regression  classification  BERC  model ob tained from    e n  m       Several researchers have suggested using BERC mod els  at least implicitly  see Bishop        Chapter       and references therein   An example of a BERC model  Equation   shows that an BERC model is a poly nomial softmax regression on the indicator variables I   xI           I   Xn     Note that there are polynomial soft  max regressions that cannot be obtained from any Bayesian network   Although BERC models are convenient  we find non  obtained from a naive Bayes model is shown in Fig  trivial BERC models to be problematic   ure  lar  consider a BERC model    n m   obtained from      If a BERC model    n  m   is obtained from  a model which is itself a BERC model  we refer to   O n m    as a trivial BERC model  The BERC model  is Figure   is non triv ial  For any Bayesian network with finite state variables  it is not difficult to obtain its corresponding BERC model  Let X         Xn   Y  Xn  l          Xn be a total  m  Y appears as late as possible in the ordering   a non BERC model   Om  m    W hereas in the BERC  model  observations of X are necessarily uninformative about Bylx such observations may be informative in the original model   Om  m   Thus  in  constructing the  BERC model  we may be ignoring parts of our prior knowledge that are important for learning   ordering on the variables that is consistent with  To illustrate this point   such that  model for binary variables Y   The latter condition says that the node corresponding  In particu  ping from  Bm  to  Bx  consider the naive Bayes  XI  x   x    is shown in F igure     The map It is not        Heckerman and Meek  B y   B xUy   B xIY   B x IY     ll y   B x ly   B xly   B x lv   B y   B xijy   B xIY      B x lv      B y   B xijy   B xly      B x IY     l xJxx    B y   B x ly   B xly   B x IY     B y   B x IY   B xIY   B x lv    B xixx   B y   B x ly      B x IY       B x IY      B y   B xJiy       l xly       B x IY     B xix x    B y      B x ly     l x IY   B x IY     B y   l  B xJiy    B xly   B x IY    B xrxx   B y       B xJ IY    B xly      B x IY      B y   l  B xj IY    B xly      B x IY     O xrxx    B y       B xj IY    B xIY   B x IY     ll y      B xJiy    B xly   B x IY   Bm to Bx for the naive Bayes model where Y renders X    X   and X  mutually in   and p     Bm  m    l y   O xl  xz  xs   and B x  ly  to denote p yiBm  m   p x   xz  x  Bm  m    x ly    Figure    The mapping from  dependent  We use respectively   difficult to show that the rank of the Jacobian ma  observations of X often will influence the estimate of  Bm  for almost all values of  m  see  e g   Geiger et al          It follows that  for almost every point e n in Bm  there is an inverse map ping from Bx to Bm in a neighborhood around e n    Consequently  the possible values that Bm  and hence Byjx  can assume will depend on the value of Bx  and observations of X will inform By x through Bx   ferred to as regression classification models should  trix   f x  Bm is full   i e   equal to the number of non  redundant parameters in  More generally  conditional models often re  By x   not be used without consideration of variational de pendencies that may arise from the joint model   Learning Regression Classification     Models  Averaging Versus Selection  In general  given two variables  random or otherwise   Now that we have examined several classes of models  A and B  if the possible values that can be assumed by A depend on the value of B  then A is said to be variationally dependent on B  In our example   y x  for the regression classification task  let us concentrate  is variationally dependent on   x   Such variational  dependence is not limited to this example  For any model   Bm  m    if the rank of the Jacobian matrix  Bm to Bx is full  then E m  and  yjx  is variationally dependent on Bx  Geiger al         conjecture that  for naive Bayes mod  for the mapping from  on Bayesian methods for learning such models   First  consider model averaging  Given a random sam  ple  D from the  most everywhere full   and Geiger et al   Bm                  could identify only one naive  Hayes model in which the Jacobian matrix was not of full rank almost everywhere   Bm  p Bmlm  p DIBm  m  p   m ID  m    p Dim   to fix is al  In addition  Goodman  and  p m  p Dim  p miD    l m  p m   p Dim    els in which all variables are binary  the rank of the Jacobian matrix for the mapping from  m  using Bayes  rule   hence et  true distribution of Y and X  we com  pute the posterior distributions for each  where  Thus  the use of non  trivial BERC models at least those obtained from  most naive Bayes models is suspect   With these quantities in hand  we can determine the  Note that our remarks extend to non Bayesian anal yses   For example  in a classical analysis  a poly  nomial softmax regression should not be substituted  for and  a Bayesian network  In the former model   y x  E x  are variationally independent   model   y x and  E x  In the latter  are variationally dependent  and   The pa rameters Om are said to be locally identifiable given observations of X  e g   Goodman          conditional distribution for Y given X in the next case  to be seen by averaging over all possible model struc tures and their parameters   p ylx D   p ylx  D m     L P miD  p ylx  D  m  m        j p ylx  m  m  p BmiD  m dBm         Models   Selection Criteria for Regression  Note that joint analysis is handled i n  essentially  the  The term  P Yt  XtiYl  x         Yt    Xt    m  is the pre  Yt  xi   made by model structure m after  same way  For example  to determine the joint dis  diction for  tribution of Y and X in the next case to be seen  we  averaging over its parameters  Equation  use  p y  xJD   p y xJD m         LP mJD p y  xjD  m  m             The log  of this term can be thought of as the utility for this        Jp y xJ  m m  p BmJD m dem        Model averaging  however  is not always appropriate for an analysis   For example  only one or a few models may be desired for domain understanding or for fast prediction  In these situations  we select one or a few  prediction   Thus  a model structure with the highest log marginal likelihood is also a  model  structure that  is the best sequential predictor of the data logarithmic utility function   Let  D given the  us now consider local criteria that are more ap  propriate for the task of regression classification  To  keep the discussion  brief  we discuss only the  logarith  mic utility function  although other utility functions may  be  more reasonable for a given problem  At least   good  model structures from among all possible mod  two prequential criteria are reasonable  In one situa  cedure is known as model selection when one model is  As a result  we obtain a criterion that  els  and use them as if they were exhaustive  This pro  chosen  and selective model averaging when more than  tion  we  imagine that we see          al   call a  one model is chosen  Of course  model selection and selective model averaging are also useful when it is im  practical to average over all possible model structures  W hen our goal is model selection  a  good  model for joint analysis may not be a good model for re gression classification  and vice versa  Scores that de  c  N  CNM D m   Llogp y Jxi Y  x   Yt   xt   m                In another situation  we imagine that we first see all of  the input data x          XN   sequentially   criteria  A criterion commonly used for joint analy  class sequential criterwn   logp DJm       logp m     This criterion is global in the sense that it  CSC D m   N  L logp ydy           Yl    x           XN m          is equally sensitive to possible dependencies among all  variables  Criteria for regression classification  should be local in the sense that they concentrate on how well X classifies Y   In the following section  we examme  two such criteria   The criteria that we discuss  or  terms  of Dawid s  prequential method   To simplify  the          can  be  understood  predictive sequential  A simple example of this  Let us consider this example  discussion  let us assume that that  i s uniform  so that the joint anaiysis criterion  reduces to the log marginal likelihood  logp DJ m      From the chain rule of probability  the log marginal likelihood is given by  logp DJm   L logp yt  XtiY   XJ       Yl   Xt    m        The generalization straightforward   et  al           describe  parameter  a  set  of  independence  tion of the class sequential criterion is exponential in  the  sample size N   to non uniform model priors is  Monte Carlo or asymptotic tech  niques can be used to perform the computation for  large N  see  e g   Heckerman           We have applied both criteria to small Bayesian net works and small data sets chosen  arbitrarily   In all  cases  we have found that the two criteria differ  Nonetheless   there are conditions  under which the two  criteria are the same  In particular  we can rewrite the  two  criteria as follows   CNM D m   N     Spiegelhalter  Under these same assumptions  the exact computa  first   p m   decision tree structures   monitor can be computed efficiently in closed form   method  applied to joint analysis  yields the posterior probability criterion         used this criterion for selection among  and Dirichlet priors under with the conditional node  Regression Classification  in          assumptions essentially   Prequential Criteria for     Buntine  and then see the class data  Consequently  we obtain the following  sis is the logarithm of the relative posterior probabil  logp m  D     YI  Xt  sequentially  Spiegelhalter et  on ditional node monitor   fine  good  model structures are commonly known as  ity of the model structure  pairs  N     L log P  Yt XtlYl  x          Yt    Xt      m       p xtiY   x            Yl    Xt    m         The utility log x is also known as a scoring rule  Bernardo        shows that this scoring rule has several desirable properties         Heckerman and Meek  CSc D m    log  P YJ      yN XJ       xNim  p  x       XN Im            Friedman  N  and Goldszmidt  M          Building classifiers using Bayesian networks  In Proceed  Therefore  the two criteria will agree when  p x JY   XJ         Yl l  Xi    m      ings AAAI    Thirteenth National Conference  p xt XJ        Xi J  m        for l          N    It is not difficult to show that Equation    holds whenever  Bm  m  is a BRC model  Thus  the two criteria agree for BRC models       theory  The prequential approach  with Discus sion   Journal of the Royal Statistical Society A                   on Artificial Intelligence   Portland  OR  pages             AAAI Press  Menlo Park  CA   Geiger  D   Beckerman  D   and Meek  C          Asymptotic model selection for directed net works with hidden variables  In Proceedings of Twelth Conference on Uncertainty in Artificial     Intelligence   Discussion  Several researchers have demonstrated that Bayesian networks for both the joint analysis and regres sion  classification tasks provide better predictions when local distribution functions are encoded with a small number of parameters  as is the case with the use of decision trees  decision graphs  and causal independence models  e g   Friedman and Goldszmidt        Chickering et a          Meek and Heckerman         Despite our theoretical objections to the use of BERC models  they offer another parsimonious pa rameterization of local distribution functions  and may lead to better predictions in practice  For example  polynomial softmax regressions may be useful when a node and its parents are discrete  Experiments are needed to investigate these possibilities   Portland  OR  Morgan Kaufmann   Gelman  A   Carlin  J   Stern  H   and Rubin  D          Bayesian Data Analysis  Chapman and HalL Goodman  L          Exploratory latent structure analysis using both identifiable and unidentifi able models  Biometrika              Beckerman  D          A tutorial on learning Bayesian networks  Technical Report MSR TR        Mi crosoft Research  Redmond  WA  Revised Jan uary        Meek  C  and Beckerman  D          Structure and parameter learning for causal independence and causal interaction models  In Proceedings of Thirteenth Conference on Uncertainty in Artifi cial Intelligence   Acknowledgments  We thank Max Chickering for useful discussions  
 We show that if a strictly positive joint prob ability distribution for a set of binary random variables factors according to a tree  then ver tex separation represents all and only the in dependence relations encoded in the distribu tion  The same result is shown to hold also for multivariate strictly positive normal dis tributions  Our proof uses a new property of conditional independence that holds for these two classes of probability distributions     Introduction  A useful approach to multivariate statistical model ing is to first define the conditional independence con straints that are likely to hold in a domain  and then to restrict the analysis to probability distributions that satisfy these constraints  An increasingly pop ular way of specifying independence constraints are directed and undirected graphical models where inde pendence constraints are encoded through the topolog ical properties of the corresponding graphs  Lauritzen       Lauritzen and Spiegelhalter        Pearl        Whittaker         The key idea behind these specification schemes is to utilize the correspondence between vertex separation in graphs and conditional independence in probability  each vertex represents a variable and if a set of vertices Z blocks all the paths between two vertices  then the corresponding two variables are asserted to be condi tionally independent given the variables corresponding to Z  The success of graphical models stems in part from the fact that vertex separation and conditional in dependence share key properties which render graphs an effective language for specifying independence con straints  In this paper we show that when graphical models are trees and distributions are from specific classes  then the relationship between vertex separation and conditional independence is much more pronounced  More specifically  we show that if a strictly positive  Part of this work was done w hile sabbatical at Microsoft research   the  author was on  Christopher Meek Microsoft Research Redmond  WA         USA meek microsoft com  joint probability distribution for a set of binary ran dom variables factors according to a tree  then vertex separation represents all and only the independence relations encoded in the distribution  The same result is shown to hold also for multivariate strictly positive normal distributions  The class of Markov trees has been studied in several contexts  Practical algorithms for learning Markov trees from data have been used for pattern recogni tion  Chow and Liu         Geometrical properties of families of tree like distributions have been studied in  Settimi and Smith         F inally  the property of perfectness  when a graphical model represents all and only the conditional independence facts encoded in a distribution  is a key assumption in learning causal relationships from observational data  Glymour and Cooper            Preliminaries  Throughout this article we use lowercase letters for sin gle random variables  e g   x  y  z   and boldfaced low ercase letters  e g   x  y  z   for specific values for these random variables  Set of random variables are denoted by capital letters  e g   X  Y  Z   and their values are denoted by boldfaced capital letters  e g   X  Y  Z   For example  if Z     x  y  then Z stands for   x  y  where x is a value of x and y is a value of y  We use P X  as a short hand notation for P X  X   We say that P X  is strictly positive if VX P X       We use X y as a short hand notation for X U  y   Let X  Y and Z be three disjoint sets of ran dom variables having a joint probability distribution P X  Y  Z   Then  X and Y are conditionally inde pendent given Z  denoted by X l p Y I Z  if and only if VXVYVZ P X  Y  Z P Z    P X  Z P Y  Z   When P is strictly positive an equivalent definition is that X l p Y I Z holds if and only if VXVYVZ P X IZ    P XIY  Z   When P X  Y  Z  is a strictly positive joint normal distribution  then X and Y are conditionally indepen dent given Z if and only if Pxy Z     for every x EX   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS           and y E Y where Pxy Z is the partial correlation coef ficient of x an d y given Z  Cramer         The ternary relation X   lp Y I Z was introduced in  Dawid        and further studied in  e g   Spohn       Pearl and Paz       Pearl       Geiger and Pearl       Studeny         The ternary relation X  lp Y I Z satisfies the following five properties which are called the graphoid axioms  Pearl and Paz                     Decomposable transitivity  aB   lp De I c    a   lp e I BD    a   lp c I B V c   lp e I D       Symmetry  X  lp y I z    y   lp X I z          Decomposition  X  lp YW I z   X  lp y I z       Weak Union  X  lp YW I z   X  lp y I zw       We now prove that decomposable transitivity holds for strictly positive joint probability distributions of bi nary random variables and for strictly positive normal distributions  We then show that decomposable tran sitivity holds also for vertex separation in undirected graphs   Contraction  X   lp y I z    X   lp  I ZY    X  lp YWIZ       If P is strictly positive  then Intersection  X   lp y I zw    X  lp w I ZY    X   lp YW I z       w  The following property holds for joint normal distri butions P X Y  Z  c   Pearl         It also holds for discrete random variables if Z     and c is a binary random variable    The main result in this paper is a converse to Eq    under suitable conditions  W hen the converse holds we say that G is a perfect representation of P  To facilitate our argument we must first introduce a new property for conditional independence   Weak Transitivity  X   lp Y I Z    X   lp Y I Zc    X   lp c I z v c   lp y I z       A Markov network of a probability distribution   P x          xn  is an undirected graph G  V  E  where V     x          xn  is a set of vertices  one for each ran dom variable x   and E is a set of edges each repre sented as  x  xj  such that  x  xj  E E if and only if X    lp Xj I  x         Xn      x   Xj  A Markov tree is a Markov network where G is a tree  A key property of Markov networks is the following  Let A   lc B I C stand for the assertion that every path in G between a vertex in A and a vertex in B passes through a vertex in C  where A  B  and C are mu tually disjoint sets of vertices  Note that whenever A   lc B I C holds in G  A and B are  vertex  sepa rated by C  The ternary relation A   lc B I C satisfies all the properties we listed for A   lp B I C and some additional properties that do not hold for A   lp B I C  Pearl          Theorem    Pearl and Paz        Pearl      Let G be a Markov network of P x        Xn     and sup pose Intersection holds for P  Then A   la B I C implies A   lp B I C     for every disjoint set of vertices A  B  and C of G and their corresponding random variables in  x          Xn     New property of conditional independence  Theorem   Let a  c  e be binary random variables  B and D be  possibly empty  sets of binary random vari ables  and P a  c  e B D  be a strictly positive joint probability distribution for these random variables  Then aB   lp De I c    a   lp e I BD    a   lp c I B V c   lp e I D holds for P  Proof  We use a to denote a value for a  B to denote a value for a set of variables B  and a  and a  to denote the two values of a binary random variable a  Due to aB   lp De I c it follows that P a B c D e  P c    P a B c  P c  D e      for every value a c  e B D of the corresponding ran dom variables  Due to a   lp e I BD it follows that P a  B D e   P a  B D e     P  al  B  D  e   P a   B  D  e         for every value B D of B  D  Since c is a binary vari able P a B D e   P a B c  D e   P a B cl D e       Now  substituting Eq    into Eq      then substitut ing the result into Eq      yields using some divisions  which are allowed because P is strictly positive  that    a B  B D    a B    B D  where  and  P c  D e   P c  D e   P c  D e   P c  D el  Consequently  either a B      or  B D       Further more  since B and D are arbitrary values of B and D  respectively  we have  fB fD  a B      V  B D       which is equivalent to   fB a B       V   v D  B D       which is equivalent to a   lp c I B V c   lp e I D     B D       UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS  Theorem   Let a c  and e be continuous random variables  B and D be  possibly empty  sets of con tinuous random variables  and let P a  c  e B  D  be a strictly positive joint normal probability distribution for these random variables  Then  aB l p De I c    a l p e I BD a l p c I B V     c  l p e I D                 on the path    between a and c  or that a vertex b E B resides on the path    between c and e  In the first case vertices a and d are connected and the path that connects them does not include c  and in the second case vertex b and e are connected and the path that connects them does not include c  Thus  in both cases  aB l a De I c does not hold in G  contradicting our umptn     holds for P   Proof  We use a formal logical deduction style to em phasize that the only properties of normal distribu tions being used are the ones encoded in Symmetry  Decomposition  Intersection  Weak union  and Weak transitivity  Recall that weak transitivity holds for every normal distribution and that intersection holds for strictly positive normal distributions  The other properties hold for every probability distribution  We now derive the conclusion of Eq     from its an tecedents      aB l p De I c   Given     a l p e I BD   Given     a l p D I cB   W  union  Decomposition  and Symmetry on         B l p e I cD   W  union  Decomposition  and Symmetry on         a l p e I BDc   Weak union and Symmetry on         a l p c I BD V c l p e I BD   Weak transitivity on     and         a l p cD I B V Be l p e I D   Intersection and Symmetry on          and         a l p c I B V c l p e I D   Symmetry and Decomposition on         Theorem   Let a c  and e be distinct vertices of an undirected graph G  and let B and D be two  possibly empty  disjoint sets of vertices of G that do not include a  c or d  Then  aB l a De I c    a l a e I BD a l a c I B V     c  l a e I D       holds for G   Proof  Assume the conclusion of Eq     does not hold in G but its antecedents hold  Then  there exists a path    in G between a and c such that no vertices from B reside on     and there exists a path    in G between c and e such that no vertices from D reside on     If B and D are empty  then the concatenated path      contradicts a l a e I BD which is assumed to hold in G  Thus  we can assume either B or D are not empty  The concatenated path      contains a vertex from B or D   or both  because a l a e I BD is assumed to hold in G  Assume a vertex d E D resides     Perfect Markovian trees  We are ready to prove the main result   Theorem   Let G be a Markov tree for a probabil ity distribution P x      xn   If x       xn are bi nary random variables and P is a strictly positive joint probability distribution  or if x       Xn are continuous random variables and P is a strictly positive joint nor mal distribution then  in both cases  A  l a B I C if and only if  A  l p B I C        for every disjoint set of vertices A  B  and C of G and their corresponding random variables in   x      xn    Proof  Theorem   proves one direction of Eq      and so it remains to prove that A  l p B I C implies  A  l a B I C        To prove Eq     it is sufficient to show that a l p b I C implies a l a b I C for every pair of vertices a E A and b E B because A l p B I C implies VaVb a l p b I C and VaVb a l a b I C is equivalent by definition to A l a B I C  We proceed by contradiction  Let x and y be a pair of vertices for which there exists a set of vertices Z satisfying      x l p y I Z    x l a y I Z and such that x and y are connected with the shortest path among all pairs x  y  for which there exists a set Z  satisfying x  l p y  I Z     x  l a y  I Z   Suppose first that the path between x and y is merely an edge connecting the two vertices  We will now reach a contradiction by showing that G cannot be a Markov network of P  In particular  we show that P satisfies x l p y I Uxy where Uxy are all vertices except x and y  Let Ux be all the vertices on the x side of the edge  x  y  and Uy be the rest of the vertices    Namely  Ux are the vertices in the component of x after removing the edge  x y    Let B   Ux n Z and D   Uy n Z  We proceed by a formal deduction using properties of conditional independence     B l a Dy I x   By definition of B and D in G     B l p Dy I X   From     and since G is a Markov network of P     B l p y I xD   Weak union on         X l p y I BD  Z   BD and x l p y I Z is assumed        UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS          xB l p y I D  Intersection and Symmetry on     and         X l p y I D  Decomposition on         X l G D I y  By definition of D in G     X l p D I y  From     and since G is a Markov network of P     X l p yD      Intersection on     and          X l p Y      Decomposition on          X l G Uy I y  Definition of Uy      X l p Uy I y  From      and since G is a Markov network of P      X l p yUy     Contraction on      and           Ux l c yUy I x  Definition of Ux and Uy      Ux l p yUy I X  From      and since G is a Markov network of P      xUx l p yUy     Contraction and Symmetry on      and           x l p yiUxUy  Weak union and Symmetry on       Now suppose the path between x andy has more than one edge and that c is a vertex on this path  We reach a contradiction by showing that the pair x  y is not the closest pair of vertices that satisfy Eq     for some set Z   contrary to our selection of these vertices  Let B  D be a partition of Z such that B are the vertices in Z on the x side of c and D   Z   B  The rest of the derivation is a formal deduction using properties of conditional independence     xB l c Dy I c  By definition of B and D in G     xB l p Dy I c  From     and since G is a Markov network of P     x l p yiBD  Z   BD and x l p y I Z is assumed     X l p c I B v c l p y I D  Decomposable transitivity on     and           x l c c I B      c l p y I D  By definition of B and D in G  v     x l p c I B      x l c c I B       and        c l p y I D      c l c y I D  Each disjunct in Step     exhibits a pair of vertices that are closer to each other than x and y and yet satisfy Eq     for some set Z   Note that Step     uses De composable transitivity which holds if Xt          Xn are binary random variables and P is a strictly positive joint probability distribution  or if Xt          Xn are con tinuous random variables and P is a strictly positive joint normal distribution  as assumed  D     Discussion  Our proof uses a new property of conditional indepen dence that holds for the two classes of probability dis tributions we have focused on  The approach of using logical properties of conditional independence as a way of reasoning follows the approach taken by  Pearl and Paz        who analyzed the logical properties shared by vertex separation and conditional independence  The algorithmic consequence of Theorem   is that in order to check whether a Markov tree of P represents all the conditional independence statements that hold in P  assuming P satisfies Intersection and Decom posable transitivity  requires one to check whether for each edge  x  y  in G  x l p y     holds in P  Note that this test is more reliable and simpler than checking for each edge  x  y  in G  whether x l p y I Uxy holds  as the definition of a Markov tree requires  An open question remains as to what is the minimal computa tion needed to ensure that a general Markov network represents all the conditional independence statements that hold in P and what properties P needs to satisfy to accommodate these computations  A straightforward attempt to extend our results with out changing the tests or the assumptions on P is quite limited because we have counter examples to Theo rem   when G is a polytree  a directed graph with no underlying undirected cycles  and when P does not satisfy Intersection or Decomposable transitivity  These counter examples  together with the proof of Theorem    show that if G is a Markov tree of a prob ability distribution P  then G is a perfect represen tation of P if and only if P satisfies Intersection and Decomposable transitivity   
  We describe a graphical representation of probabilistic relationships an alternative to the Bayesian network called a dependency network  Like a Bayesian network  a depen dency network has a graph and a probabil ity component  The graph component is a  cyclic  directed graph such that a node s parents render that node independent of all other nodes in the network  The probabil ity component consists of the probability of a node given its parents for each node  as in a Bayesian network    We identify several ba sic properties of this representation  and de scribe its use in collaborative filtering  the task of predicting preferences  and the visu alization of predictive relationships  Keywords  Dependency networks  graphical models  inference  data visualization  exploratory data analy sis  collaborative filtering  Gibbs sampling    Introduction  The Bayesian network has proven to be a valuable tool for encoding  learning  and reasoning about probabilis tic relationships  In this paper  we introduce another graphical representation of such relationships called a dependency network  The representation can be thought of as a collection of regression classification models among variables in a domain that can be com bined using Gibbs sampling to define a joint distribu tion for that domain  The dependency network has several advantages and disadvantages with respect to the Bayesian network  For example  a dependency net work is not useful for encoding causal relationships and is difficult to construct using a knowledge based ap proach  Nonetheless  in our three years of experience with this representation  we have found it to be easy to  learn from data and quite useful for encoding and dis playing predictive  i e   dependence and independence  relationships  In addition  we have empirically verified that dependency networks are well suited to the task of predicting preferences a task often referred to as col laborative filtering  Finally  the representation shows promise for density estimation and probabilistic infer ence  The representation was conceived independently by Hofmann and Tresp         who used it for density es timation  and Hofmann        investigated several of its theoretical properties  In this paper  we summarize their work  further investigate theoretical properties of the representation  and examine its use for collabora tive filtering and data visualization  In Section    we define the representation and describe several of its basic properties  In Section    we de scribe algorithms for learning a dependency network from data  concentrating on the case where the local distributions of a dependency network  similar to the local distributions of a Bayesian network  are encoded using decision trees  In Section    we describe the task of collaborative filtering and present an empirical study showing that dependency networks are almost as accurate as and computationally more attractive than Bayesian networks on this task  Finally  in Sec tion    we show how dependency networks are ideally suited to the task of visualizing predictive relationships learned from data     Dependency Networks  To describe dependency networks and how we learn them  we need some notation  We denote a variable by a capitalized token  e g   X  X      Age   and the state or value of a corresponding variable by that same token in lower case  e g   x  x      age   We denote a set of variables by a bold face capitalized token  e g   X  X   Pa    We use a corresponding bold face lower case token  e g   x  x   pa   to denote an assignment of   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       state or value to each variable in a given set  We use p X xiY   y   or p xiy  as a shorthand  to denote the probability that X   x given Y   y  We also use p  x iy  to denote the probability distribution for X given Y  both mass functions and density functions   Whether p xiy  refers to a probability  a probability density  or a probability distribution will be clear from context     Consider a domain of interest having variables X    X          Xn     A dependency network for X is a pair     P  where q is a  cyclic  directed graph and P is a set of probability distributions  Each node in q corre sponds to a variable in X  We use X  to refer to both the variable and its corresponding node  The parents of node X   denoted Pa   correspond to those variables Pa  that satisfy     The distributions in P are the local probability distributions p  x  j p a     i              n  We do not require the distributions p   x  x       Xi   Xi         xn    i             n to be obtainable  via inference  from a sin gle joint distribution p x   If they are  we say that the dependency network is consistent with p  x   We shall say more about the issue of consistency later in this section   l  A Bayesian network for X defines a joint distribution for X via the product of its local distributions  A dependency network for X also defines a joint distri bution for X  but in a more complicated way via a Gibbs sampler  e g   Gilks  Richardson  and Spiegel halter         In this Gibbs sampler  we initial ize each variable to some arbitrary value  We then repeatedly cycle through each variable X          Xn  in this order  and resample each X  according to p x ix       Xi   Xi         Xn    p  x   lp a     We call this procedure an ordered Gibbs sampler  As described by the following theorem  also proved in Hofmann         this ordered Gibbs sampler defines a joint dis tribution for X  Theorem    An ordered Gibbs sampler applied to a dependency network for X  where each X  is discrete and each local distribution p   x  IPa   is positive  has a unique stationary joint distribution for X   xt  tth  Proof  Let be the sample of x after the iteration of the ordered Gibbs sampler  The sequence x   x         can be viewed as samples drawn from a homogenous Markov chain with transition matrix M having ele ments Mjli   p   xt       i    We use the termi nology of Feller         It is not difficult to see that M is the product M  Mn  where Mk is the  lo cal  transition matrix describing the resampling of Xk  jlxt                    according to the local distribution p xk IPak  The pos itivity of local distributions guarantees the positivity of M  which in turn guarantees     the irreducibility of the Markov chain and     that all of the states are ergodic  Consequently  there exists a unique joint dis tribution that is stationary with respect to M    Because the Markov chain described in the proof is irreducible and ergodic  after a sufficient number of iterations  the samples in the chain will be drawn from the stationary distribution for X  Consequently  these samples can be used to estimate this distribution  Note that the Theorem holds for both consistent and inconsistent dependency networks  Furthermore  the restriction to discrete variables can be relaxed  but will not be discussed here  In the remainder of this paper  we assume all variables are discrete and each local distribution is positive  In addition to determining a joint distribution  a de pendency network for a given domain can be used to compute any conditional distribution of interest that is  perform probabilistic inference  We discuss an algorithm for doing so  which uses Gibbs sampling  in Heckerman  Chickering  Meek  Rounthwaite  and Kadie         That Gibbs sampling is used for in ference may appear to be a disadvantage of depen dency networks with respect to Bayesian networks  When we learn a Bayesian network from data  how ever  the resulting structures are typically complex and not amenable to exact inference  In such situations  Gibbs sampling  or even more complicated Monte Carlo techniques  are used for inference in Bayesian networks  thus weakening this potential advantage  In fact  when we have data and can learn a model for X  dependency networks have an advantage over Bayesian networks  Namely  we can learn each local distribution in a dependency network independently  without regard to acyclicity constraints  Bayesian networks have one clear advantage over de pendency networks  In particular  dependency net works are not suitable for the representation of causal relationships  For example  if X causes Y  so that X and Y are dependent   the corresponding depen dency network is X     Y  that is  X is a parent of Y and vice versa  It follows that dependency networks are difficult to elicit directly from experts  Without an underlying causal interpretation  knowledge based elicitation is cumbersome at best  Another important observation about dependency net works is that  when we learn one from data as we have described learning each local distribution independently the model is likely to be inconsistent   In an extreme case  where     the true joint distribu    UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            tion lies in one of the possible models      the model search procedure finds the true model  and     we have essentially an infinite amount of data  the learned model will be consistent   A simple approach to avoid this difficulty is to learn a Bayesian network and apply inference to that network to construct the dependency network  This approach  however  will eliminate the advantage associated with learning dependency net works just described  is likely to be computationally inefficient  and may produce extremely complex local distributions  When ordered Gibbs sampling is applied to an inconsistent dependency network  it is important to note that the joint distribution so defined will de pend on the order in which the Gibbs sampler visits the variables  For example  consider the inconsistent dependency network X    Y  If we draw sample pairs  x  y  that is  x and then y then the resulting sta tionary distribution will have X and Y independent  In contrast  if we draw sample pairs  y  x   then the resulting stationary distribution may have X and Y dependent  The fact that we obtain a joint distribution from any dependency network  consistent or not  is comforting  A more important question  however  is what distri bution do we get  The following theorem  proved in Heckerman et al          provides a partial answer  Theorem    If a dependency network for X is con sistent with a positive distribution then the sta tionary distribution defined in Theorem   is equal to  p x    p x    When a dependency network is inconsistent  the situa tion is even more interesting  If we start with learned local distributions that are only slight perturbations  in some sense  of the true local distributions  will Gibbs sampling produce a joint distribution that is a slight perturbation of the true joint distribution  Hof mann        argues that  for discrete dependency net works with positive local distributions  the answer to this question is yes when perturbations are measured with an L  norm  In addition  Heckerman et al         show empirically using several real datasets that the joint distributions defined by a Bayesian network and dependency network  both learned from data  are sim ilar  We close this section with several facts about consis tent dependency networks  proved in Heckerman et al          We say that a dependency network for X is bi directional if X  is a parent of Xj if and only if Xj is a parent of X    for all X  and Xj in X  We say that a distribution is consistent with a dependency net work structure if there exists a consistent dependency network with that structure that defines  p x   p x    Theorem    The set of positive distributions consis tent with a dependency network structure is equal to the set of positive distributions defined by a Markov network structure with the same adjacencies  Note that  although dependency networks and Markov networks define the same set of distributions  their rep resentations are quite different  In particular  the de pendency network includes a collection of conditional distributions  whereas the Markov network includes a collection of joint potentials  Let pa  be the lh parent of node X    A consistent de pendency network is minimal if and only if  for every node X  and for every parent pa    X  is not indepen dent of pa  given the remaining parents of X    Theorem    A minimal consistent dependency net work for a positive distribution must be bi directional   p x      Learning Dependency Networks  In this section  we mention a few important points about learning dependency networks from data  When learning a dependency network for X  each local distribution for X  is simply a regression classification model  with feature selection  for x  with X   xi  as inputs  If we assume that each local distribution has a parametric model p  x   Pa   B    and ignore the de pendencies among the parameter sets Bt         n  then we can learn each local distribution independently us ing any regression classification technique for mod els such as a generalized linear model  a neural net work  a support vector machine  or an embedded re gression classification model  Heckerman and Meek         From this perspective  the dependency network can be thought of as a mechanism for combining re gression classification models via Gibbs sampling to determine a joint distribution  In the work described in this paper  we use decision trees for the local distributions  A good discussion of methods for learning decision trees is given in Breiman  Friedman  Olshen  and Stone         We learn a deci sion tree using a simple hill climbing approach in con junction with a Bayesian score as described in Fried man and Goldszmdit        and Chickering  Hecker man  and Meek         To learn a decision tree for X    we initialize the search algorithm with a single ton root node having no children  Then  we replace each leaf node in the tree with a binary split on some variable Xj in X  X    until no such replacement in creases the score of the tree  Our binary split on Xj is        UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       a decision tree node with two children  one of the chil dren corresponds to a particular value of Xj  and the other child corresponds to all other values of Xj  Our Bayesian scoring function uses a uniform prior distri bution for all decision tree parameters  and a structure prior proportional to KJ  where K     is a tunable pa rameter and f is the number of free parameters in the decision tree  In studies that predated those described in this paper  we have found that the setting K        yields accurate models over a wide variety of datasets  We use this same setting in our experiments  For comparison in these experiments  we also learn Bayesian networks with decision trees for local distri butions using the algorithm described in Chickering  Heckerman  and Meek         When learning these networks  we use the same parameter and structure priors used for dependency networks  We conclude this section by noting an interesting fact about the decision tree representation of local distri butions  Namely  there will be a split on variable X in the decision tree for Y if and only if there is an arc from X to Y in the dependency network that in cludes these variables  As we shall see in Section    this correspondence helps the visualization of data     Collaborative Filtering  In the remainder of this paper  we consider useful ap plications of dependency networks  whether they be consistent or not  The first application is collaborative filtering   CF   the task of predicting preferences  Examples of this task include predicting what movies a person will like based on his or her ratings of movies seen  predicting what new stories a person is interested in based on other stories he or she has read  and predicting what web pages a person will go to next based on his or her history on the site  Another important application in the burgeoning area of e commerce is predicting what products a person will buy based on products he or she has already purchased and or dropped into his or her shopping basket  Collaborative filtering was introduced by Resnick  la covou  Suchak  Bergstrom  and Riedl        as both the task of predicting preferences and a class of al gorithms for this task  The class of algorithms they described was based on the informal mechanisms peo ple use to understand their own preferences  For ex ample  when we want to find a good movie  we talk to other people that have similar tastes and ask them what they like that we haven t seen  The type of algo rithm introduced by Resnik et al          sometimes called a memory based algorithm  does something simi   lar  Given a user s preferences on a series of items  the algorithm finds similar users in a database of stored preferences  It then returns some weighted average of preferences among these users on items not yet rated by the original user  As done in Breese  Heckerman  and Kadie         let us concentrate on the application of collaborative filtering that is  preference prediction  In their pa per  Breese et al         describe several CF sce narios  including binary versus non binary preferences and implicit versus explicit voting  An example of explicit voting would be movie ratings provided by a user  An example of implicit voting would be know ing only whether a person has or has not purchased a product  Here  we concentrate on one scenario im portant for e commerce  implicit voting with binary preferences for example  the task of predicting what products a person will buy  knowing only what other products they have purchased  A simple approach to this task  described in Breese et al          is as follows  For each item  e g   prod uct   define a variable with two states corresponding to whether or not that item was preferred  e g   pur chased   We shall use     and     to denote not preferred and preferred  respectively  Next  use the dataset of ratings to learn a Bayesian network for the joint distribution of these variables X   X        Xn  The preferences of each user constitutes a case in the learning procedure  Once the Bayesian network is constructed  make predictions as follows  Given a new user s preferences x  use the Bayesian network to determine p Xi    lx   Xi      for each prod uct Xi not purchased  That is  infer the probability that the user would have purchased the item had we not known he did not  Then  return a list of recom mended products among those that the user did not purchase ranked by this probability  Breese et al         show that this approach out performs memory based and cluster based methods on several implicit rating datasets  Specifically  the Bayesian network approach was more accurate and yielded faster predictions than did the other methods  What is most interesting about this algorithm in the context of this paper is that only the probabilities p X     lx  X       are needed to produce the recom mendations  In particular  these probabilities may be obtained by a direct lookup in a dependency network  p Xi      lx  X          p Xi      lpa          where pai is the instance of Pai consistent with X  Thus  dependency networks are a natural model on which to base CF predictions  In the remainder of this section  we compare this approach with that based   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            Table    Number of users  items  and items per user for the datasets used in evaluating the algorithms  Users in tra mmg set Users in test set  Total items Mean items per user in training set  Dataset MS COM Nielsen                                              MSNHC                           on Bayesian networks for datasets containing binary implicit ratings  Datasets       We evaluated Bayesian networks and dependency net works on three datasets      Nielsen  which records whether or not users watched five or more minutes of network TV shows aired during a two week period in       made available courtesy of Nielsen Media Re search       MS  COM  which records whether or not users of microsoft com on one day in      visited ar eas  vroots    of the site  available on the Irvine Data Mining Repository   and     MSNBC  which records whether or not visitors to MSNBC on one day in      read stories among the most popular      stories on the site  The MSNBC dataset contains        users sampled at random from the approximate         users that visited the site that day  In a separate anal ysis on this dataset  we found that the inclusion of ad ditional users did not produce a substantial increase in accuracy  Table     provides additional information about each dataset  All datasets were partitioned into training and test sets at random           Evaluation Criteria and Experimental Procedure  We have found the following three criteria for collab orative filtering to be important      the accuracy of the recommendations      prediction time the time it takes to create a recommendation list given what is known about a user  and     the computational re sources needed to build the prediction models  We measure each of these criteria in our empirical com parison  In the remainder of this section  we describe our evaluation criterion for accuracy  Our criterion attempts to measure a user s expected utility for a list of recommendations  Of course  dif ferent users will have different utility functions  The measure we introduce provides what we believe to be a good approximation across many users  The scenario we imagine is one where a user is shown  a ranked list of items and then scans that list for pre ferred items starting from the top  At some point  the denote user will stop looking at more items  Let the probability that a user will examine the kth item on a recommendation list before stopping his or her scan  where the first position is given by k     Then  a reasonable criterion is  p k   cfaccuracyt  list    LP k  c k k       where c k is   if the item at position k is preferred and   otherwise  To make this measure concrete  we assume that p k  is an exponentially decaying function   p k   Tk a       where a is the  half life  position the position at which an item will be seen with probability      In our experiments  we use a     In one possible implementation of this approach  we could show recommendations to a series of users and ask them to rate them as  preferred  or  not preferred    We could then use the average of cfaccuarcy   list  over all users as our criterion  Be cause this method is extremely costly  we instead use an approach that uses only the data we have  In par ticular  as already described  we randomly partition a dataset into a training set and a test set  Each case in the test set is then processed as follows  First  we randomly partition the user s preferred items into in put and measurement sets  The input set is fed to the CF model  which in turn outputs a list of recommen dations  Finally  we compute our criterion as N           Lk cS k   cfaccuracy hst    K   N L    i l L k      p k  p k        where N is the number of users in the test set  K  is the number of preferred items in the measurement set for user i  and c  k is   if the kth item in the recommen dation list for user i is preferred in the measurement set and   otherwise  The denominator in Equation   is a per user normalization factor  It is the utility of a list where all preferred items are at the top  This nor malization allows us to more sensibly combine scores across measurement sets of different size  We performed several experiments reflecting differing numbers of ratings available to the CF engines  In the first protocol  we included all but one of the preferred items in the input set  We term this protocol all but    In additional experiments  we placed       and    pre ferred items in the input sets  We call these protocols given    given    and given     The all but   experiments measure the algorithms  per formance when given as much data as possible from   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       each test user  The various given experiments look at users with less data available  and examine the perfor mance of the algorithms when there is relatively little known about an active user  When running the given m protocols  if an input set for a given user had less than m preferred items  the case was eliminated from the evaluation  Thus the number of trials evaluated under each protocol varied   Table    CF accuracy for the MS COM  Nielsen  and MSNBC datasets  Higher scores indicate better per formance  Statistically significant winners are shown in boldface  MS COM  Algorithm BN DN  All experiments were performed on a     MHz Pen tium II with     MB of memory  running the NT     operating system            Given                Tables   and   compare the two methods with the remaining criteria  Here  dependency networks are a clear winner  They are significantly faster at prediction sometimes by almost an order of magnitude and require substantially less time and memory to learn   AllBut                                         Baseline                              Given   Given                AllBut          GivenS              RD                            Baseline                              Nielsen  Algorithm BN DN  Table   shows the accuracy of recommendations for Bayesian networks and dependency networks across the various protocols and three datasets  For a com parison  we also measured the accuracy of recommen dation lists produced by sorting items on their overall popularity  p X        The accuracy of this approach is shown in the row labeled  Baseline   A score in boldface corresponds to a significantly significant win ner  We use ANOVA  e g   McClave and Dietrich        with a       to test for statistical significance  When the difference between two scores in the same column exceed the value of RD  required difference   the difference is significant   The magnitudes of accuracy differences  however  are not that large  In particular  the ratio of   cfac curacy BN    cfaccuracy DN   to  cfaccuracy BN  cfaccuracy Baseline   averages    S percent across the datasets and protocols   Given                RD  Results  From the table  we see that Bayesian networks are more accurate than dependency networks  This re sult is interesting  because there are reasons to ex pect that dependency networks will be more accurate than Bayesian networks and vice versa  On the one hand  the search process that learns Bayesian net works is constrained by acyclicity  suggesting that de pendency networks may be more accurate  On the other hand  the conditional probabilities used to sort the recommendations are inferred from the Bayesian network  but learned directly in the dependency net work  Therefore  dependency networks may be less accurate  because they waste data in the process of learning what could otherwise be inferred  For this or perhaps other reasons  the Bayesian networks are more accurate   GivenS                                   MSNBC  Algorithm BN DN  Given   GivenS                          S   Given                RD                             Baseline                              AllBut             S  Overall  Bayesian networks are slightly more accurate but much less attractive from a computational per spective     Data Visualization  Bayesian networks are well known to be useful for visualizing causal relationships  In many circum stances  however  analysts are only interested in predictive that is  dependency and independency relationships  In our experience  the directed arc se mantics of Bayesian networks interfere with the visu alization of such relationships  As a simple example  consider the Bayesian network X     Y  Those familiar with the semantics of Bayesian networks immediately recognize that observ ing Y helps to predict X  Unfortunately  the untrained individual will not  In our experience  this person will interpret this network to mean that only X helps to predict Y  and not vice versa  Even people who are expert in d separation semantics will sometimes have difficulties visualizing predictive relationships using a Bayesian network  The cognitive act of identifying a node s Markov blanket seems to interfere with the vi sualization experience  Dependency networks are a natural remedy to this   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            problem  If there is no arc from X to Y in a depen dency network  we know immediately that X does not help to predict Y   Table    Number of predictions per second for the MS COM  Nielsen  and MSNBC datasets  MS COM  Algorithm BN DN  Given              Given              Algorithm BN DN  Given               Given               Algorithm BN DN  Given              Given              Given               AllBut              Nielsen  Given                AllBut               MSNBC  Given              AllBut              Table    Computational resources for model learning  MS COM  Algorithm BN DN  Memory  Meg            Algorithm BN DN  Memory  Meg           Algorithm BN DN  Memory  Meg            Learn Time  sec                Nielsen  Learn Time  sec             MSNBC  Learn Time  sec                Figure   shows a dependency network learned from a dataset obtained from Media Metrix  The dataset contains demographic and internet use data for about       individuals during the month of January       On first inspection of this network  an interest ing observation becomes apparent  there are many  predictive  dependencies among demographics  and many dependencies among frequency of use  but there are few dependencies between demographics and frequency of use  Over the last three years  we have found numerous interesting dependency relationships across a wide va riety of datasets using dependency networks for visu alization  In fact  we have given dependency networks this name because they have been so useful in this regard  The network in Figure   is displayed in DNViewer  a dependency network visualization tool developed at Microsoft Research  The tool allows a user to display both the dependency network structure and the de cision tree associated with each variable  Navigation between the views is straightforward  To view a de cision tree for a variable  a user simply double clicks on the corresponding node in the dependency network  Figure   shows the tree for Shopping Freq  An inconsistent dependency net learned from data of fers an additional advantage for visualization  If there is an arc from X to Y in such a network  we know that X is a significant predictor of Y  significant in what ever sense was used to learn the network  Under this interpretation  a uni directional link between X and Y is not confusing  but rather informative  For example  in Figure    we see that Sex is a significant predictor of Socioeconomic status  but not vice versa an in teresting observation  Of course  when making such interpretations  one must always be careful to recog nize that statements of the form  X helps to predict Y  are made in the context of the other variables in the network  In DNViewer  we enhance the ability of dependency networks to reflect strength of dependency by includ ing a slider  on the left   As a user moves the slider from bottom to top  arcs are added to the graph in the order in which arcs are added to the dependency net work during the learning process  When the slider is in its upper most position  all arcs  i e   all significant dependencies  are shown    UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            Figure    A dependency network for Media Metrix data  The dataset contains demographic and internet use data for about       individuals during the month of January       The node labeled Overall Freq represents the overall frequency of use of the internet during this period  The nodes Search Freq  Edu Freq  and so on represent frequency of use for various subsets of the internet       r          J                   C l                 i  J                NoM                      ahw                 other       ott  r          Low          Figure    The decision tree for Shopping Freq obtained by double clicking that node in the dependency network  The histograms at the leaves correspond to probabilities of Shopping Freq use being zero  one  and greater than one visit per month  respectively    UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            r  I I  I  I s  irko  Figure    The dependency network in Figure   with the slider set at half position  Figure   shows the dependency network for the Media Metrix data with the slider at half position  At this setting  we find the interesting observation that the dependencies between Sex and XXX Freq  frequency of hits to pornographic pages  are the strongest among all dependencies between demographics and internet use     Summary and Future Work  We have described a new representation for probabilis tic dependencies called a dependency network  We have shown that a dependency network  consistent or not  defines a joint distribution for its variables  and that models in this class are easy to learn from data  In particular  we have shown how a dependency network can be thought of as a collection of regres sion classification models among variables in a domain that can be combined using Gibbs sampling to define a joint distribution for the domain  In addition  we have shown that this representation is useful for col laborative filtering and the visualization of predictive relationships  Of course  this research is far from complete  There are many questions left to be answered  For example   what are useful models  e g   generalized linear models  neural networks  support vector machines  or embed ded regression classification models  for a dependency network s local distributions  Another example of par ticular theoretical interest is Hofmann s        result that small    norm perturbations in the local distribu tions lead to small    norm perturbations in the joint distributions defined by the dependency network  Can this result be extended to norms more appropriate for probabilities such as cross entropy  Finally  the dependency network and Bayesian net work can be viewed as two extremes of a spectrum  The dependency network is ideal for situations where the conditionals p x lx   x   are needed  In con trast  when we require the joint probabilities p x   the Bayesian network is ideal because these probabil ities may be obtained simply by multiplying condi tional probabilities found in the local distributions of the variables  In situations where we need probabili ties of the form p ylx  y   where Y is a proper subset of the domain X  we can build a network structure that enforces an acyclicity constraint among only the variables Y  In so doing  the conditional probabilities p ylx  y  can be obtained by multiplication    UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       Acknowledgments  We thank Reimar Hofmann for useful discussions  Datasets for this paper were generously provided by Media Metrix  Nielsen Media Research  Nielsen   Mi crosoft Corporation  MS COM   and Steven White and Microsoft Corporation  MSNBC   
