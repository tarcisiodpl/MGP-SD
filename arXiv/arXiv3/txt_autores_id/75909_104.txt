 In previous work  we pointed out the limitations of standard Bayesian networks as a modeling framework for large  complex domains  We proposed a new  richly structured modeling language  Object oriented Bayesian Networks  that we argued would be able to deal with such domains  However  it turns out that OOBNs are not expressive enough to model many in teresting aspects of complex domains  the existence of specific named objects  arbitrary relations between ob jects  and uncertainty over domain structure  These as pects are crucial in real world domains such as battle field awareness  In this paper  we present SPOOK  an implemented system that addresses these limitations  SPOOK implements a more expressive language that allows it to represent the battlespace domain naturally and compactly  We present a new inference algorithm that utilizes the model structure in a fundamental way  and show empirically that it achieves orders of magni tude speedup over existing approaches      Introduction  Bayesian networks are a graphical representation language in which complex probabilistic models can be represented compactly and naturally  The power of the representation comes from its ability to capture certain structure in the do main  the locality of influence among different attributes  This structure  which is formalized as probabilistic condi tional independence  is the key to the compact representa tion  It also supports effective inference algorithms  In previous work  KP     we argued that  despite their power  Bayesian networks  BNs  are not adequate for deal ing with large complex domains  Such domains require an explicit representation of additional types of structure   the notion of an object  a complex structured domain en tity with its own properties  and the notion of a class of objects  that captures properties common to an entire set of similar objects  Our Object Oriented Bayesian Networks  OOBNs  extended the language of BNs with these addi tional concepts   By introducing objects and classes  OOBNs provide us with a representation language that makes it much easier to specify large models in a compact and modular way  How ever  these new concepts also reveal the shortcomings of the OOBN framework  As soon as we have objects  we want to encode various relationships between them that go beyond part whole  For example  we may have an object representing some physical location  with its own proper ties   We may well wish to assert that another object  such as a military unit  is at the location  This relation is not a part whole relation  and thus does not fit naturally into the OOBN framework  In  KP     we described a language that allows a much richer web of relations between objects  It also extends the expressive power of the language in several significant ways  For example  by making relations first class citizens in our ontology  we can express knowledge we might have about them  just as importantly  we can express lack of knowledge about relations  For example  we can express the fact that we do not know which of several locations a unit is at  we can even quantify this uncertainty using prob abilities  We can also express uncertainty about the number of subunits that a unit has  Although the additional expressive power provided by OOBNs and its extensions is natural and even desirable  one still needs to make the case that it actually helps model real life domains  We need also to show that we have the capability to answer interesting queries using a rea sonable amount of computation  In this paper  we address both of these points  We present an implemented system called SPOOK  System for Probabilistic Object Oriented Knowledge  We show that it can be used to represent and reason about a real world complex domain  The domain we have chosen for this test is military situa tion assessment  ML     This domain is notoriously chal lenging for traditional Bayesian networks  It involves a large number of objects  related to each other in a variety of ways  There is also a lot of variability in the models appropriate to different situations  We started with a set of Bayesian networks constructed for this domain by lET  Inc         Pfeffer  Koller  Milch  and Takusagawa  We then used our SPOOK language to construct a single uni fied model for this domain  one with a rich class hierarchy  The resulting model was compact  modular  natural  and easy to build  We also investigate our ability to answer queries effectively using such a complex model  One approach  the one we proposed in  KP     is based on knowledge based model construction  KBMC   WBG     converting the complex model into a traditional BN  and using standard BN infer ence  The BNs constructed from a complex SPOOK model are large enough to stretch the limitations of existing in ference algorithms  Even the network for a single SCUD battalion involves over      nodes and requires    minutes to answer a query  A network for many interacting units in a battlespace would be orders of magnitude larger  The challenges posed by real life complex models require a more sophisticated approach to inference  In our origi nal OOBN paper  KP     we described an inference algo rithm that makes use of the structure made explicit in the more expressive language  the encapsulation of one object within another  and the model reuse implied by the class hierarchy  The OOBN algorithm is too simple to apply to our much richer SPOOK language  However  it turns out that many of the same ideas can be adapted to this task  We present a new inference algorithm  implemented in the sys tem  that utilizes encapsulation and reuse in a fundamental way  We present experimental results for our algorithm on realistic queries over the battlespace model  and show that by utilizing encapsulation and model reuse  we obtain orders of magnitude speedup over the KBMC approach     The SPOOK Language  In this section we review the SPOOK representation lan guage  The language presented here is based on the prob abilistic frame systems of  KP     it extends the language of object oriented Bayesian networks  OOBNs   KP    in several important ways  The basic unit in the SPOOK language is an object  An ob ject has attributes  which may be either simple or complex  A simple attribute is a function from objects to values in some specified domain  it is similar to a variable in a stan dard BN  A complex attribute represents a relationship be tween objects  If the value of complex attribute A of object X is Y  notated X  A   Y    the relation A X Y   holds  Complex attributes may be single valued  corresponding to functional relationships  or multi valued  corresponding to general binary relations  A complex attribute may have an inverse  if the inverse of attribute A is B  andY is a value of X A  then X must be a value ofY B  For example  a scud battalion object has a simple attribute under fire  whose value ranges over   none light  heavy   It has a single valued complex attribute at location  whose  value is an object corresponding to the location of the bat talion  It has a multi valued complex attribute has battery  each of whose values is a battery in the battalion  The has battery attribute has an inverse in battalion  which is a single valued complex attribute of a battery object  If battery   is a value of scud battalion charlie has battery  then battery Lin battalion   scud battalion charlie  The dot nota tion can be extended to attribute chains A  A       Ak  denoting the composition of the relations A       Ak  If A        Ak   are single valued complex attributes  and Ak is a simple attribute  we call the attribute chain simple  The probability model for an object is specified by defining a local probability model for each of its simple attributes  As in BNs  The local probability model consists of a set of parents  and a conditional probability distribution  CPO   A parent can be either another simple attribute of the same ob ject  or a simple attribute chain  Allowing attribute chains as parents provides a way for the attributes of an object to be influenced probabilistically by attributes of related ob jects  If two objects are inverses of each other  each can be influenced by the other  Continuing our example  the under fire attribute of scud battalion has a parent at location defense support  and the CPO for under fire indicates that the battalion is more likely to be under heavy fire if it is in a location with poor defense support  The battery object has a hit attribute whose parent is in battalion under fire  thus creating an in direct chain of influence from the location  through the battalion at the location  to the battery in the battalion  Since in battalion is an inverse of has battery  the battalion can in turn be influenced by the battery it contains  For example the attribute scud battalion next activity depends on has battery launch capability   Section     explains how to specify dependence on multi valued attributes        Classes and instances  In SPOOK  a probability model is associated with a class  which corresponds to a type of entity in the domain  An instance of a class corresponds to a domain entity of the appropriate type  and derives its probability model from its class  We use object to denote either a class or an instance  For example  scud battalion is a class and scud battalion charlie is an instance of scud battalion  Classes provide reusable probability models  that can be applied to many different objects  Classes are organized in a class hierarchy  A subclass inherits the probability model of its superclass  and it can also override or extend it  The inheritance mechanism facilitates model reuse by allowing the commonalities between different classes to be captured in a common superclass  For example  the battalion super class captures those features common to all battalions  Classes also provide a type system for the SPOOK language    SPOOK  System for probabilistic object oriented knowledge  Every complex attribute A has a type T A   and for any object X  the value of X  A must be an instance ofT A   If no particular value is specified for X  A  we use the unique names assumption  which states that the values of X  A are generic  unnamed instances ofT A   that are not related in any other way to the instances in the model  The unique names assumption implies that in the class models  no two battalions can be at the same location  In stances provide a way to specify such webs of inter related objects  In this example  there are two battalion instances  battalion   and battalion    and a location instance location a  By stating that battalion l  at location   location a and that battalion   at location   location a  the objects are hooked to gether appropriately       Multi valued attributes    structural uncertainty  As discussed above  a complex attribute can be multi valued  but a parent of a simple attribute must be a simple attribute chain  in which the attributes are single valued  In order to allow the attributes of an object to be influenced by attributes of related objects when the relationship is multi valued  we introduce a quantifier attribute  A quantifier attribute has the form   A  p   v    where A is a multi valued complex attribute  p is a simple attribute chain  and v is a possible value of p  If X is an object with attribute A  X    A  p   v  denotes the number of objects Y such that A X Y   II Y  p   v  Quantifier attributes allow attributes of an object to depend on aggregate properties of a set of related objects  Con tinuing our running example  we may specify that a par ent of scud battalion next mission is the quantifier attribute   has battery launch capability high   The value of the quan tifier is determined by the value of launch capability for each of the batteries in the battalion  If the set of batteries in the battalion is fixed  the quantifier simply expresses an aggre gate property of the set  However  we may also have uncer tainty over the number of batteries in the battalion  This is an example of structural uncertainty  which is uncertainty not only over the properties of objects in the model but over the relational structure of the model itself  The type of structural uncertainty encountered in this ex ample is number uncertainty  uncertainty over the number of values of a multi valued complex attribute  Number un certainty is integrated directly into the probability model of an object using a number attribute  If A is a multi valued complex slot  the number attribute  A denotes the number of values of A  A number attribute is a standard random variable whose range is the set of integers from   to some upper bound n  It can participate directly in the probability model like any other variable  In our exam ple  scud battalion  has battery depends probabilistically on scud battalion country  Under number uncertainty  the value of a quantifier depends on the value of the number attribute        as well as on the values of the related objects  Another kind of structural uncertainty is reference uncer tainty  which is uncertainty over the value of a single valued complex attribute  For example  we may have un certainty over whether a battalion is located in a mountain or a desert location  As with number uncertainty  reference uncertainty can be introduced directly into the probability model of an object using a reference attribute  If A is a single valued complex attribute whose value is uncertain  R A  is a reference attribute whose range determines the possible values of A  An element of the range ofR A  may either be a subclass C of T A   or an instance I of T A   If the value of X R A  is the type C  then the value of X  A is a generic instance of C  if the value of X R A  is the instance I  then the value of X  A is I  As with number attributes  reference attributes participate in the probabil ity model  and can depend on and be influenced by other attributes  We call this type of uncertainty  reference un certainty  because we do not know which object is being referred to when we refer to the value of A  A SPOOK knowledge base consists of a set of classes and instance models  In  KP     we defined a data structure called a dependency graph that can be used to make sure that all the probabilistic influences  including the influences between different objects  are acyclic  We defined a se mantics for SPOOK models  based on a generative process that randomly generates values for attributes of instances in the domain  including number and reference attributes  We showed that if the dependency graph is acyclic  then the knowledge base defines a unique probability distribu tion over the values of all simple attributes of all named instances in the KB     Modeling the Battlespace Domain  To demonstrate the representational power of the SPOOK language  we implemented a model for reasoning about military units in a battlespace  In  LM     Mahoney and Laskey describe how they model this domain using net work fragments  In this section  we introduce the domain  discuss why it is difficult to model using BNs  and describe how we modeled it using SPOOK  The purpose of the battlespace model is to reason about the locations and status of military units based on intelligence reports  Our model deals specifically with missile battal ions  the batteries within those battalions  and the individ ual units   vehicles  radar emplacements  missile launch ers  etc    within the batteries  A scenario consists of multiple battalions  some of which may be at the same lo cation  A battalion typically has four batteries  each with about    units  Thus  the model for a battalion includes about     units  and a scenario may include      units  Let us consider trying to model our domain directly with        Pfeffer  Koller  Milch  and Takusagawa  a BN  With four or five variables for each unit  a flat BN for a battalion model will typically contain over a thousand nodes  The sheer size of this network is a major obstacle to its construction  In addition  the resulting BN will be too rigid for practical purposes  The configuration of a battal ion is highly flexible  with the exact number of units of each type varying considerably between different battalions  These difficulties have led to an alternative approach  in which several different BNs are used  one for each aspect of the model  Figure   a  shows a Bayesian network for an SA  battalion  There are similar networks for other types of units  such as Scud battalions and batteries  Although a Scud battalion contains Scud batteries  the battalion model does not replicate all the details of the battery model  rather  it summarizes the status of all the batteries with nodes  in dicating the initial number of batteries  the number of dam aged batteries  and the current number  These summaries serve two purposes  to keep the network reasonably sim ple  and to account for changing model configuration by making the initial number of subunits a variable  A major disadvantage of this approach is that it is very difficult to reason between the different networks  The only way to reason from one network to another is to reach conclusions about the state of variables in one net work and assert them as evidence in the other network  For example  the only way to transfer conclusions from a battery to a battalion is to condition one of the summary nodes in the battalion model  going from one battery to an other requires conditioning the battalion model  reasoning about the battalion  and then conditioning the other bat tery model  This type of reasoning has no sound proba bilistic semantics  There is no way to combine evidence about multiple different units in a probabilistically coher ent manner  Furthermore  this type of reasoning between fragments must be performed by a human or a program  It requires some model of the relationship between the frag ments  e g   that the status node of the battery model is re lated to the number damaged batteries node of the battalion model  Nowhere is this relationship made explicit  Another disadvantage is that multiple BNs do not allow us to take advantage of redundancy within a model and simi larities between models  For example  the battalion model in Figure I  a  contains many similar substructures  summa rizing groups of units of different kinds  In addition  differ ent battalions may all have substructures describing their locations  as shown in the bottom right corner of the figure  In the multiple BNs approach  the only mechanism for ex ploiting these redundancies is cut and paste  This makes it very hard to maintain these models  because each time one of the reused components is changed  it must be updated in all the different networks that use it  OOBNs solve the problems inherent in the multiple BN ap proach  By allowing a battalion to contain a battery as a  sub object  we can easily have the battalion model encom pass the complete models of the different batteries in it  which in turn contain complete models of their subunits  without making the battalion model impossibly complex  We can then reason between different objects in the part of hierarchy in a probabilistically coherent manner  In addi tion  by allowing us to define a class hierarchy  OOBNs allow us to exploit the redundancy in the model  However  the language of OOBNs is quite restricted  in a way that is problematic in our domain  If we want to model the effect of a unit s location on the unit  we need to rep resent the relationship between the unit and its location  In our model  this was the only relationship that did not fall into the part of hierarchy  but richer models of the bat tlespace domain require more sophisticated relationships  such as that between a unit supporting another unit  In addition  our domain requires multi valued attributes and quantifiers  A battalion contains several batteries  and each battery contains several units of different types  The higher level objects do not depend directly on the individual lower level objects  but only on aggregate properties of the set of objects  expressed through quantifier attributes  The abil ity to create named instances and hook them together via relations is also important in our domain  as illustrated by the example from the previous section of two battalions in the same location  Finally  the battlespace domain contains a great deal of structural uncertainty  in particular number uncertainty over the number of subunits  One may also have reference uncertainty as to the location of a unit  SPOOK includes all the capabilities of OOBNs to repre sent part of and class hierarchies  and also handles relations between objects  multi valued attributes  named instances  and structural uncertainty  all of which cannot be expressed in OOBNs  Our SPOOK model of the battlespace do main includes a natural class hierarchy  with Military Unit  Environment  Location and Weather as root classes  The Battalion  Battery  Group  and Unit families are all part of the Military Unit hierarchy  Similarly  part of relationships are easy to model in SPOOK using inverse relations  The has battery attribute of a battalion  and the in battalion at tribute of a battery  are inverses  allowing the battalion and its contained battery to influence each other  Batteries do not contain individual units directly  but instead contain a Group object for each type of unit  For instance  a battery has  among others  groups of missile launchers  command vehicles  and anti aircraft artillery units  Each Group has a multi valued attribute relating it to the individual units  as well as a number attribute and a set of quantifier attributes that summarize the status of the units  Using Group objects is convenient because we summarize the same attributes for all types of units   An object of class  Unit has simple attributes reported  and reported damaged  These attributes are influenced by the location of the battalion   specifioperational  damaged   SPOOK  System for probabilistic object oriented knowledge  Figure            a  SA  Battalion Bayesian network   b  SPOOK model of Scud Battalion  cally  the location s support for concealment and defense   and by the battalion being under fire  We repre sent these influences in SPOOK by specifying  for exam ple  at location defense support as a parent of damaged  The number of damaged units in turn influences the battery s operational attribute  and a quantifier slot that counts the number of operational batteries in a battalion influences the battalion s current activity  Subclassing gives us the ability to provide models for certain types of units that are sim ilar to the general unit model but not exactly the same  For instance  Missile Launcher has an additional activity at tribute that indicates whether it is launching  reloading  or idle  While we only modeled the domain up to the battal ion level  we could easily extend our model to higher level groups in the military hierarchy  In our current model  all units in a battalion share a com mon environment  which is referred to by the in environment attribute of the battalion  The environment is composed of Location and Weather objects  which between them deter mine the current support of the environment for various ac tivities such as moving  hiding and launching missiles  We could have associated a different environment with each battery or unit  making locations of lower level objects re lated probabilistically to higher level objects  To give an example of the power of reasoning at multiple levels of the hierarchy and between different objects  we present a series of queries we asked the model  First we queried the prior probability that a particular Scud battery was hit  and found it to be       We then observed that the containing battalion was under heavy fire  and the proba bility that the battery was hit went up to       We then observed  however  that none of the launchers in the bat tery had been reported to be damaged  and the probability that the battery was hit went down to       We then ex plained away this last observation  by observing that the environment has good support for hiding  the probability  that the battery was hit went back up to       This example combines causal  evidential and intercausal reasoning  and involves battery and battalion objects  individual launcher objects  the launcher group  and the environment object     Inference  In the previous sections we described the SPOOK language  and how we used it to model the battlespace awareness do main  Of course  in order for the language to be useful  we need an efficient algorithm for performing inference in it  Ideally  we would like the language features to lend themselves to efficient inference  Indeed  as we argued in  KP     one of the measures of a successful represen tation language is that it makes the structure of the domain explicit  so that it can be exploited by an appropriately de signed inference algorithm  One way to perform inference in SPOOK is to use the technique of knowledge based model construction  KBMC   WBG     In this approach  we construct a BN that represents the same probability distribution as that de fined by our model  and answer queries in this BN using standard BN inference algorithms  We described the KBMC process for our language in detail in  KP     and showed that if the dependency graph is acyclic  it always terminates  While the KBMC approach provides a sound and complete method for answering queries in SPOOK it is somewhat un satisfactory  It fails to exploit the language s ability to make explicit the structure of the domain  All notions of objects and relationships are lost when the model is turned into a fiat BN  In  KP     we argued that the object structure of a model can and should be exploited for efficient inference  We argued that two aspects of the structure in particular should be exploited  the fact that the internal state of each        Pfeffer  Koller  Milch  and Takusagawa  object is encapsulated from the remainder of the model via its interface  and that locality of interaction typically in duces small interfaces  and the fact that the same type of object may appear many times in a model  Since the flat BN produced by KBMC has no notion of an object  the KBMC algorithm cannot exploit these structural features  We now present an object based inference algorithm that does exploit the structural features of a model  The algo rithm is based on the ideas presented in  KP     but it is significantly more complex due to the increased expressiv ity of our language  The added complexity arises princi pally from four new language features  First  the  multi centeredness  of the language implies that each object can be accessed by a multitude of other objects  in a variety of different ways  In OOBNs  we assumed that each type of object had a unique set of inputs and outputs  and that we could precompute a conditional distribution over the outputs given the inputs  This is no longer the case  Because an object can be accessed in many different ways  its outputs can be arbitrarily complex  In addition  its in puts are not fixed  but are determined by the way the object is accessed  and the particular set of outputs required  as will be explained below  Thus  for each object referred to by another object  our algorithm must determine its inputs and outputs on the fly  during the processing of a query  The second relevant language feature is the ability to cre ate instances and hook instances together via relations  As we shall explain later  this property implies that encapsu lation  although still present  no longer holds in exactly the same way as in OOBNs  The third feature is multi valued attributes and quantifier attributes that depend on them  which do not appear in OOBNs  and require a new treatment  The final complicating feature is structural uncertainty  The naive approach to dealing with structural uncertainty  that could be applied to OOBN models  is as follows  To com pute P Q   enumerate all possible structural hypotheses h  and compute P Q I h  for each such hypothesis  P Q  is then equal to Lh P h P Q I h   Unfortunately  the num ber of structural hypotheses is exponential in the number of structural variables  rendering this approach completely infeasible with more than a very small number of structural variables  In the battlespace awareness domain  the number of structural variables is large  since we have uncertainty over the number of units in many different groups  There fore we need a much better way of doing inference with structural uncertainty  Our inference algorithm is related to the KBMC algo rithms  but its recursive nature makes it quite different  so we describe it in detail  It is fairly complex  so we present it in stages  We begin with the basic algorithm  for class objects without multi valued complex attributes  we then extend it to deal with instances  and finally we show how  we deal with multi valued attributes  quantifier attributes  number uncertainty and reference uncertainty       Basic algorithm  Our inference algorithm is recursive  The main function of the algorithm answers a query on an object  The key to understanding the algorithm is to understand how the function is recursively called  and the relationship between the object calling the function and the object on which it is called  Suppose that  during the process of solving a query on an object X  we encounter a complex attribute D of X  For now  let us assume that D is single valued  There is some object Y that is the value of X D  Let us assume for now that no value is asserted in the knowledge base for X D  so that Y is a generic  unnamed  instance of T D   Recall that other attributes of X may depend on the value of D  i e   on Y   Specifically  let a          CTn be the com plete set of attribute chains  such that attributes of X de pend on each of the Y  a  but on no other aspects of the value of Y   In order to solve a query on X  we will need to solve a subquery on Y   to obtain a distribution over Y  a          Y   Tn  Recall  however  thatY may itself depend on X  This will happen if D has an inverse E  so that the value of Y  E is X  Let r        Tm be the complete set of attribute chains through which Y depends on X  The dis tribution overY  a         Y CTn will depend on the values of X r           X rm  The subquery onY needs to return a con ditional distribution over a          Tn given r           Tm  The issue is further complicated by the fact that  while solving a query for object X  we do not yet know the set r           rm  through whichY depends on X  This information can only be computed within Y itself  Therefore  when answering the subquery on Y   we return not only the conditional dis tribution over a          Tn  but also the conditioning vari ables T         Tm     The main function of our algorithm  SolveQuery  takes three arguments  one of which is optional  The two re quired arguments are an object Y   called the target of the query  and a set of attribute chains u   a          Tn  called the outputs of the query  The optional argument is an at tribute E  called the entry point of the query  E is the entry point intoY ifY  E is X  The entry point is used for discov ering the dependencies of Y on X  Y depends on X  T only when some attribute in Y depends on B  r  In this case  T is said to be an input to the query  SolveQuery returns two values  the set of inputs T   r           rm to the query  and a conditional probability distribution over u given T  A query may have no entry point if it is the top level call to SolveQuery or if it was called for an attribute D of X that has no inverse  In that case  Y cannot get inputs from X  so that T will be empty  and the distribution returned over u will be unconditional  The basic procedure of  SolveQuery  is as follows    SPOOK  System for probabilistic object oriented knowledge  constructs a local BN  which it will eventu ally use to solve the query  The BN consists of nodes for each of the attributes of the query target Y  nodes for the inputs and outputs  and other nodes that help communicate between different attributes  In order to add a node to the network  we must complete four steps  create it  specify its range  specify its parents  and specify its conditional prob ability distribution  CPD   These steps are not always per formed together  in some cases  we cannot specify the CPD of a node at the time that it is created   SolveQuery  initialization phase  First it cre ates a node v A  in the network for every attribute A ofY  For each simple attribute A  we specify the range of v A  to be the range of A  If A is complex  we want the range to be the product of all the attribute chains through which Y depends on A  but we do not yet know this set  For this reason  we maintain a set needed  A  for each complex at tribute A  SolveQuery begins with an  Next  SolveQuery creates an output node v output   to represent the query output  The range of v output  is x lDom a    where Dom a   is the range of the sim ple attribute at the end of the attribute chain a   For each a   we call the function GetChainNode  see below  to ob tain a node v a    whose range is Dom a    and make it a parent of v output   The CPD for v output  simply implements the cross product operation  if the values of v at        v an  are Vt       Vn  the value of v output  is  vt       vn  with probability I     is called whenever we need to produce a node to represent the value of an attribute chain a  If v a  is already in the BN  we simply return it  This will always be the case if a is just a simple attribute A  Otherwise  a must have the form A p  where A is a complex attribute  The algorithm thus needs to ensure that the processing of A will give the required information about A p  We there fore add p to the set needed  A   We can extract the value from the output of A by creating a new projection node v a   whose range is Dom a   and set its lone parent to be v A   As we will see below  the projection node performs the inverse operation to that of the cross product node   GetChainNode  The main phase of SolveQuery performs a backward chaining process to determine the interfaces of complex attributes  First  we order the attributes of Y in an order consistent with the dependency graph  Such an order must exist if the model is well defined  We then process the at tributes one by one  in a bottom up order  Children must precede their parents  since processing a child tells us what  information  we need from its parents  Processing a sim ple attribute A is easy  We simply obtain the set of attribute chain parents of A  as specified in the model ofY  For each such parent a  we convert it into a BN node v a  by calling GetChainNode  and add it as a parent of v A   We then set the CPD of v A  as specified in the model ofY        Processing a complex attribute A requires a recursive call  If A is the entry point of the query  we ignore it  it gets special treatment later  If needed  A  is empty  we can sim ply prune A  Otherwise  we will need to ask a subquery to obtain a distribution over needed  A   For now  we assume that Y A has no asserted value in the knowledge base  so that the value of Y A is some unnamed instance Z of class T A   Since the model of Z is the same as that of ev ery other unnamed instance of T A   we can ask the sub query on the class object T A   We therefore make a call to SolveQuery  in which the target is T A  and the set of out puts is needed  A   In addition  if A has an inverse B  the entry point is B  otherwise there is no entry point  The call to SolveQuery will return a set of inputs rA  and a con ditional probability distribution over needed  A  given rA We treat the inputs r A to A in the same way as the parents of a simple slot  using GetChainNode  We set the range of v A  to be x  Eneeded A Dom a   and set the CPD of v A  to be that returned by the recursive call   W hen we have finished processing all of the attributes  we can fill in the CPDs for the projection nodes  Each such node v a  represents a component of the value of a com plex attribute A  We could not specify the CPDs for these nodes at the time they were created  since we did not yet know the range of v  A   Once all the nodes have been created  we simply set the CPD of v a  to implement the projection function from x  Eneeded A Dom a  onto a  At this point  we have almost built the complete network for solving the query  Recall that we have not yet processed the entry point E  The node v E  is the input node  repre senting the input of the query  We set the range of v E  to be ITrEneeded E  Dom r   The node v E  has no parents and no CPD We are now done building the local BN for the objectY  If the knowledge base asserts a value vfor a sim ple attribute A ofY  we assert the value of v A  to be vas evidence in the network  We then use a standard BN algo rithm to compute the conditional probability of the output node given the input node  and return this conditional prob ability  along with the optional set of inputs needed E   To summarize  let us consider how our algorithm exploits the two types of structure described in  KP     Each recur sive call computes a distribution over the interface between two related objects  The algorithm exploits the fact that all the internal details of the callee are encapsulated from the caller by the interface  Much of the work of the algorithm  in particular maintaining the needed   sets and returning the set of inputs r  is concerned with computing these in terfaces on the fly  As for exploiting the recurrence of the same type of ob ject many times in the model  observe that different calls to SolveQuery with the same set of arguments will always re turn the same value  In order to reuse computation between different objects of the same type  we maintain a cache  in         Pfeffer  Koller  Milch  and Takusagawa  dexed by the three arguments to SolveQuery  Note that we cannot reuse computation between different queries on the same object  because they may generate very different computations down the line  However  if the two queries are similar  many of the recursive computations they gen erate will be the same  and we will be able to reuse those        Dealing with instances  If an instance has a value asserted for one of its attributes  we can no longer use the generic class model for that in stance  In addition  if one instance is related to another  the internals of the two instances are not necessarily en capsulated from each other  Consider  for example  three instances I  J and K  such that    A   J  I E   K  and J C   K  In this case K is not encapsulated from I by J  Hence  the interface between I and J does not separate the internals of I from the internals of J  When answering a query on I  we cannot simply perform a recursive call to obtain a distribution over the interface between I and J  as we would lose the fact that the internals of I and J may be correlated by their mutual dependence on K  A possi ble solution to this problem is to include K in the interface between I and J  However  including entire objects in an interface creates huge interfaces  and defeats the purpose of using an object based inference algorithm  In order to deal with this issue  we create a new top level object   in the knowledge base  This object contains an attribute     A for every named instance I and each of its attributes A  If A is simple  Dom I     A    Dom A   if it is complex  T  I   A    T A   If the KB asserts a value for    A       A has the same value  Every user query will be directed through the top level object  More precisely  a user query will have the form I u   ft CJ         ln  CJn  where each Ii is an instance  not necessarily distinct   and CJi is an attribute chain on Ii  The query is answered using a call SolveTopLevel    I u   Since this is the top level query  there is no entry point  and we will simply return a distribution over I u  SolveTopLevel is very similar to SolveQuery  so we omit the details  The main difference is in the way attribute chains are treated  On the top level  all attribute chains are attached to an instance  This is true both for the attribute chains required in the query output  and for the parents of any top level attribute     A  We replace GetChainNode with a function GetTopLeveiChainNode that takes two ar guments   an instance and an attribute chain  This function behaves similarly to GetChainNode  except for one situ ation  If the chain CJ is of the form A  p  and    A   J  then l  A  CJ   J  p  The algorithm eliminates this step of indirection  and continues to follow the rest of the chain        Multi valued attributes    structural uncertainty  We first show how to perform inference with multi valued attributes with no number uncertainty  Let A be a multi valued complex attribute with n values  One way to per form inference with multi valued attributes is to replace A with an array of n single valued attributes AI          An  Now consider a quantifier Q     A  p   v     The value of Q depends on the values of A   p         An  p  We there fore introduce a projection node for each of the Ai   p  and p is added to needed Ai  The CPT for v Q  is defined to count the number of v AiP  whose value is v  The problem with this approach is that v Q  has n parents  so its CPT has size exponential in n  A better solution uses the fact that the value of v Q  does not depend directly on each of the individual v Ai p   but only on the number of them that have the value v  Therefore  we do not need to introduce the v Ai   p  explicitly  Given the probability p that a single AiP has the value v  the probability that k out of n have the value v is given simply by the binomial term n G Pk     p    k We can compute the CPT for v Q  in time O n    using a recurrence relation  Let Pm Q   k  denote the probability that k out of the first A   p          Am   p have value v  Then P  Q           and Pm I Q   k        p Pm Q   k    pPm Q   k      If there are multiple quantifiers QI          Q   where Qi   e   A  pi   vi    the situation is a little more complicated  but similar  Since  for a particular value of A  the Pi may not be independent of each other  the different quantifiers are also not independent of each other  and we need to compute a joint distribution over all of them  We begin by making a recursive call to SolveQuery for A  where needed A     pi          pt   This gives us a distribution over the values of the Pi for a single value of A  We can encode the contribution of a single value of A to the quan tifiers in a vector of length  in which the j th component is I if Ai Pi   vi    otherwise  The distribution over the  e such contributions can be computed from the result of the recursive call to SolveQuery  Let Pc  denote the com puted probability of the contribution C  Similarly  each joint value of the quantifier variables can be encoded by a vector of components  where each component is between   and n  We can then use a similar recurrence relation to the one above to compute the joint distribution over the values of all the quantifiers  i E O l    k  E O       m    k C k   We need to compute O  n      i      summations  and each one involves    e  terms  so the time to compute the joint distribution over the quantifiers is      n      i      This computation is accomplished within the framework of by setting the range of v A  to be the set of  SolveQuery   SPOOK  System for probabilistic object oriented knowledge       possible values of the quantifiers  In the above discussion  we assumed that A has no inputs  If it does  we of course have to perform the above computation for each value of the inputs We then set the CPT for v A  to choose the com puted joint probability distribution over the Qj given each value of the inputs of A  Finally  the CPT for v Qj  simply computes a projection from the range of v A   As mentioned earlier  we cannot deal with structural un certainty by reasoning about all possible structures  In stead  we need to exploit the fact that many of the structural variables do not interact  Each of the complete structural hypotheses can be decomposed into many independent or conditionally independent sub hypotheses  For example  the numbers of units of different types in a battery may all be independent of each other given the country to which the battery belongs  This type of reasoning about the con ditional independence between different hypotheses is ide ally performed in a BN  We need to express all possible structures within a single network  so that the BN inference algorithm can exploit these independencies  This can be accomplished quite simply for number uncer tainty in the above framework  We add v  A  as a parent of v A   In the above recurrence relations  Pm Q   k  is the probability that the contributions of the first m values of A to the set of quantifiers will total k  This is exactly the probability we need to use if the value of v  A    m  So the entire CPT for v A  with number uncertainty can be computed in the same time as above  We deal with reference uncertainty as follows  Let A be a complex attribute with reference uncertainty  For each value v in the range of R  A   we create an attribute Av  and a corresponding BN node v Av   If vis equal to the type C  we set the type of Av to be C  This operation en sures that Av will later be processed correctly  as a generic attribute of type C  If vis equal to the instance I  we set the value of Av to be I  In this case  Av will be processed as a named instance  W hile we do not know the actual value of A  introducing all these nodes into the network accounts for all possible hypotheses over its value  We can now deal with dependencies on A  Consider a projection node v A p   We introduce a set of projection nodes v Av p  for each value v of R  A   We make v A p  depend on all the v AvP  as well as on R  A   and set its CPO to select the value of the parent specified by R  A   We can think of the CPO of v A p  as implementing a multiplexer  with selector R  A    See  BFGK    for a similar construction      Experimental Results  We have implemented the SPOOK system for representing models in the SPOOK language  and performing inference on these models  At the core of the system is a module containing the data structures necessary to represent the SPOOK data model  On top of this module is a user in   Figure    Experimental results  terface  see Figure    b   in which the user can create class and instance objects  build probability models  observe val ues and query probabilities  SPOOK models can also be stored in an external knowledge server such as Ontolingua  SPOOK communicates with the knowledge server using the OKBC protocol  CFF      a generic protocol for commu nication between knowledge based systems  Inference can be performed in SPOOK either by using the KBMC algo rithm  or the object based inference algorithm described in Section    Both inference methods use the same home grown underlying BN inference engine  In our experiments  we compared the performance of the object based algorithm with the KBMC algorithm on mod els of different sizes  Each model consists of a single bat talion with four batteries  each containing I I groups of dif ferent kinds with the number of units in each group varying from I to    The model also contains objects for the envi ronment  location and weather  as described in Section    The size of the constructed BN grows linearly in the num ber of units per group  and varies from     to      nodes  In order to measure separately the benefits from exploit ing interfaces and from reusing computation  we tried two different versions of the object based algorithm  with and without reuse  We also compared the naive and combina toric approaches to dealing with multivalued attributes de scribed in Section      Figure   shows the running time in seconds of the different algorithms  From the graph  we see that all versions of the object based algorithm out perform the KBMC algorithm by a large margin  and that the algorithm with reuse outperforms the algorithm with out reuse  For example  with four units per group  the object based algorithm with reuse takes   seconds  without reuse takes    seconds  while the KBMC algorithm takes      seconds  In addition  we see that for the combina toric approach to number uncertainty  the inference cost hardly increases with the number of units per group  its performance curve is just above the x axis   Even with    units per group  the cost of inference topped out at I I sec onds  whereas for the naive approach we see an exponential        Pfeffer  Koller  Milch  and Takusagawa  blowup as we increase the number of units per group  The reason for the great disparity between the inference times for the flat BN and for the object based algorithm without reuse  is that the BN reasoning algorithm is fail ing to find optimal junction trees in the flat BN  The largest clique constructed for the flat BN contains    nodes  whereas the largest clique over all of the local BN compu tations for the structured algorithm contains only   nodes  The BN inference engine uses the standard minimum dis crepancy triangulation heuristic to construct the junction tree  We see that at least for a standard BN implementation  exploiting object structure and the small interfaces between objects is vital to scaling up inference  W hile algorithms do exist for computing optimal triangulations  SG     most implementations of Bayes nets do not use them  and these algorithms do not address the issue of reuse     Discussion  An alternative approach to ours to modeling large  com plex domains probabilistically is the networkfragments ap proach of Laskey and Mahoney  LM     They provide net work fragments for different aspects of a model  and oper ations for combining the fragments to produce more com plex models  Network fragments exploit the same types of domain structure as do OOBNs  Because they allow com plex fragments to be constructed out of simpler ones  they allow models to be composed hierarchically  Similarly  be cause they allow the same fragment to be reused multiple times  they exploit the redundancy in the domain  The main difference between the two approaches is that ours focuses on building structured models  while theirs fo cuses on exploiting the domain structure for the knowledge engineering process  but the constructed models them selves are unstructured  An analogy from programming languages is that network fragments are like macros  which are preprocessed and substituted into the body of a pro gram before compilation  SPOOK class models  on the other hand  are like defined functions  which become part of the structure of the compiled program  The advantages of the two approaches are comparable to those of their pro gramming language analogues  Network fragments  like macros  have the advantage of flexibility  since no assump tions need be made about the relationship between com bined fragments  For example  the restriction of OOBNs to part of relationships was never an issue in the network frag ment approach  The SPOOK language  on the other hand  provides a stricter  more semantic approach to combining models  Like structured programming languages  it allows strong type checking in the definition of models  The most important advantage of the SPOOK approach is that the models are themselves structured  The domain structure can then be exploited for efficient inference  as explained in Section    As our experimental results in  Section   show  exploiting the domain structure can lead to great computational savings  In addition  because the domain structure is an explicit part of the model  we can now integrate uncertainty over the structure directly into the probability model  SPOOK provides a bridge between probabilistic reasoning and traditional logic based knowledge representation  Be cause it utilizes explicit notions of objects and the relation ships between them  SPOOK is able to incorporate and aug ment the relational models used in many KR systems  This capability is enhanced by the ability of sPOOK to commu nicate with such systems through the OKBC protocol   Our experiences with SPOOK are encouraging  Our hypoth esis that exploiting the object structure of a domain can help both in knowledge representation and inference seems to be correct  Of course  we have only worked with one domain  and it remains to be seen if the advantages carry over to other domains  If they do  perhaps the door will be opened to a wide range of new and more complex applica tions of Bayesian network tecnhology  Acknowledgements Grateful thanks to Suzanne Mahoney  KC Ng  Geoff Woodward and Tod Levitt of lET Inc  for their battlespace models  to Uri Lerner  Lise Getoor and all the Phrog hackers  to Barbara Engel hardt and Simon Tong for help with the knowledge engineering  and to Jim Rice for help with integrating with Ontolingua  This work was supported by ONR contract N     l     C      under DARPA s HPKB program  by DARPA contract DACA      C     under subcontract to Information Extraction and Transport  Inc   and through the generosity of the Powell foundation   
 Tasks such as record linkage and multi target tracking  which involve reconstructing the set of objects that underlie some observed data  are particularly challenging for probabilistic inference  Recent work has achieved efficient and accurate inference on such problems using Markov chain Monte Carlo  MCMC  techniques with customized proposal distributions  Currently  implementing such a system requires coding MCMC state representations and acceptance probability calculations that are specific to a particular application  An alternative approach  which we pursue in this paper  is to use a general purpose probabilistic modeling language  such as BLOG  and a generic Metropolis Hastings MCMC algorithm that supports user supplied proposal distributions  Our algorithm gains flexibility by using MCMC states that are only partial descriptions of possible worlds  we provide conditions under which MCMC over partial worlds yields correct answers to queries  We also show how to use a context specific Bayes net to identify the factors in the acceptance probability that need to be computed for a given proposed move  Experimental results on a citation matching task show that our general purpose MCMC engine compares favorably with an application specific system      INTRODUCTION  Many probabilistic reasoning problems involve reconstructing the set of  possibly related  real world objects that underlie some observed data  for instance  the publications and authors that are mentioned in a set of bibliographic citations  or the aircraft that underlie a set of observed radar blips  Because the number of possible ways to map a set of observations to underlying objects is huge  these problems are extremely challenging for standard proba   Stuart Russell Computer Science Division University of California Berkeley  CA            russell cs berkeley edu  bilistic inference algorithms  Specialized algorithms have been developed in the fields of record linkage  Fellegi and Sunter        and data association  Bar Shalom and Fortmann        that yield approximate solutions for particular classes of models  Recently  Pasula et al         and Oh et al         have achieved state of the art results on these problems using Markov chain Monte Carlo  MCMC  methods  Given a probability distribution p on an outcome space   an MCMC algorithm approximates the probability of a query event Q given an evidence event E by generating a sequence of samples s    s            sN from a Markov chain over   This Markov chain is chosen so that it only visits outcomes consistent with E  and its stationary distribution is proportional to p s   The desired probability p Q E  is then approximated as the fraction of s            sN that are in Q  If the Markov chain is ergodic  then this approximation converges to the correct posterior probability as N    Pasula et al         and Oh et al         use the MetropolisHastings  M H  algorithm  Metropolis et al         Hastings        to construct a Markov chain whose stationary distribution is proportional to p s   In the M H algorithm  when the current state of the chain is sn   a new state is sampled from a proposal distribution q s   sn    The acceptance probability for this proposed move is    p s   q sn  s           sn   s     max    p sn  q s   sn   With probability  sn   s     the move is accepted and sn   is set to s    otherwise  sn     sn   The proposal distribution can incorporate domain specific heuristics that help the chain to move quickly among reasonably probable hypotheses  As long as this Markov chain is ergodic  the stationary distribution will be proportional to p s  regardless of the proposal distribution  The recent successes of the M H algorithm suggest that it could be applied usefully to other relational inference tasks  such as resolving coreference among noun phrases in text  However  to recycle a comment that Gilks et al  made about Gibbs sampling in       Until now all existing implemen    tations have involved writing one off computer code in low or intermediate level languages such as C or Fortran  Although perhaps Matlab has replaced Fortran  this is still true about M H implementations today  the data structures that represent MCMC states and the algorithms that compute acceptance probabilities are application specific  Tackling a new application  or even adding a variable to an existing model  requires rewriting portions of the state representation and acceptance probability code  in addition to modifying the proposal distribution   current world  Sec        More interestingly  we can determine which factors in the acceptance probability need to be recomputed by maintaining a context specific Bayes net graph over the instantiated variables  Sec        Sec    presents experimental results on the citation matching task  showing that our generic M H system supports the same proposal distribution that was used in a hand coded implementation  and has a running time of the same order of magnitude   We would prefer to have a general approximate inference system that computed answers to queries based on a usersupplied probability model and proposal distribution  This paper presents a prototype for such a system  To represent the model  we use Bayesian logic  BLOG   Milch et al       a   a language that allows us to express uncertainty about the number of latent objects and the relations among objects and observations  Many of our results would also be applicable to other probabilistic modeling languages  Pfeffer        Jaeger        Laskey and da Costa        Richardson and Domingos        Mjolsness         Ideally  we would also like to have a declarative language for specifying proposal distributions  However  at this point we are only beginning to understand what constructs and features such a language would need to have  Thus  we assume that proposal distributions are specified procedurally  as Java classes that implement a certain interface      This paper focuses on the interface between the proposal distribution and the main M H engine  specifically  the representation of MCMC states  and on how the engine can efficiently compute acceptance probabilities for arbitrary proposals  We begin in Sec    by describing the probability model and M H implementation used by  Pasula et al         to resolve coreference among citations  We then briefly review the BLOG language of  Milch et al       a   Sec    introduces the architecture of our generic M H system  Our main contributions begin in Sec     which discusses the state space of our M H algorithm  The key point here is that it is impractical to use MCMC states that correspond to single possible worlds  instead  states are represented with partial descriptions that denote whole sets of worlds  We provide conditions under which MCMC over sets of worlds yields asymptotically correct answers to queries  Taking advantage of this theorem  we use state descriptions that are partial in two ways  they do not instantiate irrelevant variables  and they abstract away the numbering of interchangeable objects  Sec    discusses the data structures and algorithms necessary to make generic M H efficient  The goal here is to avoid having the time required to compute the acceptance probability and update the MCMC state grow with the number of hypothesized objects or the number of instantiated variables  We use data structures that represent a proposed world as a set of differences with respect to the       BACKGROUND CITATION MATCHING  Pasula et al         employ an M H algorithm to cluster citations into groups that refer to the same publication  They use a generative model to define a distribution over worlds containing publications  researchers  and citations  This model includes prior distributions for researcher names and publication titles  The authors of each publication are chosen uniformly from the set of researchers  and the publication cited by each citation is chosen uniformly from the set of publications  The text of a citation is generated from the author names and title of the publication it cites  through an observation model that allows abbreviations  errors  and various styles of formating  Given the text of some observed citations  the goal is to infer which citations co refer  The proposal distribution of  Pasula et al         is based on moves that split and merge clusters of co referring citations  In a preprocessing step  the citations are grouped into canopies  overlapping groups of citations that are similar enough  according to a rough heuristic  that they have a non negligible chance of co referring  McCallum et al          For each move  the proposal distribution randomly chooses a canopy and two citations c    c  in that canopy  If c  and c  refer to the same publication p    then a new publication p  is added and the citations of p  are split randomly among p  and p    If c  and c  refer to different publications  then the two publications may be merged  New titles and authors are proposed for the affected publications  based on the text of citations that now refer to them  Finally  any publications and researchers that are no longer connected to citations are removed from the MCMC state  The resulting M H algorithm recovers between     and     of the true co referring clusters exactly  This accuracy is significantly better than that reported by the developers of Citeseer  Lawrence et al          and is competitive with more recent discriminative methods  Wellner et al               BAYESIAN LOGIC  Bayesian logic  BLOG   Milch et al       a  is a language for defining probability distributions over structures that can contain varying numbers of objects with varying re      type Res  type Pub  type Cit    guaranteed Cit Cit   Cit   Cit   Cit      Res  NumResearchersPrior    random String Name Res r   NamePrior                    Pub  NumPublicationsPrior  random String Title Pub p   TitlePrior  random NaturalNum NumAuthors Pub p   NumAuthorsPrior  random Res NthAuthor Pub p  NaturalNum n  if  n   NumAuthors p   then  Uniform Res r       random Pub PubCited Cit c      Uniform Pub p      random String TitleText Cit c      TitleObsModel Title PubCited c        random String NthAuthorText Cit c     NaturalNum n     if  n   NumAuthors PubCited c       then  AuthorObsModel     Name NthAuthor PubCited c   n        random String AuthListSuffix Cit c     NaturalNum n     if  n   NumAuthors PubCited c       then  AuthJoinModel     NthAuthorText c  n      AuthListSuffix c  Succ n       else          random String Text Cit c      FormatModel TitleText c      AuthListSuffix c        Figure    BLOG model for citation matching  lations among them  These possible worlds are represented formally as model structures of a typed first order logical language  A typed first order language includes a set of types  such as String  NaturalNum  Citation  and Publication  and a set of function symbols    such as Name  Title  and PubCited  A model structure specifies a set of objects for each type  and for each function symbol  it specifies a mapping from argument tuples to values  A BLOG model specifies a generative process for constructing such possible worlds  Fig    shows a simplified version of the BLOG model that we use for citation matching  The model begins by declaring object types  line    and introducing some guaranteed objects that exist in all possible worlds  The rest of the model consists of two kinds of statements  Number statements  appearing on lines   and    describe generative steps that add new objects to the world  Dependency statements describe steps that set the value of a function on a tuple of arguments  For instance  the statement on lines      specifies a distribution for the observed author name NthAuthorText c  n   conditioning on the true name Name NthAuthor PubCited c   n    The objects that exist in a possible world include built in objects  of types NaturalNum  String  etc    guaranteed objects introduced in the BLOG model  and non guaranteed  objects generated by number statements  Specifically  if a number statement for type  generates N objects  these objects are consecutively numbered pairs                   N    A possible world is fully specified by the values of certain basic random variables  For a given BLOG model  the basic variables include a number variable for each number statement   and a function application variable Vf  o            ok   for each k ary random function f and each tuple of appropriately typed objects o            ok that exist in any possible world  A BLOG model implicitly defines a Bayes net  BN  over its basic random variables  This BN may be infinite  and it is typically contingent  edges are active only in certain contexts  Milch et al       b   For instance  TitleText Cit   depends on Title  Pub      only in the context where PubCited Cit      Pub          METROPOLIS HASTINGS ARCHITECTURE  Our general purpose M H system is implemented in Java as part of the BLOG inference engine  which is available for download from http   www cs berkeley edu  milch blog  Proposal distributions are written as Java classes that implement an interface called Proposer  More precisely  a class implementing the Proposer interface defines a family of proposal distributions  an object of this class defines a specific distribution q s   sn   once it has been initialized with a particular BLOG model  observed evidence  and list of queries  Useful Proposer classes may be specialized to a particular model and type of query  for instance  a proposer for citation matching might only support BLOG models identical to that in Fig     except for variations in the number of citations   evidence that consists of observed text for each citation  and queries for whether two citations refer to the same publication  i e   have the same PubCited value   To begin the MCMC chain  the M H engine calls a method on the Proposer object that generates an initial state s  consistent with the evidence  Then on each iteration  the engine calls the following Proposer method  double proposeNextState MCMCState state    The state object passed in is a copy of the current state sn   The method changes the values of certain basic random variables in state so that it represents a proposed state s  chosen from q s   sn    The proposer must ensure that s  satisfies the evidence and is complete enough to answer the queries specified at initialization  The method returns the log proposal ratio ln  q sn  s    q s   sn           We treat predicates as function symbols with return type Boolean  and constant symbols as zero ary function symbols   In models where objects generate other objects  there is a number variable for each application of a number statement to a tuple of generating objects  see  Milch et al       a      The general purpose M H engine then computes the probability ratio p s    p sn    and uses this along with the log proposal ratio to compute the acceptance probability given in Eq     If it accepts the proposal  it sets sn   equal to the state object that was modified by the proposer  otherwise  it sets sn   equal to a saved copy of sn       MCMC STATES  MCMC states serve as the interface between the generalpurpose and application specific parts of the generic M H system  The obvious way to apply MCMC to a BLOG model is to let the MCMC states be possible worlds  However  the proposal distribution of  Pasula et al         does not propose complete possible worlds  A full possible world typically contains many publications that are not cited  that is  are not the value of PubCited c  for any citation c  The world must specify the values of the Title and NthAuthor functions on all the publications that exist  But the proposal distribution discussed in Sec      never proposes titles or authors for uncited publications  The contingent BN for the citation matching model makes it clear that attributes of uncited publications are irrelevant  in a world where a publication p is uncited  the Title and NthAuthor variables defined on p are not active ancestors of query or evidence variables  Proposing values for these variables would be a waste of time  In fact  in some BLOG models  such as a model for aircraft tracking with variables State a  t  for every aircraft a and natural number t  each possible world assigns non null values to infinitely many variables  In such models  proposing and storing full possible worlds would require infinite time and space       EVENTS AS MCMC STATES  Our generic MCMC architecture circumvents these difficulties by allowing proposal distributions to use partial descriptions of possible worlds  For instance  the proposer for citation matching specifies the values of the PubCited function on all citations  and specifies attributes for the cited publications and their authors  Such a partial specification can be thought of as an event  a set of full possible worlds that satisfy the specification  Thus  our system runs a Markov chain over a set  of events  which are subsets of the outcome space   The following theorem gives conditions under which a Markov chain over  will yield correct answers to queries  Theorem    Let p be a probability distribution over a set   E and Q be subsets of   and  be a set of subsets of   Suppose s    s            sN are samples from an ergodic Markov chain over  with stationary distribution proportional to p s   If      is a partition of E  and     for each s    either s  Q or s  Q     PN then N  n     sn  Q  converges to p Q E   Proof  Let  be the stationary distribution of the Markov e be the set of states  s     s  chain over   and let Q Q   Then by standard results about ergodic Markov chains  PN   e n     sn  Q  converges to  Q  as N    So N e   p Q E   By definition  it suffices to show that  Q  P e  Q    e  s   Now since  s  is proportional to sQ p s   P e p s  sQ e      Q    P s p s  By P the assumption that  is a partition of E  we know e s p s    p E   We now argue that the set of events Q is a partition of Q  E  To see this  consider any   Q  E  Because  is a partition of E  there is exactly one set s   such that   s  Given that   s  Q  it follows by ase Thus  since sumption   that s  Q  Therefore s  Q  e    there is exactly one s  Q e containing   So Q e is a Q P partition of Q  E and sQe p s    p Q  E   Plugging e   p QE    p Q E   into Eq     we find that  Q  p E   The next section discusses a way to choose the event set        PARTIAL INSTANTIATIONS  The most straightforward events to use as MCMC states are those corresponding to partial instantiations of the basic random variables  To satisfy Thm     these partial instantiations must instantiate the evidence variables to their observed values  instantiate the query variables  and define a partition of the worlds consistent with the evidence  Furthermore  to compute the acceptance probability given in Eq     the system must be able to compute the ratio p s    p sn   for events sn   s     In general  it is not easy to compute the probability of a partial instantiation  for instance  if the instantiation just includes the evidence variables  then computing its probability involves summing out all the hidden variables  In some cases it is possible to sum out uninstantiated variables analytically  but our generic MCMC system currently cannot do so  Instead  we limit ourselves to partial instantiations whose probabilities are given by simple product expressions  These are the self supporting instantiations  those that include all the active parents of the variables they instantiate  To say this formally  we need a bit more background on contingent BNs  see  Milch et al       b  for details   In a contingent BN  the conditional probability distribution  CPD  for a variable V is given by a tree where each internal node is labeled with a parent variable U   edges out of a node are labeled with values of U   and each leaf is labeled with a probability distribution over V   A particular parent variable may occur on some paths through   the tree and not on others  for instance  in the tree for TitleText Cit    the root is labeled with PubCited Cit    and the variable Title  Pub      occurs only in the subtree where PubCited Cit      Pub      An instantiation  supports V if it is complete enough so that only one path through the tree is consistent with   This path leads to a leaf with some distribution over V   we write pV  v   for the probability of the value v under this distribution  An instantiation is self supporting if it supports every variable that it instantiates  By the semantics of a contingent BN  if  is a finite  self supporting instantiation  then  Y pV   V         p     V vars    where  V   is the value that  assigns to V   Thus  if we use self supporting partial instantiations as our MCMC states  we can compute p s    p sn   with no summations  To satisfy the conditions of Thm     we need to use selfsupporting instantiations that form a partition of E  In particular  we need to ensure that these instantiations are mutually exclusive  if some of them define overlapping events  then worlds occurring in several events will be overcounted  The following result ensures that we can avoid overlaps by using minimal instantiations  Definition    Let V be a set of random variables  and  be a self supporting instantiation that instantiates V  Then  is minimal beyond V if no sub instantiation of  that instantiates V is self supporting  Proposition    Let V be a set of random variables in a contingent BN  The self supporting instantiations that are minimal beyond V are mutually contradictory  Proof  Assume for contradiction that two distinct selfsupporting instantiations  and  that are minimal beyond V are both satisfied by some world   By definition  neither  nor  can be a sub instantiation of the other  Therefore  instantiates a variable  call it X    that  does not instantiate  Consider a graph over vars    where there is an edge from X to Y if the path through Y s CPD tree that is consistent with  contains a node labeled with X  Since  is minimal beyond V  there must be a directed path in this graph from X  to V  otherwise the sub instantiation obtained by removing X  and all its descendents would still instantiate V and be self supporting  But since  is also consistent with    must instantiate all the variables along this directed path in order to be self supporting  This contradicts the assumption that  does not instantiate X    We have now identified a set of partial instantiations that satisfy the conditions of Thm    and have probabilities that are easy to compute  If the evidence variables are VE and the query variables are VQ   we use the set of selfsupporting instantiations that assign the observed values to VE and are miminal beyond VE  VQ         OBJECT IDENTIFIERS         Proposers and interchangeable objects  Recall that in a BLOG model  the objects that satisfy a given number statement are numbered  For instance  in worlds where there are    publications  the publication objects are  Pub               Pub       The BLOG model in Fig    specifies that the value of each PubCited variable is chosen uniformly from these publication objects  However  our description of the Pasula et al  proposal distribution in Sec      does not say how it chooses publication objects to serve as the values for PubCited variables   For instance  consider an MCMC state where  Pub         but only     distinct publication objects currently serve as values for PubCited variables  When the proposer performs a split move  taking  say  Pub      and splitting off some of its citations to join a new publication  which of the     previously uncited publications is used as the PubCited value for these citations  One answer that seems reasonable is to choose the lowestnumbered uncited publication  However  in order to have non zero acceptance probabilities  all our MCMC moves must be reversible  the reverse proposal probability q sn  s    must be positive  Under the policy just described  a move that merges  say   Pub     into  Pub     is not reversible when  Pub     happens to be uncited  Any split move in the resulting state would assign citations to  Pub      not  Pub      Such reversibility problems can be avoided by choosing the new PubCited value randomly from the publications that are uncited in the current partial instantiation  But it seems that it should not be necessary to spend time invoking the pseudo random number generator to choose a publication  since all the uncited publications are interchangeable  Furthermore  if the proposer samples publications randomly  then it must include these sampling probabilities in the forward and backward proposal probabilities  this increases the amount of bookkeeping involved in writing a proposal distribution         Abstract partial instantiations  Our general MCMC system includes an additional layer of abstraction that makes it easier to write proposal distributions involving interchangeable objects  The idea is to specify MCMC states using abstract partial instantiations  in which unnumbered object identifiers can be used as both arguments and values for basic random variables  For instance  an abstract partial instantiation using the identifier Pub A F could say  PubCited Cit     Pub A F  Title Pub A F    foo  We will refer to guaranteed and    The original formulation of this proposer in  Pasula et al         does not include PubCited variables  the MCMC states just specify a partition of the citations into co referring groups    non guaranteed objects that exist in possible worlds as concrete objects  to distinguish them from object identifiers  Definition    An abstract function application variable has the form Af  o            ok   where f is a k ary function symbol and o            ok are concrete objects or object identifiers  An abstract partial instantiation  consists of a set of number variables  and abstract function application variables  denoted vars     and a function that maps each element of vars    to a concrete object or object identifier  For each type  an abstract partial instantiation uses either object identifiers or concrete objects to represent the nonguaranteed objects  not both  Semantically  object identifiers can be thought of as existentially quantified logical variables  The abstract partial instantiation used as an example above is equivalent to x  PubCited Cit     x    Title x    foo    When an abstract instantiation uses several object identifiers  they are also asserted to be distinct  Definition    A partial instantiation  is a concrete version of an abstract partial instantiation  if there is a one toone function h from object identifiers used in  to concrete objects that exist in some world consistent with   such that  instantiates Af  o            ok   if and only if  instantiates Vf  h o             h ok     and h  Af  o            ok         Vf  h o             h ok      A world satisfies an abstract partial instantiation  if and only if it satisfies some concrete version of   For instance  the abstract partial instantiation   Pub      PubCited Cit     Pub A F  Tit Pub A F    foo  has three concrete versions   Pub      PubCited Cit      Pub      Tit  Pub        foo  Pub      PubCited Cit      Pub      Tit  Pub        foo  Pub      PubCited Cit      Pub      Tit  Pub        foo         Probabilities of abstract instantiations  Each abstract instantiation corresponds to an event  namely the set of possible worlds that satisfy it  note that two instantiations using different object identifiers may represent the same event   But how do we compute the probability of this event  Lemma    Let  be an abstract partial instantiation for a BLOG model  Then all concrete versions of  have the same probability  which we will call pc     Also  if any concrete version of  is self supporting  then they all are  The proof of this lemma relies on the stipulation in Def    that an abstract instantiation cannot use both concrete objects and object identifiers for the same type  If such mixing were allowed  then some concrete versions might have   In models where objects generate other objects  number variables can also be abstract   different probabilities than others  depending on whether certain object identifiers were mapped to concrete objects used elsewhere in the instantiation  If an abstract instantiation  contains an instantiated number variable asserting that there are n objects of a given type  and  uses m object identifiers of that n  type  then there are n Pm    nm   distinct functions that could play the role of h in Def     However  this observation does not lead to a general formula for the probability of   The problem is that the concrete versions produced by different h functions may correspond to overlapping events  For instance  two concrete versions of the abstract instantiation  Title Pub A F    foo  are  Title  Pub        foo  and  Title  Pub        foo   There are many worlds that satisfy both these concrete instantiations  Two h functions may even yield exactly the same concrete instantiation  For example  suppose     Title Pub A F    foo  Title Pub B      foo   Here an h function that maps Pub A F to  Pub     and Pub B   to  Pub     yields the same concrete instantiation as one that does the opposite  since  makes the same assertion about Pub A F and Pub B    The difficulty in this last example is that  has a non trivial automorphism  interchanging Pub A F and Pub B   yields  itself  In general  the number of distinct concrete versions of an abstract instantiation with a automorphisms is a   n Pm    But if the instantiation specifies relations among the non guaranteed objects  for instance  publications citing one another  then counting automorphisms becomes difficult  Indeed  counting the number of automorphisms of an undirected graph is polynomially equivalent to determining whether two graphs are isomorphic  Mathon         a problem for which no polynomialtime algorithm is known  This issue of automorphisms does not just arise because we are trying to use abstract partial instantiations as MCMC states  if we required the proposer to choose non guaranteed objects randomly  its proposal probability calculations would also need to determine how many different choices would yield the same proposal         A useful special case  Fortunately  for many models of practical interest  there is a simple way to avoid this issue  The abstract partial instantiations that we use for citation matching only make assertions about cited publications  That is  if  uses an object identifier such as Pub A F  then  asserts PubCited c    Pub A F for some citation c  If we apply two h functions that yield different concrete values for Pub A F  say  Pub     and  Pub      then the resulting concrete versions define disjoint events  one asserts PubCited c     Pub     and the other asserts PubCited c     Pub      In general  Definition    An object identifier i is grounded in an ab    stract partial instantiation  if there is a logical ground term ti such that every mapping function h  as in Def     yields a concrete instantiation where h i  is the value of ti   Proposition    Suppose  is an abstract partial instantiation whose concrete versions are self supporting instantiations having probability pc     Let T be the set of types for which  uses identifiers  and assume that for every type   T    instantiates a number variable asserting that there are n non guaranteed objects of type    If every identifier used in  is grounded  then  Y     p     pc    n  Pm     PERFORMING M H STEPS EFFICIENTLY  Our overall goal is to compute the probability ratio and update the MCMC state in time that does not grow with the number of existing objects or the number of instantiated variables  This is not always possible  but applicationspecific implementations exploit various forms of structure to do these computations in constant time  We are able to exploit some of the same structure in our generic system       DIFFERENCE DATA STRUCTURES   T  where m is the number of identifiers of type  used in    Proof  Given our discussion above  it suffices to show that the mapping functions h all yield disjoint events when applied to   Consider any two distinct mapping functions h  and h    and let   and   be the corresponding concrete versions of   Let i be any identifier used in  such that h   i     h   i   Because i is grounded in   Def    implies that there is a logical ground term ti such that ti evaluates to h   i  in every world satisfying     and ti evaluates to h   i  in every world satisfying     Since h   i     h   i   this implies   and   are disjoint  Logical ground terms include not just expressions such as PubCited Cit    but also nested expressions such as NthAuthor PubCited Cit        The requirement that object identifiers be grounded is not burdensome in scenarios  such as citation matching  where the relevant objects are those connected to guaranteed objects by some chains of function applications  In BLOG models that involve weighted sampling or aggregation  non guaranteed objects that do not serve as function values may become relevant  In such cases  the proposer would need to represent such objects concretely  In cases where Prop    applies  we can compute the probability of an abstract instantiation by just computing the probability of one of its concrete versions and then multiplying in an adjustment factor that is a product of factorials  In fact  the ratio of these adjustment factors in the acceptance probability is the same as the ratio of adjustments to the backward and forward proposal probabilities that would emerge if we required the proposal distribution to choose a distinct non guaranteed object for each identifier randomly  But we have avoided the need to actually do this random sampling  and shifted this computation from the application specific proposal distribution to general purpose code     This result can be extended to cases where objects generate objects  then the product is not over types  but over applications of number statements to tuples of generating objects  Abstract instantiations must be extended to specify the generating objects for each object identifier   We said in Sec    that the M H engine saves a copy of the current state sn before passing a modifiable copy to the proposer  But making a full copy of sn would take time linear in the number of instantiated variables  Thus  our implementation does something more subtle  The state object passed to proposeNextState is actually a difference structure or patch built on top of the current state sn   This difference structure contains a hash table that maps changed or newly instantiated basic variables to their new values  as well as a list of newly uninstantiated variables  The proposer actually just changes this patch  the underlying copy of sn is left unchanged  However  the difference structure supports all the same access methods as an ordinary MCMCState data structure  if a client asks for the value of a variable that has not been changed  the request is just passed through to the original state  If the proposal is rejected  the patch is simply discarded  and sn   is set equal to sn   If the proposal is accepted  then sn   is obtained by applying the patch to sn   that is  changing the underlying state so it reflects the changes made in the patch  This operation takes time linear in the number of changed variables  The patch is then cleared  leaving it free to accept modifications from the next call to proposeNextState       COMPUTING THE ACCEPTANCE PROBABILITY  Besides maintaining the MCMC state  the main task for our general purpose code is to compute the acceptance probability  The proposal distribution provides q sn  s    q s   sn    so we must compute the probability ratio p s    p sn    If sn and s  are represented as selfsupporting partial instantiations n and      Eq    tells us that this ratio is  Q     p      V vars      pV    V       Q     p n   V vars n   pV  n  V   n    Computing this ratio naively would require time proportional to the number of instantiated variables in    and n   But fortunately  many of the factors in the numerator and denominator may cancel    Definition    If a partial instantiation  supports a variable V   then the active parents of V in  are those variables that occur as labels on nodes in V s CPD tree on the unique path that is consistent with   Proposition    Suppose two partial instantiations  and    agree on a variable V and on all the variables that are active parents of V in   Then pV      V          pV   V      Also  V has the same active parents in    as in   Thus  we only need to compute the factors for variables that are newly instantiated  uninstantiated  or changed in      or whose active parents have changed values  Because we are explicitly representing the differences between    and n  see Sec        we can identify the changed variables efficiently  However  it is not so easy to identify variables whose active parents have changed  We can enumerate V s active parents in n by walking through V s CPD tree  But if only a few variables have changed  we dont want to iterate over all variables  seeing which ones happen to have a changed variable as an active parent  To avoid this iteration  we maintain a graph over the instantiated variables in n   this graph contains those edges from the BLOG models contingent BN that are active in n   Each variable has pointers to its children  that is  the variables of which it is an active parent in n   Given this data structure  we can efficiently enumerate the children of all variables that are changed in      The graph is constructed on the initial state  and then updated after each accepted proposal to reflect newly active or inactive parent relationships in      Conveniently  by Prop     we only need to update a variables active parent set if one of its active parents in n has changed  and we are enumerating these variables anyway to recompute their probability factors  If we use abstract partial instantiations  the probability ratio includes the factorial adjustment factors given in Eq     Again  computing these factorials naively would take time linear in the magnitudes of the number variables  But if the proposal makes small changes to the values of number variables and the number of used identifiers  then most of the factors inside the factorials cancel out  The calculation techniques presented here do have some limitations  One is that a variables child set may grow linearly with the number of objects  In the citation matching model  where the probability that a PubCited variable takes on any particular value in a world with N publications is   N   the  Pub variable is always an active parent of all PubCited variables  So the time required to compute the acceptance probability for a proposal that changes the number of publications grows linearly with the number of citations  This slowdown could be avoided by recognizing that every PubCited variable makes the same contribution the probability ratio  so we can compute this contribution once and raise it to the power of the number of citations  However  our current implementation does not detect when  this can be done  Conversely  a variables active parent set may grow linearly with the number of hypothesized objects  this happens in cases of weighted sampling or aggregation  Finally  our approach does not allow the system to detect cancellations between the p s    and q s   sn   factors  such as occur in Gibbs sampling  Gelman             EXPERIMENTS  We have developed a BLOG model and proposal distribution for the citation matching domain  Earlier work on applying M H to this task  Pasula et al         used an implementation hand coded in Lisp  Unfortunately  we do not know all the details of the model and proposal distribution used in that implementation  nor do we have data on its running time  However  we do have all these details for an application specific Java system that we implemented in the summer of       Our BLOG implementation almost exactly reproduces the model and proposal distribution used in this hand coded Java system  which thus serves as our reference for speed and accuracy comparisons  The BLOG model we use is an elaboration of the one shown in Fig     The prior distributions for author names and titles are n gram models learned from the author and title fields of a large BibTeX file  some parameters of the citation formating model are estimated from a set of handsegmented citations  Other parameters  such as typo probabilities  are set by hand  the exact values of these parameters have little influence on the accuracy results  The proposal distribution uses split merge moves of the kind described in  Jain and Neal         Table   shows results on four sets of about        unparsed citations that were collected by  Lawrence et al          The files are annotated with the true clustering of citations into co referring groups  the accuracy metric is the fraction of true clusters recovered exactly  All of the M H implementations achieve better accuracy than the  Lawrence et al         technique  with the  Pasula et al         implementation doing best by a significant margin  The  Pasula et al         implementation outperforms the others because it uses more sophisticated prior distributions for author names and citation formats  and more finely tuned heuristics for proposing parses of citations  There is little difference in accuracy between the handcoded Java implementation and the general purpose BLOG engine  this is to be expected  since they implement approximately the same model and proposal distribution  The timing results in Table   reflect the time required to initialize the system and run MCMC for        samples  Both systems display significant variation in run time across data sets  this reflects differences in the average number of citations affected by split merge moves  the data sets have different ratios of citations to publications  and differences in the fraction of proposals that are accepted  However    Phrase matching M H  Pasula et al  M H  Java  M H  BLOG  accuracy accuracy  avg  accuracy  avg  accuracy  final  time accuracy  avg  accuracy  final  time  Face  Reinforcement  Reasoning  Constraint      citations      citations      citations      citations                                             s                                    s                                             s                                    s                                             s                                     s                                             s                                    s  Table    Citation matching results for the phrase matching algorithm of  Lawrence et al          the hand coded M H implementation used by  Pasula et al          a simpler M H implementation hand coded in Java  and the BLOG inference engine  For the M H algorithms  accuracy may be averaged over all        samples or computed on the final MCMC state  times are measured for a run that computes the accuracy only on the final state  For the last two systems  we give     confidence intervals based on    independent runs   the BLOG engine consistently takes   times as long as the hand coded Java implementation      There are three main reasons for this difference  First  in the hand coded implementation  an MCMC state is represented as a collection of Java objects of application specific classes such as Publication and Citation  The current values of functions such as Title and PubCited are stored in fields on those objects  By contrast  the general BLOG engine does not include specialized Java classes for the citation domain  it uses a hash table that maps functions and argument tuples to values  Thus  accessing and updating the state is considerably slower in the BLOG implementation  Second  the hand coded implementation includes special code for determining which variables are affected by moves that are proposed by its specific proposal distribution  In order to support arbitrary proposals  the BLOG engine must look at the list of variables changed by the proposal  find their children in the current BN graph  and  if the proposal is accepted  update the BN graph to reflect dependencies that are active in the new world  Finally  computing the probabilities of variables given their parents is slower in the BLOG implementation  The BLOG engine must interpret ifthen clauses that occur in the BLOG model  e g   lines    and    of Fig     and explicitly store values in the MCMC state for intermediate variables  such as AuthListSuffix in Fig     In the hand coded implementation  if statements and local variables can be written into the Java code  allowing faster execution   We have described a general MCMC inference system that just requires the user to provide a BLOG model and a proposal distribution  Our main contribution is a semantics for MCMC states that do not fully specify a possible world  By allowing partial world descriptions  we support proposal distributions that do not instantiate irrelevant variables or assign numbers to interchangeable objects  We also show how to use a context specific Bayes net graph to determine efficiently what factors in the acceptance probability need to be computed for a given proposal   As a result  while the hand coded implementation does        samples in      seconds  the BLOG engine takes       seconds  However  our notes from summer of      indicate that with the computers and Java runtime environment we had then  the hand coded implementation ran in about     seconds  In other words  our computing infrastructure has improved enough that a general system runs faster than a hand coded system did three years ago   CONCLUSIONS  Our current system still requires that the user implement a proposal distribution  which can be a significant undertaking  Other sampling based approaches to approximate inference require less customization  and allow correspondingly less flexibility  For instance  the widely used BUGS system  Gilks et al         allows users to run Gibbs sampling on a wide range of graphical models with no additional programming  However  Gibbs sampling falls short in scenarios where it is difficult to move between highprobability hypotheses by changing one variable at a time  In such cases  M H algorithms can explore the posterior distribution more efficiently  There has been some recent work on adding generic M H capabilities to BUGS using adaptive proposal distributions  Lunn et al          Another approach to automatic approximate inference is forward sampling  using the models CPDs to sample variables given their parents  Milch et al       b  use forward sampling in a general likelihood weighting algorithm for contingent BNs  Jaeger        explores several variations on forward sampling for relational Bayesian networks  including a version where values are also propagated up from evidence nodes through deterministic dependencies  Angelopoulos and Cussens               on the other hand  use forward sampling in a proposal distribution within an   M H algorithm  Their models are represented as stochastic logic programs  which define distributions over Prolog proof trees  the proposal distribution resamples a sub tree of the current proof tree  This algorithm has been successful on several applications  However  it seems that more data driven proposal distributions are needed for applications such as citation matching  where forward sampling has a negligible probability of yielding author names and publication titles consistent with the observed citations  Clearly there is more work to be done on general purpose inference for relational probabilistic models  In the citation matching domain  we are extending our BLOG model and proposal distribution to simultaneously reconstruct the publications  researchers  and venues mentioned in a set of citations  We also plan to develop BLOG models and proposal distributions for other tasks  such as resolving coreference among names and pronouns in newswire articles  We hope that through these efforts  we will come to understand some common principles that underlie effective proposal distributions for various tasks  This understanding should lead toward the development of a library of  possibly adaptive  proposal distribution modules  which can be combined to yield effective proposal distributions for new tasks with little or no programming  Acknowledgements This work was supported by DARPA IPTO under the CALO project            and the Effective Bayesian Transfer Learning project  FA              B  Milch was also supported by a Siebel Scholarship  
 The ways in which an agents actions affect the world can often be modeled compactly using a set of relational probabilistic planning rules  This paper addresses the problem of learning such rule sets for multiple related tasks  We take a hierarchical Bayesian approach  in which the system learns a prior distribution over rule sets  We present a class of prior distributions parameterized by a rule set prototype that is stochastically modified to produce a task specific rule set  We also describe a coordinate ascent algorithm that iteratively optimizes the task specific rule sets and the prior distribution  Experiments using this algorithm show that transferring information from related tasks significantly reduces the amount of training data required to predict action effects in blocks world domains      Introduction  One of the most important types of knowledge for an intelligent agent is that which allows it to predict the effects of its actions  For instance  imagine a robot that performs the familiar task of retrieving items from cabinets in a kitchen  This robot needs to know that if it grips the knob on a cabinet door and pulls  the door will swing open  if it releases its grip when the cabinet is only slightly open  the door will probably swing shut  and if it releases its grip when the cabinet is open nearly    degrees  the door will probably stay open  Such knowledge can be encoded compactly as a set of probabilistic planning rules  Kushmerick et al         Blum and Langford         Each rule specifies a probability distribution over sets of changes that may occur in the world when an action is executed and certain preconditions hold  To represent domains concisely  the rules must be relational rather than propositional  for example  they must make statements about cabinets in general rather than individual cabinets   Luke S  Zettlemoyer MIT CSAIL Cambridge  MA       lsz csail mit edu  Leslie Pack Kaelbling MIT CSAIL Cambridge  MA       lpk csail mit edu  Algorithms have been developed for learning relational probabilistic planning rules by observing the effects of actions  Pasula et al         Zettlemoyer et al          But with current algorithms  if a robot learns planning rules for one kitchen and then moves to a new kitchen where its actions have slightly different effects  because  say  the cabinets are built differently   it must learn a new rule set from scratch  Current rule learning algorithms fail to capture an important aspect of human learning  the ability to transfer knowledge from one task to another  We address this transfer learning problem in this paper  In statistics  the problem of transferring predictions across related data sets has been addressed with hierarchical Bayesian models  Lindley         The first use of such models for the multi task learning problem appears to be due to Baxter         the approach has recently become quite popular  Yu et al         Marx et al         Zhang et al          The basic idea of hierarchical Bayesian learning is to regard the task specific models R            RK as samples from a global prior distribution G  This prior distribution over models is not fixed in advance  but is learned by the system  thus  the system discovers what the task specific models have in common  However  applying the hierarchical Bayesian approach to sets of first order probabilistic planning rules poses both conceptual and computational challenges  In most existing applications  the models Rk are represented as real valued parameter vectors  and the hypothesis space for G is a class of priors over real vectors  But a rule set is a discrete structure that may contain any number of rules  and each rule includes a precondition and a set of outcomes that are represented as arbitrary length conjunctions of first order literals  How can we define a class of prior distributions over such rule sets  Our proposal is to let G be defined by a rule set prototype that is modified stochastically to create the task specific rule sets  Our goal is to take data from K source tasks  plus a limited set of examples from a target task K      and find the  rule set RK   for the target task with the greatest posterior probability  In principle  this involves integrating out the       DESHPANDE ET AL   pickup X  Y                           on X  Y    clear X   inhand nil  block Y    wet inhand X   clear X   inhand nil       on X  Y    clear Y        on X  TABLE   on X  Y         no change       noise  pickup X  Y                                             s in sentence   and a   pickup B A  B B   both of the rules in Fig    would have the binding     X B A  Y  B B   The first rule would apply  since its preconditions are all satisfied  while the second one would not because wet is not true in s  We disallow rule sets in which two or more rules apply to the same  s  a  pair  these are called overlapping rules   In cases where no rules apply  a default rule is used that has an empty context and two outcomes  no change and noise  which will be described shortly   on X  Y    clear X   inhand nil  block Y    wet inhand X   clear X   inhand nil  on X  Y    clear Y   on X  TABLE   on X  Y   no change noise  Figure    Two rules for the pickup action in the slippery gripper blocks world domain  other rule sets R            RK and the rule set prototype G  As an approximation  however  we use estimates of G and  found by a greedy local search algorithm  We R            RK present experiments with this algorithm on blocks world tasks  showing that transferring data from related tasks significantly reduces the number of training examples required to achieve high accuracy on a new task      Probabilistic Planning Rules  Probabilistic planning rule sets define a state transition distribution p st  st    at    In this section  we present a simplified version of the representation developed by  Zettlemoyer et al          A state st is represented by a conjunctive formula with constants denoting objects in the world and proposition and function symbols representing the objects properties and relations  The sentence inhand nil  on B A  B B   on B B  TABLE   clear B A  block B A   block B B   table TABLE        represents a blocks world where the gripper holds nothing and the two blocks are in a single stack on the table  This is a full description of the world  all of the false literals are omitted for compactness  Block B A is on top of the stack  while B B is below B A and on the table TABLE  Actions at are ground literals where the predicate names the action to be performed and the arguments are constant terms that correspond to the objects which will be manipulated  For example  at   pickup B A  B B  would represent an attempt to pick block B A up off of block B B  Each rule r has two parts that determine when it is applicable  an action z and a context  that encodes a set of preconditions  Both of the rules in Fig    model the pickup X  Y   action  Given a particular state st  and action a  we can determine whether a rule applies by computing a binding  that finds objects for all the variables  by matching against a  and then testing whether the preconditions hold for this binding  For example  for the state  Given the applicable rule r  the discrete distribution p over outcomes O  described on the right of the   defines what changes may happen from st  to st   Each non noise outcome o  O implicitly defines a successor state function fo with associated probability po   an entry in p  The function fo builds st from st  by copying st  and then changing the values of the relevant literals in st to match the corresponding values in  o   In our running example of executing pickup B A  B B  in sentence    for the first outcome of the first rule  where the picking up succeeds  fo would set five truth values  including setting on B A  B B  to be false  In the third outcome  which indicates no change  fo is the identity function  In this paper  we will enforce the restriction that outcomes do not overlap  for each pair of outcomes o  and o  in a rule r  there cannot exist a stateaction pair  s  a  such that r is applicable and fo   s    fo   s   In other words  if we observe the state that results from applying a rule  then there is no ambiguity about which outcome occurred   Finally  the noise outcome is treated as a special case  There is no associated successor function  which allows the rule to define a type of partial model where r does not describe how to construct the next state with probability pnoise   Noise outcomes allow rule learners to ignore overly complex  rare action effects and have been shown to improve learning in noisy domains  Zettlemoyer et al          Since rules with noise outcomes are partial models  the distribution p st  st    at   is replaced with an approximation   p st  st    at      po pnoise pmin  if fo  st      st otherwise       where the set of possible outcomes o  O is determined by the applicable rule  The probabilities po and pnoise make up the parameter vector p  The constant pmin can be viewed as an approximation to a distribution p st  st    at   onoise   that would provide a complete model      Hierarchical Bayesian Model  In a hierarchical Bayesian model  as illustrated in Fig     the data points xkn in task k come from a task specific dis   This restriction simplifies parameter estimation  as we will see in Sec     without limiting the class of transition distributions that can be defined  Any rule with overlapping outcomes can be replaced by an equivalent set of rules applying to more specific contexts  with non overlapping outcomes    DESHPANDE ET AL  G  R        R   x n  x n N   RK  xKn N   NK  Figure    A hierarchical Bayesian model with K tasks  where the number of examples for task k is Nk   tribution p xkn  Rk    and the task specific parameters Rk are in turn modeled by a prior distribution p Rk  G   The hyperparameter G has its own prior distribution p G   By observing data from the first K tasks  the learner gets information about R            RK and hence about G  For instance  the learner can compute  perhaps approximately   the values  R            RK   G   that have maximum a posteriori  MAP  probability given the data on the first K tasks  Then when it encounters task K     the learners estimates of the task specific model RK   are influenced by both the data observed for task K     and the prior p RK    G    which captures its expectations about the model based on the preceding tasks       Rule Set Prototypes  In the context of learning planning rules  the task specific models Rk are rule sets  Our intuition is that if the tasks are related  then these rule sets have some things in common  Certain rules may appear in the rule sets for many tasks  perhaps with some modifications to their contexts  outcomes  and outcome probabilities  To capture these commonalities  we assume that the rule sets are all generated from an underlying rule set prototype G  A rule set prototype consists of a set of rule prototypes  A rule prototype is like an ordinary rule  except that rather than specifying a probability distribution over its outcomes  it specifies a vector of Dirichlet parameters that define a prior over outcome distributions  For a rule prototype with n explicit outcomes  this is a vector  of n   non negative real numbers  n   corresponds to a special seed outcome on   that generates new outcomes in local rules  and n   accounts for the noise outcome  Unlike in local rule sets  we allow overlapping rules and outcomes in rule set prototype to allow for better generalization           can be found by identifying the single rule in Rk that applies to  st    at    or the default rule  if no explicit rule applies  and using Eq     Then theQprobability of the entire Nk data set for task k is p xk  Rk     n   p xkn  Rk    The distribution for G and R            Rk is defined by a generative process that first creates G  and then creates R            Rk by modifying G  Note that this generative process is purely a conceptual device for defining our probability model  we never actually draw samples from it  As we will see in Sec     our learning algorithm uses the generative model solely to define a scoring function for evaluating rule sets and prototypes  Two difficulties arise in using our generative process to define a joint distribution  One is that the process can yield rule sets Ri that are invalid  in the sense of containing overlapping rules or outcomes  It is difficult to design a generative process that avoids creating invalid rule sets  but still allows the probability of a rule set to be computed efficiently  Intuitively  we want to discard runs of the generative process that yield invalid rule sets  The other difficulty is that there may be many possible runs of a generative process that yield the same rule set  For instance  as we will see  a rule set prototype is generated by choosing a number m  generating a sequence of m rule prototypes independently  and then returning the set of distinct rule prototypes that were generated  In principle  a set of m distinct rules could be created by generating a list of any length m  m  with duplicates   we do not want to force ourselves to sum over all these possibilities to compute the probability of a given rule set prototype  Again  it is convenient to discard certain non canonical runs of the generative process  in this case  runs where the same rule prototype is generated twice  Thus  we will define measures PG  G  and Pmod  Rk  G  that give the probability of generating a rule set prototype G  or a rule set Rk   through a valid sampling run  Because some runs are considered invalid  these measures do not sum to one  The resulting joint distribution is  p G  R            RK   x            xK     K  Y   PG  G  Pmod  Rk  G p xk  Rk   Z       k    The normalization constant Z is the total probability of valid runs of our generative process  Since we are just interested in the relative probabilities of hypotheses  we never need to compute this normalization constant    Overview of Model  Our hierarchical model defines a joint probability distribution p G  R            RK   x            xK    In our setting  each example xkn is a state st obtained by performing a known action at in a known initial state st    Thus  p xkn  Rk       One might be tempted to define a model where the normalization is more local  for instance  to replace the factor Pmod  Rk  G  in Eq    with a normalized distribution Pmod  Rk  G  Z G   However  the normalization factor Z G  is not constant  so it would have to be computed to compare alternative values of G        DESHPANDE ET AL        set R of size m from a prototype G of size m is   Modifying the Rule Set Prototype  Pmod  R G     We begin the discussion of our generative process by describing how a rule set prototype G is modified to create a rule set R  the process that generates G will be a simplified version of this process   The first step is to choose the rule set size m from a distribution Pnum  m m    where m is the number of rule prototypes in G  We define Pnum  m m   so that all natural numbers have non zero probability  but m is likely to be close to m   and the probability drops off geometrically for greater values of m   Pnum  m m      Geom   m  m        Binom m     m   if m   m otherwise       Here Geom   is a geometric distribution with success probability   Thus  if m   m   then Pnum  m m            mm     We set  to a small value to discourage the rule set R from being much larger than G  The sum of the Geom   distribution over all values greater than zero is   leaving a probability mass of     to be apportioned over rule set sizes from   through m   The binomial distribution Binom m      which yields the probability of getting exactly m heads when flipping m coins with heads probability   is a convenient distribution over this range of integers  We set  to a value close to   to express a preference for local rule sets that are not much smaller than the prototype set  Next  for i     to m  we generate a local rule ri   The first step in generating ri is to choose which rule prototype in G it will be derived from  This choice is represented by an assignment variable Ai   whose value is either a rule prototype in G  or a special value NIL indicating that this rule is generated from scratch with no prototype  The distribution PA  ai  G  assigns the probability rule to NIL and spreads the remaining mass uniformly over the rule prototypes  Since the Ai are chosen independently  a single rule in G may serve as the prototype for several rules in R  or for none  Next  given the rule prototype  or null value  ai   the local rule ri is generated according to a distribution Prule  ri  ai    We discuss this distribution in Section      The rule set generated by this process is the set of distinct rules in the list r            rm   We consider a run of the generative process to be invalid if any of these rules have overlapping contexts  in particular  this constraint rules out cases where the same rule occurs twice  So the probability of generating a set  r            rm   on a valid run is the sum of the probabilities of all permutations of this set  This is m  times the probability of generating the rules in any particular order  Thus  the probability of getting a valid local rule  Pnum  m m    m    m Y i         X  PA  ai  G Prule  ri  ai         ai  G NIL   Modifying and Creating Rules  We will now define the distribution Prule  r r    where r may be either a rule prototype  or the value NIL  indicating that r is generated from scratch  Suppose r consists of a context formula   an action term z  a set of non noise outcomes O  and a probability vector p  The corresponding parts of r will be referred to as    z    O   and   recall that this last component is a vector of Dirichlet parameters   If r   NIL  then  is an empty formula  z  is NIL  O consists of just the seed outcome  and  is a two element vector consisting of a   for the seed outcome and a   for the noise outcome  For rules derived from a rule prototype  we assume the action term is unchanged  So if z  is not NIL  we use the distribution Pact  z z    that assigns probability one to z    If a rule is generated from scratch  we need to generate its action term  For simplicity  we assume that each action term consists of an action symbol and a distinct logical variable for each argument  we do not allow repeated variables or more complex terms in the argument list  The distribution Pact  z z    chooses the action term uniformly from the set of such terms when z    NIL  The next step in generating r is to choose its context   We define the distribution for  by means of a general formulamodification distribution Pfor      v   where v is the set of logical variables that occur in z and thus are eligible to be included in   This distribution is explained in Sec       To generate the outcome set O from O   we use essentially the same method we used to generate the rule set R from G  We begin by choosing the size n of the outcome set from the distribution Pnum  n n    where n    O    The distribution Pnum here is the same one used in Sec       one could use different  and  parameters here   Then  for i     to n  we choose which prototype outcome serves as the source for the ith local outcome  This choice is represented by an assignment variable Bi   As in the case of rules  we allow some local outcomes to be generated from scratch rather than from a prototype  this choice is represented by the seed outcome  The value of Bi is chosen from PB  bi  O    which assigns probability out to the seed outcome and is uniform over the rest of the outcomes  Once the source for each local outcome has been chosen  the next step is to generate the outcomes themselves  Recall that an outcome is just a formula  Thus  we define the outcome modification distribution using the general formula    DESHPANDE ET AL  modification process Pfor  oi  bi   v  that we will discuss in Sec       again  v is the set of logical variables in z   If bi is the seed outcome  then Pfor treats it as an empty formula  A list of outcomes is considered valid if it contains no repeats and no overlapping outcomes  Since repeats are excluded  the probability of a set of n outcomes is n  times the probability of any corresponding list  Thus  we get the following probability of generating a valid outcome set O and an assignment vector b  given that the prototype outcome set is O and the number of local outcomes is n  Pout  O  b O   n    n   n Y  PB  bi  O  Pfor  oi  bi   v        i    The last step is to generate the outcome probabilities p  These probabilities are sampled from a Dirichlet distribution whose parameter vector depends on the prototype parameters  and the assignment vector b   b            bn    Specifically  define the function f    b  to yield a parameter vector                n     such that   i            b i C b bi    n    if i  n       if i   n          where T is a set of simple terms and I is a function from elements of T to values  This representation guarantees that the elements of T are unordered  and each element is mapped to only one value  So to define our formula modification distribution Pfor      v   we will suppose     T  I  and     T    I     Recall that v is the set of logical variables that may be used in  and    To generate   we first choose a set Tkeep  T    where each term in T  is included in Tkeep independently with probability term   The terms in Tkeep will be included in T   Next  we generate a set Tnew of new terms to include in T   The size of Tnew   denoted knew   is chosen from a geometric distribution with parameter term   Then  for i     to knew   we generate a term ti according to a distribution Pterm  ti  v   This distribution chooses a predicate or function symbol f uniformly at random  and then chooses each argument of f uniformly from the set of constant symbols plus v  We consider a run invalid if any element of Tnew is in T    this ensures that while computing the probability of a term set T given a prototype term set T    we can recover Tkeep as T  T  and Tnew as T   T     This definition says that if oi is generated from prototype outcome bi  including the seed outcome   then  i is obtained by dividing up bi over all the local outcomes derived from bi   The number of such outcomes is computed by the function C b  bi    which returns the number of indices j              n  such that bj   bi   Finally  for the noise outcome  we have  n     n      Next  we choose the term to value function I  For a term t  T  T    the value I t  is equal to I   t  with probability   and with probability       it is sampled according to a distribution Pvalue  x v   If t    T    then I t  is always sampled from Pvalue  x v   This distribution Pvalue  x v  is uniform over the constant symbols in the language  plus v   To define the overall distribution for a local rule r given a rule prototype r   we sum out the assignment variables Bi   For valid rules r  we get        Prule  r r     Pact  z z    Pfor      v  Pnum  n n    X Pout  O  b O   n  Dir f    b   p        b  O  NIL  n   Here Dir f    b   is the Dirichlet distribution with parameter vector f    b    Generative Model for Rule Set Prototypes  The process that generates rule set prototypes G is similar to the process that generates local rule sets from G  but all the rule prototypes are generated from scratch  there are no higher level prototypes from which they could be derived  We assume that the number of rule prototypes in G has a geometric distribution with parameter proto   Thus the probability of a rule set prototype G of size m with  rule prototypes  r            rm    is         Modifying Formulas  The formulas that serve as contexts and outcomes are very simple  they are just conjunctions of literals  where a literal has the form t   x for some term t and value x  The term must be simple in the sense that each of its arguments is either a constant symbol or a logical variable  similarly  x must be a constant symbol or a logical variable   We do not care about the order of literals in a formula  and we would also like to rule out self contradictory formulas in which multiple values are assigned to the same term  It is convenient to think of a formula  as a pair  T  I     We are treating true and false as constant symbols  so a literal such as on X  Y   is represented as on X  Y     false   PG  G    Geom proto   m    m     m Y  Pproto  ri         i    We consider a generative run to be invalid if it generates the same rule prototype more than once  although we allow rule prototypes to have overlapping contexts  The rule prototypes are generated independently from the distribution Pproto  r    This is similar to the distribution for generating a local rule from scratch  as given by Eq      The action term z  is chosen from the uniform distribution Pact  z   NIL   the context formula  is generated by running our formula modification process on the empty formula  given the logical variables v from z    the number of outcomes n has a geometric distribution  and each outcome o in the outcome set O is also generated from       DESHPANDE ET AL   Pfor  o    v   The main difference from the case of local rules is that rather than generating an outcome probability vector p  we generate a vector of Dirichlet weights   defining a prior over outcome distributions  We use a hyperprior P   n   on  in which the sum of the Dirichlet weights has an exponential distribution  Thus  if r consists of an action term z  containing logical variables v  a context    and an outcome set O of size n   then  Pproto  r     Pact  z   NIL  Pfor      v  Y  Geom   n  P   n   Pfor  o   v  oO      Learning  In our problem formulation  we are given sets of examples x         xK from K source tasks  and a set of examples  xK     from the target task   In principle  one could maximize the objective in Eq    using the data from the source and target tasks simultaneously  However  if K is fairly large  the data from task K     is unlikely to have a large effect on our beliefs about the rule set prototype G  Thus  we work in two stages  First  we find the best rule set prototype G given the data for the K source tasks  Then   given G holding G fixed  we find the best rule set RK   and xK     This approach has the benefit of allowing us to throw away our data from the source tasks  and just transfer the relatively small G   Our goal in the first stage  then  is to find the prototype G with the greatest posterior probability given x            xK   Doing this exactly would involve integrating out the source rule sets R            RK   It turns out that if we think of each rule set Rk as consisting of a structure RkS and parameters RkP  namely the outcome probability vectors for all the rules   then we can integrate out RkP efficiently  However  summing over all the discrete structures RkS is difficult  Thus  we apply another MAP approximation  searching for S the prototype G and rule set structures R S           RK that together have maximal posterior probability  It is important that we integrate out the parameters RkP   because the posterior density for RkP is defined over a union of spaces of different dimensions  corresponding to different numbers of rules and outcomes in Rk    The heights of density peaks in spaces of differing dimension are not necessarily comparable  So it would not be correct to use a MAP estimate of RkP obtained by maximizing this density   the outcome probabilities  S P  G  R S           RK    PG  G   K Z Y k    Scoring Function  S In our search over G and R S           RK   our goal is to maximize the marginal probability obtained by integrating out        This equation trades off three factors  the complexity of the rule set prototype  represented by PG  G   the differences between the local rule sets and the prototype  Pmod  Rk  G   and how well the local rule sets fit the data  P  xk  Rk    Computing the value of Eq     for a given choice of G and R            RK is expensive  because it involves summing over all possible mappings from local rules to global rules  the a values in Eq     and all mappings from local outcomes to prototype outcomes  the b values in Eq      Integrating out the outcome probabilities p in each rule is not a computational bottleneck  we can push the integral inside the sums over a and b  and use a modified version of a standard estimation technique  Minka        for the Polya  or Dirichlet multinomial  parameters   Rather than summing over all possible local to global correspondences for rules and outcomes  we approximate by using a single correspondence  Specifically  for each rule set Rk   r            rm    we choose the rule correspondence vector a that maximizes the probability of the local rule contexts i given the global rule Qmcontexts  ai    ignoring outcomes  a   argmaxa i   PA  ai  G Pfor  i   ai     vi    Since each factor contains only one assignment variable ai   we can find the corresponding rule prototype for each local rule separately  Given the rule correspondence a  we next construct an outcome correspondence for each rule ri   We use the outcome correspondence that maximizes the probability of the local outcomes o            on given the outcome set O of the rule prototype Qn ai  ignoring the outcome probabilities  b   argmaxb i   PB  bi  O  Pfor  oi  bi   v   Again  the maximization decomposes into a separate maximization for each outcome  This greedy matching scheme can yield a poor result if a local rule ri has a context similar to a prototype rule  but very different outcomes  So as a final step  we compute the probability of each ri being generated from scratch  and set ai to NIL if this is a better correspondence  These approximations yield the following scoring function  an approximate version of Eq       which we use to guide our search  S Score G  R S           RK    K Z Y PG  G  k         Pmod  Rk  G P  xk  Rk   P Rk  P Rk  Pbmod  Rk  G P  xk  Rk            We modify the standard technique to take into account our hyperprior P   Also  we adjust for cases where some global outcomes are not included in a corresponding local rule  For a more detailed explanation  see the masters thesis by Deshpande           DESHPANDE ET AL   Here Pbmod is a version of the measure Pmod from Eq    in which we simply use a rather than summing over ai values  and we replace Prule with a modified version that uses b rather than summing over b vectors       Coordinate Ascent  We find a local maximum of Eq    using a coordinate ascent algorithm  We alternate between maximizing over local rule set structures given an estimate of the rule set prototype G  and maximizing over the rule set prototype given S estimates of the rule set structures  R S        RK    K Z Y  argmaxRS      RS    K  k    argmaxG P  G   K Y  P  xk  Rk  P  Rk  G   P  RkS  G   We begin with an empty rule set prototype  and use a greedy local search algorithm  described below  to optimize the local rule sets  Since R            RK are conditionally independent given G  we can do this search for each task separately  When these searches stabilize  that is  no search operator improves the objective function  we run another greedy local search to optimize G  We repeat this alternation until no more changes occur  Learning Local Rule Sets  During the coordinate ascent one task is to find the highest scoring local rule set Rk given the rule set G  The search is closely related the rule set learning algorithm problem in Zettlemoyer et al          There are three major differences      G provides a prior that did not exist before      the outcomes O for each rule are constrained to be nonoverlapping  and     the rule parameters p are integrated out instead of being set to maximum likelihood estimates         uses a subalgorithm to find the best set of outcomes  This outcome learning is done with a greedy search algorithm  as described in the next section  The following operators construct changes to the current rule set  Add Remove Rule  Two types of new rules can be added to the set  Rules can be created by an ExplainExamples procedure  Zettlemoyer et al         which uses a heuristic search to find high quality potential rules in a data driven manner  In addition  rules can be created by copying the action and context of one of the prototypes in the global rule set  This provides a strong search bias towards rules that have been found to be useful for other tasks  New rule sets can also be created by removing one of the existing rules in the current set   P Rk  k             Rule Set Search  In this section  we briefly outline a local rule learning algorithm that is a direct adaptation of the approach of Zettlemoyer et al         and highlight the places where the two algorithms differ  The search starts with a rule set that contains only the noisy default rule  At every step  we take the current rule set and apply a set of search operators to create new rule sets  Each of these new rule sets is scored  as described in section      The highest scoring set is selected and set as the new Rk   and the search continues until no new improvements are found  The operators create new rule sets by directly manipulating the current set  either adding or removing some number of the existing rules  Whenever a new rule is created  the relevant operator constructs the rules action and context and  Add Remove Literal  This operator selects a rule in the current rule set  and replaces it with a new rule that is the same except that one literal is added or removed from the context  All possible additions and deletions are proposed  Split on Literal  This operator chooses an existing rule and a new term that does not occur in that rules context  It removes the chosen rule and adds multiple new rules  one for each possible assignment of a value to the chosen term  Any time a new rule is added to a rule set  there is a check to make sure that only one rule is applicable for each training example  Any preexisting rules with overlapping applicability are removed from the rule set         Outcome Search  Given a rule action z and a context   the set of outcomes O is learned with a greedy search that optimizes the score  computed as described in section      This algorithm is a modified version of a previous outcome search procedure  Pasula et al          which has been changed to ensure that the outcomes do not overlap  Initially  O contains only the noise outcome  which can never be removed  It each step  a set of search operators is applied to build new outcome sets  which are scored and the best one is selected  The search finishes when no improvements can be found  The operators include  Add Remove Outcome  This operator adds or removes an outcome from the set  Possible additions include any outcomes from the corresponding prototype rule or an outcome derived from concatenating the changes seen as a result of action effects in a training example  following  Pasula et al           Any existing outcome can be removed  Add Remove Literal  This operator appends or removes a literal from a specific outcome in the set  Any literal that is not present can be added and any currently present literal can be removed        DESHPANDE ET AL   Split on Literal  This operator takes an existing outcome and replaces it with multiple new outcomes  each containing one of the possible value assignments for a new term  Merge Outcomes  This operator creates a new outcome computing the union of an existing outcome and one that could be added by the add operator described above  The original outcome is removed from the set  Two of the operators  add outcome and remove function  have the potential to create overlapping outcomes  To fix this condition  functions are greedily added to overlapping outcomes until no pair of outcomes overlap  This new outcome set is scored  and the search continues       Estimating the Dirichlet parameters for the Polya distribution does not have a closed form solution  but gradient ascent techniques have been developed for the maximum likelihood solution  Minka         To estimate the parameters for a rule prototype r   the required occurrence counts are computed for each prototype outcome and each local rule that corresponds to r  under the correspondence a described in Sec        If a local rule contains several outcomes corresponding to the same prototype outcome  under b   their counts are merged   Experiments  We evaluate our learning algorithm on synthetic data from four families of related tasks  all variants of the classic blocks world  We restrict ourselves to learning the effects of a single action  pickup X  Y    Adding more actions would not significantly change the problem  since the action is always observed  one can learn a rule set for multiple actions by learning a rule set for each action separately          For each source task  generate a set of Nsource state transitions to serve as a training set  In each state transition  the action is pickup A  B  and the initial state is created by assigning random values to all functions on  A  B    Then the resulting state is sampled according to the task specific rule set  Note that the state transitions are sampled independently of each other  they do not form a trajectory   Learning the Rule Set Prototype  The second optimization involves finding the highest scor    ing rule set prototype G given rule sets  R         RK Again  we adopt an approach based on greedy search through the space of possible rule sets  This search has exactly the same initialization and uses all of the same search operators as the local rule set search  There are three differences      the AddRule operator tries to add rules that are present in the local rule sets  without directly referencing the training sets      we relax the restriction that rules and outcomes can not overlap  simplifying some of the checking that the operators have to perform  and     we need to estimate the Dirichlet parameters for the outcomes for each new prototype rule considered by the structure search         Generate K source task rule sets from a prior distribution  This prior distribution is implemented by a special purpose program for each family of tasks  This is slightly more realistic than generating the rule sets from a rule set prototype expressed in our modeling language   Methodology     Run our full learning algorithm on the K source task training sets to find the best rule set prototype G      Generate a target task rule set RK   from the same distribution used in Step       Generate a training set of Ntarget state transitions as in Step    using RK   as the rule set  bK   for the target task using the    Learn a rule set R algorithm from Sec       with G as the fixed rule set prototype     Generate a test set of      initial states using the same distribution as in Step    For each initial state s  compute the variational distance between the next state distributions defined by the true rule set RK   and bK     This is defined in our case the learned rule set R as follows  with a equal to pickup A  B  and s  ranging over possible next states  X  Finally  compute the average variational distance over the test set  Variational distance is a measure of error  but we would like the y axis in our graphs to be a measure of accuracy  so we use     variational distance   The free parameters in our hierarchical Bayesian model  and hence in our scoring function  are set to the same values in all experiments  While we found that the scoring function in Eq     leads to good results on large training sets  we also saw that with small training sets  the very small probabilities of formulas  in contexts and outcomes  tend to dominate the score  For the experiments reported    Each run of our experiments consists of the following steps   bK     p s   s  a  RK      p s   s  a  R  s   The distribution used here is biased so that A is always a block and the robots gripper is usually empty  this focuses our evaluation on cases where pickup A  B  has a chance of success    DESHPANDE ET AL      Slippery Gripper Domain    No Transfer  x      x                Variational Distance      Variational Distance   Gripper Size Domain                                                                     No Transfer  x      x                                         Target Task Examples           a    b   Slippery Gripper with Size Domain  Random Domain                       No Transfer  x      x                                                 Target Task Examples   c      Variational Distance        Variational Distance                                 Target Task Examples              No Transfer  x      x      x                                                   Target Task Examples   d   Figure    Accuracy using an empty rule set prototype  labeled No Transfer  and transfer learning  labeled KxN where K represents the number of source tasks and N represents the number of examples per source task  here  we use a modified scoring function in which each occurrence of the formula distribution Pfor is raised to the power      The fact that this ad hoc modification yields better results suggests that our distribution over formulas is overly flat  and it would be worthwhile to develop a formula distribution that gives common literals or subformulas higher probability       Results  In this section  we present results in the four blocks world domains  For each domain  we briefly describe the task generation distribution and then present results   For each experiment  we graph variational distance as a function of the number of training examples in the target task  Each experiment was repeated    times  our graphs show the average results with     confidence bars  The time required for each run varied from    seconds to    minutes depending on the complexity of the domain  Our first experiment investigates transfer learning in a domain where the rule sets are very simple  just single rules  but the rule contexts vary across tasks  We use a family of tasks where the robot is equipped with grippers of varying sizes  There are seven different sizes of   Deshpande        presents a more detailed description of these domains   blocks on the table  the robot can only pick up blocks that are the same size as its gripper  Thus  each task can be described by a single rule saying that if block X has the proper size  then pickup X  Y   succeeds with some significant probability  this probability also varies across tasks   If X has the wrong size  then no rule applies and there is no change  Since the proper size varies from task to task  the rules for different tasks have different contexts  To increase the learning difficulty  two extra distracter predicates  color and texture  are randomly set to different values in each example state  Fig    a  shows the transfer learning curves for this domain  The transfer learners are consistently able to learn the dynamics of the domain with fewer examples than the non transfer learner  In practice  in each source task  the algorithm learns the specific pickup rule with the appropriate size literal in the context  The algorithm learns a single rule prototype whose context also contains some size literal  This rule prototype provides a strong bias for learning the correct target task rule set  the learner only has to replace the size literal in the prototype with the correct size literal for the given task  To see how transfer learning works for more complex rule sets  our next experiment uses a slippery gripper domain adapted from  Kushmerick et al          The correct model for this domain has four fairly complex rules  describing       DESHPANDE ET AL   cases where the gripper is wet or not wet  which influences the success probability for pickup  and the block is being picked up from the table or from another block  in the latter case  the rule must include an additional outcome for the block falling on the table   The various tasks are all modeled by rules with the same structure  but include relatively large variation in outcome probabilities  Fig    b  shows the transfer learning curves for the slippery gripper domain  Again  transfer significantly reduces the number of examples required to achieve high accuracy  We found that the transfer learners create prototype rule sets that effectively represent the dynamics of the domain  However  the structure of the prototype rules do not exactly match the structure of the four specific rules that are present in each source task  Despite this fact  these prototypes still capture common structure that can be specialized to quickly learn the correct rules in the target task  Our third domain  the slippery gripper domain with size  is a cross between the slippery gripper domain and the gripper size domain  In this domain  all four rules of the slippery gripper domain apply with the addition that each rule can only succeed if the targeted block is of a certain taskspecific size  Thus  the domain exhibits both structural and parametric variation between tasks  As can be seen in Fig    c   the transfer learners perform significantly better than the non transfer learner  In this case  the rule set prototype provides both a parametric and structural bias to better learn the domain  Our final experiment investigates whether our algorithm can avoid erroneous transfer when the tasks are actually unrelated  For this experiment  we generate random source and target rule sets with   to   rules  Rule contexts and outcomes are of random length and contain random sets of literals  Since rule sets sampled this way may contain overlapping rules or outcomes  we use rejection sampling to ensure that a valid rule set is generated for each task  As can be seen in Fig    d   the transfer and non transfer learners performances are statistically indistinguishable  The learning algorithm often builds a rule set prototype containing a few rules with random structure and high variance outcome distribution priors  These prototype rules do not provide any specific guidance about the structure or parameters of the specific rules to be learned in the target task  However  their presence does not lower performance in the target task      Conclusion  In this paper  we developed a transfer learning approach for relational probabilistic world dynamics  We presented a hierarchical Bayesian model and an algorithm for learning a generic rule set prior which  at least in our initial experiments  holds significant promise for generalizing across  different tasks  This learning problem is particularly difficult due to the need to learn relational structure along with probabilities simultaneously for a large number of tasks  The current approach addresses many of the fundamental challenges for this task and provides a strong example that can be extended to work in more complex domains and with a wide range of representation languages  
 Many applications of intelligent systems require reasoning about the mental states of agents in the domain   We may want to reason about  an agent s beliefs  including beliefs about other agents  we may also want to reason about an agent s preferences  and how his beliefs and pref erences relate to his behavior  We define a prob abilistic epistemic logic  PEL  in which belief statements are given a formal semantics  and provide an algorithm for asserting and query ing PEL formulas in Bayesian networks  We then show how to reason about an agent s be havior by modeling his decision process as an in fluence diagram and assuming that he behaves rationally  PEL can then be used for reasoning from an agent s observed actions to conclusions about other aspects of the domain  including un observed domain variables and the agent s men tal states      Introduction  When an intelligent system interacts with other agents  it frequently needs to reason about these agents  beliefs and decision making processes  Exam ples of systems that must perform this kind of reason ing  at least implicitly  include automated e commerce agents  natural language dialogue systems  intelligent user interfaces  and expert systems for such domains as international relations  A central problem in many domains is predicting what other agents will do in the future  Since an agent s decisions are based on its be liefs and preferences  reasoning about mental states is essential to making such predictions  An equally important task is making inferences about the state of the world based on another agent s beliefs  possibly re vealed through communication  and decisions  Since other agents often observe variables that are hidden from our intelligent system  their beliefs and decisions may provide information about the world that the sys tem cannot obtain by other means   Daphne Koller Computer Science Department Stanford University Stanford  CA            koller cs  stanford  edu Suppose  for example  that we are developing a sys tem to help analysts and policymakers reason about international crises  In one example  based loosely on a scenario presented in      Iraq purchases weapons grade anthrax  a deadly bacterium  and begins to de velop a missile capable of delivering anthrax to targets in the Middle East  There is a vaccine against anthrax which the United States is currently administering to its troops  but for ethical reasons the U S  has not done controlled studies of the vaccine s effectiveness  Iraq  on the other hand  may have performed such tests  Iraq s purpose in attempting to develop an anthrax equipped missile is to strike U S  Air Force personnel in Turkey or Saudi Arabia  inflicting as many casual ties as possible  However  if Iraq works on developing the missile  it must use an old weapons plant that is prone to fire  a fire at the plant would be visible to U S  satellites  We would like our intelligent system to be able to answer questions like   If we observe that Iraq has purchased anthrax  what is the probability that the vaccine is effective    and  Does Iraq believe  e g   with probability at least      that if they begin developing an anthrax carrying missile  the U S  will realize  e g   believe with probability at least      that they have acquired anthrax    Efforts to formalize reasoning about beliefs date back to Hintikka s work on epistemic logic      The classical form of epistemic logic does not allow us to quantify an agent s uncertainty about a formula  we can only say that an agent knows  p or does not know  p  Prob abilistic logics of knowledge and belief         remove this limitation  However  evaluating the probability that an agent a assigns to a formula  p in a model of one of these logics requires evaluating  p at every state that a considers possible  As the number of states is exponential in the number of domain variables  this process is computationally intractable  One of the main contributions of this paper is the introduction of a probabilistic epistemic logic  PEL  that uses Bayesian networks  BNs       as a compact        UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       representation for the agents  beliefs  This framework allows us to perform probabilistic epistemic inference without enumerating an exponential number of states  Our approach is based on the common prior as sumption common in economics      It states that the agents have a common prior probability distribu tion over outcomes and their beliefs differ only because they have different observations  this assumption al lows us to use a single BN for representing all the agents  beliefs  We describe an implemented algorithm for adding nodes to this BN so that it can be used to evaluate arbitrary PEL formulas  In most domains  agents do not just passively observe the world and form beliefs  they also make decisions and act  In many existing probabilistic reasoning sys tems  e g                a human expert defines the con ditional probability distributions  CPDs  that describe how likely an agent is to take each possible action  given an instantiation of the variables relevant to the agent s decision process  But this technique relies on a human s understanding of how agents make deci sions  and it may be difficult for a human to perform such analysis for a complex model  If we assume an agent acts rationally  the intelligent system can use de cision theory to derive the CPDs for the agent s actions automatically  This problem involves subtle strategic  game theoretic  reasoning when multiple agents are acting and have uncertainty about each other s ac tions      In this paper we restrict attention to the case where only one agent acts  We model the agent s decision process using an influence diagram  ID       then convert this influence diagram into a Bayesian network  This extension allows us to use PEL in or der to reason about the decision maker s likely course of action  and  more interestingly  to use his actions to reach conclusions about unobserved aspects of the world  We can also extend the framework to reach con clusions about the decision maker s preferences  which may not be common knowledge   main  a set A of agents  and a number Na of observa tion stages for each agent a E A  At each of an agent s observation stages  there is a certain set of variables whose values the agent has observed  In this paper  we will make the perfect recall assumption  agents do not forget observations they have made  The values of the variables themselves do not change from stage to stage  if we want to model an aspect of the world that changes over time  we must create separate variables for separate times   Given these parameters  the language of PEL consists of the following   atomic formulas of the form X  v  where X E  I  and v E dom X   the domain of X   Note that dom X  need not be  true  false   it may be any non empty finite set   formulas of the form   P and cp V  if   where cp and  if  are PEL formulas  we use cp       as an abbreviation for     P V    J    formulas of the form BelCond     cp I  if    where a E A  i E           Na   cp and  if  are PEL for mulas  and r is a probability in           Our atomic formulas play the same role as propositions in the FH logic  The modal formula BelCond     cp I  if   should be read as   according to agent a in stage i  the conditional probability of cp given  if  is at least r   The unconditional belief operator Bel     cp  is an abbreviation for BelCond   cp I true   We will provide formal semantics for thee statements after defining a model theory for PEL  Note that the ability to express conditional belief statements is not included in the FH logic  although their belief statements are more expres sive than ours in allowing probabilities to be related by arbitrary linear inequalities   modelM of the PEL language having random variables  I   agents A and observation process lengths  Na aEA is a tuple  S   r  K  P   where  S is a set of possible states of the world  is a value function mapping each random vari able symbol X E  I  to a discrete random variable XM  a function from S to dom X    K maps each pair in     i  E A x z  i  Na  to an accessibility relation Ka i which is an equiv alence relation on S  P is a probability distribution over S   Definition   A       A Probabilistic Epistemic Logic  Our probabilistic epistemic logic  PEL  is essentially a special case of the logic of knowledge and belief defined by Fagin and Halpern      FH hereafter   In PEL  we assume that agents have a common prior probability distribution over states of the world  and an agent s local probability distribution at state s is equal to this global distribution conditioned on the set of states the agent considers possible at s  These assumptions are not uncontroversial  but we will defer a discussion of the alternatives until Section    The language of PEL is parameterized by a set  I  of random variable symbols  each with an associated do        r  a        Thus  a PEL model specifies a set of states and maps each random variable symbol to a random variable de fined on those states  In the rest of the paper  we will often refer to a random variable XM simply as X  it should be clear from context whether a random vari able or a random variable symbol is intended  The   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       accessibility relation Ka i holds between worlds that are indistinguishable to agent a at stage i  In other words  at stage i  if s and s  are in the same accessibil ity equivalence class  agent a has no information that allows him to distinguish between world s and world s   We will use the notation Ka i s  to refer to the set of states s  E S such that Ka i s  s    With this semantics  the perfect recall assumption is formalized as a requirement that if  Ka i s  s    then for all j   i  we also have that   Ka j s  s    P is the agents  common prior probability distribution over the set of states S  For each agent a  stage i  and state s  we can derive a local distribution Pa i s over the states accessible from s  This local distribution is the subjective probability that the agent assigns to each accessible state  Definition   Consider any a E A  i E           Na   and s E S  Then for each state s  E Ka i  s   we define  Pa i s s   P s  I Ka i s       Note that an agent a s subjective probability distri bution varies from state to state  Thus  other agents  uncertainty about the state of the world can lead to uncertainty about a s beliefs  For example  in some states Iraq believes the anthrax vaccine to be effec tive  and in other states it does not  the U S  may not be able to distinguish these two kinds of states  The semantics of PEL will be familiar to readers with background in modal logic  We introduce a satisfac tion relation F   such that  M  s  F  r p means the for mula r p is satisfied at world s in model M  We also define an inverse relation  r p  M   s E S   s F  r p       M  s  F  r p if one of the following holds  r p is an atomic formula X v and X  s  v  r p    lj  and  M  s   lt   J  r p  ljJ V x  and  M  s  F   ljJ or  M  s  F  X r p BelCond      J I x   Pa i s  x M         and Pa i s   lf  M I  X M   r   Definition                        Note that if there are no states accessible from s that satisfy x  then BelConda i is defined to be false  This definition of satisfaction allows us to evaluate a PEL formula at any states in a given model M  We can then use the prior probability distribution P to find the total probability of states that satisfy a for mula r p  If we do this evaluation directly in the PEL model  we need to evaluate r p at each of lSI states  and the size of the state space can be quite large   typ ically exponential in the number of variables  In the next section  we present a representation for PEL mod els based on Bayesian networks  and an algorithm that uses the independence assumptions encoded in the BN       to find the probabilities of PEL formulas efficiently  Thus  we are proposing an efficient model checking procedure for PEL formulas  We could also provide a proof system for PEL  in fact  Fagin and Halpern pro vide a complete axiomatization for their logic  How ever  it is reasonable to assume that an intelligent agent will have a complete model representing its own belief state  and it is often more efficient to assert and query formulas in a model than to attempt to derive formulas from a knowledge base  which would need to be quite large to completely define the agent s beliefs      Representing a PEL model as a BN  Bayesian networks provide a compact representation of a complex probability space  We can augment Bayesian networks to provide a compact representa tion of a certain class of PEL models  The basic idea is as follows  We define a PEL model M over the set of random variables  I  using a BN B that has a node for each X E  r  I    We define S to be the set of all possible assignments x to the variables in  r   I    The distribution defined by B specifies the distribution P over S  To define the accessibility relation Ka i in this frame work  we place the restriction that an agent s obser vations always correspond to some set of random vari ables  Observation Set Assumption  For every a E A and i E           Na   there is an observation set Oa i C  r   I   such that  Ka i s  s      VX E Oa i   X s      X s     Given this assumption  the perfect recall assumption is equivalent to the requirement that if j   i  then Oa i  Oa j Definition   Let M  S   r  K  P  be a PEL model  let B be a EN defining a joint distribution Pr and let Oa i be observation sets consisting of random variables appearing in B  We say that M and  B   Oa i   are equivalent if   for every X E  I   X is in B   for any instantiation x of  r  I    P x  Pr x    for each agent a and stage i  Ka i is related to Oa i       according to the Observation Set assumption   We can now use this framework to model the sce nario described in the introduction  The equiva lent Bayesian network is shown in Figure    Let i stand for Iraq and u stand for the United States  We assume that Iraq has a six stage observation pro  V  P   B    V   Oi    V  P   Oi   cess  Oi l           UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            struction process with an example  but it is clearly general enough to model uncertainty about whether any variable X is in any observation set Oa i The modified BN and observation sets now define a PEL model over a richer set of states than simply the pos sible instantiations of  r   fl      Figure    Basic Bayesian network for the crisis man agement problem     V P B F M          V P B F M A   and   V P B F M A C   Meanwhile  the U S  has Ou l     Ou z   F   and Ou     F A C              Before it decides whether to attack the U S  air base  is Iraq quite sure that U S  casualties will be either high or medium  We can answer this question by evaluat ing the formula Bel        C  high  V  C  medium    A more complex qery is  Does Iraq believe with probability at least     that if they begin devel oping an anthrax carrying missile  the U S  will believe with probability at least     that they have acquired anthrax    If we fill in the stages of the observation processes that are im plicit in this question  we get the PEL formula BelCond fg  Bel    P  true  B  true       I     The Observation Set Assumption implies that it is common knowledge what variables agent a has ob served at stage i  In many cases  this assumption is unrealistic  in our example  the U S  might be un certain whether Iraq observed the effectiveness of the anthrax vaccine at stage    As we show  we can han dle such situations without modifying PEL  We simply add a new node Observes     V  to the BN of Figure    This node is true if Iraq has observed V at stage    and false otherwise  it can have as parents any nodes that are not descendents of V  We also add a node ObservedValue     V  that has V and Observes    V  as parents  Its domain is dom  V  U  unknown   It takes the value unknown if Observes     V  is false  but has the same value as V if Observes     V  is true  We let      contain Observes     V  and ObservedValue     V   but not V itself  Under this construction  it is common knowledge that Iraq knows at stage   whether it has observed V at stage    and knows what value it has observed  However  since the value of Observes     V  is not common knowledge  the U S  may not know whether ObservedValue     V  has the uninformative unknown value  or is a copy of V  We have defined this con   Evaluating PEL Formulas in a BN  This framework allows us to represent a PEL model compactly  but how do we answer queries such as the ones shown above  We can use an equivalent BN B to find the probability P X  v  of any atomic formula  simply by finding Pr X   v   We want to extend B so that it allows us to compute the probability of an arbitrary PEL formula cp  To this end  we first define an indicator variable  TJ  cp  which is true if M  s F  cp and false otherwise  We then extend the BN to include not only the random variables  r   fl   but also indicator variables for some set  of formulas that we may assert or query  Since both  r  fl  and all such indicator variables are defined on S  the distribution P over S defines a joint distribution for  r  fl Ury     Our goal in constructing the augmented BN is to ensure that it defines the same joint distribution  Definition   Let M    S   r  K  P  be a PEL model  let B be an augmented BN defining a joint distribution Pr and let Oa i be observation sets  Let  be a set of PEL formulas  Then M and  B   Oa i   are  equivalent if M and B are equivalent and   for every cp E   TJ  cp  is in B   for any instantiation x of   r  fl  U TJ      P x    Pr x   We now present an algorithm that  given a BN that is equivalent to a PEL model M  adds indicator vari ables to create an augmented BN that is  equivalent to M  for an arbitrary set of formulas   The cen tral function of our algorithm is CreateNode B cp   which takes as arguments a BN l  and a PEL formula cp  Its purpose is to create an indicator node for cp  store it in a global table  and give it the proper condi tional distribution given the other variables in B  If there is already a node  TJ  cp  in the table  CreateN ode returns immediately  If cp is an atomic formula X  v  then the function creates a node  J  cp  whose sole parent is X  It defines the CPD of TJ  cp  such that  J  cp    true  with probability    if X  v  and TJ  cp   false otherwise  If cp      lj J  the function calls CreateNode B   lj J   Then it creates a node  TJ  cp  with one parent  TJ   lj J   It defines the CPD of  J  cp  like a NOT gate  TJ  cp    true iff TJ   lj J    false  If cp    ljJ V x  the function calls        UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       Calling CreateNode on this formula results in a re cursive call to create a node for   C   h  V  C  m    which in turn calls CreateNode for  C   h  and  C   m    There are five random variables in Iraq s observation set at stage    but it turns out that only two  V  vaccine effective  andM  missile developed   are relevant to   C   h  V  C   m     To obtain the CPD for TJ   p    we perform BN inference to calculate Pr ry   C  h  V  C m   l rei  for each of the four in stantiations rei of  V M   In our parameterization of the model  it turns out that this probability is      only when rei assigns false to V and true toM  So the CPD for TJ   p  specifies true with probability   in this case  and false with probability   in the other three cases  The resulting BN is illustrated in Figure       In proving the correctness of this algorithm  we will use the following lemma  Figure    Bayes net with indicator variables added   Lemma   Let M be a PEL model  a E A  i E           Na   and s E S  Let Oa i s be the instantia tion of Oa i that s satisfies  Then for any formulas  p and  P     CreateNode B  P  and CreateNode B x   Then it creates a node TJ   p  with two parents  TJ   P  and TJ  x   In this case  the CPD for TJ   p  is like an OR gate  TJ   p   true iff TJ   P   true or TJ  x   true  The interesting case is where  p   BelCond    P I x   As usual  the function begins by  calling CreateNode B  P  and CreateNode B x   Now  recall that Oa i is the set of variables whose values agent a has observed at stage i  Clearly  whether the agent assigns probability at least r to  P given x depends on what the agent has observed  However  it may be that not all the observations are relevant  some of the variables in Oa i may be d separated from TJ   P  given the other observations and TJ  x   Using an algorithm such as that of       CreateNode determines the minimal subset Rei C Oa i of relevant observations such that Oa i Rei is d separated from TJ   P  given Rei U  TJ  x    It then creates a node TJ   p  with the elements of Rei as parents  Next  CreateNode sets TJ  x    true as evidence  and uses a BN inference algorithm  e g         to obtain a joint distribution over TJ   P  and Rei  For each instantiation rei of Rei  the function uses the joint distribution to calculate Pr ry   P  I  rei  TJ  x    true    We then set the CPD P ry   p  I rei  to give probability   to true if Pr  P I  rei  TJ  x    true    r and probability   to false otherwise     As an example of how this algorithm works  consider the formula we discussed earlier involving Iraq s beliefs about U S  casualties    p  Bel     C  high  V  C  medium    Pa i s   p M I   P M     P ry  p   true I  oa i s TJ  P   true   This lemma puts the criterion for satisfaction of BelCond    p   P  in a more convenient form  The proof  which we do not give here  uses the definition of Pa i s and the Observation Set assumption  Proposition      Correctness of CreateNode   Suppose an augmented BN B is D  equivalent to a PEL modelM  Then when CreateNode B  p  terminates  B is     U   p   equivalent toM  Proof  We use structural induction on  p  the induc tive hypothesis is that Proposition   holds for all sub formulas of  P  Thus  the recursive calls at the begin ning of CreateNode make it so B is f equivalent to M  where r is    plus all the subformulas of  p  Then CreateNode B   p  adds TJ   p  to B  Let Pr be the dis tribution defined by B before this addition  and Pr  be the distribution afterwards  By the definition of f equivalence  we know that for every instantiation x oh  J  Ury  f   P x   Pr x   We must show that for every instantiation  x   TJ  p   t   of  r  J   U TJ      U  TJ   p     P   x  TJ   p     t     Pr     x  TJ   p   t         Let pa be the instantiation x limited to the par ents of the newly created node TJ   p     Then by the definition of conditional probability and the chain   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            rule for Bayes nets  equation     is equivalent to  P ry  cp    t I x   P x    Pr  ry  cp    t I pa   Pr  x   CreateNode only adds nodes as children of existing nodes  so the marginal distribution over existing nodes is not changed  Thus Pr   x   Pr x   Along with the fact that P x   Pr x   this allows us to reduce equa tion     to  P ry  cp    t I x   Pr   ry  cp   t I pa   In this case  CreateNode adds a node  fJ  cp  with the relevant members of Oa i as parents  to simplify the presentation  we will assume that all members of Oa i are relevant   Suppose x assigns values Oa i to Oa i Then what we have to prove is    t I x   Pr   ry  cp   t I Oa i              lraq Purchases Anthrax  Dl        So what we must show is that the CPDs defined by CreateNode are the correct CPDs for the indicator variables  The cases where cp is an atomic or Boolean formula are straightforward  so we move directly to the interesting case where cp  BelCond     lj  I x     P ry  cp   Anthrax Vaccine Effective  V        Consider any state s in which x holds  By Lemma   and the definition of satisfaction   fJ  cp   s    true if and only if  P  ry   l     true I Oa i s  f   x   true      r  But  ljJ and x are subformulas of cp  and Oa i C II   so by the assumption that B is r equivalent toM   P ry  l     true I Oa i  fJ X   true    Pr  ry   l     true I Oa i  fJ X   true  This last probability value is exactly what CreateNode compares to r in constructing the  CPD for  fJ  cp   So the CPD is correct  Once we have a BN that is Ll equivalent to M we can assert any formula cp E Ll by setting  f   cp   true as ev idence  To find the probability of any formula cp E   we simply query  f   cp    true  For example  the for mula cp   Bel     C  h  V  C  m   that we dis cussed earlier has probability      in our model  How ever  if we assert V  false  i e   the vaccine is ineffec tive   then Pr cp  goes up to      The number of BN queries required to make a BN  equivalent toM is linear in the number of BelCond for mulas  since CreateNode is only called once for each subformula  The CreateNode function takes time exponential in the maximal number of relevant obser vations for the BelGond subformulas  as we need to compute the probability Pr ry     J  I  rei   f   x    true   for every instantiation rei of Rei  Most naively  we simply run BN inference for each rei separately  In cer tain cases  we can get improved performance by run ning a single query Pr ry   l     Rei I  f   X    true  and then renormalizing appropriately  this approach can  Figure    Influence diagram representing Iraq s deci sion scenario  No forgetting arcs are not shown allow us to exploit the dynamic programming of BN inference algorithms  We note that the newly added nodes also add complexity to the BN  and can make the inference cost grow in later parts of the computa tion  e g   by increasing the size of cliques       Reasoning about Decisions  So far  we have assumed that we have a probability distribution over all variables in the system  In prac tice  however  we have agents who make decisions in accordance with their beliefs and preferences  In our example  P  B and A are actually decisions made by Iraq  Our construction took these to be random vari ables  each with a CPD representing a distribution over Iraq s decision  If these CPDs are reasonable  then our system will give reasonable answers  e g   we will obtain a lower probability that the anthrax vac cine is effective if we observe that Iraq has purchased anthrax  since it would not be rational for Iraq to pur chase a bacterium for which the U S  has an effective vaccine  We would like to extend our framework to in duce automatically the actions that agents will take at various decision points  As discussed in the introduc tion  this problem is quite complex when there are mul tiple decision makers with conflicting goals  We there fore focus on the case of a single decision maker  We note  however  that we can still have multiple agents reasoning about the decision maker and about each other s state of knowledge  Assuming that agents act rationally  we can automate the construction of CPDs for decision nodes by mod eling the decision maker s decision process with an in fluence diagram  and solving the influence diagram to obtain CPDs for the decision nodes  Somewhat sur prisingly  the possibility of modeling other agents with influence diagrams has not been explored deeply in the   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       existing literature  although Nilsson and Jensen men tion it in passing       Suryadi and Gmytrasiewicz      take an approach similar to ours in that they use an ID to model another agent s decision process  However  they discuss learning the structure and parameters of the ID from observations collected over a large set of similar decision situations  We assume that the ID is given  and concentrate on the inferences that can be made only from a few observations about the current situation  Figure   depicts an influence diagram for the scenario described in the introduction  An influence diagram is a directed acyclic graph with three kinds of nodes  Chance nodes  like nodes in a BN  correspond to ran dom variables  they are represented by ovals  Decision nodes  drawn as rectangles  correspond to variables that the decision maker can control  Utility nodes  drawn as diamonds  correspond to components of the decision maker s utility function  The decision nodes of an ID are ordered D         Dn according to the order in which the decisions are made  The parents of D   denoted Pa D    are those variables whose value the decision maker knows when decision D  is made  Thus  when we are creating a PEL model and an ID for the same scenario  the decision maker s observation stages correspond to his decision nodes  with Oa i equal to Pa Di   A utility node U  repre sents a deterministic function fi from instantiations of Pa  U   to real numbers  The utility of an outcome is the sum of the individual utility functions k Solving an influence diagram means deriving an opti mal policy  consisting of a decision rule for each deci sion node  A decision rule    for a node D  is a function from dom Pa D    to dom D    For each instantiation of Pa D    the decision rule gives the action that max imizes the decision maker s expected utility  assuming it will act rationally in all future decisions  The stan dard algorithms for solving IDs utilize backwards in duction  the decision rules for the decision nodes are calculated in the reverse of their temporal order      After we have the decision rules  we can easily trans form an influence diagram V into a Bayesian network B V   We remove the utility nodes  and change the de cision nodes into chance nodes  ordinary BN nodes   If D  is a decision node  then for each instantiation pa of Pa D    we create a probability distribution that gives probability   to J  pa    and probability   to all other elements of dom D    This distribution becomes the CPD for D  given pa  We can use this system to make inferences about un observed world variables based on evidence of agents  actions  Suppose the parameters of the model V de picted in Figure   are such that the prior probability       of the vaccine being effective is      but it is irrational for Iraq to purchase anthrax unless it has observed the vaccine to be ineffective  As above  we may need to add some additional nodes to V  such as Observed and ObservedValue nodes to model the U S  s uncertainty about whether Iraq observes V at stage    We then use the method described in this section to derive CPDs for Iraq s decision nodes  creating a BN B V   The in fluence diagram defines the observation sets for Iraq  we will use the U S  observation sets described in Sec tion    We can then use the algorithm of Section   to find the probabilities of arbitrary PEL formulas in the PEL model corresponding to B V   At stage    the U S  assigns probability     to the vaccine being effective  all states satisfy Bel     V  true   At stage    however  the situation changes  It turns out that Bel     V   true  is true if and only if there is not a fire at the Iraqi bi ological weapons plant  A fire provides the U S  with strong evidence that Iraq has begun developing an anthrax carrying missile  which would not be ratio nal unless Iraq had purchased anthrax  which implies that Iraq has observed the anthrax vaccine to be in effective  So in this model  Pr Bel    V  true     Pr F   false   In a more comple query  we could compute Pr Bel    V  true  I V  false   i e   the probability that the U S  will believe the vaccine to be effective despite the fact that it is not  The answer to this query would depend on the prior probability about the vaccine s effectiveness  Iraq s decisions  and the chances of observing a fire  The CPDs for decision nodes derived by solving an influence diagram become part of the common prior distribution in the resulting BN  However  these CPDs are derived using the decision maker s utility function  Thus  in assuming that the decision maker s decision rules are part of the common prior  we are implicitly assuming that the decision maker s utility function is common knowledge  Like the assumption that obser vations are common knowledge  this is an assumption we would like to relax  Just as we introduced Observes nodes to model un certainty about an agent s observations  we can in troduce preference nodes to model uncertainty about an agent s utility function  These preference nodes are parents of particular utility nodes  and modify the way the utility depends on other variables  They are also in all the decision maker s observation sets  as suming he knows his own preferences  One might pro pose to use continuous valued preference nodes that define a distribution over the decision maker s util ity value  The problem with this approach is that these continuous valued preference nodes must be par ents of every decision node  and standard ID solution   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            algorithms cannot handle continuous values in such a context  We therefore use discrete valued prefer ence nodes  with the resulting coarse grained prefer ence models  For example  we can introduce a node A representing Iraq s aversion to doing business with criminal biological weapons dealers  which is a parent of the cost node associated with D   If A high  then the cost is greater in magnitude than it would be if A low  The preference node A is in the parent sets of all Iraq s decision nodes  but the U S  will not be able to observe it directly           Discussion and Future Work  This paper combines epistemic logic with Bayesian networks to create an integrated system for probabilis tic reasoning about agents  beliefs and decisions  Al though PEL is essentially a restricted version of the logic presented by Fagin and Halpern  we believe it is flexible enough to be useful in many practical applica tions  Furthermore  the simplicity of PEL allows us to define an algorithm for finding the probability of a for mula in a PEL model using a Bayesian network  rather than constructing the PEL model explicitly  We also show how to construct this Bayesian network from an influence diagram  rather than having a human fill in the CPDs for nodes that represent an agent s decisions  Our approach is limited by the common prior assump tion  which implies that all differences between agent s beliefs are due to their having different observations  This assumption is common in economics  and has important ramifications      It allows agents  beliefs to be arl  itrarily diffenmt  as long as they have re ceived sufficiently different observations  But it may be impractical to represent in a BN all the different observations that have caused agents  beliefs to di verge  An alternative is to explicitly represent un certainty about each agent s probability distribution  However  this approach introduces substantial com plications  Do we also model one agent s distribution about another agent s distribution  If so  do we model the infinite belief hierarchy  Therefore  the extension to this case is far from obvious  Another assumption that we would like to relax is that agents are perfect probabilistic reasoners and decision makers  The other obvious limitation of the system described in this paper is that although it can reason about the beliefs of an arbitrary number of agents  it can only reason explicitly about one agent s decisions  If we wish to have the system automatically derive the CPDs for decisions made by multiple agents  the max imum expected utility solution concept is no longer appropriate  since the agents do not have probability distributions over each other s actions  We could uti   lize game theoretic solution concepts     to find ratio nal strategies for the agents  and then substitute these strategies for the agents  CPDs as we did in Section    the rest of our results would still be applicable  How ever  the framework of multi agent rationality is sub stantially more ambiguous than the single agent case  so that this approach does not define a unique answer  We hope to investigate this issue in future work  Acknowledgments  We thank Yoav Shoham for use ful discussions and Uri Lerner and Lise Getoor for their work on the PHROG system  This work was supported by ONR contract N         C      under DARPA s HPKB program  
