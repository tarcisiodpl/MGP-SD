 Various tasks in decision making and decision support systems require selecting a preferred subset of a given set of items  Here we focus on problems where the individual items are described using a set of characterizing attributes  and a generic preference specification is required  that is  a specification that can work with an arbitrary set of items  For example  preferences over the content of an online newspaper should have this form  At each viewing  the newspaper contains a subset of the set of articles currently available  Our preference specification over this subset should be provided offline  but we should be able to use it to select a subset of any currently available set of articles  e g   based on their tags  We present a general approach for lifting formalisms for specifying preferences over objects with multiple attributes into ones that specify preferences over subsets of such objects  We also show how we can compute an optimal subset given such a specification in a relatively efficient manner  We provide an empirical evaluation of the approach as well as some worst case complexity results      Introduction Work on reasoning with preferences focuses mostly on the task of recognizing preferred elements within a given set  However  another problem of interest is that of selecting an optimal subset of elements  Optimal subset selection is an important problem with many applications  the choice of feature subsets in machine learning  selection of a preferred bundle of goods  as in  e g   a home entertainment system   finding the best set of items to display on the users screen  selecting the best set of articles for a newspaper or the best members for a committee  etc  Earlier work on this problem has mostly focused on the question of how one can construct an ordering over subsets of elements given an ordering over the elements of the set  Barbera  Bossert    Pattanaik         The main distinction made has been between sets of items that are mutually exclusive  in the sense that only one can eventually materialize  and sets in which the items will jointly materialize  Our formalism is agnostic on this issue  although we are clearly motivated by the latter case  As Barbera et al  note  most past work focused on the case of mutually exclusive elements  This  for example  would be the case if we are selecting a set of alternatives from which some decision maker  or nature  will ultimately choose only one  e g   courses of action   However        AI Access Foundation  All rights reserved    B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  there is a substantial body of work on the latter setting in which items might materialize jointly  and individual items are preferentially comparable  This paper focuses on a somewhat different context for set preference specification  First  we assume that the items from which our subsets are composed are structured  in the sense that some set of attributes is associated with them  For example  if the items are movies  these attributes could be the genre  language  year  director  if the items are politicians  the attributes could be the political views of the politicians on various topics  their party affiliation  their level of experience  Second  we require a generic preference specification  in the sense that it can be used with diverse collections of items  For example  if we are specifying guidelines for the composition of some committee  these guidelines are generic  and can be used to induce a preference relation over subsets of any given set of politicians  provided that the set of attributes is fixed  Third  we do not assume any preferential ordering over the individual items  although that can certainly be captured by one of the attributes describing the items  An instructive example of the type of domain we have in mind is that of personalized online newspapers  First  the problem of selection for a newspaper is one of subset selection  we have to select a subset of the set of available articles to place in the newspaper  Second  the database of articles is constantly changing  Therefore  an approach that requires explicitly specifying preferences for the inclusion of each specific item is inappropriate  both because the number of such items is very large  and because this would require us to constantly change the preference specification as the set of items changes  Finally  we would not want to base our approach on a method for transforming an ordering over items into an ordering over subsets of items  because we do not want to have to rank each item  and because there are obvious instances of complementarity and substitutability  For instance  even if I prefer articles on Britney Spears to articles on any other topic  two very similar articles about her may be less interesting than a set comprising one about her and one about the Spice Girls   One recent work that considers a similar setting is that of desJardins and Wagstaff         which works by specifying preferences over more abstract properties of sets  In particular  desJardins and Wagstaff offer a formalism for preference specification in which users can specify their preferences about the set of values each attribute attains within the selected set of items  One could assert whether the values attained by an attribute on the selected subset should be diverse or concentrated around some specific value  In addition  desJardins and Wagstaff also suggest a heuristic search algorithm for finding good  though not necessarily optimal  such sets of items  In this work  we present a more general  two tiered approach for dealing with set preferences in the above setting  This approach combines a language for specifying certain types of set properties  and an arbitrary preference specification language for expressing preferences over single  attributed items  The basic idea is to first specify the set properties we care about  and then specify preferences over the values of these properties  Such a specification induces a preference ordering over sets based on the values these sets provide to the properties of interest  We believe that the suggested approach is both intuitive and powerful  Although in this paper we focus on a particular set of properties for which we have devised a relatively efficient optimization algorithm  in its most general form  this two tiered approach generalizes the approach of desJardins and Wagstaff        because diversity and specificity are just two set properties  In principle  one can express both more general    We realize that common rules of rationality may not apply to users with such preferences         G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  properties referring to multiple attributes  as well as more general conditional preferences over the values of these properties  Essentially  our approach re states the problem of specifying preferences over sets in terms used to specify preferences over single items  In our formulation  items stand for the possible sets  and attributes of such items are their  user defined  set property values  Thus  in principle  this approach allows us to re use any formalism for specifying preferences over single items  In this paper we will consider two specific instantiations of such a formalism  qualitative preferences based on CP or TCP nets  Boutilier  Brafman  Domshlak  Hoos    Poole        Brafman  Domshlak    Shimony      a   and quantitative preferences represented as generalized additively independent  GAI  value functions  Bacchus   Grove        Fishburn         The algorithm we suggest for computing an optimal subset given qualitative preferences is based on a similar optimization algorithm for TCP nets  But because the number of items in our case is very large  this algorithm is modified substantially to exploit the special structure of these items  These modifications enable us to compute an optimal subset faster      Specifying Set Preferences The formalism we use for set preference specification makes one fundamental assumption  the items from which sets of interest are built are described in terms of some attributes  and the values of these attributes are what distinguishes different items  We shall use S to denote the set of individual items  and X to denote the set of attributes describing these items  For example  imagine that the items in question are US senate members  and the attributes and their values are  Party affiliation  Republican  Democrat   Views  liberal  conservative  ultra conservative   and Experience  experienced  inexperienced       From Properties of Items to Properties of Item Sets Given the set X of item describing attributes  first  we can already talk about more complex item properties  e g   senate members with liberal views  or inexperienced  conservative senate members  More formally  let X be the union of the attribute domains  that is  X    X   x   X  X   x  Dom X     and let LX be the propositional language defined over X with the usual logical operators  LX provides us with a language for describing complex properties of individual items  Since items in S can be viewed as models of LX   we can write o     whenever o  S and o is an item that satisfies the property   LX   Given the language LX   we can now specify arbitrary properties of item sets based on the attribute values of items in a set  such as the property of having at least two Democrats  or having more Democrats than Republicans  More generally  given any item property   LX   we can talk about the number of items in a set that have property   which we denote by    S   that is     S      o  S o        Often the set S is implicitly defined  and we simply write     Thus   Experience experienced  S  is the number of experienced members in S  Often  we simply abbreviate this as  experienced   While      is an integer valued property of sets  we can also specify boolean set properties as follows  h   REL ki  where   LX   REL is a relational operator over integers  and k  Z is a       B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  non negative integer  This property is satisfied by a set S if   o  S o       REL k  In our running example we use the following three set properties   P    h Party affiliation   Republican  Political view   conservative    i  P    h Experience   experienced    i  P    h Political view   liberal    i P  is satisfied  only  by sets with at least two members that are either Republican or conservative  P  is satisfied by sets with at least   experienced members  P  is satisfied by sets with at least one liberal  We can also write h   REL   i  with a similar interpretation  For example  h Republican     Democrat i holds for sets containing more Republicans than Democrats  An even more general language could include arithmetic operators  e g   require twice as many Republicans as Democrats  and aggregate functions  e g   the average number of years on the job   All these are instances of the general notion of specifying properties of sets as a function of the attribute values of the sets members  In this paper  we focus on the above language with the relational operators restricted to equalities and inequalities  We do so because having a clear  concrete setting eases the presentation  and because restricting the language allows us to provide more efficient subset selection algorithms  Indeed  many of the ideas we present here apply to more general languages  In particular  this generality holds both for the overall preference specification methodology  and for the search overCSPs technique for computing optimal subsets introduced later in the paper  However  the more specific techniques we use to implement these ideas  such as bounds generation  and the specific translation of properties into CSPs  rely heavily on the use of specific  more restrictive languages  Finally  we note an important property of our preference specification approach of being independent of the actual set of items available at the moment  This generality is important for many applications where the same reasoning about set preferences must be performed on different  and often initially unknown sets of items  For example  this is the case with specifying guidelines for selecting articles for an online newspaper  or for selecting a set of k results for an information query      Reasoning with Set Preferences Once we have specified the set properties of interest  we can define preferences over the values of these properties using any preference specification formalism  Here we discuss two specific formalisms  namely TCP nets  Brafman et al       a   an extension of CP nets  Boutilier et al          and Generalized Additively Independent  GAI  value functions  Bacchus   Grove        Fishburn         The former is a formalism for purely qualitative preference specification  yielding a partial preference order over the objects of interest  The latter is a quantitative specification formalism that can represent any value function  Let P    P            Pk   be some collection of set properties  A TCP net over P captures statements of the following two types      Conditional Value Preference Statements  If Pi    pi       Pij   pij then Pl   pl is preferred to Pl   p l   That is  when Pi            Pij have a certain value  we prefer one value for Pl to another value for Pl          G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS      Relative Importance Statements  If Pi    pi       Pij   pij then Pl is more important than Pm   That is  when Pi            Pij have a certain value  we prefer a better value for Pl even if we have to compromise on the value of Pm   Each such statement allows us to compare between certain pairs of item sets as follows    The statement if Pi    pi       Pij   pij then Pl   pl is preferred to Pl   p l  implies that given any two sets S  S   for which     Pi    pi       Pij   pij holds      S satisfies Pl   pl and S   satisfies Pl   p l   and     S and S   have identical values on all properties except Pl   we have that S is preferred to S       The statement if Pi    pi       Pij   pij then Pl is more important than Pm  implies that given any two sets S  S   for which     Pi    pi       Pij   pij holds      S has a more preferred value for Pl   and     S and S   have identical values on all attributes except Pl and Pm   we have that S is preferred to S      Notice that we do not care about the value of Pm if Pl is improved   We refer the reader to the work of Brafman et al       a  for more details on TCP nets  their graphical structure  their consistency  etc  The algorithms in this paper  when used with TCP nets  assume an acyclic TCP net Brafman et al   The latter property ensures both consistency of the provided preferences  as well as existence of certain good orderings of P with respect to the TCP net  As an example  consider the following preferences of the president for forming a committee  He prefers at least two members that are either Republican or conservative  that is  he prefers P  to P  unconditionally   Depending on the context  we use P to denote both the property P and the value P   true  We use P to denote P   false   If P  holds  he prefers P  over P   that is  at least two experienced members   so that the committee recommendations carry more weight  If P  holds  he prefers P  to P   that is  all but one are inexperienced  so that it would be easier to influence their decision  The president unconditionally prefers to have at least one liberal  that is  he prefers P  to P    so as to give the appearance of balance  However  P  is less important than both P  and P    There is an additional external constraint  or possibly a preference  that the total number of members be three   GAI value functions map the elements of interest  item sets in our case  into real values quantifying theP relative desirability of these elements  Structure wise  GAI value functions have the form U  S    i       n Ui  Pi  S    where each Pi  P is a subset of properties  For example  the Presidents preferences imply the following GAI structure  U  S    U   P   S   P   S     U   P   S   because the Presidents conditional preferences over P  s value tie P  and P  together  but are independent of P  s value  U  would capture the weight of this conditional preference  combined with the absolute preference for P  s value  U  would represent the value of property P    We might quantify these preferences as follows  U   P    P          U   P    P         U   P    P         U   P    P         while U   P         U   P         Of course  infinitely many other quantifications are possible     Some external constraints  such as this cardinality constraint  can be modeled as a preference with high value importance  In fact  this is how we model cardinality constraints in our implementation         B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY                                          Q     Sopt   while Q contains a set S such that UB S    Value Sopt   do S  argmaxS   Q UB S     Q  QS    S     LB Sopt    UB S      Q  Q  S   o    o  S   S  S  argmaxS   Q Value S     if Value S    Value Sopt   then Sopt  S end if end while return Sopt Figure    Subset space branch and bound search for an optimal subset of available items S      Finding an Optimal Subset In general  given a preference specification and a set S of available items  our goal is to find an optimal subset Sopt  S with respect to the preference specification  That is  for any other set S    S  we have that the properties Sopt satisfies are no less desirable than the properties S   satisfies  We now consider two classes of algorithms for finding such an optimal subset  These two classes of algorithm differ in the space in which they search  In the next section  we describe a comparative empirical evaluation of these algorithms  For our running example we use the following set of available items S  o  o  o  o   Republican Republican Democrat Democrat  conservative ultra conservative conservative liberal  inexperienced experienced experienced experienced      Searching in Sets Space The most obvious approach for generating an optimal subset is to search directly in the space of subsets  A priori this approach is not too attractive  and indeed  we shall see later that our implementation of this approach did not scale up  However  given that often we are interested in sets of small size and that heuristics can be used to enhance search quality  we thought it is worth exploring this approach  A branch and bound  B B  algorithm in the space of sets is depicted in Figure    For each set S  the algorithm assumes access to an upper bound UB S  and to a lower bound LB S  estimates on the maximal value of a superset of S  The algorithm maintains a queue Q of sets  and this queue is initialized to contain only the empty set  At each step  the algorithm selects a highest upper bound set S from the queue  Next  the algorithm removes from Q all sets S   with upper bound UB S     being at most as good as the lower bound LB S  of the selected set S  and adds to Q all the minimal  that is  one item  extensions of S  The latter sets correspond to the successors of S in the search space  Different implementations of the algorithm differ in how they sort the queue  The best first version depicted in the pseudo code sorts the queue according to a heuristic value of the set  and in       G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  our case this heuristic is an upper bound on the value of the sets supersets  In contrast  the depthfirst version always positions the children of the newly expanded node at the front of the queue  We implemented and tested both versions  The method used to generate bounds for a set S must depend on the actual preference representation formalism  as well as on the type of set properties being used  and the idea is more natural given a quantitative value function  For a lower bound LB S  we can use the actual value Value S  of S  Note that it is possible that all descendants of S will have lower values because  in general  set properties may not be monotonic  e g   average value higher than     However  since S itself is a possible solution  this is a valid lower bound  For an upper bound  we proceed as follows  First  we consider which set property values are consistent with S  That is  for each set property  we examine what values S and any of its supersets can potentially provide to that property  For example  consider P  and suppose S contains a single experienced member  So currently  P  holds  However  we can satisfy P  if we add one more experienced member  Thus  both values of P  are consistent with S  In contrast  if we had two experienced members in S  then P  is inconsistent with S because no matter who we add to S  we can never satisfy P    Next  given such sets of possible set properties values with respect to the set S  we can bound the value of S and of any of its supersets by maximizing values locally  Specifically  in a GAI value function  we can look at each local function Ui   and consider which assignment to it  from among the consistent values  would maximize Ui   Clearly  this may result in an overall value overestimation  since we do not know whether these locally optimizing joint assignments are consistent  Similar ideas can be used with other quantitative representations  as in various soft constraint formalisms  Bistarelli  Fargier  Montanari  Rossi  Schiex    Verfaillie         Consider our running example with the GAI value function as at the end of Section    and consider searching for an optimal subset of S    o    o    o    o    using a depth first version of B B  We start with the empty set  and the property values provided by the empty set are P    P    P    Thus  the lower bound LB    which is the value of the empty set  is    For the upper bound UB    we consider the best property values that are individually consistent with the extensions of   which are P    P    P    and their accumulative value is     Sopt is also initialized to the empty set  and next we generate all of the children of the  only possible  selected set   which are all singleton sets   o      o      o      o     Except for  o     they all have lower and upper bounds identical to those of the empty set  and are inserted into the queue   o    has a lower bound of   and the upper bound is     Suppose  o    is the first queue element  and we select it for expansion  This results in adding  o    o      o    o      o    o    into the queue  and the lower and upper bounds of these sets are                            respectively  Next  the set  o    o    is examined with respect to the current Sopt     and Sopt is assigned to  o    o     Since we assumed here a depth first version of B B we proceed with expanding  o    o     obtaining  o    o    o      o    o    o    with lower and upper bounds being  respectively           and           With a lower bound of    for  o    o    o    we can prune away all the rest of the nodes in the queue  and we are done  An important issue for depth first B B is the order in which sets are generated  In our implementation  at each node in the search space  the items in S are ordered according to the sum of the value of the properties they can help satisfy  For example  initially  a conservative member such as o  could help us satisfy P    In contrast to quantitative preference representation formalisms  qualitative preferences typically induce a partial ordering over property collections  In this case  it is harder to generate strict       B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  upper and lower bounds  as they must be comparable to any possible solution  One way to handle this is to linearize the ordering and require the stronger property of optimality with respect to the resulting total order  Here  TCP nets present themselves as a good choice because there is an efficient and simple way of generating a value function consistent with an acyclic TCP net  Brafman   Domshlak         This value function retains the structure of the original network which is important to make the bounds computation efficient  notably  each Ui depends on a small number of property values       Searching over CSPs The attractiveness of the item subsets is evaluated in terms of a fixed collection of set properties P  and thus different sets that provide all identical property values are equivalent from our perspective  The immediate conclusion is that considering separately such preferentially equivalent subsets of available items S is redundant  To remove this redundancy  we suggest an alternative method in which we search directly over set property value combinations  Of course  the problem is that given a set property value combination  it is not obvious whether we can find an actual subset of S that has such a combination of properties  To answer this question  we generate a CSP that is satisfiable if and only if there exists a subset of S with the considered set property values  The overall search procedure schematically works as follows     Systematically generate combinations of set property values     For each such combination  search for a subset of S providing that combination of setproperty values     Output a subset of S satisfying an optimal  achievable  combination of set property values  To make this approach as efficient as possible  we have to do two things  namely      Find a way to prune sub optimal set property value combinations as early as possible      Given a set property value combination  quickly determine whether a subset of S satisfies this combination  Considering the first task  let P            Pk be an ordering of the set properties P   Given such an ordering of P  we incrementally generate a tree of property combinations  The root of that tree corresponds to an empty assignment to P  For each node n corresponding to a partial assignment P    p            Pj   pj   and for every possible value pj   of the property Pj     the tree contains a child of n corresponding to the partial assignment P    p            Pj   pj   Pj     pj     The tree leaves correspond to  all  complete assignments to P  Such a tree for our running example is depicted in Figure    Note that  implicitly  each node in this tree is associated with a  possibly empty  set of subsets of S  notably  the subsets that provide the set property value combination associated with that node  In our search for an optimal set  we expand this tree of set property value combinations while trying to expand as few tree nodes as possible by pruning certain value combinations of P as either    Throughout this paper  we will assume that in preference specifications using TCP nets  there are only conditional preference  CP  arcs  and importance arcs  but no conditional importance  CI  arcs  While our scheme and implementations allow these arcs  CI arcs force the ordering of the set properties to be dynamic  as it may depend on value assignments to previous properties  For clarity of exposition  we thus preferred not to present these technical details         G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS    P    P   P  P  P   P   P    P  P    P  P  P  P  P    P  P   P  P  P   P    P   P   P   P   P   P   P   P   P   P  P   P   P  P    Figure    Illustration of a search tree for our running example  sub optimal with respect to set preferences  or unsatisfiable with respect to S  A standard way to do this is  again  by using a branch and bound search procedure  and this requires from us to derive effective upper and lower bounds on the value of the best subset satisfying a partial value combination for P  In addition  the order we associate with properties and their values affects our pruning ability throughout the search process  To get the most leverage out of our bounds  we would like to explore the children of a node in the decreasing order of their purported attractiveness  Moreover  when fixing the ordering of the set properties themselves  we would like properties that can potentially contribute more to appear earlier in this ordering  For instance  P  s value in our running example has a greater influence on the overall attractiveness of a subset than the value of P    and thus P  should better be branched on first  In addition  P  is preferred to be true  and thus the subtree corresponding to P    true should better be explored first  Similarly  P  is preferred to be true when P    true  and preferred to be false  otherwise  This ordering is reflected in the tree in Figure    for a left to right pre order traversal of the tree  Now  let us consider the second task of determining whether a subset of S satisfies a given setproperty value combination  Given such a partial assignment  to P  we set up the following CSP  First  the CSP has a boolean variable xi for every available item oi  S  In our example  the CSP contains the variables x            x  for items o            o  respectively  Intuitively  xi     encodes oi being a part of our  searched for  subset of S  whereas xi     means that oi is not in that subset  Next  we translate every set property value in  into a certain constraint on these variables  For instance  if  P      true  the constraint C    x    x    x     is added to the CSP  Note that C  explicitly encodes the requirement  of P    true  for the subset to have at least two of the elements that satisfy Republican  conservative  That is because  o    o    o    are all the candidates in S that are either Republican or conservative  Alternately  if  P      f alse  then the constraint C    x    x    x      is added to the CSP  Finally  if  does not specify a value for P    then no constraints related to P  should be added at all  Likewise  for  P      true and  P      true we would add the constraints C    x    x    x     and C    x      respectively  In general  it is not hard to verify that the CSP constructed this way for a concrete item set S and a set property value combination  is solvable if and only if S has a subset satisfying   Moreover  if this CSP is solvable  then any of its solutions explicitly provides us with such a subset of S  It is worth briefly pointing out the difference between the CSPs we generate here and the more typical CSPs usually discussed in the literature  Most work on general CSPs deals with constraints       B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  over small  typically just two variable  subsets of problem variables  In contrast  the constraints in the CSPs generated in our optimization process are global  with each constraint being possibly defined over all the CSP variables  Yet another special property of CSPs constructed for our purposes is that there is a sense in which it is meaningful to talk about partial assignments in our contextunassigned variables can always be regarded de facto as if assigned the value   since the corresponding items  by default  do not belong to the subset we search for  Because partial assignments to set properties P map to CSPs  each node in our tree of setproperty value combinations maps to a CSP  and the entire tree can be viewed as a tree of CSPs  The important property of this tree of CSPs is that the children of each CSP node are CSPs obtained by adding one additional constraint to the parent CSP  notably the constraint corresponding to the additional property value that we want the set to satisfy  This implies that if some CSP node in the tree is unsatisfiable  then all of its descendants are unsatisfiable as well  In fact  we can make a stronger use of the nature of this search tree  recognizing that we can reuse the work done on a parent node to speed up the solution of its children  To see the latter  consider some CSP C in our tree of CSPs  some child CSP C   of C   and let S  S be a solution to C   As C   extends C with a constraint C  any subset S    S ruled out by C will be also ruled out by C     Hence  if solving C and C   considers subsets of S in the same order  that is  by using the same ordering over set elements   then solving C   can start from the leaf node corresponding to S  the solution generated for C   Moreover  if a constraint C represents a boolean set property  and S is not a solution to C     C   C   then S has to be a solution to C   C   which is the sibling of C     Using these ideas  we share the work done on different CSP nodes of our tree of CSPs  In fact  when all set properties are boolean  this approach needs to backtrack over each property at most once  we call this property limited backtracking   thereby considerably improving the empirical performance of the algorithm  The overall branch and bound algorithm in the space of CSPs is depicted in Figure    As is  the algorithm is formulated for the case of quantitative preference formalisms  The formulation of the algorithm for the qualitative case is essentially the same  with minor technical differences and an important computational property  For CP TCP nets  we can guarantee that only limited backtracking is required if we follow the following guidelines  First  we must order the variables  line    in an order consistent with the topology of the network  Note that for TCP nets  this ordering may be conditional  that is  the order of two variables may vary depending on the value of some of the earlier variables  Second  in line    the property values must be  possibly partially  ordered from best to worst  given the values of the parent properties  which must be and will be instantiated earlier   In that case  the first satisfiable set of properties constitutes an optimal choice  Brafman et al       a   Assuming we solve intermediate nodes in the tree of CSPs  we know that we should backtrack at most once in each level assuming boolean set properties  but  again  more backtracks may occur with integer valued properties  The node data structure used by the algorithm has two attributes  For a search node n   n  captures a partial assignment to the set properties P associated with the node n  and  n S captures a subset of S satisfying n  if such exists  and otherwise has the value false  The functions Value  LB  and UB have the same semantics as in the subset space search algorithm in Figure    In the pseudocode we assume a fixed ordering over set property values  line     but one can vary it depending on earlier values  and we exploit that in our implementation   Finally  the       G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS                                                                          Fix an ordering over set properties P Fix an ordering over the values of each set property P  P Fix an ordering over all available items S Q   n      Sopt   while Q is not empty do n  pop Q  construct and solve csp n  if n S    f alse and UB n S    Value Sopt   then if Value n S    Value Sopt   then Sopt  n S end if Let P be the highest ordered set property unassigned by n  for each possible value p of P do n    n    P   p   n S  Q  Q   n      The position of n  in Q depends on the search strategy end for end if end while return Sopt Figure    CSP space branch and bound search for an optimal subset of available items S   pseudo code leaves open the choice of search strategy for used by the branch and bound  and this choice is fully captured by the queue insertion strategy in line     To illustrate the flow of the algorithm  let us consider again our running example  Recall that the example already has a requirement for the discovered subset to be of size    and this translates into a constraint C   x    x    x    x       The first CSP we consider has  C  C    as its only constraints  Assume the CSP variables are ordered as  x    x    x    x     with value   preceding value   for all xi   In that case  the first solution we find is S    x       x       x       x       Our next CSP adds the constraint C    When solving this CSP  we continue to search  using the same order on the xi s and their values  from the current solution S    which turns out to satisfy C  as well  Thus  virtually no effort is required to solve this CSP  Next  we want to also satisfy C    This set of constraints corresponds to a leaf node in the tree of CSPs which corresponds to the complete assignment P  P  P  to the set properties  Our current item set Sopt   S  does not have a liberal  so we have to continue to the assignment S    x       x       x       x       requiring us to backtrack in the CSP solution space over the assignments to x  and x     We now have a set that satisfies the properties in the leftmost leaf node in our tree of CSPs  If we can prove that this setproperty value combination is optimal using our upper lower bounds  we are done  Otherwise  we need to explore additional nodes in our tree of CSPs  In the latter case  the next CSP will correspond to P    P    P    with constraints  C  C    C    C     However  we already have a solution to this node  and it is exactly S    To see that  note that S  was a solution to the parent of our current CSP  but it was not a solution to its sibling  C  C    C    C     Hence  since P  is a boolean property  S  must satisfy  C  C    C    C            B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY      Solving the underlying CSPs Our algorithm for solving the intermediate CSPs is based on the well known backtrack search algorithm  first presented by Prosser        in a simple iterative form  At the same time  we have adapted both the algorithm and some well known enhancements in CSP solving  such as NoGood recording and forward checking  FC   to the specifics of the CSPs in our setting  Initially  variables and their values are statically ordered from the most to least constrained  although we also discuss a few experiments performed with dynamic variable value ordering   Our motivation for static ordering is two fold  First  because the constraints are very much global  we can do the ordering at a preprocessing stage  Second  as discussed in the previous section  static ordering allows us to better utilize solutions of CSPs when solving descendent CSPs  The basic backtrack algorithm  which on its own  unsurpisingly performs quite poorly in our setting  is refined by utilizing the following observations and techniques   Monotonicity of improving constraints  If the operator of the constraint is   and there are more items having the constrained property already in the current partial solution  then one cannot satisfy the constraint by making additional assignments  The same property holds for the constraint operators    and   Using this observation  it is possible to detect the need to backtrack early on in the search   Forward Checking  A certain type of forward checking can be performed for our constraints  Clearly  if satisfying some constraint requires at least k items to be added to the subset  and the number of remaining items that satisfy the desired property is less than k  then the search algorithm must backtrack   Can Must strategy  The can must strategy corresponds to a more advanced check of the interactions between the constraints  The idea is quite simple  if  i  at least p items must be added to the constructed subset to satisfy the constraint Ci    ii  at most q items can be added to the constructed subset without violating another constraint Cj    iii  all the items that can be added and have the property constrained by Ci also have the property constrained by Cj   and  finally   iv  p   q  then both Ci and Cj cannot be satisfied simultaneously  Moreover  no further assignments to yet unassigned variables can resolve this conflict  and thus the situation is a dead end  This kind of reasoning allows discovery of such barren nodes quite early in the search  pruning large portions of the search tree  To reason correctly about the can must strategy  we have to maintain a data structure of unique items for each pair of constraints  as well as to keep track of the number of remaining items that influence property constrained by Ci and do not influence properties constrained by Cj   As an example  assume we are in the middle of the search and we have two set properties  SP     A    a     and SP     A    b      Suppose that we have already picked   items that influence SP  and   items that influence SP    As a result  to satisfy SP    we must add at least another two items that influence it and to satisfy SP  we can add at most one item that influences SP    If all the items that we can choose from  ok    on   have a value a for the attribute A  and value b for the attribute A    then obviously we cannot satisfy both SP  and SP  within this setting  and thus we should backtrack  Finally  below we discuss recording NoGoods  an improvement of the basic backtracking algorithm that proved to have the most impact in our setting        G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS        N O G OOD R ECORDING The standard definition of a NoGood in the CSP literature is that of a partial assignment that cannot be extended into a full solution of the problem  Once we learn a NoGood  we can use it to prune certain paths in the search tree  The smaller the NoGood  the more occasions we can use it  the greater its pruning power  Thus  it is of interest to recognize minimal NoGoods  and different techniques have been developed to perform NoGood resolution in order to produce the best and most general NoGoods possible  see  e g   Dechter        Schiex   Verfaillie        Dago   Verfaillie         As noted earlier  the CSPs we generate differ significantly from the more typical binary CSPs  Consequently  the NoGood recording algorithm has to be adapted accordingly  In particular  because our constraints are global  it makes sense to try generating NoGoods that are global  too  Thus  instead of recording assignments to variables  we record the influence of the current assignment on the constraints  Every variable influences a set of constraints   Thus  as a NoGood  we store the influence the set selected so far has on all the constraints  Specifically  suppose we have generated the set S    and recognized that it is not extensible into a set satisfying the constraints   This immediately follows from the fact that we backtracked over this set   We now generate a NoGood N that records for each property associated with each constraint  how many items satisfying that property occur in S    Now  suppose we encounter a different set S  that has the same effect N on the constraints  If there are fewer options to extend S  than there are to extend S    we know that S    as well  cannot be extended into a solution  However  if there are more options to extend S  than S    we cannot conclude that S  is a NoGood at this point  In order to better quantify the options that were available to extend S  we record  beyond the actual NoGood N   the level  depth  in the assignment tree at which it was generated  Given that the CSP solver uses a static variable ordering  we know that if we encounter a set S that generates the same properties as the NoGood N   at a level no higher than that of S    we can safely prune its extensions  The reason for that is  there are no additional extension options available for S than there were for S    The correctness of the NoGood recording mechanism proposed here depends on having a static variable ordering  as well as a specific value ordering for all the variables in the CSP  namely  h    i  To show correctness  we should note that a NoGood can be used only after it is recorded  Consequently  any node using a NoGood would be to the right in the search tree of a node the NoGood was recorded at  Here we would like to stress again that  since the constraints are global  it does not matter which items are added to the subset  but rather what influence these items had on the constraints  Any two sets having exactly the same influence on the constraints are identical with respect to the optimization process        S EARCH A LGORITHM The procedure depicted in Figure   extends the basic backtrack algorithm by a subroutine C AN I M PROVE which can be altered to include any combination of the in depth checks discussed earlier  to utilize early conflict detection techniques  including the NoGoods check  Also added is a call to the A DD N O G OOD subroutine for recording NoGoods while backtracking  P and n  the generated instance of a CSP problem with variables indexed from   to  S  and the node in the tree space search    We assume without loss of generality that every item in the set of available items influences at least one constraint in the constraint set C   since items that influence no constraint can be safely eliminated         B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  respectively  are the inputs to the procedure  The algorithm systematically tries to assign values to the problem variables  backtracking and recording NoGoods when facing a dead end                                              consistent  n S satisfies n  while not consistent  do     if H AS VALUES P  vars i   and  C AN I MPROVE P    then P i  L ABEL P i  consistent    If current CSP variable has available values  try to set  update consistency else    A DD N O G OOD  P  i    Record NoGood     P i  U NLABEL P i    Backtrack end if if P i     then   If backtracked over the first indexed variable  no solution available return false end if end while return true Figure    Conflict backtrack algorithm with NoGood recording     Experimental Results We evaluate the different algorithms using a subset of the movie database publicly available from imdb com  We simulated a scenario of selecting movies for a three day film festival according to organizers preferences  Three models of growing complexity have been engineered to reflect the preferences of the organizers  these models are defined in terms of       and    set properties  respectively  In addition  the total number of films is constrained to be    which we actually modeled using a very strong preference   Figure   depicts the list P   of the    properties and their alterations  P  and P  consist of the corresponding prefixes  SP  through SP    and SP  through SP    respectively  of P     To produce even more complex problem instances that cause many backtracks in the space of set property assignments we slightly altered the    properties model  creating two   and P      additional models that are denoted henceforth as P          Preference Specification Figure   provides a verbal description of qualitative preferences for the film festival program which we used in our experiments  Figure   depicts a TCP net that encodes these preferences in terms of the more concrete set properties listed in Figure    For the experiments with GAI value functions  these preferences were quantified by compiling this TCP net into a GAI value function that orders the items consistently with that TCP net  Brafman   Domshlak         The task in our empirical evaluation was to find an optimal subset of a set of available movies S   S      S       S       S        where Si corresponds to a set of i movies  and that with respect to each of the five models of preferences over sets  All the experiments were conducted using Pentium     GHz processor with  GB memory running Java     under Windows XP Professional  The runtimes reported in the tables below are all in seconds  with  indicating process incompletion after four hours         G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  SP    h Year           i SP    h Genre   Comedy    i SP    h Genre   Thriller    i SP    h Genre   Family     i SP    h Color   B W     i SP    h Director   Spielberg    i SP     h Director   Spielberg    i SP    h Sound   Mono    i SP    h Genre   War  Genre   Film noir     i  SP     h Genre   War  Genre   Film noir    i SP     h Genre   Film noir    i SP    h Location   North America     i SP     h Actor   Famous  Actress   Famous     i SP     h Actress   Famous    i SP     h Genre   Drama    i SP     h Release Date           i SP     h Net Profit             i SP      h Net Profit             i  Figure    Set properties used in modeling user preferences in the movies selection domain      Alteration of P     to achieve more backtracking   denoted as P           Further alteration of P   to achieve even more backtracking   denoted as P       I prefer new movies to old movies  and therefore prefer that all movies be from      or later  and this is important to me     I love comedies  thrillers and family movies     I prefer not to have too many movies in black and white  not more than one such movie      If all the movies are new  after       then I would prefer to have at least   comedies     If I can find at least   comedies then I also prefer to have more than   family movie  but less then   thrillers  However having the right number of family movies is more important to me than having the right number of thrillers     If not all the movies are new  I prefer to have at least   movies in black and white for the vintage touch     If not all the movies are new  I prefer at least one movie to be directed by Steven Spielberg  but otherwise  I dont like his newer films    If the previous condition holds  then the number of movies with mono sound may be greater than       I prefer not to have any war films or film noir in the festival  However if this condition can not be satisfied  then I prefer not to have any films that were filmed in North America and this is more important to me than my preferences about the movie being in color or in B W      To draw more attention  I prefer all   movies to have famous actors or actresses      To highlight female roles  I prefer at least   movies with a famous actress      I prefer to have at least   dramas because people tend to think dramas are more sophisticated movies than any other genre      I prefer to have at least one classical movie      I prefer to have at least one commercially successful movie  i e  a movie whose net profit was more than one million dollars   Figure    Informal description of the assumed preferences for selecting a set of movies for a film festival program   First  our initial experiments quickly showed that the search in the space of subsets  Table    does not scale up  With just over    elements  it did not converge to an optimal solution within an hour  even when the preference specification involved only   set properties  This outcome holds for all combinations of qualitative and quantitative preference specifications  depth first and best first schemes of branch and bound  and queue ordering based on sets upper bound  lower bound  and        B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  weighted combinations of both  Table   provides a snapshot of the corresponding results for a TCPnet specified over nine set properties  The table describes the total number of subsets generated until an optimal subset was found  see the column Subset until Sopt    the total number of subsets generated until the optimal subset was recognized as optimal  under Subsets generated   DFS appears to be much more effective than BFS  but the branching factor of larger databases overwhelms this approach  Also  it may be thought that with larger databases it should be easier to quickly generate good sets  but we found that for moderately larger  e g        and much larger  e g         datasets  this approach is too slow  Various improvements may be possible  but given the much better performance of the other approach discussed later  they are unlikely to make a difference   SP    SP   SP  SP    SP   SP   SP    SP   SP  SP    SP   SP   SP    SP   SP  SP    SP   SP   SP   SP   SP   SP   SP   SP   SP   SP   SP   SP   SP  SP   SP  SP   SP  SP   SP            SP  SP  SP  SP   SP   SP    SP   SP  SP   SP  SP   SP  SP   SP            SP   SP   SP   SP    SP    SP   SP  SP    SP   SP   SP   SP  SP   SP  SP   SP  SP   SP            SP   SP   SP   SP     SP    SP    SP    SP    SP     SP   SP   SP   SP   SP    SP   SP  SP    SP   SP   SP    SP   SP  SP    SP   SP   SP   SP   SP   SP    SP    SP    SP    SP   SP    SP    SP    SP     SP    SP   SP     SP    SP     SP    SP    SP    SP    SP   SP     SP    SP   SP     SP    SP    Figure    TCP net model of preference over sets of movies for the film festival program  Next  we consider the CSP space branch and bound search  In particular  here we compared between the two variants of this approach that use dynamic and static variable and value orderings  In what follows  these two variants are denoted as BB D and BB S  respectively  While static variable value orderings are usually considered to be a weaker approach to CSP solving  earlier we have shown that  in our domain  static ordering allows for certain optimizations that have a potential to improve the efficiency of the overall problem solving  In particular  static variable ordering allows to record global NoGoods as described in Section        the results for algorithms that record NoGoods are denoted by a name suffix  ng  In addition  we have tried to share        G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  S  S  S   S   S   S   S   S    Method BFS DFS BFS DFS BFS DFS BFS DFS  Subsets until Sopt                                      Subsets generated                                                 Time  sec                                                 Table    A snapshot of the results for subsets space search  The preferences here are specified by a TCP net over nine set properties  Method  S     S      S      S      P  P  P  P  P   BB D BB S BB S inc BB S ng BB S ng inc                                                                                                       P  P  P  P  P   BB D BB S BB S inc BB S ng BB S ng inc                                                                                                          P   P   P   P   P    BB D BB S BB S inc BB S ng BB S ng inc                                                                                                          P     P     P     P    BB S BB S inc BB S ng BB S ng inc                                                                             P      P      P      P      P    BB D BB S BB S inc BB S ng BB S ng inc                                                                                                 Set properties  Table    Empirical results of evaluating the CSP space search procedures with qualitative preference specification using TCP nets   information between consecutive CSP problem instances while doing the search in the tree of CSPs  the algorithms adopting this technique are denoted by a name suffix  inc  Table   depicts the results of the evaluation of all variants of the CSP space branch and bound search algorithm  Figure     First  the table shows that the overhead of maintaining NoGoods does not pay off for the simple preference specifications  However  for the more complex problems requiring more intense CSP solving  the use of NoGood recording proved to be very useful  letting us        B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  Method  S     S      S      S      P  P   BB S BB S                                              P   P    BB S inc BB S ng inc                                              Set properties  Table    Results for the CSP space search with quantitative preference specification using GAI value functions   solve previously unsolvable instances  Next  the reader may notice from the table that  at least for the problems used in our tests  the contribution of the incremental approach is not substantial  For instance  NoGood recording by itself seems to contribute much more to the efficiency of the optimization process  Moreover  for the more complex problems  switching to the incremental version sometimes even leads to performance degradation  It appears that the overhead of maintaining and copying the partial solution in these cases does not pay off  Our next set of experiments mirrored the first one  but now with GAI value functions instead of the purely qualitative TCP nets  The GAI functions were obtained by properly quantifying the qualitative preferences used for the first tests  Table   provides a representative snapshots of the results  With value functions over set properties P  and P  the basic branch and bound algorithm with static variable value orderings performs and scales up  with growing set of alternatives S  quite well  With the more complex value functions over the larger set of properties P   the performance significantly degrades  and even the incrementality enhanced algorithm cannot solve problem instances with more than      CSP variables  On the other hand  adding NoGoods recording proves to dramatically improve the performance  leading to solving even the largest problem instances  Tables   and   suggest a qualitative difference in the performance of the CSP space search with quantitative and qualitative preference representation models  There are good reasons to expect such behavior  First  compact qualitative models of preference may  and typically do  admit more than one optimal  that is  non dominated  solution  That  in principle  makes finding one such optimal solution easier  Second  if the preferences are captured by a TCP net  then there are variable orderings ensuring that the first solution found will be an optimal one  In contrast  with GAI value functions  after we generate an optimal solution  typically we still have to explore the search tree to prove that no better solution exists  In the worst case  we have to explore the entire tree of CSPs  forcing us to explore a number of CSPs that is exponential in  P   In summary  the first conclusion to be taken from our experiments is that subsets space search fails to escape the trap of the large branching factor  while the stratified procedures for CSP space search show a much higher potential  On the problems that require little backtracking in the space of CSPs  the latter procedures are actually very effective for both TCP net and GAI function preference specification  Obviously  if the procedure is forced to explore many different CSPs  the performance unavoidably degrades  We note that  on larger databases  such backtracks often indicate an inherent conflict between desirable set properties  and such conflicts might possibly be recognized and resolved off line  In this work we do not investigate this issue  leaving it as an optional direction for future improvement  The rather non trivial example used in this section provides the reader also with the opportunity to assess the suitability of different preference specification languages  For example  although we        G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  used boolean valued set properties  it may be argued that some of our natural language preference statements would better be expressed using integer valued set properties  Similarly  users may find that some other preference specification formalism  such as soft constraints  Bistarelli et al          can more naturally capture these natural language preferences  This is an opportunity for us to reemphasize that while  for obvious reasons  we had to focus on a concrete choice of language  we believe that the two tiered approach suggested here is far more general      Complexity Analysis Though reasonable runtimes have been obtained by us empirically with search over CSPs  both algorithm classes described above have a worst case exponential running time  This begs the question of whether the problem itself is computationally hard  Obviously  with external constraints  subset optimization is NP hard  Below we show that even without external constraints  the problem typically remains NP hard  even with significant restrictions on the problem  Naturally  the complexity of subset selection depends on the precise nature of the preference specification formalism used  Most of the results presented here assume TCP net based specification  Hardness results for this model immediately apply to the GAI model  based on an existing reduction  Brafman   Domshlak         In some cases  problems that are tractable under the TCPnet model become NP hard when a GAI model is used  instead  Thus  unless stated otherwise  we assume henceforth that preferences over properties are specified by a TCP net  In analyzing the complexity of the problem we consider the following problem parameters   n  the overall number of items in the data set   a  the number of attributes of the items   m  the number of set properties  i e  number of nodes in the TCP net   k  maximal property formula size  defined as the number of logical connectives  and  or  not  in the formula   d maximum attribute domain size  i e  the maximum number of distinct values for each attribute     the number of times an attribute value can appear in the dataset      NP Hard Classes Theorem    When using TCP based preferences over set properties  finding an optimal subset of a given set of items  POS  is NP hard even if the items are described only in terms of binary valued attributes  and all the set properties are atomic  that is  we have d     and k       Proof  The proof is by a polynomial reduction from the well known NP hard Vertex Cover  VC  problem  Given a graph G    V  E   a vertex cover of G is a vertex subset V    V covering all the edges in the graph  that is  for every edge e  E  there is a vertex v  V   such that e is incident on v  The optimization version of VC corresponds to finding a minimal size vertex cover of G  Given an VC problem instance G    V  E   we construct a POS problem instance by specifying a TCP net N and an item set S as follows  For each vertex v  V we create an item o  denoted       B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  Pe   Pe   Pe   Pe   Pe   Pe   Pe   Pe   Pe   Pek  Pek      Pek  SUM SUM      SUM    SUM           SUM n  Figure    TCP net in the reduction from VC to POS in the proof of Theorem    by ov    and thus we have  S     V     n items  For each edge e  E we define an attribute X  denoted by Xe    and thus we have  X      E    a attributes  All the attributes in X are defined to have a binary          domain  For each item ov   the value of each attribute Xe is ov  Xe       if and only if e is incident on v in G  Next  for each edge e  E  we define a binary set property Pe   h Xe      i that takes the value true if and only if at least one item in the selected subset provides the value   to the attribute Xe   In addition  we define a single multi valued empty set property SUM  h  i    The domain of the SUM property is defined to be the integer value range     n   Note that  by construction  the properties utilize only one attribute per property  and thus no logical connectives  providing us with k      The preferences over these set properties are    For each binary property Pe   the preference is for the value true  that is  Pe   Pe      For the empty property SUM we simply prefer smaller values  that is  SUM         SUM       SUM               SUM n  The only edges in the TCP net N   depicted in Figure    are the importance arcs from each Pe to SUM  meaning that we would rather have to temporize in the value of the SUM property than have any of the Pe being f alse  Proposition   ensures that any optimal subset in the POS problem constructed as above always corresponds to a proper vertex cover of G  Proposition    For any subset S of S that is undominated with respect to the constructed TCP net N   and every edge e  E  we have Pe  S    true  Proof  Given an undominated  with respect to N   subset S  S  let Pe be a set property such that Pe  S    f alse  By construction  there exists an item o  S such that o Xe        Considering S     S   o   we have S   being preferred to S with respect to N because  i  S and S   provide exactly the same values to all the set properties except for Pe and SUM   ii  S provides a preferred    Since the formula  inside this set property is degenerate  and in fact equivalent to h true i  every item in the selection set will have to comply with it  This set property is the simplest implementation of a counter        G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  value to SUM while S   provides a preferred value to Pe   and  iii  preferential improvement of Pe dominates that of SUM  Thus S   dominates S  contradicting the assumption that S is undominated  Lemma    For any subset S of S that is undominated with respect to the constructed TCP net N   there exists a vertex cover VS of G with  VS      S   Proof  The proof is straightforward  Let VS    v   ov  S   Because S is undominated with respect to N   from Proposition   we have Pe  S    true for all binary edge related properties Pe   In turn  Pe  S    true implies that o Xe       for at least one item o  S  By the construction  o Xe       if and only if vertex v covers edge e  Together with the mapping between the vertices V and items S being bijective  the latter implies  VS      S   Lemma    There exists a minimal vertex cover of G of size s if and only if there exists a subset S  S undominated with respect to N such that SUM S    s  Proof  Let S be an undominated subset of S with  S    s  By construction  we have Pe  S    true for all binary set properties Pe   and SUM S       s  By Lemma    there exists a vertex cover VS of G with  VS     s  Suppose to the contrary that VS is not minimal  that is  there exists a vertex cover V   of G with  V       s  Now  construct the subset S      ov   v  V      Since the mapping between S and V is bijective  we have  S        V       s  and thus SUM S       s  Likewise  by construction of our set properties and V   being a vertex cover  we have Pe  S    true for all Pe   This  however  implies that S   is preferred to S with respect to N   contradicting the statement that S is undominated  Theorem   now follows immediately from Lemma   and the fact that the reduction is clearly polynomial  Theorem    Given TCP based preferences over set properties  finding an optimal subset of a given set of items  POS  is NP hard even if the items are described in terms of a single attribute  all the set properties are binary valued  each containing at most   logical connectives  that is  we have a     and k       Proof  The proof is by a polynomial reduction from k SAT  for any k     Given a k SAT problem instance over propositional variables V and logical formula   we construct a POS problem instance by specifying a TCP net N and an item set S as follows  For each variable v  V   construct an item ov and an item ov   and thus S contains an item for every possible literal in the formula  The value of the only attribute X is defined as follows  for each item ol   we have A ol     l  where l is a literal  either v or v  for all v  V    The binary set properties P for the TCP net N are now defined as follows   Properties ensuring that a variable assignment is legitimate  For each variable v  V    Pv  h X   v  X   v     i  that is  for any S  S  Pv  S    true if and only if S contains exactly one of the items  ov   ov          B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY   Properties ensuring that  is satisfied  For each clause C    l   l   l           PC  h X   l   X   l   X   l          i that is  for any S  S  PC  S    true if and only if S contains at least one item corresponding to a literal in C  Finally  to complete the preference specification  we make all properties independent  that is  the TCP net has no edges   and for each of the properties we prefer value true to value false  To illustrate the above construction  consider a   SAT formula     x  y  z    y    x  z   For this formula  the construction leads to item ox ox oy oy oz oz  X x x y y z z  Set properties  Px  h X   x  X   x     i Py  h X   y  X   y     i Pz  h X   z  X   z     i PC   h X   x  X   y  X   z    i PC   h X   y    i PC   h X   x  X   z    i  We now show that finding an undominated subset of S with respect to N as above is equivalent to finding a satisfying assignment to   Let S  S be undominated with respect to N   We can show that S provides value true to all set propositions Pv and PC  in this case we call S an ultimately preferred subset  if and only if  is satisfiable  First  let S be an ultimately preferred subset of S  Given such S  we can construct a mapping A   V    true  f alse  such that A v    true if ov  S  and A v    f alse if ov  S  Note that A is well defined because  for an ultimately preferred subset S  all Pv  S    true  and thus  for each v  V   exactly one item from  ov   ov   is present in S  Clearly  A is a legal assignment for   In addition  we have all PC  S    true  Thus  for each clause C    at least one item with X   li  C belongs to S  By construction  this implies that A satisfies all the clauses in   and thus  is satisfiable  Converesly  suppose that S  S is preferentially undominated with respect to N   but is not ultimately preferred  If our POS problem has such an undominated subset S  we show that  is unsatisfiable  Assuming the contrary  let A be a satisfying assignment of   Given A  we construct a subset SA  S as SA    ol   literal l  A   and show that SA dominates S with respect to N  contradicting the assumed undominance of S  and finalizing the proof of Theorem     By construction  since A is a legal assignment to V   we have Pv  SA     true for all set properties Pv   Also  since A is a satisfying assignment for   we have PC  SA     true for all set properties PC   Therefore  SA is actually an ultimately preferred subset of S  Finally  since all the set properties P are preferentially independent in N   and value true is always preferred to value f alse for all the set properties  we have that SA dominates S with respect to N   Notice that Theorems   and   do not subsume each other  Theorem   poses no restriction on the number of item attributes in the problem instance  but does restrict the domain of all the attributes  Theorem   restricts the number of attributes to    but has no restriction on the domain size of this attribute  and its restriction on the property size is looser than that imposed in Theorem          G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  Finally  we note that tightening the condition of Theorem    by allowing only at most   connective in each set property definition prevents us from using the same reduction as in the proof of Theorem   because the respectibe satisfiability problems would be the polynomial time solvable   SAT problems  Our conjecture  however  is that this fragment of POS is still NP hard  In fact  in Section     we show that the corresponding fragment of POS with the GAI preference specification  instead of TCP nets  is indeed NP hard      Tractable Classes Several tractable classes of POS  obtained by further restricting the problem class discussed in Theorem    and characterized by single attribute item description  that is  a       are discussed below  In both trivially tractable  Section        and non trivially tractable  Section        cases  we assume that the relational symbols are either equalities or inequalities  that in the specification of a property only equalities  attribute   value  are used  and in addition we do not allow an empty set property to be specified  The latter restriction is due to the fact that the empty set property is somewhat special  as it enriches the descriptive power by allowing one to simulate an additional attribute in certain cases  and the single attribute restriction is crucial for our tractability result  Before we proceed with the actual results  note that  with a single attribute item description  no two set properties can be in a conflict that demands backtracking while choosing items  i e  during CSP solution   To illustrate such conflicts  consider the following examples        a h A   ai     i   b h A   ai     i  Set property   a is redundant  subsumed by   b        a h A   as      i   b h A   as      i  One of these set properties must be false         a h A   al      i   b h A   al     i  One of these set properties must be false   All such conflicts between set properties can be resolved offline  prior to the actual process of subset selection  totally disregarding the available items  Hence  within the process of subset selection  we assume that there are no conflicts between set properties  Consequently  subset selection can be done in a greedy manner        T RIVIALLY T RACTABLE C LASS Theorem    Finding an optimal subset of a given set of items  POS  with respect to a TCP net preference specification is in P if the items are described in terms of a single attribute  and all the set properties are atomic  that is  we have a     and k       An algorithm for the problem class in Theorem   is depicted in Figure    The algorithm runs in time O m  n   where m is the number of set properties and n is the number of available items S  The for loop in line   of the algorithm iterates over all the set properties  each time checking compatibility with the previously considered properties  which requires  m    time  The procedures G ET S ATISFYING S ET    and H AS S ATISFYING S ET    have to process each item in S only once  Hence  the total running time of the algorithm is O m  n       This runtime analysis does not include the ordering of the TCP net variables that is assumed to be given  One way to do that would be a topological sort of the net  that obviously can be done in polynomial time         B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY                                                                                                 Sopt   Fix a preference ordering over set properties P Pass   for each property P  P do while  not  P  isSatisfied   do if P is in conflict with Pass then Set next value to P w r t  Pass else if H AS S ATISFYING S ET P   then Sopt  Sopt  G ET S ATISFYING S ET P   P  isSatisfied  true Pass  Pass   P   end if end if end while end for return Sopt procedure G ET S ATISFYING S ET P   S for each item o  S do if o has the property value defined by P then S  S   o  end if if  S  P  op P  cardinality then return S end if end for end procedure    Offline conflict resolution    If cardinality of S satisfies P  Figure    A polynomial time algorithm for the POS problems with TCP net preference specification  single attribute item description  and all the set properties being atomic  that is  a     and k              N ON  T RIVIALLY T RACTABLE C LASS At the end of Section     we have mentioned that the complexity of POS under limiting the setproperty description to at most one logical connective is still an open problem  If  however  we impose the limitations summarized in Table    we can show that the problem becomes tractable  Theorem    Finding an optimal subset of a given set of items  POS  with respect to a TCP net preference specification is in P if it is restricted as in Table    First we should discuss the implicit limitations  or special problem properties  that are imposed by the explicit limitations listed in Table          G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS     All the items have only one attribute  a         All the property formulas have at most   connective  k       and are positive  that is  we disallow negation     The empty property is disallowed    The number of attribute value appearances is limited to at most       that is  values in the attribute domain cannot be repeated  Table    Characteristics of the tractable subclass of POS presented in Section           The restriction to at most one attribute value appearance in the data set provides a one toone correspondence between attribute values and items in S  This means that each item can uniquely represent a specific attribute value combination  and vice versa     The restriction to a single attribute item description renders the  connective redundant  That is because the properties using the  logical connective can only be of the form  X   xi  X   xj    Without loss of generality we assume i    j  or otherwise we can simply drop one of the terms   These properties obviously cannot be satisfied because no item can have two different values for the only attribute X  In fact  set properties defined this way are equivalent to a property that is always f alse     The only relevant cardinalities for the set properties are         A property defined using only one connective with the restriction on the number of repetitions is not expressive enough to state a set property involving more than   items  If the value in a set property  h A   ai  A   aj    op  valuei  is greater than    and op         then again it cannot be satisfied  If the op of a property is  or    and the value is greater than    then it can be substituted by an effectively equivalent set property with op being  and value       The algorithm for the problem class in Theorem   is depicted in Figure     This algorithm bears some similarity to the algorithm in Figure    except that here the procedures G ET S ATISFYING S ET and H AS S ATISFYING S ET reason simultaneously about satisfaction of collections of set property values  and do that by utilizing   SAT solving  Specifically  in Table   we show how any valid property in such a POS problem can be translated into a   SAT CNF formula  In Lemma   we prove the correctness of this translation  We should note that by using   SAT we can have an answer to the question Is there a subset of items satisfying some already evaluated set property values  The procedures G ET S ATISFYING S ET and H AS S ATISFYING S ET use the aforementioned reduction to   SAT to provide the answer in polynomial time  Lemma    There is a subset S satisfying all the property values Pass if and only if there is a satisfying assignment A to the   SAT formula constructed from Pass         B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  h X h X h X h X h X h X    xi      i  infeasible   xi     i  infeasible   xi     i  substituted by   xi      i and translated to  vi   clause   xi     i  translated to  vi  v i   clause   xi      i  translated to  v i   clause Properties having   logical connectives  h X   xi  X   xj      i  infeasible h X   xi  X   xj     i  substituted by h X   xi  X   xj      i and translated to  vi   and  vj   clauses h X   xi  X   xj     i  translated to  vi  vj   clause h X   xi  X   xj      i  translated to  vi  vj   and  v i  v j   clauses h X   xi  X   xj     i  translated to  v i  v j   clause h X   xi  X   xj      i  translated to  v i   and  v j   clauses Properties having   logical connective  Table    Translation of the set properties for the POS subclass in Section       to   SAT                                                  Fix a preference ordering over set properties P Sopt   Pass   for each property P  P do while  not  P  isSatisfied   do Set next value to P w r t  Pass if H AS S ATISFYING S ET Pass   then Sopt  G ET S ATISFYING S ET Pass   P  isSatisfied  true Pass  Pass   P   end if end while end for return Sopt    Use reduction to   SAT   Use reduction to   SAT  Figure     A poly time algorithm for the POS problems with TCP net preference specification  and characteristics as in Table     Proof  By construction  we have an injective correspondence between the properties in the POS problem and clauses in the   SAT problem  Every property P  P injectively corresponds to a certain clause P   Every item o  S injectively corresponds to a propositional variable vi  V   Thus  the correspondence between the selected subset S and the assignment A is simply vi   true  o  S              G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  Because the translation is injective and rather straightforward  without introducing any auxiliary clauses or properties   it is trivial that S is a subset that satisfies all the properties in Pass if and only if A is an assignment that satisfies all the clauses in the corresponding   SAT formula  The above shows correctness of the algorithm in Figure     and finalizes the proof of Theorem        Complexity of POS  TCP nets vs  GAI Preference Specification With the restrictions as in Table   we were able to show that the POS problem with TCP net preference specification is tractable by reduction to   SAT  because there is no need to backtrack while searching in the attribute value space  An interesting question is  what if the specification were done using GAI functions  Theorem    Finding an optimal subset of a given set of items  POS  with respect to a GAI preference specification is NP hard even if the items are described in terms of a single attribute  all the set properties are binary valued  each containing at most   logical connective  that is  we have a     and k       Proof  The proof is by a polynomial reduction from MAX  SAT  As far as item definitions and properties are concerned  the reduction is essentially the same as the reduction from k SAT in the proof of Theorem    That is  for each variable v  V   construct an item ov and an item ov   The value of the only attribute X is defined as follows  for item ol   we have A ol     l  where l is a literal  either v or v  for all v  V    Set properties are also as in the proof of Theorem    but now they are limited to only   variables per clauses  re stated for convenience below    For each variable v  V    Pv  h X   v  X   v     i  that is  properties ensuring that a variable assignment is legitimate   For each clause C    l   l        PC  h X   l   X   l      i  that is  properties ensuring that  is satisfied  The value function specification is such that legitimate variable assignments are enforced  and a larger number of clauses satisfied is preferred  This is achieved by using an additively independent value function  i e   where each factor contains a single variable   with values being as follows  Each clause satisfying property has a value of   for being true  and   for being f alse  Each literalsatisfying property has a value of   for being true  and a negative value of  m for being f alse  where m is the number of clauses  Lemma    Given a GAI value function and item set S constructed as above for a   CNF formula   there exists a subset S  S with value of U  S    p if and only if there exists an assignment A satisfying p clauses in         B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  Proof  Let S be any subset of S that has non negative value  This implies by construction  since there are only m clause satisfying properties PC   that all literal satisfying properties must be true for S  and the respective assignment AS can be constructed as in Equation    Conversely  let A be a legitimate assignment to the variables V   One can define a corresponding set SA   for which  by construction  all properties Pv are true  Also  observe that by construction the number of PC set properties that are true on SA is the same as the number of clauses satisfied by the assignment A  The theorem follows immediately from the properties of the construction of the set properties and preferences  At the end of Section     we have noted that if the restrictions on the problem parameters are more severe than in Theorem    by limiting the number of logical connectives per set property to at most    we can no longer show whether the problem is tractable or NP hard under the TCPnet preference specification  However  Theorem   shows that  with preferences specified using a GAI value function  the problem is in fact NP hard  Moreover  the problem class from Theorem   subsumes the class from Theorem    and thus provides an additional result showing that even though with the TCP net specification the respective problem is tractable  with a GAI preference specification it becomes NP hard      Related Work In the introduction  we mentioned the closely related work of desJardins and Wagstaff         In that approach  the motivation to provide the user with a diverse collection of values is either to reflect the set of possible choices better for applications where the user must eventually select a single item  or when the diversity of the selected set is an objective on its own  The work of Price and Messinger        is explicitly concerned with this problem  Specifically  they consider the problem of recommending items to a user  and view it as a type of subset selection problem  For example  suppose we want to recommend a digital camera to a user  We have a large set of available cameras  and we are able to recommend k cameras  Price and Messinger consider the question of how to select this set  proposing that the candidate set will maximize the expected value of the users choice from this set  They suggest a concrete algorithmic approach for handling this problem  The input to their problem is some form of partial representation of the users preferences  which can be diverse  as in our work  and naturally  the concrete techniques are different from ours  Both these papers share the assumption on ranking sets  common to most previous work as discussed by Barbera et al          that ultimately one item will be selected from this set  However  they do not necessarily start out with an initial ranking over single items  and as in our case  the work of desJardins and Wagstaff utilizes the attribute value of items in the selection process  Earlier work on ranking subsets was motivated by problems such as the college admissions problem  Gale   Shapley         where we need to select the best set of fixed cardinality among a pool of college candidates  The admissions officer has various criteria for a good class of students and wishes to come up with an optimal choice  Some of the key questions that concerned this line of work were what are good properties of such set rankings and whether they have some simple representation  An example of a property of the set ranking that may be desirable is the following  given a set S  if we replace some member c  S with some other member c  to obtain the set S     and c  is preferred to c  then S   is preferred to S  An example of a representation of the ranking       G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  is an additive representation where items are associated with real values and one set is preferred to another if the sum of its elements values is larger  It would be interesting to study similar question in our context of structured objects  This question of ranking sets appears in other areas  such as logics of preference and likelihood  For example  the main question considered by Halpern        is how to construct an ordering over formulas based on an ordering over truth assignments  Formulas are associated with the set of worlds in which they are satisfied  and hence  the question of comparing the likelihood of formulas  and  corresponds to that of ranking their respective set of models given the initial ranking on single models  Much work on non monotonic logics uses Shohams preference semantics  Shoham         and semantically  such work  see  e g   Kraus  Lehmann    Magidor        can be viewed as attempting to answer the opposite question  define a ranking over single truth assignments given some  possibly partial  ordering over formulas  i e   sets of models  A number of lines of work are related to our specification and solution methods  The first is the work on Russian Doll Search  RDS   a well known algorithm for combinatorial optimization  originally presented by Verfaillie  Lematre  and Schiex        as an efficient algorithm for Constraint Optimization Problems  COP   The idea behind the approach is to solve consecutively harder problems  Initially  the problem is solved while considering only one variable  The optimal result provides a lower bound  Each iteration  additional variables are considered  until eventually the original problem is solved  By using the lower bound obtained from the previous iteration  and other optimizations  this technique is often able to solve the original problem more efficiently  Recently Rollon and Larrosa        extended Russian Doll Search to support multi objective optimization problems  In a multi objective optimization problem the goal is to optimize several parameters  attributes  of the variables in the problem  Usually all the parameters cannot be simultaneously optimized  The technique of Rollon and Larrosa involves incremental solution with more and more objectives included  and  in this sense  it is related to our search over CSPs approach in which we incrementally consider more and more set properties  Indeed  different desirable set properties can be viewed as different objectives  Another related area is that of Pseudo Boolean Constraint  PBC  Satisfaction Problems  Sheini   Sakallah         A PBC has the form  X wi li  k  i  Here the li s are literals and we interpret their values as being either    false  or    true   the wi are real valued coefficients  and k is an integer  Thus Pseudo Boolean CSPs are a special form of integer programs  and can nicely represent the cardinality constraints we generate  Thus  one option for solving the type of CSPs generated here would be using a dedicated PBC solver  We run several popular PBC solvers on the satisfiability instances generated during the optimization  Pueblo  Sheini   Sakallah         MiniSat  Een   Sorensson         and Galena  Dixon   Ginsberg         These solvers showed comparable results for satisfiable cases  while for the unsatisfiable cases  the PBC solvers showed better performance  This appears to be due to their use of linear programming as a preliminary test for satisfiability  Another line of work that bears important connection to ours is that of winner determination in combinatorial auctions  In regular auctions  bidders bid for a single item  In combinatorial auctions  bidders bid on bundles of items  Thus  bidders must provide their preferences over different subsets of the set of auctioned items  The goal in combinatorial auctions is to allocate the set of       B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  goods to different bidders in the best manner  e g   maximizing the payment to the seller or maximizing total welfare   This differs from the problem of selecting a single optimal subset with which we are concerned  However  in both cases  preferences over subsets must be provided to the optimization algorithm  As the number of subsets is exponential in the number of items  researchers in combinatorial auctions have sought bidding languages that can succinctly describe preferences of interest  Boutilier   Hoos        Nisan         What distinguishes our specification approach is its reliance on the existence of item features and the desire to provide a generic specification that does not depend on the concrete set of items  Work in combinatorial auctions also attempts to break the specification in some way  This is typically done by specifying values for small bundles and providing rules for deriving the value of larger sets from the values of the smaller sets      Conclusion We suggested a simple  yet general approach to lifting any attribute based preference specification formalism to one for specifying preferences over sets  We then focused one instantiation of this idea via a concrete language for specifying set properties  and suggested two methods for computing an optimal subset given such a specification  One method is based on searching the space of explicit subsets  while the other searches over implicit subsets represented as CSPs  Both search spaces are meaningful regardless of the specific underlying preference specification algorithm although the precise search and bounds generation method will vary  We focused on two concrete and popular specification formalisms  one qualitative and one quantitative  on which we experiment and provide complexity results  Although the problem is generally NP hard  as expected  the experimental results are quite encouraging  We wish to reemphasize that other choices  both for the set property language and the preference specification formalism are possible  and may be more appropriate in various cases  Indeed  an interesting topic for future research would be to see which choices fit best some natural application areas  whether and how the algorithm presented in this paper can be modified to handle such languages  and how the complexity of the optimal subset selection problem is affected by such choices  Though incremental search over CSPs appears to be the better method for optimal subset selection  it leaves a few questions open  First  it is an interesting question whether an efficient NoGood recording scheme that does not rely on static variable and value orderings exists  Intuitively  such a scheme should exist since the CSPs generated can be efficiently encoded into SAT as a boolean CNF formula  Bailleux   Boufkhad        Een   Sorensson         and clause learning is a well known technique in SAT solving  Second  we have seen that while the incremental approach usually improves the overall performance  its contribution is not substantial and what really improves the performance is better individual CSP solving  This begs two questions      Can we better utilize solutions across CSPs  and     Would representing and solving the CSPs generated as pseudo boolean CSPs  Manquinho   Roussel        or SAT instances lead to faster solution times  Naturally  alternative approaches are also feasible  Finally  in various applications  the set of elements gradually changes  and we need to adapt the selected subset to these changes  An example is when we use this approach to choose the most interesting current articles  and new articles constantly appear  It is likely that in this case the preferred set is similar to the current set  and we would like to formulate an incremental approach that adapts to such changes quickly         G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  Acknowledgments Preliminary versions of this work appeared in  Brafman  Domshlak  Shimony    Silver      b  Binshtok  Brafman  Shimony  Mani    Boutilier         The authors wish to thank our anonymous reviewers for their useful comments and suggestions  Brafman was supported in part by NSF grant IIS          Brafman and Domshlak were supported by the COST action IC      Binshtok  Brafman and Shimony were supported by Deutsche Telekom Laboratories at Ben Gurion University  by the Paul Ivanier Center for Robotics Research and Production Management  and by the Lynn and William Frankel Center for Computer Science   
 We consider online planning in Markov decision processes  MDPs   In online planning  the agent focuses on its current state only  deliberates about the set of possible policies from that state onwards and  when interrupted  uses the outcome of that exploratory deliberation to choose what action to perform next  The performance of algorithms for online planning is assessed in terms of simple regret  which is the agents expected performance loss when the chosen action  rather than an optimal one  is followed  To date  state of the art algorithms for online planning in general MDPs are either best effort  or guarantee only polynomial rate reduction of simple regret over time  Here we introduce a new Monte Carlo tree search algorithm  BRUE  that guarantees exponentialrate reduction of simple regret and error probability  This algorithm is based on a simple yet non standard state space sampling scheme  MCTS e  in which different parts of each sample are dedicated to different exploratory objectives  Our empirical evaluation shows that BRUE not only provides superior performance guarantees  but is also very effective in practice and favorably compares to state of the art  We then extend BRUE with a variant of learning by forgetting  The resulting set of algorithms  BRUE    generalizes BRUE  improves the exponential factor in the upper bound on its reduction rate  and exhibits even more attractive empirical performance      Introduction Markov decision processes  MDPs  are a standard model for planning under uncertainty  Puterman         An MDP hS  A  T r  Ri is defined by a set of possible agent states S  a set of agent actions A  a stochastic transition function T r   S  A  S          and a reward function R   S AS  R  Depending on the problem domain and the representation language  the description of the MDP can be either declarative or generative  or mixed   In any case  the description of the MDP is assumed to be concise  While declarative models provide the agents with greater algorithmic flexibility  generative models are more expressive  and both types of models allow for simulated execution of all feasible action sequences  from any state of the MDP  The current state of the agent is fully observable  and the objective of the agent is to act so to maximize its accumulated reward  In the finite horizon setting that will be used for most of the paper  the reward is accumulated over some predefined number of steps H  The desire to handle MDPs with state spaces of size exponential in the size of the model description has led researchers to consider online planning in MDPs  In online planning      the agent  rather than computing a quality policy for the entire MDP before taking any action  focuses only on what action to perform next  The decision process consists of a deliberation phase  aka planning  terminated either according to a predefined schedule or due to an external interrupt  and followed by a recommended action for the current state  Once that action is applied in the real environment  the decision process is repeated from the obtained state to select the next action and so on  The quality of the action a  recommended for state s with H steps to go  is assessed in terms of the probability that a is sub optimal  and in terms of the  closely related  measure of simple regret H  s  a   The latter captures the performance loss that results from taking a and then following an optimal policy   for the remaining H   steps  instead of following   from the beginning  Bubeck   Munos         That is  H  s  a    QH  s     s  H    QH  s  a   where     QH  s  a    Es  R s  a  s      QH   s       s    H        With a few recent exceptions developed for declarative MDPs  Bonet   Geffner        Kolobov  Mausam    Weld        Busoniu   Munos         most algorithms for online MDP planning constitute variants of what is called Monte Carlo tree search  MCTS   One of the earliest and best known MCTS algorithms for MDPs is the sparse sampling algorithm by Kearns  Mansour  and Ng  Kearns  Mansour    Ng         Sparse sampling offers a nearoptimal action selection in discounted MDPs by constructing a sampled lookahead tree in time exponential in discount factor and suboptimality bound  but independent of the state space size  However  if terminated before an action has proved to be near optimal  sparse sampling offers no quality guarantees on its action selection  Thus it does not really fit the setup of online planning  Several later works introduced interruptible  anytime MCTS algorithms for MDPs  with UCT  Kocsis   Szepesvari        probably being the most widely used such algorithm these days  Anytime MCTS algorithms are designed to provide convergence to the best action if enough time is given for deliberation  as well as a gradual reduction of performance loss over the deliberation time  Sutton   Barto        Peret   Garcia        Kocsis   Szepesvari        Coquelin   Munos        Cazenave        Rosin        Tolpin   Shimony         While UCT and its successors have been devised specifically for MDPs  some of these algorithms are also successfully used in partially observable and adversarial settings  Gelly   Silver        Sturtevant        Bjarnason  Fern    Tadepalli        Balla   Fern        Eyerich  Keller    Helmert         In general  the relative empirical attractiveness of the various MCTS planning algorithms depends on the specifics of the problem at hand and cannot usually be predicted ahead of time  When it comes to formal guarantees on the expected performance improvement over the planning time  very few of these algorithms provide such guarantees for general MDPs  and none breaks the barrier of the worst case only polynomial rate reduction of simple regret and choice error probability over time  This is precisely our contribution here  We introduce a new Monte Carlo tree search algorithm  BRUE  that guarantees exponential rate reduction of both simple regret and choice error probability over time  for general MDPs over finite state spaces  The algorithm is based on a simple and efficiently implementable sampling scheme  MCTS e  in which     MCTS   input  hS  A  T r  Ri  s   S  search tree T  root node s  while time permits    sample s    T   T  expand tree T     update statistics T     return recommend action s    T   Figure    High level scheme for regular Monte Carlo tree sampling  different parts of each sample are dedicated to different competing exploratory objectives  The motivation for this objective decoupling came from a recently growing understanding that the current MCTS algorithms for MDPs do not optimize the reduction of simple regret directly  but only via optimizing what is called cumulative regret  a performance measure suitable for the  very different  setting of reinforcement learning  Bubeck   Munos        Busoniu   Munos        Tolpin   Shimony        Feldman   Domshlak         Our empirical evaluation on some standard MDP benchmarks for comparison between MCTS planning algorithms shows that BRUE not only provides superior performance guarantees  but is also very effective in practice and favorably compares to state of the art  We then extend BRUE with a variant of learning by forgetting  The resulting family of algorithms  BRUE    generalizes BRUE  improves the exponential factor in the upper bound on its reduction rate  and exhibits even more attractive empirical performance      Monte Carlo Planning MCTS  a high level scheme for Monte Carlo tree search that gives rise to various specific algorithms for online MDP planning  is depicted in Figure    Starting with the current state s    MCTS performs an iterative construction of a tree T rooted at s    At each iteration  MCTS issues a state space sample from s    expands the tree T using the outcome of that sample  and updates information stored at the nodes of T   Once the simulation phase is over  MCTS uses the information collected at the nodes of T to recommend an action to perform in s    For compatibility of the notation with prior literature  in what follows we refer to the tree nodes via the states associated with these nodes  Note that  due to the Markovian nature of MDPs  it is unreasonable to distinguish between nodes associated with the same state at the same depth  Hence  the actual graph constructed by most instances of MCTS forms a DAG over nodes  s  h   S                 H   By A s   A in what follows  we refer to the subset of actions applicable in state s  Numerous concrete instances of MCTS have been proposed  with UCT  Kocsis   Szepesvari        probably being the most popular such algorithm these days  Gelly   Silver        Sturtevant        Bjarnason et al         Balla   Fern        Eyerich et al         Keller   Eyerich      a   To give a concrete sense of MCTSs components  as well as to ground some intuitions discussed later on  below we describe the specific setting of MCTS corresponding to the core UCT algorithm  and Figure   illustrates the UCT tree construction  with n denoting the number of state space samples       sample  The samples    hs    a    s            ak   sk i are all issued from the root node s    The sample ends either when a sink state is reached  that is  A sk       or when k   H  Each node action pair  s  a  is associated with a counter n s  a  and a value b a   Both n s  a  and Q s  b a  are initialized to    and then updated accumulator Q s  by the update statistics procedure  Given si   the next on the sample action ai   is selected according to the deterministic UCB  policy  Auer  Cesa Bianchi    Fischer      a   originally proposed for optimal cumulative regret minimization in stochastic multi armed bandit  MAB  problems  Robbins         If n si   a      for all a  A si    then s     log n s   i b i   a    c ai     argmax Q s       n si   a  a P where n s    a n s  a   Otherwise  ai   is selected uniformly at random from the still unexplored actions  a  A si     n si   a        In both cases  si   is then sampled according to the conditional probability P S si   ai      induced by the transition function T r   expand tree  Each state space sample    hs    a    s            ak   sk i induces a state trace hs    s            si i inside T   as well as a state trace hsi             sk i outside of T   In principle  T can be expanded with any prefix of hsi             sk i  a popular choice in prior work appears to be expanding T with only the upper most node si      If T is constructed as a DAG  it is expanded with the first node along  that leaves T     update statistics  For each node si along  that is now part of the expanded tree T   the counter n si   ai     is incremented and the estimated Q value is updated as b b i   ai      Q s b i   ai       Ri  Q si   ai       Q s n si   ai     where Ri    Pk  j i       R sj   aj     sj        recommend action  Interestingly  the action recommendation protocol of UCT was never properly specified  and different applications of UCT adopt different decision rules  including maximization of the estimated Q value  of the augmented estimated Q value as in Eq     of the number of times the action was selected during the simulation  as well as randomized protocols based on the information collected at the root  The key property of UCT is that its exploration of the search space is obtained by considering a hierarchy of forecasters  each minimizing its own cumulative regret  that is  the loss of the total reward incurred by exploring the environment  Auer et al       a   Each such pseudo agent forecaster corresponds to a state steps to go pair  s  h   In that respect  according to Theorem   of Kocsis and Szepesvari         UCT asymptotically achieves the best possible  logarithmic  cumulative regret  However  as recently pointed out in numerous works  Bubeck   Munos        Busoniu   Munos        Tolpin   Shimony        Feldman   Domshlak         cumulative regret does not seem to be the right objective for online MDP planning  and this is because the rewards collected at the simulation     n       n    n    n     Q     Q       Q     Q     Q     n    Q                                Q     Q          Q              Q                                      Q     n    n    n   Q            Q      Q     n    n    Q     Q     Q      Q     Q      Q      Q            Q      Q       Q      n    Q     Q     Q     Q     Q     Q     Q     Q     Q     Q     Q     Q     Q     Q      Q     Q     Q     Q       Figure    Illustration of the UCT dynamics  phase are fictitious  Furthermore  the work of Bubeck  Munos  and Stoltz        on multiarmed bandits shows that minimizing cumulative regret and minimizing simple regret are somewhat competing objectives  Indeed  the same Theorem   of Kocsis and Szepesvari        claims only a polynomial rate reduction of the probability of choosing a non optimal action  and the results of Bubeck et al         on simple regret minimization in MABs with stochastic rewards imply that UCT achieves only polynomial rate reduction of the simple regret over time  Some attempts have recently been made to adapt UCT  and MCTS based planning in general  to optimizing simple regret in online MDP planning directly  and some of these attempts were empirically rather successful  Tolpin   Shimony        Hay  Shimony  Tolpin    Russell         However  to the best of our knowledge  none of them breaks UCTs barrier of the worst case polynomial rate reduction of simple regret over time      Simple Regret Minimization in MDPs We now show that exponential rate reduction of simple regret in online MDP planning is achievable  To do so  we first motivate and introduce a family of MCTS algorithms with a two phase scheme for generating state space samples  and then describe a concrete algorithm from this family  BRUE  that     guarantees that the probability of recommending a non    optimal action asymptotically convergences to zero at an exponential rate  and     achieves exponential rate reduction of simple regret over time      Exploratory concerns in online MDP planning The work of Bubeck et al         on pure exploration in multi armed bandit  MAB  problems was probably the first to stress that the minimal simple regret can increase as the bound on the cumulative regret is decreases  At a high level  Bubeck et al         show that efficient schemes for simple regret minimization in MAB should be as exploratory as possible  thus improving the expected quality of the recommendation issued at the end of the learning process  In particular  they showed that the simple round robin sampling of MAB actions  followed by recommending the action with the highest empirical mean  yields exponential rate reduction of simple regret  while the UCB  strategy that balances between exploration and exploitation yields only polynomial rate reduction of that measure  In that respect  the situation with MDPs is seemingly no different  and thus Monte Carlo MDP planning should focus on exploration only  However  the answer to the question of what it means to be as exploratory as possible with MDPs is less straightforward than it is in the special case of MABs  For an intuition as to why the pure exploration dilemma in MDPs is somewhat complicated  consider the state steps to go pairs  s  h  as pseudo agents  all acting on behalf of the root pseudo agent  s    H  that aims at minimizing its own simple regret in a stochastic MAB induced by the applicable actions A s     Clearly  if an oracle would provide  s    H  with an optimal action    s    H   then no further deliberation would be needed until after the execution of    s    H   However  the task characteristics of  s    H  are an exception rather than a rule  Suppose that an oracle provides us with optimal actions for all pseudoagents  s  h  but  s    H   Despite the richness of this information   s    H  in some sense remains as clueless as it was before  To choose between the actions in A s      s    H  needs  at the very least  some ordinal information about the expected value of these alternatives  Hence  when sampling the futures  each non root pseudo agent  s  h  should be devoted to two objectives      identifying an optimal action    s  h   and     estimating the actual value of that action  because this information is needed by the predecessor s  of  s  h  in T   Note that both these objectives are exploratory  yet the problem is that they are somewhat competing  In that respect  the choices made by UCT actually make sense  Each sample  issued by UCT at  s  h  is a priori devoted both to increasing the confidence in that some current candidate a for    s  h  is indeed    s  h   as well as to improving the estimate of Qh  s  a    while as if assuming that    s  h    a   However  while such an overloading of the samples is unavoidable in the learning while acting setup of reinforcement learning  this should not necessarily be the case in online planning  Moreover  this sample overloading in UCT comes with a high price  As it was shown by Coquelin and Munos         the number of samples after which the bounds of UCT on both simple and cumulative regret become meaningful might be as high as hyper exponential in H          Separation of Concerns at the Extreme Separating the two aforementioned exploratory concerns is at the focus of our investigation here  Let s  be a state of an MDP hS  A  T r  Ri with rewards in         K applicable actions at each state  B possible outcome states for each action  and finite horizon H  First  to get a sense of what separation of exploratory concerns in online planning can buy us  we begin with a MAB perspective on MDPs  with each arm in the MAB corresponding to a flat policy of acting for H steps starting from the current state s    A flat policy  is a minimal partial mapping from state steps to go pairs to actions that fully specifies an acting strategy in the MDP for H steps  starting at s    Sampling such an arm  is straightforward as  prescribes precisely which action should be applied at every state that can possibly be encountered along the execution of   The reward of such an arm  isPstochastic  with H  i H support     H   and the number of arms in this schematic MAB is K     K i   B  K B   Now  consider a simple algorithm  NaiveUniform  which systematically samples each flat policy in a loop  and updates the estimation of the corresponding arm with the obtained reward  If stopped at iteration n  the algorithm recommends  s     where  is the arm policy with best empirical value  n   By the iteration n of this algorithm  each arm will be sampled at least b Bn H c times  Therefore  using the Hoeffdings inequality  the K probability that the chosen arm  is sub optimal in our MAB is bounded by  P   n     n     P   n    n           exp   b  n K BH  c    H              where         and thus the expected simple regret can be bounded as Ern  HK  BH  exp   b  n K BH  cd    H              Note that NaiveUniform uses each sample     s    a    s    a            aH    sH   to update the estimation of only a single policy   However  recalling that arms in our MAB problem are actually compound policies  the same sample can in principle be used to update the estimates of all policies    that are consistent with  in the sense that  for    i  H         si   H  i  is defined and it is defined as     si   H  i    ai   The resulting algorithm  CraftyUniform  generates samples by choosing the actions along them uniformly at random  and uses the outcome of each sample to update all the policies consistent with it  Note that sampling the arms in CraftyUniform cannot be done systematically as in NaiveUniform because the set of policies updated at each iteration is stochastic  Since the sampling is uniform  the probability of any policy to be updated by the sample issued at any iteration of CraftyUniform is K H   For an arm      let N   n denote the number of samples issued at the n iterations of CraftyUniform that are consistent with the policy      The probability that   the best empirical arm after n iterations  is sub optimal is bounded by           P   n    n    P  n      P  n                  Each of the two terms on the right hand side can be bounded as          n  n o n  P  n     P N n    P N n      n       K H  K H       n X      n H  e  K   N n   i P  N n   i  P  n      n i   e  e         n  K  H  n  K  H    e  n  K  H      e   K H            P  n           P  n         e  n    K  H H    N n  n       K H     n     K H     N n    n X i  nH  K  P  N n   i      n    K H H           where    and    are by the Hoeffding inequality  In turn  similarly to Eq     the simple regret for CraftyUniform is bounded by H  Ern   HK B e    nd   K  H H            Since H is a trivial upper bound on Ern   the bound in Eq    becomes effective only when   H nd  B  K exp   K  H H        that is  for    n  K B   H       H d     log K        Note that this transition period length is still much better than that of UCT  which is hyper exponential in H  Moreover  unlike in UCT  the rate of the simple regret reduction is then exponential in the number of iterations      Two phase sampling and BRUE While both the simple regret convergence rate  as well as the length of the transition period of CraftyUniform  are more attractive than those of UCT  this in itself is not much of a H help  CraftyUniform requires explicit reasoning about K B arms  and thus it cannot be efficiently implemented  However  it does show the promise of separation of concerns in online planning  We now introduce an MCTS family of algorithms  referred to as MCTS e  that allows utilizing this promise to a large extent  The instances of the MCTS e family vary along four parameters  switching point function    N              H   exploration policy  estimation policy  and update policy  With respect to these four parameters  the MCTS components in MCTS e are as follows   Similarly to UCT  each node action pair  s  a  is associated with variables n s  a  b a   However  while counters n s  a  are initialized to    value accumulators and Q s  b a  are schematically initialized to   Q s       sample  Each iteration of BRUE corresponds to a single state space sample of the MDP  and these samples    hs    a    s            ak   sk i are all issued from the root node s    The sample ends either when a sink state is reached  that is  A sk       or when k   H  The generation of  is done in two phases  At iteration n  the actions at states s            s n   are selected according to the exploration policy of the algorithm  while the actions at states s n            sk  are selected according to its estimation policy   expand tree  T is expanded with the suffix of state sequence s            s n   that is new to T    update statistics  For each state si   s            s n      the update policy of the algorithm prescribes whether it should be updated  If si should be updated  then the counter n si   ai     is incremented and the estimated Q value is updated according to Eq     p       recommend action  The recommended action is chosen uniformly at random among b     a   the actions a maximizing Q s In what follows  for n      the n th iteration of BRUE will be called H iteration if  n    H  At a high level  the two phases of sample generation respectively target the two exploratory objectives of online MDP planning  While the sample prefixes aim at exploring the options  the sample suffixes aim at improving the value estimates for the current candidates for     In particular  this separation allows us to introduce a specific MCTS e instance  BRUE   that is tailored to simple regret minimization  The BRUE setting of MCTS e is described below  and Figure   illustrates its dynamics   The switching point function    N              H  is  n    H    n     mod H         that is  the depth of exploration is chosen by a round robin on             H   in reverse order   At state s  the exploration policy samples an action uniformly at random  while the estimation policy samples an action uniformly at random  but only among the actions b a   a  A s  that maximize Q s   For a sample  issued at iteration n  only the state action pair  s n     a n    immediately preceding the switching state s n  along  is updated  That is  the information obtained by the second phase of  is used only for improving the estimate at state s n     and is not pushed further up the sample  While that may appear wasteful and even counterintuitive  this locality of update is required to satisfy the formal guarantees of BRUE discussed below  Before we proceed with the formal analysis of BRUE  a few comments on it  as well as on the MCTS e sampling scheme in general  are in place  First  the template of MCTS e is    Short for Best Recommendation with Uniform Exploration  the name is carried on from our first presentation of the algorithm in  Feldman   Domshlak         where estimation was referred to as recommendation       n    n    Uniform  n   a  r   a  r   a  r   a  r   a  r   a  r   a  r   a  r   a  r        Switching point  Switching point  Empirical  aH rH  Best  a  r   Uniform  a  r        a  r   a  r   Uniform       a  r   a  r   Switching point  Empirical  a  r   Best a  r   Q      a  r   Empirical Best  aH rH  Q       Q      aH rH  n    n    n    Switching point  Switching point  Switching point  Q      Q     Q        Q        Q      Q       n     n     n     Q      Q     Q      Q      Q      Q      Q     Q      Q     Q      Q      Q      Q      Q      Q      Q      Q      Q     Q      Q      Q      Q      Q      Q      Q      Q      Q      Q      Q     Q     Q      Q     Q      Q      Q     Q      Q      Q      Q     Q      Q      Q      Q      Q      Q      Q      Q      Q     Q     Q      Q     Q      Q     Q      Q      Q     Q        Q      Q      Q      Q      Q        Q      Q      Q       Q      Q      Q      Q      Q      Q      Q      Q      Q      Figure    Illustration of the BRUE dynamics  rather general  and some of its parametrizations will not even guarantee convergence to the optimal action  This  for instance  will be the case with a  seemingly minor  modification of BRUE to purely uniform estimation policy  In short  MCTS e should be parametrized with care  Second  while in what follows we focus on BRUE  other instances of MCTS e may appear to be empirically effective as well with respect to the reduction of simple regret over time  Some of them  similarly to BRUE  may also guarantee exponential rate reduction of simple regret over time  Hence  we clearly cannot  and do not  claim any uniqueness of BRUE in that respect  Finally  some other families of MCTS algorithms  more sophisticated that MCTS e  can give rise to even more  formally and or empirically  efficient optimizers of simple regret  The BRUE   set of algorithms that we discuss later on is one such example          Upper Bounds on Simple Regret Reduction Rate with BRUE For the sake of simplicity  in our formal analysis of BRUE we assume uniqueness of the optimal policy     that is  at each state s and each number h of steps to go  there is a single optimal action  and it is    s  h   Let Tn be the graph obtained by BRUE after n b h  s  a  denote the accumulated value Q s  b a  for s at depth H  h  For iterations  and let Q B all state steps to go pairs  s  h   Tn   n  s  h  is a randomized strategy  uniformly choosing b h  s  a   We also use some additional auxiliary notation  among actions a maximizing Q K   maxsS  A s    i e   the maximal number of actions per state  p   mins a s   T r s a s      T r s  a  s     i e   the likelihood of the least likely  but still possible  outcome of an action in our problem  d   mins a    s  a   i e   the smallest difference between the value of the optimal and a second best action at a state with just one step to go  Our key result on the BRUE algorithm is Theorem   below  The proof of Theorem    as well as of several required auxiliary claims  is given in Appendix A  Here we outline only the key issues addressed by the proof  and provide a high level flow of the proof in terms of a few central auxiliary claims  Theorem   Let BRUE be called on a state s  of an MDP hS  A  T r  Ri with rewards in        and finite horizon H  There exist pairs of parameters c  c       dependent only on  p  d  K  H   such that  after n   H iterations of BRUE  we have simple regret bounded as    EH  s  nB  s    H    Hc  ec n   and choice error probability bounded as     P nB  s    H        s    H   c  ec n                In particular  these bounds hold for c    K  H     H  Q   H     H     H    H  h    h        d H    H   p H    H  and c      d H  p H     H  H   H    K  H              Before we proceed any further  some discussion of the statements in Theorem   are in place  First  the parameters c and c  in the bounds established by Theorem   are problemdependent  in addition to the dependance on the horizon H and the choice branching factor K  which is unavoidable   the parameters c and c  also depend on the distribution parameters p and d  While it is possible that this dependence can be partly alleviated  Bubeck et al         showed that distribution free exponential bounds on the simple regret reduction rate cannot be achieved even in MABs  that is  even in single step to go MDPs  see Remark   of Bubeck et al          which is based on a lower bound on the cumulative      regret established by Auer  Cesa Bianchi  Freund    Schapire      b   Second  the specific parameters c and c  provided by Eqs     and    are worst case for MDPs with parameters d  p  and K  and the bound in Eq     becomes effective after         ln c  KH H n     O c pd iterations  for some small constant       While there is still some gap with this transition period length and the transition period length of the theoretical CraftyUniform algorithm  see Eq      this gap is not that large   The proof of Lemma   below constitutes the crux of the proof of Theorem    Once we have proven this lemma  the proof of Theorem   stems from it in a more or less direct manner  Lemma   Let BRUE be called on a state s  of an MDP hS  A  T r  Ri with rewards in        and finite horizon H  For each h  JHK  there exist parameters ch   c h      dependent only on  p  d  K  H   such that  for each state s reachable from s  in H  h steps and any t      it holds that     b h  s  a   Qh  s  a   d nh  s  a    t  ch ec h t   P Q            d c h t b P Qh  s  a   Qh  s  a    nh  s  a    t  ch e     In particular  these bounds hold for Q   h     h     h    h  i    i        d  h     p Hh h   Hh     H   ch    K  Hh h  and c h     d  h   pH h      h   h    K H h               The proof for Lemma   is by induction on h  Starting with the induction basis for h      it is easy to verify that  by the Chernoff Hoeffding inequality      d  d b P Q   s  a   Q   s  a   n  s  a    t   e   t             that is  the assertion is satisfied with c      and c     d    Now  assuming the claim holds for h     below we outline the proof for h      relegating the actual proof in full detail to Appendix A  In the proof for h      it is crucial to note the invalidity of applying the ChernoffHoeffding bound directly  as was done in Eq      There are two reasons for this     Some of this gap can probably be eliminated by more accurate bounding in the numerous bounding steps towards the proof of Theorem    However  all such improvements we tried made the already lengthy proof of Theorem   even more involved        b is an unbiased estimator of Q  that is  EQ b   Q  In contrast  the  F   For h      Q b estimates inside the tree  at nodes with h      are biased  This bias stems from Q possibly being based on numerous sub optimal choices in the sub tree rooted in  s  h   b are independent  This is not so for h       F   For h      the summands accumulated by Q where the accumulated reward depends on the selection of actions in subsequent nodes  which in turn depends on previous rewards  However  we show that these deficiencies of h     can still be overcome through a novel modification of the seminal Hoeffding Azuma inequality  Lemma    Modified Hoeffding Azuma inequality  Let  Xi   i   be a sequence of random variables with support     h  and i   EXi   If limi i     and P  E  Xi   X            Xi          cp ece i          for some     cp and     ce     then  for all       h    it holds that   t X           ce  h       cp      e  h  t   P Xi  t   t  ce i     t       X     ce  h  P      cp      e  h  t   Xi  t  t  ce                i    Together with Lemma   below  the inequalities provided by Lemma   allow us to prove the induction hypothesis in the proof of the central Lemma    Note that the specific bound in Lemma   is selected so to maximize the exponent coefficient  For any         the probabilities of interest in Eqs        can also be bounded by     c         ce  cp  e    h e  h  t      e ce       for further details  we refer the reader to Discussion    in Appendix A  Definition   Let hS  A  T r  Ri be an MDP with rewards in         planned for initial state s   S and finite horizon H  Let s be a state reachable from s  with h steps still to go  let a be an action applicable in s  and let tB be a policy induced by running BRUE on s  until exactly t     samples have finished their exploration phase with applying action a at s with h    steps still to go  Given that   Xt h  s  a  is a random variable  corresponding to the reward obtained by taking a at s  and then following tB for the remaining h    steps   Et h  s  a  is the event in which Xt h  s  a  is sampled along the optimal actions at each of the h    choice points delegated to tB    t h  s  a    Qh  s  a   E  Xt h  s  a          Lemma   Let hS  A  T r  Ri be an MDP with rewards in         planned for initial state s   S and finite horizon H  Let s be a state reachable from s  with h     steps still to go  and a be an action applicable in s  Considering Et h    s  a  and t h    s  a  as in Definition    for any t      if Lemma   holds for horizon h  then pc h  P  Et h    s  a     Kh      ch   e  K t   pc    Kh t  t h    s  a    Kh       ch   e                Together with a modified version of the Hoeffding Azuma bound in Lemma    the bounds b h   around Qh   as established in Lemma   allow us to derive concentration bounds for Q in Lemma   below  which serves the key building block for proving the induction hypothesis in the proof of Lemma    Lemma   Let BRUE be called on a state s  of an MDP hS  A  T r  Ri with rewards in        and finite horizon H  For each state s reachable s  with h     steps still to go  each action a applicable  and any t      it holds that   P        d  pc h    h       c K d  h b h    s  a   Qh    s  a      h     K   nh    s  a    t        Q e   d  p  c   h          Learning With Forgetting and BRUE   When we consider the evolution of action value estimates in BRUE over time  as well as in all other Monte Carlo algorithms for online MDP planning   we can see that  in internal nodes these estimates are based on biased samples that stem from the selection of non optimal actions at descendant nodes  This bias tends to shrink as more samples are accumulated down the tree  Consequently  the estimates become more accurate  the probability of selecting an optimal action increases accordingly  and the bias of ancestor nodes shrinks in turn  An interesting question in this context is  shouldnt we weigh differently samples obtained at different stages of the sampling process  Intuition tells us that biased samples still provide us with valuable information  especially when they are all we have  but the value of this information decreases as we obtain more and more accurate samples  Hence  in principle  putting more weight on samples with smaller bias could increase the accuracy of our estimates  The key question  of course  is which of all possible weighting schemes are both reasonable to employ and preserve the exponential rate reduction of expected simple regret  Here we describe BRUE     an algorithm that generalizes BRUE  BRUE    by basing the estimates only on the  fraction of most recent samples  We discuss the value of this addition both from the perspective of the formal guarantees  as well as from the perspective of empirical prospects  BRUE   differs from BRUE in two points  b a   each node action pair  s  a  in BRUE    In addition to the variables n s  a  and Q s  is associated with a list L s  a  of rewards  collected at each of the n s  a  samples that b a   are responsible for the current estimate Q s        When a sample    hs    a    s            ak   sk i is issued at iteration n  and update statistics updates the variables at x    s n     a n     that update is done not according to Eq    as in BRUE  but according to  n x   n x       L x  n x     k  X  R si   ai     si            i  n    b Q x      d  n x e  n x   X  L x  i    i n x dn x e  Theorem   Let BRUE    be called on a state s  of an MDP hS  A  T r  Ri with rewards in        and finite horizon H  There exist pairs of parameters c  c       dependent only on    p  d  K  H   such that  after n   H iterations of BRUE  we have simple regret bounded as   EH  s  nB  s    H    Hc  ec n        and choice error probability bounded as     P nB  s    H        s    H   c  ec n          The proof for Theorem   follows from Lemma   below similarly to the way Theorem   follows from Lemma    Note that in Theorem   we do not provide explicit expressions for the constants c and c  as we did in Theorem    for        This is because the expressions that can be extracted from the recursive formulas in this case do not bring much insight  However  we discuss the potential benefits of choosing      in the context of our proof of Theorem    Lemma   Let BRUE   be called on a state s  of an MDP hS  A  T r  Ri with rewards in        and finite horizon H  For each h  JHK  there exist parameters ch   c h      dependent only on    p  d  K  H   such that  for each state s reachable from s  in H  h steps and any t      it holds that     d   b P Qh  s  a   Qh  s  a   nh  s  a    t  ch ech t              d c h t b P Qh  s  a   Qh  s  a    nh  s  a    t  ch e     The proof for Lemma   is by induction  following the same line of the proof for Lemma    In fact  it deviates from the latter only in the application of the modified Hoeffding Azuma inequality  which has to be further modified to capture the partial sums as in BRUE    Lemma    Modified Hoeffding Azuma inequality for partial sums  Let  Xi   i   be a sequence of random variables with support     h  and i   EXi   If limi i     and P  E  Xi   X            Xi          cp ece i              for some     cp and     ce     then  for all       h    it holds that  P  P   t  X  i tdte  t  X  Xi  t   t  Xi  t  t    i tdte                      ce cp ce      t    e  h  t   e ce                    ce cp ce      t    e  h  t   e ce              Considering the benefits of sample forgetting as in BRUE    let us compare the bound in Lemma   to the bound       c     cp    c e  t  e   e  h    e  h   ce       provided by Lemma   for BRUE  that is  when all accumulated samples are averaged  While both bounds are very similar  the exponent of the second exponential term is multiplied for BRUE       by       t  This poses a tradeoff  Decreasing  reduces the sampling bias  c and thus decreases the term cpe   but increases the other exponential term with no leading constant  Obviously  since there is no bias at leaf nodes  it makes no sense to set      c there  However  as we go further up the tree  the bias tends to grow   cpe        but we also expect to have more samples  t is larger   Thus  from the perspective of formal guarantees  it seems appealing to choose smaller values of   Nevertheless  we do not try to optimize here the value of   First  optimizing bounds doesnt necessarily lead to optimized empirical accuracy  Second  the underlying optimization would have to be specific to each horizon h and each sample size t  which is obviously out of the question   and thus anyway we would have to consider only some rough approximations to this optimization problem  Finally  biased samples in practice might be more valuable than what the theory suggests  as long as all actions at the same state steps to go decision point experience a similar bias      Experimental Evaluation We have evaluated BRUE empirically on the MDP sailing domain  Peret   Garcia        that was used in previous works for evaluating MC planning algorithms  Peret   Garcia        Kocsis   Szepesvari        Tolpin   Shimony         as well as on random game trees used in the original empirical evaluation of UCT  Kocsis   Szepesvari         In the sailing domain  a sailboat navigates to a destination on an   connected grid representing a marine environment  under fluctuating wind conditions  The goal is to reach the destination as quickly as possible  by choosing at each grid location a neighbor location to move to  The duration of each  such move depends on the direction of the move  ceteris paribus  diagonal moves take   more time than straight moves   the direction of the wind relative to the sailing direction  the sailboat cannot sail against the wind and moves fastest with a tail wind   and the tack  The direction of the wind changes over time  but its strength is assumed to be fixed  This sailing problem can be formulated as a goal driven MDP over finite state space and a finite set of actions  with each state capturing the position of the sailboat  wind direction  and tack                       brue brueper            uct gct       brue brueper      uct gct  Average Error  Average Error                                                                         Running Time  sec                                                                 brue brueper       brue brueper            uct gct  uct gct       Average Error       Average Error           Running Time  sec                                                                 Running Time  sec                                                         Running Time  sec                               Figure    Empirical performance of BRUE  BRUE       UCT  and   greedy   UCT  denoted as GCT  for short  in terms of the average error on sailing domain problems on n  n grids with n                    In a goal driven MDP  the lengths of the paths to a terminal state are not necessarily bounded  and thus it is not entirely clear to what depth BRUE shall construct its tree  In the sailing domain  we chose H to be    n  where n is the grid size of the problem instance  as it is unlikely that the optimal path between any two locations on the grid will be larger than a complete encircling of the considered area  We note  however  that the recommendation oriented samples  always end at a terminal state  similar to the rollouts issued by UCT and   greedy   UCT  Snapshots of the results for different grid sizes are shown in Figure    We compared BRUE with two MCTS based algorithms  the UCT algorithm  and a recent modification of UCT    greedy   UCT  obtained from the former by replacing the UCB  policy at the root node with the   greedy policy  Tolpin   Shimony         The motivation behind the design of   greedy   UCT was to improve the empirical simple regret of UCT  and the results for   greedy   UCT reported by  Tolpin   Shimony         and confirmed by our experiments                brue brueper             uct gct  uct gct                  Average Error  Average Error  brue brueper                                                             Running Time  sec                B     D                    Running Time  sec           B     D       Figure    Empirical performance of BRUE  UCT  and   greedy   UCT  denoted as GCT  in terms of the average error on the random game trees with branching factor B and tree depth D   here  are very impressive  We also show the results for BRUEper        a slight modification of BRUE      with a more permissive update scheme  Instead of updating only the stateaction node at the level of the switching point  we also update any ancestor for which either not all applicable actions have been sampled or the chosen action was identical to the best empirical one  All four algorithms were implemented within a single software infrastructure  As suggested by more recent works on UCT  the exploration coefficient for UCT and   greedy   UCT  parameter c in Eq     was set to the empirical best value of an action at the decision point  Keller   Eyerich      b    This setting of the exploration coefficient resulted in better performance of both UCT and   greedy   UCT than with the settings reported on the sailing domain in the respective original publications   The   parameter in   greedy   UCT was set to     as in the experiments of Tolpin   Shimony        Each algorithm was run on      randomly chosen initial states s    and the performance of the algorithm was assessed in terms of the average error Q s    a   V  s     that is  the difference between the true values of the action a chosen by the algorithm and that of the optimal action    s     Consistently with the results reported by Tolpin and Shimony         on the smaller tasks   greedy   UCT outperformed UCT by a very large margin  with the latter exhibiting very little improvement over time even on the smallest        grids  The difference between   greedy   UCT and UCT on the larger tasks was less notable  In turn  BRUE substantially outperformed   greedy   UCT  with the improvement being consistent except for relatively short planning deadlines  and BRUEper       performed even better than BRUE  The above allows us to conclude that BRUE is not only attractive in terms of the formal performance guarantees  but can also be very effective in practice for online planning  Likewise  the learning with forgetting extension of BRUE   also has its practical merits  Under the same parameter setting of UCT and   greedy   UCT  we have also evaluated the      three algorithms in a domain of random game trees whose goal is a simple modeling of two person zero sum games such as Go  Amazons and Globber  In such games  the winner is decided by a global evaluation of the end board  with the evaluation employing this or another feature counting procedure  the rewards thus are associated only with the terminal states  The rewards are calculated by first assigning values to moves  and then summing up these values along the paths to the terminal states  Note that the move values are used for the tree construction only and are not made available to the players  The values are chosen uniformly from          for the moves of MAX  and from          for the moves of MIN  The players act so to  depending on the role  maximize minimize their individual payoff  the aim of MAX is to reach terminal s with as high R s  as possible  and the objective of MIN is similar  mutatis mutandis  This simple game tree model is similar in spirit to many other game tree models used in previous work  Kocsis   Szepesvari        Smith   Nau         except that the success failure of the players in measured not on a ternary scale of win lose draw  but via the actual payoffs they receive  We ran some experiments with two different settings of the branching factor  B  and tree depths  D   As in the sailing domain  we compared the convergence rate obtained by BRUE  UCT and   greedy   UCT  Figure   plots the average error rate for two configurations  B      D     and B      D       with the average in each setting obtained over     trees  The results here appear encouraging as well  with BRUE overtaking the other two algorithms more quickly on the deeper trees      SUMMARY We have introduced BRUE  a simple Monte Carlo algorithm for online planning in MDPs that guarantees exponential rate reduction of the performance measures of interest  namely the simple regret and the probability of erroneous action choice  This improves over previous algorithms such as UCT  which guarantee only polynomial rate reduction of these measures  The algorithm has been formalized for finite horizon MDPs  and it was analyzed as such  However  our empirical evaluation shows that it also performs well on goal driven MDPs and two person games  A few questions remain for future work  In the setting of  discounted MDPs with infinite horizons  a straightforward way to employ BRUE is to fix a horizon H  use the algorithm as is  and derive guarantees on the aforementioned measures of interest by simply accounting for the additive gap of  H Rmax        between the state action values under horizon H and those under an infinite horizon  However  this is not necessarily the best way to plan online for infinite horizon MDPs  and thus this setting requires further inspection  Second  it is not unlikely that the state space independent factors ch   and c h in the guarantees of BRUE can be improved by employing more sophisticated combinations of exploration and estimation samples  Another important point to consider is the speed of convergence to the optimal action  as opposed to the speed of convergence to good actions  BRUE is geared towards identifying the optimal action  although in many large MDPs  good is often the best one can hope for  To identify the optimal solution  BRUE devotes samples equally to all depths  However  focusing on nodes closer to the root node may improve the quality of the recommendation if the planning time is severely limited  Finally  the core tree sampling scheme employed by BRUE differs from the more standard scheme employed in previous work  While this difference plays a critical role in establishing      the formal guarantees of BRUE  it is still unclear whether that difference is necessary for establishing exponential over time reduction of the performance measures  Acknowledgements This work is partially supported by and carried out at the Technion Microsoft Electronic Commerce Research Center  as well as partially supported by the Air Force Office of Scientific Research  USAF  under grant number FA                 
 Tackling the problem of ordinal preference revelation and reasoning  we propose a novel methodology for generating an ordinal utility function from a set of qualitative preference statements  To the best of our knowledge  our proposal constitutes the first nonparametric solution for this problem that is both efficient and semantically sound  Our initial experiments provide strong evidence for practical effectiveness of our approach      INTRODUCTION  Human preferences are a key concept in decision theory  and as such have been studied extensively in philosophy  psychology  and economics  e g                  The central goals have been to provide logical  cognitive  and mathematical models of human decision making  More recently this research effort was joined by AI researchers  motivated by the goal of automating the process of decision support  To illustrate the need for automated decision support  consider the nowadays common task of searching for some goods in a database of an online vendor such as Amazon com or eBay  Such databases are too large for a user to search exhaustively  Using the purchase of a used car as an example  a decision support system might allow a user to state preferences like I like ecologically friendly cars  I prefer Mercedes to Lada  or For a sport car  I prefer red color to black color  The system should then use these preference statements to guide the user to the relevant parts of the database  Various logics of preference  graphical preference representation models  preference learning and reasoning algorithms have been proposed in AI in the last three decades            While these works have made significant contributions  there is still a substantial gap between theory and practice of decision support  In par   Thorsten Joachims Computer Science Dept  Cornell University Ithaca  NY        ticular  so far there is no single framework for revealing user preferences and reasoning about them that is both generically scalable and generically robust  i e  both efficient and effective for any set of decision alternatives and any form of preference information  It is clear nowadays that getting closer to such a universal framework requires new insights into the problem          In this paper  we tackle this challenge in the scope of revelation and reasoning about ordinal preferences  i e   as in the database search example above   and develop a robust solution for this problem that is both efficient and effective  Specifically  we propose a novel methodology for generating an ordinal utility function from a set of qualitative preference statements  Our proposal is based on a somewhat surprising mixture of techniques from knowledge representation and machine learning  We show formally that it leads to a flexible and unprecedentedly powerful tool for reasoning about ordinal preference statements  Furthermore  we present experiments that provide initial evidence for practical applicability and effectiveness of our method  making it promising for a wide spectrum of decision support applications       PROBLEM STATEMENT AND BACKGROUND  Using the used car database search as our running example  the content of the database constitutes the relevant subset of all possible choice alternatives   The ordinal preferences of a user who wants to buy a car can be viewed as a  possibly weak  possibly partial  binary preference relation P over        A decision support system should allow its user to state her preferences  use these statements to approximate P   and present the database content in a way that enables the user to quickly home in on desirable alternatives  The choice alternatives in such scenarios are typically described in terms of some attribution X    X            Xn   abstracting  to X   Dom Xi    e g   attributes of the database schema   and the user can   express her preferences in terms of X  Now  what preference information can we expect the users to provide  As suggested in the used car example  and supported by multi disciplinary literature           typically users should be expected to provide only qualitative preference statements that either compare between pairs of complete alternatives  e g   I prefer this alternative to that alternative   or generalize users preference over some properties of   e g   In a minivan  I prefer automatic transmission to manual transmission   Formally  this means that the user provides us with a qualitative preference expression  lead to restricting user expressions S to simplified languages that incorporate this prior assumption  In summary  computationally efficient schemes for multiattribute utility revelation proposed in economics and AI are parametrized by the structure that user preferences induce on X  and thus are applicable only when such structure exists and is known to the system   S    s            sm      h       i       hm  m m i        Having in mind these limitations  let us return back to the needs of decision support application  and list the challenges these applications pose to the research on OUR  The vision here is threefold  First  the user should be able to provide preference expressions S while being as little constrained in her language as possible  Second  the utility revelation machinery should be completely non parametric  i e   free of any explicit assumptions about the structure of user preferences  Third  both utility revelation  i e   generating U from S  and using the revealed utility function should be computationally efficient  including the case where user preferences pose no significant independence structure on X whatsoever   consisting of a set of such preference statements  s            sm    where i   i are logical formulas   i            and       and  have the standard semantics of strong preference  weak preference  and preferential equivalence  respectively  For ease of presentation  we assume attributes X are boolean   denoting Dom Xi      xi   xi     and i   i are propositional logic formulas over X  Given such a preference expression S  one has to interpret what information S conveys about P   decide on a representation for this information  and decide on the actual reasoning machinery  Several proposals for direct logical reasoning about S have been made  yet all these proposals are limited by  this or another  efficiency expressiveness tradeoff  In attempt to escape this tradeoff as much as possible  several works in AI  e g   see          proposed to compile information carried by S into an ordinal utility function U   X   R       consistent with  what we believe S tells us about  P   that is requiring x  x   X   U  x   U  x     P     x    x         In what follows  we refer to the task of constructing such a utility function U from S as ordinal utility revelation  OUR   Observe that specifying a utility function U as in     can be expensive due to the fact that  X     O  n    Hence  previous works on OUR searched for special conditions under which U can be represented compactly  e g   see                         The general scheme followed by these works  which we refer to as independence based methodology  is as follows  First  one defines certain independence conditions on X  and provides a representation theorem stating that under these conditions U can be compactly specified  Second  one possibly defines some additional conditions under which U can also be efficiently generated from S  Finally  assuming all these conditions    Extending our framework to arbitrary finite domain variables is straightforward  yet requires a more involved notation that we decided to avoid here        CHALLENGES AND OUR RESULTS  In this paper  we present the first approach that fulfills these goals  Combining ideas from knowledge representation  machine learning  and philosophical logic we provide a concrete mathematical setting in which all the above desiderata can be successfully achieved  and formally show that this setting is appealing both semantically and computationally  The mathematical framework we propose is based on a novel highdimensional structure for preference decomposition  and a specific adaptation of certain standard techniques for high dimensional continuous optimization  frequently used in machine learning in the context of Support Vector Machines  SVMs            HIGH DIMENSIONAL PREFERENCE DECOMPOSITION  Considering our vision for preference revelation  one can certainly be somewhat skeptical  Indeed  how can OUR be efficient if the user preferences pose no significant independence structure on X  or  if they do  the system is not provided with this independence information  The basic idea underlying our proposal is simple  Since we are not provided with a sufficiently useful independence information in the original space X   maybe we should move to a different space in which no independence information is required  Specifically  let us schematically map the alternatives   X into a new  higher dimensional space F using n     X   F   R          As one would expect  the mapping  is not arbitrary  Let FS   f         f n   be the dimensions of F  and D   Dom Xi   be the union of attribute domains in X  Let val   F   D be a bijective mapping from the dimensions of F onto the power set of D  uniquely associating each dimension fi with a subset val fi     x    x         xn   xn    In what follows  by Var fi    X we denote the subset of attributes instantiated by val fi    Given that  for each x  X and fi  F  we set       val fi    x  x  i           otherwise From     it is easy to see that dimensions fi with val fi   containing both a literal and its negation are effectively redundant  Indeed  later we show that we actually use only the   n     dimensional subspace of F  dimensions of which correspond to all the non empty partial assignments on X  Hence  for ease of presentation  in what follows we discuss F as if ignoring its redundant dimensions  However  for some technical reasons important for our computational machinery  the structure of F and  has to be defined as in          To illustrate our mapping   if X    X    X    and x   x  x    we have  x  i      if and only if val fi     x    x    x  x     that is     B   B   B B    x    B B   B B            val f     x     C val f      x  C val f      x  C C val f      x  C C val f      x  x  C C val f      x  x  A val f      x  x  val f      x  x        where     addresses only the non redundant dimensions of F  Geometrically   maps each n dimensional vector x  X to the  n  dimensional vector in F that uniquely encodes the set of all projections of x onto the subspaces of X   But is F semantically intuitive  After all  why should we adopt this and not some another dimensional structure for   To answer this question  recall that X is just an attribution of   induced by some application dependent considerations   and as such it does not necessarily correspond to the criteria affecting preference of the user over the actual physical alternatives  However  if the user provides us with some preference statements in terms of X  the implicit criteria behind these statements obviously have some encoding in terms of X  Given that  the semantic attractiveness of F is apparent  it is not hard to see that  evaluation of any such implicit  preference related criterion on x  X necessarily corresponds to a single dimension of F  In addition  Theorem   shows that F is not only semantically intuitive  but also satisfies our requirement of no need for independence information  Theorem   Any preference ordering P over X is additively decomposable in F  that is  the existence of a linear function n  U   x        X  wi  x  i        i    satisfying     is guaranteed for any such P over X   The proof of Theorem   is straightforward since we can always specify weights wi associated with all complete assignments to X such that     is satisfied  It is important to note  however  that this explicit construction of U only serves the existential proof of Theorem    and does not reflect whatsoever the machinery of our proposal  Since  by Theorem    dimensions F can successfully linearize any preference ordering P over X   in what follows we can focus only on linear utility functions as in      Of course  the reader may rightfully wonder whether this linearization in a space of dimension  n can be of any practical use  and not just a syntactic sugar  However  at this stage we ask the reader to postpone the computational concerns  and focus on the interpretation of preference expressions in the scope of our new high dimensional space F  There are two major categories of preference statements one would certainly like to allow in S       notably dyadic  comparative  statements  indicating a relation between two referents using the concepts such as better  worse  and equal in value to   and monadic  classificatory  statements  evaluating a single referent using ordinal language concepts such as good  very bad  and worst    For ease of presentation  let us focus on dyadic statements for now  In particular  consider an instance comparison statement x is better than x    where x  x   X   The interpretation of this statement poses no serious difficulties because it explicitly compares between complete descriptions of two alternatives  However  this is the exception  rather than the rule  Most of the preference statements that we use in our everyday activities  e g   I prefer compact cars to SUVs  have this or another generalizing nature  As such  these statements   This classification does not cover more higher order preferences  such as x is preferred to y more than z is preferred to w       Although here we do not discuss such statements  they as well can be processed in our framework    typically mention only a subset of attributes  This creates an ambiguity with respect to their actual referents  Several proposals on how to interpret preference statements have been made both in philosophy and AI  but there is no  and cannot be   an agreed upon solution to this problem       However  all the proposals suggest to interpret generalizing preference statements as comparing between complete descriptions X of the alternatives  while disagreeing on what complete descriptions are actually compared by each statement separately  and or by a multi statement preference expression as a whole  Considering interpretation of qualitative preference expressions in F  observe that each parameter wi of U as in     can be seen as capturing the marginal value of the interaction between Var fi   when these take the value val fi    Note that wi corresponds to this specific interaction only  all the syntactically related interactions of subsets and supersets of val fi   are captured by other parameters w  and the dimensional structure of F allows such an independent bookkeeping of all possible value related criteria  Now  consider an arbitrary dyadic statement      Let X  X  and similarly X   be the variables involved in   and M     Dom X   be the set of s models  Following the most standard  if not the only  interpretation scheme for OUR  we compile     into a set of constraints on the space of candidate utility functions       In our case  however  these constraints are posed on the functions of form      which are linear  real valued functions from the feature space F  and not from the original attribute space X as in previous works  Specifically  we compile     into a set of  M       M     constraints   m  M     m   M      X  X  wi    fi  val fi   m  wj      fj  val fj   m     where  m denotes the set of all value subsets of m  For example  statement  X   X       X     e g   It is more important that the car is powerful or fast than not having had an accident  is compiled into wx    wx    wx  x    wx  wx    wx    wx  x    wx  wx    wx    wx  x    wx   In first view  we clearly have some complexity issues here  First  while the constraint system C is linear  n it is linear in the exponential space R    Second  the summations in each constraint as in     are exponential in the arity of  and   i e   in  X   and  X     Finally  the number of constraints generated for each preference statement can be exponential in the arity of  and  as well  While exponential dimensionality of F is inherit in our framework  and we promised to do something about it later   the description complexity of C deserves a closer look  First  the description size of each constraint is clearly something to worry about  For instance  each instance comparison between a pair of complete alternatives in X is translated into a constraint with up to  n   summation terms  and this is a very natural form of everyday preference statements  Fortunately  in Section   we efficiently overcome this obstacle  On the other hand  the number of constraints per preference statement seems to be less problematic in practice  because the number of constraints equals the number of models of  and   and explicit simultaneous preferential comparison between large sets of models are rarely natural      COMPUTATIONAL MACHINERY  At this point  we hope to have convinced the reader that semantically our construction is appealing  What still remains to be shown is that it is computationally realistic  We begin with summarizing the complexity issues that we have to resolve   a  Our target utility function U is a linear  real valued function from a  n dimensional space F  Thus  not only generating U  but even keeping and evaluating this function explicitly might be infeasible        The constraint system C resulting from such compilation of a user expression S defines the space of solutions for our formulation of OUR  On the side of the semantics  we argue that C corresponds to a least committing interpretation of preference statements  This    encodes the principle that  if there is no reason for a bias towards certain explanations for      a most general explanation should be preferred  In Section   we describe how we pick a particular assignment to wi for a given set of constraints  and justify this choice in Section       The constraints for dyadic statements of the form     and    are similar to     with   being replaced by  and    respectively    b  The space of all suitable functions U is defined by n a set of linear constraints C in R    In addition to the dimensionality of this satisfiability problem  even the description of each constraint can be exponential in n    X  for many natural preference statements  In the following we show that both these complexity issues can be overcome  For ease of presentation and without loss of generality  we introduce our machinery on preference expressions consisting only of strict   instance comparisons x   x    where x  x   X  Our translation of each such dyadic preference statement x   x  leads to a linear constraint of the form  n      U   x     U  x         X  n  wi  x  i     i        X  wi  x    i   i    w   x    w   x           According to this formulation  the set of utility functions consistent with a set of k such preference statements is defined by the solutions of the linear system C     i  k  w   xi     w   x i            n  consisting of k constraints in R   Clearly  naive approaches to solving such systems will be computationally intractable for interesting n  In what follows  we will exploit duality techniques from optimization theory  see      and Mercer kernels  see       as used in machine learning to solve such systems in time that is linear in n and polynomial in k  At the first step  we reformulate our task of satisfying C as an optimization problem  Since the solution of      is typically not unique  we select a particular solution by adding an objective function and a margin by which the inequality constraints should be fulfilled  Specifically  similar to an ordinal regression SVM       we search for the smallest L  weight vector w that fulfills all constraints with margin    The corresponding constrained optimization problem is    Minimize  w  r  t  w    w  w   subject to      i  k  w   xi    w   many kinds of mappings   inner products can be computed efficiently using a Mercer kernel  see        even if  maps into a high dimensional  or infinite dimensional  space  Our task  thus  is to find such a kernel for the specific mapping  that we use in our construction          Let us define an injective representation of attribute vectors x by projecting them to indicator vectors  x  R n   Each attribute value is mapped onto a single dimension  If an attribute value is present in x  the corresponding component of  x is    otherwise    If an attribute is unspecified  all corresponding components of  x are set to    Using this construction  inner products for an  effectively equivalent  variant  of our mapping  can be computed as follows  Theorem   For the mapping    X   F   R   p c   val fi        x  i        c  k     n X  X  l  l k  l           lk    l          lk   l  l    l      lk          and any x  x   X and          n     the kernel K x  x      n X  l   x   x   l        l          computes the inner product   x     x      K x  x          Note that this reformulation of the problem does not affect its satisfiability  and that the solution of      is unique  since it is a strictly convex quadratic program   Proof The following chain of equalities holds  K x  x       In the second step we consider the Wolfe dual     of             k X  k k   XX i  i j    xi     x i       xj     x j       i   i   j       n X l       The third and final step is based on the observation that the dual      can be expressed in terms of inner products in the high dimensional feature space  For  n X  l  x  x   l  n X k     xi  x i  xi  x i     xil x il    X  l  l    subject to        This is a standard technique frequently used in the context of SVMs           The Wolfe dual      has the same optimum value as the primal       From the parameter vector  that solves the dual one can derive P  the solution w of the primal as w   m i   i   xi       xi      n X l      Maximize  w  r  t             where      x i    val fi    x otherwise  n   i       il          n l   xi  xi     xil   x i  x i     x il     X  l  i       il          n l  X  c  k    xi  xi     xik   x i  x i     x ik     i       ik         n       x     x     c  k  is the multiplicity with which a monomial of size k occurs  The multiplicity is influenced by two factors  First  different orderings of the index sequence  i         il   lead to the same term  This is counted by the l    where l         lk are the multinomial coefficient l      l k  powers of each factor  Second  all positive powers of any xi x i are equal  We therefore sum over all such   equivalent terms X l           lk    l          lk   l  l  l      lk    Note that many of the monomials always evaluate to zero under our encoding  x of x  Specifically  monomials corresponding to expressions  xi  xi       will always be nullified  In particular  it is therefore sufficient to consider only those monomials of size less or equal to n  since all others will always evaluate to zero   The kernel       which is similar to a polynomial kernel       allows us to compute inner products in the highdimensional space in linear time  and  for strictly positive          n   moving from  to  does not change the satisfiability of our constraint system C  To see the latter  observe that any solution w of      for  corresponds to a solution w of      for  via w i   w  i    p  c   val fi         The difference between the mappings  and  is that the former biases the inferences prior towards smaller size monomials  preferring more general explanations for user preference statements  On the other hand  this bias can be controlled to a large degree via the kernel parameters          n   Now  using the kernel inside of the dual leads to the following equivalent optimization problem  Maximize  w  r  t      k X i    i   k k   XX i j  K xi   xj    K xi   x j     i   j          K x i   xj     K x i   x j     As a final comment on the mechanics of our inference procedure  note that it would be unreasonable to expect that a users preference statements will always be consistent  In case of inconsistent preference specification  one can use the standard soft margin technique      trading off constraint violations against margin size       INFERENCE SEMANTICS  Since the users statements typically provide only partial information about her preferences  the constraint system in      is underconstrained  and thus the utility revelation takes the form of inductive reasoning  If the system has access to a prior P r U  over utility functions  a reasonable inductive inference procedure would be to pick the most likely utility function U that fulfills all constraints  In particular  for the Gaussian   prior P r U   e  w   this procedure results in finding the weight vector with minimum L   norm that fulfills the constraints  This is exactly our objective in       To illustrate the behavior arising from this prior  consider the statements s  s  s      X   X       X        X       X        X       X      For this small set of constraints  we can compute the solution without the use of kernel and get the following weights  wx         wx         wx        wx        wx      wx         wx      wx        wx  x         wx  x        All other weights are set to zero  Below is an illustrative excerpt of the ordering induced by the utility function generated in our framework   subject to        It is known that such convex quadratic programs can be solved in polynomial time      To compute the value of U for a given alternative x    X   it is sufficient to know only the dual solution and the kernel  k X     U  x       w  x       i  K xi  x    K x i  x      i          Hence  neither computing the solutions of the constraint system C  nor computing the values of U on X n requires any explicit computations in R    Through the use of kernels  all computations can be done efficiently in the low dimensional input space     We have extended SV M light to solve this type of quadratic optimization problem  The implementation is available at http   svmlight joachims org   It can efficiently handle large scale problems with n  m            U   x  x  x  x     U   x  x  x  x     U   x  x  x  x     U   x  x  x  x     U   x  x  x  x     U   x  x  x  x     U   x  x  x  x                                                      We believe that this ordering reflects a natural interpretation of the statements  Furthermore  alternatives for which the statements give no clear judgment receive utility values closer to zero than those for which a statement clearly applies  In general  the Gaussian prior appears reasonable in situations where we expect the utility function to have a compact form  i e  the weights in w are small     Now  recall that  i  each wi is devoted to capture the marginal value of the event val fi    and that  ii  we strive to a least committing interpretation of preference expressions  Observe that our inference procedure implicitly provides us with a reference point n    R    In short  we have wi     in case there is no reason to believe the user associates some  positive negative  value with val fi    Thus  consistent with standard logics of monadic preference concepts      utility U  x       indicates that a user is either indifferent about x  i e   has no reason to like it or dislike it   or neutral about it  users reasons to like x somehow balance her reasons to dislike it   Moreover  this reference point provides us with an intuitive encoding of monadic preference statements  For instance  a statement  isP good is translated into a set of  M     constraints fi  val fi   m wi      which can be seen as a special case of          EVALUATION OF EMPIRICAL EFFECTIVENESS  To demonstrate practical effectiveness of our approach  we conducted experiments on the EachMovie dataset    The dataset consists of six point scale movie ratings collected from       users on a corpus of      movies  Each movie is described by a set of attributes  out of which we use the decade of the movie  whether it is currently in the movie theaters  and a binary classification according to ten  non disjoint  genre categories  In our experiments we generate one ordinal utility function for each user  The EachMovie dataset contains ratings for individual movies  but no generalizing preference statements  To simulate generalizing preference statements  we generated such statements using the C    decision trees learning algorithm      on the following binary classification problem  As training examples  we form all pairs of movies by concatenating their attribute vectors  For each user we generate a separate training set  If the first movie was rated higher  lower  than the second movie  the pair is labeled positive  negative   No pair is generated if at least one of the movies was not rated or if both movies have the same rating  since it was unclear how to translate such cases into training examples for the classification task  On this data  we run the C    decision tree learner    Using the c  rules software included in the C    package we then convert the resulting decision tree into a set of rules ordered by their level of confidence  and interpret each of these learned rules as a single preference statement  For example  the highest ranked rule for      http   research compaq com SRC eachmovie  http   www cse unsw edu au quinlan   the user that rated the largest number of movies was the rule  a  below    a   B decade     s B Art Foreign     B Family     B Romance        A preferred to B   b   A decade     s A Thriller     B Classic     B Horror        A preferred to B  This rule can be interpreted as the monadic preference statement the user does not like foreign films from the   s that are not Romance or Family movies  For the same user  the highest ranked dyadic rule is rule  b   meaning the user prefers thrillers from the   s over non classic horror movies  The quality of the orderings induced by the generated utility functions is measured in terms of ordering error  that is the fraction of times where the user rating and the utility function disagree on the ordering of two movies  For this error measure we consider only movie pairs unequally rated by the user  Ties in the ordering induced by the utility function are broken randomly  Note that random performance according to this error measure is a score of      and that a score of     indicates a perfect ordering  All results that follow are averaged over the    users that provided the largest number of movie ratings  To normalize for different numbers of ratings  for each user we consider exactly     movie ratings randomly selected from her rating list  The left hand panel of Figure   shows how well the utility function orders the movies depending on the number of preference statements used to generate this function  In this analysis we use the top k preference statements as returned by c  rules  Each curve in Figure   gives the performance for a different choice of kernel degree  i e   different choice of kernel parameters          n   The degree d indicates that all i with i   d are set to zero  while all others are one  This eliminates all monomials of size greater then d  For small numbers of preference statements  all degrees perform roughly equivalently  but for larger sets of preference statements  high degree kernels substantially outperform low degree kernels  It appears that low degree kernels cannot capture the dependencies in the preference statements used in the evaluation  and thus the ability to handle large degree monomials  i e   non linear interactions between attributes X  is beneficial  Since we are using a very coarse description of the movies  the attributes do not suffice to produce a perfect ordering from a small number of preference statements  In particular  the average error rate of the complete set of C    rules is       Note that this pairwise classification performed by C    is potentially easier than the utility revelation problem  since the rules do                              Error  Error       degree   degree   degree   degree   degree   degree   degree   degree   degree                              Number of Preference Statements  degree   degree   degree   degree   degree   degree   degree   degree   degree                                  Number of Instance Preference Statements      Figure    Average error rate as a function of the number of statements in S  where S contains unrestricted generalizing  left   or  right  only instance level statements  not have to form an ordering  Comparing the C    performance against the error rates of around      achieved by the ordinal utility function for the highdegree kernels  we conclude that our method performs the translation into a consistent ordering effectively and with good accuracy  The right hand panel shows an analog plot for using only instance level statements  Compared to the generalizing statements  the error rates here are worse  and this indicates the beneficial expressive power of generalizing statements  For both instance and generalizing statements we performed additional experiments using a soft margin approach  This reduced error rates  but gave qualitatively similar results  Regarding computational efficiency  the average CPUtime of SV M light for solving the quadratic program for a set of    generalizing statements was less than     seconds      RELATED WORK AND CONCLUSIONS  We have described a novel approach to ordinal utility revelation from a set of qualitative preference statements  To the best of our knowledge  our proposal constitutes the first solution to this problem that can handle heterogeneous preference statements both efficiently and effectively  The key technical contribution is a computationally tractable  non parametric transformation into a space where ordinal utility functions decompose linearly and where dimensions have clear and intuitive semantics  As such  our approach addresses a long standing open question in the area of preference representation  formulated by Doyle     as  Can one recast the underlying set  of attributed alternatives  in terms of a different  from the original attribution  span of dimensions such that the utility  function becomes linear  If so  can one find new linearizing dimensions that also mean something to human interpreters  We have found in the literature only one work directly attempting to shed some light on this question  namely the work of Shoham on utility distributions       Specifically  Shoham shows that a set of linearizing dimensions exists for any utility function  and that this set of dimensions may have to be exponentially larger than the original set of attributes  The result of Shoham  however  is more foundational than operational  First  the connection between the original attribution and the particular set of dimensions proposed in      is not generally natural  and thus it is rather unclear how to perform preference elicitation with respect to this set of dimensions  Second  no efficient computational scheme for reasoning about this set of dimensions has been proposed so far  Thus  we believe that our work is the first to provide an affirmative  practically usable  answer to the question of generic existence of an intuitive linearizing space of dimensions  Our ongoing and future work builds upon the foundations laid in this paper in several directions  First  we would like to provide some informative upper bounds on the number of preference statements that a user will have to specify before the inferred utility function approximates her preferences sufficiently well  Furthermore  we would like to study applicability and efficiency of standard active learning techniques to mixedinitiated preference elicitation in our framework  Finally  we would like to perform a deeper analysis of the semantics of our inference procedure  connecting it  for instance  with the recent axiomatic approaches for preference revelation such as         This work was funded in part under NSF CAREER Award IIS                R  L  Keeney and H  Raiffa  Decision with Multiple Objectives  Wiley         
  Bayesian knowledge bases  BKBs  are a gen eralization of Bayes networks and weighted proof graphs  WAODAGs   that allow cycles in the causal graph  Reasoning in BKBs re quires finding the most probable inferences consistent with the evidence  The cost sharing heuristic for finding least cost ex planations in WAODAGs was presented and shown to be effective by Charniak and Hu sain  However  the cycles in BKBs would make the definition of cost sharing cyclic as well  if applied directly to BKBs  By treat ing the defining equations of cost sharing as a system of equations  one can properly de fine an admissible cost sharing heuristic for BKBs  Empirical evaluation shows that cost sharing improves performance significantly when applied to BKBs     INTRODUCTION  Bayes networks     are a commonly used reasoning tool within the uncertainty in AI community  Lately  graphical causal probabilistic models have shown up that generalize on the acyclic Bayes networks  in or der to cater for causal phenomena which cannot be strictly partially ordered  These models have causal cycles         or undirected sections in the directed graphs   J  Clearly  one stii  needs to do either be lief revision or belief updating     in order to perform reasoning in these schemes  These more general mod els  being less restrictive  pause interesting problems in implementing reasoning algorithms for them  Bayesian knowledge bases  BKBs      are a general ization of Bayes networks and weighted  AND OR  directed acyclic  proof graphs  acronym WAODAGs       that allow cycles in the causal graph  Consider the problem of finding the most probable inference   ex planation   consistent with the evidence in a BKB  This problem is analogous to  and more general than  the NP hard problem of belief revision in Bayes net   Eugene Santos Jr   Dept  of Electrical and Comp  Eng  Air Force Institute of Technology Wright Patterson AFB  OH e mail esantos afit af mil  works  or finding minimum cost proof on a WAODAG  As for Bayes networks  reasoning with tree shaped BKBs can be done efficiently  However  it is clear that in actual applications we cannot usually force our rep resentation to belong to the easy class of problems  To date  finding most probable inference in general BKBs has been implemented as best first heuristic search  where the heuristic used was cost so far  with dismal results  The reason is that this local heuris tic does not take into account the cost of nodes  or variables  to be assigned later on in the search  Prop agation of costs to be incurred is much preferable  but it is non trivial to do so in a manner resulting in an admissible heuristic  The latter was first achieved by using the cost sharing propagated cost method      see next section for a brief definition   It was shown by Charniak and Husain     that for find ing least cost explanations in WAODAGs  the   admis sible  cost sharing heuristic has a much better perfor mance  The cost sharing heuristic was also found use ful for belief revision in Bayes networks      Here  we generalize cost sharing to apply to cyclic graphs  and show that the resulting heuristic is also admissible  The generalization of the cost sharing heuristic  while straightforward  causes several problems  First  the cycles in the BKB make the problem of properly defin ing the heuristic nontrivial  If we just used the same defining equations  the fact that there are cycles would make the defining equations cyclic  But by looking at these equations as a system of equations  we state that a solution to the system is our heuristic  Any such solution to the system of equations is shown to be an admissible heuristic  A second problem is how to solve these equations  The standard top down algo rithm used in prior work would be hindered by the cy cles  even if we convert it to a kind of message passing updating algorithm  in many cases the algorithm will loop indefinitely  Instead  we show that converting the system of semi linear equations to a linear program  we can evaluate the heuristic in polynomial time  We begin with a motivating BKB example  followed by a formal definition of BKBs  section     We then relate BKBs to WAODAGs  and review the cost shar         Shimony  Domshlak  and Santos      Figure      Example graph with RVs as nodes   ing heuristic for WAODAGs  In Section   we extend cost sharing to handle cy cles  and present an efficient method of computing the heuristic  Section   discusses several implementation issues and refinements  Sec tion   compares search with cost sharing to search with a local  cost so far  heuristic      Figure      Example Knowledge Graph  BAYESIAN KNOWLEDGE BASES  In modeling an uncertain world  we designate random variables  abbrev  RVs  to represent the discrete ob jects or events in question  We then assign a joint probability distribution to each possible state of the world  i e   a specific value assignment for each RV  Graphical probabilistic models  such as Bayes net works      represent the existing dependencies in the model  variables not shown as dependent are assumed independent    facilitating a concise representation of the distribution  as a set of conditional probabilities  Let D  E and F be RVs  The conditional probabil ity  P DIE  F   identifies the belief in D s truth given that E and F are both known to be true  and repre sents an uncertain causal rule  We call D the head of P DIE  F  and  E  F  the tail  The distribution of the model is defined by  n  P A         An    II P A IX A          i l  where X A   is the set of RVs which Ai condition ally depends upon  If set X A   is small  the amount of information we must actually store to be able to compute the required joint probability is considerably  exponentially  less than the size of the cross product of the domains  In Bayes networks  the conditional dependencies are represented with a directed acyclic graph  Let A  B and C be RVs representing a traffic light  its asso ciated vehicle detector and pedestrian signal  respec tively  Suppose that the vehicle detector affects the traffic light  which in turn affects the pedestrian sig nal  Figure   graphically depicts this network over these variables  Since the signal depends upon the light  we say that A is the parent of C  Similarly  B is the parent of A  Now  expand the model with an additional variable denoting time of day  and suppose that the domain  expert wishes to add the conditional probability that the detector is tripped during rush hour when the light is red  Such an inclusion would introduce a cycle into our graph  which would not be permitted in a Bayes network  In the application domain  however  such cycles are frequently a natural representation  By introducing a finer level of distinction than one node per RV  using instead one node for each possi ble RV instantiation  the BK B representation finesses this problem  Assuming the same trio of RV s and the partial set of values below  P C   Don t Walk  lA  red  x   P A   greenjB   On    X  P C    Walk IA  green    x  P A   redlB     Off   X   We can legally add the new constraint  P B  On lA   red  D  rush hour   xs  without creating a directed cycle  as shown in Figure    Additionally  it is possi ble to have cycles in the knowledge graph in certain cases  without jeopardizing consistency of the distri bution  see       A BK B graph has two distinct types of nodes  The first  shown as lettered ovals  corresponds to individ ual RV instantiations  These are called instantiation nodes or   nodes for short  The second type of node  depicted as a blackened circle  is called a support node or   node  These nodes  which represent the condi tional probability value  have exactly one out bound arrow to the instantiation node representing the head of the conditioning case  Support nodes also have zero or more in bound dependency or conditioning arrows representing the tail of the conditioning case  The above representation of the conditional probabili ties  by separating out the variable states and the  pos sibly partial  conditioning  results both in more flexi bility  and a more compact representation      These properties are extremely useful in knowledge acqui         Cost Sharing in Bayesian Knowledge Bases  sition and in learning models from data  for various applications such as data mining           I  t     DEFINING KNOWLEDGE GRAPHS                  I  I  sl                 I           s   I  We define the topology as follows  Definition   A correlation graph G     IUS  E  is a directed graph such that InS      and E   I x S  U  S xI   Furthermore  for all a E S   a b  and  a b   are in E if and onl y if b   b    IUS  are the nodes of G and E are the edges of G  A node in I is called an instantiation node  abbrev    node  and a node in S is called a support node  abbrev  S node      nodes represent the various states of the world such as the truth or falsity of a proposition  S nodes  on the other hand  explicitly e mbody the relationships between the   nodes  Let  r be a partition on I  Intuitively   r denotes the groups of   nodes  states  which are mutually exclu sive  This can be used to represent random variables with discrete but multiple instantiations  with each partition cell corresponding to an RV  Definition   G  is said to I  respect  r if for all cells O  in  r  for any S node b E S such that  b  a  E E  b does not have a parent in O  except  possibly  a  Basically  mutually exclusive   nodes cannot be di rectly related to each other through the S nodes  Next  we define mutual exclusion between S nodes  Definition   Two S nodes b  and be mutually exclusive with respect  b  in S are said to to  r if there exist different   nodes c   c  that are parents of b   bz  re spectively and c   c  are in the same cell in       Definition   G is said to S respect  r if for all   nodes a in I  any two distinct parents of a  S nodes b  and b   are mutually exclusive   G is said to respects and S respects  r   Definition    respect   r  if G both    To complete our knowledge graph  we define a function w from S to   This serves as the mechanism for handling uncertainty in the relationships  Definition   A knowledge graph K is a   tuple  G  w   r  where G     US  E  is a correlation graph  w is a function from S to the positive reals  for each a E S  w a  is the weight of a    r is a partition on I  and G respects  r   The probabilistic semantics of a knowledge graph is provided by relating weights to probabilities  as fol lows  P  a    e w a   where P  a  is the conditional probability that the child of a is true given that the   s     Figure         Knowledge Graph with a Cycle  parents of a are true  To make sure that the probabil ities obey the axioms of probability theory  a normal ization constraint is enforced     on BKBs  However  this issue is irrelevant to finding most probable infer ence  and is thus beyond the scope of this paper        INFERENCE GRAPHS  A BKB is a knowledge graph  together with an infer ence scheme  The latter is defined by a set of permissi ble inference graphs  An i nferen ce graph is a subgr aph of the knowledge graph corresponding to an inference chain  or proof    Let r  I  U S   E   be some sub graph of our correlation graph G    I U S  E  where I   I  S   S  and E   E  Furthermore  r has a weight w   r  defined as follows          w r     L w s    ES   An   node a E J  is said to be well supported in r i f i t h as a n incoming S node i n r  that is  if there exists an edge  b  a  in E    An S node b is said to be well founded in r if all its incoming   nodes  conditions  are also present in r  An S node b E S  is said to be well defined in r if it supports some I node  is said to be an inference over K if i t is acyclic  consistent  i e  for all cells O  in  r  II  n O l      all of its   nodes are well supported  and all of its S nodes are well founded and well defined  An inference thus corresponds to a proof  Given the knowledge graph in F igure    one possible inference can be seen in Figure     r  For an abductive BKB  the problem we are address ing is  given a set s of   nodes  find an inference r of minimum weight that contains all of s  Given the se mantics of costs in BKBs  such an inference  proof  is equivalent to a maximum probability explanation  abductive inference  for s      COST SHARING IN WAODAGS  WAODAGs     are essentially acyclic knowledge graphs  with a single sink  out degree    node s  called        Shimony  Domshlak  and Santos            s        I     s                      s     Figure      cS  An Inference in the Knowledge Graph  edges  The actual solution is the set of nodes abutting the dummy edges  Since we need to find the minimal cost solution  we need a heuristic value for each cut  In fact  the heuristic value is defined over both edges and nodes  as follows  Let w   v   be the weights of the root nodes  We define the heuristic cost function c from E U V U  E to the non negative reals as  if v is a root node if v is an AND node if v is an OR node for nodes   v ce     the evidence node   and a partition of nodes into AND nodes  corresponding to S nodes in a BKB  and OR nodes  I nodes in a BKB   The evidence node is an AND node  Each WAODAG node has an associated cost  or weight   A proof r of sis a subgraph contain ing s where for each AND node in r  all of its parents are in r  and for each OR node in r  at least one of its parents are in r  Proofs in WAODAGs correspond to inferences in BKBs  The partition function  r has no counterpart in WAODAGs  The cost of a proof r is the sum of the weights of all nodes in r  As for knowledge graphs  one would like to find a least cost proof that contains the evidence node s  This is an NP hard problem  usually solved by best first search  starting from s  and adding parents when necessary  branching when several possibilities exist at OR nodes   An obvious admissible heuristic  cost so far  estimates the cost of a partial proof p as the sum of costs of nodes currently in p  The heuristic can be improved upon by propagating costs  but preserving admissibility is non trivial  Such an improved heuristic  cost sharing  was first presented in      where the search is in terms of edges  rather than nodes  We review the cost sharing heuristic for WAODAGs below  beginning with some necessary no tation borrowed from      Let edge e     a  b   from node a to node b   we call a the source of e  and b the sink of e  Also  we say that b is a child  immediate descendent  of a  If e is an edge  then v  denotes that node v is its source  and u denotes that u is its sink  we also sometimes use the notation Ve also to denote the source node of e  likewise for sinks   If v is a node  then e is an arbitrary edge v v incoming to v  and e an outgoing edge from v  Also  Ev is the set of all incoming edges of v  and Ev is the set of all outgoing edges  A node with no parents is called a root node  For convenience  a dummy edge e  leading from the evidence node is added to the graph  as well as one dummy edge leading into each root node  A state in the search space is a cut of the WAODAG  a set wise minimal set of edges that separates s from the root nodes   The initial state is the set   e    and a final state is a cut consisting only of root node dummy   v  c e     for edges  and for sets of edges  c C      C  E   L c e  eEC     COST SHARING IN BKBS  For BKBs  we intend to use the same definitions for the cost sharing heuristic  One difference between BKBs and WAODAGs is that in WAODAGs  only root nodes have weights  whereas in BKBs every S node has a weight  The difference can be overcome by observing that for each S node v we can always add one new    node and S node pair  call the latter v     set w   v      w  v   and let the new w   v   be    The semantics of the BKB stay the same  and now only root nodes have non   cost  Instead of doing that  we will note that the new I node only has one parent and one child  and absorb w   v    into the equation for v  to get     c  v        c Ev          c  ev   w v  mine EE   if v is an S node if v is an I node       for nodes  and the same equations as above for edges  Noting  however  the optimization in      observe that disjoint S nodes are never in the same inference  and thus we can replace the equation for edges by     v  ce     c ve  k ev        where k ev  is the number of consistent immediate support paths  Specifically  if v is an S node  then k ev      since there is only one outgoing edge from an S node  If v is an I node  k  ev  is the number of consistent   nodes immediately supported by S nodes that are children of v   As for WAODAGs  we have for sets of edges   c C      L c e        eEC  This number should be an upper bound on the number of edges outgoing from v that are in any inference  It may be possible to get a tighter bound in some cases  and if so that bound can be used in place of k  e      Cost Sharing in Bayesian Knowledge Bases  It is by no means clear whether these equations are suf ficient to uniquely define the cost function  However  treating equations         as a system of equations in the variables c  v    c  e  with v E V  e E E rather than a definition  we can refer to solutions of the system  Henceforth  we will denote by c an arbitrary solution to equations          whenever unambiguous  We will show that an arbitrary solution c to the system  hence forth called a cost sharing solution  is an admissible heuristic  by extending the proof of             Consider the knowledge graph in figure    The follow ing values can be computed immediately  c  sl  il          and c   s    i    c  s        All other equations now contain undefined terms  so we proceed by evaluating partially defined minima  For example   c sl              we could now set  temporarily   c i      As a result  we get the edge cost c  i   s           since i  has two children  We now have c s        and this in turn    makes c il         c  il  s          and This causes a re evaluation of c i         c s                 which  causes re evaluation to proceed indefinitely  until even  Theorem   Any cost sharing solution c is an admis  sible heuristic for BKBs  Proof outline  we first note that while the BKB is a graph with cycles  an inference is acyclic  and corre sponds to an AND DAG  A cut of an inference is de fined exactly as for an AND DAG in      a minimal set of edges that any path from the evidence to the leaves must intersect  As in WAODAGs  we define a cut of the BKB as a cut of some BKB inference  Now  we proceed with the same proof as in      All steps of the proof are the same  it does not matter that we have cycles  as the cycles only serve to further decrease c  and thus it is still an underestimate of the true weight  The remaining problems are with applying the WAODAG expansion operator Sr  which requires a topological sort T of the DAG  Since we have cycles  this is no longer possible  We must guarantee that once the we apply the expansion operator at a node  its outgoing edges will not be used anymore  To do that  we modify the expansion operator as follows  A state s is a set of edges and a set of deleted edges  Our expansion operator S  applied at node n is the same as Sr  except that when S is applied at node n  the edges En are added to the set of deleted edges  A state which contains a deleted edge is illegal  and discarded  In order that all possible inferences be reachable  it is not sufficient to apply the expansion according to a topological ordering  If S is applied  at each state  at all nodes where there is some en in the current set of edges  reachability is maintained    We now address the problem of computing a solution c v   Clearly  the seemingly obvious solution of using the equations directly will not help  some values will be undefined initially  One could think of a scheme that  to compute a minimum over several terms  some defined and some not  just takes the minimum over the currently defined terms  and propagates the resulting value  If every node participates in some inference  such a scheme is guaranteed to assign a cost value at each node eventually  However  in order to have all equations satisfied  it may be necessary to update cost values already derived  for example  due to finding a lower value than already used before  at an   node  It turns out that such a scheme may loop indefinitely  as the following example shows   tually  in the limit of an infinite number of loops  or i n practice determined by computational numeri cal accuracy  we get convergence at  c il    c i      c s     c s        c  il  s      c  il  s         and c i     c  s   i      c s        Not e further that the  costs we get reflect an illegal  cyclic inference  but since  we need an underestimate in order to get an admissible heuristic  this is not a problem  Solving the system of equations efficiently is non trivial  In fact  if we had max functions in addition to the min functions  or if the summation included negative terms  it would be easy to show that the prob lem of finding a solution is NP hard  and deciding the existence of a solution is NP complete   However  in our case   we can use linear programming techniques to derive a solution  by transforming the equations to a linear system  as follows  For each node and edge  we have a variable  which for convenience we denote by the same name  Linear equations are left as they are  Minimization equations are translated as follows   is replaced by the set of inequalities  V    Ut     V    U            V    Uk  Observe that the latter set of inequalities is weaker than the minimization  F inally  the objective function to maximize is    c      L  vel       c v  An optimal solution c  to the above linear program can be found using standard linear programming methods  such as the simplex method      A solution always ex     ists  since setting all c  v      v E I clearly determines a unique  not necessarily optimal  solution to the equa tions and inequalities   Theorem   Let c be an optimal solution to the lin   ear program  Then c  is also a solution to the cost sharing equation system  equations           Proof  Let c  be an optimal solution to the linear pro gram  Assume that c  violates some of equations          Since the linear linear program equations are the same as equations          except that minimiza tion was replaced by inequalities  only equations of the form  c v     min c  ev  e  eE         Shimony  Domshlak  and Santos  can be violated  Let v be a variable  node  where the above equation is violated  Then  since the linear pro gram enforces c  v   S c   ev   for all eu E Ev  then it must be the case that for this variable  c  v    c  ev  for all ev E Eu  otherwise it will indeed be the min imum  thus not violating the equation   Define R to be the set of nodes consisting of v and its immediate descendents  all immediate descendents are S nodes   and let ER be all edges with sources in R  Define an  and  for I nodes with just one parent   c ve    w ue      e   EE   c we    k e           Next  observe that the linear program is only neces sary within each strongly connected component  The implementation is  thus      other solution c  to the linear program as follows  For  L      Initialization  find strongly connected compo nents  and sort them in a total ordering consistent with a topological ordering of the components  such that the evidence node s  is first   program equations  starting with edges v E  then the S nodes  then the rest of the edges in ER  determine      the as yet undefined costs in c   The resulting solution is unique  because it uses equations for which all values on the right hand side are already determined  and the  Add to the graph a dummy edge S node v      Proceed from the last component down to the first  and for each component do   every node  u  not in R let  for every edge  e  c   v    Vmin     c   u    c  u   and likewise not in ER  Jet c    e     c    e     Let mi ne v EE v c    ev     and let the linear    c     and  As an example  consider the graph of Figure    where we would get the following set of inequalities   il S      i   s     b  Solve the linear program  to get the heuristic costs   i Sl  il s   i i  il  s      i   s           Initialize an agenda with a single state s  with edges s  e   the evidence dummy edge  and an empty list of expanded nodes   il s      i S                  il  s      i   s     i    s  i  il      z   s          zl  s       where we need to maximize c i l     c i     c i    The optimal solution is the same as the convergence value shown above  i  e  c il    c i       and c i            for every   a  Set up the linear program over variables de termined by nodes and edges for the cur rent component  including edges to and from other components   Incoming edges will have costs set in previous components  if any  and these costs are considered as constants for this component      left hand side is not  Clearly  c is also a solution to the linear program   where only one I node cost was changed  increased   We have   c      thus c  is not optimal  a contradiction  D      v    IMPLEMENTATION DETAILS  In applying the cost sharing heuristic  we actually use a simplified linear program  as follows  First  whenever an   node v has only a single parent  we use c  v     c  ev   rather than the inequality  We also cancel out all edge cost variables by substituting them according to equations         Finally  we can also cancel out by substitution all the S node costs  noting that S nodes all have only one child   to get a system of inequalities just for the   node costs  For   nodes with more than one parent  we get   c ve   S w ue      L   J e wEEu  c we   k e w   Looping until time limit  or required number of solutions found  get states of lowest heuristic cost from agenda  and do   a  Find the first strongly connected component containing a node v with some outgoing edge v e in edges         b  If there is no such component  output solution    of the i neq ualities for other   nodes  which cannot cause the inequalities to be v iolated     a   c  Otherwise  expand   at the current strongly connected component  as follows  For each unexpanded node v in the current compo nent for which there is an edge dv E E   in edges       and for each edge ev E Ev such that no parent of u   the source node of e    has been expanded do      n          Costs of ed ges and S nodes can only be increased by this change  thus can  at worst   affect variables not in R through introducing higher values on the right hand side  s  m   create a new state s   with node v added to the list of expanded nodes  The edges of s  are the edges of   with all edges E   removed and all edges Eu added  Evaluate the cost of s  by subtracting the cost of removed edges and adding the cost of added edges  from the cost of s     If   is consistent  does not contain any pair of   nodes from the same cell in the partition   insert it into the agenda   For example  let us trace the algorithm as run on the BKB fragment of figure    with i  being the evidence    Cost Sharing in Bayesian Knowledge Bases  The heuristic costs are computed as shown in the pre vious section  The strongly connected components are  il  i   and   i    The starting state  So  contains just the dummy edge  i       Search proceeds as shown in table    where  Pop  is the ID of the popped state  For lack of space  the dummy edges    i      s      s   are missing from the table  but this should not ad versely affect clarity  In the actual implementation  several details should be observed  First  instead of maintaining a list of deleted edges  it is sufficient  and more efficient  to treat any edge outgoing from an expanded node as if it were a deleted edge  and maintain a list of expanded I nodes  Second  the fact that S nodes are all AND nodes with a single outgoing edge is used to save some time  once an edge outgoing from an S node is picked  we are forced to select all the incoming edges into the S node anyway  so we do all that in one expansion step  and do not keep track of expanded S nodes     Caa so f  Cou            tai WJ          f    i   CWJ Sharinj  l  i r           i    Results are depicted in Figures      using log scale of time to solution and number of expansion steps  re spectively for the Y axis  X axis is just the number of the problem instance  and thus essentially meaning less here   Times for cost sharing include initialization of the heuristic costs  The cases labeled cost so far  failed  are those taking      seconds without reach ing a solution  or crashing due to lack of swap space  Figure   plots total number of problems solved vs  to tal CPU time  Cost sharing does better than cost so far by at least one order of magnitude  Finding several best solutions is also useful      A timing comparison for the    best solutions is depicted in Figure    These preliminary experiments suggest that cost sharing is an extremely useful search heuristic for graphs with cycles  as well as directed acyclic graphs  We know of no other heuristics for this search prob lem  Nor is it clear how one would apply schemes such as clustering to BKBs  and even if they could  a strongly connected component size of over    for most of the problem instances in the experiments suggest that the clique size would be too large to handle by such schemes  Thus  heuristic search with cost sharing appears to be the only viable method for BKBs not in one of the  topologically  easier classes of problems   I    le  H                                    tOO  UtOO  Figure    Time  Cost Sharing vs  Cost So Far  EXPERIMENTAL RESULTS  The above algorithm was tested on several BKB s pro duced from an available acyclic BKB for reasoning about raising gold fish  The network has       nodes and     S nodes  Cycles were introduced by random reversal of several arc pairs  Evidence selection was also random  Runtime and number of expansion steps  iterations through step   of the algorithm  were com pared between a search algorithm using cost sharing and one using cost so far  The program was imple mented in C    and run on a SPARC                                    Cc i K  fu       eikd            Jc H JJ            f    j                                        Figure    Expansion Count Comparison      tiiilt                                                           l OO      L         l lO         I   j    j  J  i                              l  I  I I                                        I        L    d  l  l j I     I  I  I C      Figure    Number of Problems Solved vs  CPU Time   Shimony  Domshlak  and Santos       Iteration         Pop  So s   s  s  s          Expand Edge  Edges   i       i   s      i   s     i  s     i   s    i   s      i   s      s    Delete Edges  i      i   s   i    s   i   s    il  s  i  s    i   s  i   s    i   s  i   s    i  s  i   s    i   s   i      i   s  i   s  i   s  i   s    i   s  i   s   Add Edges  New State ID  i        So i    s      i   s   s      sn s  s  i  s       s     g  i   s   s     s   s     s   s   NONE Table      Cost                        Trace of the Search Algorithm  
 Domain independent planning is one of the foundational areas in the field of Artificial Intelligence  A description of a planning task consists of an initial world state  a goal  and a set of actions for modifying the world state  The objective is to find a sequence of actions  that is  a plan  that transforms the initial world state into a goal state  In optimal planning  we are interested in finding not just a plan  but one of the cheapest plans  A prominent approach to optimal planning these days is heuristic state space search  guided by admissible heuristic functions  Numerous admissible heuristics have been developed  each with its own strengths and weaknesses  and it is well known that there is no single best heuristic for optimal planning in general  Thus  which heuristic to choose for a given planning task is a difficult question  This difficulty can be avoided by combining several heuristics  but that requires computing numerous heuristic estimates at each state  and the tradeoff between the time spent doing so and the time saved by the combined advantages of the different heuristics might be high  We present a novel method that reduces the cost of combining admissible heuristics for optimal planning  while maintaining its benefits  Using an idealized search space model  we formulate a decision rule for choosing the best heuristic to compute at each state  We then present an active online learning approach for learning a classifier with that decision rule as the target concept  and employ the learned classifier to decide which heuristic to compute at each state  We evaluate this technique empirically  and show that it substantially outperforms the standard method for combining several heuristics via their pointwise maximum      Introduction At the center of the problem of intelligent autonomous behavior is the task of selecting the actions to take next  Planning in AI is best conceived as the model based approach to automated action selection  Geffner         The models represent the current situation  goals  and possible actions  Planning specific languages are used to describe such models concisely  The main challenge in planning is computational  as most planning languages lead to intractable problems in the worst case  However  using rigorous search guidance tools often allows for efficient solving of interesting problem instances  In classical planning  which is concerned with the synthesis of plans constituting goal achieving sequences of deterministic actions  significant algorithmic progress has been achieved in the last two decades  In turn  this progress in classical planning is translated to advances in more involved planning languages  allowing for uncertainty and feedback  Yoon  Fern    Givan        Palacios c      AI Access Foundation  All rights reserved    D OMSHLAK   K ARPAS     M ARKOVITCH    Geffner        Keyder   Geffner        Brafman   Shani         In optimal planning  the objective is not just to find any plan  but to find one of the cheapest plans  A prominent approach to domain independent planning  and to optimal planning in particular  is state space heuristic search  It is very natural to view a planning task as a search problem  and use a heuristic search algorithm to solve it  Recent advances in automatic construction of heuristics for domain independent planning established many heuristics to choose from  each with its own strengths and weaknesses  However  this wealth of heuristics leads to a new question  given a specific planning task  which heuristic to choose  In this paper  we propose selective max  an online learning approach that combines the strengths of several heuristic functions  leading to a speedup in optimal heuristic search planning  At a high level  selective max can be seen as a hyper heuristic  Burke  Kendall  Newall  Hart  Ross    Schulenburg         a heuristic for choosing among other heuristics  It is based on the seemingly trivial observation that  for each state  there is one heuristic which is the best for that state  In principle  it is possible to compute several heuristics for each state  and then choose one according to the values they provide  However  heuristic computation in domain independent planning is typically expensive  and thus computing several heuristic estimates for each state takes a long time  Selective max works by predicting for each state which heuristic will yield the best heuristic estimate  and computes only that heuristic  As it is not always clear how to decide what the best heuristic for each state is  we first analyze an idealized model of a search space and describe how to choose there the best heuristic for each state in order to minimize the overall search time  We then describe an online active learning procedure that uses a decision rule formulated for the idealized model  This procedure constitutes the essence of selective max  Our experimental evaluation  which we conducted using three state of the art heuristics for domain independent planning  shows that selective max is very effective in combining several heuristics in optimal search  Furthermore  the results show that using selective max results in a speedup over the baseline heuristic combination method  and that selective max is robust to different parameter settings  These claims are further supported by selective max having been a runnerup ex aequo in the last International Planning Competition  IPC       Garca Olaya  Jimenez    Linares Lopez         This paper expands on the conference version  Domshlak  Karpas    Markovitch        in several ways  First  we improve and expand the presentation of the selective max decision rule  Second  we explain how to handle non uniform action costs in a principled way  Third  the empirical evaluation is greatly extended  and now includes the results from IPC       as well as controlled experiments with three different heuristics  and an exploration of how the parameters of selective max affect its performance      Previous Work Selective max is a speedup learning system  In general  speedup learning is concerned with improving the performance of a problem solving system with experience  The computational difficulty of domain independent planning has led many researchers to use speedup learning techniques in order to improve the performance of planning systems  for a survey of many of these  see the work of Minton         Zimmerman and Kambhampati         and Fern  Khardon  and Tadepalli               O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  Speedup learning systems can be divided along several dimensions  Zimmerman   Kambhampati        Fern         Arguably the most important dimension is the phase in which learning takes place  An offline  or inter problem  speedup learner analyzes the problem solvers performance on different problem instances in an attempt to formulate some rule which would not only improve this performance but would also generalize well to future problem instances  Offline learning has been applied extensively to domain independent planning  with varying degrees of success  Fern et al          However  one major drawback of offline learning is the need for training examples  in our case  planning tasks from the domains of interest  Learning can also take place online  during problem solving  An online  or intra problem  speedup learner is invoked by the problem solver on a concrete problem instance the solver is working on  and it attempts to learn online  with the objective of improving the solvers performance on that specific problem instance being solved  In general  online learners are not assumed to be pretrained on some other  previously seen problem instances  all the information they can rely on has to be collected during the process of solving the concrete problem instance they were called for  Online learning has been shown to be extremely helpful in propositional satisfiability  SAT  and general constraint satisfaction  CSP  solving  where nogood learning and clause learning are now among the essential components of any state of the art solver  Schiex   Verfaillie        Marques Silva   Sakallah        Bayardo Jr    Schrag         Thus  indirectly  SAT  and CSP based domainindependent planners already benefit from these online learning techniques  Kautz   Selman        Rintanen  Heljanko    Niemela         However  to the best of our knowledge  our work is the first application of online learning to optimal heuristic search planning      Background A domain independent planning task  or planning task  for short  consists of a description of an initial state  a goal  and a set of available operators  Several formalisms for describing planning tasks are in use  including STRIPS  Fikes   Nilsson         ADL  Pednault         and SAS   Backstrom   Klein        Backstrom   Nebel         We describe the SAS  formalism  the one used by the Fast Downward planner  Helmert         on top of which we have implemented and evaluated selective max  Nothing  however  precludes using selective max in the context of other formalisms  A SAS  planning task is given by a   tuple    hV  A  s    Gi  V    v            vn   is a set of state variables  each associated with a finite domain dom vi    A complete assignment s to V is called a state  s  is a specified state called the initial state  and the goal G is a partial assignment to V   A is a finite set of actions  Each action a is given by a pair hpre a   eff a i of partial assignments to V called preconditions and effects  respectively  Each action a also has an associated cost C a   R     An action a is applicable in a state s iff s    pre a   Applying a changes the value of each state variable v to eff a  v  if eff a  v  is specified  The resulting state is denoted by sJaK  We denote the state obtained from sequential application of the  respectively applicable  actions a            ak starting at state s by sJha            ak iK  Such an action sequence is a plan if s  Jha            ak iK    G  In optimal planning  we are interested in finding one of Pthe cheapest plans  where the cost of a plan ha            ak i is the sum of its constituent action costs ki   C ai    A SAS  planning task    hV  A  s    Gi can be easily seen as a state space search problem whose states are simply complete assignments to the variables V   with transitions uniquely determined by the actions A  The initial and goal states are also defined by the initial state and goal of   An optimal solution for a state space search problem can be found by using the A search algorithm       D OMSHLAK   K ARPAS     M ARKOVITCH  with an admissible heuristic h  A heuristic evaluation function h assigns an estimate of the distance to the closest goal state from each state it evaluates  The length of a cheapest path from state s to the goal is denoted by h  s   and h is called admissible if it never overestimates the true goal distance  that is  if h s   h  s  for any state s  A works by expanding states in the order of increasing f  s     g s    h s   where g s  is the cost of the cheapest path from the initial state to s known so far      Selective Max as a Decision Rule Many admissible heuristics have been proposed for domain independent planning  these vary from cheap to compute yet not very accurate  to more accurate yet expensive to compute  In general  the more accurate a heuristic is  the fewer states would be expanded by A when using it  As the accuracy of heuristic functions varies for different planning tasks  and even for different states of the same task  we may be able to produce a more robust optimal planner by combining several admissible heuristics  Presumably  each heuristic is more accurate  that is  provides higher estimates  in different regions of the search space  The simplest and best known way for doing that is using the point wise maximum of the heuristics in use at each state  Given n admissible heuristics  h            hn   a new heuristic  maxh   is defined by maxh  s     max in hi  s   It is easy to see that maxh  s   hi  s  for any state s and for any heuristic hi   Thus A search using maxh is expected to expand fewer states than A using any individual heuristic PHowever  if we denote the time needed to compute hi by ti   the time needed to compute maxh is ni   ti   As mentioned previously  selective max is a form of hyper heuristic  Burke et al         that chooses which heuristic to compute at each state  We can view selective max as a decision rule dr  which is given a set of heuristics h            hn and a state s  and chooses which heuristic to compute for that state  One natural candidate for such a decision rule is the heuristic which yields the highest  that is  most accurate  estimate  drmax   h            hn    s     hargmax in hi  s    Using this decision rule yields a heuristic which is as accurate as maxh   while still computing only one heuristic per state  in time targmax in hi  s    This analysis  however  does not take into account the different computation times of the different heuristics  For instance  let h  and h  be a pair of admissible heuristics such that h   h    A priori  it seems that using h  should always be preferred to using h  because the former should cause A to expand fewer states  However  suppose that on a given planning task  A expands      states when guided by h  and only     states when guided by h    If computing h  for each state takes    ms  and computing h  for each state takes      ms  then switching from h  to h  increases the overall search time  Using maxh over h  and h  only makes things worse  because h   h    and thus computing the maximum simply wastes the time spent on computing h    It is possible  however  that computing h  for a few carefully chosen states  and computing h  for all other states  would result in expanding     states  while reducing the overall search time when compared to running A with only h    As this example shows  even given knowledge of the heuristics estimates in advance  it is not clear what heuristic should be computed at each state when our objective is to minimize the overall search time  Therefore  we begin by formulating a decision rule for choosing between one of two heuristics  with respect to an idealized state space model  Selective max then operates as an online       O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  s   s f    c  f    c sg  Figure    An illustration of the idealized search space model and the f  contours of two admissible heuristics  active learning procedure  attempting to predict the outcome of that decision rule and choose which heuristic to compute at each state      Decision Rule with Perfect Knowledge We now formulate a decision rule for choosing which of two given admissible heuristics  h  and h    to compute for each state in an idealized search space model  In order to formulate such a decision rule  we make the following assumptions   The search space is a tree with a single goal  constant branching factor b  and uniform cost actions  Such an idealized search space model was used in the past to analyze the behavior of A  Pearl          The time ti required for computing heuristic hi is independent of the state being evaluated  w l o g  we assume t   t     The heuristics are consistent  A heuristic h is said to be consistent if it obeys the triangle inequality  For any two states s  s    h s   h s      k s  s     where k s  s    is the optimal cost of reaching s  from s   We have   i  perfect knowledge about the structure of the search tree  and in particular the cost of the optimal solution c    ii  perfect knowledge about the heuristic estimates for each state  and  iii  a perfect tie breaking mechanism  Obviously  none of the above assumptions holds in typical search problems  and later we examine their individual influence on our framework  Adopting the standard notation  let g s  be the cost of the cheapest path from s  to s  Defining maxh  s    max h   s   h   s    we then use the notation f   s    g s    h   s   f   s    g s    h   s   and maxf  s    g s    maxh  s   The A algorithm with a consistent heuristic h expands states in increasing order of f   g   h  Pearl         In particular  every state s with f  s    h  I    c will surely be expanded by A   and every state with f  s    c will surely not be       D OMSHLAK   K ARPAS     M ARKOVITCH  expanded by A   The states with f  s    c might or might not be expanded by A   depending on the tie breaking rule being used  Under our perfect tie breaking assumption  the only states with f  s    c that will be expanded are those that lie along some optimal plan  Let us consider the states satisfying f   s    c  the dotted line in Fig     and those satisfying f   s    c  the solid line in Fig      The states above the f    c and f    c contours are those that are surely expanded by A with h  and h    respectively  The states above both these contours  the grid marked region in Fig      that is  the states SE    s   maxf  s    c    are those that are surely expanded by A using maxh  Pearl        Thm     p       Under the objective of minimizing the search time  note that the optimal decision for any state s  SE is not to compute any heuristic at all  since all these states are surely expanded anyway  Assuming that we still must choose one of the heuristics  we would choose to compute the cheaper heuristic h    Another easy case is when f   s   c   In these states  computing h   s  suffices to ensure that s is not surely expanded  and using a perfect tie breaking rule  s will not be expanded unless it must be  Because h  is also cheaper to compute than h    h  should be preferred  regardless of the heuristic estimate of h  for state s  Let us now consider the optimal decision for all other states  that is  those with f   s    c and f   s   c   In fact  it is enough to consider only the shallowest such states  in Figure    these are the states on the part of the f    c contour that separates between the grid marked and line marked areas  Since f   s  and f   s  are based on the same g s   we have h   s    h   s   that is  h  is more accurate in state s than h    If we were interested solely in reducing state expansions  then h  would obviously be the right heuristic to compute at s  However  for our objective of reducing the actual search time  h  may actually be the wrong choice because it might be much more expensive to compute than h    Let us consider the effects of each of our two alternatives  If we compute h   s   then s is not surely expanded  because f   s    c   and thus whether or not A expands s depends on tiebreaking  As before  we are assuming perfect tie breaking  and thus s will not be expanded unless it must be  Computing h  would cost us t  time  In contrast  if we compute h   s   then s is surely expanded because f   s    c   Note that not computing h  for s and then computing h  for one of the descendants s  of s is clearly a sub optimal strategy as we do pay the cost of computing h    yet the pruning of A is limited only to the search sub tree rooted in s    Therefore  our choices are really either computing h  for s  or computing h  for all the states in the sub tree rooted in s that lie on the f    c contour  Suppose we need to expand l complete levels of the state space from s to reach the f    c contour  Thus  we need to generate an order of bl states  and then invest bl t  time in calculating h  for all these states that lie on the f    c contour  Considering these two options  the optimal decision in state s is thus to compute h  iff t    bl t    or to express it differently  if l   logb   tt      As a special case  if both heuristics take the same time to compute  this decision rule reduces to l      that is  the optimal choice is simply the more accurate heuristic for state s  Putting all of the above cases together yields the decision rule dropt   as below  with ls being the depth to go from s until f   s    c         O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING    h    f   s    c   f   s    c    h   f  s   c       dropt   h    h     s      h    f   s    c   f   s   c   ls  logb   tt        h   f  s    c   f  s   c   l   log   t          s b t      Decision Rule without Perfect Knowledge The idealized model above makes several assumptions  some of which appear to be very problematic to meet in practice  Here we examine these assumptions more closely  and when needed  suggest pragmatic compromises  First  the model assumes that the search space forms a tree with a single goal state  that the heuristics in question are consistent  and that we have a perfect tie breaking rule  Although the first assumption does not hold in most planning tasks  the second assumption is not satisfied by many state of the art heuristics  Karpas   Domshlak        Helmert   Domshlak        Bonet   Helmert         and the third assumption is not realistic  they do not prevent us from using the decision rule suggested by the model  The idealized model also assumes that both the branching factor and the heuristic computation times are constant across the search states  In our application of the decision rule to planning in practice  we deal with this assumption by adopting the average branching factor and heuristic computation times  estimated from a random sample of search states  Finally  the decision rule dropt above requires unrealistic knowledge of both heuristic estimates  as well as of the optimal plan cost c and the depth ls to go from state until f   s    c   As we obviously do not have this knowledge in practice  we must use some approximation of the decision rule  The first approximation we make is to ignore the trivial cases that require knowledge of c   these are the cases where either s is surely expanded  or h  is enough to prune s  Instead  we apply the reasoning for the complicated case for all states  resulting in the following decision rule    h    ls  logb   tt     drapp    h    h     s       h    ls   logb   tt     The next step is to somehow estimate the depth to go ls  the number of layers we need to expand in the tree until f  reaches c   In order to derive a useful decision rule  we assume that ls has a positive correlation with h  s    h   s   h   s   that is  if h  and h  are close  then ls is low  and if h  yields a much lower estimate than h    implying that h  is not very accurate for s  then the depth to go until f   s    c is large  Our approximation uses the simplest such correlation  a linear one  between h  s  and ls   with a hyper parameter  for controlling the slope  Recall that in our idealized model  all actions were unit cost  and thus cost to go and depthto go are the same  However  some planning tasks  and notably  all planning tasks from the      International Planning Competition  feature non uniform action costs  Therefore  our decision rule converts heuristic estimates of cost to go into heuristic estimates of depth to go by dividing the cost to go estimate by the average action cost  We do this by modifying our estimate of the depthto go  ls   with the average action cost  which we denote by c  Plugging all of the above into our       D OMSHLAK   K ARPAS     M ARKOVITCH  decision rule yields    h    drapp    h    h     s     h     h  s     c  logb   tt       h  s      c  logb   tt      Given b  t    t    and c  the quantity   c  logb  t   t    becomes fixed  and in what follows we denote it simply by threshold    Note that linear correlation between h  s  and ls occurs in some simple cases  The first such case is when the h  value remains constant in the subtree rooted at s  that is  the additive error of h  increases by   for each level below s  In this case  f  increases by   for each expanded level of the sub tree  because h  remains the same  and g increases by     and it will take expanding exactly h  s    h   s   h   s  levels to reach the f    c contour  The second such case is when the absolute error of h  remains constant  that is  h  increases by   for each level expanded  and so f  increases by    In this case  we will need to expand h  s    levels  This can be generalized to the case where the estimate h  increases by any constant additive factor c  which results in h  s   c    levels being expanded  Furthermore  there is some empirical evidence to support our conclusion about exponential growth of the search effort as a function of heuristic error  even when the assumptions made by the model do not hold  In particular  the experiments of Helmert and Roger        on IPC benchmarks with heuristics with small constant additive errors show that the number of expanded nodes most typically grows exponentially as the  still very small and additive  error increases  Finally  we remark that because our decision rule always chooses an admissible heuristic  the resulting heuristic estimate will always be admissible  Thus  even if the chosen heuristic is not the correct one according to dropt   this will not result in loss of optimality of the solution  but only in a possible increase in search time      Online Learning of the Decision Rule While decision rule drapp  still requires knowledge of h  and h    we can now use it as a binary label for each state  We can compute the value of the decision rule by paying the computation time of both heuristics  t    t    and  more importantly  we can use a binary classifier to predict the value of this decision rule for some unknown state  Note that we use the classifier online  during the problem solving process  and the time spent on learning and classification is counted as time spent on problem solving  Furthermore  as in active learning  we can choose to pay for a label for some state  where the payment is also in computation time  Therefore we refer to our setting as active online learning  In what follows  we provide a general overview of the selective max procedure  and describe several alternatives for each of its components  Our decision rule states that the more expensive heuristic h  should be computed at a search state s when h   s   h   s       This decision rule serves as a binary target concept  which corresponds to the set of states where the more expensive heuristic h  is significantly more accurate than the cheaper heuristic h   the states where  according to our model  the reduction in expanded states by computing h  outweighs the extra time needed to compute it  Selective max then uses a binary classifier to predict the value of the decision rule  There are several steps to building the classifier        O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  evaluate s  hh  conf idencei    CLASSIFY s  model  if  conf idence     then return h s  else label    h  if h   s   h   s      c  logb  t   t    then label    h  update model with hs  labeli return max h   s   h   s   Figure    The selective max state evaluation procedure    Training Example Collection  We first need to collect training examples  which should be representative of the entire search space  Several state space sampling methods are discussed in Section         Labeling Training Examples  After the training examples are collected  they are first used to estimate the average branching factor b  average heuristic computation times t  and t    and the average action cost c  Once b  t    t    and c are estimated  we use them to estimate the threshold      c  logb  t   t    for the decision rule  We then generate a label for each training example by calculating h  s    h   s   h   s   and comparing it to the decision threshold  If h  s       we label s with h    otherwise with h    If t    t  we simply switch between the heuristics  our decision is always whether or not to compute the more expensive heuristic  the default is to compute the cheaper heuristic  unless the classifier says otherwise     Feature Extraction  Having obtained a set of training examples  we must decide about the features to characterize each example  Since our target concept is based on heuristic values  the features should represent the information that heuristics are derived from  typically the problem description and the current state  While several feature construction techniques for characterizing states of planning tasks have been proposed in previous literature  Yoon  Fern    Givan        de la Rosa  Jimenez    Borrajo         they were all designed for inter problem learning  that is  for learning from different planning tasks which have already been solved offline  However  in our approach  we are only concerned with one problem  in an online setting  and thus these techniques are not applicable  In our implementation  we use the simplest features possible  taking each state variable as a feature  As our empirical evaluation demonstrates  even these elementary features suffice for selective max to perform well     Learning  Once we have a set of labeled training examples  each represented by a vector of features  we can train a binary classifier  Several different choices of classifier are discussed in Section      After completing the steps described above  we have a binary classifier that can be used to predict the value of our decision rule  However  as the classifier is not likely to have perfect accuracy        D OMSHLAK   K ARPAS     M ARKOVITCH  we further consult the confidence the classifier associates with its classification  The resulting state evaluation procedure of selective max is depicted in Figure    For every state s evaluated by the search algorithm  we use our classifier to decide which heuristic to compute  If the classification confidence exceeds a confidence threshold   a parameter of selective max  then only the indicated heuristic is computed for s  Otherwise  we conclude that there is not enough information to make a selective decision for s  and compute the regular maximum over h   s  and h   s   However  we use this opportunity to improve the quality of our prediction for states similar to s  and update our classifier by generating a label based on h   s h   s  and learning from the newly labeled example  These decisions to dedicate computation time to obtain a label for a new example constitute the active part of our learning procedure  It is also possible to update the estimates for b  t    t    and c  and change the threshold  accordingly  However  this would result in the concept we are trying to learn constantly changing  a phenomenon known as concept drift  which usually affects learning adversely  Therefore  we do not update the threshold        State Space Sampling The initial state space sample serves two purposes  First  it is used to estimate the branching factor b  the heuristic computation times t  and t    the average action cost c  and then to compute the threshold      c  logb  t   t     which is used to specify our concept  After the concept is specified  the state space sample also provides us with a set of examples on which the classifier is initially trained  Therefore  it is important to have an initial state space sample that is representative of the states which will be evaluated during search  The number of states in the initial sample is controlled by a parameter N   One option is to use the first N states of the search  However  this method is biased towards states closer to the initial state  and therefore is not likely to represent the search space well  Thus  we discuss three more sophisticated state space sampling procedures  all of which are based on performing random walks  or probes  from the initial state  While the details of these sampling procedures vary  each such probe terminates at some pre set depth limit  The first sampling procedure  which we refer to as biased probes  uses an inverse heuristic selection bias for choosing the next state to go to in the probe  Specifically  the probability of choosing state s as the successor from which the random walk will continue is proportional to    maxh  s   This biases the sample towards states with lower heuristic estimates  which are more likely to be expanded during the search  The second sampling procedure is similar to the first one  except that it chooses the successor uniformly  and thus we refer to it as unbiased probes  Both these sampling procedures add all of the generated states  that is  the states along the probe as well as their siblings  to the statespace sample  and they both terminate after collecting N training examples  The depth limit for all random walks is the same in both sampling schemes  and is set to some estimate of the goal depth  we discuss this goal depth estimate later  The third state space sampling procedure  referred to here as PDB sampling  has been proposed by Haslum  Botea  Helmert  Bonet  and Koenig         This procedure also uses unbiased probes  but only adds the last state reached in each probe to the state space sample  The depth of each probe is determined individually  by drawing a random depth from a binomial distribution around the estimated goal depth        O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  Note that all three sampling procedures rely on some estimate of the minimum goal depth  When all actions are unit cost  the minimum goal depth is the same as h  s     and thus we can use a heuristic to estimate it  In our evaluation  we used twice the heuristic estimate of the initial state     maxh  s     as the goal depth estimate  However  with non uniform action costs  goal depth and cost are no longer measured in the same units  While it seems we could divide the above heuristicbased estimate by the average action cost c  recall that we use the state space sample in order to obtain an estimate for estimate c  thus creating a circular dependency  Although it is possible to estimate c by taking the average cost of all actions in the problem description  there is no reason to assume that all actions are equally likely to be used  Another option is to modify the above state space sampling procedures  and place a cost limit  rather than a depth limit  on each probe  However  this would pose a problem in the presence of   cost actions  In such a case  when a probe reaches its cost limit yet has a possible   cost action to apply  it is not clear whether the probe should terminate  Therefore  we keep using depth limited probes and attempt to estimate the depth of the cheapest goal  We compute a heuristic estimate for the initial state  and then use the number of actions which the heuristic estimate is based on as our goal depth estimate  While this is not possible with every heuristic  we use in our empirical evaluation the monotonically relaxed plan heuristic  This heuristic  also known as the FF heuristic  Hoffmann   Nebel         does provide such information  we first use this heuristic to find a relaxed plan from the initial state  and then use the number of actions in the relaxed plan as our goal depth estimate      Classifier The last decision to be made is the choice of classifier  Although many classifiers can be used here  several requirements must be met due to our particular setup  First  both training and classification must be very fast  as both are performed during time constrained problem solving  Second  the classifier must be incremental to support active learning  This is achieved by allowing online updates of the learned model  Finally  the classifier should provide us with a meaningful measure of confidence for its predictions  While several classifiers meet these requirements  we found the Naive Bayes classifier to provide a good balance between speed and accuracy  One note on the Naive Bayes classifier is that it assumes a very strong conditional independence between the features  Although this is not a fully realistic assumption for planning tasks  using a SAS  task formulation in contrast to the classical STRIPS formulations helps a lot  instead of many highly dependent binary variables  we have a much smaller set of less dependent ones  Although  as the empirical evaluation will demonstrate  Naive Bayes appears to be the most suitable classifier to use with selective max  other classifiers can also be used  The most obvious choice for a replacement classifier would be a different Bayesian classifier  One such classifier is AODE  Webb  Boughton    Wang         an extension of Naive Bayes  which somewhat relaxes the assumption of independence between the features  and is typically more accurate than Naive Bayes  However  this added accuracy comes at the cost of increased training and classification time  Decision trees are another popular type of classifier that allows for even faster classification  While most decision tree induction algorithms are not incremental  the Incremental Tree Inducer  ITI  algorithm  Utgoff  Berkman    Clouse        supports incremental updating of decision trees by tree restructuring  and also has a freely available implementation in C  In our evaluation  we used ITI in incremental mode  and incorporated every example into the tree immediately  because the       D OMSHLAK   K ARPAS     M ARKOVITCH  tree is likely to be used for many classifications between pairs of consecutive updates with training examples from active learning  The classification confidence with the ITI classifier is obtained by the frequency of examples at the leaf node from which the classification came  A different family of possible classifiers is k Nearest Neighbors  kNN   Cover   Hart         In order to use kNN  we need a distance metric between examples  which  with our features  are simply states  As with our choice of features  we opt for simplicity and use Euclidean distance as our metric  kNN enjoys very fast learning time but suffers from slow classification time  The classification confidence is obtained by a simple  unweighted  vote between the k nearest neighbors  Another question related to the choice of classifier is feature selection  In some planning tasks  the number of variables  and accordingly  features  can be over       for example  task    of the AIRPORT domain has      variables   While the performance of Naive Bayes and kNN can likely be improved using feature selection  doing so poses a problem when the initial sample is considered  Since feature selection will have to be done right after the initial sample is obtained  it will have to be based only on the initial sample  This could cause a problem since some features might appear to be irrelevant according to the initial sample  yet turn out to be very relevant when active learning is used after some low confidence states are encountered  Therefore  we do not use feature selection in our empirical evaluation of selective max      Extension to Multiple Heuristics To this point  we have discussed how to choose which heuristic to compute for each state when there are only two heuristics to choose from  When given more than two heuristics  the decision rule presented in Section   is inapplicable  and extending it to handle more than two heuristics is not straightforward  However  extending selective max to use more than two heuristics is straightforward  simply compare heuristics in a pair wise manner  and use a voting rule to choose which heuristic to compute  While there are many possible such voting rules  we go with the simplest one  which compares every pair of heuristics  and chooses the winner by a vote  weighted by the confidence for each pairwise decision  The overall winner is simply the heuristic which has the highest total confidence from all pairwise comparisons  with ties broken in favor of the cheaper to compute heuristic  Although this requires a quadratic number of classifiers  training and classification time  at least with Naive Bayes  appear to be much lower than the overall time spent on heuristic computations  and thus the overhead induced by learning and classification is likely to remain relatively low for reasonable heuristic ensembles      Experimental Evaluation To evaluate selective max empirically  we implemented it on top of the open source Fast Downward planner  Helmert         Our empirical evaluation is divided into three parts  First  we examine the performance of selective max using the last International Planning Competition  IPC       as our benchmark  Selective max was the runner up ex aequo at IPC       tying for  nd place with a version of Fast Downward using an abstraction merge and shrink heuristic  Nissim  Hoffmann    Helmert         and losing to a sequential portfolio combining the heuristics used in both runners up  Helmert  Roger    Karpas         Second  we present a series of controlled parametric experiments  where we examine the behavior of selective max under different settings  Finally  we       O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  Parameter   N Sampling method Classifier  Default value            Biased probes Naive Bayes  Meaning heuristic difference bias confidence threshold initial sample size state space sampling method classifier type  Table    Parameters for the selmax entry in IPC       compare selective max to a simulated sequential portfolio  using the same heuristics as selective max      Performance Evaluation  Results from IPC      The IPC      experiments  Garca Olaya et al         were run by the IPC organizers  on their own machines  with a time limit of    minutes and a memory limit of   GB per planning task  The competition included some new domains  which none of the participants had seen before  thus precluding the participants from using offline learning approaches  Although many planners participated in the sequential optimal track of IPC       we report here only the results relevant to selective max  The selective max entry in IPC      was called selmax  and consisted of selective max over the uniform action cost partitioning version of hLA  Karpas   Domshlak        and hLM CUT  Helmert   Domshlak        heuristics  The parameters used for selective max in IPC      are reported in Table    Additionally  each of the heuristics selmax used was entered individually as BJOLP  hLA   and lmcut  hLM CUT    and we report results for all three planners  While a comparison of selective max with the regular maximum of hLA and hLM CUT would be interesting  there was no such entry at IPC       and thus we can not report on it  In our controlled experiments  we do compare selective max to the regular maximum  as well as to other baseline combination methods  Figure   shows the anytime profile of these three planners on IPC      tasks  plotting the number of tasks solved under different timeouts  up to the time limit of    minutes  Additionally  Table   shows the number of tasks solved in each domain of IPC       after    minutes  and includes the number of problems solved by the winner  Fast Downward Stone Soup    FDSS     for reference  As these results show  selective max solves more problems than each of the individual heuristics it uses  Furthermore  the anytime profile of selective max dominates each of these heuristics  in the range between     seconds until the full    minute timeout  The behavior of the anytime plot with shorter timeouts is due to the overhead of selective max  which consists of obtaining the initial statespace sample  as well as learning and classification  However  it appears that selective max quickly compensates for its relatively slow start      Controlled Experiments In our series of controlled experiments  we attempted to evaluate the impact of different parameters on selective max  We controlled the following independent variables   Heuristics  We used three state of the art admissible heuristics  hLA  Karpas   Domshlak         hLM CUT  Helmert   Domshlak         and hLM CUT   Bonet   Helmert         None       D OMSHLAK   K ARPAS     M ARKOVITCH       Solved Instances                     BJOLP lmcut selmax                                Timeout  seconds                           Figure    IPC      anytime performance  Each line shows the number of problems from IPC      solved by the BJOLP  lmcut  and selmax planners  respectively  under different timeouts  Domain barman elevators floortile nomystery openstacks parcprinter parking pegsol scanalyzer sokoban tidybot transport visitall woodworking TOTAL  BJOLP                                          lmcut                                            selmax                                            FDSS                                              Table    Number of planning tasks solved at IPC      in each domain by the BJOLP  lmcut  and selmax planners  The best result from these   planners is in bold  The number of problems solved by Fast Downward Stone Soup    FDSS    in each domain is also included for reference         O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  of these base heuristics yields better search performance than the others across all planning domains  Of these heuristics  hLA is typically the fastest to compute and the least accurate  hLM CUT is more expensive to compute and more accurate  and hLM CUT  is the most expensive to compute and the most accurate   From the data we have gathered in these experiments  hLM CUT takes on average     more time per state than hLA   and hLM CUT  takes    more time per state than hLA   We evaluate selective max with all possible subsets of two or more of these three heuristics  While there are other admissible heuristics for SAS  planning that are competitive with the three above  for example  Helmert  Haslum    Hoffmann        Nissim et al         Katz   Domshlak         they are based on expensive offline preprocessing  followed by very fast online per state computation  In contrast  hLA   hLM CUT and hLM CUT  perform most of their computation online  and thus can be better exploited by selective max  Additionally  we empirically examine the effectiveness of selective max in deciding whether to compute a heuristic value at all  This is done by combining our most accurate heuristic  hLM CUT    with the blind heuristic   Heuristic difference bias   The hyper parameter  controls the tradeoff between computation time and heuristic accuracy  Setting      sets the threshold  to    forcing the decision rule to always choose the more accurate heuristic  Increasing  increases the threshold  forcing the decision rule to choose the more accurate heuristic h  only if its value is much higher than that of h    We evaluate selective max with values for  of                            and     Confidence threshold   The confidence threshold  controls the active learning part of selective max  Setting        turns off active learning completely  because the chosen heuristic always comes with a confidence of at least      Setting      would mean using active learning almost always  essentially reducing selective max to regular point wise maximization  We evaluate selective max with values for  of                           and        Initial sample size N   The initial sample size N is an important parameter  not just because it is used to train the initial classifier before any active learning is done  but also because it is the only source of estimates for branching factor  average action cost  and heuristic computation times  It thus affects the threshold    Increasing N increases the accuracy of the initial classifier and of the various aforementioned estimates  but also increases the preprocessing time  We evaluate selective max with values for N of          and        Sampling method  The sampling method used to obtain the initial state space sample is important in that it affects this initial sample  and thus the accuracy of both the threshold  and of the initial classifier  We evaluate selective max with three different sampling methods  all P described in Section      biased probes  selPh    unbiased probes  selU h    and the sampling method of Haslum et al          selPDB h     Classifier  The choice of classifier is also very important  The Naive Bayes classifier comB bines very fast learning and classification  selN h    A more sophisticated variant of Naive Bayes called AODE  Webb et al         is also considered here  selAODE    AODE is more h    Of course  all three heuristics are computable in polynomial time from the SAS  description of the planning task         D OMSHLAK   K ARPAS     M ARKOVITCH  Parameter Heuristics   N Sampling method Classifier  Default value hLA   hLM CUT           PDB  Haslum et al         Naive Bayes  Meaning heuristics used heuristic difference bias confidence threshold initial sample size state space sampling method classifier type  Table    Default parameters for selh   accurate than Naive Bayes  but has higher classification and learning times  as well as increased memory overhead  Another possible choice is using incremental decision trees  Utgoff et al          which offer even faster classification  but more expensive learning when the I tree structure needs to be changed  selIT h    We also consider kNN classifiers  Cover   Hart         which offer faster learning than Naive Bayes  but usually more expensive classificaN tion  especially as k grows larger  selkN   for k          h Table   describes our default values for each of these independent variables  In each of the subsequent experiments  we vary one of these independent variables  keeping the rest at their default values  In all of these experiments  the search for each planning task instance was limited to    minutes  and to   GB of memory  The search times do not include the time needed for translating the planning task from PDDL to SAS  and building some of the Fast Downward data structures  which is common to all planners  and is tangential to the issues considered in our study  The search times do include learning and classification time for selective max   Heuristics We begin by varying the set of heuristics in use  For every possible choice of two or more heuristics out of the uniform action cost partitioning version of hLA  which we simply refer to as hLA    hLM CUT and hLM CUT    we compare selective max to other methods of heuristic combination  as well as to the individual heuristics  We compare selective max  selh   to the regular maximum  maxh    as well as to a planner which chooses which heuristic to compute at each state randomly  rndh    As it is not clear whether the random choice should favor the more expensive and accurate heuristic or the cheaper and less accurate one  we simply use a uniform random choice  This experiment was conducted on all    domains with no conditional effects and axioms  which none of the heuristics we used support  from the International Planning Competitions           Because domains vary in difficulty and in the number of tasks  we normalize the score for each planner in each domain between   and    Normalizing by the number of problems in the domain is not a good idea  as it is always possible to generate any number of effectively unsolvable problems in each domain  so that the fraction of solved problems will approach zero  Therefore  we normalize the number of problems solved in each domain by the number of problems in that domain that were solved by at least one of our planners  While this measure of normalized coverage has the undesirable property that introducing a    Each search was given a single core of a  GHz Intel E     CPU machine         O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  Heuristic  hLA  hLM CUT  hLM CUT   High variance unit cost Low variance unit cost Non uniform cost                                                                                                        TOTAL                                       a  Individual Heuristics Domains High variance unit cost Low variance unit cost Non uniform cost TOTAL  maxh                                              rndh                                              selh                                              hLA   hLM CUT   High variance unit cost Low variance unit cost Non uniform cost TOTAL                                                                                                                                         hLM CUT   hLM CUT   High variance unit cost Low variance unit cost Non uniform cost TOTAL                                                                                                                                         hLA   hLM CUT   hLM CUT   High variance unit cost Low variance unit cost Non uniform cost TOTAL                                                                                                                                         Heuristics hLA   hLM CUT   b  Combinations of two or more heuristics  Table    Average normalized coverage  and total coverage in parentheses  broken down by groups of domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  Table  a  shows the results for A with individual heuristics  and table  b  shows the results for the maximum  maxh    random choice  rndh    and selective max  selh   combinations of the set of heuristics listed in each major row   new planner could change the normalized coverage of the other planners  we believe that it best reflects performance nonetheless  As an overall performance measure  we list the average normalized coverage score across all domains  Using normalized coverage means that domains have equal weight in the aggregate score  Additionally  we list for each domain the number of problems that were solved by any planner  in parentheses next to the domain name   and for each planner we list the number of problems it solved in parentheses  Tables   and   summarize the results of this experiment  We divided the domains in our experiment into   sets  domains with non uniform action costs  domains with unit action costs which exhibited a high variance in the number of problems solved between different       D OMSHLAK   K ARPAS     M ARKOVITCH  Heuristics  Domains  hLA  hLM CUT  hLA   hLM CUT  High variance unit cost Low variance unit cost Non uniform cost TOTAL                                           hLA   hLM CUT   High variance unit cost Low variance unit cost Non uniform cost TOTAL                        hLM CUT   hLM CUT   High variance unit cost Low variance unit cost Non uniform cost TOTAL  hLA   hLM CUT   hLM CUT   hLM CUT   maxh  rndh  selh                                                                                                                                                                                                                                             High variance unit cost Low variance unit cost Non uniform cost                                                                                              TOTAL                                    Table    Geometric mean of ratio of expansions relative to maxh   broken down by groups of domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs   planners  and domains with unit action costs which exhibited a low variance in the number of problems solved between different planners  We make this distinction because we conducted the following experiments  which examine the effects of the other parameters of selective max  only on the unit cost action domains which exhibited high variance  Tables   and   summarize the results for these three sets of domains  as well as for all domains combined  Detailed  per domain results are relegated to Appendix A  Table   lists the normalized coverage score  averaged across all domains  and the total number of problems solved in parentheses  Table  a lists these for each individual heuristic  and Table  b for every combination method of every set of two or more heuristics  Table   shows how accurate each of these heuristic combination methods is  Since  for a given set of base heuristics  maxh is the most accurate heuristic possible  the accuracy is evaluated relative to maxh   We evaluate each heuristics accuracy on each task as the number of states expanded by A using that heuristic  divided by the number of states expanded by A using maxh   We compute the geometric mean for each domain over the tasks solved by all planners of this accuracy ratio  and list here the geometric mean over these numbers  Each row lists the results for a combination of two or three heuristics  for combinations of two heuristics  we leave the cell representing the heuristic that is not in the combination empty  Looking at the results of individual heuristics first  we see that the most accurate heuristic  hLM CUT    does not do well overall  while the least accurate heuristic  hLA   solved the most tasks in total  and hLM CUT wins in terms of normalized coverage  However  when looking at the results for individual domains  we see that the best heuristic to use varies  indicating that combining different heuristics could indeed be of practical value  We now turn our attention to the empirical results for the combinations of all possible subsets of two or more heuristics  The results clearly demonstrate that when more than one heuristic is used  selective max is always better than regular maximum or random choice  both in terms of normalized coverage and absolute number of problems solved  Furthermore  the poor performance of rndh   in both coverage and accuracy  demonstrates that the decision rule and       O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING            Solved Instances                          maxh       rndh selh                              Timeout  seconds                           Figure    hLA   hLM CUT   hLM CUT  anytime profile  Each line shows the number of problems from IPC            solved by the maximum  maxh    random choice  rndh    and selective max  selh   combination methods of the hLA   hLM CUT   and hLM CUT  heuristics  under different timeouts   the classifier used in selective max are important to its success  and that computing only one heuristic at each state randomly is insufficient  to say the least  When compared to individual heuristics  selective max does at least as well as each of the individual heuristics it uses  for all combinations except that of hLM CUT and hLM CUT    This is most likely because hLM CUT and hLM CUT  are based on a very similar procedure  and thus their heuristic estimates are highly correlated  To see why this hinders selective max  consider the extreme case of two heuristics which have a correlation of      that is  yield the same heuristic values   where selective max can offer no benefit  Finally  we remark that the best planner in this experiment was the selective max combination of hLA and hLM CUT   The above results are all based on a    minute time limit  which  while commonly used in the IPC  is arbitrary  and the number of tasks solved after    minutes does not tell the complete tale  Here  we examine the anytime profile of the different heuristic combination methods  by plotting the number of tasks solved under different timeouts  up to a timeout of    minutes  Figure   shows this plot for the three combination methods when all three heuristics are used  As the figure shows  the advantage of selh over the baseline combination methods is even greater under shorter timeouts  This indicates that the advantage of selh over maxh is even       D OMSHLAK   K ARPAS     M ARKOVITCH  Heuristics hLA   hLM CUT  Overhead      hLA   hLM CUT        hLM CUT   hLM CUT       hLA   hLM CUT   hLM CUT        Table    Selective max overhead  Each row lists the average percentage of time spent on learning and classification  out of the total time taken by selective max  for each set of heuristics   greater than is evident from the results after    minutes  and that selh is indeed effective for minimizing search time  Since the anytime plots for the combinations of pairs of heuristics are very similar  we omit them here for the sake of brevity  Finally  we present overhead statistics for using selective max  the proportion of time spent on learning and classification  including the time spent obtaining the initial state space sample  out of the total solution time  Table   presents the average overhead on selective max for each of the combinations of two or more heuristics  Detailed  per domain results are presented in Table    in Appendix A  As these results show  selective max does incur a noticeable overhead  but it is still relatively low  It is also worth mentioning that the overhead varies significantly between different domains  We also performed an empirical evaluation of using selective max with an accurate heuristic alongside the blind heuristic  The blind heuristic returns   for goal states  and the cost of the cheapest action for non goal states  For this experiment  we chose our most accurate heuristic  hLM CUT    We compare the performance of A using hLM CUT  alone  to that of A using selective max of hLM CUT  and the blind heuristic  Because the blind heuristic returns a constant value for all non goal states  the decision rule that selective max uses to combine some heuristic h with the blind heuristic hb is simply h s      hb   that is  compute h when the predicted value of h is greater than some constant threshold  Recall that  when h s    g s    c   computing h is simply a waste of time  because s will not be pruned  Therefore  it only makes sense to compute h s  when h s   c  g s   Note that this threshold for computing h depends on g s   and thus is not constant  This shows that a constant threshold for computing h s  is not the best possible decision rule  Unfortunately  the selective max decision rule is based on an approximation that fails to capture the subtleties of this case  Table   shows the normalized coverage of A using hLM CUT    and A using selective max of hLM CUT  and the blind heuristic  As the results show  selective max has little effect in most domains  though it does harm performance in some  and in one domain  OPENSTACKS  it actually performs better than the single heuristic  Table   shows the average expansions ratio  using the number of states expanded by hLM CUT  as the baseline  note that using the blind heuristic never increases heuristic accuracy  As these results show  selective max chooses to use the blind heuristic quite often  expanding on average more than twice as many states than A with hLM CUT  alone        O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  coverage  hLM CUT   selh  airport      freecell      logistics        mprime      mystery      pipesworld tankage     satellite     zenotravel                                                                                                                                                                     blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                      elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                         TOTAL                          Table    Normalized coverage of hLM CUT  and selective max combining hLM CUT  with the blind heuristic  Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively         D OMSHLAK   K ARPAS     M ARKOVITCH  expansions  hLM CUT   selh  airport      freecell      logistics        mprime      mystery      pipesworld tankage     satellite     zenotravel                                                                               blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                             elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                  GEOMETRIC MEAN            Table    Average ratio of expanded states between the baseline of hLM CUT  and selective max combining hLM CUT  with the blind heuristic  Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively         O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  The above experiments have varied the heuristics which selective max uses  In the following experiments  we fix the set of heuristics  and examine the impact of the other parameters of selective max on performance  As we still need to evaluate over    different configurations of selective max  we will focus on eight selected domains  AIRPORT  FREECELL  LOGISTICS     MPRIME  MYS TERY   PIPESWORLD   TANKAGE  SATELLITE   and ZENOTRAVEL  These are the eight domains with the highest observed variance in the number of tasks solved across different planners  out of the unit action cost domains we used  These domains were chosen in order to reduce the computation time required for these experiments to a manageable quantity  We excluded domains with non uniform action costs  because they use a different method of estimating the goal depth for the state space sampling method  which is one of the parameters we examine  Below  we focus on one parameter of selective max at a time  and present the total number of tasks solved in our eight chosen domains  under different values of that parameter  Detailed  per domain results for each parameter appear in Appendix A   hyper parameter  Figure  a plots the total number of problems solved  under different values of   As these results show  selective max is fairly robust with respect to the value of   unless a very large value for  is chosen  making it more difficult for selective max to choose the more accurate heuristic  Detailed  per domain results appear in Table    in Appendix A  as well as in Figure    These results show a more complex picture  where there seems to be some cutoff value for each domain  such that increasing  past that value impairs performance  The one exception to this is the PIPESWORLD   TANKAGE domain  where setting      helps   confidence threshold  Figure  b plots the total number of problems solved  under different values of   Detailed  per domain results appear in Table    in Appendix A  These results indicate that selective max is also robust to values of   unless it is set to a very low value  causing selective max to behave like the regular point wise maximum   initial sample size N Figure  c plots the total number of problems solved under different values of N   with the x axis in logscale  Detailed  per domain results appear in Table    in Appendix A  As the results show  our default value of N       is the best  of the three values we tried   although selective max is still fairly robust with respect to the choice of parameter   sampling method Figure   shows the total number of problems solved using different methods for the initial state space sampling  Detailed  per domain results appear in Table    in Appendix A  As the results demonstrate  the choice of sampling method can notably affect the performance of selective max  However  as the detailed results show  this effect is only evident in the FREE CELL domain  We also remark that our default sampling method  PDB  performs worse than the others  Indeed by using the probe based sampling methods  selective max outperforms A using hLA alone  However  as this difference is only due to the FREECELL domain  we can not state with certainty that this would generalize across all domains        Solved Instances  D OMSHLAK   K ARPAS     M ARKOVITCH                                                                                           Solved Instances   a  Hyper parameter                                                         Solved Instances   b  Confidence threshold                                        c  Initial Sample Size N Figure    Number of problems solved by selective max under different values for  a  hyperparameter   b  confidence threshold   and  c  initial sample size N          Solved Instances  O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING                                airport freecell logistics   mprime mystery pw tankage satellite zenotravel                     Figure    Number of problems solved by selective in each domain under different values for             Solved Instances                             PDB      Probe     Sampling Method  UnbiasedProbe      Figure    Number of problems solved by selective max with different sampling methods         D OMSHLAK   K ARPAS     M ARKOVITCH           Solved Instances                            NB      AODE      ITI     Classifier   NN       NN      Figure    Number of problems solved by selective max with different classifiers   classifier Figure   shows the total number of problems solved using different classifiers  Detailed  per domain results appear in Table    in Appendix A  Naive Bayes appears to be the best classifier to use with selective max  although AODE also performs quite well  Even though kNN enjoys very fast learning  the classifier is used mostly for classification  and as expected  kNN does not do well  However  the increased accuracy of k     seems to pay off against the faster classification when k          Comparison with Sequential Portfolios Sequential portfolio solvers for optimal planning are another approach for exploiting the merits of different heuristic functions  and they have been very successful in practice  with the Fast Downward Stone Soup sequential portfolio  Helmert et al         winning the sequential optimal track at IPC      A sequential portfolio utilizes different solvers by running them sequentially  each with a prespecified time limit  If one solver fails to find a solution under its allotted time limit  the sequential portfolio terminates it  and moves on to the next solver  However  a sequential portfolio solver needs to know the time allowance for the problem it is trying to solve beforehand  a setting known as contract anytime  Russell   Zilberstein         In contrast  selective max can be used in an interruptible anytime manner  where the time limit need not be known in advance  Here  we compare selective max to sequential portfolios of A with the same heuristics  As we have the exact time it took A search using each heuristic alone to solve each problem  we can determine whether a sequential portfolio which assigns each heuristic some time limit will be able to solve each problem  Using this data  we simulate the results of two types of sequential portfolio planners  In the first setting  we assume that the time limit is known in advance  and simulate the results of a contract portfolio giving an equal share of time to all heuristics  In the second setting  we simulate an interruptible anytime portfolio by using binary exponential backoff time limits  starting                          Solved Instances  Solved Instances  O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING               selh portctr                    selh portctr       portint  portint                                                      Timeout  seconds                                         selh portctr                                        Timeout  seconds   hLA   hLM CUT   b   Solved Instances  Solved Instances  hLA   hLM CUT  a                     selh portctr       portint  portint                                                      Timeout  seconds        hLM CUT   hLM CUT   c                                         Timeout  seconds   hLA   hLM CUT   hLM CUT   d   Figure    Anytime profiles of sequential portfolios and selective max  Each plot shows the number of problems solved by selective max  selh    a simulated contract anytime portfolio  portctr    and a simulated interruptible portfolio  portint   using  a  hLA and hLM CUT  b  hLA and hLM CUT   c  hLM CUT and hLM CUT    and  d  hLA   hLM CUT   and hLM CUT     with a time limit of   second for each heuristic  we increase the time limit by a factor of   if none of the heuristics were able to guide A to solve the planning problem  There are several possible orderings for the heuristics here  and we use the de facto best ordering for each problem  We denote the contract anytime portfolio by portctr   and the interruptible anytime portfolio by portint   Figure   shows the number of problems solved under different time limits for selective max  the contract anytime sequential portfolio  and the interruptible anytime sequential portfolio  As these results show  the contract anytime sequential portfolio almost always outperforms selective max  On the other hand  when the sequential portfolio does not know the time limit in advance  its performance deteriorates significantly  The best heuristic combination for selective max  hLA and hLM CUT   outperforms the interruptible anytime portfolio using the same heuristics  and so does the       D OMSHLAK   K ARPAS     M ARKOVITCH  selective max combination of hLM CUT and hLM CUT    With the other combinations of heuristics  the interruptible anytime portfolio performs better than selective max      Discussion Learning for planning has been a very active field since the early days of planning  Fikes  Hart    Nilsson         and is recently receiving growing attention in the community  However  despite some early work  Rendell         relatively little work has dealt with learning for state space search guided by distance estimating heuristics  one of the most prominent approaches to planning these days  Most works in this direction have been devoted to learning macro actions  see  for example  Finkelstein   Markovitch        Botea  Enzenberger  Muller    Schaeffer        Coles   Smith         Recently  learning for heuristic search planning has received more attention  Yoon et al         suggested learning  inadmissible  heuristic functions based upon features extracted from relaxed plans  Arfaee  Zilles  and Holte        attempted to learn an almost admissible heuristic estimate using a neural network  Perhaps the most closely related work to ours is that of Thayer  Dionne  and Ruml         who learn to correct errors in heuristic estimates online  Thayer et al  attempt to improve the accuracy of a single given heuristic  while selective max attempts to choose one of several given heuristics for each state  The two works differ technically on this point  More importantly  however  none of the aforementioned approaches can guarantee that the resulting heuristic will be admissible  and thus that an optimal solution will be found  In contrast  our focus is on optimal planning  and we are not aware of any previous work that deals with learning for optimal heuristic search  Our experimental evaluation demonstrates that selective max is a more effective method for combining arbitrary admissible heuristics than the baseline point wise maximization  Also advantageous is selective maxs ability to exploit pairs of heuristics  where one is guaranteed to always be at least as accurate as the other  For example  the hLA heuristic can be used with two action cost partitioning schemes  uniform and optimal  Karpas   Domshlak         The heuristic induced by the optimal action cost partitioning is at least as accurate the one induced by the uniform action cost partitioning  but takes much longer to compute  Selective max might be used to learn when it is worth spending the extra time to compute the optimal cost partitioning  and when it is not  In contrast  the max based combination of these two heuristics would simply waste the time spent on computing the uniform action cost partitioning  The controlled parametric experiments demonstrate that the right choice of classifier and of the sampling method for the initial state space sample is very important  The other parameters of selective max do not appear to affect performance too much  as long as they are set to reasonable values  This implies that selective max could be improved by using faster  more accurate  classifiers  and by developing sampling methods that can represent the state space well  Finally  we remark that the Fast Downward Autotune entry in the sequential optimal track of the      edition of the International Planning Competition  which used ParamILS  Hutter  Hoos  Leyton Brown    Stutzle        to choose the best configuration for the Fast Downward planner  chose to use selective max to combine hLM CUT and hmax  Bonet  Loerincs    Geffner         This provides further evidence that selective max is a practically valuable method for combining heuristics in optimal planning        O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  coverage  hLA  hLM CUT  hLM CUT   airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel                                                                                                                                                                                                                                                      blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                                                                                                                        elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                                                                         TOTAL                                      Table    Detailed per domain results of A with each individual heuristic  Normalized coverage is shown  with the number of problems solved shown in parentheses  Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively   Acknowledgments The work was partly supported by the Israel Science Foundation  ISF  grant           Appendix A  Detailed Results of Empirical Evaluation In this appendix  we present detailed per domain  results of the experiments described in Section    Table   shows the normalized coverage and number of problems solved in each domain  for individual heuristics  The normalized coverage score of planner X on domain D is the number of problems from domain D solved by planner X  divided by the number of problems from domain D solved by at least one planner  Tables        give the results for combinations of two or more heuristics  Tables             and    list the normalized coverage of the individual heuristics used  and of their combination using selective max  selh    regular maximum  maxh    and random choice of heuristic at each state  rndh   after    minutes  Tables             and    give the geometric mean of the ratio of expanded states relative to maxh in each domain  over problems solved by all configurations  The number of tasks solved by all planners is listed in parentheses next to each domain  The final row gives the geometric mean over the geometric means of each domain        D OMSHLAK   K ARPAS     M ARKOVITCH  coverage  hLA  hLM CUT  maxh  rndh  selh  airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel                                                                                                                                                                                                                                                                                                                                                                                                                       blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                                                                                                                                                                                                                                          TOTAL                                                              Table     Detailed per domain normalized coverage using hLA and hLM CUT   Each line shows the normalized coverage in each domain  with the number of problems solved is shown in parentheses  Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively         O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  expansions  hLA  hLM CUT  maxh  rndh  selh  airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite     zenotravel                                                                                                                                                                                                       blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                                    elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips     sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                           GEOMETRIC MEAN                              Table     Detailed per domain expansions relative to maxh using hLA and hLM CUT   Each row shows the geometric mean of the ratio of expanded nodes relative to maxh   Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively         D OMSHLAK   K ARPAS     M ARKOVITCH  coverage  hLA  hLM CUT   maxh  rndh  selh  airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel                                                                                                                                                                                                                                                                                                                                                                                                                   blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                                                                                                                                                                                                                                          TOTAL                                                              Table     Detailed per domain normalized coverage using hLA and hLM CUT    Each line shows the normalized coverage in each domain  with the number of problems solved is shown in parentheses  Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively         O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  expansions  hLA  hLM CUT   maxh  rndh  selh  airport      freecell      logistics        mprime      mystery      pipesworld tankage     satellite     zenotravel                                                                                                                                                                                                      blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                                     elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips     sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                        GEOMETRIC MEAN                              Table     Detailed per domain expansions relative to maxh using hLA and hLM CUT    Each row shows the geometric mean of the ratio of expanded nodes relative to maxh   Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively         D OMSHLAK   K ARPAS     M ARKOVITCH  coverage  hLM CUT  hLM CUT   maxh  rndh  selh  airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel                                                                                                                                                                                                                                                                                                                                                                                                                   blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                                                                                                                                                                                                                                            TOTAL                                                              Table     Detailed per domain normalized coverage using hLM CUT and hLM CUT    Each line shows the normalized coverage in each domain  with the number of problems solved is shown in parentheses  Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively         O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  expansions  hLM CUT  hLM CUT   maxh  rndh  selh  airport      freecell      logistics        mprime      mystery      pipesworld tankage     satellite     zenotravel                                                                                                                                                                                                   blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                               elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                    GEOMETRIC MEAN                              Table     Detailed per domain expansions relative to maxh using hLM CUT and hLM CUT    Each row shows the geometric mean of the ratio of expanded nodes relative to maxh   Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively         D OMSHLAK   K ARPAS     M ARKOVITCH  coverage  hLA  hLM CUT  hLM CUT   maxh  rndh  selh  airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           TOTAL                                                                          Table     Detailed per domain normalized coverage using hLA   hLM CUT and hLM CUT    Each line shows the normalized coverage in each domain  with the number of problems solved is shown in parentheses  Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively         O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  expansions  hLA  hLM CUT  hLM CUT   maxh  rndh  selh  airport      freecell      logistics        mprime      mystery      pipesworld tankage     satellite     zenotravel                                                                                                                                                                                                                                                 blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                                                                                                                  elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips     sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                                                                 GEOMETRIC MEAN                                    Table     Detailed per domain expansions relative to maxh using hLA   hLM CUT and hLM CUT    Each row shows the geometric mean of the ratio of expanded nodes relative to maxh   Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with nonuniform action costs  respectively         D OMSHLAK   K ARPAS     M ARKOVITCH  overhead  hLA  hLM CUT  hLA  hLM CUT   hLM CUT  hLM CUT   All Three  airport      freecell      logistics        mprime      mystery      pipesworld tankage     satellite     zenotravel      blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips     elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                                                                                                                                                                                                                                                                       AVERAGE                     Table     Selective max overhead  Each row lists the average percentage of time spent on learning and classification  out of the total time taken by selective max  in each domain  for each set of heuristics  Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively         O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  coverage airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel      SUM  sel     h                             sel     h                             sel   h                             sel     h                             sel   h                             sel   h                             sel   h                             sel   h                             Table     Number of problems solved by selective max in each domain with varying values of hyper parameter   coverage airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel      SUM  sel      h                             sel     h                             sel     h                             sel     h                             sel     h                             sel      h                             Table     Number of problems solved by selective max in each domain with varying values of confidence threshold   Table    lists the average overhead of selective max in each domain  for each combination of two or more heuristics  Tables                and    list the number of problems solved in each domain  under various values for     N   sampling method and classifier  respectively   coverage airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel      SUM      selN h                                  selN h                                   selN h                             Table     Number of problems solved by selective max in each domain with varying values of initial Sample Size N        D OMSHLAK   K ARPAS     M ARKOVITCH  coverage airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel      SUM  selPDB h                             selP h                             P selU h                             Table     Number of problems solved by selective max in each domain with different sampling methods  PDB is the sampling method of Haslum et al          P is the biased probes sampling method  and U P is the unbiased probes sampling method   coverage airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel      SUM  B selN h                             selAODE h                             I selIT h                             N sel N h                             N sel N h                             Table     Number of problems solved by selective max in each domain with different classifiers        O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  coverage  selh  portint  portctr  airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel                                                                                                                                                                                                                                                       blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                                                                                                                         elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                                                                          TOTAL                                      Table     Detailed coverage of portfolio using hLA   hLM CUT   Number of problems solved by selective max  selh    a simulated interruptible portfolio  portint    and a simulated contract anytime portfolio  portctr   in each domain using heuristics hLA   hLM CUT   Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively         D OMSHLAK   K ARPAS     M ARKOVITCH  coverage  selh  portint  portctr  airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel                                                                                                                                                                                                                                                       blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                                                                                                                       elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                                                                          TOTAL                                      Table     Detailed coverage of portfolio using hLA   hLM CUT    Number of problems solved by selective max  selh    a simulated interruptible portfolio  portint    and a simulated contract anytime portfolio  portctr   in each domain using heuristics hLA   hLM CUT    Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively         O NLINE S PEEDUP L EARNING FOR O PTIMAL P LANNING  coverage  selh  portint  portctr  airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel                                                                                                                                                                                                                                                     blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                                                                                                                         elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                                                                          TOTAL                                      Table     Detailed coverage of portfolio using hLM CUT   hLM CUT    Number of problems solved by selective max  selh    a simulated interruptible portfolio  portint    and a simulated contract anytime portfolio  portctr   in each domain using heuristics hLM CUT   hLM CUT    Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with nonuniform action costs  respectively         D OMSHLAK   K ARPAS     M ARKOVITCH  coverage  selh  portint  portctr  airport      freecell      logistics        mprime      mystery      pipesworld tankage      satellite      zenotravel                                                                                                                                                                                                                                                       blocks      depot     driverlog      grid     gripper     logistics       miconic       pathways     pipesworld notankage      psr small      rovers     schedule      storage      tpp     trucks strips                                                                                                                                                                                                                                                                                                                                                                                                                                                        elevators opt   strips      openstacks opt   strips      parcprinter    strips      pegsol    strips      scanalyzer    strips      sokoban opt   strips      transport opt   strips      woodworking opt   strips                                                                                                                                                                                                                                                          TOTAL                                      Table     Detailed coverage of portfolio using hLA   hLM CUT   hLM CUT    Number of problems solved by selective max  selh    a simulated interruptible portfolio  portint    and a simulated contract anytime portfolio  portctr   in each domain using heuristics hLA   hLM CUT   hLM CUT    Domains are grouped into domains with unit cost actions and high variance in coverage  domains with unit cost actions and low variance in coverage  and domains with non uniform action costs  respectively   Tables            and    list the normalized coverage in each domain for selective max  and for the simulated contract and interruptible sequential portfolios   
