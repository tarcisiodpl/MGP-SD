 Standard models of multi agent modal logic do not capture the fact that information is often ambiguous  and may be interpreted in different ways by different agents  We propose a framework that can model this  and consider different semantics that capture different assumptions about the agents beliefs regarding whether or not there is ambiguity  We examine the expressive power of logics of ambiguity compared to logics that cannot model ambiguity  with respect to the different semantics that we propose     Introduction In the study of multi agent modal logics  it is implicitly assumed that all agents interpret all formulas the same way  While they may have different beliefs regarding whether a formula  is true  they agree on what  means  Formally  this is captured by the fact that the truth of  does not depend on the agent  Of course  in the real world  there is ambiguity  different agents may interpret the same utterance in different ways  For example  consider a public announcement p  Each player i may interpret p as corresponding to some event Ei   where Ei may be different from Ej if i    j  This seems natural  even if people have a common background  they may still disagree on how     to interpret certain phenomena or new information  Someone may interpret a smile as just a sign of friendliness  someone else may interpret it as a false smile  concealing contempt  yet another person may interpret it as a sign of sexual interest  To model this formally  we can use a straightforward approach already used in  Halpern       Grove and Halpern        formulas are interpreted relative to a player  But once we allow such ambiguity  further subtleties arise  Returning to the announcement p  not only can it be interpreted differently by different players  it may not even occur to the players that others may interpret the announcement in a different way  Thus  for example  i may believe that Ei is common knowledge  The assumption that each player believes that her interpretation is how everyone interprets the announcement is but one assumption we can make about ambiguity  It is also possible that player i may be aware that there is more than one interpretation of p  but believes that player j is aware of only one interpretation  For example  think of a politician making an ambiguous statement which he realizes that different constituencies will interpret differently  but will not realize that there are other possible interpretations  In this paper  we investigate a number of different semantics of ambiguity that correspond to some standard assumptions that people make with regard to ambiguous statements  and investigate their relationship  Our interest in ambiguity was originally motivated by a seminal result in game theory  Aumanns        theorem showing that players cannot agree to disagree  More precisely  this theorem says that agents with a common prior on a state space cannot have common knowledge that they have different posteriors  This result has been viewed as paradoxical in the economics literature  Trade in a stock market seems to require common knowledge of disagreement  about the value of the stock being traded   yet we clearly observe a great deal of trading  One well known explanation for the disagreement is that we do not in fact have common priors  agents start out with different beliefs  In a companion paper  Halpern and Kets        we provide a different explanation  in terms of ambiguity  It is easy to show that we can agree to disagree when there is ambiguity  even if there is a common prior  Although our work is motivated by applications in economics  ambiguity has long been a concern in philosophy  linguistics  and natural language processing  For example  there has been a great deal of work on word sense disambiguation  i e   trying to decide from context which of the multiple meanings of a word are intended   see Hirst        for a seminal contribution  and Navigli        for a recent survey  However  there does not seem to be much work on incorporating ambiguity into a logic  Apart from the literature on the logic of context and on underspecification  see Van Deemter and Peters          the only papers that we are aware of that does this are ones by Monz        and Kuijer         Monz allows for statements that have multiple interpretations  just as we do  But rather than incorporating the ambiguity directly into the logic  he considers updates by ambiguous statements  Kuijer models the fact that ambiguous statements can have multiple meanings by using a nondeterministic propositional logic  which  roughly speaking allows him to consider all the meanings simultaneously  He then defines a notion of implication such that an ambiguous statement A entails another ambiguous statement B if and only if every possible interpreta    tions of A entails every possible interpretation of B  This idea of considering all possible interpretations of an ambiguous statement actually has a long tradition in the philosophy literature  For example  Lewis        considers assigning truth values to an ambiguous formula  by considering all possible disambiguations of   This leads to a semantics where a formula can  for example  have the truth value  true  false   Lewis views this as a potential justification for relevance logic  a logic where a formula can be true  false  both  or neither  cf   Rescher and Brandom         Our approach is somewhat different  We assume that each agent uses only one interpretation of a given ambiguous formula   but an agent may consider it possible that another agent interprets  differently  In our applications  this seems to be the most appropriate way to dealing with ambiguity  especially when it comes to considering the strategic implications of ambiguity   There are also connections between ambiguity and vagueness  Although the two notions are differenta term is vague if it is not clear what its meaning is  and is ambiguous if it can have multiple meanings  Halpern        also used agent dependent interpretations in his model of vagueness  although the issues that arose were quite different from those that concern us here  Given the widespread interest in ambiguity  in this paper we focus on the logic of ambiguity  We introduce the logic in Section    The rest of the paper is devoted to arguing that  in some sense  ambiguity is not necessary  In Section    we show that a formula is satisfiable in a structure with ambiguity  i e   one where different agents interpret formulas differently  if and only if it is satisfiable in a structure without ambiguity  Then in Section    we show that  by extending the language so that we can talk explicitly about how agents interpret formulas  we do not need structures with ambiguity  Despite that  we argue in Section   that we it is useful to be able to model ambiguity directly  rather than indirectly     Syntax and Semantics     Syntax We want a logic where players use a fixed common language  but each player may interpret formulas in the language differently  Although we do not need probability for the points we want to make in this paper  for the applications that we have in mind it is also important for the agents to be able to reason about their probalistic beliefs  Thus  we take as our base logic a propositional logic for reasoning about probability  The syntax of the logic is straightforward  and is  indeed  essentially the syntax already used in papers going back to Fagin and Halpern          There is a finite  nonempty set N               n  of players  and a countable  nonempty set  of primitive propositions  Let LC n    be the set of formulas that can be constructed starting from   and closing off under conjunction  negation  the modal operators  CB G  GN G    and the formation of probability formulas   We omit the  if it is irrelevant or clear from context   Probability formulas are constructed as      follows  If             k are formulas  and a            ak   b  Q  then for i  N  a  pr i                ak pr i  k    b is a probability formula  where pr i    denotes the probability that player i assigns to a formula   Note that this syntax allows for nested probability formulas  We use the abbreviation Bi    for pr i         EB  G  for iG Bi   and EB m    for EB m G EB G  for m               Finally  G we take true to be the abbreviation for a fixed tautology such as p  p       Epistemic probability structures There are standard approaches for interpreting this language  Fagin and Halpern        but they all assume that there is no ambiguity  that is  that all players interpret the primitive propositions the same way  To allow for different interpretations  we use an approach used earlier  Halpern       Grove and Halpern        formulas are interpreted relative to a player  An  epistemic probability  structure  over   has the form M       j  jN    Pj  jN    j  jN    where  is the state space  and for each i  N  i is a partition of   Pi is a function that assigns to each    a probability space Pi       i    Fi    i     and i is an interpretation that associates with each state a truth assignment to the primitive propositions in   That is  i    p    true  false  for all  and each primitive proposition p  Intuitively  i describes player is interpretation of the primitive propositions  Standard models use only a single interpretation   this is equivalent in our framework to assuming that          n   We call a structure where          n a common interpretation structure  we call a structure where i    j for some agents i and j a structure with ambiguity  Denote by   p  i the set of states where i assigns the value true to p  The partitions i are called information partitions  While it is more standard in the philosophy and computer science literature to use models where there is a binary relation Ki on  for each agent i that describes is accessibility relation on states  we follow the common approach in economics of working with information partitions here  as that makes it particularly easy to define a players probabilistic beliefs  Assuming information partitions corresponds to the case that Ki is an equivalence relation  and thus defines a partition   The intuition is that a cell in the partition i is defined by some information that i received  such as signals or observations of the world  Intuitively  agent i receives the same information at each state in a cell of i   Let i    denote the cell of the partition i containing   Finally  the probability space Pi       i    Fi    i    describes the beliefs of player i at state   with i  a probability measure defined on the subspace i  of the state space   The  algebra Fi  consists of the subsets of i  to which i  can assign a probability   If i  is finite  we typically take Fi     i    the set of all subsets of i     The interpretation is that i   E  is the probability that i assigns to event E  Fi  in state   Throughout this paper  we make the following assumptions regarding the probability assignments Pi   i  N      A   For all     i    i     A   For all     if    i     then Pi        Pi     A   For all j  N         i     j      Fi    Furthermore  we make the following joint assumption on players interpretations and information partitions  A   For all     i  N  and primitive proposition p    i       p  i  Fi    These are all standard assumptions  A  says that the set of states to which player i assigns probability at state  is just the set i    of worlds that i considers possible at state   A  says that the probability space used is the same at all the worlds in a cell of player is partition  Intuitively  this says that player i knows his probability space  Informally  A  says that player i can assign a probability to each of js cells  given his information  A  says that primitive propositions  as interpreted by player i  are measurable according to player i       Prior generated beliefs One assumption that we do not necessarily make  but want to examine in this framework  is the common prior assumption  The common prior assumption is an instance of a more general assumption  that beliefs are generated from a prior  which we now define  The intuition is that players start with a prior probability  they then update the prior in light of their information  Player is information is captured by her partition i   Thus  if is prior is i   then we would expect i  to be i     i      Definition     An epistemic probability structure M       j  jN    Pj  jN    j  jN   has prior generated beliefs  generated by  F                  Fn   n    if  for each player i  there exist probability spaces    Fi   i   such that  for all i  j  N and     j     Fi    for all i  N and     Pi       i     Fi   i     i     where Fi   i    is the restriction of Fi to i      and i   E    i  E   i     for all E  Fi   i    if i  i           There are no constraints on i  if i  i            It is easy to check that if M has prior generated beliefs  then M satisfies A   A   and A   More interestingly for our purposes  the converse also holds for a large class of structures  Say that a structure is countably partitioned if for each player i  the information partition i has countably many elements  i e   i is a finite or countably infinite collection of subsets of      Recall that the restriction of Fi to i    is the  algebra  B  i      B  Fi         Proposition     If a structure M has prior generated beliefs  then M satisfies A   A   and A   Moreover  every countably partitioned structure that satisfies A   A   and A  is one with prior generated beliefs  with the priors i satisfying i  i         for each player i  N and state     Proof  The first part is immediate  To prove the second claim  suppose that M is a structure satisfying A A   Let Fi be the unique algebra generated by  Fi    To define i   if there are Ni    cells in the partition i   define i      N i i      Otherwise  if the collection i is countably infinite  order the elements of i as p i   p i          Choose some state k  pki for each k  with associated probability space Pi  k      i k   Fi k   P i k    By A   each choice of k in pki gives the same probability measure i k   Define i   k   k i k   It is easy to see that i is a probability measure on   and that M is generated by  F                  Fn   n    Note that the requirement that that M is countably partitioned is necessary to ensure that we can have i  i         for each player i and state   In light of Proposition      when it is convenient  we will talk of a structure satisfying A A  as being generated by  F                  Fn   n    The common prior assumption discussed in the introduction is essentially just the special case of prior generated beliefs where all the priors are identical       Capturing ambiguity We use epistemic probability structures to give meaning to formulas  Since primitive propositions are interpreted relative to players  we must allow the interpretation of arbitrary formulas to depend on the player as well  Exactly how we do this depends on what further assumptions we make about what players know about each others interpretations  There are many assumptions that could be made  We focus on two of them here  ones that we believe arise in applications of interest  and then reconsider them under the assumption that there may be some ambiguity about the partitions  Believing there is no ambiguity The first approach is appropriate for situations where players may interpret statements differently  but it does not occur to them that there is another way of interpreting the statement  Thus  in this model  if there is a public announcement  all players will think that their interpretation of the announcement is common knowledge  We write  M    i   out  to denote that  is true at state  according to player i  that is  according to is interpretation of the primitive propositions in    The superscript out denotes outermost scope  since the formulas are interpreted relative to the outermost player  namely the player i on the left hand side of  out   We define  out   as usual  by induction  If p is a primitive proposition   M    i   out p iff i    p    true      This just says that player i interprets a primitive proposition p according to his interpretation function i   This clause is common to all our approaches for dealing with ambiguity  For conjunction and negation  as is standard   M    i   out  iff  M    i     out    M    i   out    iff  M    i   out  and  M    i   out   Now consider a probability formula of the form a  pr j                ak pr j  k    b  The key feature that distinguishes this semantics is how i interprets js beliefs  This is where we capture the intuition that it does not occur to i that there is another way of interpreting the formulas other than the way she does  Let     out        M    i   out    i Thus      out is the event consisting of the set of states where  is true  according to i  Note that i A  and A  guarantee that the restriction of j  to i    belongs to Fi    Assume inductively that       out  j              k   out  j   Fj    The base case of this induction  where  is i i a primitive proposition  is immediate from A  and A   and the induction assumption clearly extends to negations and conjunctions  We now define  M    i   out a  pr j                ak pr j  k    b iff a  j         out  j              ak j     k   out  j     b  i i Note that it easily follows from A  that  M    i   out a  pr j                ak pr j  k    b if and only if  M     i   out a  pr j                ak pr j  k    b for all    j     Thus    a  pr j                ak pr j  k    b  i is a union of cells of j   and hence   a  pr j                ak pr j  k    b  i  j   Fj    With this semantics  according to player i  player j assigns  probability b if and only if the set of worlds where  holds according to i has probability b according to j  Intuitively  although i understands js probability space  player i is not aware that j may interpret  differently from the way she  i  does  That i understands js probability space is plausible if we assume that there is a common prior and that i knows js partition  this knowledge is embodied in the assumption that i intersects   k   out with j  when assessing what probability j assigns to i   k    Given our interpretation of probability formulas  the interpretation of Bj  and EB k  follows  For example   M    i   out Bj  iff j       out i           Note that at state   player i will not in general know that it is state   In particular  even if we assume that i knows which element of js partition contains   i will not in general know which of js cells describes js current information  But we assume that i does know that if the state is   then js information is described by j    Thus  as usual   M  i     out  should perhaps be understood as according to i   is true if the actual world is   This interpretational issue arises even without ambiguity in the picture       For readers more used to belief defined in terms of a possibility relation  note that P if the probability measure j  is discrete  i e   all sets are j   measurable  and j   E     E j      for all subsets E  j      we can define Bj            j             that is         Bj if  in state   agent j gives state   positive probability  In that case   M    i   out Bj  iff  M      i   out  for all   such that        Bj   That is   M    i   out Bj  iff  is true according to i in all the worlds to which j assigns positive probability at   It is important to note that  M    i     does not imply  M    i    Bi   while  M    i   out  means  is true at  according to is interpretation  this does not mean that i believes  at state   The reason is that i can be uncertain as to which state is the actual state  For i to believe  at    would have to be true  according to is interpretation  at all states to which i assigns positive probability  Finally  we define  M    i   out CB G  iff  M    i   out EB kG  for k               for any nonempty subset G  N of players  Awareness of possible ambiguity We now consider the second way of interpreting formulas  This is appropriate for players who realize that other players may interpret formulas differently  We write  M    i   in  to denote that  is true at state  according to player i using this interpretation  which is called innermost scope  The definition of  in is identical to that of  out except for the interpretation of probability formulas  In this case  we have  M    i   in a  pr j                ak pr j  k    b iff in a  j         in j  j              ak j     k   j  j     b  in   Hence  according to player i  where     in j is the set of states  such that  M    j    player j assigns  probability b if and only if the set of worlds where  holds according to j has probability b according to j  Intuitively  now i realizes that j may interpret  differently from the way that she  i  does  and thus assumes that j uses his  js  interpretation to evaluate the probability of   Again  in the case that j  is discrete  this means that  M    i   in Bj  iff  M      j   in  for all   such that        Bj   Note for future reference that if  is a probability formula or a formula of the form CB G    then it is easy to see that  M    i   in  if and only if  M    j   in   we sometimes write  M     in  in this case  Clearly   out and  in agree in the common interpretation case  and we can write    There is a sense in which innermost scope is able to capture the intuitions behind outermost scope  Specifically  we can capture the intuition that player i is convinced that all players interpret everything just as he  i  does by assuming that in all worlds   that player i considers possible  i        j     for all players j   Ambiguity about information partitions Up to now  we have assumed that players understand each others probability spaces  This may not be so reasonable in the presence of     ambiguity and prior generated beliefs  We want to model the following type of situation  Players receive information  or signals  about the true state of the world  in the form of strings  formulas   Each player understands what signals he and other players receive in different states of the world  but players may interpret signals differently  For instance  player i may understand that j sees a red car if  is the true state of the world  but i may or may not be aware that j has a different interpretation of red than i does  In the latter case  i does not have a full understanding of js information structure  We would like to think of a players information as being characterized by a formula  intuitively  the formula that describes the signals received   Even if the formulas that describe each information set are commonly known  in the presence of ambiguity  they might be interpreted differently  To make this precise  let  be the set of formulas that is obtained from  by closing off under negation and conjunction  That is   consists of all propositional formulas that can be formed from the primitive propositions in   Since the formulas in  are not composed of probability formulas  and thus do not involve any reasoning about interpretations  we can extend the function i    to  in a straightforward way  and write     i for the set of the states of the world where the formula    is true according to i  The key new assumption that we make to model players imperfect understanding of the other players probability spaces is that is partition cell at  is described by a formula i      Roughly speaking  this means that i    should consist of all states where the formula i  is true  More precisely  we take i    to consist of all states where i  is true according to i  If player j understands that i may be using a different interpretation than he does  i e   the appropriate semantics are the innermost scope semantics   then j correctly infers that the set of states that i thinks are possible in  is i        i    i   But if j does not understand that i may interpret formulas in a different way  i e   under outermost scope   then he thinks that the set of states that i thinks are possible in  is given by   i    j   Of course    i    j does not in general coincide with i     Indeed    i    j may even be empty  If this happens  j might well wonder if i is interpreting things the same way that he  j  is  In any case  we require that j understand that these formulas form a partition and that  belongs to   i    j   Thus  we consider structures that satisfy A A   and possibly A   when we use outermost scope semantics   A   For each i  N and     there is a formula i    such that i        i    i   A   For each i  j  N  the collection    i    j       is a partition of  and for all         i    j   Assumption A  ensure that the signals for player i define an information partition according to every player j when we consider the outermost scope semantics  With innermost scope  this already follows from A  and the definition of i     We can now define analogues of outermost scope and innermost scope in the presence of ambiguous information  Thus  we define two more truth relations   out ai and  in ai    The ai here stands for ambiguity of information   The only difference between  out ai and      out is in the semantics of probability formulas  In giving the semantics in a structure M  we assume that M has prior generated beliefs  generated by  F                  Fn   n    As we observed in Proposition      this assumption is without loss of generality as long as the structure is countably partitioned  However  the choice of prior beliefs is relevant  as we shall see  so we have to be explicit about them  When i evaluates js probability at a state   instead of using j    player i uses j       j    i    When i   j  these two approaches agree  but in general they do not  Thus  assuming that M satisfies A  and A   which are the appropriate assumptions for the outermost scope semantics   we have  M    i   out ai a  pr j                ak pr j  k    b iff a  j        out ai     j    out ai         i i out ai out ai  ak j    k   i     j    i    b  where     out ai         M    i   out ai    i That is  at     player j receives the information  a string  j    which he interprets as   j    j   Player i understands that j receives the information j  in state   but interprets this as   j    i   This models a situation such as the following  In state   player j sees a red car  and thinks possible all states of the world where he sees a car that is red  according to j   Player i knows that at world  player j will see a red car  although she may not know that the actual world is   and thus does not know what color of car player j actually sees   However  i has a somewhat different interpretation of red car  or  more precisely  of j seeing a red car  than j  is interpretation corresponds to the event   j    i   Since i understands that js beliefs are determined by conditioning her prior j on her information  i can compute what she believes js beliefs are  We can define  in ai in an analogous way  Thus  the semantics for formulas that do not involve probability formulas are as given by  in   while the semantics of probability formulas is defined as follows  where M is assumed to satisfy A   which is the appropriate assumption for the innermost scope semantics    M    i   in ai a  pr j                ak pr j  k    b iff a  j        in ai     j    in ai         j j in ai  ak j    k   j     j    in ai    b  j Note that although we have written   j    in ai   since j  is a propositional formula    j    in ai   i i out ai out in   j    i     j    i     j    i   It is important that j  is a propositional formula here  otherwise  we would have circularities in the definition  and would somehow need to define   j    in ai   i Again  here it may be instructive to consider the definition of Bj  in the case that j  is discrete for all   In this case  Bj becomes the set          j        j    in ai        That j   is  state  is considered possible by player j in state  if agent j gives  positive probability after conditioning his prior j on  his interpretation of  the information j  he receives in state   With this definition of Bj   we have  as expected   M    i   in ai Bj  iff  M      i   in ai  for all   such that        Bj        The differences in the different semantics arise only when we consider probability formulas  If we go back to our example with the red car  we now have a situation where player j sees a red car in state   and thinks possible all states where he sees a red car  Player i knows that in state   player j sees a car that he  j  interprets to be red  and that this determines his posterior  Since i understands js notion of seeing a red car  she has a correct perception of js posterior in each state of the world  Thus  the semantics for  in ai are identical to those for  in  restricted to the class of structures with prior generated beliefs that satisfy A    though the information partitions are not predefined  but rather generated by the signals  Note that  given an epistemic structure M satisfying A A   there are many choices for i that allow M to be viewed as being generated by prior beliefs  All that is required of j is that for all    and E  Fj  such that E    j    jout ai   it holds that j  E    j    out ai   j    j    out ai     j   E   However  because   j    iout ai may not be a subj j   j     we can have two prior probabilities j and j that generate the set of   j    out ai j same posterior beliefs for j  and still have j    k   out ai     j    iout ai      j    k   iout ai   i   j    out ai   for some formulas k   Thus  we must be explicit about our choice of priors here  i    Common interpretations suffice In this section  we show in there is a sense in which we do not need structures with ambiguity  Specifically  we show that the same formulas are valid in common interpretation structures as in structures that do not have a common interpretation  no matter what semantics we use  even if we have ambiguity about information partitions  To make this precise  we need some notation  Fix a nonempty  countable set  of primitive propositions  and let M   be the class of all structures that satisfy A A  and that are defined over some nonempty subset  of  such that     is countably infinite   Given a subset  of   a formula   LC n     and a structure M  M   over   we say that  is valid in M according to outermost scope  and write M  out   if  M    i   out  for all    and i  N  Given     say that  is valid according to outermost scope in a class N  M   of structures  and write N  out   if M  out  for all M  N defined over a set    of primitive propositions that includes all the primitive propositions that appear in   We get analogous definitions by replacing  out by  in    out ai and  in ai throughout  in the latter two cases  we have to restrict N to structures that satisfy A  and A  or just A   respectively  in addition to A A    Finally  given a class of structures N   let Nc be the subclass of N in which players have a common interpretation  Thus  Mc    denotes the structures in M   with a common interpretation  Let Mai    denote all structures in M      Most of our results hold if we just consider the set of structures defined over some fixed set  of primitive propositions  However  for one of our results  we need to be able to add fresh primitive propositions to the language  Thus  we allow the set  of primitive propositions to vary over the structures we consider  but require     to be countably infinite so that there are always fresh primitive propositions that we can add to the language        with prior generated beliefs that satisfy A  and A   where we assume that the prior  that describes the initial beliefs is given explicitly    Theorem     For all formulas   LC n     the following are equivalent   a  Mc         b  M    out    c  M    in    d  Mai c         e  Mai     out ai    f  Mai     in ai   Proof  Since the set of structures with a common interpretation is a subset of the set of structures  it is immediate that  c  and  b  both imply  a   Similarly   e  and  f  both imply  d   The fact that  a  implies  b  is also immediate  For suppose that Mc       and that M       j  jN    Pj  jN    j  jN    M   is a structure over a set    of primitive propositions that contains the primitive propositions that appear in   We must show that M  out   Thus  we must show that  M    i   out  for all    and i  N  Fix    and i  N  and let Mi       j  jN    Pj  jN    j  jN    where j   i for all j  Thus  Mi is a common interpretation structure over   where the interpretation coincides with is interpretation in M  Clearly Mi satisfies A A   so Mi  Mc     It is easy to check that  M    i   out  if and only if  Mi     i     for all states    and all formulas   LC n      out Since Mi     we must have that  M    i      as desired  To see that  a  implies  c   given a structure M       j  jN    Pj  jN    j  jN    M   over some set    of primitive propositions and a player j  N  let j be a disjoint copy of   that is  for every state     there is a corresponding state j  j   Let           n   Given E    let the corresponding subset Ej  j be the set  j     E   and let E  be the subset of  corresponding to E  that is  E     j     E  j  N   Define M         j  jN    Pj  jN    j  jN    where            n and  for all    and i  j  N  we have  i  j      i       i  j   p    j    p  for a primitive proposition p       Pi  j      i j   Fi    i j    where i j   i    Fi     El   E  Fi    l  N   j j   i j  Ei     i   E   i j  El       if l    i     For ease of exposition  we assume A  even when dealing with innermost scope        Thus           n   so that M  is a common interpretation structure  on a state j   these interpretations are all determined by j   Also note that the support of the probability measure i j is contained in i   so for different players i  the probability measures i j have disjoint supports  Now an easy induction on the structure of formulas shows that M    j      if and  only if  M    j   in  for any formula   LC n     It easily follows that if M     then in C M    for all   Ln     The argument that  d  implies  e  is essentially identical to the argument that  a  implies  b   similarly  the argument that  d  implies  f  is essentially the same as the argument that  a  implies  c   Since Mai c     Mc      a  implies  d   To show that  d  ai implies  a   suppose that Mc       for some formula   LC n     Given a structure M       j  jN    Pj  jN      Mc    over a set    of primitive propositions that includes the primitive propositions that appear in   we want to show that  M    i     for each state    and player i  Fix   Recall that RN    consists of the set of states N reachable from   Let M     RN      j  jN    Pj  jN        with j and Pj the restriction of j and Pj   respectively  to the states in RN     be a structure over a set  of primitive propositions  where  contains  and new primitive propositions that we call pi  for each player i and state   RN      Note that there are only countably many information sets in RN     so  is countable  Define   so that it agrees with   restricted to RN     on the propositions in   and so that   pi    i   i     Thus  M  satisfies A  and A   It is easy to check that  for all       RN    and all formulas   LC n     we have that  M     i     iff  M      i       Since M     it follows that  M    i      as desired  From Theorem     it follows that for formulas in LC n     we can get the same axiomatization with respect to structures in M   for both the  out and  in semantics  moreover  this axiomatization is the same as that for the common interpretation case  An axiomatization for this case is already given in  Fagin and Halpern        there is also a complete characterization of the complexity of determining whether a formula is valid  However  the equivalence in Theorem     does not extend to subclasses of M  Mc   and ai M   As shown in our companion paper  Halpern and Kets        the equivalence result does not hold if we consider the innermost scope semantics and restrict attention to the subclasses of M and Mc that satisfy the common prior assumption  We defer a further discussion of the modeling implications of this result to Section       A more general language Although  when considering innermost scope  we allowed for agents that were sophisticated enough to realize that different agents might interpret things in different ways  our syntax did    This is the one argument that needs the assumption that the set of primitive propositions can be different in different structures in M    and the fact that every     is countable  We have assumed for simplicity that the propositions pi  are all in      and that they can be chosen in such a way so that        pi    i              n        is countable        not reflect that sophistication  Specifically  the language does not allow the modeler  or the agents  to reason about how other agents interpret formulas  Here we consider a language that is rich enough to allow this  Specifically  we have primitive propositions of the form  p  i   that can be interpreted as is interpretation of p  With this extended language  we do not need to have a different interpretation function i for each i  it suffices in a precise sense to use a single  common  interpretation function  We now make this precise  and show that this approach is general enough to capture both outermost and innermost scope  More precisely  we consider the same syntax as in Section      with the requirement that the set  of primitive propositions have the form   N  for some set    that is  primitive propositions have the form  p  i  for some p   and some agent i  N  We interpret these formulas using a standard epistemic probability structure M       j  jN    Pj  jN      with a common interpretation   as in  Fagin and Halpern        Thus  truth is no longer agentdependent  so we have only  M    on the left hand side of    not  M    i   In particular  if  p  i  is a primitive proposition   M       p  i  iff     p  i     true  As expected  we have  M      a  pr j                ak pr j  k    b iff a  j           j              ak j     k     j     b  in We no longer need to write   j   ou i or   j   i   since all agents interpret all formulas the same way  We now show how we can capture innermost and outermost scope using this semantics  Specifically  suppose that we start with an epistemic probability structure M       j  jN    Pj  jN    j  jN   over some set  of primitive propositions  Consider the corresponding common interpretation structure Mc       j  jN    Pj  jN     over   N  where    p  i    i    p   Thus  M and Mc are identical except in the primitive propositions that they interpret  and how they interpret them  In Mc   the primitive proposition  p  i     N is interpreted the same way that i interprets p in M  out We can now define  for each formula   two formulas in with the property that i and i in in out out  M    i     iff  Mc       i and  M    i     iff  Mc       i   We start with in i   defining it by induction on structure    pin i    p  i  in  in        in i   i   i   in in   a  pr j                ak pr j  k    b in i   a  pr j      j             ak pr j   k  j    b in   CB G  in i   CB G  jG Bj j          Note that in i is independent of i if  is a probability formula or of the form CB G   This is to be expected  since  as we have seen  with innermost scope  the semantics of such formulas is independent of i  The definition of  CB G  in i is perhaps the only somewhat surprising clause here  as we discuss after the proof of Theorem     below  the more natural definition  in  CB G  in i   CB G  i    does not work  For outermost scope  the first two clauses of the translation are identical to those above  the latter two change as required for outermost scope  Thus  we get  pout    p  i  i        out   iout   i  out i out   a  pr j                ak pr j  k    b out   a  pr j      out i i             ak pr j   k  i    b    CB G  out   CB G  iout    i Interestingly  here the natural definition of  CB G  out does work  i Theorem     If M is a probabilistic epistemic structure over  and Mc is the corresponding common interpretation structure over   N  then  a   M    i   in  iff  Mc       in i    b   M    i   out  iff  Mc       out i   Proof  We prove the result by induction on the structure of   The argument for outermost scope is completely straightforward  and left to the reader  The argument for innermost scope is also straightforward  except for the case that  has the form CB G   We now consider this case carefully  By definition   Mc        CB G  in i iff  Mc       CB G  jG Bj jin   iff  Mc        EB G  k  jG Bj jin   for k                   in Note that  by definition   EB G  in i   jG Bj j   Thus  by the induction hypothesis  it follows that  Mc       jG Bj jin iff  M    i   in EB G    Now by a straightforward induction on k  we can show that  Mc       EB k  jG Bj jin   iff  M    i   in EB k   G   That is   Mc       CB jG Bj jin   iff  M    i   in EB kG  for k                             It immediately follows from     that if  M    i   in CB G   then  Mc       CB jG Bj jin    The converse also follows from      once we show that  M    i   in EB  G  implies  M    i   in EB G   But this too follows easily since implies implies iff iff   M    i   in  M    i   in  M    i   in  M    i   in  M    i   in  EB  G  jG Bj  jG Bj   jG Bj  Bj   jG Bj  EB    This completes the argument  To see why we need we need the more complicated definition of  CB G  in i   it is perhaps in best to consider an example  By definition   CB       p     CB        B   p      B   p       By way of contrast  CB        pin       CB        p      which  using arguments similar in spirit to those used above  can be shown to be equivalent to CB        B   p      B   p       They key point here is whether we have B   p     or B   p      We want the latter  which is what we get from the more complicated translation that we use  it is easy to show that the former does not give the desired result  These issues do not arise with outermost scope  Theorem     shows that  from a modelers point of view  there is no loss in working with common interpretations structures  Any structure that uses ambiguous propositions can be converted to one that uses unambiguous propositions of the form  p  i   In a sense  this can be viewed as a strengthening of Theorem      Theorem     says that any formula that is satisfiable using innermost or outermost semantics in the presence of ambiguity is also satisfiable in a common interpretation structure  However  that common interpretation structure might be quite different from the original structure  Theorem     shows that if a formula  is true out according to agent i at a state  in a structure M  then a variant of   namely  in i or i   is true at state  in essentially the same structure  Moreover  once we add propositions of the form  p  i  to the language  we have a great deal of additional expressive power  For example  we can say directly that agent i believes that all agents interpret p the same way that he does by writing Bi  j   p  i    p  j     We can also make more complicated statements  such as agent i believes that agents j and k interpret p the same way  although they interpret p differently from him  Bi   p  j    p  k    Bi   p  i    p  j    Clearly  far more subtle relationships among agents interpretations of primitive propositions can be expressed in this language     Discussion We have defined a logic for reasoning about ambiguity  and then showed that  in two senses  we really do not need structures with ambiguity      the same axioms hold whether or not we have ambiguity  and     we can use a richer language to talk about the ambiguity  while giving      an unambigious interpretation to all formulas  So why do we bother using structures with ambiguity  Perhaps the main reason is that it allows us to describe the situation from the agents point of view  For example  if we are dealing with outermost scope  an agent does not realize that there are other interpretations possible other than the one he is using  Thus  the simpler language more directly captures agents assertions  Similarly  a structure with ambiguity may more accurately describe a situation than a structure with a common interpretation  We thus believe that structures with ambiguity will prove to be a useful addition to a modelers toolkit  In any case  whatever modeling framework and language is used  it is clear that we need to take ambiguity into account  and reason explicitly about it  There are two extensions of our framework that we have not considered  First  we model ambiguity by allowing a formula to be interpreted differently by different agents  we assume that each individual agent disambiguates each formula  That is  no agent says Im not sure how to disambiguate   It could correspond to the U of worlds  or it could correspond to U    Im not sure which is right  As we mentioned earlier  this view is closer to that of Lewis        and Kuijer         It would involve a nontrivial change to our framework to capture this  Second  we have allowed only ambiguity about the meaning of primitive propositions  which then extends to ambiguity about the meaning of arbitrary formulas   But we have not considered ambiguity about the meaning of belief  for example  i might interpret belief in  terms of having a proof of  in some axiom system  while j might use a possible worlds interpretation  as we do in this paper   Capturing this seems interesting  but quite difficult  Indeed  even without ambiguity  it is not nontrivial to design a logic that captures various resource bounded notions of belief   See  Fagin  Halpern  Moses  and Vardi       Chapters      for more on this topic   Acknowledgments  We thank Moshe Vardi and the anonymous reviewers of this paper for helpful comments  Halperns work was supported in part by NSF grants IIS          IIS         IIS          and CCF          A preliminary version of this work appeared as Ambiguous language and differences in beliefs in the Principles of Knowledge Representation and Reasoning  Proceedings of the Thirteenth International Conference        pp           by AFOSR grants FA                FA                and FA                and by ARO grant W   NF            The work of Kets was supported in part by AFOSR grant FA                 
 In previous work studied the   BGHK    BGHK     we have random worlds approacha particul ar   and quite powerful  method for generating degrees  of belief  i e   subjective probabilities  from a knowl edge base consisting of objective  first order  slalisti  cal  and defaull  infonnation  But all owing a k n ow l edge base to contain only objective in form ation is    sometimes limiting  We occa  ionally wish to include infonnation about d egrees of belief in the knowledge base as well  because there are contex t s in which old  be iefs represent importan t information that should influence new beliefs  In this paper  we describe three quite general techniques for extending a method that generates degrees of belief from objective informa tion to one that can make use of d egrees of belief as well  All of our techniques  are  ha  ed on well known  approaches  such a  cross emropy  We di sc uss gen  eral connections between the techniques and in partic    ular show that  although concept u ally and technically quite different  all of the t echniques give the same answer when applied to the random worlds method      halpern almaden ihm com  Daphne Koller  Computer Science Division University of California  Berkeley Berkeley  CA       daphne cs berkeley edu  principle determine if the agent s objective information is cmTect  by ex amin ing what is actually the case in its envi ronment   we cannot so ea  ily say that its subjective beliefs are   Xmcct  The truth or falsity of these pieces of informa tion is not detc nni n ed by the state of the environment  Although su b j ecti ve infonnation could take many differ  ent l mns  we will concentrate here on  degrees of belief  arc probabilities that are assigned to fonnulas ex pressing objective a sse rti ons  For example  the assertion  the weather is warm in New York  is an objective one  it  These  is either true or false in the agent s environment  But when  we  L    sig n a degree of belief to this assertion  as above  we  obtain  a  subjective asertion  it becomes a statement about  the state of the agent s be l ie fs  In tl e context of probability  d is tinction between subjective and objective can  theory the  appear somewhat subtle  be cau se some form of objective information  such  L   proportions  or frequencies  obey the  laws of probahility j ust a   d o degr ees of belief  Yet the dis  tincrion can be a significant one if we want to use or interpret  a pmbahilistic theory conectly  Camap s work   Car     is  notewort  y for its care ful distinction between  and study of  both st at i s tical  degree of belief  probabilities  which are objective  and probabil it ies  which are subjective   In order to und erstand  Introduction  vide  a  this distinction  it is useful to pro  formal semantics for degrees of belief that captures  the difference between them and objective information  As  When we examine the knowledge or information possessed by an agent  it is useful to distinguish between  subjective  objective information  Objective information is infor mation about me environment  whcrca suiective informa and  tion is infonnation about the state of the agen t s hcliefs  For example  we might c hara ct erize the infonnation of an agent    travelling from San Francisco  to New York as conisting of the objective infonnation tlmt the weather is warm in San Francisco  and the subjecti ve infotmation that the proba  bility rhat the weather is wann in New York is      The important thing to notice here i s tlmt altl  ugh we can in  This research has been supported in p art by the Canadian  Government through their NSERC nnd IRIS programs  by the  Air Force Office of Scientific Research  AFSC  under Contract F         C       and by a University of California President s  Postdoctoral Fellowship  The United States Government is au thorized to reproduce nnd distribute reprints for govemmentJI purposes    Joseph Y  Halpern IDM Almaden Research Center     Hany Road San Jose  CA             dcmonstraled by Halpern  Hal     a natural  and very gen  eral   way to give a d efi nin g worlds    semantics  to degrees of belief is by  probabi li ty distribution over a set of possible The degree of bel ie f in a fonnul a r p is then the  a  probab il it y of the set of worlds where r p is true  In this framework we can characterize oj ective infonnation as consisting of assertions   ex pressed as fmmulas  that can he assi gned a truth value by a single world  For example  in any given world Tweety the bird does or does not fly  Hence  the fonnula Fly Tweety  is objective  Statistical assertions such as IIFly x IBird J  II    i m atel y      of         read  approx  birds fly   are also objective  On the other  hand  Pr  Fly Tweety            expressing the assertion that   Conceptually  this notion of world is just as in classical possibl worlds semantics   a complete picture or description of tht  way the world might he  Formally  we take a world to be an intcrprctntion  model  for first order logic    Bacchus  Grove  Halpern  and Koller      the agent s degree of belief in Tweety  l yi ng  is      is n ot  objective  as its truth is determined by whether or not tlle pr obability of the set of worlds where Tweety flies is        Although we cannot easily characterize an agent s degr ees of beliefs as being correct or incorrect  it is nevertlleless clear that these beliefs should have some rel ation to objec tive reality  One way of guaranteeing this is to actually  generate them from the objective information available to the agent  Several ways of doing this h ave been consid ered in the literature  for example   BGHK    PV    each  discuss several possibilities  The appr oach es in  BGHK    are based in a very natural way on tlle semantics des cr ib e d above  Assume we have a  prior  probability distribution over some set of worlds   We cru  t  e n generate degr ees  of belief from an objective know ledge bae KB by u sin g standard Bayesian conditioning  to t  e formul a  P we a sign as its degree of belief the conditional prob ab i lity  of  r p given KB  In  BGHK    we considered three particu lar choices for a prior  and i nve stigat ed the properties of the resulting inductive inference sy stem s   In   BGHK     we concentrated on the simp lest of these methods the choice of prior is essen  random worlds m eth od whose  tially the uniform prior over the se t of possible worlds   More precisely  suppose we re strict our attention to worlds  i e   interpretations of ru  appropriate vocabul ary for first  order logic  with t  e domain    I          N    Assumin g we  have a finite vocabulary  there will be only finitely many  such worlds  Random worlds ta kes a   the set of worlds all  of these worlds  and uses p erh ap s the s i mpl e st probability distribution over them the uniform distributionthus as suming that each of t  e worlds is eq u ally likely  This gi ves a prior distribution on the set of pos sibl e worlds  We can now induce a degree of belief i n  P gi ven KB by using the conditional probability of  P  given Kll with respect to this of  uniform distribution  II is ea  y to see that the degree  belief in r p given KB is then s i mply tJ e fraction of possible worlds satisfying KB that also sati s fy  P In general   how  ever  we do not know the domai n size N  we know only that it is typically large  We cm  therefore appro x i mate the  degree  of belief for the true but unknown  N  by computing  the limiting value of this degree of be l ief as N g rows large  This limiting value  if it exists  which it may not  is denoted    r piKB   and it is what the rando m  w orld method takes  to be the degree of belief in  P given  KB  In  BGHK     we  showed that U is method posse ss es a number of anractive properties   such  as a prefe renc e for more  specific infonna  tion and the ab i lity to ignore inelevant information  The random worlds method Clli  generate degrees of be Iief from rich k nowledge b ases that may contain first order  statistical   and default information  However  w  with any  conditioning process  is limited to deal ing  with objective  information  When we add subje cti ve formulas to  KB  we  can no longer simply c ond iti o n on KB  the conditioning process eliminates those worlds inconsistent with our infor  mation  while U e truth of a subjective formula cannot be determined by a single world    Hence  we would like to    In the context of random worlds  and in other cases where the degrees of belief are de termined using  a  prior  on  the  set  of  extend the nmdom worlds method so as to enable it to deal with both objective and subjective information  Why do we wrun to take into account subjective beliefs  There are a number of situations where this seems to make sense  For example  suppose a birdwa tcher is interested in a domain of birds  m d has an obj ective knowledge base KBbird con si sting of t  e statistical inf ormation  IICardinal x i  Red      x      IICardina   t IRed x llx            Now the b irdw at cher catches a glimpse of a bird  b flying by  that seems to be r ed  The birdwatcher is trying to decide  if b is a crudinal   By the results of  BGHK     if the  birdwatcher assumes U at U e bird is n ot red  random worlds  gi ves      Prr Cardinal b IKBbird    Red b               On the  other hand  if she assumes tlmt the bird is red  we get  Red  b              But it does not  to he able to generate a d eg ree of b eli ef  in Cardinal  b   PJ     Conlinal b IKB    rJ      seem ap prop riate for her to do either  rather we would like that takes into acco u nt the birdwatcher s degree of belief in  Red  b    For example  if this degree of  be lief is      then  we would like to use a kn owled ge ba  e such as KBb rd    Pr   Red  b       O R  It seems re asonable to expect that the  resul t ing degree of oclief in  Cardinal b   somewhere bet wee n the two e xtremes of  would then be       and       As ano ther example  suppose we have reason to believe  that two sensors are independent  For simplicity  suppose  the sensors measure temperature  and report it to be either  high  h  or low  I  We can imagine t  ree unary predicates  S   r   indica ting that sensor   reports the value x  S  x    and Actual   x     i ndi cating That the sensors are inde pen d ent  given the actual value  can be represented by the     co nj unct i o n over all choices for  r     J  and J i n  I  h  of   a similar predicate for s ensor that the act u al  Pr S   t          temperature is  r       S   r  IActual  r    Pr Sl  t  IActua   r    x  Pr S  x  IActual x     It co u ld he tha t we h ave dctennined that ilie sensors are independent through the observation readings   of a n umber  of test  Such e mpirical evidence c oul d be summarized  by a stati s t ical assertion md thus added to our knowledge  base without req u i ring a degree of be lie f statement like ilie  ab ove  However  this is not the normal situation  Rather  we  arc more likely to have based our belief in independence  on other i n form ation  such a    our  beliefs  about causality   For example  the sensors may h ave been built by different manufacturers   In this cae  it seems most reasonable to  represent this kind of informa tion using an assertion about degrees of belief   How  t hen   can we incorp or at e information about degrees of belief into the ran d om  worlds framework  More generally    given any inference proce u  i e   a method for generat ing degrees of belief from objective infonnat i on we would worlds   this problem can be v iewed as an instance of the general problem of conditioning a distribution on uncertain evidence   The term inference process  is taken hom Paris and Vencov  sko I PVX    Our framework is slightly different from theirs  but we think t h i s usage of the term is consistent with their intent    Generating New Beliefs from Old  like to extend it so that it can also deal with subjective infor mation  This is an issue that has received some attention re cently  PV    Jae  b  Jae  a   We discuss lhree techniques      by us in g cross entropy  KL     Given two probability dis tributions p and p   the cross entropy of p  relative to J l  denoted C         is a meao  ure of how  far  J t  is from J l  here  and consider their application in the specific context of random worlds  As we shall see  all of our techniques  a p rior  are very closely based on well known ideas in the litera ture  Two make use of cross entropy  while the t  ird is a  can t  en find the distribution on worlds satisfying the con s train ts tllat minimizes cross entropy relative to the prior   generalization of a method considered by Paris and Vencov  ska  PV     They are conceptually and  formally d istin ct     yet there are some interesting connections between them  In particular  in the context of random worlds they gener ally yield the same answers  where the compruison makes sense  the various methods have different nmges of applica bility   Many of the results we discuss are  in general terms  if not in specific details  already known  Nevertlleless  th eir combination is quite interesting  We now describe the three methods in a lillie more detail  The first method we exrunin e is  perhaps the simplest to ex t Je context of random worlds  Fix N  Random worlds considers all of the worlds that have domain            N   ru d assumes they are equal ly likely  which seems reasonable in the ab sence of information to the contrary  But now suppose that we have a degree of belief such as Pr Red b          In thi s case it is no longer reasonable to assume that all worlds are equally likely  our knowledge base tells us that the worlds where b is red are plain  We consider it first in   SJ    Sho     Given an inference method that generates  and  and a set of constraints determined by the KB  we  then use t  is new distribution to compute degrees of We call this method CEW  for cross entropy on  belief   worlds   The next method we consider also uses cross entropy  but in  a completely different way  Suppose we have the  ob  KBbird given above  and a separate  Pr Red b           As we sug gested  if the birdwatcher were sure Umt b was red  random worlds would give a degree of belief of     in Cardinal  b   similarly  if she were sure that b was not red  random worlds would give      Given that her degree of belief in Red b  jective  knowledge base      beli e f  ha  e  BBbird  is O R  it seems reasonable to asign a degree of belief of O R x           x     to Cardinal b   In fact  if we consider any inference process I   not necessarily one that generates a prior prnhahility on possihle worlds   it seems reasonable to ddine I  Cardinal  b  I KBhird       he equally likely  we divide the worlds into two sets  those which satisfy Red b  and those which satisfy   Red  b   Our beliefs require that the first set have probability     md the second probability      But otherwise we can make the worlds within each set equally likely  This is consi ste nt with the random worlds approach of making all worlds equally likely  Intuitively  we are considering the probability dis t ibut ion on the worlds that is as close as possible to our ori g i nal uniform distribu tion subject to the constraint that the set of worlds where Red  b  holds should have probability      tion  Rather than taking all worlds to  r  What do we do if we have ru  inference  process other than  random worlds  As long as it also proceeds by generating a prior on a set of possible worlds and then conditioning  we can deal with at least tl i s examp le   We simply use the ao  sign relative weights to the worlds in the sets determined hy Red b  and   Red  b   and then scale these weights wi thin each set so that the sets are assigned probabi l i ty     ru d     respectively  Readers familiar with Jeffrey s rule  Jer    will realize that this is es sentially an application of that rule   Again  intuitively  we are considering the distribution closest to Ute original prior that gives the set of worlds satisfying Red b  probabi l ity prior generated by the method to               Unfortunately  the knowledge bao  e is rarely this simple  Our degrees of belief often place co mple x constraints on the probability distribution  over possihle worlds  Never  theless  we would like to maintain the intuition that we are considering the distribution closest to the original prior       that satisfies the constnunts imposed by the KB  But how do we determine the  closest  distribution  One way is       x     more likely than the worlds where b is not red  Nevenheless   there is a straightforward way of incorporating this informa     BBbird  I Cardinal b JKBbirdi Red b       x I Cardinal b JKBbird A   Red  b     More  generally  we might hope that given an inference and a knowledge bao  e of t  e form KB A BB  we can gen erate from i t a collection of objective knowl edge hase KD i       KB   suc h tlmr I   PIKB    BB  is a weighted average of I  pJKBI        I lf IKBm   as in the example  In general  ho wever achieving this in a reasonable fas h ion is not so easy  Consider t  e belief base BB rd    Pr Red b              Pr   inw   b           In this case  we would like to d efi ne    Cardinal  b  JKBbird    BB rd  us ing a weighted average of I Cardinal b JKBbird   Red b     Snwll b    I Cardinal b IKBbint    Red b        Smnll b    etc  As in the simple example  it seems reasonable to take the we i ght of the tenn l Cardinal b JKBbird    Red b     Small  b   to he the degree of belief in Red  b     Smnll b   Unfortunately  while ss   rd tells us t  e degree of belief in Red      and Small  b  separately  it does not give us a degree of hel ief for their conjunction  A superficially plausible heu ri sti c would he to ao   sume that Red  b  and Smnll b  are independent  and thus assi gn degree of belief     x     to their conjunction  While this seems reasonable in this case  at other times it is completely inapp rop riate For example  if our knowledge base asser ts that all small things are red  then Red  b  and Snwll  b  cannot be independent  and we should dearly take the degree of belief in Red b     Smnll  b  to he the same a the degree of belief in Small  b   namely       In general  our new degre e of belief for the formula Red b     Small b  may depend not only on the new de grees of be lief for the two conjuncts  but also on our old process I           degree of belief    Red  b       Small b  JKBb rd    One reason  to computing t  ese degrees of belief is to make the smaflesr c hange possible to achieve consistency with the hclief hase  Here  as before  cross entropy is a u seful tool  Indeed  a we shall show  there is a way of able approach       Bacchus  Grove  Halpern  and Koller  applying cross entropy in this context to gi ve us a general approach  We call Ibis method CEF  for cross entropy on formulas  Altbough both CEW and CEF use cross entropy  they use it in conceptually d i fferen t ways  As the names suggest  CEW uses cross entropy to compare two probabil ity distributions over possible worlds  while CEF uses it to compare two probability distributions over formulas  On the other hand  any probability distribution on worlds gen erates a probability distribution on formulas in th e obvious way  tbe probability of a formula is the p rob abil i ty of the set of worlds where it is true   and so we can use a well known property of the cross entropy function to observe that the two approaches are in fact equiv ale nt when they can hmh  be applied   It is worth noting that the two approach es are actua lly in comparable in their scope of application  Because CEF is not restricted to inference processes tlJat generate a pri or probability on a set of possible worlds  it can be app lied to more inference processes than CEW  On the other hand  CEW is applicable to arbitrary KB s while  as we shall see  for CEF to apply we need to make mo re restrictions on the form of the KB   the metho ds also agree when appli ed to our version of the ME process and when applied to random worlds  Putting t  e results together  we can show that all these metbods CEW  CEF  and RS agree when applied to random worlds and in fact  CEW and CEF agree in general  In addition     t  e r esu lt ing extension of random worlds agrees with the approach obtained when we apply CEF and RS to the ME  process   The rest of this paper is organi zed as follows  In the next  sect i on we r evi ew the formal model of  Ha     for degrees  of belief and statistical information  and some material from    GHK    regarding the random worlds method  We give the formal definitions of t  e three metbods we consider in S ecti on    and discuss their equivalence  In passing  we also d i sc uss the conn ecti on to Jeffrey s rule  which is an other very well known met  od of updating by uncertain infonnation  We conclude in Section   witb some discus sion or computational issues and possible generalizations of lhesc approaches      Technical preliminaries  In Ibis paper  we focus on two instantiations of CEF  The first applies it to the random worlds method  The seco n d       used by Paris and Venco vska  PV      an d simililr in spirit to the metbod used by Jaeger  Jae  b    which we henceforth call the ME  inference  process  Using results of  GHK    PV     we prove that t  ese two instm ll ia l ions are equivalent   and reaso n with hoth statistical information and degrees of belief  We hriclly review the relevant mmerial here  We sta rt with a standard first order la ngu a ge over a finite vo cabulary    and a u gment it with proportion expressions and belief expressions  A basic proportion expression has the form       r  O J  IIx and denotes the proportion of do  applies it to a variant of the maximum entropy approach  The third method we consider also app l i es only to certain types of in ference processes  In panicu ar  it take a    its basic intuition that all degrees of belief must ultimately he the result of some statistical process  Hence  it re q u ires an inference process tlmt cm  gene rate degrees of belief from statistics  like random worlds  S uppo se we have the belief Pr Red b          If we view th is belief as havin g arisen from some statistical sampling process  then we can regard it as an abbreviation for statistical information ahout the class of individuals who are  just li ke b   For example  say that we get only a quick glm ce at b  so we are not certain it is red  The above asser ti on could be con strued as being an abbreviated way of saying that     of the objects that give a similar sense perception are red  To capture this idea formally we can view b as a membe r of a small set of  possibly fictional  ind ividual s S that are   just like b  to  the best of our knowledge  and ass u me that our degrees of belief about b actually represents the statistical information aboutS  IIRed x IS x llr       Once all degree ofhelief assertions have been convert e d into statistical assertions  we can tben apply any method for in fer r in g degn es of belief from statistical knowledge bases  We call this the RS method  for representative set   The general intuition for this metbod goes back to s tatistical mechanics  Lan  J  It was also defined  independently it seems  by Paris and Vencovska  PV      we follow their presentation here  Paris and Vencovska showed t   a t the RS method and the CEF metbod agree when app li ed to their version of the ME process  Using results of GHK    PV     we can show that  A fitst ol  ler  logic of probahility  In  Hal     a l o g ic is presente d that allows us to represent  main elements s atis fyin g  j  from among those elements satisfyin g B   We take                to be an abbreviation for       r  lmw  r           On the other hm d  a basic beliefexpres     l ion has  the form  Pr    J IO  m d denotes tbe agent s degree    The set of p roport ion  resp  belief   or belief in    g i ven  expressions is formed by ad din g the rational numbers to the set of basic proportion  resp  belief  expressions and then closing off und er addition m d mu lt ip lica tio n    We compme two pro por ti on expression s using the approx    ap pro xim at ely less than or equal    the result is a proportion formu l a  We use       as an abbreviation for        e               Thus  for example  we can express the stateme nt      of birds fly  using the proportion formula IIFly x IBird x llx        We com pa re two belief expressions using standard   the result is a basic belief ormula  For example  Pr Re d b        is a baic belief form ula    Of course Pr Red b       can be expressed as the o hv io us c onjunct ion   In the full language  we allow arbitrary llrst order qu ant i fication and nesting of belief and proportion formula    For example  complex imate connective                  fonnulas like  in   Pr V t I Knmvs  r   y IIY                    are   We remark that in  Hal    there was no use of approximate equality       We use it here since  as argued in  BGHK     its  use is crucial in our intended applications  On the other hand  in   DGI  K     we used a whole family of approxima te equality func  tions of the form   i we use only one here                        To simplify the presentation    Generating New Beliefs from Old  We will also be interested in various sublanguages of    A fonn ul a in which the  Pr  operator does not appear is m  objective formula  Such fonnulas are assigned truth values by single worlds  The sublanguage restricted to objective fonnulas is den oted by c obj   The standard rand om  worl ds method is restricted to knowledge bases expressed in cobj   l The set of belief formulas  c oe is fanned by starting with   basic belief formulas and closing off under conju nction   n eg ati on   and first order quantification  In contra  t to ob j ective fonnulas  the truth value of a be l ief fonnula is com pletely i ndepen dent of the world where it is evaluat ed   A flat formula is a B ool ean combination of belief formulas  such that in each belief expression Pr   P     the formula  P is a closed  i e   con taining no free variables  obj ective form u la   Hence we have no nesti nr  of  Pr  in nat formulas nor any  quantifying in    Let   at be the language consisting of the fiat fonnulas  give semantics to botl  proportion form u l a   and belief formulas  we use a special case of what were called in  Hal    type   structures  In part i cu l ar  we consider type   structures of the fonn  WN   p    where WN co n si s t s of al l worlds  first order models  with domain   I           A    over the vocabu l ary  ll   and Jl is a probabi l i t y distribution over WN    Given a structure and a world i n that structure  we eval uate a proportion expression              IO    r   I I    as the frac tion of domain el emen ts sat isfying        I    among those sat isfying O x     We evaluate a belief form u l a us i n g our proha bi ity distribution over tl e set of possib l e worlds  More pre cisely  given a structure M    WN        a world w E WN   a tolerance r E     I   u sed to i n te rpre t         and   S     and a val u ati on V  used to i n terpret the free variables   we asso ciate with each fonnula a tru tll value and with each belief expression or proportion expression   a numher   j M    v  r   We give a few representative clauses here   To  w      If   is tlle proporti on expression I I          I      I I      then    M w   v   r is the num ber of domai n elements i n w sat i s fy i ng           d i v i de d hy the numher sat i s fyi n g       Note that these n u m bers may depend on w     We take this fraction to be   if n o domain elements sat i s fies     I f   is  the belief expression Pr   P I I       then        M w  V r Again    p   tv      M   w    V  r       P         p   w      M  w    V  r              we take this to he   i f the denominator is       m d     are two proportion   M   w   T   V  I      S    iff  If  expressions      M w   r   V  S      M   w   r  V     th e n  T   That is  approximate less than or eq ual allows a tolerance of r      is a belief expression  th en i t s value i s in dependen t of the world w  Moreover  i f it is cl osed then its value is in dep enden t of the val u a t i on V  Thus  we can write    M   in tllis ca  o e  Similarly  if  p E      is a cl o sed  Notice that if     In general  type   structures  addition a lly allow for a distribu   l           N      Here  we always  tion over the domain  in this case   use the unifonn d isui b u ti on over the doma in   belief form u l a   its truth depends only on M and r     cp i n this ca  e   can write   M  r            so we  The random worlds method  Given these semantics  tlle random worlds method is now easy to describe  S uppose we have a KB of objective for mula  and we wrull to a  sign a degree of belief to a fonnula tp   Let p f v be the uniform distribution over WN   and let w M V    WN   Jlf r    Let Prr  cpi K B     Pr cpjKB  MN   r  Typically  we know on l y tl at N i s large and that r is small  Hence  we approximate the value for the true N and r by ddining  P        lKB      lim lim Prrw cpjKB   N    CXJ   r      a  suming the limit exists  P      cpiKB  is the degree ofbelief in  P given KI  acc ord i ng to the random worlds method       Maxi m u m entl Opy and cross entropy  The entropy or a probab i l i t y d is tribu ti on Jl over a finite space  n  Lw E n  l   w   ln  l w       It ha been argued  Jay    the amou n t of  information  i n a probabi l i t y di stri b u t i on  i n t h e sense of information tlleory  The uniform distri bution has the maximum possible en t rop y  I n general  g i ven som e constraints on the probability is    that entropy measures  with maximum entropy that viewed as the one that i ncor i nfonnation above and beyond  distributions  the distri b u t i o n  satisfies t h e c onst rai n ts cllil be porates the least addi t i onal the constrai nts   The related cross entropy function measures the additional information gained by mov i n g from one di stribu ti on Jl to another uistri hu t ion Jl         I      Jt                  tl  w       L      w In p  w    wEn  Various arguments have been pre sent ed showing that cross meas u res how close one probability distribution is to ano t he r  S TRO  S ho      Thus  given a prior distribution I  and a set S  of add i tio nal constraints  we are typically i n t ere st c u i n th e unique distribution    tllat satisfies S and minimizes C p    p     It is well  known tlmt a su fficient con dition for such a u n i q u e distribution to exist is that the set of di stribu tions sat i sfyi n g S form a convex set  and that t here be at le L  t one d i stribution p  sati sfying S such that C IJ     I     is fi n i te   These conditions often h old in practice   entropy         The three methods CEW  As w e ment ioned in  the introduction  our first metllod   CEW  assumes as input an inference process I that proceeds by generati ng a pri or Jl f on a se t of possible worlds W  and t h e n conditioning on th e objective i n formati on   Given such an inference process I   a k n owl ed ge base KB  that can con tain subjective infonnation  and an objective formula cp  we wish t o co m p u te CEIV   I   piKB   where CEW I  i s a       Bacchus  Grove  Halpern  and Koller  new degree of belief generator that can handle knowledge bases that can include subjective infmmation   We say that an inference process I is world based if there is some structure M     Wr   llt  and a tolerance r such that  l PIKB     Pr lf IKB  M   T   Notice that Pr   rw is world based for each N  where the structure corresponding to Pr   rw is MjV      on the other hand  is not world ba  ed  we return to this point shortly   Given a world based inference process I  we define as follows  Given a knowledge base KB which can be an arbitrary formula in the full language  C  let Jt    be the probability distribution o n WI su ch t  at C Jl    JlJ   is minimized  if a unique such distribution exists  among all distributions tl such that  WI   p    T   I  Pr KB    l  Intu itively  pf  is the probability distribution closest to t he prior Jli that gives KB probability l   Let Mf      WI   JLf    We can then define CEW I   c oiKB      Pr  cp J  Ks   T    CEW I   I  The first thing to observe is that i f KB is objective  then standard properties of cross entropy can he used to show that pf  is t  e condilional distri b u t i o n I  I C l KI      We thus immediately get  Proposition      lfKB is objective  then CEW  I       p j K I    l lf  I KB     Thus  CEW I  is a true extension of        Another important property of CEW fo llow s from the wel l  known fact that cross entropy generalizes Jeffrey  s rule  Jef     Standard probability theory tells us that if we start with a probability function p an d observe that event E holds  we should update to the conditional probabi lity function Jl     I E   Jeffrey s rule is mean t to ueal w i th the possibility that rather than get ting certain i n formation  we only get partial information  such a   that E hold s with proh ability o   Jeffrey s rule suggests that in tl  i s case  we should update to the probability function p  such that  tt  A      o JI   A I E       I   rr  p   A IE     where E denotes the complement of E      i s rul e uniformly rescales the probabilities within E and  separately  those within E so as to satisfy the constrain t Pr  E    a  Clearly  if o        then Jl  is j ust the conditional prohab i l i t y p   I E     This rule can be generalized i n a strai ght forward fashion   If we are given a family of mutually ex c l u si ve and ex haustive events       Ek with de si red new prohahi l i t ies              ak  necessarily L i c r          t h en we can define             p  A      a   lt A I El                ni  I   A I Ek     Suppose our knowledge base ha  t he form   Pr   PI     n     A    A  Pr  lf k     a k     where the If    s are mu tually exclusive and exhaustive objective fonnulas and c r         cr     I   The formulas lf  l           lf t   conespond to mu tually ex clu sive and exhaustive events  Tilus  Jeffrey s rule would suggest that to compute the degree of belief in If  g i ven this knowl edge base  we should compute tile degree of belief in  P given each of the If   separately  and then take th e linear combination  Using t  e fact Umt cross entropy generalizes Jeffrey s rule  it is immediate that CEW i n fact docs t h i s     Proposition      Suppose that I is a world based inference process and that KB   is of the form KB A BB  where KB is objective and B B has the form  Pr            o  t   A  A  Pr  lf k     a t       where the lf i  s are mutually exclusive and exhaustive objective formulas and cq        o k      Then     k  CEW  I   c oi KB         L o   I   If I KB    cp      i l  As we observed above  CEW as stated does not apply di rectly t o U e random worlds method Pr   since it is not wor l d   based   It is  however  the limit of world based meth ods    This is also true for the ot  er methods considered in  BGH K      We can ea  ily extend CEW so that it applies to limits of world ba  ed methods by taking limits in the obvious way  In particular  we define CEW  Pr       H  f  I K B       l i m lim r     N   oo  CEW Pr   rw  PIKB      provided t he limit exists  For convenience  we abbreviate CEW   Pr     as Prw    note that the distribution defined by d i s tri bu t i on of maximum entropy that sati sfies the constraint Pr  KB    l    l is follows from the observation that the distri bution that minimizes the cross entropy from the u n i form distribution among those distri butions sa t i s fy i ng some constraints S   is exactly the distri bution or max i m um entropy satisfying     This maximum entropy characterization demonstrates Umt Prw extends ran dom worlds by making the probabilities of the possible worlds   t   equal as possi b l e  given the constraints  It is i n teresting to  CEW  Prrt          is the  CEF  Paris and Vencovska  PV    consider inferences processes that arc n o t world based  so CEW cannot be applied to them  The method CEF we now define applies to arbitrary  but requ i res that the knowledge base form  For the remainder of this section  we assume that the knowledge ba   e has the fonn KB    BB  where KB i s an objective formula and B B  which we call the hclicr base  is in         inference processes  be or a re st ri c t ed  BB is of UJe form Pr  th     U e t J   s were mutually exclu sive  then we could define C E F   I   lf IBB  so that Propo si t io n       he l d   B u t what i f the     s are not mutually exclu  First  suppose for simplicity that  d             A  Pr  V  d     Pk  If  sive        atoms over  J        Jt    i  e   those where each   J  is ei t her rJ   or  I J   Atoms are always mutually exclusive and ex h au s t i ve   so  if we could find appropriate degrees of helier for these at om s  we could again define things so that Propo s i t i o n     holds  A simple way of doing this Consider the r   conj u nct ions o r     the form                        A l JI      We remark that in  GHK    PV    a connection was es lahlished between random worlds and maximum entropy  Here maximum entropy is playing a different role  It is being used here to extend rnndom worlds rather than to characterize properties of random worlds as in  GHK    PV       Generating New Beliefs from Old  would be to assume that  after conditioning  the a  sertions  if   are independent  But  as we observed in the i ntroduction  assuming independence is inappropriate in general   Our solution is to first employ cross en trop y to find appro priate probabi l i ti es for these atoms  We proceed as follows  Suppose I is an arbitrary i n feren c e process       E C f a t   and   J              Jk are the formulas that appear in subexpres sions of the form Pr   if   in B B   We form the K    k at oms generated by the  if     de no ting them by A             A K   Con  sider the probab i l ity Jl defin ed on the space of atoms via t t Aj     I Aj   KB      There is an obvious way of defining whether the formula B B is satisfied by a probability distri bution on the atoms A             Ak  we defer t  e formal details to the full paper   but i n gen eral B B will not be sat isfied by the distribu tion     For a si mpl e example  if we take the in ference procedure to be random worlds and consider the knowledge base KBb nJA Pr Red b             from the intro duction  it turns out that P      Red   b     K B     d   is around           Clearly  the di stri bu tio n    such that p  Red  b     i s around      does not satisfy t  e constraint Pr Red  b               Let Jl  be the probability d i stribution over the atoms that mini mizes cross entropy relative to p among those t hat satisfy BB  provided tl ere is a unique such distribution  We then define  CEF I     p KB A B B             A l  I   P   KB A A             JJ     A K        p   KB A A g    It is immediate from the definition that CEF  I   Formally  w e h ave Proposition       I  P   KB    lf KB   P  E     extends      c j   then CEF         p   K B       Both CEW and CEF use cross entropy  However  t h e two applicatio ns are quite different  In the cm e of CEW  we apply cro ss  en trop y witl  respect to probabi lity di s t ri bu  tions over pos si ble worlds  whereas with CEE we apply i t to probabi lity distributions over formulas  Nevert hel e ss   as we mentioned in the i n trod u c ti o n   there is a tight connection  between the approaches  since any probahi l i t y distri bution over worlds defines a proba bi l i t y distribution over fonn u  las  In fact the following eq u i val e n c e can be proved  usi n g simple properties of tJJe cross emropy fu nct i on  Theorem       Suppose I i s a world based i erence process  KB    p E co i   and B B E  fl     Then CEW I  P I KB A B B     CEF         P   KB A B B     Thus  CEF and CEW agree defined   i n contexts w h ere both are  By analogy to tl e defin iti on for CEW  we define Pr   cp KB A BB      lim  lim  r O N   ro  CEF  Prrw      p   KB A BB      It immediately follows from Theorem      that    S ince  BB  Pr cunnot be nested in   J S are necessa ily objective  an d o are the  E c Jlat by assumption  an d  a flat b e lief base  the  atoms they generate  Thus   l  A   KB   is well defined       Corollary         KB   IP E Co i   and BB E  flat  then  Prw    P   K B A B B       Pr  r t  KB A BB    As the no t at i on suggests  we view of rr  obt ai n ed by applying CEF   PrF as the extension  Why did we not define PrF as CEF Pr     Cl earl y CEF rr      and Pr  are closely related  Indeed  if both are defined  then they are equal    ff both CEF Pr     piKB A BB  and Prr    P I KB A B B   are defined then they are equal   Theon m        It is q u i te p o ssi ble   in ge n e ral   that eitller one of Pr  and defmed while the other is not  The fo l l owin g  CEF  Pr   is  example demonstrates one type of situation where Pr  is dell ned and CEF  PrC    is no t  The converse situation typical ly ruises only in pathological examples  In fact  as we show in Theorem       there is an i mportan t class of cases where the existence of CEF Pr     g u arant ees that of PrF  Suppose KB is   Fly  x    Bird x    r  I A Rird   Tweety  and B B is Pr Fly Tweety       A Pr Red  Tweety          Then   just as we would expect  Pr    Red  lll eet v    KB    BB        On the other hand  CEF  P        Red    veety     KB A BB  is undefined  To see why  let  t be the probabi lity distribution on the four atoms ucfineu by Fly    veery  and Red   Tweety  determined by Pts         I K B     S i nce Pts   Fly  Tweety IKB    I   it must he t he case that     Fly  Tweety         or  more accu rately    t   Fiy  iveety  A Red  Tweety       p Fly Tweety  A   Red  liveetv      l     On th e other hand  any distri but ion    over the four atoms defined by Fly Tweety  and Red   iveety  that sati s fi es BB mu st be s uch that it    Fiy   iveety          It ea  ily fo l low s that if p  sat isfies B B   then C   p     I     oo   Thus  there is not a unique u i st ri h u t i o n over the atom s that satisfies BB and mi n i m i zes cross entropy relative to p   This means that CEI    Prr       Red    veety   I KB    B B   i s undefined  I Example        We nex t consider what happen s  when we instantiate CEF process considered by Paris and VL ncovska that u ses max i mum e nt rop y  PV     Paris and Vcncovsk a restrict at t e n t i on to rather simple lang u ag es   cor respond ing to the notion of   ess e n tial l y propositional  for m u l as de f i n ed below  When co ns i dering  our variant  of the i r method we shal l make the same restriction  w i th a p art i c ul a r inference  We say that       r   is an essentially propositional formula if it i s a quantifier free fi rst   ord e r formula that mentions only u nary predicates  and no con stan t or function sym bols   whose onl y free variable is x   A simple kno wl  edge base K B abollt c ha   t he form ll Pt   x   IO    x   ll r   S o                                 A      p k    r     fh   x       x   S O k        c   where         Ok         are all essen t ial ly propositional       P k   O      The M E i n fe re nce process  is only defined for  a  simple  M Nolice that II P  x   fB       f   t o  is expressible as      P        B    r    f l x      I   a   th is means we can also express          I Iowcvcr  because of the fact that we disallow negations in a sim ple KB   we cannot ex press s trict i ne qu al i ty  This is an important  rcstric lion        Bacchus  Grove  Halpern  and Koller  knowledge base about c and an essen t i al l y propositional query  p  c  about c  Let KB      KB        c   be m essen t ial l y propositional knowledge base abou t c  where KB  is the part of the knowledge base that does not mention c   I f the unary predicates that appear in KB are P     Pt           Pk     then KB  can be viewed as pu tti ng constraints on the     atoms over P    The fonn of KB  en s ures that U ere will be a unique distribution llme over Ulese atoms Ulat maxi mizes entropy and sati sfies the constraints  We then de fine ME   p  c  I KB     Jj  c   to be P me   lf  l         I n t u i t ively  we are choosing the d istribution of maximum entropy over the atoms that satisfies KB    and treating c a   a  nmdom  ele  ment of Ule domain  assuming i t satisfies each at om over P wiili Ule probabil i ty dictated by Jlme  To apply CEF to ME  we also need to put restrictions on tlle belief base  We say that D B E  c Jra t is an es  sentially propositional belief base about c i f every basic proportion expressi on has the fo nn Pr  y  c   I O   c       w here  p and B are essen t ial ly p roposi t ional  In p art icu lar  this    disallows statistical fotmul a   simp le belief base about c is  Pr  pt  c IBt  c        O J  in the  a  scope conjunction        Pr   pl    c  I Ok   c     of  Pr    o f the       ok   A  form  w h ere  all of tlle fonnulas th at appear are essential l y proposi tional  We can only apply CEF to ME if the knowledge bae has the fonn KB    BB  where KB is a simple knowledge hase about c and B B i s a simp l e belief bae abou t c  It fo l lows from results of  GHK    PV    that random worlds and ME give the same results on th ei r common domain  Hence  they are also equal after we appl y tl e CEF transformation  Moreover  on Ulis domain  if CEF Pr   is de fi ned   then so is PrF   The con verse docs not hold  as shown hy Example        Thus  we get Theorem      If KB is a simple knowledge base about   BB is a simple belief base about c  and   P is on essenTially propositionalformu a  then     CEF ME   p c  I KB A B B        CEF  Prr          P   c   I K D A I  I      Moreover  ifCEF ME    p   c   I KB CEF ME    p c  IKB A BB      A  B B   is defined  then  PrF   P  c   I KB A B B          RS The last method we consider  RS  i s based on t he intu ition that degree of belief asertions must u l timately ari se from statistical statements  This general idea goes hack to work in Ule field of statistical mechanics  LanRO   whe re it has been applied to the problem of reasoning abou t the total energy of physical systems  If the system consi sts of many particles then what is  in essence  a random worlds analysis can be appropriate  If the energy of the system is known exactly no conceptual problem arises  some possibl e configurations have the specified energy  while others are impossible because they do not  H owever it turns out that i t is frequently more appropriate to assume that all we know i s the expected energy  Unfortunately  i t questionable whether      An  mulas  atom over P is an atom  as de fi ned ahove   over the for  P    x             Pk   x      this i s real l y an  objective  a  sertion about th e system in que  tion       and in fact the physicist   encounter a problem  analogous to that which motivated our paper  Like us  one response they have con si dered is to modify the assump t i o n of unifonn probability and move to maximum entropy  thus u si n g essent i al l y  an in st ance of our CEW applied to a uniform prior   But another response is the fol lowing  Ph ysi cal l y  expected energy is appropriate for systems in th ermal equilibrium  i e   at a con stant temperature   But in practice this means Ulat Ule s yste m is in Ulennal contact with a  general l y much larger  system  sometimes called a heat bath  So another approach is to model the system of i n teres t a  being part of a much larger system  including the h e a t bath  whose total energy is truly fixed  On Ulis l arger scale  random worlds is on ce again applicable  B y ch oosi ng the energy for the total system appropriately  Ule ex pec t ed energy of the sm all subsystem will be as speci fied   Hence  we have converted s u bjective statements into objective ones  so that we are able to u se our standard tech niques  In this domain  there is a clear physical intuition for the con nec t i on between t  e objective infonnation  Ule       energy of the  exp ec t ed     heat bat h   and the subjective infonnation  the  energy of the  small system    A more recent  and q u i t e  di fferent  appearance of Ulis intu  ition is in t he work of Paris and Vencovska  PV      They dell ned t h ei r method so that i t ha   the same restricted scope  ME method  We presen t a more general version here  that can handle a somewhat richer set of knowledge  as th e  bases  al though i t s scope  is still more restricted than CEF  It  can deal with arbitrary inference proces ses   but Ule knowl BE  where KB is o bj ec ti ve and D B is an essentially p ro po s i ti onal belief base ah o u t some co n s tant c   The first step in the method is to transform    I  in t o an objective formula  Let S be a new unary predicate  representing the set of individuals ust l i ke c    We transform BD to KBnn by replacing all tenus of the form Pr    J  c ID c   by           x   IB x     S x ll t   and rep l aci n g all occmTences of     by    We then add Ule cnnj u ncts I I S   r l l l           md S c   s ince S is assumed For example  to he a small set and c must be in S  if D B is Pr Red c           A Pr Small c             then the nmcsponding KBnn is   I I Red x  I S x llx             ISmu     r J IS  r   ll               I S  z    l            I  S c   We then define R S          p  c   IKB A B B     I  IP   c  I KB A KB aa     I t is al most imme d ia t e from the d efin i ti ons that if B B is a si mple belief base ahout c   then RS Pr      p c  I KB A D B     li mr o limN     RS Pr r   piKB   We abbrevi a t e R S   Prr      as Pr   e d g e hase must have the form  KB         RS and  CEF are distinct   This observa of  PV    concerning an infer ence process CM  show i ng that RS CM  cannot be equal to CEF  CM     On th e other hand  Uley show Ulat  in the restricted setting in which ME applies  RS ME  CEF  ME     S i nce ME   Pt in this se t t ing we have  In  general   tion fol l ows from results     if lf it is objective  it is most plausibly a statement about the average energy over time  While this is a reasonable viewpoint  it  does not rea l l y escape from philosophical or technical problems  either    Generating New Beliefs from Old  Theorem      If KB  is a simple knowledge base about  c   tiona  Conference on Artificial Intelligence  AAA        pages                  B B is an essentially propositional knowledge base about c  and tf  is an essentially propositional formula  then  CEF rc    p c  IKB    B B      CEF ME   p c    KB II B B     RS ME   p c    KB II B B     Pr   p c  I KB II B B        Discussion  A    T  Grove  J   Y  Halpern  and D  Koller  Statistical foundations for default rea  oning  In Proc  Thirteenth International Joint Conference on Artificial Intelligence   J CA                 BGHK    F  B acchus     Car     that they can deal with degrees of belief  We  view the fact that the three methods essentially agree when   GHK     Uld RS a  su m e cert ain res t ri c  tions on the form of the knowl e d ge base  which are not assumed in CEW  Is it possible to ex t en d these methods so that they apply to more gen eral knowledge bas e s   In  M   J aeger  A        facts to KB   Jac J b   prevents  appl icatio n of  U is idea  belief bases about some const an t lems we have found trying to  that  prob do this seem dirtlcult but  be viewed as U ru  seq ue ntial updat ing here  Sup pose our knowledge base co ntains two constraints  Pr  pt     u      Pr  p      o   Although we cannot u s u  a l l y apply Jeffrey s rule to such a conj unction  we can a p  ply the rule seq uentially  first u pdating by Pr   p    and then by  Pr   p       et    We have    n     described o u r meth  ods in ilie context of u p d a t i ng by any set of constrai n t s at once  but they can also b e defined  to update b y con straints one at a time  TI e two possibilitie  usual ly give different results  Sequential updating may not p reserve any but the last constraint used  and in general is order dependent  Whether this should be seen  a   a problem  doing  is wh y this issue can  be  ig nored when  B ayesian condi tionin g in general  and in ordinary    KL    l  S   K u l lback and R   A  Leibler  On informa t i o n and su fficiency  Annals of Mathematical  bridge         Swtistics                       LanXO    BGHK     F  B acchus   Physics  volume          B   Paris and A  Yencovska  On the appli ca bi l i t y of max i m u m entropy to inexact rea son i n g   International Jo urn a l of Approximate   PY     J     S ho      J   Reasoning                     B  Paris and A   Vencovska  A method for up dat ing j u st i fy ing minimum cross entropy  In ternational Journal qf Approxi mate Reason ing                          E  Shore  R el ative entropy  probabilistic in ference  and AI  In L  N   Kanal and J   F  Lem  mer  edi tors  Uncertainty in Artificial intelli gence  North  Holland  Amsterdam           S I     
 We consider a setting where an agents uncertainty is represented by a set of probability measures  rather than a single measure  Measureby measure updating of such a set of measures upon acquiring new information is well known to suffer from problems  agents are not always able to learn appropriately  To deal with these problems  we propose using weighted sets of probabilities  a representation where each measure is associated with a weight  which denotes its significance  We describe a natural approach to updating in such a situation and a natural approach to determining the weights  We then show how this representation can be used in decision making  by modifying a standard approach to decision makingminimizing expected regretto obtain minimax weighted expected regret  MWER   We provide an axiomatization that characterizes preferences induced by MWER both in the static and dynamic case      Introduction  Agents must constantly make decisions  these decisions are typically made in a setting with uncertainty  For decisions based on the outcome of the toss of a fair coin  the uncertainty can be well characterized by probability  However  what is the probability of you getting cancer if you eat fries at every meal  What if you have salads instead  Even experts would not agree on a single probability  Representing uncertainty by a single probability measure and making decisions by maximizing expected utility leads to further problems  Consider the following stylized problem  which serves as a running example in this paper   The authors thank Joerg Stoye for useful comments  Work supported in part by NSF grants IIS          IIS          and IIS          by AFOSR grants FA               and FA                and by ARO grant W   NF                 cont back check    broken                    broken                   Table    Payoffs for the robot delivery problem  Acts are in the leftmost column  The remaining two columns describe the outcome for the two sets of states that matter  The bakers delivery robot  T      is delivering        cupcakes from the bakery to a banquet  Along the way  T     takes a tumble down a flight of stairs and breaks some of the cupcakes  The robots map indicates that this flight of stairs must be either ten feet or fifteen feet high  For simplicity  assume that a fall of ten feet results in one broken cupcake  while a fall of fifteen feet results in ten broken cupcakes  T    s choices and their consequences are summarized in Table    Decision theorists typically model decision problems with states  acts  and outcomes  the world is in one of many possible states  and the decision maker chooses an act  a function mapping states to outcomes  A natural state space in this problem is  good broken        where each state is a possible state of the cupcakes  However  all that matters about the state is the number of broken cakes  so we can further restrict to states with either one or ten broken cakes  T     can choose among three acts  cont  continue the delivery attempt  back   go back for new cupcakes  or check   open the container and count the number of broken cupcakes  and then decide to continue or go back  depending on the number of broken cakes  The client will tolerate one broken cupcake  but not ten broken cupcakes  Therefore  if T     chooses cont  it obtains a utility of         if there is only one broken cake  but a utility of         if there are ten broken cakes  If T     chooses to go back   then it gets a utility of    Finally  checking the cupcakes costs        units of utility but is reliable  so if T     chooses check   it ends up with a utility of        if there is one broken cake  and a utility of        if there are ten broken cakes  If we try to maximize expected utility  we must assume some probability over states  What measure should be used  There are two hypotheses that T    entertains      the stairs are ten feet high and     the stairs are fifteen feet high  Each of these places a different probability on states  If the stairs are ten feet high  we can take all of the        states where there is exactly one broken cake to be equally probable  and take the remaining states to have probability    if the stairs are fifteen feet high  we can take all of the C           states where there are exactly ten broken cakes to be equally probable  and take the remaining states to have probability    One way to model T    s uncertainty about the height of the stairs is to take each hypothesis to be equally likely  However  not having any idea about which hypothesis holds is very different from believing that all hypotheses are equally likely  It is easy to check that taking each hypothesis to be equally likely makes check the act that maximizes      utility  but taking the probability that the stairs are fifteen feet high to be     makes back the act that maximizes expected utility  and taking the probability that the stairs are ten feet high to be     makes cont the act that maximizes expected utility  What makes any of these choices the right choice  It is easy to construct many other examples where a single probability measure does not capture uncertainty  and does not result in what seem to be reasonable decisions  when combined with expected utility maximization  A natural alternative  which has often been considered in the literature  is to represent the agents uncertainty by a set of probability measures  For example  in the delivery problem  the agents beliefs could be represented by two probability measures  Pr  and Pr     one for each hypothesis  Thus  Pr  assigns uniform probability to all states with exactly one broken cake  and Pr   assigns uniform probability to all states with exactly ten broken cakes  But this representation also has problems  Consider the delivery example again  Why should T     be sure that there is exactly either one broken cake or ten broken cakes  Of course  we can replace these two hypotheses by hypotheses that say that the probability of a cake being broken is either      or      but this doesnt solve the problem  Why should the agent be sure that the probability is either exactly      or exactly      Couldnt it also be        Representing uncertainty by a set of measures still places a sharp boundary on what measures are considered possible and impossible  A second problem involves updating beliefs  How should beliefs be updated if they are represented by a set of probability measures  The standard approach for updating a single measure is by conditioning  The natural extension of conditioning to sets of measure is measure by measure updating  conditioning each measure on the information  and also removing measures that give the information probability     However  measure by measure updating can produce some rather counterintuitive outcomes  In the delivery example  suppose that a passer by tells T     the information E  the first     cupcakes are good  Assuming that the passerby told the truth  intuition tells us that there is now more reason to believe that there is only one broken cupcake  However  Pr    E places uniform probability on all states where the first     cakes are good  and there is exactly one broken cake among the last      Similarly  Pr     E places uniform probability on all states where the first     cakes are good  and there are exactly ten broken cakes among the last      Pr    E still places probability   on there being one broken cake  just like Pr    Pr     E still places probability   on there being ten broken cakes  There is no way to capture the fact that T     now views the hypothesis Pr   as less likely  even if the passer by had said instead that the first     cakes are all good  Of course  both of these problems would be alleviated if we placed a probability on hypotheses  but  as we have already observed  this leads to other problems  In this paper  we propose an intermediate approach  representing uncertainty using weighted sets of probabilities  That is  each probability measure is associated with a weight  These weights can be viewed as probabilities  indeed  if the set of probabilities is finite  we can normalize them so that they     are effectively probabilities  Moreover  in one important setting  we update them in the same way that we would update probabilities  using likelihood  see below   On the other hand  these weights do not act like probabilities if the set of probabilities is infinite  For example  if we had a countable set of hypotheses  we could assign them all weight    so that  intuitively  they are all viewed as equally likely   but there is no uniform measure on a countable set  More importantly  when it comes to decision making  we use the weights quite differently from how we would use second order probabilities on probabilities  Second order probabilities would let us define a probability on events  by taking expectation  and maximize expected utility  in the usual way  Using the weights  we instead define a novel decision rule  minimax weighted expected regret  MWER   that has some rather nice properties  which we believe will make it widely applicable in practice  If all the weights are    then MWER is just the standard minimax expected regret  MER  rule  described below   If the set of probabilities is a singleton  then MWER agrees with  subjective  expected utility maximization  SEU   More interestingly perhaps  if the weighted set of measures converges to a single measure  which will happen in one important special case  discussed below   MWER converges to SEU  Thus  the weights give us a smooth  natural way of interpolating between MER and SEU  In summary  weighted sets of probabilities allow us to represent ambiguity  uncertainty about the correct probability distribution   Real individuals are sensitive to this ambiguity when making decisions  and the MWER decision rule takes this into account  Updating the weighted sets of probabilities using likelihood allows the initial ambiguity to be resolved as more information about the true distribution is obtained  We now briefly explain MWER  by first discussing MER  MER is a probabilistic variant of the minimax regret decision rule proposed by Niehans      and Savage       Most likely  at some point  weve second guessed ourselves and thought had I known this  I would have done that instead  That is  in hindsight  we regret not choosing the act that turned out to be optimal for the realized state  called the ex post optimal act  The regret of an act a in a state s is the difference  in utility  between the ex post optimal act in s and a  Of course  typically one does not know the true state at the time of decision  Therefore the regret of an act is the worst case regret  taken over all states  The minimax regret rule orders acts by their regret  The definition of regret applies if there is no probability on states  If an agents uncertainty is represented by a single probability measure  then we can compute the expected regret of an act a  just multiply the regret of an act a at a state s by the probability of s  and then sum  It is well known that the order on acts induced by minimizing expected regret is identical to that induced by maximizing expected utility  see     for a proof   If an agents uncertainty is represented by a set P of probabilities  then we can compute the expected regret of an act a with respect to each probability measure Pr  P  and then take the worst case expected regret  The MER  Minimax Expected Regret  rule orders acts according to their worst case expected regret  preferring the act that minimizes the worst case regret  If the set of measures is the set of all probability     measures on states  then it is not hard to show that MER induces the same order on acts as  probability free  minimax regret  Thus  MER generalizes both minimax regret  if P consists of all measures  and expected utility maximization  if P consists of a single measure   MWER further generalizes MER  If we start with a weighted set of measures  then we can compute the weighted expected regret for each one  just multiply the expected regret with respect to Pr by the weight of Pr  and compare acts by their worst case weighted expected regret  Sarver      also proves a representation theorem that involves putting a multiplicative weight on a regret quantity  However  his representation is fundamentally different from MWER  In his representation  regret is a factor only when comparing two sets of acts  the ranking of individual acts is given by expected utility maximization  By way of contrast  we do not compare sets of acts  It is standard in decision theory to axiomatize a decision rule by means of a representation theorem  For example  Savage      showed that if an agents preferences   satisfied several axioms  such as completeness and transitivity  then the agent is behaving as if she is maximizing expected utility with respect to some utility function and probabilistic belief  If uncertainty is represented by a set of probability measures  then we can generalize expected utility maximization to maxmin expected utility  MMEU   MMEU compares acts by their worst case expected utility  taken over all measures  MMEU has been axiomatized by Gilboa and Schmeidler      MER was axiomatized by Hayashi     and Stoye       We provide an axiomatization of MWER  We make use of ideas introduced by Stoye      in his axiomatization of MER  but the extension seems quite nontrivial  We also consider a dynamic setting  where beliefs are updated by new information  If observations are generated according to a probability measure that is stable over time  then  as we suggested above  there is a natural way of updating the weights given observations  using ideas of likelihood  The idea is straightforward  After receiving some information E  we update each probability Pr  P to Pr   E  and take its weight to be Pr   Pr E   supPr P Pr  E   If more than one Pr  P gets updated to the same Pr   E  the sup of all such weights is used  Thus  the weight of Pr after observing E is modified by taking into account the likelihood of observing E assuming that Pr is the true probability  We refer to this method of updating weights as likelihood updating  If observations are generated by a stable measure  e g   we observe the outcomes of repeated flips of a biased coin  then  as the agent makes more and more observations  the weighted set of probabilities of the agent will  almost surely  look more and more like a single measure  The weight of the measures in P closest to the measure generating the observations converges to    and the weight of all other measures converges to    This would not be the case if uncertainty were represented by a set of probability measures and we did measure by measure updating  as is standard  As we mentioned above  this means that MWER converges to SEU  We provide an axiomatization for dynamic MWER with likelihood updat    ing  We remark that a dynamic version of MMEU with measure by measure updating has been axiomatized by Jaffray       Pires       and Siniscalchi       Likelihood updating is somewhat similar in spirit to an updating method implicitly proposed by Epstein and Schneider      They also represented uncertainty by using  unweighted  sets of probability measures  They choose a threshold  with           update by conditioning  and eliminate all measures whose relative likelihood does not exceed the threshold  This approach also has the property that  over time  all that is left in P are the measures closest to the measure generating the observations  all other measures are eliminated  However  it has the drawback that it introduces a new  somewhat arbitrary  parameter   Chateauneuf and Faro     also consider weighted sets of probabilities  they model the weights using what they call confidence functions   although they impose more constraints on the weights than we do  They then define and provide a representation of a generalization of MMEU using weighted sets of probabilities that parallels our generalization of MER  Chateauneuf and Faro do not discuss the dynamic situation  specifically  they do not consider how weights should be updated in the light of new information  The rest of this paper is organized as follows  Section   introduces the weighted sets of probabilities representation  and Section   introduces the MWER decision rule  Axiomatic characterizations of static and dynamic MWER are provided in Sections   and    respectively  We conclude in Section        Weighted Sets of Probabilities  A set P   of weighted probability measures on a set S consists of pairs  Pr  Pr    where Pr         and Pr is a probability measure on S   Let P    Pr    Pr     P      We assume that  for each Pr  P  there is exactly one  such that  Pr     P     We denote this number by Pr   and view it as the weight of Pr  We further assume for convenience that weights have been normalized so that there is at least one measure Pr  P such that Pr       We remark that  just as we do  Chateaunef and Faro     take weights to be in the interval         They impose additional requirements on the weights  For example  they require that the weight of a convex combination of two probability measures is at least as high as the weight of each one  This does not seem reasonable in our applications  For example  an agent may know that one of two measures is generating his observations  and give them both weight    while giving all other distributions weight      In this paper  for ease of exposition  we take the state space S to be finite  and assume that all sets are measurable  We can easily generalize to arbitrary measure spaces    While we could take weights to be probabilities  and normalize them so that they sum to    if P is finite  this runs into difficulties if we have an infinite number of measures in P  For example  if we are tossing a coin  and P includes all probabilities on heads from     to      using a uniform probability  we would be forced to assign each individual probability measure a weight of    which would not work well in the definition of MWER       As we observed in the introduction  one way of updating weighted sets of probabilities is by using likelihood updating  We use P     E to denote the   result of applying likelihood updating to P     Define P  E    sup Pr Pr E       Pr  P   if P  E       set Pr E   sup Pr P Pr  E Pr E  Pr Pr  E    Note that P  E   given a measure Pr  P  there may be several distinct measures Pr in P such that Pr   E   Pr   E  Thus  we take the weight of Pr   E to be the sup of the   possible candidate values of Pr E   By dividing by P  E   we guarantee that Pr E          and that there is some measure Pr such that Pr E      as long as     there is some pair  Pr   Pr   P such that Pr Pr E    P  E   If P  E       we take P     E to be   Pr   E  Pr E     Pr  P      If P  E       then P     E is undefined  In computing P     E  we update not just the probability measures in P  but also their weights  The new weight combines the old weight with the likelihood  Clearly  if all measures in P assign the same probability to the event E  then likelihood updating and measure by measure updating coincide  This is not surprising  since such an observation E does not give us information about the relative likelihood of measures  We stress that using likelihood updating is appropriate only if the measure generating the observations is assumed to be stable  For example  if observations of heads and tails are generated by coin tosses  and a coin of possibly different bias is tossed in each round  then likelihood updating would not be appropriate  It is well known that  when conditioning on a single probability measure  the order that information is acquired is irrelevant  the same observation easily extends to sets of probability measures  As we now show  it can be further extended to weighted sets of probability measures  Proposition    Likelihood updating is consistent in the sense that for all E    E   S   P     E      E     P     E      E    P      E   E     provided that P      E   E    is defined  Proof  By standard results   Pr   E      E     Pr   E      E    Pr    E   E     Since the weight of the measure Pr   E  is proportional to Pr Pr E     the weight of  Pr   E      E  is proportional to Pr Pr E    Pr E    E      Pr Pr E   E     Likewise  the weight of  Pr   E      E  is proportional to Pr Pr E    Pr E    E      Pr Pr E   E     Since  in all these cases  the sup of the weights is normalized to    the weights of corresonding measures in P      E   E      P     E      E  and  P     E      E  must be equal      MWER  We now define MWER formally  Given a set S of states and a set X of outcomes  an act f  over S and X  is a function mapping S to X  For simplicity in this paper  we take S to be finite  Associated with each outcome x  X is a utility      u x  is the utility of outcome x  We call a tuple  S  X  u  a  non probabilistic  decision problem  To define regret  we need to assume that we are also given a set M  X S of feasible acts  called the menu  The reason for the menu is that  as is well known  and we will demonstrate by example shortly   regret can depend on the menu  Moreover  we assume that every menu M has utilities bounded from above  That is  we assume that for all menus M   supgM u g s   is finite  This ensures that the regret of each act is well defined   For a menu M and act f  M   the regret of f with respect to M and decision problem  S  X  u  in state s is     reg M  f  s    sup u g s    u f  s    gM  That is  the regret of f in state s  relative to menu M   is the difference between u f  s   and the highest utility possible in state s  among all the acts in M    The regret of f with respect to M and decision problem  S  X  u  is the worst case regret over all states  max reg M  f  s   sS   S X u   f    reg M  and usually omit the superscript  S  X  u  if it We denote this as is clear from context  If there is a probability measure Pr over the states  then we can consider the probabilistic decision problem  S  X  u  Pr   The expected regret of f with respect to M is X reg M Pr  f     Pr s reg M  f  s   sS  If there is a set P of probability measures over the states  then we consider the P decision problem  S  X  u  P   The maximum expected regret of f  M with respect to M and  S  X  u  P  is   X Pr s reg M  f  s    reg M P  f     sup PrP  sS  Finally  if beliefs are modeled by weighted probabilities P     then we consider the P    decision problem  S  X  u  P      The maximum weighted expected regret of f  M with respect to M and  S  X  u  P     is   X Pr s reg M  f  s    reg M P    f     sup Pr PrP  sS  The MER decision rule is thus defined for all f  g  X S as  S X u   f  S X u M P g iff reg M P   S X u    f    reg M P   g      Stoye      assumes that  for each menu M   there is a finite set A M of acts such that M consists of all the convex combinations of the acts in AM   Our assumption is clearly much weaker than Stoyes       cont back check    broken cake Payoff Regret                                   broken cakes Payoff Regret                                  Table    Payoffs and regrets for delivery example   cont back check new    broken cake Payoff Regret                                                  broken cakes Payoff Regret                                                 Table    Payoffs and regrets for the delivery problem with a new choice added  That is  f is preferred to g if the maximum expected regret of f is less than that  S X u  S X u of g  We can similarly define  M reg    S X u M Pr   and  M P   by replacing reg M P  S X u    S X u    S X u   by reg M   reg M Pr   and reg M P     respectively  Again  we usually omit the superscript  S  X  u  and subscript Pr or P     and just write  M   if it is clear from context  To see how these definitions work  consider the delivery example from the introduction  There are        states with one broken cake  and C           states with ten broken cakes  The regret of each action in a state depends only on the number of broken cakes  and is given in Table    It is easy to see that the action that minimizes regret is check   with cont and back having equal regret  If we represent uncertainty using the two probability measures Pr  and Pr     the expected regret of each of the acts with respect to Pr   resp   Pr     is just its regret with respect to states with one  resp  ten  broken cakes  Thus  the action that minimizes maximum expected regret is again check   As we said above  the ranking of acts based on MER or MWER can change if the menu of possible choices changes  For example  suppose that we introduce a new choice in the delivery problem  whose gains and losses are twice those of cont  resulting in the payoffs and regrets described in Table    In this new setting  cont has a lower maximum expected regret           than check            so MER prefers cont over check   Thus  the introduction of a new choice can affect the relative order of acts according to MER  and MWER   even though other acts are preferred to the new choice  By way of contrast  the decision rules MMEU and SEU are menu independent   the relative order of acts according to MMEU and SEU is not affected by the addition of new acts  We next consider a dynamic situation  where the agent acquires information  Specifically  in the context of the delivery problem  suppose that T    learns Ethe first     items are good  Initially  suppose that T          has no reason to believe that one hypothesis is more likely than the other  so assigns both hypotheses weight    Note that P   E        and Pr    E    C          C                  Thus  P     E     Pr    E       Pr     E  C             C              We can also see from this example that MWER interpolates between MER and expected utility maximization  Suppose that a passer by tells T     that the first N cupcakes are good  If N      MWER with initial weights   is the same as MER  On the other hand  if N       then the likelihood of Pr   is    and the only measure that has effect is Pr    which means minimizing maximum weighted expected regret is just maximizing expected utility with respect to Pr    If     N        then the likelihoods  hence weights  of Pr  and Pr   are          and C     N     C               N          N          Thus  as N increases  the weight of Pr   goes to    while the weight of Pr  stays at        An axiomatic characterization of MWER  We now provide a representation theorem for MWER  That is  we provide a collection of properties  i e   axioms  that hold of MWER such that a preference order on acts that satisfies these properties can be viewed as arising from MWER  To get such an axiomatic characterization  we restrict to what is known in the literature as the Anscombe Aumann  AA  framework      where outcomes are restricted to lotteries  This framework is standard in the decision theory literature  axiomatic characterizations of SEU      MMEU      and MER         have already been obtained in the AA framework  We draw on these results to obtain our axiomatization  Given a set Y  which we view as consisting of prizes   a lottery over Y is just a probability with finite support on Y   Let  Y   consist of all finite probabilities over Y   In the AA framework  the set of outcomes has the form  Y    So now acts are functions from S to  Y     Such acts are sometimes called Anscombe Aumann acts   We can think of a lottery as modeling objective uncertainty  while a probability on states models subjective uncertainty  thus  in the AA framework we have both objective and subjective uncertainty  The technical advantage of considering such a set of outcomes is that we can consider convex combinations of acts  If f and g are acts  define the act f        g to be the act that maps a state s to the lottery f  s         g s   In this setting  we assume that there is a utility function U on prizes in Y   The utility of a lottery l is just the expected utility of the prizes obtained  that is  X l y U  y   u l     yY   l y      This makes sense since l y  is the probability of getting prize y if lottery l is played  The expected utility of an act f with respect to a probability Pr is then       P just u f     sS Pr s u f  s    as usual  We also assume that there are at least two prizes y  and y  in Y   with different utilities U  y    and U  y     Given a set Y of prizes  a utility U on prizes  a state space S  and a set P   S  Y   u of preference of weighted probabilities on S  we can define a family  M P   orders on Anscombe Aumann acts determined by weighted regret  one per menu M   as discussed above  where u is the utility function on lotteries determined S  Y   u by U   For ease of exposition  we usually write  S Y U   M P   rather than  M P   We state the axioms in a way that lets us clearly distinguish the axioms for SEU  MMEU  MER  and MWER  The axioms are universally quantified over acts f   g  and h  menus M and M    and p          We assume that f  g  M when we write f  M g   We use l to denote a constant act that maps all states to l  Axiom     Transitivity  f  M g  M h  f  M h  Axiom     Completeness  f  M g or g  M f   Axiom     Nontriviality  f M g for some acts f and g and menu M   Axiom     Monotonicity  If  f  s      f  s     g s      g s   for all s  S  then f  M g  Axiom     Mixture Continuity  If f M g M h  then there exist q  r         such that qf       q h M qf    q h  g M rf    r h  rf       r h  Menu independent versions of Axioms    are standard  Clearly  menuindependent versions of  Axioms          and   hold for MMEU  MER  and SEU  Axiom   is assumed in all the standard axiomatizations  and is used to get a unique representation  Axiom     Ambiguity Aversion  f M g  pf       p g  M pf    p g  g  Ambiguity Aversion says that the decision maker weakly prefers to hedge her bets  It also holds for MMEU  MER  and SEU  and is assumed in the axiomatizations for MMEU and MER  It is not assumed for the axiomatization of SEU  since it follows from the Independence axiom  discussed next  Independence also holds for MWER  provided that we are careful about the menus involved  Given a menu M and an act h  let pM       p h be the menu  pf       p h   p  M      Stoye      assumed that menus were convex  so that if f  g  M   then so is pf       p g  We do not make this assumption  although our results would still hold if we did  with the axioms slightly modified to ensure that menus are convex   While it may seem reasonable to think that  if f and g are feasible for an agent  then so is pf       p g  this not always the case  For example  it may be difficult for the agent to randomize  or it may be infeasible for the agent to randomize with probability p for some choices of p  e g   for p irrational         Axiom     Independence  f  M g iff pf       p h  pM   p h pg       p h  Independence holds in a strong sense for SEU  since we can ignore the menus  The menu independent version of Independence is easily seen to imply Ambiguity Aversion  Independence does not hold for MMEU  Although we have menu independence for SEU and MMEU  we do not have it for MER or MWER  The following two axioms are weakened versions of menu independence that do hold for MER and MWER  Axiom     Menu independence for constant acts  If l and  l   are constant acts  then l  M  l   iff l  M   l     In light of this axiom  when comparing constant acts  we omit the menu  An act h is never strictly optimal relative to M if  for all states s  S  there is some f  M such that  f  s      h s     Axiom     Independence of Never Strictly Optimal Alternatives  INA   If every act in M  is never strictly optimal relative to M   then f  M g iff f  MM  g  Axiom      Boundedness of menus  For every menu M   there exists a lottery  l   Y   such that for all f  M and s  S   f  s     l   The boundedness axiom enforces the assumption that we made earlier that every menu has utilities that are bounded from above  Recall that this assumption is necessary for regret to be finite  We now present our representation theorem for MWER  Roughly  the representation theorem states that a family of preferences satisfies Axioms     if and only if it has a MWER representation with respect to some utility function and weighted probabilities  In the representation theorem for SEU      not only is the utility function unique  up to affine transformations  so that we can replace U by aU   b  where a     and b are constants   but the probability is unique as well  Similarly  in the MMEU representation theorem of Gilboa and Schmeidler      the utility function is unique  and the set of probabilities is also unique  as long as one assume that the set is convex and closed  To get uniqueness in the representation theorem for MWER  we need to consider a different representation of weighted probabilities  Define a sub probability measure p on S to be like a probability measure  i e   a function mapping measurable subsets of S to        such that p T  T      p T     p T    for disjoint sets T and T     without the requirement that p      We can identify a weighted probability distribution  Pr    with the sub probability measure  Pr   Note that given a sub probability measure p  there is a unique pair    Pr  such that P    Pr  we simply take    p S  and Pr   p    A set C of sub probability measures is downward closed if  whenever p  C and q  p  then q  C  We get a unique set of sub probability measures in our representation theorem if we restrict to sets that are convex  downward closed  closed  and contain at least one  proper  probability measure   The latter requirement corresponds to      having Pr     for some Pr  P      For convenience  we will call a set regular if it is convex  downward closed  and closed  We identify each set of weighted probabilities P   with the set of subprobability measures C P         Pr    Pr  Pr    P          Pr    Note that if    Pr   P     then C P     includes all the sub probability measures between the all zero measure and Pr Pr  We need to restrict to closed and convex sets of sub probability measures to get uniqueness in the representation of MWER for much the same reason that we need to restrict to closed and convex sets to get uniqueness in the representation of MMEU  To see why convexity is needed  consider the delivery example and the expected regrets in Table    and the distribution a Pr       a  Pr     for some a          The weighted expected regret of any act with respect to a Pr       a  Pr   is bounded above by the maximum weighted expected regret of that act with respect to Pr  and Pr     Therefore  adding a Pr     a  Pr   to P   for some weight a         does not change the resulting family of preferences  Similarly  we need to restrict to closed sets for uniqueness  since if we start with a set C of sub probability measures that is not closed  taking the closure of C would result in the same family of preferences  While convexity is easy to define for a set of sub probability measures  there seems to be no natural notion of convexity for a set P   of weighted probabilities  Moreover  the requirement that P   is closed is different from the requirement that C P     is closed  The latter requirement seems more reasonable  For example  fix a probability measure Pr  and let P          Pr         Pr     Pr    Pr   Thus  P   essentially consists of a single probability measure  namely Pr  with weight    all the weighted probability measures     Pr   have no impact  This represents the uncertainty of an agent who is sure that that Pr is true probability  Clearly P   is not closed  since we can find a sequence Prn such that     Prn        Pr   although     Pr     P     But C Pr    is closed  Restricting to closed  convex sets of sub probability measures does not suffice to get uniqueness  we also need to require downward closedness  This is so because if p is in C  then adding any q  p to the set leaves all regrets unchanged  Finally  the presence of a proper probability measure is also required  since for any a          scaling each element in the set C by a leaves the family of preferences unchanged  In summary  if we consider arbitrary sets of sub probability measures  then the set of sub probability measures that represent a given family of MWER preferences would be unique if we required the set to be regular and contain a probability measure  Theorem    For all Y   U   S  and P     the family of preference orders  S Y U M P   satisfies Axioms      Conversely  if a family of preference orders  M on the acts in  Y  S satisfies Axioms      then there exist a a utility U on Y and a weighted set P   of probabilities on S such that C P     is regular and    M   S Y U M P     Moreover  U is unique up to affine transformations  and C P        is unique in the sense that if Q   represents  M   and C Q     is regular  then C Q       C P      Showing that  S Y U M P   satisfies Axioms     is fairly straightforward  we leave details to the reader  The proof of the converse is quite nontrivial  although it follows the lines of the proof of other representation theorems  We provide an outline of the proof here  details can be found in the appendix  Using standard techniques  we can show that the axioms guarantee the existence of a utility function U on prizes that can be extended to lotteries in the obvious way  so that l    l   iff U  l   U  l    We then use techniques of Stoye      to show that it suffices to get a representation theorem for a single menu  rather than all menus  the menu consisting of all acts f such that U  f  s      for all states s  S  This allows us to use techniques in the spirit of those used by by Gilboa and Schmeidler     to represent  unweighted  MMEU  However  there are technical difficulties that arise from the fact that we do not have a key axiom that is satisfied by MMEU  C independence  discussed below   The heart of the proof involves dealing with the lack of C independence  as we said  the details can be found in the appendix  It is instructive to compare Theorem   to other representation results in the literature  Anscombe and Aumann     showed that the menu independent versions of axioms    and   characterize SEU  The presence of Axiom    menuindependent Independence  greatly simplifies things  Gilboa and Schmeidler     showed that axioms    together with one more axiom that they call Certaintyindependence characterizes MMEU  Certainty independence  or C independence for short  is a weakening of independence  which  as we observed  does not hold for MMEU   where the act h is required to be a constant act  Since MMEU is menu independent  we state it in a menu independent way  Axiom      C Independence  If h is a constant act  then f   g iff pf       p h   pg       p h  As we observed  in general  we have Ambiguity Aversion  Axiom    for regret  Betweenness     is a stronger notion than ambiguity aversion  which states that if an agent is indifferent between two acts  then he must also be indifferent among all convex combinations of these acts  While betweenness does not hold for regret  Stoye      gives a weaker version that does hold  A menu M has state independent outcome distributions if the set L s     y   Y     f  M  f  s    y  is the same for all states s  Axiom     If h is a constant act  and M has state independent outcome distributions  then h M f  pf       p h M pf    p h  f  The assumption that the menu has state independent outcome distributions is critical in Axiom     Stoye      shows that Axioms    together with Axiom    characterize MER   Non probabilistic regret  which we denote REG  can be viewed as a   Stoye  actually worked with choice correspondences  see Section          cont       cont     back back check    broken cake Payoff Regret                                               broken cakes Payoff Regret                                               Table    Payoffs and regrets for the delivery problem  with cont mixed with the constant act back    cont       cont     back back check   check      broken cake Payoff Regret                                                                broken cakes Payoff Regret                                                             Table    Payoffs and regrets for the delivery problem  with state independent outcome distributions  special case of MER  where P consists of all distributions  This means that it satisfies all the axioms that MER satisfies  As Stoye      shows  REG is characterized by Axioms    and one additional axiom  which he calls Symmetry  We omit the details here  The assumption that the menu has state independent outcome distributions is critical in Axiom     For example  suppose that we change the payoffs in the delivery problem so that cont has the same maximum expected regret as back            However  as seen in Table       cont      back has lower maximum expected regret          than cont            showing that the variant of Axiom    without the state independent outcome distribution requirement does not hold  Although Axiom    is sound for unweighted minimax expected regret  it is no longer sound once we add weights  For example  suppose that we modified the delivery problem so that all states we care about have the same outcome distributions  as required by Axiom     Then the payoffs and regrets will be those shown in Table    Suppose that the weights on Pr  and Pr   are   and      respectively  Then cont has the same maximum weighted expected regret as back            However     cont      back has lower maximum weighted expected regret          than cont  showing that Axiom    with weighted probabilities does not hold  Table   describes the relationship between the axioms characterizing the decision rules        Ax           Ind C Ind Ax     Symmetry  SEU X X X X X  REG X X  MER X X  X X  X  MWER X X  MMEU X X  Table    Characterizing axioms for several decision rules      Characterizing MWER with Likelihood Updating  We next consider a more dynamic setting  where agents learn information  For simplicity  we assume that the information is always a subset E of the state space  If the agent is representing her uncertainty using a set P   of weighted probability measures  then we would expect her to update P   to some new set Q   of weighted probability measures  and then apply MWER with uncertainty represented byQ     In this section  we characterize what happens in the special case that the agent uses likelihood updating  so that Q      P     E   For this characterization  we assume that the agent has a family of preference orders  E M indexed not just by the menu M   but by the information E  Each preference order  E M satisfies Axioms      since the agent makes decisions after learning E using MWER  Somewhat surprisingly  all we need is one extra axiom for the characterization  we call this axiom MDC  for menu dependent dynamic consistency  To explain the axiom  we need some notation  As usual  we take f Eh to be the act that agrees with f on E and with h off of E  that is   f  s  if s  E f Eh s    h s  if s    E  In the delivery example  the act check can be thought of as  cont E back    where E is the set of states where there is only one broken cake  Roughly speaking  MDC says that you prefer f to g once you learn E if and only if  for any act h  you also prefer f Eh to gEh before you learn anything  This seems reasonable  since learning that the true state was in E is conceptually similar to knowing that none of your choices matter off of E  To state MDC formally  we need to be careful about the menus involved  Let M Eh    f Eh   f  M    We can identify unconditional preferences with preferences conditional on S  that is  we identify  M with  S M   We also need to restrict the sets E to which MDC applies  Recall that conditioning using   likelihood updating is undefined for an event such that P  E       That is  Pr Pr E      for all Pr  P  As is commonly done  we capture the idea that conditioning on E is possible using the notion of a non null event  Definition    An event E is null if  for all f  g   Y  S and menus M with      f Eg  g  M   we have f Eg M g  MDC  For all non null events E  f  E M g iff f Eh  MEh gEh for some h  M    The key feature of MDC is that it allows us to reduce all the conditional preference orders  E M to the unconditional order  M   to which we can apply Theorem    Theorem    For all Y   U   S  and P     the family of preference orders  S Y U P    E M    for events E such that P  E      satisfies Axioms     and MDC  Conversely  if a family of preference orders  E M on the acts in  Y  S satisfies Axioms     and MDC  then there exists a utility U on Y and a weighted set P   of probabilities on S such that C P     is regular  and for all non null E   E M   S Y U P    E M   Moreover  U is unique up to affine transformations  and C P     is unique in the sense that if Q   represents  E M   and C Q     is regular  then C Q       C P      Proof  Since  M   S M satisfies Axioms      there must exist a weighted set P   of probabilities on S and a utility function U such that f  M g iff f  S Y U M P      g  We now show that if E is non null  then P  E       and f  E M g iff  S X u  f  M P    E g     For the first part  it clearly is equivalent to show that if P  E       then E   is null  So suppose that P  E       Then Pr Pr E      for all Pr  P  This means that Pr Pr s      for all Pr  P and s  E  Thus  for all acts f and g  reg M P    f Eg P     supPrP Pr P sS Pr s reg M  f Eg  s    Pr   supP M  f  s  PrP sE Pr s reg     sE c Pr s reg  g  s    P M   supPrP Pr sS Pr s reg M  g  s    reg M P    g   Thus  f Eg M g for all acts f  g and menus M containing f Eg and g  which means that E is null    For the second part  we first show that if P  E       then for all f  h  M   we have that   reg MEh P    f Eh    P  E reg M P    E  f      Although we do not need this fact  it is worth noting that the MWER decision rule has the property that f Eh  M Eh gEh for some act h iff f Eh  M Eh gEh for all acts h  Thus  this property follows from Axioms            We proceed as follows           reg MEh P    f Eh    P supPrP Pr sS Pr s reg MEh  f EH  s  P supPrP Pr Pr E  sE Pr s    E reg M  f  s  P  Pr sE c Pr s reg  h   h  s    P supPrP  Pr Pr E  sE Pr s E reg M  s  f     P   supPrP P  E Pr E sE Pr s E reg M  f  s   since Pr E   sup Pr P Pr  E Pr E         Pr Pr  E      P  E   P  E   reg M P    E  f     Thus  for all h  M   reg MEh P    f Eh   reg MEh P    gEh        iff P  E   reg M P    E  f    P  E   reg M P    E  g  iff reg M P    E  f    reg M P    E  g   It follows that the order induced by P   satisfies MDC  Moreover  if     and MDC hold  then for a weighted set P   that represents  M   we have f  E M g iff for some h  M  f Eh  MEh gEh iff reg M P    E  f    reg M P    E  g   as desired  Finally  the uniqueness of C P     follows from Theorem    which says that the family  S M of preferences is already sufficient to guarantee the uniqueness of C P      Analogues of MDC have appeared in the literature before in the context of updating preference orders  In particular  Epstein and Schneider     discuss a menu independent version of MDC  although they do not characterize updating in their framework  Sinischalchi      also uses an analogue of MDC in his axiomatization of measure by measure updating of MMEU  Like us  he starts with an axiomatization for unconditional preferences  and adds an axiom called constant act dynamic consistency  CDC   somewhat analogous to MDC  to extend the axiomatization of MMEU to deal with conditional preferences      Dynamic Inconsistency  There is an important issue when one attempts to apply MWER with likelihood updating to dynamic decision problems  If you want to execute a plan  at every step youll need to stick with that plan and execute the corresponding part of the plan  However  after following the initial steps of an ex ante optimal plan       a MWER agent may no longer wish to adhere to the plan  In such a situation  the agent is said to have dynamically inconsistent preferences  Dyanmic inconsistency is well known to hold for regret  Indeed  as Epstein and Le Breton     show  dynamic inconsistency arises for any non Bayesian approach to decision making  i e   any approach that does not involve maximizing expected utility  that satisfies certain minimal assumptions  Not surprisingly  it arises for MWER as well  In the rest of this section  we discuss the problem and some standard approaches to dealing with it  and illustrate some subtleties that arise in dealing with it in the context of MWER  To understand the problem in the context of regret  consider the two stage decision problem of having dinner  represented as a decision tree in Figure    Solid circles denote decision points  and empty circles denote points where nature reveals information to the agent  The decision tree also includes information about what states are considered possible at each node  The set of states considered possible at the root is always the entire state space  and natures actions at each nature decision point partitions the set of possible states   m  b   Italian restaurant  Chinese restaurant  stirfry  plain rice   m      b    m    b              m    b          Figure    Dynamic inconsistency example  First  you have to choose between a Chinese restaurant and an Italian restaurant  Once you have arrived at a particular restaurant  you cannot change your mind and go to another  so in the second stage you must order something from the menu at the chosen restaurant  Your utility is a combination of how much you enjoy the food  and whether you get an allergic reaction  Initially  you know that there are two possible states  you must be either allergic to MSG  state m  or to basil  state b   but not both  Assume that all Italian foods will have traces of basil  and Chinese stir fry has MSG but plain rice does not  However  you do not enjoy eating plain rice  so the utility of ordering rice is    Suppose that you make decisions using the minimax regret decision rule  viewing a plan  i e   a strategy  as an act  A straightforward computation      shows that  ex ante  going to the Chinese restaurant and ordering plain rice has the lowest regret      However  if you go to the Chinese restaurant  the choice of going to the Italian restaurant is now irrelevant  If we now compute regret with respect to the menu of the two remaining choices  then the regret of ordering stir fry is lower     than that of ordering rice      You thus end up ordering the stir fry  The plan of going to the Chinese restaurant and ordering plain rice cannot be carried out  More generally  dynamic consistency requires that the plan considered optimal ex ante continues to be considered optimal at any later time  As we said earlier  Epstein and Le Breton     show that dynamic inconsistency will arise for essentially all non Bayesidan decision rules  A standard approach for dealing with this lack of dynamic consistency in the literature is to consider sophsticated agents  who are aware of the potential for dynamic inconsistency  and thus use backward induction to determine the feasible plans  In the restaurant example  a sophisticated agent believes correctly that she will prefer stir fry over rice  once she is at the Chinese restaurant  Therefore  she no longer considers going to the Chinese restaurant and ordering plain rice a viable plan  The only feasible options are going to the Italian restaurant  or having stir fry at the Chinese restaurant  A subtlety arises when trying to apply backward induction to menu dependent decision rules  which menu do we use when comparing the viable plans  For example  in the restaurant example  do we use the menu consisting of all three plans  or the menu consisting of just the viable plans  It turns out not to matter in this examplewith respect to both menus  going to the Italian restaurant minimizes regret  However  in general  the choice of menu can matter  Hayashi     uses the menu of viable plans in computing for minimax expected regret agents in optimal stopping problems  but it seems to us that both choices  and perhaps others  can be justified  A second subtlety that arises when considering sophisticated agents  What choice do they make when they are indifferent between two plans  Sinischalchi      axiomatizes consistent planning  with menu independent preferences over plans   which augments backward induction with a tie breaking assumption  This tie breaking assumption in consistent planning allows an agent to commit to a plan as long as each stage of the plan is considered to be one of the best at each local decision node  In order to axiomatize consistent planning  Siniscalchi must assume that the agent has preferences that are more general than preferences over plans  Rather  the agent must be assumed to have preferences over decision trees  such as that in Figure     Plans are the special case of decision trees with no branching at decision nodes  we can identify a decision tree with a set of plans  essentially  the branches in the decision tree   Sophistication is captured by an axiom that says  roughly  that the agent is indifferent between a decision tree and the same tree with a non optimal  based on backward induction  plan removed  Preferences over decision trees are similar in spirit to preferences over menus       If we try to apply Siniscalchis approach to regret  we encounter further difficulties  In a menu independent setting  we can compare two decision trees      by comparing the best plans in each decision tree  if we identify a decision tree with a set of plans   But once menus become relevant  we must decide what menu to use when making this comparison  It is not clear which menu to choose  What we really have here are menus over menus  it is not even clear how to apply regret in this setting  Defining and axiomatizing consistent planning in a regret based setting remains an open problem      Conclusion  We proposed an alternative belief representation using weighted sets of probabilities  and described a natural approach to updating in such a situation and a natural approach to determining the weights  We also showed how weighted sets of probabilities can be combined with regret to obtain a decision rule  MWER  and provided an axiomatization that characterizes static and dynamic preferences induced by MWER  We have considered preferences indexed by menus here  Stoye      used a different framework  choice functions  A choice function maps every finite set M of acts to a subset M  of M   Intuitively  the set M  consists of the best acts in M   Thus  a choice function gives less information than a preference order  it gives only the top elements of the preference order  The motivation for working with choice functions is that an agent can reveal his most preferred acts by choosing them when the menu is offered  In a menu independent setting  the agent can reveal his whole preference order  to decide if f  g  it suffices to present the agent with a choice among  f  g   However  with regret based choices  the menu matters  the agents most preferred choice s  when presented with  f  g  might no longer be the most preferred choice s  when presented with a larger menu  Thus  a whole preference order is arguably not meaningful with regret based choices  Stoye      provides a representation theorem for MER where the axioms are described in terms of choice functions  The axioms that we have attributed to Stoye are actually the menu based analogue of his axioms  We believe that it should be possible to provide a characterization of MWER using choice functions  although we have not yet proved this  Finally  we briefly considered the issue of dynamic consistency and consistent planning  As we showed  making this precise in the context of regret involves a number of subtleties  We hope to return to this issue in future work   A  Proof of Theorem    We show here that if a family of menu dependent preferences  M satisfies axioms       then  M can be represented as minimizing expected regret with respect to a set of weighted probabilities and a utility function  Since the proof is somewhat lengthy and complicated  we split it into several steps  each in a separate subsection        A    Simplifying the Problem  Our proof starts in much the same way as the proof by Stoye      of a representation theorem for regret  Lemma   guarantees the existence of a utility function U on prizes that can be extended to lotteries in the obvious way  so that l    l   iff U  l   U  l    In other words  preferences over all constant acts are represented by the maximization of U on the corresponding lotteries that the constant acts map to  Lemma   is a consequence of standard results  Our menus are arbitrary sets of acts  as opposed to convex hulls of a finite number of acts in       Lemma   shows that Stoyes technique can be adapted to work when menus are arbitrary sets of acts  Finally  following Stoye       we reduce the proof of existence of a minimax weighted regret representation for the family  M to the proof of existence of a minimax weighted regret representation for a single menu independent preference ordering    Lemma     Lemma    If Axioms            and   hold  then there exists a nonconstant function U   X  R  unique up to positive affine transformations  such that for all constant acts l and  l   and menus M   X X l  y U  y   l y U  y   l  M  l     y  l  y       y  l  y      Proof  By menu independence for constant acts  the family of preferences  M all agree when restricted to constant acts  The lemma then follows from standard results  see  e g          since menu independence for constant acts  combined with independence  gives the standard independence  substitution  axiom from expected utility theory  P As is commonly done  given U   we define u l     y  l y     l y U  y   Thus  u l  is the expected utility of lottery l  We extend u to contsant acts by taking u l     u l   Thus  Lemma   says that  for all menus M   l    l   iff u l    u l    If c is the utility of some lottery  let lc be a constant lottery that u lc     c  The following is now immediate  We state it as a lemma so that we can refer to it later  Lemma    u lc    u lc   iff lc   lc   similarly  u lc     u lc   iff lc  lc   and u lc     u lc   iff lc  lc   The key step in showing that we can reduce to a single menu is to show that  roughly speaking  for each menu  there exists a menu dependent function gM such that u gM  s      supf M u f  s    Stoye      proved a similar result  but he assumed that all menus were obtained by taking the convex hull of a finite set of acts  Because we allow arbitrary bounded menus  this result is not quite true for us  For example  suppose that the range of u is        Then there may be a menu M such that supf M u f  s        so  supf M u f  s        But there is no act g such that u g s        since u is bounded below by    The following weakening of this result suffices for our purpose        Lemma    There exists a utility function U such that for every menu M   there exists o         and constant act l such that for all f  g  M   f  M g  t f    t M  t g   where t has the form t f     of       o l and t M      t f     f  M    Moreover  there exists an act gt M  such that u gt M   s      supf t M  u f  s   for all s  S  Proof  The nontriviality and monotonicity axioms imply there must exist prizes x and y such that U  x    U  y   We consider four cases  Case    The range of U is bounded above and below  Then we can rescale so that the range of U is         Thus  there must be prizes x and y such that U  x      and U  y       For all c          there must be a prize x that is a convex combination of x and y such that u x     c  so we can clearly define a function gM such that  for all s  S  we have u gM  s      supf M u f  s    Furthermore  we know that such a gM exists because it can be formed as an act which maps each state to an appropriate lottery over the prizes x and y  More generally  we know that an act with a certain utility profile exists if its utility for each state is within the range of U   This fact will be used in the other cases as well  Thus  in this case we can take t to be the identity  i e   o       Case    The range of U is       Again  for all c        there must exist a prize x such that u x    c  Since menus are assumed to be bounded above  we can again define the required function g and take o      Case    The range of U is bounded above and unbounded below  Then we can assume without loss of generality that the range is        and for all c in the range  there is a prize x such that u x    c  For all menus M   o      and acts f  g  M   by Independence  we have that f  M g  of       o l   oM   o l  og       o l    There exists an o     such that for all s  S     sup ou f  s         o      f M  Let t f     of    o l   Clearly there exists an act gt M  such that u gt M   s      supf t M  u f  s   for all s  S  Case    The range of U is bounded below and unbounded above  By the upper boundedness axiom  every menu has an upper bound on its utility range  Therefore  for every menu M   o      and all acts f and g in M   by Independence    f  M g  of       o l   oM   o l  og       o l     There exists o     such that for all s  S   sup ou f  s         o u l   s        f M   Let t f     of       o l    Again  it is easy to see that gt M  exists        In light of Lemma    we henceforth assume that the utility function u derived from U is such that its range is either                        or        In any case  its range always includes         Before proving the key lemma  we establish some useful notation for acts and utility acts  Given a utility act b  let fb   the act corresponding to b  be the act such that fb  s    lb s    if such an act exists  Conversely  let bf   the utility act corresponding to the act f   be defined by taking bf  s    u f  s    Note that monotonicity implies that if fb   gb   then f M g for all menus M   That is  only utility acts matter  If c is a real  we take c to be the constant utility act such that c  s    c for all s  S  Lemma    Let M  be the menu consisting of all acts f such that      bf        Then  U  P     represents  M   i e    M    S X U M   P     iff  U  P   represents  M for all menus M   Proof  Our arguments are similar in spirit to those of Stoye       By Lemma    there exists t such that t f     of       o h for a constant function h such that f  M g iff t f    t M  t g   moreover  for this choice of t  the act gt M  defined in Lemma   exists  By Independence          t f     gt M       t M      gt M   t g    gt M            Let M  be the menu that contains all acts with utilities in         By INA  we know that for all acts f and g  and menus M for which gM is defined  we have         f  M g iff f   gM  M  g   gM           t f    t M  t g  iff  This is because acts of the form    f      gM are never strictly optimal with respect to the menu    M      gM   At every state there must be some act in    M      gM that has utility    namely  the mixture that involves the act argmaxf M u f  s    Thus          f  M g iff t f     gt M   M  t g    gt M            Since the MWER representation also satisfies Independence and INA  we know that for all menus M   and acts f and g in M           t f     gt M   S X U t g    gt M      P   M         Therefore  to show that  M has a MWER representation with respect to  U  P      it suffices to show that  M  has a MWER representation with respect to  U  P      S X U f  S X U M P   g  t f    t M  P   t g    In the sequel  we drop the menu subscript when we refer to the family of preferences  and just write    to denote  M     by Lemma    it suffices to consider  M         A    Defining a functional on utility acts  As we said  Stoye      also started his proof of a representation theorem for MER by reducing to a single preference order  M    He then noted that  the expected regret of an act f with respect to a probability Pr and menu M  is just the negative of the expected utility of f   Thus  the worst case expected regret of f with respect to a set P of probability measures is the negative of the worstcase expected utility of f with respect to P  Thus  it sufficed for Stoye to show that  M  had an MMEU representation  which he did by showing that  M  satisfied Gilboa and Schmeidlers     axioms for MMEU  and then appealing to their representation theorem  This argument does not quite work for us  because now  M  does not satisfy the C independence axiom   This is because our preference order  M  is based on weighted regret  not regret   However  we can get a representation theorem for weighted regret by using some of the techniques used by Gilboa and Schmeidler to get a representation theorem for MMEU  appropriately modified to deal with lack of C independence  Specifically  like Gilboa and Schmeidler  we define a functional I on utility acts such that the preference order on utility acts is determined by their value according to I  see Lemma     Using I  we can then determine the weight of each probability in  S   and prove the desired representation theorem  Recall that u represents   on constant acts  and that only utility acts matter to    The space of all utility acts is the Banach space B of real valued functions on S  Let B  be the set of nonpositive functions in B  where the function b is nonpositive if b s     for all s  S  We now define a functional I on utility acts in B  such that for all f  g with bf   bg  B    we have I bf    I bg   iff f   g  Let Rf       l    f    If    b        then fb exists  and we define I b    inf Rfb    For the remaining b  B    we extend I by homogeneity  Let   b       minsS b s    Note that if b  B    then    b   b          so we define I b      b  I b   b        Lemma    If bf  B    then f  lI b f   Proof  Suppose that bf  B  and  by way of contradiction  that lI b  f   If f   f  l    then it must be the case that I bf        since I bf      by definition of inf  and f  l   lo for all o     by Lemma    so I bf     o for all o       Therefore  f  lI b   Otherwise  since bf  B    by monotonicity  we must have f     l   f   and thus l   f  lI b   By mixture continuity  there is some q         f   such that q  l        q   lI b  l  q I bf    f   contradicting the fact that I b  f  is the greatest lower bound of Rf           If  on the other hand  lI b  f   then lI b  f   lc for some c  R  If f  f  f  lc then it must be the case that I bf     c  I bf    c since lc   lc   and I bf    c since for all c   c  lc  f  lc    Otherwise  lI b  f  lc   and by mixture continuity  there is some q         f   such that q lI bf      q lc  f   Since qI bf     q c   I bf    this contradicts the fact that I bf   is a lower bound of Rf   Therefore  it must be the case that  lI b  f  f   We can now show that I has the required property  Lemma    For all acts f  g such that bf   bg  B    f   g iff I bf    I bg      Proof  Suppose that bf   bg  B    By Lemma    lI b  f and g  lI b   Thus  g  f      f   g iff lI bf     lI bg     and by Lemma    lI bf     lI bg   iff I bf    I bg     In order to invoke a standard separation result for Banach spaces  we extend the definition of I to the Banach space B  We extend I to B by taking I b    I b   for b  B  B    where for all b  B  b is defined as   b s   if b s       b  s       if b s       Clearly b  B  and b   b if b  B    We show that the axioms guarantee that I has a number of standard properties  Since we have artificially extended I to B  our arguments require more cases than those in       We remark that such an artificial extension seem unavoidable in our setting   Moreover  we must work harder to get the result that we want  We need different arguments from that for MMEU      since the preference order induced by MMEU satisfies C independence  while our preference order does not  Lemma      a  If c     then I c     c    b  I satisfies positive homogeneity  if b  B and c      then I cb    cI b    c  I is monotonic  if b  b  B and b  b   then I b   I b     d  I is continuous  if b  b    b           B  and bn  b  then I bn    I b    e  I is superadditive  if b  b  B  then I b   b    I b    I b    Proof  For part  a   If c is in the range of u  then it is immediate from the defintion of I and Lemma   that I c     c  If c is not in the range of u  then since        is a subset of the range of u  we must have c      and by definition of I  we have I c      c I c   c     c  For part  b   first suppose that   b      and b  B   i e      b          Then there exists an act f such that bf   b  By Lemma    f  lI b    We now need to consider the case that c    and c     separately  If c     by       Independence  cfb       c l   clI b        c l    By Lemma    I bcfb    c l      I bclI b     c l     It is easy to check that bcfb    c l    cb  and bclI b        c l    cI b    Thus  I cb    I cI b     By part  a   I cI b      cI b   Thus  I cb    cI b   as desired  If c      there are two subcases  If   cb       since   c      by what we have just shown I b    I   c  cb      c I cb   Crossmultiplying  we have that I cb    cI b   as desired  And if   cb        by definition  I cb      cb  I bc   cb      c  b  I b   b     since bc   cb     b   b     Since   b       by what we have shows   I b   Again  it follows I b    I   b   b   b        b  I b   b     so I b   b        b   that I cb    cI b   Now suppose that   b        Then I b      b  I b   b     Again  we have two subcases  If   cb        then  I cb      cb  I cb   cb      c  b  I b   b      cI b   And if   cb       by what we have shown for the case   b           I b    I   cb     I cb   c c so again I cb    cI b   For part  c   first note that if b  b  B    If   b      and  b        then the acts fb and fb exist  Moreover  since b  b   we must have  fb  s      fb    s  for all states s  S  Thus  by Monotocity  fb   fb   If either   b       or   b         let n   max   b      b      Then   b n      and   b  n       Thus  I b n   I b  n   by what we have just shown  By part  b   I b   I b    Finally  if either b  B  B  or b  B  B    note that if b  b   then b   b     By definition  I b    I b   and I b     I b     moreover  b    b    B    Thus  by the argument above  I b   I b    For part  d   note that if bn  b  then for all k  there exists nk such that bn     k   bn  bn      k  for all n  nk   Moreover  by the monotonicity of I  part  c    we have that I b     k     I bn    I b      k     Thus  it suffices to show that I b     k     I b  and that I b      k     I b   To show that I b     k     I b   we must show that for all o      there exists k such that I b     k     I b   o  By positive homogeneity  part  b    we can assume without loss of generality that   b              and that   b       Fix o      If I b           I b   o  then we are done  If not  then I b    I b   o   I b           Since   b      and   b               fb and fb      exist  Moreover  by Lemma    fb  f I b o   fb        By mixture continuity  for some p          we have pfb       p f b       f I b o    It is easy to check that bpfb    p fb        b      p         Thus  by Lemma    fb  p         f I b o    and I b      p          I b   o  Choose k such that   k       p        Then I b     k     I b      p          I b   o  as desired  The argument that I b      k     I b  is similar and left to the reader  For part  e   first suppose that b  b  B    If   b      b        and I b   I b      b b b b    consider I b  and I b      Since I  I b      I  I b          it follows from Lemma        that f p f  b I b   b I b     f   f  b I b      By Ambiguity Aversion  for all p          pf   b I b          b I b   I b   I b  b b b b   Thus  I  I b  I b    I b    I b  I b   I b      I  I b      I  I b              Hence  I b   b    I b    I b    If b  b  B  and either   b       or   b         and both I b       and  I b         then the result easily follows by positive homogeneity  property  b      If b  b  B and either I b      or I b        let bn   b n  and bn   b  n       Clearly   bn           bn         bn  b  and bn  bn   By our argument above  I bn   bn    I bn     I bn   for all n     The result now follows from continuity  Finally  if either b  B  B  or b  B  B    observe that     b  s    b  s   if b s      b  s          b  s    b  s   if b s      b  s      b   b    s   b  s    b  s   if b s       b  s          b  s    b  s   if b s      b  s        Therefore   b   b    b   b   Thus  I b   b     I  b   b      I b   b   by the monotonicity of I  and I b   b    I b     I b   by superadditivity of I on B    Therefore  I b   b    I b    I b     A    Defining the weights  In this section  we use I to define a weight Pr for each probability Pr   S   The heart of the proof involves showing that the resulting set P   so determined gives us the desired representation  Given a set P   of weighted probability measures  for b  B    define X NWREG b    inf Pr   b s  Pr s    PrP  sS  Note that NWREG is the negative of the weighted regret when the menu is B    Define X b s  Pr s   NREG b    inf PrP  and  NREG Pr  b     X  sS  b s  Pr s    EPr b   sS  For each probability Pr   S   define Pr   sup   R   NREG Pr  b   I b  for all b  B           Note that Pr    for all distributions Pr   S   since    I b  for b  B   by monotonicity   and Pr     since NREG Pr          I           for all distributions Pr  Thus  Pr          Moreover  it is immediate from the definition of Pr that Pr NREG Pr  b   I b  for all b  B    The next lemma shows that there exists a probability Pr where we have equality       Lemma      a  For some distribution Pr  we have Pr        b  For all b  B    there exists Pr such that Pr NREG Pr  b    I b   Proof  The proofs of both part  a  and  b  use a standard separation result  If U is an open convex subset of B  and b    U   then there is a linear functional  that separates U from b  that is   b      b  for all b  U   We proceed as follows For part  a   we must show that for some Pr  for all b  B    NREG Pr  b   I b   Since NREG Pr  b    EPr b  it suffices to show that EPr  b   I b  for all b  B  Let U    b  B   I b         U is open  by continuity of I   and convex  by positive homogeneity and superadditivity of I   and        U   Thus  there exists a linear functional  such that  b            for b  U   We want to show that  is a positive linear functional  that is  that  b     if b      Since    U   and           it follows that             Since  is linear  we can assume without loss of generality that             Thus  for all b  B    I b       implies  b         The fact that I cb     I     follows from the definition of I on elements in B  B    Suppose that c     and b      From the definition of I  it follows that I cb     I              So c b      cb        so  b       c  Since this is true for all c      it must be the case that  b       Thus   is a positive functional  Define the probability distribution Pr on S by taking Pr s      s    To see that Pr is indeed a probability distribution  note P that since  s    and  is positive  we must have   s       Moreover  sS Pr s              In addition  for all b  B  we have X X  b       s  b  s    Pr s b  s    EPr  b    sS  sS  Next note that  for b  B    for all c      if I b    c  then  b    c        For if I b    c  then I b  c       by positive homogeneity  so  b  c       and  b    c  The result now follows  For if b  B    then I b   I         by monotonicity  Thus  if c   I b   then c      so  by       b    c  Since  b    c whenever I b    c  it follows that EPr  b     b   I b   as desired  The proof of part  b  is similar to that of part  a   We want to show that  given b  B    there exists Pr such that Pr NREG Pr  b    I b   First supose that   b       If I b       then there must exist some s such that b s       for otherwise there exists c     such that b  c   so I b   c  If b s       let Prs be such that Prs  s       Then NREG Prs  b       so  b  holds in this case  If   b      and I b       let U    b   I b     I b    Again  U is open and convex  and b    U   so there exists a linear functional  such that  b      b  for  b  U   Since    U and           we must have  b       Since      b      is not in U   and therefore we also have             Thus  we can      assume without loss of generality that             and hence             The same argument as above shows that  is positive  for all c     and b      I cb       as before  Since I b       it follows that I cb     I b   so cb  U and  cb      b               Thus  as before  for all c      b       b       c   so  is a positive functional  Therefore   determines a probability distribution Pr such that  for all b  B    we have  b     EPr  b    This  of course  will turn out to be the desired distribution  To show this  we need to show that Pr   I b  NREG Pr  b   Clearly Pr  I b  NREG Pr  b   since if    I b  NREG Pr  b   then NREG Pr  b    I b   since NREG Pr  b     b        To show that Pr  I b  NREG Pr b  we must show that  I b  NREG Pr  b  NREG Pr  b    I b   for all b  B    Equivalently  we must show that I b  b    b   I b   for all b  B    Essentially the same argument used to prove     also shows for all c      if I b     cI b   then  b     c b     In particular  if I b     cI b   then by positive homogeneity  I bc     I b   so b b  c  U   and   c      b  and hence  b     c b    Thus  if I b    I b     c and c      then I b     cI b   and hence   b     b     c  It follows that  b     b    I b    I b   for all b  B    Thus  I b  b    b   I b   for all b  B    as required  Finally  if   b        let b   b   b    By the argument above  there exists a probability measure Pr such that Pr NREG Pr  b   b      I b   b     Since NREG Pr  b   b      NREG Pr  b    b    and I b   b      I b    b    we must have that Pr NREG Pr  b    I b   We can now complete the proof of Theorem    By Lemma   and the definition of Pr   for all b  B    I b     inf  Pr S      inf  Pr NREG b   Pr S     sup PrP  Pr  X  Pr     b s  Pr s   sS  X          b s  Pr s     sS  Recall that  by Lemma    for all acts f  g such that bf   bg  B    f   g iff I bf    I bg    Thus  f   g iff     X X Pr Pr sup u f  s   Pr s   sup u g s   Pr s    Pr S   sS  Pr S   sS  Note that  for f  M    B    we have reg M   Pr  f     sup u f  s   Pr s   since     dominates all acts in M    Thus     S Y U     Pr  Pr   Pr  M   P     where P        S    By Lemma    this means  U  P     represents  M for all menus M   as required  We have already observed that U is unique up to affine transformations  so it remains to show that P   is maximal  This follows from the defini    tion of Pr   If  M   S Y U M  P       and     Pr    P     then we claim that      R   NREG Pr  b   I b  for all b  B     If not  there would be some b  B  with   b         such that  NREG Pr  b    I b   which  by the S Y U S Y U   definition of S Y U M    P      means that l  M    P     fb M    P     lI b    Recall that I bf     inf    l  M  f    Moreover  since S Y U M    P     satisfies the Mixture Continuity  there exists some p         such that fb S Y U M    P     S Y U    pl        p lI b  S Y U M    P     M    P     lI b    This contradicts the definition of I b   Therefore       R   NREG Pr  b   I b  for all b  B     and hence   Pr    A    Uniqueness of Representation  In the preceding sections  we have shown that if a family of menu dependent preferences  M satisfies axioms        then  M can be represented as minimizing weighted expected regret with respect to a canonical set P   of weighted probabilities and a utility function  We now want to show uniqueness  In this section  we show that the canonical set of weighted probabilities we constructed  when viewed as a set of subnormal probability measures  is regular and includes at least one proper probability measure  Moreover  this set of sub probability measures is the only regular set that induces a family of preferences  M that satisfies axioms        Our uniqueness result is analogous to the uniqueness results of Gilboa and Schmeidler      who show that the convex  closed  and non empty set of probability measures in their representation theorem for MMEU is unique  By Lemma    it suffices to consider the preference relation  M    The argument is based on two lemmas  the first lemma says that the canonical set of sub probability measures is regular  and the second lemma says that a set of subprobability measures representing  M  that is regular and contains at least one proper probability measure is unique  The proof of this second lemma  like the proof of uniqueness in Gilboa and Schmeidler      uses a separating hyperplane theorem to show the existence of acts on which two different representations must disagree  However  a slightly different argument is required in our case  since our acts in M  must have utilities corresponding to nonpositive vectors in R S    Lemma    Let P   be the canonical set of weighted probability measures representing  M    The set C P     of sub probability measures is regular  Proof  It is useful to note that  by definition  p  C P     if and only if Ep  b   I b  for all b  B         where expectation with respect to a subnormal probability measure is defined in the obvious way   Recall that a set is regular if it is convex  closed  and downward closed  We first show that C P     is downward closed  Suppose that p  C P     and q  p  i e   q s    Pr s  for all s  S  Since p  C P      Ep  b   I b  for all b  B    Since q  p and  if b  cB    we have b      it follows that Eq  b   Ep  b   I b  for all b  B    and thus q  C P      To see that C P     is closed  let p   limn pn   where each pn  C P      Since pn  C P     it must be the case that Epn  b   I b  for all b  B    By the continuity of expectation  it follows that Ep  b   I b  for all b  B    Thus  p  C P      To show that C P     is convex  suppose that p  q  C P      Then Ep  b   I b  and Eq  b   I b  for all b  B    It easily follows that for all a          Eap   a q  b   I b  for all b  B    Thus  ap       a q  C P      Lemma     A set of sub probability measures representing  M  that is regular  and has at least one proper probability measure is unique  Proof  Suppose for contradiction that there exists two regular sets of subnormal probability distributions  C  and C    that represent  M  and have at least one proper probability measure  First  without loss of generality  let q  C   C    We actually look at an extension of C  that is downward closed in each component to   Let C      p  R S    p  p    Note an element p of C   may not be subnormal probability measures  we do not require that p s     for all s  S  Since C   and  q  are closed  convex  and disjoint  and  q  is compact  the separating hyperplane theorem      says that there exists   R S  and c  R such that   p   c for all p  C     and   q   c        By scaling c appropriately  we can assume that   s      for all s  S  Now we argue that it must be the case that  s     for all s  S  so that  corresponds to the utility profile of some act in M     Suppose that  s       for some s  S  By        p   c for all p  C     However  consider p  C   defined by      if s    s p  s     c    s    if s   s   Clearly    p  c  contradicting      Thus it must be the case that  s     for all s  S  Consider the  given by the separating hyperplane theorem  and let f be an act such that u  f     By continuity  f M  ld for some constant act ld   Since C  and C  both represent  M    and C  and C  both contain a proper probability measure  min p   u  f     min p   u  ld     d   min p   u  f     pC   pC   pC        However  by      min p   u  f     c   min p   u  f    pC   pC   which is a contradiction   
  Conditioning is the generally agreed upon method for updating probability distribu tions when one learns that an event is cer tainly true  But it has been argued that we need other rules  in particular the rule of cross entropy minimization  to handle up dates that involve uncertain information  In this paper we re examine such a case  van Fraassen s Judy Benjamin problem         which in essence asks how one might update given the value of a conditional probability  We argue that contrary to the suggestions in the literature it is possible to use simple conditionalization in this case  and thereby obtain answers that agree fully with intu ition  This contrasts with proposals such as cross entropy  which are easier to apply but can give unsatisfactory answers  Based on the lessons from this example  we speculate on some general philosophical issues concern ing probability update     INTRODUCTION  How should one update one s beliefs  represented as a probability distribution Pr over some space S  when new evidence is received  The standard Bayesian an swer is applicable whenever the new evidence asserts that some event T  S is true  and furthermore  this is all that the evidence tells us   In this case we simply condition on T  leading to the distribution Pr IT   For successful  real world  applications of probability theory so far  conditioning has been a mostly sufficient answer to the problem of update  But many people have argued that conditioning is not a philosophically adequate answer  in particular   Jeffrey         Once we try to build a truly intelligent agent interacting in complex ways with a rich world  conditioning may end up being practically inadequate  as well  The problem is that some of the information that we receive is not of the form  Tis  definitely  true  for  any T  What would one do with a constraint such as   Pr   T          or  the expected value of some ran dom variable on S is       We cannot condition on this information  since it is not an event in S  Yet it is clearly useful information  So how should we in corporate it  There is in fact a rich literature on the subject  e g   see  Bacchus  Grove  Halpern  and Koller       Diaconis and Zabell       Jeffrey       Jaynes       Paris and Vencovska       Uffink         Most proposals attempt to find the probability distribution that satisfies the new information and is in some sense the  closest  to the original distribution Pr  Certainly the best known and most studied of these proposals is to use the rule of minimizing cross entropy  Kullback and Leibler       as a way of updating with general probabilistic information  This rule can also be shown to generalize Jeffrey s rule  Jeffrey        which in turn generalizes conditioning  But is cross entropy   CE  really such a good rule  The traditional justifications of CE are that it satisfies vari ous sets of criteria  such as those of  Shore and Johnson        which  while plausible  are certainly not com pelling  Uffink        Van Fraassen  in a paper entitled  A problem for relative information  CE  minimizers in probability kinematics         instead approached the question in a different way  he looked at how CE behaves on a simple specific example  He calls his ex ample the Judy Benjamin  JB  problem  in essence it is just the question of how one should update by a conditional probability assertion  i e    Pr AIB    c  for some events A  B and c E         As we now explain  van Fraassen uncovers what seems  to us  to be an unintuitive feature of cross entropy  although in later papers on the same issue he endorses CE and a family of other similar rules  Furthermore  none of his rules agree with most people s strong in tuition about the solution to his problem  The pur pose of this paper is to give a new analysis  which is based on simple conditionalization  and is  we argue  in good agreement with people s expectations  Our hope is that the example and our analysis will be an instructive study of the subtleties involved in proba bility update  and in particular the dangers involved in indiscriminately applying supposedly  simple  and   Probability Update  Conditioning vs  Cross Entropy   general  rules like CE  Van Fraassen explains the JB problem as follows          The story  derives from the movie Private in which Goldie Hawn  playing the title character  joins the Army  She and her platoon  participating in war games on the side of the  Blue Army   are dropped in the wilderness  to scout the opposition   Red Army    They are soon lost  Leaving the movie script now  suppose the area is di vided into two halves  Blue and Red territory  which each territory is divided into Head quarters Company area and Second Com pany area  They were dropped more or less at the center  and therefore feel it is equally likely that they are now located in one area as in another  This gives us the following muddy Venn diagram  drawn as a map of the area  Benjamin        Red nd       RedHQ     B  Ue They have some difficulty contacting their own HQ by radio  but finally succeed and de scribe what they can see around them  After a while  the office at HQ radios   I can t be sure where you are  If you are in Red ter ritory  the odds are     that you are in HQ Company area      At this point the radio gives out  We must now consider how Judy Benjamin should adjust her opinions  if she accepts this radio message as the sole and correct con straint to impose  The question on which we should focus is  what does it do to the proba bility that they are in friendly Blue territory  Does it increase  or decrease  or stay at its present level of l     The intuitive response is that the message should not change the a priori probability of     of being in Blue territory  More precisely  according to this response  Judy s posterior probability distribution should place probability     on being at each of the two quad rants in the Blue territory  probability     on being in the Headquarters Company area of Red territory  and probability     on being in the Second Company area of Red territory  Van Fraassen        notes that his many informal surveys of seminars and conference audiences find that people overwhelmingly give this answer        However  this intuitive answer is inconsistent with cross entropy  In fact  it can be shown that cross entropy has the rather peculiar property that if HQ had said  If you are in Red territory  the odds are o      that you are in HQ company area        then for all o  f     the posterior probability of being in Blue territory  according to the distribution that minimizes cross entropy and satisfies this constraint  would be greater than      it would stay at     only if o       This seems  to us  at least  highly counterintuitive  Why should Judy come to believe she is more likely to be in Blue territory  almost no matter what the mes sage says about o   For example  what if Judy knew in advance that she would receive such a message for some a f     and simply did not know the value of o   Should she then increase the probability of being in Blue territory even before hearing the message  As van Fraassen        says  as part of an extended dis cussion of this phenomenon  It is hard not to speculate that the dangerous implications of being in the enemy s head quarters area are causing Judy Benjamin to indulge in wishful thinking      However  as van Fraassen points out  crediting Peter Williams for the observation   there also seems to be a problem with the intuitive response  Presumably there is nothing special about hearing the odds of being in Red territory are      The posterior probability of be ing in Blue territory should be     no matter what the odds are  if we really believe that this information is irrelevant to the probability of being in Blue terri tory  But if o      then  to quote van Fraassen          he would have told her  in effect   You are not in Red Second Company area    Assuming that this is indeed equivalent  it seems that Judy could have used simple conditionalization  with the result that her posterior probability of being in Blue territory would be      not       In  van Fraassen       van Fraassen  Hughes  and Harman        van Fraassen and his colleagues for mulate various principles that they argue an update rule should satisfy  Their first principle is motivated by the observation above and simply says that  when conditioning seems applicable  the answer should be that obtained by conditioning  To state this more pre cisely  let q   o   l o   be the probability  rather than the odds  of being in red HQ company area given that Judy is in Red territory  In the case of the JB problem  the first principle becomes  If q     the prior is transformed by simple conditionalization on the event  Red HQ area or Blue territory   if q     by simple condi tionalization on  Red  nd company area or Blue territory     We remark that this behavior of CE has also been cussed and criticized         in  a  dis  more general setting  Seidenfeld        Grove and Halpern  This first principle already eliminates the intuitive rule  i e   the rule that the posterior probability should stay at     no matter what q is   Note also that we cannot make the rule consistent with this principle by trea ting q     and q     as special cases  unless we are prepared to accept a rule that is discontinuous in q   For van Fraassen  this is apparently a decisive refuta tion of the intuitive rule  which he thus says is flawed  van Fraassen         This does not deny the usefulness of rules like CE  There will be some  perhaps large  family of situations in which CE is indeed appropriate  and we would like to better understand what this family is and how to recognize it  But if CE  or any other rule  is blindly applied whenever the information is of the appropriate syntactic form  we should not be surprised if the results are often unexpected and unhelpful   However  in this paper we give a new  and simple anal ysis of the JB problem  We believe that our solution is well motivated  and it agrees completely with the in tuitive answer  It thus also does not exhibit the coun terintuitive behavior of CE      Our basic idea is simply to use conditioning  but to do so in a larger space where it makes sense  i e   where the information we receive is an event   Of course  people have always realized that this option is avail able  It is perhaps not popular because it appears to pose certain serious philosophical and practical prob lems as a general approach  In particular  which lar ger space do we use  There may be many equally natural possibilities  leading to different answers  so the rule will be indeterminate  Also possible is that all ex tended spaces we can think of seem equally unnatural and contrived  again  we will be stuck  In addition  there is the practical concern that a rich enough space might be vastly larger and more complicated to work in than the original  Against this  a rule like cross entropy seems extremely attractive  It provides a single general recipe which can be mechanically applied to a huge space of up dates  Even families of rules  such as van Fraassen proposes  are not so bad  aft er one has chosen a rule  usually by selecting a single real valued parameter  Uffink         the rest is again mechanical  general  and determinate  Furthermore  all these rules work in the original spaceS  without requiring expansion  and so may be more practical in a computational sense  all we do in this paper is analyze one particular problem  we must be careful in making general state ments on the basis of our results  Nevertheless  they do seem to support the claim that sometimes  the only  right  way to update  especially in an incompletely specified situation  is to think very carefully about the real nature and origin of the information we receive  and then  try to  do whatever is necessary to find a suitable larger space in which we can condition  If this doesn t lead to conclusive results  perhaps this is because we do not understand the information well enough to update with it  However much we might wish for one  a genemlly satisfactory mechanical rule such as cross entropy  which saves us all this question ing and work  probably does not exist  Since    Although  we are aware of no published analysis simi  lar to our own  we have learned that Seidenfeld has earlier presented a closely related analysis in several lectures  Sei denfeld         CONDITIONING  In this section  we present our alternative analysis of the JB problem  In the following  let B   B   R  R  denote the events that Judy is in  respectively  Blue HQ  Blue Second Company  Red HQ  and Red Second Company areas  Let B   B  V B  and R   R  V R   The message HQ sent   If you are in Red territory  the odds are     that you are in HQ Company area   is equivalent to asserting that the conditional proba bility of R  given R is true is      In general  let M q  be the similar message asserting that this probability is q E     lj for some q not necessarily        i e   the announced odds are q      q      instead of         We use Prjrior to denote Judy s prior beliefs  i e   be fore the message is received  and Prj to denote her posterior distribution after receiving M q   The key step is to re examine the problem from the be ginning  and ask ourselves how Judy should treat HQ s message  Note t hat Van Ftaassen explicitly assumes  in his statement of the problem  that HQ s statement should be treated as a constraint on Judy s beliefs  Thus  he interprets it as an imperative   Make your beliefs be such that this is true   This interpretation of probabilistic informat ion as constraints is a common one  especially in the context of CE   but is difficult to justify  Uffi nk        Van Fraassen is  of course  quite aware of the philosophical issues raised by his interpretation  see  van Fraassen         But is the interpretation that HQ s stat ement should be regarded as a constraint on Judy s beliefs the only possible one  Note that  as the story is presented  it certainly sounds as though HQ was trying to give Judy some true and useful information  But  at the time M is sent  the statement that Prjriar RtJR      is clearly not true of Judy s beliefs  Thus  if we wish to interpret M as referring directly to Judy s beliefs  we will be unable to regard it as a factual assertion in any straightforward sense     But suppose we instead view M q  as being a cor rect statement regarding HQ  s beliefs  i e   as asserting PrnQ RtJR    q where PrnQ denotes HQ s distribu tion over where Judy might be  This certainly seems to be a reasonable interpretation in light of the story  How should Judy react to it  Unfortunately  the story does not give us enough information to be able to pro vide a definite answer to this question  Judy s correct reaction to the message depends on aspects of the situ ation that were not included in the problem statem ent    Probability Update  Conditioning vs  Cross Entropy  The followi n g is a partial list of things that could be relevant  W hat does Judy know about HQ s beliefs and knowledge  How did HQ expect Judy to react to the message  and what did Judy know about these ex pectations  What messages could HQ have sent  For instance   might HQ have sent M q  for some other value of q if it were appropriate  or would it have said something else entirely if q        Does Judy believe that HQ even has th e option of sen ding messages that are not of the form M q   if so  what mess ag es   And so o n   We now give one particular analysis  filling in such missing details in what  which follows by we feel is a plau sible way  As we said  we assume that M      is a fac tual statement about HQ s beliefs  We further assume that  no matter what HQ actually knows  its message  would always have been simply M q  for the appropri a te value of q  Thus  Judy can read nothing more into M q  other than to regard it as a true statement about HQ s beliefs  As noted in the previous paragraph   even to get this far relies on several strong assumptions   Once Judy he ars M q   it seems n at ural to want to The problem is t hat   as yet  we condition on it  have not introduced a space in which M q  is an ev ent  Of course  there are many possible such spaces  To construct an appropriate one  we must consider how Jud y models HQ   s beli efs   and what she believes about these beliefs  Again  here we make perhaps the simplest possible choice  We suppose that Judy models HQ s beliefs as a distribution ove r the four  R   R   B   B    Prc be the distribution on  R   R   B   B   such that Prc  R     a  p a   c P rHQa  b   c  R      b  pr a b c HQ  B      c  r HbQ  B          a   b   c  Thus the set of all possible distri  quadrants  butions  HQ  Let  might have  given our assumptions  is  PHQ    Prcla b c     a b cl   In the following   we view Pr nQ  R   I R   Pr HQ  RI    Pr HQ B     and so on  as random variables on the space PHQ Thus  for example   Pr nQ R IR    q  denotes the event  Prc I Pr    c  R IR    q   Again  we stress that we are not forced to use P HQ Judy might actually have a richer model of HQ s be liefs  e g   she might think that HQ makes finer geo graphical distinctions than simply the four quadrants  or a coarser model  e g   J udy might take as the space of possibilities the possible values of PrnQ RliR   and  ab out HQ  s       bel iefs    Since Judy d oes not know what HQ actually believes  her beliefs will be a distribution over distributions  i e   a dis tribu tion over PnQ Which distribution  Again  we have many choices  but a na tural one is to suppose that before Judy hears the message  she considers a uniform distribution over   a  b  c  t uples   Formally  we consider the distribution function defined  by Prj q Pr c I a    A b    B c    C    ABC  so that the density function is j ust    We also use the notation Prj HQ to denote Judy s beliefs about HQ s   beliefs after receiving M q   It might be thought that  having decided to take PH Q as the set of possible beliefs that HQ could have and given the  implicit  assumption that Ju d y is initially completely ignorant of HQ s beliefs  the prior density on P HQ is determined complet ely  Unfortunately  this is not the case  Ther e is no unique  uniform distribu tion  on PnQ Uniformity depends on how we choose to parameterize the space  We have chosen to param eterize the elements of this space by a triple  a  b  c  denoting the probabilities of R   R   and Bt  respec  tively  However  we could have chosen to characterize an element of the space by a triple  a   b   c   denot ing the square of the probabilities of R   R   and B   re spec tivel y  Or perhaps more reasonably  we could have chosen to characterize an element by a triple   a    b    c   denoting the probability of R  the probabil ity of R  given R  and the probability of B  given B  A uniform distribution with respect to either of these parameterizations would be far from uniform with re spect to the parameterization we have chosen  and vice versa   This is  of course  just an instan ce of the well known impossibility of defining a unique notion of  l mi form in a continuous sp ace  H ow son and U rbach        Since M q  is an event in the new space  PHQ  Judy should be able to condition on it  One might object that  since M q  is an event of measure    condition ing is not well defined  This is t rue  but there are t w o  closely related  ways of dealing with this prob lem  The more elementary and intuitive approach is based on the observation that  in practice  HQ w ill n ot  in general  be able to announce its value for Pr nQ RI IR  exactly  since this could require HQ to announce an infinite precision real number  It seems more reasonable to regard the announced value of q as being rounded or approximated in some fashion  In  not reason about the rest of HQ s distribution   How ever  given the description of the story  PHQ seems to be the most natural space for Judy to model her beliefs  particular  we might suppose that M q  really means PtHQ RIIR  E  q   E  q   e  for some small val ue E      This event has non zero probability according  first   We note  however  that the uniform densities with respect to all   possible parameterizations that involv   To see the possible relevance of this  note that if there are other possible messages  then the very fact that HQ s message was not one of these others could be impor  tant information in and of itself  Judy might reason that  M       must have been the most important fact HQ pos  sessed  On the other hand  since the radio died before the message was completed  such inferences depend heavily on the protocol Judy expects HQ to follow    to Prj  Q   and  so  conditioning is unproblematic   ing choosing   out of the   probabilities from PrnQ Rt   Pr nQ R      PrnQ Bt   PrnQ Bz   do lead to the same dis tribution over PnQ  and so o ur decision to use the first three of these probabilities does not affect  our  analysis    Grove and Halpern       The second approach directly invokes the standard def inition of conditioning on  the value of  a random variable  We briefly review the details here  Sup pose we have two random variables X and Y  If  Pr X     a      Pr Y     then  defined as Pr Y   b  l X   would expect  If Pr X   a    bJX    is just a  as we    then we take the     a   Pr X        a     straightforward analogue of this definition using den  sity functions  If fxy x  y  is the joint density function for X and Y  and fx   x   is the density for X alone  then the conditional density of Y given X is given by Jy x yJx    fxy x y ffx x   Using the density function we can then compute the probability by inte grating as usual  Further details can be found in any standard text on probability  for instance  Papoulis           To use this approach  we need to identify a random variable X and value b such that M q  corresponds to the event X   b  The choice of random variable  is crucial  we can easily have two random variables X and X  such that X    b and X    b are the same event  yet conditioning on X  band X   b leads to different results  since X and X  have different density functions  In our case there is an obvious choice of random variable  given our description of the situation   PrHq B    p and Prn q   R  J R     q are independent  This is of course extremely intuitive  It seems reason  able that HQ s beliefs about the probability of Judy being in Blue Territory should be independent of HQ s  beliefs of her being in Red HQ area  given that she is in Red territory   Using this  it is trivial to prove the following proposi  tion  which holds whether we choose to use any par  ticular t       or if we use the standard definition of conditioning on the value of a random variable  which  as we have said  essentially corresponds to considering the limit as t       In this proposition  pr  p  denotes the density function for the random variable P r m B   i e   pr B P    dPrJ HQ PraQ B    p jdp  Similarly  pr B  P I M q    pr  p       p   p          for the next result    Proposition      PrnQ B    p    PI M  q   dp   it immediately follows that although we do not need this fact    dPrJ HQ PrnQ  B    Note that from  and     In  P  M q   prB P   HQ  PrjjrQ    the events  are independent  Formally      pr  pJM q     is easy to see that the two approaches give us the same  With this result  we are very close to showing that Judy s beliefs regarding the probability of her be ing in Blue territory don t change as a result of the  and then considering the limit as the interval width  regarding where Judy is   The posterior distribution  PrnQ RtiR    With this choice of random variable  it  answer  the use of the density function corresponds to considering a small interval around PrnQ RtiR    q  tends to     message   PnQ   Pr   c RtiR    af  a  b   Prjj Q PrnQ RtiR      we have  q     a  b   dcdbda r t a   c O  qa O h a l q     rl a   a b dcdhda a  O J b O  c O   a b dcdhd   r a   Ja O b  c O q        a   q                           a  b dbda   lq  q  a   da     q  q  a O    p           p p    PrjjQ Prnq R IR    qAPr nQ B     p   and  is a distribution on  j HQ   Prj  Q I M q   is still a distribution on    Pnq   As a result of conditioning  Judy revises her beliefs about HQ s beliefs  But to determine Judy s beliefs about where she is we need a distribution on  Rt  R   Bt  B     The question is how Judy s beliefs about HQ s beliefs about where she is are related to her beliefs about where she is  Notice that there is no necessary relation  After all  for all we know  Judy might think that HQ has no reliable information  and thus decide to ignore HQ s statement when forming her opinion regarding where she is  But  in keeping with the spirit of the story  we assume that Judy trusts HQ  and thus forms her beliefs by taking expectations over her beliefs about HQ s beliefs  For example  if Judy was certain that HQ was certain that she was in Blue territory  then she would ascribe probability   to being in Blue territory  More generally  Judy weights HQ s beliefs according to her beliefs about how likely it is that HQ holds those beliefs  We formalize this trust assumption as follows      q  Two other results  which are derived in a similar fash ion  also tmn out to be useful   Prj  Q PrnQ B   PrjQ  that is  on Judy s beliefs about HQ s beliefs  Pr  Before computing the result of conditioning on M q   under either approach   it t urns out to be use ful to do some more general computations  Since  Notice that          q     p p     The point here is not just the values themselves  but  more importantly  that the final distribution function is the product of the first two  That is  the events   Trust   At any point in time  Judy s beliefs about event in the space  R   R   B   B   are formed by taking expectations of HQ s probability of the same event  according to Judy s distribu any  tion over HQ s possible beliefs  Formally  we have   Pr  E     f Pr  HQ Pr  J c  Pr  J c E  dabc lPrcEPHQ        Pr obability Update  Conditioning vs  Cross Entropy          prk e  e de    prior  probability  U         In the second line  which for t E theory  pr    e  follows from standard is the density function of the random variable  Pr c E   e jde        i e   pr  e     dPr HQ Pr c E      Note that when we apply this rule before Judy receives the message  so that t  prior  we have     Pr   ior B      Prrior B     Prrio r Rl    Prrior R           which  is consistent with our earlier assumption that Judy started with a uniform prior on   Bt  B   Rt  R     M q   q  The desired result now follows quite readily using the The re trust principle after Judy has received sult is that  no matter what the value of is  her beliefs regarding being in Blue territory remain unchanged  exactly in accord with most people s strong intuitions   Theorem       Proof   Pr j B           for all  q  E             Prj HQ Pr    c  Pr  jc B  dabc  p QEPHQ    Prj B     i  rB PIM q  pdp     pr  p  pdp       p   p  pdp                 I  Note that this theorem applies even if q      Van Fraassen would interpret the message M l  as mean ing that Judy is definitely not in R   We interpret this it as PrnQ R IR  E      t      for some  arbitrar ily  small and unspecified       Although the two interpretations seem close  after all  they differ by at most t  in the probability that they assign to R  and R    they are not equivalent  As Theorem     shows  this is a significant difference  It is the claimed equiv alence of the two interpretations that was behind van Fraassen s first principle  and hence his rejection of the intuitive answer that P r  B          This equivalence may be correct under van Fraassen s constraint based interpretation of M  but it is not inevitable under our is indeed a factual alternative reading  in which announcement  but about HQ s beliefs  not Judy s    j  M     DIS CUSSION  belief as characterized by   Rt  R  B   B     to a  M q        q  M q  is interpreted as meaning that Pr nQ    E  q        so that we can condition on this    q  event   However  our result holds no matter what t  is  Thu s we can regard t  as an arbitrarily small and unknown nonzero quantity      Judy s distribution on  Bt  B   Rt  R   was de rived by taking the expectation of her beliefs re garding HQ s beliefs  Although these assumptions seem to us quite reason able  they are clearly not the only assumptions that could have been made  It is certainly worth trying to understand to what extent our results depend on these assumptions  and in particular whether they can be ex tended to provide more general statements of how to update by probabilistic information  considered by van Fraassen and his colleagues  As we said in the introduction  such rules may be useful in certain cases  but we believe it is an important research question to understand and explain precisely when  We do not  in particular  find CE to give particularly plausible results in the JB problem  But how could this have been predicted in advance  The JB problem shows that we need more than just an axiomatic justification for the use of CE  or any other method of update   An alternative to the use of a rule is to do what we have done for the JB problem in this paper  that is  to try to  complete the picture  in as much detail as possible  so that ultimately all we need to do is condition  In practice  this may be unneces sarily complex and shortcuts  such as CE  might exist  However  it would be useful to understand better the assumptions that are necessary for their use to cor respond to conditioning  In any case we believe that some of the issues we addressed cannot be avoided  it will never be sensible to blindly apply a rule  like CE  to all information that merely  seems  probabilistic or can be reformulated as such  Rather  one must always think carefully about precisely what the information means   Acknowledgments  It is worth reviewing the assumptions that were nec essary for us to prove Theorem      We assumed     HQ s     The only messages that HQ could send were those and the one that HQ did send of the form was the one that correctly reflected HQ s beliefs   W here does this leave CE and all the other methods   by Theorem         from     Judy s beliefs regarding HQ s beliefs were characterized by the uniform distribution on HQ s beliefs  when parameterized by the tuple  PrsQ RI   PrsQ R    PrnQ Bt        where Judy is can be distribution on the space  We thank Teddy Seidenfeld and Bas van Fraa ssen for useful comments  The second author s work was sup ported in part by the NSF  under grant IRl           and the Air Force Office of Scientific Research   AFSC   under grant F                        Grove and Halpern  
  in domains with uncertainty  There have been numerous  As probabilistic systems gain popularity and are  proposals  both proba bilistic and qualitative   for defining explanation in such domains    GID denfors       Hempel  that explains the system s findings and recom        Salmon       describe the work done by the philoso phers and give numerous references  the more recent work  will also need a mechanism for ordering compet ing explanations  We examine two representa  Henrion and Druzdzel       Pearl       Shimony       Suermondt         Since we are interested in explanation  coming into wider use  the need for a mechanism  mendations becomes more critical  The system  tive approaches to explanation  in the literature  one due to Gardenfors and one due to Pearl and show that both suffer from significant prob lems  We propose an approach to defining a notion of   better  explanation  that combines some of the  features of both together with more recent work  by Pearl and others on causality   in AI includes  for example   Boutilier and Becher        in probabilistic systems  our f ocus is on proposals that seek a probabilistic connection between the explanation and the explanandum  In the philosophical literature  the focus has been on the probability of the explanandum given the ex planation  The requirements range from just requiring that this conditional probability change  to requiring that it be  very high  to requiring that it be greater than the uncon ditional  probability of the explanandum  so that learning  the explanation increases the probability of the explanan     INTRODUCTION  Probabilistic inference is often hard for humans to under  stand Even a simple inference in a small domain may seem counterintuitive and surprising  the situation only    gets worse for large and complex domains  tem doing probabilistic inference  Thus  a sys must be able to explain  its findings and recommendations to evoke confidence on  the part of the u ser Indeed  in experiments with medical diagnosi s systems  medical students not only trusted the    system more when presented with an explanation of the diagnosis  but also were more confident about disagreeing  with it when the explanations did not account adequately for all of the aspects of the case  Suennondt and Cooper  dum   see  Giirdenfors       Salmon       for discussion and further references  In contrast  the research on expla nation in Bayesian networks  Henrion and Druzdzel       Pearl       Shimony       has concentrated on comput ing the conditional probability of the explanation given the  explanandum  adding in some cases the additional require ment that the explanation be a complete world description   Clearly the appropriateness of a notion of explanation will  depend in large part on the intended app l ication  A scientific  explanation might well have different properties from an  explanation provided by an intelligent tutoring system  In  our intended application  the system will typically have some uncertainty regarding the true state of the world  and  partially correct explanation should be the best indication  domain s causal structure   represented a probability distribution  Note that this is different from  say an intelligent tutoring system  where we assume the system to have the full knowledge of the domain  For  Our goal is to find a notion of explanation in a probabilistic setting that can be usefully applied by a reasoning system  knowledge   Because we expect that there will typically be a number of competing explanations that can be provided         Explanation can also play an important role in refin ing and debugging probabilistic systems  An i ncorrect or  to an expert of a potential problem   to explain its findings to a human  Of course  we are not the first to examine explanation  It has been has analyzed  possibly even the as     simplicity  we make the  admittedly unrealistic  assumption that the user s knowledge can be identified with the system s  to the user  we are interested not just in finding an absolute notion of explanation  but a comparative notion  We want  by philosophers for many years  Traditionally  it has been  to be able to another   to scientific enquiry  this approach is not easily applicable  to fit it is  modeled by introducing a deductive relation between the explanation and the fact to be exp lained  explanandum   Hempel and Oppenheim        W hile perhaps applicable     judge when one explanation is better than  Modeling the user s knowledge and adjusting the explanation one of the planned extensions of this work    Defining Explanation in Probabilistic Systems  In this paper  we concentrate on two definitions of expla nation  one due to Gardenfors  I      and the other to Pearl          as represen tative s of the two approaches mentioned above   While  as we point out  there are signifi cant prob lems with these definitions  we consider them because they have some important features that we feel should constitute part of an ap p roach to defining explanation  We suggest an approach that combines what we feel are the best features of these two definitions with s ome ideas from the more re cent work on causality  Balke and Pearll     Druzdzel and Simon       Beckerman and Shachter       Pearl          One of the observations that falls naturally out of our ap proach is that we should expect different answers depending on whether we are asking for an explanation of beliefs or facts   For example  if the agent believes that it rained last night and we ask for an explanation for this belief  then a perfe ctly reasonable explanation i s that he or she notic OO the wet grass in the morning  which is correlated with rain  However  if the agent observes that it is raining and we ask for the best explanation of this observation  then it would certainly not be sati sfactory to be told that the grass is wet  We do not accept the wet grass as an expl anation in the second case because the wet grass is not a cause of rain  However  we would accept it in the first case because the agen t believing that the grass is wet is a cause of the agent believing that it rained  The critical difference between ex planations of beliefs and explanations of observations does not seem to have been discussed before in the literature  The rest of the p aper is organized as follows  In Sections    a nd   we present and analyze Gardenfors  and Pearl s  definitions  In Section   we present a new ap proach which  generalizes elements of both  We conclude with some open pr oblems in Section            GARDENFORS  APPROACH THE DEFINITION  As we sug gested earlier r oughly speaking for Gardenfors  X is an explanation of E if Pr EIX    Pr E   That is  X is an explanati on of E if learning X raises the pr obability of E  In order to flesh out this intuition  we need to make precise what probability distribution we are using        According to Gardenfors  what requires explanation i s  something that is already known  but was unexpected   A person asking fo r an explanation expresses a  cognitive dis sonance  between the explanandum and the rest of his or her beliefs  We don t typically require an explanation for something we expected all along  The amount of disso nance is mea sured by the surprise value of the explanan dum in the belief state in whi ch we reject our belief in the explanandum while holding as many as possible of our other beliefs intact  this operation is called contraction and c ome s from the belief revision framework  Alchourr n  Gardenfors  and Makinson         An explanation pro vides  cognitive relief   the degree of cognitive relief  is measured by the degree to which the explanation decreases the surprise value            For example if we ask for an explanation of why David has the flu  then we already know that David has the flu  Thus  if E is the statement  David has the flu   then in the current situation  we already ascribe probability   to E  Nothing that we could learn could increase that probability  On th e other hand  we pr esumably asked for an explanation    because before David got sick  we did not expect him to get sick  That is  if Pr E describes the agent s probability distribution in the contracted belief state  before David got flu  we expect Pr E  E  not to be too high  An explanation X     like  David was playing with S ara who also has the flu   would raise the probability of E in the contracted belief state  that is  we have    PrE  EIX      PrE  E    As Giirdenfors  definition stresses  what counts as an e xp la nation de pends on the agent s epistemic state  An explana tion for one agent may not be an explanation for another  as the following example  essentially taken from  Giirdenfors        shows     Example     If we ask why Mr  Johansson has been taken ill with lung cancer  the information that he worked in as  bestos manufacturing for many years is not going to be a satisfactory explanation if we don t know anything about the effects of asbestos on people s health  Adding the state ment      of those who work with asbestos develop lung cancer  makes the explanation complete  The explana tion must consist of both statements  However  if we try to explain Mr  Johansson s illness to his close friend  who is likely to know his profession  we would supply only the second piece of information  Similarly  to someone who knows more about asbestos but less about Mr Johansson  we would only present the information about his profession   To formalize these intuitions  Glirdenfors characterizes a  p robab ili stic  epistemic state using the possible worlds model  At any given time  an agent is assumed to con sider a number of worlds  or states of the world  possible  For example  if the agent looks out the window and notices that it is raining  his set of possible worlds would include only worlds where it is raining  Learning new facts about the world furthe r restricts the set of the worlds we con sider p ossible Among the possible worlds  some may be more like l y than the others  To describe this likelihood the       agent is assumed to have a probability distribution over the possible worlds  Thus  an epistemic state is taken to be a pair K  W  Pr   where W is a set of possible worlds  or possible states of the world  and Pr is a probability distribution on W  A sentence A is said to be accepted as knowledge in an epistemic state K if Pr  A       We sometimes abuse notation and write    A  E  K if A is accepted in epistemic state K   Given an epistemic state K    W  Pr  of an agent  let        WE   Pr E  denote the contraction of K with re spect to E  i e   the epistemic state characterizing the agent s beliefs that is as close to K as possible such that E  KF   Gardenfors describes a number o f postulates that K should satisfy  such as K E   Kif Eft K  It is be yond the scope of this paper to discuss these postulates  see  Ki        Chajewska and Halpern   Alchourr n  Giirdenfors  and Makinson         However  these postulates do not serve to specify Ki uniquely  that is  given K and E  there may be several epistemic states K  that satisfy the postulates  On the other band  there are some situations where it is straightforward to specify Ki  For example  if Pr is determined by a Bayesian network together with some observations  including E   then Prj is just the distribution that results from the Bayesian network and all the observations but E  We can now present Giirdenfors  definition of explanation  Definition      from  Gll rdenfors         X is an explana tion of E relative to a state of belief K    W  Pr   where E  E  K if     Pr E EIX      Pr g E   and     Pr X       that is  X   K   We have already seen the first clause of this definition  Note that  in this clause  and throughout this paper   we identify the formulas E and X with sets of possible worlds  namely  the sets of worlds  in W B   in which E and X  respectively  are true  The second clause helps enforce the intuition that the explanation depends on the agent s epistemic state  The explanation cannot be something the agent already knows  For example  fire will not be an explanation of smoke if the agent already knows that there is a fire  Notice that the second clause also prevents E from being an explanation for itself   Clearly E satisfies the first clause  since Pr E  EIE    Pr E  E   since we have assumed E E K  E does not satisfy the second clause   Unfortunately  as we shall see  while the second clause does exclude E as an explanation  it does not exclude enough  Given this notion of explanation  we can define an ordering on explanations that takes into account the degree to which an explanation raises the probability of the explanandum  Gardenfors in fact defined explanatory power as the dif ference between the posterior and prior probability of the explanandum  Thus  a better explanation is one with better explanatory power  The difference is not always a good measure of distance between probabilities  An explanation which raises the probability of a statement of interest from         l to      is not so powerful   On the other hand  an explanation raising the probability from          to      would be received quite differently  although the difference in probabilities is the same  A more natural way to define explanatory power is by using the ratio of the two probabilities  Definition      The explanatory power  EP  of X with re  spect to E is EP X  E      Pr E EIX  PrE  E      According to this definition  the two explanations above have dramatically different explanatory power  For this paper  we take the latter definition as our formal definition of explanatory power   Before we get to our critique of Gardenfors  definition  there is one other issue we need to discuss  the language in which explanations are given  Definition     makes per  feet sense if  for example  explanations are propositional formulas over a finite set of primitive propositions  In tha case  a world w could be taken to be a truth assignment to a finite family of these primitive propositions  We could also take explanations to be first order formulas  in which case a world could be taken to be a first order interpretation  Gllrdenfors in fact allows even richer explanations  involv ing statistical statements  As we saw  in Example      a possible explanation of Mr  Johansson s illness for someone who already knew that he worked in asbestos manufactur ing is to say      of those who work with asbestos develop lung cancer   To make sense of this  Glirdenfors associates with a world not only a first order interpretation  but a distri bution over individuals in the domain   This type of model is also considered in  Halpern        wbere a structure con sists of possible worlds  with a distribution over the worlds  and  in each world there is a distribution on the individuals in that world  a formal language is provided for reasoning about such models  If the domain is finite  we could sim plify things and assume that the distribution is the uniform distribution  as is done in  Bacchus  Grove  Halpern  and Koller         While it is not necessary to consider such a rich language to make sense of Glirdenfors  definition  one of his key insights is that statistical assertions are an important component of explanations  Indeed  he explicitly describes an explanation as a conjunction xl    x   where X  is a conjunction of statistical assertions and X  is what Glirdenfors calls a singular sentence  by which he means a Boolean combination of atomic sentences in a first order language with only unary predicates   Either conjunct may be omitted   As we shall argue  we need to generalize this somewhat to allow causal assertions as well as statistical assertions        A  CRITIQUE  While Giirdenfors  definition has some compelling features  see  Glirdenfors       for further discussion   it also has some serious problems  both practical and philosophical  We describe some of them in this section      While the second clause prevents E from being an ex  planation of itself  there are many other explanations that it does not block  Let F be any formula such that Pr F      and Pr g  E    F       Then E    F will be an explanation for E  Moreover  it will be the explanation with the highest possible explanatory power  both according to Gdenfors  original defi nition and our modification   This is obvious  since Pr g  EI E    F       Note that F can be practically any formula here  We surely wouldn t want to accept   E and the coin lands heads  as an explanation for E  One possible solution to this problem is to restrict ex planations to only involving certain propositions  For example  if we are looking for an explanation for some symptoms  we might require that the explanation be a disease  There are many cases where such restrictions make sense  but if we are to do this  then we mus   Defining Explanation in Probabilistic Systems  bilities in that contracted belief state   If an approach like this is to be used in a system  we need techniques for computing the contraction  More accurately  since the contraction is not unique  we need to focus on ap plications where there is a relatively straightforward notion of contraction   explain where the restrictions are coming from      Even if we restrict attention to a particular vocabulary  for explanations  there is nothing preventing us from adding irrelevant conjuncts to an explanation  More precisely  note that if X is an explanation of E  and C is conditionally independent of E given X  then PrE  EJX    Pri EJX A C   Thus  X and X A C are viewed as equally good explanations         The fact that learning X raises the probability of E  does not by itself qualify X to be an explanation of E  For example  suppose s is a symptom of disease d and Bob knows this  If Bob learns from a doc tor that David has disease d and asks the doctor for an explanation  he certainly would not accept as an explanation that David has symptoms  even though Pr I djs    Pr f d   Giirdenfors is aware of this is sue  and discusses it in some detail        p        He would call s an explanation of d  but not a causal ex planation  Gi rdenfors provides a definition of causal explanation  Unfortuna tely  while it deals with this problem  it does not deal with the other problems we have raised  so we do not discuss it here   We dis agree with Gardefnors that there are explanations that are not causal  we view all explanations as causal  In particular  we do not think that Bob would accept s as an explanation of d at all  Note  however  that if Bob had asked the doctor why he   the doctor  believed that David had disease d  an acceptable explanation would have been that the doctor believed  or knew  that David had symptoms  There is a big difference between what Bob would accept as an explanation for d and what he would accept as an explanation of the doctor s belief that d  We return to this issue below      As a practical matter  Gardenfors  definition requires  the computation of the contraction of a belief state  besides the computation of many conditional proba    For the interested reader  C is said to be a causal explanation of E wi th respect to belief state K such that E Kif      Pr  C     Pr g E C       Pr j     E  PrE   Pr j    where is the belief state that arises when we add C to the stock of beliefs in K  This is the notion called belief expansion  Alchourr n           Pr g E        Giirdenfors  and Makinson        Thus  we add clause     to the definition of explanation  Note  however  if F is independent of E  then E    F would be a causal explanation of Similar  E   arguments show that Giirdenfors  definition of causal explanation still suffers from all the other problems we have raised   THE MAXIMUM A POSTERIORI  MODEL APPROACH     The definition does not take into account the likeli  hood of the explanation  For example  suppose there are two explanations for a symptoms  disease d  and d isea se d   with the same explanatory power  but d  is a relatively common disease  while d  is quite rare  If the explanation is given by an expert that is trusted by the user  as in the case of an intelligent tutoring system   then once we are told that  say d  is the ex planation  we would presumably accept it as true  In this case  the prior probability  i e   the fact that d  is rare  is irrelevant  However  in our context  even if Pr   sldt    Pr   s d    it seems clear that we should prefer the explanation dt to d             THE DEFINITION  Most of the work done on explanation in belief networks was based on the intuition that the best explanation for an observation is the state of the world that is most proba ble given the evidence  Henrion and Druzdzel       Pearl       Shimony        There is no notion of  cognitive dissonance  or surprise  The explanation is an  informed  guess about the possible world we are currently in  based on the evidence  which includes the explanandum   In some cases  e g    Pearl l       the guess must specify the world completely formulas describing sets of worlds are not allowed as explanations  This approach  which we call Maximum A Posteriori model  MAP  after  Shimony         has been also known under other names  Most Prob able Explanation  MPE   Pearl      and Scenario Based Explanation  Henrion and Druzdzell      Formally  according to Pearl  given an epistemic state K    W  Pr   an explanation for E is simply a world w in which E is true  This notion of explanation in duces an obvious ordering on explanations  World w  is a better explanation of E than w  if E is true in both w  and w  and Pr wiJE    Pr w jE   Finally  the best or most probable explanation  MPE  is the world w  such that Pr w jE    maxwEW Pr wJE    We remark that although we have spoken here of an ex planation as being a world  we could equally well take an explanation to be the formula that characterizes the world if we assume  as Pearl does  that each world is uniquely characterized by a formula  If our vocabulary consists of a finite number of propositions P         Pit  and each world is a truth ass gnment to these primitive propositions  then an explanation would have the form QII  A Qk  where each Qi is either Pi or Pi Of course  if we have richer languages  finding formulas that characterize worlds becomes more of an issue      Two other variants of the MAP approach have been pro posed  by Henrion and Druzdzel        and Shimony               They share with Pearl s definition two impor tant features  Ftrst  the explanation is a truth assigrunent to   Actually  Pearl did not define the notion of explanation  just that of most probable explanation  However  our definitions are certainly in the spirit of his  Also  he did not talk explicitly of  worlds and epistemic states  but these are implicit in his defini tions  Pearl assumes that there is a Bayesian network that de scribes a number of variables of interest  The set W then consists of all possible assignments to the variables  and the probability distribution Pr on W is determined by the Bayesian network        Chajewska and Halpern  a subset of propositions  including the explanandum  Sec ond  the ordering of explanations is based on their posterior probability given the explanandum  Henrion and Drozdzel actually discuss a number of ap proaches to explanation  Of most relevance here are what they call scenario based explanations  They assume a tree of propositions  a scenario tree   where a path from the root to a leaf represents a scenario  or a sequence of events  They are looking for the scenario with the highest probabil   ity given the explanandum  Thus  their approach differs from Pearl s in that the system has additional knowledge  the scenarios   They also allow explanations to be partial  The truth values of all propositions do not have to be spec ified  However  explanations are restricted to coming from a set of prespecified scenarios  Shimony              also allows partial explanations  He works in the framework of Bayesian networks  as does Pearl  in fact  although his definition makes sense even if probabilities are not represented using Bayesian networks    In his framework  the explanandum is an in stantiation of  truth assignment to  some nodes in the net work  these are called the evidence nodes  An explanation is a truth assignment to the  relevant  nodes in the net  work  The relevant nodes include the evidence nodes and  only ancestors of evidence nodes can be relevant  Roughly  speaking  an ancestor of a given node is irrelevant if it has the property that it is independent of that node given the values of the other ancestors  In  Shimony        the best  explanation is taken to be the one with the highest poste rior probability  In  Shimony        this is extended to allow explanations to be sets of partial truth assignments   subject to certain constraints  Section            A   discussed in more detail in  CRITIQUE  The MAP approach has an advantage over Gardenfors   it doesn t require contraction  However  it has its own problems  Some of the problems are particularly acute in Pearl s approach  with its requirement that the explanation  be complete  i e   a world  they are alleviated somewhat if  we allow partial explanations  sets of worlds   However  some of the problems arise in all variants of the approach  and are a consequence of ordering according to the posterior probability distribution     By making the explanation a complete world  the no  tion becomes very sensitive to the choice of language  as Pearl himself observes    For example  if our lan guage consists of  s  d   d    then the best explanation    Actually  they suggest presenting all scenarios that have suf ficiently high probability  and pointing out how the most probable one differs from the other likely scenarios    Recall that a Bayesian network is an acyclic directed graph whose nodes represent primitive propositions  or random vari ables   together with conditional probability tables describing the probability of a node given instantiations of its parents  Pearl          Shimony        calls this the  overspecification problem   for symptoms might be d   or  more precisely  the world characterized by s A d   A     d   For the purposes of this example  suppose that diseases are mutually exclusive  so all worlds where the agent has more than one disease have probability    Now suppose we sub divide d  into two diseases d and d   again mutually exclusive  as  for example  hepatitis can be subdivided into hepatitis A and hepatitis B   Then we might find d  to be a better explanation than either d or d  that is  Pr  d A d A d l s  may be greater than either Pr d A   d   A d ls  or Pr  d Ad A d ls       Pearl gives an even sharper example of this phe  nomenon  Suppose that d  is a a diagnosis of per fect health  d  is a diagnosis of a fatal disease  Pr dtls         and Pr d ls         Now suppose we expand the vocabulary to include h       hs  where the hi s are possible holidays that the agent will take next year  provided he or she is indeed healthy   and the agent considers each of these vacation plans equally      and the likely  Then we have that Pr  h  A dtl s  most likely explanation of the symptom has changed          from d   to d   So just by considering possible holidays he might take given that he is healthy  the agent finds that the best explanation for his symptoms becomes a fatal disease      A  related problem is the fact that if we have a large  number of primitive propositions  most will probably  be irrelevant or only marginally relevant to explaining a particular proposition  Yet  Pearl s definition forces us to consider worlds  thus forcing us to worry about the truth value of all propositions  This can cause computational problems  In addition  conciseness is a  desirable feature in an explanation  particularly in an interactive system  The user usually wants to know only the most influential elements of the complete explanation  and does not want to be burdened with unnecessary detail  This problem is particularly se vere if we insist on complete explanations  However  Shimony s partial explanations are not necessarily as concise as one would hope either  It is not hard to show that for each evidence node X  the explanation must include an assignment to all the nodes in at least one path from X to the root  since for each relevant node  at least one of its parents must be relevant Moreover  the irrelevance condition is quite strong and only in limited contexts is it likely to achieve significant prun ing  Shimony attempts to overcome this problem by relaxing the irrelevance assumption to what he calls approximate or   irrelevance  While helpful in some domains  the extent to which it will result in concise explanations in general is not clear  We discuss this point in more detail in the full paper      The ordering on explanations used in the MAP ap proach is supposed to maximize the probability of the explanation given the explanandum  However   if we consider only explanations which include the explanandum  as all MAP explanations do   this re duces to maximizing the prior of the explanation  The ordering is then based only on the likelihood of the ex planation and not in any way on the degree to which the   Defining Explanation in Probabil istic Systems  explanation raises the probability of the explanandum      All the MAP approaches discussed above consider es sentially propositional languages  Once we move to richer languages  like first order  or languages that al low statistical information   then each world may end up having very low probability  Indeed  if we have a continuous number of worlds  each world may have probability    In this case  the definition which re quires explanations to be complete worlds is not even useful  Given the difficulties with complete explanations  why do Shimony and Henrion and Druzdzel put such restrictions on the allowable partial explanations  What is the prob lem with partial explanations  Suppose our language con sists of the propositions  Pl        pk   Why not just allow Pl as an explanation  instead of requiring something like Pl A     P          A    pit  Gardenfors certainly allows such explanations  It is not bard to see why Pearl does not allow partial explanations  Notice that a partial explanation is really a set of worlds  or equivalently  the disjunction of the formulas representing the worlds   But a disjunction will always have higher conditional probability than any of its disjuncts  except in the degenerate case where all but one of the disjuncts has probability     and thus will be viewed as a more probable explanation than any of its disjuncts  It is because of this that Shimony puts restrictions on the allowable partial explanations as well  As we shall see  we can deal with this problem  at least to some extent  by modifying the ordering of explanations      SYNTHESIS  As we have seen  both Gardenfors  definition and the MAP definition have problems  We believe that in order to deal with these problems  we need to deal with two relatively orthogonal issues      we must decide what counts as an explanation  and     we must decide how to compare two explanations        WHAT COUNTS AS AN EXPLANATION   The MAP approach seems somewhat too restrictive in what counts as an explanation  An explanation must be a com plete description of a world  or a restricted form of partial explanation   Gardenfors  on the other hand  is not restric tive enough  He allows E A C to be an explanation of E  for example  and this seems to us unreasonable  In ad dition  he would allow a falling barometer reading to be an explanation for a storm  thus missing out on the causal structure  As we mentioned above  we view all explanations as causal  We distinguish between explaining facts and explaining be liefs  but in both cases we look for the same thing in an explanation  a causal mechanism which  possibly together with some facts  is responsible for the fact observed or the beliefs adopted  By enforcing causality  AGMwe be lieve that we can avoid the problems in G rdenfors  defini tion  while still allowing more general explanations than the      MAP approach would allow  We remark that we are not the first to stress the role of causality in explanation  Salmon  I      discusses the issue at length  although the technical details of his proposal are quite different from ours  The literature on causality is at l east as large as the literature on explanation  it is well beyond the scope of this paper to develop a new theory of causality  For the purposes of the rest of this paper  we work at the propositional level  since that is essentially what the recent approaches to causality do  and assume that the causal mechanism is described by a causal structure  which we take to be a Bayesian network interpreted causally   We believe that much of what we do is independent of the particular way we choose to model causality  In particular  we can replace the causal network by structural equations  as described in  Druzdzel and Simon       Pearl       We have chosen to use Bayesian networks as our representation for causality simply to make it easier to relate our approach to Pearl s approach  In this setting  part of the agent s uncertainty concerns what the right causal mechanism is  For example  an agent may be uncertain whether smoking causes cancer or whether there is a gene that causes both a susceptibility to cancer and a susceptibility to smoking  Thus  we assume that a  world is a pair   w  C  consisting of a truth assignment w and a causal structure C  As before  an epistemic state K is a pair  W  Pr   where W is a set of worlds of this form  and Pr is a probability distribution on W  However  we assume that this epistemic state arises from a simpler  description  We assume that the agent has a probability distribution Pr  o n causal structures and has made some observations  Notice that a causal structure  C  also places  a probability distribution Pre on worlds  We require that  the distribution Pr be consistent with the causal mechanisms  considered possible and the observations   in the following  sense  There must be a probability distribution IY on causal mechanisms such that Pr w  C    Pr  C  Prc wiO   that is  the probability of  w  C  is the probability of the causal mechanism C times the probability that C induces on w  given the observation  In particular  this means that if the agent considers only one causal mechanism possible  we can identify Pr with a probability on truth assignments  just as Pearl does   We assume that the explanandum E is one of the ob This means that Pr E has a simple form  servations   Pr     w C      Pr  C  Prc wiO    E    It is easy to see  that this definition satisfies the postulates for contraction  An explanation of  E in epistemic  state  K  is a conjunction  X   X      X  consisting of a partial causal mechanism X   that is  a description of a causal structure  see below  and an instantiation of nodes X  that causally precede E in Xt such that Pr X    l   Yt e defer for now the is sue of whether the explanation raises the probability of the explanandum   We are deliberately being vague about the language used to describe the causal mechanism  since we believe that this is  an area for further research  For the purposes of this paper        Chajewska and Halpern  we can take Xt to be simply a description of a subgraph of the causal graph  intuitively  that part of the causal graph that is relevant to explaining E  i e   a subset of the set of paths from nodes in X  to E   We allow the conjunct describing the causal mechanism to be missing from the explanation if it is known   In practice  this might mean that the system providing the explanation believes that the agent to whom the explanation is being pro vided knows the causal mechanism   Notice that if the agent knows the causal mechanism  and thus considers only one causal mechanism possible  as is implicitly the case when a situation is described by a Bayesian network which is given a causal interpretation   then a world can be identified with a truth assignment  In this case  ignoring the requirement that all the conjuncts in a basic explanation of E must pre cede E causally   what Pearl called an explanation would be a special case of what we are calling an explanation  However  we allow more general explanations  in that we do not require an explanation to be a truth assignment  In this sense  our framework can be viewed as generalizing Pearl s and S bimony s   Our definition also borrows heavily from Glirdenfors  defi nition  We take from him the requirement that Pr  X        His other requirement  that Pre E I X     Pre  E   will also play a role in our ordering of explanations  The form of the explanation a conjunction of a  partial  causal mech anism and an instantiations of nodes is also taken from G irdenfors   Since we are working with propositional Bayesian networks  the instantiation of nodes clearly corre sponds to taking the conjunction of atomic sentences in first order logic  Giirdenfors allows disjunctions as well  since he allows singular sentences  which are Boolean combina tions of atomic sentences   Allowing disjunctions seems to cause problems for us  we return to this issue in Section      The  partial  causal mechanism can be viewed as a gener alization of statistical assertions  We view the requirement of the causal mechanism as a key difference between our definition and Giirdenfors   For one thing  the causality requirement prevents E    C from being an explanation of E  since E cannot precede E in the causal ordering  It also prevents a symptom from being an explanation of a disease  We would argue that causality is what makes most of Gardenfors examples involving statistics so compelling  For example  consider the case of Mr  Johansson  We be lieve that the explanation      of those who work with asbestos develop lung cancer  involves more than just the statistical assertion  It is accepted as an explanation because we implicitly accept that there is a causal structure with an edge from a node labeled asbestos to a node labeled lung cancer  with a conditional probability table saying that the probability of lung cancer given asbestos is       And it is the lack of causality that causes us  if the reader will pardon the pun  not to accept      of the time that the barometer reading goes down there is a storm  as an explanation of a storm  unless we happen to believe that barometer readings have a causal influence on storms     Originally   the idea carne from Hempel s work on explanation   Hempel and Oppenheim         However  the situation is different if we try to explain our beliefs to someone else  In this case  the causal structure is symmetric  The fact that I believe that there is a storm does explain my belief that the barometer reading has gone down  my belief that the barometer reading has gone down is an explanation for my belief that there is a storm  Ultimately  these beliefs should be rooted in an observation  either of the storm or the barometer   We can readily convert a causal network describing a sit uation to a network describing an agent s beliefs  We just reinterpret all the nodes so that a node labeled X talks about the agent s belief in X  moralize the graph and change all the directed edges to undirected edges  The resulting Markov network  Pearl        captures the causal as well as proba bilistic dependencies between the agent s beliefs  Note that the resulting network is no longer asymmetric  While we do not view a symptom as a cause for a disease  believing that a patient has a certain symptom might well cause us to believe that he has a disease  However  an explanation for the agent s beliefs would then be an acyclic subnetwork of this network  together with some new nodes representing the external causes of some of the beliefs  For example  an external cause for the belief that the patient has symptom d is the observation of the symptom  an external cause for the belief that David has an ear infection might be receiving that information from a doctor  We discuss this in more detail in the full paper        ORDERING EXPLANATIONS  As we have seen in the few examples presented so far  and as is indeed the case in many applications  there are typi cally several competing explanations  We need to be able to compare them and choose the best  The two proposals pre sented above for ordering explanations Giirdenfors  no tion of explanatory power and Pearl s notion of considering the probability of the explanation given the explanandum both have their merits  but neither seems quite right to us  The following example might help clarify the differences between them   Example     Assume that we have a bag of     coins     of which are strongly biased       towards heads and one that is just as strongly biased towards tails  We pick a coin at random and toss it  The coin lands tails   We can nwdel this situation by using two random variables  C  the type ofcoin  with values bh and bt  biased towards heads and biased towards tails  and R  the result of the toss   with values h and t  A priori  the probability that we picked a coin that is biased towards heads is very high  in fact P C    bh        After receiving the evidence of the coin landing tails  wefind out that P C    bhiR t  is close to      less that the prior on C   bh but still very high  What explanation would we acceptfor thefact that the coin landed tails  Clearly  the causal structure in this situation is known  there is a causal relation between C and R  with the obvious conditional probability table described by the story  Since the causal structure is known  the allowable bh and C bt  explanations can be identified with C            Defining Explanation in Probabilistic Systems  What is the relative merit of these explanations   According to Gardenfors  definition  C   bt is a much better explanation than C   bh  since Pr R   tiC   bt  is much greater than Pr R      respect to E and the prior of X   We can then place a partial order t E on explanations of E by taking X   t E X  iff EP X    E   EP X   E  and Pr E XJ    Pr E  X     Notice that with thi s ordering  the two explanations in the    ti C   bh    where Pr is the prior probability distribution  before the outcome R   t is known  Intuitively  C   bt has far better explanatory power because it accounts for the observation far better than C   bh does   forces the user to decide whether the explanatory power or  According to Pearl s ordering  the best explanation of the coin landing tails is C   bh  since Pr  C   bh R t  is much greater than Pr  C   bti R   t    This explanation  although  Although the ordering is partial in general  it can be viewed as a natural generalization of Pearl s ordering  Suppose the  On the other hand  the explanation seems unsatisfactory  since it does not take into account the low probability that the coin biased towards tails will be picked   very likely itself  doesn t seem to relieve the  cognitive  dissonance  between the explanandum and the rest of our beliefs  While it may be the correct diagnosis of the situa tion  it doesn t seem right to call it an explanation  The fact that the potential explanation is less probable a posteriori than a priori should at least cause some suspicion   Pr C    bh  R  The term     t      R    bh    X  Pr C    bh     Pr  Jbh  is what we called the explanatory  power of C   bh with respect to R   t  Thus  the degree to which C bh is an explanation of R   t according to Pearl is precisely the product of EP  C   bh  R  t  and the prior probability of C   bh  Thus  we can see the precise sense in which Pearl s definition takes into account the prior whereas Gardenfors  does not     Although the two definitions disagree in this example  there are many situations of interest in which they agree  which is  perhaps  why both have seemed to be acceptable definitions of the notion of explanation    In particular  they agree in situations where the prior probability of all explanations is the same  or almost the same   Thus  if the user has no particular predisposition to accept one explanation over another  both approaches will view the same explanation as most favorable    Since we cannot always count on the prior of all explana tions being equal  we would like an ordering on explana tions that takes into account both the explanatory power and the prior  One obvious way of taking both into ac count is to multiply them  which is essentially what Pearl does  but multiplication loses significant information and sometimes gets counterintuitive results   More examples of this appear below   A straightforward alternative is to associate with each explanation X of E the pair of numbers   EP  X E    Pr E  X            bh  and  C   bt  are incomparable   This  the prior is the more significant feature here  In a case like this  such a wide divergence between the explanatory power and the prior of two explanations might signal a problem with the causal model  Perhaps the agent s prior on C   bh vs  C   bt is incorrect in this case   causal mechanism is known  as is implicitly assumed by  Pearl  If we allow explanations that are complete descrip  tions of worlds  then all complete descriptions that include E have exactly the same explanatory power      Pr E   E     Thus  our ordering would order them by their prior  just a s Pearl s and Shimony s does   Our ordering also avoids the problem in Gardenfors  or  Notice that by Bayes  rule   Pr   coin example  C  the explanatory power of  X  with     Note that  according to Pearl s definition  C   bh would not be an explanation of R   t  The two possible explanations would  be C   bh i  R    t and C   bt l  R   t  What we are analyzing here is the ordering produced by Pearl s definition of better explanation on the notion of explanation defined according to our approach    Here we are also implicitly assuming that there is a prior agreement on what counts as an explanation  As we have ob served  the two approaches differ in this respect too   dering that adding irrelevant conjuncts results in an equally preferred explanation  For example  if X is an explanation of E then X    Y  for all Y conditionally independent of E given the epistemic state  would be considered a worse explanation than X in our ordering since their explanatory powers are the same and X  s prior is higher   If we add a conjunct that is not completely irrelevant  then our approach forces the agent to decide between more spe cific explanations that have higher explanatory power  and less specific explanations  that have a higher prior  For example  suppose we want to understand why a somewhat sheltered part of the lawn is wet  One possible explanation is that it rained last night  but rain does not always cause that part of the lawn to get wet  A better explanation might be that it was raining and very windy  The combination of rain and wind has better explanatory power than rain alone  but a lower prior  According to our ordering  this makes the two explanations incomparable  This does not seem so unreasonable in this case  We would expect a useful explanatory system to point out both possible explanations  and let the user decide if the gain from the extra explanatory power of wind is sufficiently high to merit the lower prior   Note that if we multiply the explanatory power of the ex planation by its prior  we will always prefer the expla nation  rain   To see this  note that for any explanation  X  the product of the explanatory power and the prior is Pr E  X JE    Since clearly Pr E   X J E   Pr E X A Y I E   the simpler explanation i s preferred  This is a case where multiplication causes a loss of useful information        DEALING WlTH DISJUNCTIONS  As we have defined it  an explanation is a conjunction of a partial causal mechanism together with an instantiation of nodes  We have not allowed disjunctions  Disallow ing disjunctions of causal mechanisms seems reasonable  It is consistent with the intuition that  you have cancer either because you smoke or because you have a genetic       Chajewska and Halpern  predisposition to cancer  is viewed as a disjunction of two explanations  not one explanation which has the form of a disjunction  We suspect that it is for similar reasons that Gardenfors disallowed the disjunction of statistical asser tions in his definition   On the swface  it may seem less reasonable to disallow  the disjunction of instantiations of nodes  Certainly it is straightforward to modify our definition so as to allow them  and doing so would be more in keeping with Glirdenfors   allowing singular sentences  However  notice that allowing the disjunction of instantiations bas the effect of allowing disjunctions of causal mechanisms   Consider a case in which we ask for an explanation of huge forest fires recently occurring in California  One possible explanation is that the fire prevention caused the brush to overgrow  another that the tourists often leave campfires  unattended  Both these explanations are very plausible  and so is their conjunction   Suppose the agent considers only one causal network possible  and it contains both of these  mechanisms  Thus  by allowing the explanation  either some tourists left their campfire unattended or the brush was overgrown   we are effectively allowing a disjunction of causal mechanisms  This example suggests that we may want to make a distinction between what appear to be two different causal mechanisms co existing within the same causal structure  perhaps using the techniques discussed by Druzdzel and Simon           This is an area for future research   On the other hand  there  are cases where allowing disjunc  tions seems useful  For example  consider a situation in which we have four coins  Ct   C   C    and C    where Ct  and c    are biased towards heads and c  and c  are bi ased toward tails  We pick one coin at random and toss  it three times  The coin lands heads every time  The ob  vious explanation for this fact is that we picked one of the coins biased towards heads  that is  either cl or c     And  indeed  our ordering would prefer the explanation X   det   C   CJ   v   C   C   to either of the explanations C   C  or C same bias      C   assuming that both  C   and C  had the  way for deciding when to add such variables  Shimony s work can be viewed as an attempt to provide  principles as to when to consider disjunctive explanations  The partial explanations of  Shimony        are sets of worlds where the truth values of some primitive propo  sitions are fixed  whi le the rest can be arbitrary  The sets of  partial explanations of  Shimony        correspond to more general sets of worlds  but there are still significant restric tions  For example  the disjunctive explanation must corre spond to a node already in the network and the probability of the explanandum must be the same for every disjunct in the disjunctive explanation  The latter restriction is quite severe  In our coin example  if the coins biased towards heads have different biases  Shimony s approach would not allow us to consider the explanation xl    we picked a coin biased towards heads   Of course  we can easily loosen this restriction to allow disjunctions where the conditional probabilities are almost the same  However  it seems to us that we want more than just similar conditional probabili ties here  We only want to allow disjunctions if the causal mechanism for each disjunct is the same   To be fair  Shimony uses his restrictions to allow him to find good explanations algorithmically  It is not clear whether there are also philosophical reasons to restrict them in this way  We hope to explore both the algorithmic and founda tional issues in future work      CONCLUSIONS  We feel that the contribution of this paper is twofold  First  we present a critique of two important approaches to ex planation  second  we outline a sketch of a novel approach that tries to take into account the best features of both  and combine them with a notion of causality   Our approach clearly needs to be fieshed out  S ome areas for future research include    By way of contrast  the explanation X   dcf  C   Ct   V   C   C    v   C   C    does not seem at all reasonable although  according to our ordering  it is incomparable to XJ   While XI has higher explanatory power  x  has a higher prior  While most people would clearly reject X    it would be useful to have to have some automatic way of rejecting it     on their application to causal reasoning  Along simi  This example suggests that rather than allowing disjunc tions  a better strategy might be to add an additional variable representing the type of the coin  with possible values bh and bt  as before   However  we have as yet no principled  lar lines  it would be useful to have a good language for reasoning about causality  that allowed first order reasoning and temporal constructs       orh is is another case where multiplyin g the components gives a misleading answer  Xz has a higher product than X    In general  if we compare the explanation X to a disjunctive explanation X V Y by multiplying the explanatory power times the prior  then we will always prefer X V Y to X   for the same reasons as given earlier for preferring X to X    Y   Obviously  much of the effort will involve research in causality  Most of the work in causality has allowed only what amounts to propositional reasoning   The nodes represent random variables that take on a small finite number of values   Can we extend it to allow causal explanations that involve first order constructs and temporal constructs  There has been some work on adding these constructs to Bayesian networks  see  for example   Dean and Kanazawa        Glesner and Koller       Haddawy          but no work focusing  As we have observed  our approach  which provides only a partial ordering on explanations  seems too  weak  While it is not clear that we want to have a total order  it does seem that we want to allow more explanations to be comparable than is the case accord ing to our ordering  This is particularly the case if we allow disjunctive explanations    Defining Explanation in Probabilistic Systems      A natural extension would be to apply our definition to countetfactuals  After all  humans seem to have no problem with ex plaining hypothetical facts  We believe that our basic framework should be able to handle this  although per haps we may need to use structural equations and the interpretation of countetfactuals given by Balke and Pearl           As we said earlier  given that our goal is to have the system provide an explanation that is useful to a user  it would be important to model the user s knowledge state and adjust explanations accordingly  The work of Suermondt         is relevant in this regard  He also puts the emphasis on explaining beliefs  or  specifi cally  probability distribution over the node of inter est  adopted by the system as a result of receiving some observation  His goal is to find a small subset of ev idence responsible for this change and the links most influential in transmitting it  In our context  we can understand Suermondt as considering a system which has full knowledge of the domain  characterized by a Bayes Net together with all the conditional probability tables  and knows the values of some variables  trying to explain its beliefs to a user with no  or minimal  knowledge  Thus  for him  an explanation amounts to finding a  small  set of instantiations of variables  i e   a partial truth assignment  and a   small  partial causal mechanism that will raise the posterior probability of the observations   Given the importance of explanation  we believe that these questions represent fruitful lines for further research   Acknowledgments We thank anonymous reviewers for pointing out several im portant references and Adam Grove for useful discussions  Part of this work was carried out while the second author was at the ffiM Almaden Research Center  IBM s support is gratefully acknowledged  The work was also supported in part by the NSF  under grants IRI            and IRI           and the Air Force Office of Scientific Research  AFSC   under grant f                    
   We define a new notion of conditional which plays the same role for Dempster Shafer belief functions as conditional probability does for probability functions  Our definition is dif ferent from the standard definition given by Demp ster  and avoids many of the well known problems of that definition  Just as the conditional prob ability Pr IB  is a probability function which is the result of conditioning on B being true  so too our conditional belief function Bel  IB  is a belief function which is the result of conditioning on B being true  We define the conditional belief as the lower en llelope  that is  the infimum  of a family of conditional probability functions  and provide a closed form expression for it  We show by example the intuitive appeal of our definition  and compare it in detail to the more standard definition  showing why and how it differs  belief      Introduction  How should one update one s belief given new ev idence  If beliefs are expressed in terms of proba bility  then the standard approach is to use condi tioning  If an agent s original estimate of the prob ability of A is given by Pr A   and then some new evidence  say B  is acquired  then the new estimate is given by the conditional probability Pr AIB   defined as Pr A n B  Pr B    The Dempster Shafer approach to reasoning about uncertainty  Sha    has recently become quite popular in expert systems applications  see  for example   Abe    Fal    LU    LG      This approach uses belief functions  a class of functions that satisfy three axioms  somewhat related to the axioms of probability  In this paper  we consider how to define a  notion of conditional belief  which generalizes conditional probability    Thie definition ie not completely uncontrovereial   aee  e g    DZ    for a diecu  ion and further references    One definition for conditional belief was already suggested by Dempster  Dem  J  and is derived us ing the rule of combination  hereafter we refer to Dempster s definition a s the DS definition of con ditional belief  Although the DS definition also gen eralizes conditional probability  it is well known to give counterintuitive results in a  number of situa tions  see  e g    Ait    Bla    Dia    DZ    Hun    Lem    Pea     Pea     Za d     We provide here a  new definition of conditional belief  which also generalizes conditional probability  but is different from the DS definition in general  We can show that our definition avoids many of the problems as sociated with the DS definition  The motivation for our definition of conditional belief comes from probability theory  It is well known that a  belief function Bel is the lower en  l elope of the family of a ll probability functions Pr consistent with Bel  That is  Bel A  is the infimum of Pr A   where the infimum is taken over a ll pro b a bility functions Pr such that Bel A    Pr A   for a ll A    We define Bel AIB  to be the lower enve lope of the family of a ll functions Pr IB  where Pr is consistent with Bel  similarly to the situa tion with conditional probability  we assume that Bel B       so that everything is well defined   Although we define Bel  IB  in terms ofa lower en velope  we show that there is an elegant closed form expression for it  Moreover  we can show that just a s the conditional probability function is in fact a probability function  our conditional belief function is a belief function  The rest of this paper is organized as follows  In the next section  we review belief functions and de fine our notion conditional belief  We show how it compares to the DS notion by applying both defiSome author   e g    DP     have used the term lower to denote what we are calling lower envelopes  We have ueed the term lower envelope here to avoid con fuaion with Dempeter   technical uaage of the phraae lower probability in  Dem    Dem  J  which  although related  is not equivalent to what we are calling a lower envelope     probability        nitions to the well known three pri oner  problem  Gar    Dia     We then conduct a more thor ough investigation of the differences between the two notions  and their relationship to conditional probability  showing why the DS notion occasion ally provides counterintuitive answers  In Section   we discuss the relationship between belief functions and sets of probability functions  We conclude in Section   with some discussion on the implications of our results to the use of belief functions     Updating belief functions  Recall that a probability space is a tuple  S  X  Pr   where S is the sample space  X is a collection of sub sets of S containing S and closed under complemen tation and countable union  and Pr is a probability function defined on X  Note that Pr is defined not on all subsets of S  but only on the sets in X  tra ditionally called the mea urable sets  Subsets of S not in X are called nonmea urable  The Dempster Shafer theory of evidence  Sha    provides an approach to attaching likelihoods to events that is different from probability theory  The theory starts out with a belief function  For every event  i e   set  A  the belief in A  denoted Bel A   is a number in the interval        that places a lower bound on likelihood of A  We have a corresponding number Pl A       Bel A   called the plausibility of A  which places an upper bound on the likelihood of A  Thus  to every event A we can attach the in terval  Bel A   Pl A    Like a probability measure  a belief function assigns a  weight  to subsets of a set S  but unlike a probability measure  the domain of a belief function is always taken to be all subsets of S  Formally  a belief function Bel on a set S is a function Bel                satisfying  BO  Bel           Bl  Bel A    B   Bel S  B   Bel A         A    LI   l     A   I f             Bel niEI Ai   u     u  We remark that a probability function defined on all of     is easily seen to be a belief function  In a companion paper  HF     we argue that there are two quite distinct ways of relating be lief functions to probability theory  One approach views belief as a generalized probability  the sec ond views it as a way of representing evidence  H we would like to update beliefs  then it seems most appropriate to view beliefs as generalized probabil ities  There are a number of ways of doing this   Dem    Dem    FH  b  Kyb    Sha     We fo cus on one here  since it is perhaps the most well known  that is the approach of viewing a belief function as an infimum of a family of probability functions  Given a set    of probability functions all defined on a sample space S  define the lower en  elope of    to be the function J such that for each A S  we have f A    inf  Pr A    Pr E      We have the corresponding definition of the upper en  Ielope of     It was already known to Dempster  Dem    that a belief function can be viewed as a lower envelope  More formally  let Bel be a belief function defined on S  and let  S  X  Pr  be a prob ability space with sample space S  We say that Pr is consistent with Bel if Bel A   Pr A   Pl A  for each A E X  Intuitively  Pr is consistent with Bel if the probabilities assigned by Pr are consistent with the intervals  Bel A   Pl A   given by the belief function Bel  It is easy to see that Pr is consistent with Bel if Bel A   Pr A  for each A E X  that is  it follows automatically that Pr A   PI A  fo each A E Xl   This is because Pl A        Bel A       Pr A    Pr A   Let   Bel be the set of all probability functions defined on     consistent with Bel  The next theorem tells us that the belief function Bel is the lower envelope of   Bel  and Pl is the upper envelope  Theorem      Let Bel be a belief function on S  Then for all  A S   Bel A    infp e p    Pr A  Pl A    supp  E  Ps    Pr A   We remark that the converse to Theorem     does not hold  not every lower envelope is a be lief function  Counterexamples are well known  Bla    Dem    Kyb     We return to this issue in Section    Theorem     suggests how we might update a belief function to a conditional belief function  and a plausibility function to a conditional plau ibility function   We define  Bel AIB      Pl AIB     inf  Pr AiB   sup  Pr AiB    PE Psel PE Psel  It is not hard to see that the infimum and supre mum above are not well defined unless Bel B       therefore  we define Bel AIB  and Pl AIB  only if Bei B       It is straightforward to check that if Bel is actually the probability function Pr  then Bel AlB    Pr AIB   Thus  our definition of con ditional belief generalizes that of conditional prob ability  Note that taking B   true in the preceding  I I I I I I I I I I I I I I I I I I I        I I I I I I I I I I I I I I I I I I I  definition  we get as a special case that Bei A     infp e      Pr A  and Pl A    supp E   s t Pr A    which is Theorem     above  Our definition of conditional belief and plausibil ity does not give us much help in computing these expressions  We would like to have a closed form expression for them  We can in fact provide an elegant closed form expression  as shown in the fol lowing theorem  Theorem      If Bel is a belief function on S such  that Bei B    Bei AIB   O      Pl AIB     then Bel A n B  Bel An B   Pl A n B  PI An B   Pl An B   Bel A n B   The expressions given above for conditional belief and plausibility are quite natural  Not sm   risingly  it turns out that other authors have discovered them as well  In particular  essentially these ex pressions appear in  Wal      SK     and  dCLM     Indeed  it even appears  lost in a  welter of notation  as Equation     in  Dem      Interestingly  none of these papers references any other work as the source of the formula   It is well known that the conditional probability function is a probability function  That is  if we start with a probability function Pr on S  and B is a subset of S such that Pr B       then the func tion Pr IB  is a probability function  We might hope that the same situation holds with belief func tions  so that the conditional belief and plausibility functions are indeed belief and plausibility func tions  Given our definitions of conditional belief and plausibility as lower and upper envelopes  it is not clear that this should he so  since lower and up per envelopes of arbitrary sets of probability func tions do not in general result in belief and plau sibility functions  Fortunately  as the next result shows  in this case they do  Thus  we have a way of updating belief and plausibility functions to give us new belief and plausibility functions in the light of new information  Theorem      Let Bel be a belief function defined  on S  and PI the corresponding plausibility func tion  Let B  S be such that Bel B      Then Bel IB  is a belief junction and Pl IB  is the cor responding plausibility function   The proof of Theorem     is somewhat difficult  We outline the proof in the appendix  full details can be found in the full paper  FH  a   We remark  that this result which we view as the main tech nical result of the paper appears in none of the papers cited above that contain the expression for conditional belief from Tlteorem      In  dCLM    the question of whether Bel  IB  is a belief function is discussed  but left unanswered  As we mentioned in the introduction  our defi nition is quite different from that given by Demp ster  Given a belief function Bel   Dempster defines a conditional belief function Bel IIB  as follows  Sha    p        Bel AIIB     Bel Au B   Bel B       Bel B   The corresponding plausibility function is shown to satisfy  PI  An B  Pl AIIB    Pl B    A brief glance at the DS definition compared with the formula in Theorem     should convince the reader that in general these two definitions of con ditional belief will not agree  It is easy to show that both definitions of conditional belief general ize the standard definition of conditional probabil ity as long as all sets are measurable  that is  have a probability assigned to them  The key difference turns out to be in the way they treat nonmeasurable sets   See  FH  b  for a discussion of nonmeasur able sets and their relationship to belief functions   We return to this issue below  we first consider an example that highlights the differences between the two approaches  Example  In order to compare our updating tech nique with that of Dempster  we consider the well known three prisoner   problem    Of three prisoners a  b  and c  two are to be executed but a does not know which  He therefore says to the jailer   Since ei ther b or c is certainly going to be ex ecuted  you will give me no information about my own chances if you give me the name of one man  either b or c  who is go ing to be executed   Accepting this argu ment  the jailer truthfully replies   b will be executed   Thereupon a feels happier  Dempacer t definition is uaually  given  aa a special ap  plication of a more  eneral   Uie of combination for belief functions  It would take us too far afield here co discuaa the  rule of combination  aee the companion paper   HF     for a  ditcuaaion of the role of the rule of combination    For  an excellent introduction to the problem as well a a  Bayeaian aolution  see   Gar      Our description of the story  ia taken from  Dia    and much of our discuuion is baaed on that of Diaconis and Zabell  Dia    DZ             because before the jailer replied  his own  Thus  in this case  the jailer s answer does not affect  chance of execution was two thirds  but  a s probability  Suppose more generally that  afterwards there are only two people  him self and  c     a    who could be the one not ex  one half   a  replied  he seems to be implicitly assuming that  I  Pr aaya b    Pr    a  b     Pr    c  b      a        I  the one to get pardoned is chosen at random from and  c   Then straightforward compu  Pr livea a    a     to believe that his own  chance of execution was two thirds before the jailer  a  b           Pr livea ajaaya b     We make this assumption ex  plicit in the remainder of our discussion   Is a justified in believing that his chances of es caping have improved  It seems that the jailer did not give him any relevant extra information  Yet how could a s subjective probabilities change if he  does not acquire any relevant extra information   X  a      a   a         a          This says that if a           i e   if the jailer had a par ticular preference for answering either b or c when a was the one pardoned    then a would learn some thing from the answer  in that he would change his estimate of the probability that he will be executed   For example  if  a        then if a is pardoned  the Thus  if the jailer actu   DZ     we model a possible situation by an ordered pair   c  y   where  c  y E  a  b  c   In tuitively  a pair   c  y  represents a situation where  c is pardoned and the jailer says that y will be ex  jailer will definitely say  ecuted in response to a s question  Since the jailer  c is pardoned  then the jailer will say b  while if b is pardoned the jailer will say c  Given that the jailer says b  then from a s point of view the one pardoned is equally likely to be him or c  thus  Pr live alays b         As a  ranges from   to    it is easy to check that Pr livea aiaaya b  ranges from   to       Following  answers truthfully  we cannot have   c    y   since  the jailer will never tell a directly that a will be  y   a  Thus  the set of possible outcomes is    a  b    a  c     b  c      c  b    The event that a lives  which we denote livea a  corresponds to the set   a  b    a  c    Similarly  we define the events livea b and livea c  which corre spond to the sets   b  c   and   c  b    respectively  executed  we cannot have  By assumption  each of these three events has prob ability        aaya b   ally says  b   pardoned  i e   that  ilarly  if  c   then a knows that he is definitely not  a        Pr livea aiaaya b        Sim  then a knows that if either he  or  How can we capture this situation using a belief  function  It seems reasonable that if lief function and  PI  Bel  is the be  the corresponding plausibility  function used to capture the situation  then  Bel  b   which we de  should agree with probability function where the  corresponds to the set    a  b    c  b     probability is known  so that   The event that the jailer says note  a priori  both the li lles a  li lles b   the story does not give us a probability for this  belief and plausibility of the events  event   li IJt s c should be      All we know about the a priori probability of says b is that it lies between     and      it is at least the probability that c is chosen   since in that case the jailer must say b    In order to do a Bayesian analysis of the  situation  we will need this probability  Note that we do know that the probability of    c  b   is        a  b     we just need to know the probability of  This depends on the jailer s strategy in the one case that he has free choice  namely when gets to choose between saying  b  and  c  a  lives  He  in that case   We need to know the probability that he says i e    If  b   Pr aaya bjlivea a   we assume that the jailer chooses at ran  b and c if a is pardoned  so that Pr aaya bjlivea a         then Pr   a  b      Pr    a  c          and Pr aaya b         We can dom between saying  now easily compute that  Pr livea ajaaya b    Pr livea a n aaya b  Pr aaya b                      I  Pr aaya bjlivea a   Pr     a  b     Note that in order for  a   tations show that  ecuted  and so his chance of execution is  among  for       Pr aaya bllives a   I  and  and it cannot be more than the probability that  b  Bel satis Pl aay b         Simi we can argue that Bel livea a n aaya b      Pl livea a n aaya b         Plugging these  is not chosen  Thus  we assume that  fies  Bel aay b         larly  while  and  numbers into our formulas  it is easy to compute that        Bel livea aiiaya b    Pl livea aiiaaya b    Thus   for the DS notion of conditional  probability  the range reduces to the single point       By way of contrast  it is easy to check that Bel livea ajaaya b      while Pl livea ajaaya b         I This example shows that the two notions of con ditioning can give quite different answers   The  I I I I I I I I I I I I I I I        I I I I I I I I I I I I I I I I I I I  range          computed by our notion of condition ing is easy to explain  it is precisely the range de termined by letting the probability that the jailer will say b in the one situation that he has a choice between saying b and c  namely  when a is the one pardoned  range from   to    The fact that our definition gives this range is not an accident  It is a direct consequence of our definitions and Theo rem      The range            determined by the DS no tion of conditioning seems much more mysterious  The answer     corresponds to the situation where the jailer says b whenever he can  i e   whenever a is pardoned or c is pardoned   Why is this a reason able answer  More importantly  why does it arise  Is there a natural probabilistic interpretation for it  In the full paper  we consider this issue in detail  The following construction  which is a generaliza tion of the  beehive  example in  SK     as well as being a formalization of some comments made in  dCLM      may help provide a partial explana tion  Suppose a set S is partitioned into  nonempty  disjoints sets X     Xk  An agent chooses X  with probability a   where a      ak      and then chooses z  E X  with some unknown probability  Given subsets A and B of S  we want to know what the probability is that the element z  chosen is in A  and the probability that x is in A given that it is in B  H A   X   then it is clear that the probability that x E A is a   However  if A is not one of the X  s  then all we can compute are upper and lower bounds on the probability  Let  P be the set of probability functions on S consistent with this situation  namely  Pr E  P iff Pr X     a   fori           k  Let Bel be the lower envelope of  P  it is not hard to show that Bel is a belief function  we do so in the full paper   It seems reasonable to argue that the best lower and upper bounds we can give on the probability that z  E A are Bel A  and Pl A   Similarly  the best lower and upper bounds we can give on the probability that z  E A given that x E B are given by the infimum and supremum of  Pr AIB    Pr E  P   These are precisely Bel AIB  and Pl AIB   Now suppose we slightly change the rules of the game  We are told that the probabilistic process that chooses an element in X  will definitely choose an element in B if possible  This does not affect anything if X   B or if X   B  However  if X  n B      and X  n B       then  rather than choosing X  with probability a   the probability is now redistributed so that X  n B is chosen with probability a   while X  n B is chosen with proba            bility    The probability that used to be spread over all of X  is now concentrated on X  n B  W hat is the probability that an element of A is chosen given that the element chosen is definitely in B with re spect to this new process  where an element of B is chosen whenever possible  We now have to con sider the family  P  of probability functions consis tent with this new process  and take the infimum and supremum of  Pr  AIB    Pr E  P    As we show in the full paper  these bounds are given by Bel AIJB  and Pl AIIB   Suppose we now reconsider the three prisoners problem from this point of view  We can now see that Bel lives aiJsays b  gives the probability that a lives given the extra hypothesis that the jailer says b whenever possible  In particular  this means that the jailer definitely says b if a is the one that is pardoned  i e   Pr says bJlives a       Under this revised situation  the probability that a lives given that the jailer says b is indeed ex actly      W ith this understanding of the DS no tion of updating  the result Bel lives aJJsays b    Pl lives aJJsays b        should come as no sur prise  To sununarize  this discussion has shown that Bel AIIB  corresponds to a somewhat unnatural updating process  where before we condition with respect to B  we first try to choose an element in B whenever possible  In terms of the process discussed above  it is easy to see that this extra step before updating makes no differene if B is the union of some of the X  s  This amounts to B being a measurable set  It will make a difference if B is not measurable  This is the case in the three prisoner problem  where says b is not a measurable set  and is the cause of the answer     that we get when we try to apply DS conditioning in this case  We remark that this analysis can also be used to explain the well known observation that Bel AIB   Bel AIIB   Pl AIIB   Pl AIB    Dem    Dem     see also  Kyb      Not only does it show why the interval defined by  Bel AlB   Pl AIB   contains that defined by  Bel AIIB   Pl AIIB    it explains when and why we get equality  See the full paper for details     Belief functions velopes  and  lower  en  Theorem     says that each belief function is the lower envelope of a set of probability functions  and each plausibility function an upper envelope  Un fortunately  the lower envelope of an arbitrary set of probability functions is not in general a belief function  nor is the upper envelope of an arbitrary        set of probability functions in general a plausibil ity function  Nevertheless  results such as Theo rem     show that there are natural sets of proba bility functions that do induce belief and plausibil ity functions  Although a general characterization is lacking  further examples in  F H  b  HF    sug gest that this is not an isolated example  However  even if a set P of probability functions does induce a belief and plausibility function  say Bel and PI  it is reasonable to ask whether we should represent P by Bel and Pl  Clearly the answer depends very much on the intended appli cation  However  it is worth noting that this rep resentation of P might result in a loss of valuable information  For example  consider a sample space consisting of three points  say  a  b  c   Let P con sist of all probability functions on S with the follow ing three properties           Pr  a                  Pr  b         and     Pr  a     Pr  b    It is not hard to show that the lower envelope of P is a belief function  If we call this belief function Bel and take PI to be the corresponding plausi bility function  we get Bel  a     Bel  b         and PI   a     PI   b          Thus  we retain the information that the probability of a and b both range between     and      However  we have lost the information that the probabilities of a and b are the same in all the probability func tions in P  This loss of information has some se rious repercussions  As we show in the full paper  by extending the example above   one consequence is that updates do not commute  More precisely  suppose we start with a belief function Bel on a set S  observe B  S and then observe C  S  The result is the belief function BeiB IC   where Be   A    Bei AIB   Similarly  if we observe C and then B  we get the belief function Belc IB   We might hope that for all sets A  we would have Be   AIC    Belc AIB    Bei AIBAC   That is  observing B then C should be the same as observ ing C then B  which in turn should be the same as observing B A C  This is certainly the case if Be l is a probability function  but not in general  It turns out that the problem here is that informa tion is lost as we update the belief function   See the full paper for further details of this issue   By way of contrast  the DS rule of conditioning is com mutative  Conditioning with respect to C and then with respect to B is equivalent to conditioning with respect to B A C  However  as we have pointed out  it has other problems when viewed as a technique for updating beliefs  These observations suggest to us that the ques tion of the  best  representation of evidence does  not have a unique answer  It may be easier to com pute with a pair of belief and plausibility functions than to have to carry around a whole set of prob ability functions  Nevertheless  since information may be lost in this process  this ease of computation comes at a cost   See  Pea    for further examples of this phenomenon      Conclusions  We have defined a new notion of conditional belief  distinct from the DS notion  that seems to lead to more intuitive results  Our notion also allows us to avoid some paradoxes associated with the DS no tion  For example  we would expect that if both an agent s belief in a proposition p given q and his belief in p given   q are at least a   then his belief in p should be at least a   whether or not he learns anything about q  This is essentially what Sav age  Sav    has called the sure thing principle  It is easy to see that conditional probability satisfies the sure thing principle  but the DS conditioning rule does not  see  Pea    for an example   On the other hand  it is easy to see that our notion of conditioning does satisfy the sure thing principle  For suppose we have an arbitrary belief function Bel such that Bel plq   a  and Bel pl  q   a   Choose an arbitrary probability function Pr com patible with Bel  By our definition of conditional belief as an infimum  we see that Pr plq   a  and Pr pl  q   a   So Pr p   a   Thus  Pr p   a  for all probability functions Pr compatible with Bel  So  from Theorem      it follows that Bel p   a   Although our results show that belief functions can play a useful role even when one wants to think probabilistically  the observations of the previous section do show that information can be lost if we pass to belief functions  This suggests they should be used with care  One thing we have not really discussed in this paper is what is considered perhaps the key com ponent of the Dempster Shafer approach  namely  the rule of combination  This rule is a way of com bining two belief functions to obtain a third one  The reason we have not discussed it is that we feel that the rule of combination does not fit in well with the viewpoint of belief functions as a general ization of probability functions that is discussed in this paper  However  there is another way of view ing belief functions  which is as representations of evidence  This is in fact the view taken in  Sha     When belief is viewed as a representation of evi dence  then the rule of combination becomes more appropriate  These issues are discussed in more de tail in a companion paper  HF      I I I I I I I I I I I I I I I I I I I        I I I I I I I  Appendix  Proof of Theorem     In order to carry out this proof  it will be tech nically useful to think in terms of mass function rather than belief functions  A mass function on S is simply a function m              such that  m          M     EA  m A   Proposition       I I I I I I I I I I I      I     Sha    p        If Bel is a belief function on    and S is fi nite  then there is a unique mass function m on    such thatBel  A     EncA m B  for every sub et A of S     Recall that we want to show Bel IB  is a belief function  and PI IB  is the corresponding plausi bility function  provided that Bel B       For sim plicity in this proof  we work under the assumption that S is finite  so that there is a mass function m corresponding to Bel  We remark that using tech niques of  F H  b  we could drop this assumption  It is easy to see  using the formulas in Theo rem      that               u Ao         II lBel   n A    iEI I   l     k  J t        If m is a mass function on S  then the func tion Bel              defined by Bel  A     EnA m B  is a belief function   Pl AIB   u  L        Intuitively  m A  is the weight of evidence for A that has not already been assigned to some proper subset of A  W ith this interpretation of mass  we would expect that an agent s belief in A is the sum of the masses he has assigned to all the subsets of A  i e   Bel A     EncA m B   Indeed  this intuition is correct   I  It is clear that Bel  satisfies BO B   All that remains is to show that Bel  satisfies B   Thus we must show that the following inequality holds   Bel  A   Ml       satisfies axioms BO B   it immediately follows that  Bel IB  does   Pl AnB  PI  AnB    Bel  AnB  Bel  An B                       Pl AnB    Bel  AnB      Bel AIB      Thus  once we show that Bel IB  is a belief func tion  it will immediately follow that Pl IB  is the corresponding plausibility function  Let Bel  be the function defined on    such that for each subset A of B   Let B     B  be the distinct sets with positive mass contained in B  Let A       A be the distinct sets with positive mass that intersectB but are not subsets of B  and let Ai   A  n B  for         i       n  Since Bel B       we know that there is some Bi   but there may be no A    Let a    m A    and  jf   m B    for each i  Let N           a    E  l f f   Note that N      since there is some Bi  Let ai   a fN  and   i       N  for each i  Thus  the ai s and f i s are normalized versions of the a   s and f    s  We want to define a mass function m  corre sponding to Bel   We first need to do a small detour  If s  so is a string  and if         i      ip       k  then we call B i B i  a substring of   s  Bin which we write as B i  B i  j B  Bk  For example  s s s  is a substring of BJB B B B   The substring is proper if it does not equal the full string      s    we then write Bi  Bi   BJ      so  We now define a function m   whose domain is  A        A   B        Bt   the set of finite strings over the alphabet consisting of the names of the sets with positive mass that intersect B    We shall usually not bother to distinguish between a set and the name of a set  but  as we shall see  it is con venient to consider explicitly strings of names of sets    First  we let m  B       i  for         i       t  As sume now that we have defined m  BiA h    Ai    whenever s   r and j      j   Assume that i          j  Let   It clearly suffices to show that Bel  is a belief function  since for all subsets C of S  we have Bel CIB    Bel  C nB   Once we show that Bel                                                                 j     A  m   BA I  I         m  BiY    L Y   Ai J Aj   If A is not of the formBiAh    Aj  with i          j   then m  A       We are now ready to define the alleged mass func tion m   If X is the string Bi A h Aj   where i       j   then we say that X represents the set given by Bi U Ah U U Aj   We would like to let m  be simply m    that is  by letting m  ap plied to a set be equal to m  applied to a string that represents the set  and let m  A      for sets not of the form Bi Ah Aj     The problem is that         Bel  A    Bel A   Bel A    Pl AnB                               several distinct strings may represent the same set  for example  it is quite possible that  say  the sets B  U A   and B  U A  U As are the same  We define m  A  to be Lx represents A m   X   For example  if the set A equals both B  U A   and B  U A  U As  but if A is not of the form B  UAil  U Aj  for any other choices of B   Ail        Aj  with il       j    then m  A    m  B A     m  B A As   We shall prove that m  is a mass function  and that Bel   A    L ccA m  C   This will show that Bel  is a belief funct  ion  Thus  we must show that A   m           B   m  A         for each AB   C  LAB D   m  A        Bel  A    LcA m  C    By definition of m  and m   we know that  A  holds  We now prove  D   Let AA p      A     where k       kq  be the A   s contained in A  and let B       B   be the B  s contained in A  W hat is Bel  A   As before  let N       a     L l f I   It is easy to see that Bel A      I         L  and Pl A n B    N     a A       a A     f t              Hence      Bel  A  Bel A   Bel A    Pl A n B    f tl      f t     N   a A l      a A      W hen we divide numerator and denominator by N  we see that  To prove  D   we must show that LccA m  C  equals the right hand side of      Let us call an expression m  B Ah Aj    where i is a mem ber of  i        i    and where i          j   are members of  k      kq   a good tenn  Note that if m  B Ah Aj   is a good term  then B  U Ail U  U Aj  A  Now LccA m  C  equals the sum of all good terms  This is because  a  each good term is a part of the sum defining m   C  for exactly one C  A  and  b  if C  A  then m  C  is defined as the sum of certain good terms  So we must show that the sum of all of the good terms equals the right hand side of      Now let i be a fixed member of  i      i    The sum of all good terms of the form m  B Ah  Aj   ex cept for the good term m  B A    A     is simply    I I  L  Y   A    A     m  B Y    it follows that the sum of all good terms of the form m  B Ah  Aj   equals                  a       So the sum of all good terms is                    a          a       as desired  This proves  D   Now  C  follows from  D   since it is easy to see that Bel  B       So we need only prove  B   The proof of  B  involves some nontrivial combinatorial arguments  the details can be found in the full pa per  I     We remark that in response to an early draft of this paper  Zhang  Zha    constructed a proof along very different lines  although also quite com plicated   Acknowledgments  The second author would like to thank Judea Pearl for a series of net conver sations that inspired the development of the def inition of conditional belief  We also gratefully acknowledge Nati Linial for his help in the proof of Theorem      Comments by Hector Levesque  Philippe Smets  and Moshe Vardi inspired a num ber of useful changes  Finally  we thank Judea Pearl  Tom Strat  and Sue Andrews  for sending us  respectively   dCLM      SK     and  Wal     and Enrique Ruspini for pointing out that our expres sions for conditional belief and plausibility actually appear in  Dem      
 Standard models of multi agent modal logic do not capture the fact that information is often ambiguous  and may be interpreted in different ways by different agents  We propose a framework that can model this  and consider different semantics that capture different assumptions about the agents beliefs regarding whether or not there is ambiguity  We consider the impact of ambiguity on a seminal result in economics  Aumanns result saying that agents with a common prior cannot agree to disagree  This result is known not to hold if agents do not have a common prior  we show that it also does not hold in the presence of ambiguity  We then consider the tradeoff between assuming a common interpretation  i e   no ambiguity  and a common prior  i e   shared initial beliefs       Introduction  In the study of multi agent modal logics  it is always implicitly assumed that all agents interpret all formulas the same way  While they may have different beliefs   This paper wil appear in the Proceedings of the Thirteenth International Conference on Principles of Knowledge Representation and Reasoning  KR             regarding whether a formula  is true  they agree on what  means  Formally  this is captured by the fact that the truth of  does not depend on the agent  Of course  in the real world  there is ambiguity  different agents may interpret the same utterance in different ways  For example  consider a public announcement p  Each player i may interpret p as corresponding to some event Ei   where Ei may be different from Ej if i    j  This seems natural  even if people have a common background  they may still disagree on how to interpret certain phenomena or new information  Someone may interpret a smile as just a sign of friendliness  someone else may interpret it as a false smile  concealing contempt  yet another person may interpret it as a sign of sexual interest  To model this formally  we can use a straightforward approach already used in  Halpern       Grove and Halpern        formulas are interpreted relative to a player  But once we allow such ambiguity  further subtleties arise  Returning to the announcement p  not only can it be interpreted differently by different players  it may not even occur to the players that others may interpret the announcement in a different way  Thus  for example  i may believe that Ei is common knowledge  The assumption that each player believes that her interpretation is how everyone interprets the announcement is but one assumption we can make about ambiguity  It is also possible that player i may be aware that there is more than one interpretation of p  but believes that player j is aware of only one interpretation  For example  think of a politician making an ambiguous statement which he realizes that different constituencies will interpret differently  but will not realize that there are other possible interpretations  In this paper  we investigate a number of different semantics of ambiguity that correspond to some standard assumptions that people make with regard to ambiguous statements  and investigate their relationship  Our interest in ambiguity is motivated by a seminal result in game theory  Aumanns        theorem showing that players cannot agree to disagree  More precisely  this theorem says that agents with a common prior on a state space cannot have common knowledge that they have different posteriors   This result has been viewed as paradoxical in the economics literature  Trade in a stock market seems to require common knowledge of disagreement  about the value of the stock being traded   yet we clearly observe a great deal of trading  One well known explanation for the disagreement is that we do not in fact have common priors  agents start out with different beliefs  We provide a different explanation here  in terms of ambiguity  It is easy to show that we can agree to disagree when there is ambiguity  even if there is a common prior  We then show that these two explanations of the possibility of agreeing to disagree are closely related  but not identical  We can convert an explanation in terms of ambiguity to an ex   We explain this result in more detail in Section         planation in terms of lack of common priors   Importantly  however  the converse does not hold  there are models in which players have a common interpretation that cannot in general be converted into an equivalent model with ambiguity and a common prior  In other words  using heterogeneous priors may be too permissive if we are interested in modeling a situation where differences in beliefs are due to differences in interpretation  Although our work is motivated by applications in economics  ambiguity has long been a concern in linguistics and natural language processing  For example  there has been a great deal of work on word sense disambiguation  i e   trying to decide from context which of the multiple meanings of a word are intended   see Hirst        for a seminal contribution  and Navigli        for a recent survey  However  there does not seem to be much work on incorporating ambiguity into a logic  Apart from the literature on the logic of context and on underspecification  see Van Deemter and Peters          the only paper that we are aware of that does this is one by Monz         Monz allows for statements that have multiple interpretations  just as we do  But rather than incorporating the ambiguity directly into the logic  he considers updates by ambiguous statements  There are also connections between ambiguity and vagueness  Although the two notions are differenta term is vague if it is not clear what its meaning is  and is ambiguous if it can have multiple meanings  Halpern        also used agent dependent interpretations in his model of vagueness  although the issues that arose were quite different from those that concern us here  The rest of this paper is organized as follows  Section   introduces the logic that we consider  Section   investigates the implications of the common prior assumption when there is ambiguity  Section   studies the tradeoff between heterogeneous priors and ambiguity  and Section   concludes      Syntax and Semantics      Syntax We want a logic where players use a fixed common language  but each player may interpret formulas in the language differently  We also want to allow the players to be able to reason about  probabilistic  beliefs  The syntax of the logic is straightforward  and is  indeed  essentially the syntax already used in papers going back to Fagin and Halpern          There is a finite     More precisely  we can convert a model with ambiguity and a common prior to an equivalent modelequivalent in the sense that the same formulas are truewhere there is no ambiguity but no common prior       nonempty set N               n  of players  and a countable  nonempty set  of primitive propositions  Let LC n    be the set of formulas that can be constructed starting from   and closing off under conjunction  negation  the modal operators  CBG  GN G     and the formation of probability formulas   We omit the  if it is irrelevant or clear from context   Probability formulas are constructed as follows  If             k are formulas  and a            ak   b  Q  then for i  N   a  pr i                ak pr i  k    b is a probability formula  where pr i    denotes the probability that player i assigns to a formula   Note that this syntax allows for nested probability formulas  We m      for   for use the abbreviation Bi  for pr i         EBG iG Bi   and EBG m EB    for m               Finally  we take true to be the abbreviation for a EBG G fixed tautology such as p  p       Epistemic probability structures There are standard approaches for interpreting this language  Fagin and Halpern        but they all assume that there is no ambiguity  that is  that all players interpret the primitive propositions the same way  To allow for different interpretations  we use an approach used earlier  Halpern       Grove and Halpern        formulas are interpreted relative to a player  An  epistemic probability  structure  over   has the form M       j  jN    Pj  jN    j  jN    where  is the state space  and for each i  N   i is a partition of   Pi is a function that assigns to each    a probability space Pi       i    Fi    i     and i is an interpretation that associates with each state a truth assignment to the primitive propositions in   That is  i    p    true  false  for all  and each primitive proposition p  Intuitively  i describes player is interpretation of the primitive propositions  Standard models use only a single interpretation   this is equivalent in our framework to assuming that          n   We call a structure where          n a common interpretation structure  Denote by   p  i the set of states where i assigns the value true to p  The partitions i are called information partitions  While it is more standard in the philosophy and computer science literature to use models where there is a binary relation Ki on  for each agent i that describes is accessibility relation on states  we follow the common approach in economics of working with information partitions here  as that makes it particularly easy to define a players probabilistic beliefs  Assuming information partitions corresponds to the case that Ki is an equivalence relation      and thus defines a partition   The intuition is that a cell in the partition i is defined by some information that i received  such as signals or observations of the world  Intuitively  agent i receives the same information at each state in a cell of i   Let i    denote the cell of the partition i containing   Finally  the probability space Pi       i    Fi    i    describes the beliefs of player i at state   with i  a probability measure defined on the subspace i  of the state space   The  algebra Fi  consists of the subsets of i  to which i  can assign a probability   If i  is finite  we typically take Fi     i    the set of all subsets of i     The interpretation is that i   E  is the probability that i assigns to event E  Fi  in state   Throughout this paper  we make the following assumptions regarding the probability assignments Pi   i  N   A   For all     i    i     A   For all     if    i     then Pi        Pi     A   For all j  N         i     j       Fi    Furthermore  we make the following joint assumption on players interpretations and information partitions  A   For all     i  N   and primitive proposition p    i       p  i  Fi    These are all standard assumptions  A  says that the set of states to which player i assigns probability at state  is just the set i    of worlds that i considers possible at state   A  says that the probability space used is the same at all the worlds in a cell of player is partition  Intuitively  this says that player i knows his probability space  Informally  A  says that player i can assign a probability to each of js cells  given his information  A  says that primitive propositions  as interpreted by player i  are measurable according to player i       Prior generated beliefs and the common prior assumption One assumption that we do not necessarily make  but want to examine in this framework  is the common prior assumption  The common prior assumption is an instance of a more general assumption  that beliefs are generated from a prior  which we now define  The intuition is that players start with a prior probability  they then update the prior in light of their information  Player is information is captured by her partition i   Thus  if is prior is i   then we would expect i  to be i     i           Definition     An epistemic probability structure M       j  jN    Pj  jN    j  jN   has prior generated beliefs  generated by  F                  Fn   n    if  for each player i  there exist probability spaces    Fi   i   such that  for all i  j  N and     j     Fi    for all i  N and     Pi       i     Fi   i     i     where Fi   i    is the restriction of Fi to i      and i   E    i  E   i     for all E  Fi   i    if i  i           There are no constraints on i  if i  i            It is easy to check that if M has prior generated beliefs  then M satisfies A   A   and A   More interestingly for our purposes  the converse also holds for a large class of structures  Say that a structure is countably partitioned if for each player i  the information partition i has countably many elements  i e   i is a finite or countably infinite collection of subsets of   Proposition     If a structure M has prior generated beliefs  then M satisfies A   A   and A   Moreover  every countably partitioned structure that satisfies A   A   and A  is one with prior generated beliefs  with the priors i satisfying i  i         for each player i  N and state     Proof  The first part is immediate  To prove the second claim  suppose that M is a structure satisfying A A   Let Fi be the unique algebra generated by  Fi    To define i   if there are Ni    cells in the partition i   define i      N i i      Otherwise  if the collection i is countably infinite  order the elements of i as p i   p i          Choose some state k  pki for each k  with associated probability space Pi  k      i k   Fi k   i k    By A   P each choice of k in pki gives the same probability measure i k   Define i   k   k i k   It is easy to see that i is a probability measure on   and that M is generated by  F                  Fn   n    Note that the requirement that that M is countably partitioned is necessary to ensure that we can have i  i         for each player i and state   In light of Proposition      when it is convenient  we will talk of a structure satisfying A A  as being generated by  F                  Fn   n    The common prior assumption is essentially just the special case of priorgenerated beliefs where all the priors are identical  We make one additional technical assumption  To state this assumption  we need one more definition  A state    Recall that the restriction of Fi to i    is the  algebra  B  i      B  Fi             is G reachable from     for G  N   if there exists a sequence             m in  with      and m       and i            im  G such that l  il  l     Denote by RG      the set of states G reachable from   Definition     An epistemic probability structure M       j  jN    Pj  jN    j  jN   satisfies the common prior assumption  CPA  if there exists a probability space    F    such that M has prior generated beliefs generated by   F              F      and  RN         for all     As shown by Halpern         the assumption that  RN         for each    is needed for Aumanns        impossibility result       Capturing ambiguity We use epistemic probability structures to give meaning to formulas  Since primitive propositions are interpreted relative to players  we must allow the interpretation of arbitrary formulas to depend on the player as well  Exactly how we do this depends on what further assumptions we make about what players know about each others interpretations  There are many assumptions that could be made  We focus on two of them here  ones that we believe arise in applications of interest  and then reconsider them under the assumption that there may be some ambiguity about the partitions  Believing there is no ambiguity The first approach is appropriate for situations where players may interpret statements differently  but it does not occur to them that there is another way of interpreting the statement  Thus  in this model  if there is a public announcement  all players will think that their interpretation of the announcement is common knowledge  We write  M    i   out  to denote that  is true at state  according to player i  that is  according to is interpretation of the primitive propositions in    The superscript out denotes outermost scope  since the formulas are interpreted relative to the outermost player  namely the player i on the left hand side of  out   We define  out   as usual  by induction  If p is a primitive proposition   M    i   out p iff i    p    true  This just says that player i interprets a primitive proposition p according to his interpretation function i   This clause is common to all our approaches for dealing with ambiguity       For conjunction and negation  as is standard   M    i   out  iff  M    i     out    M    i   out    iff  M    i   out  and  M    i   out   Now consider a probability formula of the form a  pr j            ak pr j  k    b  The key feature that distinguishes this semantics is how i interprets js beliefs  This is where we capture the intuition that it does not occur to i that there is another way of interpreting the formulas other than the way she does  Let     out        M    i   out    i Thus      out is the event consisting of the set of states where  is true  according i to i  Note that A  and A  guarantee that the restriction of j  to i    belongs to Fi    Assume inductively that       out  j              k   out  j   Fj    i i The base case of this induction  where  is a primitive proposition  is immediate from A  and A   and the induction assumption clearly extends to negations and conjunctions  We now define  M    i   out a  pr j                ak pr j  k    b iff a  j         out  j              ak j     k   out  j     b  i i Note that it easily follows from A  that  M    i   out a  pr j            ak pr j  k    b if and only if  M      i   out a  pr j                ak pr j  k    b for all    j     Thus    a  pr j                ak pr j  k    b  i is a union of cells of j   and hence   a  pr j                ak pr j  k    b  i  j   Fj    With this semantics  according to player i  player j assigns  probability b if and only if the set of worlds where  holds according to i has probability b according to j  Intuitively  although i understands js probability space  player i is not aware that j may interpret  differently from the way she  i  does  That i understands js probability space is plausible if we assume that there is a common prior and that i knows js partition  this knowledge is embodied in the assumption that i intersects   k   out with j  when assessing what probability j assigns to i k        Note that at state   player i will not in general know that it is state   In particular  even if we assume that i knows which element of js partition contains   i will not in general know which of js cells describes js current information  But we assume that i does know that if the state is   then j information is described by j    Thus  as usual   M  i     out  should perhaps be understood as according to i   is true if the actual world is   This interpretational issue arises even without ambiguity in the picture       Given our interpretation of probability formulas  the interpretation of Bj  and EB k  follows  For example   M    i   out Bj  iff j       out i        For readers more used to belief defined in terms of a possibility relation  note that if the probability j  is discrete  i e   all sets are j   measurable  and P measure     for all subsets E        we can define B   j   E        j j  E j            j             that is          Bj if  in state   agent j gives state   positive probability  In that case   M    i   out Bj  iff  M      i   out  for all   such that         Bj   That is   M    i   out Bj  iff  is true according to i in all the worlds to which j assigns positive probability at   It is important to note that  M    i     does not imply  M    i    Bi   while  M    i   out  means  is true at  according to is interpretation  this does not mean that i believes  at state   The reason is that i can be uncertain as to which state is the actual state  For i to believe  at    would have to be true  according to is interpretation  at all states to which i assigns positive probability  Finally  we define k  M    i   out CBG  iff  M    i   out EBG  for k                for any nonempty subset G  N of players  Awareness of possible ambiguity We now consider the second way of interpreting formulas  This is appropriate for players who realize that other players may interpret formulas differently  We write  M    i   in  to denote that  is true at state  according to player i using this interpretation  which is called innermost scope  The definition of  in is identical to that of  out except for the interpretation of probability formulas  In this case  we have  M    i   in a  pr j                ak pr j  k    b iff in a  j         in j  j              ak j     k   j  j     b  in   Hence  according where     in j is the set of states  such that  M    j    to player i  player j assigns  probability b if and only if the set of worlds where  holds according to j has probability b according to j  Intuitively  now i realizes that j may interpret  differently from the way that she  i  does  and thus assumes that j uses his  js  interpretation to evaluate the probability of   Again  in the case that j  is discrete  this means that  M    i   in Bj  iff  M      j   in  for all   such that         Bj        Note for future reference that if  is a probability formula or a formula of the form CBG    then it is easy to see that  M    i   in  if and only if  M    j   in   we sometimes write  M     in  in this case  Clearly   out and  in agree in the common interpretation case  and we can write    Ambiguity about information partitions Up to now  we have assumed that players understand each others probability spaces  This may not be so reasonable in the presence of ambiguity and prior generated beliefs  We want to model the following type of situation  Players receive information  or signals  about the true state of the world  in the form of strings  formulas   Each player understands what signals he and other players receive in different states of the world  but players may interpret signals differently  For instance  player i may understand that j sees a red car if  is the true state of the world  but i may or may not be aware that j has a different interpretation of red than i does  In the latter case  i does not have a full understanding of js information structure  We would like to think of a players information as being characterized by a formula  intuitively  the formula that describes the signals received   Even if the formulas that describe each information set are commonly known  in the presence of ambiguity  they might be interpreted differently  To make this precise  let  be the set of formulas that is obtained from  by closing off under negation and conjunction  That is   consists of all propositional formulas that can be formed from the primitive propositions in   Since the formulas in  are not composed of probability formulas  and thus do not involve any reasoning about interpretations  we can extend the function i    to  in a straightforward way  and write     i for the set of the states of the world where the formula    is true according to i  The key new assumption we make to model players imperfect understanding of the other players probability spaces is that is partition cell at  is described by a formula i      But  of course  this formula may be interpreted differently by each player  We want i    to coincide with is interpretation of the formula i    If player j understands that i may be using a different interpretation than he does  i e   the appropriate semantics are the innermost scope semantics   then j correctly infers that the set of states that i thinks are possible in  is i        i    i   But if j does not understand that i may interpret formulas in a different way  i e   under outermost scope   then he thinks that the set of states that i thinks are possible in  is given by   i    j   and  of course    i    j may not coincide with i     In any case  we require that j understand that these formulas form a partition and that  belongs to   i    j   Thus  we consider structures that satisfy A  and A   for outermost scope  or A  and A   for innermost scope   in addition to A A         A   For each i  N and     there is a formula i    such that i        i    i   A   For each i  j  N   the collection    i    j       is a partition of  and for all         i    j   A    For each i  N   the collection    i    i       is a partition of  and for all         i    i   Assumption A  is appropriate for outermost scope  it presumes that player j uses his own interpretation of i  in deducing the beliefs for i in   Assumption A  is appropriate for innermost scope  Note that A  is a weakening of A   While A  requires the signals for player i to induce an information partition according to every player j  the weaker version A  requires this to hold only for player i himself  We can now define analogues of outermost scope and innermost scope in the presence of ambiguous information  Thus  we define two more truth relations   out ai and  in ai    The ai here stands for ambiguity of information   The only difference between  out ai and  out is in the semantics of probability formulas  In giving the semantics in a structure M   we assume that M has prior generated beliefs  generated by  F                  Fn   n    As we observed in Proposition      this assumption is without loss of generality as long as the structure is countably partitioned  However  the choice of prior beliefs is relevant  as we shall see  so we have to be explicit about them  When i evaluates js probability at a state   instead of using j    player i uses j       j    i    When i   j  these two approaches agree  but in general they do not  Thus  assuming that M satisfies A  and A   which are the appropriate assumptions for the outermost scope semantics   we have  M    i   out ai a  pr j                ak pr j  k    b iff             j    out ai a  j        out ai i i out ai  ak j    k   out ai            b  j  i i         M    i   out ai    where     out ai i That is  at     player j receives the information  a string  j    which he interprets as   j    j   Player i understands that j receives the information j  in state   but interprets this as   j    i   This models a situation such as the following  In state   player j sees a red car  and thinks possible all states of the world where he sees a car that is red  according to j   Player i knows that at world  player j will see a red car  although she may not know that the actual world is   and thus does not know what color of car player j actually sees   However  i has a      somewhat different interpretation of red car  or  more precisely  of j seeing a red car  than j  is interpretation corresponds to the event   j    i   Since i understands that js beliefs are determined by conditioning her prior j on her information  i can compute what she believes js beliefs are  We can define  in ai in an analogous way  Thus  the semantics for formulas that do not involve probability formulas are as given by  in   while the semantics of probability formulas is defined as follows  where M is assumed to satisfy A  and A    which are the appropriate assumptions for the innermost scope semantics    M    i   in ai a  pr j                ak pr j  k    b iff a  j        in ai     j    in ai         j j in ai in ai  ak j    k   j     j    j    b  Note that although we have written   j    in ai   since j  is a propositional fori out ai out        in   It is important that mula    j    in ai                 j  i j  i j  i i j  is a propositional formula here  otherwise  we would have circularities in the   definition  and would somehow need to define   j    in ai i Again  here it may be instructive to consider the definition of Bj  in the case that j  is discrete for all   In this case  Bj becomes the set           j        j    in ai        That is  state   is considered possible by player j in state j  if agent j gives   positive probability after conditioning his prior j on  his interpretation of  the information j  he receives in state   With this definition of Bj   we have  as expected   M    i   in ai Bj  iff  M      i   in ai  for all   such that         Bj   The differences in the different semantics arise only when we consider probability formulas  If we go back to our example with the red car  we now have a situation where player j sees a red car in state   and thinks possible all states where he sees a red car  Player i knows that in state   player j sees a car that he  j  interprets to be red  and that this determines his posterior  Since i understands js notion of seeing a red car  she has a correct perception of js posterior in each state of the world  Thus  the semantics for  in ai are identical to those for  in  restricted to the class of structures with prior generated beliefs that satisfy A  and A     though the information partitions are not predefined  but rather generated by the signals  Note that  given an epistemic structure M satisfying A A   there are many choices for i that allow M to be viewed as being generated by prior beliefs  All that is required of j is that for all    and E  Fj  such that E    j    jout ai   it holds that j  E    j    out ai   j    j    out ai     j   E   However  because j j out ai out ai   j    i may not be a subset of   j    j   j     we can have two prior      probabilities j and j that generate the same posterior beliefs for j  and still have   for some formulas     j    out ai      j    k   out ai     j    out ai j    k   out ai i i i i k   Thus  we must be explicit about our choice of priors here      The common prior assumption revisited  This section applies the framework developed in the previous sections to understand the implications of assuming a common prior when there is ambiguity  The application in Section     makes use of the outermost  and innermost scope semantics  while Section     considers a setting with ambiguity about information partitions       Agreeing to Disagree The first application we consider concerns the result of Aumann        that players cannot agree to disagree if they have a common prior  As we show now  this is no longer true if players can have different interpretations  But exactly what agreeing to disagree means depends on which semantics we use  Example      Agreeing to Disagree  Consider a structure M with a single state   such that      p    true and      p    false  Clearly M satisfies the CPA  The fact that there is only a single state in M means that  although the players interpret p differently  there is perfect understanding of how p is interpreted by each player  Specifically  taking G           we have that  M     in CBG  B  p  B  p   Thus  with innermost scope  according to each player  there is common belief that they have different beliefs at state   that is  they agree to disagree  With outermost scope  we do not have an agreement to disagree in the standard sense  but the players do disagree on what they have common belief about  Specifically   M        out CBG p and  M        out CBG p  That is  according to player    there is common belief of p  and according to player    there is common belief of p  To us  it seems that we have modeled a rather common situation here   Note that in the model of Example      there is maximal ambiguity  the players disagree with probability    We also have complete disagreement  As the following result shows  the less disagreement there is in the interpretation of events  the closer the players come to not being able to agree to disagree  Suppose that M satisfies the CPA  where  is the common prior  and that     so that  is a propositional formula   Say that  is only o ambiguous in M if the set of states where the players       disagree on the interpretation of  has  measure at most o  that is       i  j  M    i     and  M    j          o  We write   here because  as we observed before  all the semantic approaches agree on propositional formulas  so this definition makes sense independent of the semantic approach used  Note that if players have a common interpretation  then all formulas are   ambiguous  Proposition     If M satisfies the CPA and  is only o ambiguous in M   then there cannot exist players i and j  numbers b and b with b   b   o  and a state  such that all states are G reachable from  and  M     in CBG   pr i      b    pr j      b     Proof  Essentially the same arguments as those used by Aumann        can be used to show that if all states are reachable from  and  M     in CBG  pr i      b   then it must be the case that      i     b  where  is the common prior  Similarly       j     b   This contradicts the assumption that  is only o ambiguous in M        Understanding differences in beliefs Since our framework separates meaning from message  it is worth asking what happens if players receive the same message  but interpret it differently  Aumann        has argued that people with different information may legitimately entertain different probabilities  but there is no rational basis for people who have always been fed precisely the same information to do so  Here we show that this is no longer true when information is ambiguous  even if players have a common prior and fully understand the ambiguity that they face  except under strong assumptions on players beliefs about the information that others receive  This could happen if players with exactly the same background and information can interpret things differently  and thus have different beliefs  We assume that information partitions are generated by signals  which may be ambiguous  That is  in each state of the world   each player i receives some signal i  that determines the states of the world he thinks possible  that is  i        rec i  i     i   where rec i  i      is i received i    As usual  we restrict attention to structures with prior generated beliefs that satisfy A  and A  when considering innermost scope semantics and A  and A  when considering outermostscope semantics       In any given state  the signals that determine the states that players think are possible may be the same or may differ across players  Following Aumann         we are particularly interested in the former case  Formally  we say that  is a common signal in  if i     for all i  N   For example  if players have a common interpretation  and all players observe a red car in state   then  is red car  while rec i     is i observes a car that is red  The fact that red car is a common signal in  means that all players in fact observe a red car in state   But assuming that players have received a common signal does not imply that they have the same posteriors  as the next example shows  Example     There are two players    and    and three states  labeled             The common prior gives each state equal probability  and players have the same interpretation  In     both players receive signal   in     only   does  in     only   receives   The primitive proposition p is true in   and     and the primitive proposition q is true in   and     In state     both players receive signal   but player   assigns probability   to p and probability    to q  while   gives probability     to p and probability   to q  Thus  players who receive a common signal can end up having a different posterior over formulas  even if they have a common prior and the same interpretation  The problem is that even though players have received the same signal  they do not know that the other has received it  and they do not know that the other knows they have received it  and so on  That is  the fact that players have received a common signal in  does not imply that the signal is common knowledge in   We say that signal  is a public signal at state  if  M      CBN  iN rec i      it is commonly believed at  that all players received   For the remainder of this section  we will be considering structures with a common prior   To avoid dealing with topological issues  we assume that  is a discrete measure  Of course  if the common prior  is discrete  then so are all the measures i    Let Supp   denote the support of the probability measure   If  is discrete  then Supp                   Even though common signals are not sufficient for players to have the same beliefs  as Example     demonstrates  Aumanns claim does hold for commoninterpretation structures if players receive a public signal  provided that they started with a common prior   Proposition     If M is a common interpretation structure with a common prior  and  is a public signal at   then players posteriors are identical at   for all i  j  N and E  F  i   E  i       j   E  j           In particular  for any formula   i         i       j         j      Proof  Let  be the common prior in M   By assumption  i        rec i      for all players i  N   Since  is public  we have that  M      Bi  rec j      Thus   M        rec j    for all    Supp i     It follows that Supp i     j    for all players i and j  Since i   Supp i          we have that  j      i        i      j          Thus  for all E  F  we must have  E   i        E   j     The result now follows immediately  There is another way of formalizing the assumption that  it is commonly believed that  players are  fed the same information  namely  we say that if one player i receives a signal  then so do all others  Formally  a signal  is a shared signal at state  if  M      i jN CBN  rec i     rec j      If there is no ambiguity  a signal is shared iff it is public  we leave the straightforward proof  which uses ideas from the proof of Proposition      to the reader  Proposition     If M is a common interpretation structure  and  is received at state  by all players  then  is a public signal at  iff  is a shared signal at   The assumption that signals are public or shared is quite strong  one requires common belief that a particular signal is received  and so precludes any uncertainties about what one player believes that other players believe that others have received   while the other requires common belief that different players always receive the same signal  and  similarly  precludes uncertainties about what is received   What happens if we introduce ambiguity  If the signal itself is a propositional formula  which is the case in many cases of interest   then players may interpret the signal differently  that is  we may have      i         j for i    j  Moreover  players may have a different interpretation of observing a given signal  i e   it is possible that   rec i      i      rec i      j   Going back to our example of the red car  different players may interpret red car differently  and they may interpret the notion of observing a red car differently  In addition  it is now possible that players have the same posteriors over events  but not over formulas  or vice versa  given that they may interpret formulas differently  If we assume that players are not aware that there is ambiguity  then we retain the equivalence between shared signals and common signals  and players posteriors over formulas coincide after receiving a public signal  However  they may have different beliefs over events  Proposition     If M is a structure satisfying A  and A   and  is received at state  by all players  then  is a public signal at  iff  is a shared signal at  under      outermost scope semantics  Moreover  if M has a common prior  and  is a public signal at   then players posteriors on formulas are identical at   that is  for all formulas   we have i       out ai  i       j       out ai  j      i j However  players posteriors on events may differ  that is  there may exist some E such that i   E  i        j   E  j      We leave the straightforward arguments to the reader  The situation for innermost scope presents an interesting contrast  A first observation is that public signals and shared signals are no longer equivalent  Example     Consider a structure M with two players  where                          Suppose that   rec             rec                       and   rec             rec                       Assume that the beliefs in M are generated by a common prior that gives each state probability      Clearly  M        in ai CBN  rec       rec       CBN  rec        The problem in Example     is that  although the signal is shared  the players dont interpret receiving the signal the same way  It is not necessarily the case that player   received  from player  s point of view iff player   received  from player  s point of view  The assumption that players receive shared signals is not strong enough to ensure that they have identical posteriors  either over formulas or over events  In Example      for example  players clearly have different posteriors on the event            in state      similarly  it is not hard to show that players can have different posteriors over formulas  Say that  is strongly shared at state  if   M     in ai i j CBN  rec i     rec j      and   M     in ai i j CBN  Bi  rec i      Bj  rec j       The second clause says that it is commonly believed at  that each player believes that he has received  iff each of the other players believes that he has received   This clause is implied by the first in common interpretation structures and with outermost scope  but not with innermost scope  Proposition     If M is a structure satisfying A  and A    and  is received at  by all players  then  is a public signal at  iff  is a strongly shared signal at  under the innermost scope semantics  If M is a structure with a common prior and        is a public signal at   then players posteriors over events are identical at   for all i  j  N and all E  F  i   E  i       j   E  j      However  players posteriors on formulas may differ  that is  for some formula   we could have that i       in ai  i        j       in ai  j      i j These results emphasize the effect of ambiguity on shared and public signals      Common priors or common interpretations   As Example     shows  we can have agreement to disagree with ambiguity under the  in semantics  and thus  also the  in ai semantics   We also know that we can do this by having heterogeneous priors  As we now show  structures with ambiguity that satisfy the CPA have the same expressive power as commoninterpretation structures that do not necessarily satisfy the CPA  and commoninterpretation structures  by definition  have no ambiguity   On the other hand  common interpretation structures with heterogeneous priors are more general than structures with ambiguity and common priors  To make this precise  we consider what formulas are valid in structures with or without ambiguity or a common prior  To define what it means for a formula to be valid  we need some more notation  Fix a nonempty  countable set  of primitive propositions  and let M   be the class of all structures that satisfy A  A  and that are defined over some nonempty subset  of  such that     is countably infinite   Given a subset  of   a formula   LC n     and a structure M  M   over   we say that  is valid in M according to outermost scope  and write M  out   if  M    i   out  for all    and i  N   Given     say that  is valid according to outermost scope in a class N  M   of structures  and write N  out   if M  out  for all M  N defined over a set    of primitive propositions that includes all the primitive propositions that appear in   We get analogous definitions by replacing  out by  in    out ai and  in ai throughout  in the latter two cases  we have to restrict N to structures that satisfy A  and A  or A    respectively  in addition to A A    Finally  given a class    Most of our results hold if we just consider the set of structures defined over some fixed set  of primitive propositions  However  for one of our results  we need to be able to add fresh primitive propositions to the language  Thus  we allow the set  of primitive propositions to vary over the structures we consider  but require     to be countably infinite so that there are always fresh primitive propositions that we can add to the language        of structures N   let Nc be the subclass of N in which players have a common interpretation  Thus  Mc    denotes the structures in M   with a common interpretation  Let Mai    denote all structures in M   with prior generated beliefs that satisfy A  and A   where we assume that the prior  that describes the initial beliefs is given explicitly    Finally  let Mcpa     resp   Mcpa ai     consist of the structures in M    resp   Mai     satisfying the CPA  Proposition     For all formulas   LC n     the following are equivalent   a  Mc         b  M    out    c  M    in    d  Mai c         e  Mai     out ai    f  Mai     in ai   Proof  Since the set of structures with a common interpretation is a subset of the set of structures  it is immediate that  c  and  b  both imply  a   Similarly   e  and  f  both imply  d   The fact that  a  implies  b  is also immediate  For suppose that Mc       and that M       j  jN    Pj  jN    j  jN    M   is a structure over a set    of primitive propositions that contains the primitive propositions that appear in   We must show that M  out   Thus  we must show that  M    i   out  for all    and i  N   Fix    and i  N   and let Mi       j  jN    Pj  jN    j  jN    where j   i for all j  Thus  Mi is a common interpretation structure over   where the interpretation coincides with is interpretation in M   Clearly Mi satisfies A A   so Mi  Mc     It is easy to check that  M    i   out  if and only if  Mi     i     for all states     out   and all formulas   LC n     Since Mi     we must have that  M    i    as desired  To see that  a  implies  c   given a structure M       j  jN    Pj  jN    j  jN    M   over some set    of primitive propositions and a player j  N   let j be a disjoint copy of   that is  for every state     there is a corresponding state j  j   Let              n   Given E    let the corresponding subset Ej  j be the set  j     E   and let E  be the subset of  corresponding to E  that is  E     j     E  j  N       For ease of exposition  we assume A  even when dealing with innermost scope  Recall that A  implies A    which is actually the appropriate assumption for innermost scope        Define M         j  jN    Pj  jN    j  jN    where              n and  for all    and i  j  N   we have  i  j      i        i  j   p    j    p  for a primitive proposition p            Pi  j      i j   Fi  i j    where i j   i    Fi j    El   E  j Fi    l  N    i j  Ei     i   E   i j  El       if l    i   Thus           n   so that M  is a common interpretation structure  on a state j   these interpretations are all determined by j   Also note that the support of the probability measure i j is contained in i   so for different players i  the probability measures i j have disjoint supports  Now an easy induction on the structure of formulas shows that M    j      if and only if  M    j   in  for  in  for all any formula   LC n     It easily follows that if M     then M     LC n     The argument that  d  implies  e  is essentially identical to the argument that  a  implies  b   similarly  the argument that  d  implies  f  is essentially the same as the argument that  a  implies  c   Since Mai c     Mc      a  implies  d   To show C that  d  implies  a   suppose that Mai c       for some formula   Ln     Given a structure M       j  jN    Pj  jN      Mc    over a set    of primitive propositions that includes the primitive propositions that appear in   we want to show that  M    i     for each state    and player i  Fix   Recall that RN    consists of the set of states N  reachable from   Let M     RN      j  jN    Pj  jN        with j and Pj the restriction of j and Pj   respectively  to the states in RN     be a structure over a set  of primitive propositions  where  contains  and new primitive propositions that we call pi  for each player i and state   RN      Note that there are only countably many information sets in RN     so  is countable  Define   so that it agrees with   restricted to RN     on the propositions in   and so that   pi    i   i     Thus  M  satisfies A  and A   It is easy to check that  for all    RN    and    all formulas   LC n     we have that  M     i     iff  M      i      Since  M     it follows that  M    i      as desired  The proof that  a  implies  c  shows that  starting from an arbitrary structure M   we can construct a common interpretation structure M  that is equivalent to   This is the one argument that needs the assumption that the set of primitive propositions can be different in different structures in M    and the fact that every     is countable  We have assumed for simplicity that the propositions pi  are all in      and that they can be chosen in such a way so that        pi    i              n        is countable        M in the sense that the same formulas hold in both models  Note that because the probability measures in the structure M  constructed in the proof of Proposition     have disjoint support  M  does not satisfy the CPA  even if the original structure M does  As the next result shows  this is not an accident  cpa     out   Mcpa     in Proposition     For all formulas   LC n     if either M   Mcpa ai     out ai   or Mcpa ai     in ai   then Mcpa c        Moreover  cpa     out  and Mcpa ai     out ai   However  in if Mcpa        then M c cpa     in   general  if Mcpa c        then it may not be the case that M  Proof  All the implications are straightforward  with proofs along the same lines as that of Proposition      To prove the last claim  let p   be a primitive proposition  Aumanns agreeing to disagree result shows that Mcpa c      CBG  B  p  B  p   while Example     shows that Mcpa       in CBG  B  p  B  p   Proposition     depends on the fact that we are considering belief and common belief rather than knowledge and common knowledge  where knowledge is defined in the usual way  as truth in all possible worlds   M    i   in Ki  iff  M      i   in  for all    i     with Ki the knowledge operator for player i  and where we have assumed that   i    for all i  N and     Aumanns result holds if we consider common belief  as long as what we are agreeing about are judgments of probability and expectation   With knowledge  there are formulas that are valid with a common interpretation that are not valid under innermost scope semantics when there is ambiguity For example  Mc      Ki     while it is easy to construct a structure M with ambiguity such that  M        in K  p  p  What is true is that M    in  K               Kn      This is because we have  M    i   in Ki     so one of K              Kn    must hold  As shown in  Halpern        this axiom essentially characterizes knowledge if there is ambiguity  As noted above  the proof of Proposition     demonstrates that  given a structure M with ambiguity and a common prior  we can construct an equivalent commoninterpretation structure M  with heterogeneous priors  where M and M  are said to be equivalent  under innermost scope  if for every formula   M  in  if and only if M   in   The converse does not hold  as the next example illustrates  when formulas are interpreted using innermost scope  there is a common interpretation structure with heterogeneous priors that cannot be converted into an equivalent structure with ambiguity that satisfies the CPA        Example     We construct a structure M with heterogeneous priors for which there is no equivalent ambiguous structure that satisfies the CPA  The structure M has three players  one primitive proposition p  and two states    and     In     p is true according to all players  in     the proposition is false  Player   knows the state  his information partition is                   The other players have no information on the state  that is  i              for i         Player   assigns probability    to     and player   assigns probability    to     Hence  M is a common interpretation structure with heterogeneous priors  We claim that there is no equivalent structure M  that satisfies the CPA  To see this  suppose that M  is an equivalent structure that satisfies the CPA  with a common prior  and a state space    As M   in pr    p       and M   in pr    p         we must have          M            in p                   M            in p          Observe that M  in B   p  B  p   B   p  B  p   Thus  we must have M   in B   p  B  p   B   p  B  p   Let E           M            in B  p   It follows that we must have  E        and  E         a contradiction  Example     demonstrates that there is no structure M  that is equivalent to the structure M  defined in Example      that satisfies the CPA  In fact  as we show now  an even stronger result holds  In any structure M  that is equivalent to M   whether it satisfies the CPA or not  players have a common interpretation  Proposition     If a structure M   M   is equivalent under innermost scope to the structure M defined in Example      then M   Mc   Proof  Note that M   p   pr    p        Hence  if a structure M  is equivalent to M   we must have that M   in p   pr    p        that is  for all    and i  N    M      i   in p   pr    p        By a similar argument  we obtain that for every    and i  N   it must be the case that  M      i   in p   pr    p        Since the truth of a probability formula does not depend on the player under the innermost scope semantics  it follows that for each i  j  N   the interpretations i and j in M  coincide  In other words  M  is a common interpretation structure      Discussion  We have defined a logic for reasoning about ambiguity  and considered the tradeoff between having a common prior  so that everyone starts out with the same belief       and having a common interpretation  so that everyone interprets all formulas the same way   We showed that  in a precise sense  allowing different beliefs is more general than allowing multiple interpretations  But we view that as a feature  not a weakness  of considering ambiguity  Ambiguity can be viewed as a reason for differences of beliefs  as such  it provides some structure to these differences  We have not discussed axiomatizations of the logic  From Proposition     it follows that for formulas in LC n     we can get the same axiomatization with respect to structures in M   for both the  out and  in semantics  moreover  this axiomatization is the same as that for the common interpretation case  An axiomatization for this case is already given in  Fagin and Halpern        Things get more interesting if we consider Mcpa     the structures that satisfy the CPA  Halpern        provides an axiom that says that it cannot be common knowledge that players disagree in expectation  and shows that it can be used to obtain a sound and complete characterization of common interpretation structures with a common prior   The axiomatization is actually given for common knowledge rather than common belief  but a similar result holds with common belief   By Proposition      the axiomatization remains sound for outermost scope semantics if we assume the CPA  However  using Example      we can show that this is no longer the case for the innermost scope semantics  The set of formulas valid for innermost scope semantics in the class of structures satisfying the CPA is strictly between the set of formulas valid in all structures and the set of formulas valid for outermost scope semantics in the class of structures satisfying the CPA  Finding an elegant complete axiomatization remains an open problem  Acknowledgments  Halperns work was supported in part by NSF grants IIS         IIS          and IIS          by AFOSR grants FA               and FA                and by ARO grant W   NF            The work of Kets was supported in part by AFOSR grant FA                 
  We propose a new definition of actual causes  model counterfac tuals  We show that the definition yields a plausi ble and elegant account of causation that handles well examples which have caused problems for other definitions and resolves major difficulties in the traditional account  using structural equations to     INTRODUCTION  What does it mean that an event A actually causes event B  This is a question that goes beyond mere philosophical speculation  As Good        argues persuasively  in many legal settings  what needs to be established  for determining responsibility  is not a counterfactual kind of causation  but  cause in fact   A typical example considers two fires ad vancing toward a house  If fire A burned the house before fire B  we  and many juries nationwide  would consider fire A  the actual cause  for the damage  even supposing the house would have definitely burned down by fire B  if it were not for A  Actual causation is also important in arti ficial intelligence applications  W henever we undertake to explain a set of events that unfold in a specific scenario  the explanation produced must acknowledge the actual cause of those events  The automatic generation of adequate expla nations  a task essential in planning  diagnosis and natural language processing  therefore requires a formal analysis of the concept of actual cause  Giving a precise and useful definition of actual causality is notoriously difficult  The philosophical literature has been struggling with this notion since the days of Hume           See  Sosa and Tooley         Hall        and  Pearl      for some recent discussions   To borrow just one example from Hall         suppose a bolt lightning hits a tree and starts a forest fire  It seems reasonable to say that the lightning bolt is a cause of the fire   Indeed  the description  the lightning bolt     starts a forest fire  can be viewed as saying this   But what about the oxygen in the air and the fact that the wood was dry  Presumably  if there has not been oxygen or the wood was wet there would not have been a fire  Carrying this perhaps to the point of absurdity   what about the Big Bang  This problem is relatively easy to deal with  but there are a host of other  far more subtle  difficulties that have been raised over the years  Here we give a definition of actual causality based on the language of structural equations  in a companion paper   Halpern and Pearl        see also the full paper  Halpern and Pearl         we give a definition of  causal  explana tion using the definition of causality  The use of structural equations as a model for causa l relationships is standard in the social sciences  and seems to go back to the work of Sewall W right in the     s  see  Goldberger       for a discussion   the framework we use here is due to Pearl         and is further developed in  Galles and Pearl       Halpern       Pearl        While it is hard to argue that our definition  or any other definition  for that matter  is the  right definition   we show that it deals well with the difficulties that have plagued other approaches in the past  especially those exemplified by the rather extensive com pendium of Hall         There has been extensive discussion about causality in the literature  particularly in the philosophy literature  To keep this paper to manageable length  we spend only minimal time describing other approaches and comparing ours to them  We refer the reader to  Hall       Pearl       Sosa and Tooley       Spirtes  Glymour  and Scheines       for details and criticism of the probabilistic and logical approaches to causality in the philosophy literature   We do try to point out where our definition does better than perhaps the best known approach  due to Lewis              in the course of discussing the examples   There has also been work in the AI literature on causal ity  Perhaps the closest to this are papers by Pearl and his colleagues that use the structural model approach  The def inition of causality in this paper was i n spired by an earlier paper of Pearl s        that defined actual causality in terms of a construction called a causal beam  The causal beam definition was later modified somewhat  see  Pearl       Chapter       largely due to the considerations addressed in this paper  The definition given here is more transparent and handles a number of cases better  see Example       Tian and Pearl        give results on calculating the prob ability that A is a necessary cause of B that is  the proba bility that B would not have occurred if A had not occurred    HALPERN   PEARL  UAI       Necessary causality is related to but different from actual causality  as the definitions should make clear  Other work  for example   Heckerman and Shachter        focuses on when a random variable X is the cause of a random vari able Y  by way of contrast  we focus on when an event y  As we such as X   x causes an event such as Y shall see  many of the subtleties that arise when dealing with events simply disappear if we look at causality at the level of random variables  Finally  there is also a great deal of work in AI on formal action theory  see  for exam ple   Lin       Sandewall        which is concerned with the proper way of incorporating causal relationships into a knowledge base so as to guide actions  The focus of our work is quite different  we are concerned with extracting the actual causality relation from such a knowledge base  coupled with a specific scenario          The set U ofexogenous variables includes things we need to assume so as to render all relationships deterministic  such as whether the wood is dry  there is enough oxygen in the air  etc    If i  is a setting of the exogenous variables that makes a forest fire possible  i e   the wood is sufficiently dry  there is oxygen in the air  and so on  then  for example  FF il  L ML  is such that F   I if L   or ML           Given a causal model M     S   F   a  possibly empty  vector X of variables in V  and vectors x and i  of values for the variables in X and U  we can define a new causal model denoted Mx   fi over the signature Sx  U  V X   R Iv x    Intuitively  this is the causal model that results    when the variables in X are set to x by some external action that affects only the variables in X  we do not model the action or its causes explicitly  Formally  Mx       x    CAUSAL MODELS  A REVIEW     We briefly review the basic definitions of causal models  as defined in terms of structural equations  and the syntax and semantics of a language for reasoning about causality  See  Galles and Pearl       Halpern       Pearl       for more details  motivation  and intuition  Causal Models  The basic picture here is that the world is described by random variables  some of which may have a causal influence on others  This influence is modeled by a set of structural equations  where each equation represents a distinct mechanism  or law  in the world  one that may be modified  by external actions  without altering the others  In practice  it seems useful to split the random variables into two sets  the exogenous variables  whose values are deter mined by factors outside the model  and the endogenous variables  It is these endogenous variables whose values are described by the structural equations   More formally  a signatureS is a tuple  U  V   R   where U is a finite set of exogenous variables  V is a finite set of endogenous variables  and n associates with every variable Y E U U V a nonempty set  R Y  of possible values for Y  that is  the set of values over which Y ranges   A causal model  or structural model  over signature S is a tuple M    S  F   where Fassociates with each variableX E V a ftmction denoted Fx such that Fx    xuEuR U   x  xYEV  x R Y     R X   Fx tells us the value ofX given the values of all the other variables in U U V  Example      Suppose that we want to reason about a forest fire that could be caused by either lightning or a match lit by an arsonist  Then the causal model would have the following endogenous variables  and perhaps others     F    L    for fire  F       if there is one  F  for lightning  L otherwise      ML for match lit  ML ML   otherwise           otherwise     if lightning occurred  L           I if the match was lit and   Sx    x   x   where F   fi is obtained from Fy by setting the values of the variables in X to x   It may seem strange that we are trying to understand causal ity using causal models  which clearly already encode causal relationships  Our reasoning is not circular  Our aim is not to reduce causation to noncausal concepts  but to interpret questions about causes of specific events in fully specified scenarios in terms of generic causal knowledge such as what we obtain from the equations of physics  The causal models encode background knowledge about the ten dency of certain event types to cause other event types  such as the fact that lightning can cause forest fires   We use the models to determine the causes and explanations of single events  such as whether it was arson that caused the fire of June           given what is known or assumed about that particular fire  We can describe  some salient features of  a causal model M using a causal network  This is a graph with nodes corresponding to the random variables in V and an edge from a node labeled X to one labeled Y ifFy depends on the value of X  Intuitively  variables can have a causal effect only on their descendants in the causal network  if Y is not a descendant of X  then a change in the value of X has no affect on the value of Y  In this paper  we restrict attention to what are called recursive  or acyclic  equations  these are ones that can be described with a causal network that is a dag  It should be clear that if M is a recursive causal model  then there is always a unique solution to the equations in Mx       r given a setting i  for the variables in U  we call such a setting i  a context   As we shall see  there are many nontrivial decisions to be made when choosing the structural model  The exogenous variables to some extent encode the background situation  that which we wish to take for granted  Other implicit back ground assumptions are encoded in the structural equations themselves  Suppose that we are trying to decide whether a lightning bolt or a match was the cause of the forest fire  and we want to take for granted that there is sufficient oxygen in the air and the wood is dry  We could model the dryness of the wood by an exogenous variable D with values    the wood is wet  and I  the wood is dry   By making D   HALPERN   PEARL       exogenous  its value is assumed to be given and out of the control of the modeler  We could also take the amount of oxygen as an exogenous variable  for example  there could be a variable   with two values    for insufficient oxygen  and    for sufficient oxygen   alternatively  we could choose not to model oxygen explicitly at all  For example  suppose we have  as before  a random variable ML for match lit  and another variable WB for wood burning  with values    it s not  and l  it is   The structural equation Fw   would describe the dependence of WB on D and ML  By setting Fw                we are saying that the wood will bum if the match is lit and the wood is dry  Thus  the equation is implicitly modeling our assumption that there is sufficient oxygen for the wood to burn  If we were to explicitly model the amount of oxygen in the air  which certainly might be relevant if we were analyzing fires on Mount Everest   then Fw   would also take values of   as an argument  Besides encoding some of our implicit assumptions  the structural equations can be viewed as encoding the causal mechanisms at work  Changing the underlying causal mechanism can affect what counts as a cause  Section   provides several examples of the importance of the choice of random variables and the choice of causal mechanism  It is not always straightforward to decide what the  right  causal model is in a given situation  nor is it always obvi ous which of two causal models is  better  in some sense  These may be difficult decisions and often lie at the heart of determining actual causality in the real world  Neverthe less  we believe that the tools we provide here should help in making principled decisions about those choices  To make the definition of actual causality precise  it is helpful to have a logic with a formal syntax  Given a signature S    U  V  R   a formula of the form X   x  for X E V and x E R X   is called a primitive event  A basic causa formula  overS  is one of the form  Y  o  y         Yk o  Yk  P where cp is a Boolean combination of primitive events  Y         Yk X are vari ables in V  with Yi         Yk are distinct  x E R X   and y  E R  i   Such a formula is abbreviated as  Y o  Y  P The special case where k   is abbreviated as cp  In tuitively   Y  o  y           Yk o  Yk cp says that cp holds in the counterfactual world that would arise if Y  is set toy   i              k  A causal formula is a Boolean combination of basic causal formulas  Syntax and Semantics      A causal formula  lj  is true or false in a causal model  given a context  We write  M  u  f     J if    J is true in causal model M given context u   M  u  f   Y o  Y   X x  if the variable X has value x in the  unique  since we are dealing with recursive models  solution to the equations in M y ii in context u  that is  the unique vector of values for the exogenous variables that simultaneously satisfies all equations Fi ii  Z E V  Y  with the variables in U set to ii    M  u  F  Y         YJcp for an arbitrary Boolean combination  p of formulas of the form X   x is defined similarly  We extend the definition to arbitrary causal for mulas  i e   Boolean combinations of basic causal formulas  in the standard way     UAI      Note that the structural equations are deterministic  We can make sense out of probabilistic counterfactual statements  even conditional ones  the probability that X would be   if Y  were    given that Y is in fact    in this framework  see  Balke and Pearl         by putting a probability on the set of possible contexts  This is not necessary for our discussion of causality  although it plays a more significant role in the discussion of explanation     THE DEFINITION OF CAUSE  With all this notation in hand  we can now give our defini tion of actual cause   cause  for short   We want to make sense out of statements of the form  event A is an actual cause of event  p  in context ii    As we said earlier  the context is the background information  While this has been left implicit in some treatments of causality  we find it use ful to make it explicit  The picture here is that the context  and the structural equations  are given  Intuitively  they encode the background knowledge  All the relevant events are known  The only question is picking out which of them are the causes of  p or  alternatively  testing whether a given set of events can be considered the cause of  p  The types of events that we allow as actual causes are ones of the form X  X                Xk   Xk that is  conjunctions of primitive events  we typically abbreviate this as X   x  The events that can be caused are arbitrary Boolean combinations of primitive events     Definition       Actual cause  X  xis an actual cause of  pin  M  it  if the following three conditions hold   ACl   M  it  F  X   x       p   That is  both X  X and  pare true in the actual world   AC   There exists a partition  Z  W  of V with X  i and some setting   i  w   of the variables in  X  W  such that if  M  u  F z   z  for z E i  then  a   M il       X      i  W    w j  cp  In wards  changing  X  w  from  x  w  to  x   w   changes  p from true to false   b   M  u  f   X         x  w         w   i      Z  cp for all subsets Z  of i  In words  setting w to W  should have no effect on  p as long as X is kept at its current value x  even if all the variables in an arbitrary subset of Z are set to their original values in the context a  AC   X is minimal  no subset of X satisfies conditions AC  and AC   Minimality ensures that only those elements of the conjunction X   x that are essential for changing cp cin AC  a  are considered part of a cause  inessential elements are pruned  I Note that we allow X   x to be a cause of itself  While we do not find such trivial causality terribly bothersome  it can   UAI       be avoided by requiring that X x xto be a cause ofcp   HALPERN     x       IP be consistent for     The core of this definition lies in AC   Informally  the variables in Z should be thought of as describing the  ac tive causal process  from X to cp   also called  intrinsic process  by Lewis           These are the variables that mediate between X and cp  Indeed  we can define an ac tive causal process from X   x to   p as a minimal set Z that satisfies AC   AC  a  is reminiscent of the tradi tional counterfactual criterion of Lewis          according to which cp should be false if it were not for X being x  However  AC  a  is more permissive than the traditional criterion  it allows the dependence of cp on X to be tested under special circumstances in which the variables W are held constant at some setting w   This modification of the traditional criterion was proposed by Pearl               and was named structural contingency an alteration of the model M that involves the breakdown of some mechanisms  possibly emerging from external action  but no change in the context il  The need to invoke such contingencies will be made clear in Example      AC  b   which has no obvious analogue in the literature  is an attempt to counteract the  permissiveness  of AC  a  with regard to structural contingencies  Essentially  it en sures that X alone suffices to bring about the change from   p to   cp  setting W to  merely eliminates spurious side effects that tend to mask the action of X  It captures the fact that setting w to w  does not affect the causal process by requiring that changingW from w to    has no effect on the value of   p  Moreover  although the values in the variables Z involved in the causal process may be perturbed by the change  the perturbation has no impact on the value of   p  The upshot of this requirement is that we are not at liberty to conduct the counterfactual test of AC  a  under an arbitrary alteration of the model  The alteration considered must not affect the causal process  Clearly  if the contingencies con sidered are limited to  freezing  variables at their actual value  so that   M  il  F w   W   then AC  b  is satisfied automatically  However  as the examples below show  gen uine causation may sometimes be revealed only through a broader class of counterfactual tests in which variables in W are set to values that differ from their actual values  In  Pearl        a notion of contributory cause is defined as well as actual cause  Roughly speaking  if AC  a  holds only with W   w  f  w  the A is a contributory cause of B  actual causality holds only ifW w     We remark that  like the definition here  the causal beam def inition  Pearl       tests for the existence of counterfactual dependency in an auxiliary model of the world  modified by a select set of structural contingencies  However  whereas    Recently  Lewis        has abandoned attempts to define   intrinsic process  formally  Pearl s  causal beam   Pearl       p        is a special kind of active causal process  in which AC  b   is expected to hold  with Z     z  for all settings necessarily the one used in  a    w   of W  not     PEARL       the beam criterion selects the choice of contingencies de pends only on the relationship a variable and its parents in the causal diagram  the current definition selects the mod ifying contingencies based on the specific cause and effect pair that is being tested  This refinement permits our def inition to avoid certain pitfalls  see Example      that are associated with graphical criteria for actual causation  AC  is a minimality condition  Heckerman and Shachter         have a similar minimality requirement  Lewis        mentions the need for minimality as well  Interestingly  in all the examples we have considered  AC  forces the cause to be a single conjunct of the form X x  Eiter and Lukasiewicz         and  independently  Hopkins          have recently proved that this is in fact a consequence of our definition     How reasonable are these requirements  In particular  is it appropriate to invoke structural changes in the defini tion of actual causation  The following example may help illustrate why we believe it is  Example      Suppose that two arsonists drop lit matches in different parts of a dry forest  and both cause trees to start burning  Consider two scenarios  In the first  called  disjunctive   either match by itself suffices to burn down the whole forest  That is  even if only one match were lit  the forest would bum down  In the second scenario  called  conjunctive   both matches are necessary to burn down the forest  if only one match were lit  the fire would die down  We can describe the essential structure of these two scenarios using a causal model with four variables    an exogenous variable U which determines  among other things  the motivation and state of mind of the arsonists  For simplicity  assume that R U   uoo  u    uo   u   I   if U   uii  then the first arsonist intends to start a fire iff i     and the second arson ist intends to start a fire iff j   I  In both scenarios U  ull        endogenous variables ML  and ML   each either   or I  where MLi     if arsonist i doesn t drop the match and ML    I if he does  fori         an endogenous variable FB for forest bums down  with values    it doesn t  and I  it does    Both scenarios have the same causal network  see Figure l    they differ only in the equation for FB  For the disjunctive scenario we have Fp    u        Fpa u O       Fpa u           land Fpa u O O       where u E n U    for the conjunctive scenario we have Fpa u  I  l  l and Fp  u          Fp  u          Fp   u      l     In general  we expect that the causal model for reasoning about forest fires would involve many other variables  in particular  variables for other potential causes of forest fires such lightning and unattended camp fires  here we focus on that part of the causal model that involves forest fires started by arsonists  Since for causal ity we assume that all the relevant facts are given  we can assume here that it is known that there were no unattended campfires and there was no lightning  which makes it safe to                HALPERN   PEARL  ignore that portion of the causal model  Denote by M   and causal models associated with the disjunctive and conjunctive scenarios  respectively  The causal network for the relevant portion of M   and M  is described in Figure     M  the     ML   FB Figure    The causal network for  M  and Mz   Despite the differences in the underlying models  it is not hard to show that each of ML       and MLz   I is a cause of FB     in both scenarios  We present the argument for  ML    is a cause in M  let Z    ML  FB   so W    ML    It is easy to see that the contingency ML      satisfies the two conditions ML        here  To show that  that there was a heavy rain in April and electrical storms in the following two months  and in June the lightning took hold  If it hadn t been for the heavy rain in April  the forest would have caught fire in May  The question is whether the April rains caused the forest fire  According to a naive  counterfactual analysis  they do  since if it hadn t rained  there wouldn t have been a forest fire in June  Bennett says  That is unacceptable  A good enough story of events and of causation might give us reason to accept some things that seem intuitively to be false  but no theory should persuade us that delaying a forest s burning for a month  or indeed a minute  is causing a forest fire    u  ML      in AC   AC  a  is satisfied because  in the absence of the second arsonist  ML        the first arsonist is necessary and sufficient for the fire to occur  FB       AC  b  is satisfied because  if the first match is lit  ML       the  In our framework  as we now show  it is indeed false to say that the April rains caused the fire  but they were a cause of there being a fire in June  as opposed to May  This seems to us intuitively right  To capture the situation  it suffices to use a simple model with three endogenous random variables      ML       of FB   in Mz   Again  taking Z W         ML   works      I is also a cause      ML  FB   and  This example also illustrates the need for the minimality condition AC    f lighting a match qualifies as the cause of firethen lighting a match and sneezing would also pass the  tests of AC  and AC  and awkwardly qualify as the cause of fire  Minimality serves here to strip  sneezing  and other irrelevant  over specific details from the cause  I This is a good place to illustrate the need for structural con  tingencies in the analysis of actual causation  The reason we consider ML      to be a cause of FB     in M  is that if ML  had been    rather than    FB would depend on MLt  In words  we imagine a situation in which the second  match is not lit  and we then reason counterfactually that the forest would not have burned down if it were not for the first match      EXAMPLES  In this section we show how our definition of actual causal ity handles some examples that have caused problems for other definitions  The full paper has further examples   Example      The first example is due to Bennett  and appears in  Sosa and Tooley       pp             Suppose   April showers   with two values    standing for did not rain heavily in April and I standing for  ES  for  electric storms   with four possible values           no electric storms in either May or June          electric storms in May but not June          storms in June but not May   and        storms in April and  May       order to reveal the latent dependence of FB on ML   Such a setting constitutes a structural change in the original model  since it involves the removal of some structural equations    AS for  rained heavily in April   contingency ML      does not prevent the fire from burning   in Mt  the forest  Thus  ML      is a cause of FB  Note that we needed to set ML  to    contrary to facts  in  A similar argument shows that  UAI        andF for  fire   with three possible values     no fire at all      fire  in May   or    fire in June    We do not describe the context explicitly  either here or in the other examples  Assume its value ii is such that it ensures that there is a shower in April  there are electric storms in both May and June  there is sufficient oxygen  there are no other potential causes of fire  like dropped matches   no other inhibitors of fire  alert campers setting up a bucket brigade   and so on  That is  we choose i  so as to allow us to focus on the issue at hand and to ensure that the right things happened  there was both fire and rain   We will not bother writing out the details of the structural equations they should be obvious  given the story  at least  for the context il   this is also the case for all the other examples in this section  The causal network is simple  there are edges from AS to F and from ES to F  It is easy to check that each of the following hold    AS W      is a cause ofthe June fire  F       taking     ES    VF        and  Z      AS  F    but not of fire  F         I  is a cause of both F     and  F   VF       Having electric storms in both May and  ES     June caused there to be a fire    I    ES     l     is not a cause of F      because it violates the minimality requirement of AC   each conjunct alone is a cause ofF      Similarly  AS   I    ES           is not a cause of   F     VF      AS        UA       HALPERN  The distinction between April showers being a cause of the fire  which they are not  according to our analysis  and April showers being a cause of a fire in June  which they are  is one that seems not to have been made in the discussion of this problem  cf   Lewis         nevertheless  it seems to us an important distinction  I Although we did not describe the context explicitly in Ex ample      it still played a crucial role  If the presence of oxygen is relevant then we must take this factor out of the context and introduce it as an explicit endogenous variables  Doing so can affect the causality picture  The next example already shows the importance of choosing an appropriate granularity in modeling the causal process and its structure       The following story from  Hall       is an example of preemption  where there are two potential Example  causes of an event  one of which preempts the other  An adequate definition of causality must deal with preemption in all of its guises  Suzy and Billy both pick up rocks and throw them at a bottle  Suzy s rock gets there first  shattering the bottle  Since both throws are perfectly accu rate  Billy s would have shattered the bottle had it not been preempted by Suzy s throw   Common sense suggests that Suzy s throw is the cause of the shattering  but Billy s is not  This holds in our framework too  but only if we model the story appropriately  Consider first a coarse causal model  with three endogenous variables    ST for  Suzy throws   with values    Suzy does not  throw  and    she does       PEARL       cheating  the answer is almost programmed into the model by invoking the relation  as a result of   which requires the identification of the actual cause  A more useful choice is to add two new random variables to the model      BHfor  Billy s rock hits the  intact  bottle   with val ues    it doesn t  and    it does   and SHfor  Suzy s rock hits the bottle   again with values   and     With this addition  we can go back to BS being two valued  In this model  we have the causal network shown in Figure    with the arrow SH    BH being inhibitory  BH BT    SH  that is  BH   iff BT   andSH     Note that  to simplify the presentation  we have omitted the exogenous variables from the causal network in Figure    In addition  we have only given the arrows for the particular context of interest  where Suzy throws first  In a context where Billy throws first  the arrow would go from BH to SH rather than going fromSH to BH  as it does in the figure              Figure    The rock throwing example  Now it is the case that ST     is a cause of BS       To satisfy AC   we choose W     BT  and w      and note that  because BT is set to    BS will track the setting of ST  Also note that BT   is not a cause of BS      there is no partition Z U W that satisfies AC   Attempting the symmetric choice W    BT  and w      would violate AC  b   with Z    BH     because cp becomes false when we set ST   and restore BH to its current value ofO       BT for  Billy throws   with values    he doesn t  and     he does      BS for  bottle shatters   with values    it doesn t shat ter  and    it does    Again  we have a simple causal network  with edges from both ST and BT to BS  In this simple causal network  BT and ST play absolutely symmetric roles  with BS ST V BT  and there is nothing to distinguish one from the other  Not surprisingly  both Billy s throw and Suzy s throw are classified as causes of the bottle shattering     The trouble with this model is that it cannot distinguish the case where both rocks hit the bottle simultaneously  in which case it would be reasonable to say that both ST     and BT   are causes of BS      from the case where Suzy s rock hits first  The model has to be refined to express this distinction  One way is to invoke a dynamic model  Pearl       p        Another way to gain expressiveness is to allow BS to be three valued  with values    the bottle doesn t shatter      it shatters as a result of being hit by Suzy s rock   and    it shatters as a result of being hit by Billy s rock   We leave it to the reader to check thatST     is a cause of BS      but BT     is not  if Suzy hadn t thrown but Billy had  then we would have BS     Thus  to some extent  this solves our problem  But it borders on              This example illustrates the need for invoking subsets of Z in AC  b   I Example      Is causality transitive  Consider the fol lowing story  again taken from  an early version of   Hall          Billy contracts a serious but nonfatal disease  He is hospitalized and treated on Monday  so is fine Tuesdsay morning  Had Monday s doctor for gotten to treat Billy  Tuesday s doctor would have treated him  and he would have been fine Tues day afternoon  But there is a twist  one dose of medication is harmless  but two doses are lethal  The causal model for this story is straightforward  There are three random variables  MT for Monday s treatment    if Billy was treated Monday    otherwise   TT for Tuesday s treatment     if Billy was treated Tuesday    otherwise   and BMC for Billy s medical condition    if Billy is fine both Tuesday morning and Tuesday afternoon    if Billy is sick   HALPERN       Tuesday morning  fine Tuesday afternoon    if Billy is sick both Tuesday morning and afternoon    if Bill is fine Tues day morning and dead Tuesday afternoon   In the causal network corresponding to this causal model  shown in Fig ure    there is an edge from MT to TT  since whether the Tuesday treatment occurs depends on whether the Monday treatment occurs  and edges from both MT and  T to BMC  since Billy s medical condition depends on both treatments      PEARL  UAI      then in the context where V    V    I  it is easy to see that each of Vi   I and V    I is a cause of P   l   However  suppose we now assume that there is a voting machine that tabulates the votes  Let M represent the total number of votes recorded by the machine  Clearly M V    V  and P   iff M     The following causal network repre sents this more refined version of the story  In this more       MT TT   I BMC  Figure    Billy s medical condition  In this causal model  it is true that MT     is a cause of  BMC      as we would expect because Billy is treated Monday  he is not treated on Tuesday morning  and thus recovers Tuesday afternoon    MT   I is also a cause of  T      as we would expect  and  T     is a cause of Billy s being alive  BMC     v BMC   I v BMC       However  MT   I is not a cause of Billy s being alive  It fails condition AC  a   setting MT     still leads to Billy s being alive  with W       Note that it would not help to takeW     IT  For ifTT  O thenBilly is alive no matter what MT is  while if  T      then Billy is dead when MT has its original value  so AC  b  is violated  with Z           This shows that causality is not transitive  according to our definitions  Although MT   I is a cause of  T     and  T     is a cause of BMC     v BMC   V BMC    MT  I is not a cause ofBMC   OVBMC    VBMC      Nor is causality closed under right weakening  MT     is a cause of BMC      which logically implies BMC     V BMC     V BMC      which is not caused by MT            Lewis  I           insists that causality is transitive  partly to be able to deal with preemption  Lewis        Our approach handles preemption without needing to invoke transitivity  which  as Lewis s own examples show  leads to counterintuitive conclusions  I Clause AC  b  in the definition is complicated by the need to check that no change in the value of the variables in Z can affect the value of   p  In all the previous examples  Z   z  for each variable Z E i  Could we not just require this  The following example shows that we cannot  Example      Imagine that a vote takes place  For sim plicity  two people vote  The measure is passed if at least one of them votes in favor  In fact  both of them vote in favor  and the measure passes  This version of the story is almost identical to Example      If we use V  and Vz to denote how the voters vote  V      if voter i votes against and Vi   I if she votes in favor  and P to denote whether the measure passes  P I if it passes  P     if it doesn t        Lewis s        revised  criterion of counterfactual dependence chain fails in this example  BMC does not depend on either MT or TT in the context given   Figure    An example showing the need for AC  b   refined scenario  vl     and v      are still both causes of P   l   Consider V    I  Take Z    Vi  M  P  and W   V t  Much like the simpler version of the story  if we choose the contingency V     then Pis counterfac tually dependent on V   so AC  a  holds  To check if this contingency satisfies AC  b   we set Vi to    their original value  and check that setting V  to   does not change the value of P  This is indeed the case  Although M becomes    not   as it is when V    Vz    nevertheless  P     continues to hold  so AC  b  is satisfied and V      is a cause of P      However  if we had insisted in AC  b  that  M  u  f   X of  x W of  w  Z   z  for all variables Z E Z  which in this case means that M would have to retain its original value of  when V      and V        then neither V      nor V      would be a cause of P   l  I       We remark that this example is not handled correctly by Pearl s causal beam definition  According to the causal beam definition  there is no cause for P      It can be shown if X   x is an actual  or contributory  cause of Y   y according to the causal beam definition given in  Pearl        then it is an actual cause according to the definition here  As Example     shows  the converse is not necessarily true  Example      This example concerns what Hall calls the distinction between causation and determination  Again  we quote Hall          You are standing at a switch in the railroad tracks  Here comes the train  If you flip the switch  you ll send the train down the left hand track  if you leave it where it is  the train will follow the right hand track  Either way  the train will arrive at the same point  since the tracks reconverge up ahead  Your action is not among the causes of this arrival  it merely helps to determine how the arrival is brought about  namely  via the left hand track  or via the right hand track    Again  our causal model gets this right  Suppose we have three random variables    UAI             HALPERN  F for  flip   with values    you don t flip the switch  and    you do   T for  track   with values    the train goes on the left hand track  and I  it goes on the right hand track    A for  arrival   with values    the train does not arrive at the point of reconvergence  and I  it does    Now it is easy to see that flipping the switch  F   I  does cause the train to go down the left hand track  T       but does not cause it to arrive  A   I   thanks to AC  a   whether or not the switch is flipped  the train arrives  However  our proposal goes one step beyond this simple picture  Suppose that we model the tracks using two vari ables      LT for  left track   with values    the train goes on the left hand track  and    it does not   and RT for  right track   with values    the train goes on the right hand track  and    it does not    The resulting causal diagram is shown in Figure     it is iso morphic to a class of problems Pearl        calls  switch ing causation    Lo and behold  this representation classifies F   I as a cause of A  which  at first sight  may seem coun terintuitive  Can a change in representation turn a non cause into a cause     PEARL       this possibility that should enter our mind whenever we de cide to designate each track as a separate mechanism  i e   equation  in the model and  keeping this contingency in mind  it should not be too odd to name the switch position a cause of the train arrival  or non arrival   I We conclude this section with an example that shows a potential problem for our definition  and suggest a solution  Example      Fred has his finger severed by a machine at the factory  FS   I   Fortunately  Fred is covered by a health plan  He is rushed to the hospital  where his finger is sewn back on  A month later  the finger is fully functional  FF     In this story  we would not want to say that FS   is a cause ofFF   and  indeed  according to our definition  it is not  since FF     whether or not FS      in all contingencies satisfying AC  b             However  suppose we introduce a new element to the story  representing a nonactual structural contingency  Larry the Loanshark may be waiting outside the factory with the in tention of cutting off Fred s finger  as a warning to him to repay his loan quickly  Let LL represent whether or not Larry is waiting and let LC represent whether Larry cuts of the Fred s finger  If Larry cuts off Fred s finger  he will throw it away  so Fred will not be able to get it sewn back on  In the actual situation  LL   LC      Larry is not waiting and Larry does not cut off Fred s finger  So  intu itively  there seems to be no harm in adding this fanciful element to the story  Or is there  Suppose that  if Fred s finger is cut off in the factory  then Larry will not be able to cut off the finger himself  since Fred will be rushed off   becomes a cause of FF    to the hospital   Now FS    if FS   For in the structural contingency where LL then FF    Larry will cut off Fred s finger and throw it away  so it will not become functional again   Moreover  if FS   I  then LC   and FF I  just as in the actual situation   I                A     Figure    Flipping the switch  It can and it should  The change to a two variable model is not merely syntactic  but represents a profound change in the story  The two variable model depicts the tracks as two independent mechanisms  thus allowing one track to be set  by action or mishap  to false  or true  without affecting the other  Specifically  this permits the disastrous mishap of flipping the switch while the left track is malfunctioning  Such abnormal eventualities are imaginable and expressible in the two variable model  but not in the one variable model  The potential for such eventualities is precisely what renders F   I a cause ofthe A in the model of Figure     Is flipping the switch a legitimate cause of the train s ar rival  Not in ideal situations  where all mechanisms work as specified  But this is not what causality  and causal modeling  are all about  Causal models earn their value in abnormal circumstances  created by structural contingen cies  such as the possibi lity of a malfunctioning track  It is    This can be seen by noting that condition AC  is satisfied by  the partition  Z       F  LT  A      W      RT   and choosing  the setting R T      The event RT     conflicts with F normal situations      w   as    under     This example seems somewhat disconcerting  Why should the Loanshark to the story affect  indeed  result in  the accident being a cause of the finger being functional one month later  While it is true that the accident would be judged a cause of Fred s good fortune by anyone who knew of Larry s vicious plan  many underworld figures owe their lives to  accidents  of this sort   the question remains how to distinguish genuine plans that just happened not to materialize from sheer fanciful scenarios that have no basis in reality  To some extent  the answer here is the same as the answer to essentially all the other concerns we have raised  it is a modeling issue  If we know of Larry s plan  or it seems like a reasonable possibility  we should add it to the model  in which case the accident is a cause ofthe finger being functional   otherwise we shouldn t   adding a fanciful scenario like Larry  But this answer makes the question of how reasonable a possibility Larry s plan are into an aU or nothing decision  One solution to this problem is to extend our notion of  We thank Eric Hiddleston for bringing this issue and this  example to our attention         HALPERN   PEARL  causal model somewhat  so as to be able to capture more directly the intuition that the Larry the Loanshark scenario is indeed rather fanciful  There a number of ways of doing this  we choose one based on Spohn s notion of a ranking function  or ordinal conditionalfunction   Spohn         A ranking K on a space W is a function mapping subsets of W to IN    IN U   oo  such that K W     K      oo  and K A    minw E A  K    w       Intuitively  an ordinal ranking assigns a degree of surprise to each subset of worlds in W  where   means unsurprising and higher numbers denote greater surprise  Let a world be a complete setting of the exogenous variables  Suppose that  for each context il  we have a ranking      on the set of worlds  The unique setting of the exogenous variables that holds in context il is given rank   by       other worlds are assigned ranks according to how  fanciful  they are  given context il  Presumably  in Example      an appropriate ranking K would give a world where Larry is waiting to cut off Fred s finger  i e   where LL       a rather high    ranking  to indicate that it is rather fanciful  We can then modify the definition of causality so that we can talk about X   x being an actual cause of r p in  M  u  at rank k  The definition is a slight modification of condition AC  in Definition       so the contingency         l    must hold in a world of rank at most k  we omit the formal details here  We then can restrict actual causality so that the structural contingencies involved have at most a certain rank  This is one way of ignoring fanciful scenarios        DISCUSSION  We have presented a principled way of determining actual causes from causal knowledge  The essential principles of our account include using structural equations to model causal mechanisms  using uniform counterfactual notation to encode and distinguish facts  actions  outcomes  and contingencies  using structural contingencies to uncover causal dependencies  and careful screening of these con tingencies to avoid tampering with the causal processes to be uncovered  While our definitions has some unsatisfy ing features  see Example       we hope that the examples presented here illustrate how well it deals with many of the problematic cases found in the literature  As the examples have shown  much depends on choosing the  right  set of variables with which to model a situation  which ones to make exogenous  and which to make endogenous  While the examples have suggested some heuristics for making appropriate choices  we do not have a general theory for how to make these choices  We view this as an important direction for future research  Acknowledgments We thank Christopher Hitchcock for many useful comments on earlier versions of the paper  Zoltan Szabo for stim ulating discussions  and Eric Hiddleston for pointing out Example      Halpern s work supported in part by NSF un der grants IRI          and IIS          and ONR under grant N              l   Pearl s work supported in part by grants from NSF  ONR  AFOSR  and MICRO   UA I       
