  We consider a voting setting where candidates have preferences about the outcome of the election and are free to join or leave the election  The corresponding candidacy game  where candidates choose strategically to participate or not  has been studied by Dutta et al       who showed that no non dictatorial voting procedure satisfying unanimity is candidacy strategyproof  that is  is such that the joint action where all candidates enter the election is always a pure strategy Nash equilibrium  In     Dutta et al  also showed that for some voting tree procedures  there are candidacy games with no pure Nash equilibria  and that for the rule that outputs the sophisticated winner of voting by successive elimination  all games have a pure Nash equilibrium  No results were known about other voting rules  Here we prove several such results  For four candidates  the message is  roughly  that most scoring rules  with the exception of Borda  do not guarantee the existence of a pure Nash equilibrium but that Condorcet consistent rules  for an odd number of voters  do  For five candidates  most rules we study no longer have this guarantee  Finally  we identify one prominent rule that guarantees the existence of a pure Nash equilibrium for any number of candidates  and for an odd number of voters   the Copeland rule  We also show that under mild assumptions on the voting rule  the existence of strong equilibria cannot be guaranteed     Introduction A main issue for the evaluation of voting rules is their ability to resist various sorts of strategic behavior  Strategic behavior can come from the voters reporting insincere votes  manipulation   from a third party  typically the chair  acting on the set of voters or candidates  control   on the votes  bribery  lobbying   or on the voting rule  e g   agenda control   However  strategic behavior by the candidates has received less attention than strategic behavior by the voters and  to a lesser extent  by the chair  One form thereof involves choosing optimal political platforms  But probably the simplest form comes from the ability of candidates to decide whether to run for the election or not  which is the issue we address here  The following table summarizes this rough classification of strategic behavior in voting  according to the identity of the strategizing agent s  and to another relevant dimension  namely what the strategic actions bear onvoters  votes or candidates  we omit the agenda to keep the table small     actions  agents  voters  voters  votes  strategic participation  manipulation  third party   chair  voter control  candidates     candidates  candidate control  bribery  lobbying cloning strategic candidacy    Strategic candidacy does happen frequently in real life elections  both in large scale political elections and in small scale  low stake elections  e g   electing a chair in a research group  ormoving a little bit away from electionsreputation systems   Throughout the paper we consider a finite set of potential candidates  which we simply call candidates when this is not ambiguous  and we make the following assumptions                  each candidate may choose to run or not for the election  each candidate has a preference ranking over candidates  each candidate ranks himself on top of his ranking  the candidates preferences are common knowledge among them  the outcome of the election as a function of the set of candidates who choose to run is common knowledge among the candidates   With the exception of    these assumptions were also made in the original model of Dutta et al      which we discuss below  Assumption   amounts to saying that a candidate is interested only in the winner of the election  and has no indifferences or incomparabilities  Assumption    considered as optional in      is a natural domain restriction in most contexts  Assumptions   and   are common game theoretic assumptions  note that we do not have to assume that the candidates know precisely how voters will vote  nor even the number of voters  they just have to know the choice function mapping every subset of candidates to a winner  Assumption   is required only when strong Nash equilibria are considered  Existing work on strategic candidacy is rather scarce  Dutta et al        formulate the strategic candidacy game and prove that no non dictatorial voting procedure satisfying unanimity is candidacy strategyproof  or equivalently  that for any non dictatorial voting procedure satisfying unanimity  there is a profile for which the joint action where all candidates enter the election is not a pure Nash equilibrium   Then  Dutta et al      exhibit a  non anonymous  voting tree rule for four candidates for which there is a candidacy game with no pure Nash equilibria  They also show that for the voting rule that outputs the sophisticated outcome for voting by successive elimination  the existence of a pure Nash equilibrium is guaranteed  Some of these results are discussed further  together with simpler proofs  by Ehlers and Weymark      and extended to voting correspondences by Ereslan     and Rodriguez       and to probabilistic voting rules by Rodriguez       Brill and Conitzer     extend the analysis to also include strategic behavior by the voters  Polukarov et al       study equilibrium dynamics in candidacy    In some contexts  candidates may have more refined preferences that bear for instance on the number of votes they get  how their score compares to that of other candidates  etc  We do not consider these issues here    games  in which candidates may strategically decide to enter the election or withdraw their candidacy  Obraztsova et al       study strategic candidacy games with lazy candidates  whose utility function results form the outcome of the election minus a small penalty for running for election  Studying the equilibria of a candidacy game helps predicting the set of actual candidates and therefore the outcome of the vote  However  little is known about this  we only know that for any reasonable voting rule  there are some candidacy games for which the set of all candidates is not a pure Nash equilibrium  that there exist candidacy games with no pure Nash equilibria  and that a specific rule  defined from the successive elimination procedure and assuming that voters reason by backward induction  all candidacy games have a pure Nash equilibrium  We do not know  for instance  whether pure Nash equilibria always exist for common voting rules such as plurality  Borda or Copeland  In this paper  we go further in this direction and prove some positive as well as some negative results  We first consider the case of four candidates and show that for an odd number of voters  a pure Nash equilibrium always exists for Condorcet consistent rules  while for most scoring rules and as well as for single transferable vote and plurality with runoff  this is not the case  Over the five candidate frontier  we know very few rules that  can still guarantee the existence of an equilibrium  We show that for the Copeland rule  and an odd number of voters  there is always a pure Nash equilibrium  whichever the number of candidates  On the negative side  we show that for most scoring rules  for at least four candidates  and for Borda  maximin  and the uncovered set for at least five candidates  and for the top cycle with at least seven candidates  there are candidacy games without pure Nash equilibria  We also prove a simple impossibility theorem showing that strong Nash equilibria are not guaranteed to exist provided the voting rule satisfies two mild conditions satisfied by most common rules  The paper unfolds as follows  In Section   we define the strategic candidacy games and give a few preliminary results  In Section   we focus on the case of four candidates  The case of five candidates is considered in Section    Section   deals with candidacy games with more candidates  In Section   we discuss strong Nash equilibria  and relate the candidacy game to candidate control  Finally  in Section   we discuss further issues     Model and preliminaries In this section  we define the strategic candidacy model  show that it induces a normal form game  and give preliminary results on the existence of Nash equilibria      Voting rules Let X    x    x          xm   be a set of potential candidates and N                n  a set of n voters  We assume n is odd  so that pairwise majority ties do not occur  While this is a mild assumption when the number of voters is large  this implies a loss of generality for some of our results  and when this is the case we will make it clear  For any subset Y  X of the candidates  a Y  vote is a linear ordering over Y   A Y  profile P   h            n i is a collection of n Y  votes  Although voting rules are often defined for a fixed set of candidates  here we define them for an arbitrary subset   of the set of potential candidates  a  resolute  voting rule maps every Y  profile  for every Y  X  to a candidate in Y   We will only consider resolute rules  we will first define their irresolute version and then assume that ties are broken up according to a fixed priority relation over the candidates  Because voting rules are applied to varying sets of candidates  we assume that the tie breaking rule is defined as a linear ordering on the whole set of potential candidates X  and projected to subsets of candidates  if x has priority over y  noted x  y  when all potential candidates run  this will still be the case for any set of candidates that contains x and y  We now define the rules we will use in the paper   For each of them we define its irresolute version  its resolute version being obtained as explained above   Scoring rules  A scoring rule  for a varying set of candidates  is defined by a collection of vectors S m   hs          sm i for all m  with s   s          sm and s    sm   For each m and each i  m  si is the number of points obtained by the candidate ranked in position i  and the winning candidate s  maximizes the sum of points obtained from all votes  Formally speaking  defining a family of scoring rules requires to specify a scoring vector for each size of a candidate set  for instance  h       i for three candidates  h          i for four candidates and so on   However  for the following classical rules  these collections of vectors are defined in a natural way   plurality  S m   h             i   veto  or antiplurality   S m   h             i   Borda  S m   hm     m               i  Condorcet consistent rules  Let P be a profile and NP  c  x  be the number of votes in P who rank c above x  The majority graph m P   associated with P is the graph whose vertices are the candidates and containing an edge from x to y whenever NP  x  y    n   we say that x beats y in m P    denoted by x P y   Because n is odd  m P   is a tournament  i e  a complete asymmetric graph  A candidate c is a Condorcet winner if c P y for all y    c  A voting rule r is Condorcet consistent if r P      c  whenever there is a  unique  Condorcet winner c for P   Given a profile P   the top cycle T C P   is the smallest S  X such that for every x  S and y  X   S  x P y   The uncovered set U C P   is the set S  X of candidates such that for any c  S and for any other candidate x  if x P c then there is some y such that c P y and y P x  The maximin rule chooses the candidate s  c that maximize minxX  c  NP  c  x   The Copeland rule chooses the candidate s  c that maximize   x  X c P x    Rules based on iterative elimination of candidates  Plurality with runoff proceeds in two rounds  we first select the two candidates x and y with highest plurality scores and the second round chooses between them according to majority  Single transferable vote  STV  proceeds in m    rounds  at each round  the candidate with the lowest plurality score among the remaining candidates  using tie breaking if necessary  is eliminated      Strategic candidacy In addition to voters preferences over candidates  expressed by the voter profile P   we assume that each candidate i too has a linear preference ordering i over candidates    We assume furthermore that the candidates preferences are self supportedthat is  each candidates rank herself at the top of her ranking  Let P X    PcX  cX denote the candidates preference profile  We assume that voters are sincere  therefore  when the set of candidates running for election is Y  X  each voter i reports the restriction of i to Y and the obtained profile  denoted by P Y   is the restriction of P to Y   Given a fixed voter profile P   a voting rule r can be seen as mapping each Y  X to a winner r P Y   in Y   We use the notation Y  P r x  or more simply  Y   x when there is no ambiguity  to denote that the outcome of rule r applied to profile P restricted to the subset of candidates Y  X is x  Each voting rule r induces a natural game form  where the set of players is given by the set of potential candidates X  and the strategy set available to each player is        with   corresponding to entering the election and   standing for withdrawal of candidacy  A state s of the game is a vector of strategies  sc  cX   where sc          For convenience  we use sz to denote  sc  cX  z  i e   s reduced by the single entry of player z  Similarly  for a state s we use sZ to denote the strategy choices of a coalition Z  X and sZ for the complement  and   we write s    sZ   sZ    The outcome of a state s is r P Y where c  Y if and only if sc       Coupled with a voter profile P and a candidate profile P X   this defines a normal form game    hX  P  r  P X i with m players  Here  player c prefers outcome   s  over outcome   s   if ordering PcX ranks   s  above   s        Game theoretic concepts Having defined a normal form game  we can now apply standard game theoretic solution concepts  Let    hX  P  r  P X i be a candidacy game  and let s be a state in    We say that a coalition Z  X has an improving move in s if there is sZ such that   sZ   sZ   is preferred to   s  by every z  Z  In particular  the improving move is unilateral if  Z       A state is a  pure strategy  Nash equilibrium  NE  if it has no unilateral improving moves  and a k NE if no coalition with  Z   k has an improving move  A strong Nash equilibrium  SE      is a state with no improving moves  Example    Consider the game h a  b  c  d   P  r  P X i  where r is the Borda rule  and P and P X are as follows      b c dd aa c b       P    ca dc b b ad    d a c b    b c d a    a b c d  PX ab c ab c dab bda c cd  d d a c b  When clear from the context  we use vector s to also denote the set of candidates Y that corresponds to state s  e g   if X    x    x    x     we note  x    x    and         interchangeably  In our examples  when the tie breaking ordering is not specified it is assumed to be lexicographic  We generally omit curly brackets  The first row in P indicates the number of voters casting the different ballots  We use the common convention of writing votes vertically  with the topmost candidate being preferred    The state           is not an NE  abcd   c  but abc   a  and d prefers a to c  so for d  leaving is an improving move  Now            is an NE  as noone has an improving move neither by joining  d prefers a over c   or by leaving  obviously not a  if b or c leaves then the winner is still a   It can be checked that this is also an SE      Preliminary results Regardless of the number of voters and the voting rule used  a straightforward observation is that a candidacy game with three candidates is guaranteed to possess an NE  Note that this does not hold for SE   The first question which comes to mind is whether examples showing the absence of NE transfer to larger set of candidates  They indeed do  under an extremely mild assumption  We say that a voting rule is insensitive to bottom ranked candidates  IBC  if given any profile P over X    x            xm    if P  is the profile over X   xm     obtained by adding xm   at the bottom of every vote of P   then r P      r P    This property is extremely weak  much weaker than Pareto efficiency  and is satisfied by almost all common voting rules  Lemma    For any voting rule r satisfying IBC  if there exists    hX  P  r  P X i with no NE  then there exists     hX    P    r  P Y i with no NE  where  X       X       Proof  Take  with no NE  with X    x            xm    Let X    X   xm      P  the  profile obtained from P by adding xm   at the bottom of every vote  and P X be the candidate profile obtained by adding xm   at the bottom of every ranking of a candidate xi   i   m  and whatever ranking for xm     Let Y  X  Because Y is not an NE for    some candidate xi  X has an interest to leave or to join  therefore Y is not an NE either for     Now  consider Y    Y   xm      If xi  X has an interest to leave  resp   join  Y   then because r satisfies IBC  the winner in Y     xi    resp   Y    xi    is the same as in Y    xi    resp   Y   xi     therefore xi  X has an interest to leave  resp   join  Y    therefore Y  is not an NE    We will use this induction lemma to extend some of our negative results to an arbitrary number of candidates  A noticeable exception is the veto rule  which does not satisfy IBC  In Appendix A we provide a specific lemma to handle this rule  The following result applies to any number of candidates and Condorcet consistent rules  Proposition    Let    hX  P  r  P X i be a candidacy game where r is Condorcetconsistent  If P has a Condorcet winner c then for any Y  X  Y is an SE  Y is an NE  c  Y   The very easy proof can be found in Appendix A  If P has no Condorcet winner  the analysis becomes more complicated  We provide results for this more general case in the following sections     Here is a counterexample  communicated to us by Markus Brill   The selection rule is abc   b  ab   a  ac   c  bc   c  it can be easily implemented by the scoring rule with scoring vector         i with   voters  Preferences of candidates are  a   a  b  c  b   b  c  a  c   c  a  b  The group deviations are  in  a  b  c   c leaves  in  a  b   b leaves and c joins  in  a  c   b joins  in  b  c   a joins  in  a   c joins  in  b   c joins  in  c   a and b join      The first frontier  four candidates With only four potential candidates  we exhibit a sharp contrast between the Condorcetconsistent rules  for which a Nash equilibrium is guaranteed to exist  for odd n   and many other voting rules      Scoring rules We make use of a powerful result by Saari      which states that for almost all scoring rules  any choice function can result from a voting profile  For four candidates       we define a Saari rule as a rule for which  when the scoring vector for three candidates is of the form hw    w     i  then the vector for four candidates is not h w    w     w     w     i  For instance  plurality and veto are Saari rules  but the Borda rule is not a Saari rule  For any Saari rule  any choice function can result from a voting profile          This means that our question boils down to check whether a choice function  together with some coherent candidates preferences  can be found such that no NE exists with four candidates  We solved this question by encoding the problem as an Integer Linear Program  ILP   the details of which can be found in Appendix B  It turns out that such choice functions do exist  We depict one of them in Figure    where arrows denote deviations and the right part of each cell denotes the winner   which rules out the existence of an NE when taken with the candidates preferences  a abcd b  bacd c  cdab d dabc  abcd d  abc c  ab a  a a  abd b  ad d  ac c  b b  acd a  cd c  bcd d  bc b  c c  Fig     A choice function without NE  The following result then follows directly   bd b  d d   Proposition    For four candidates  if r is a Saari rule  there are candidacy games without Nash equilibria  As a corollary  we get that  Corollary    For plurality  veto  and more generally  for k approval with any k   there are candidacy games without NE  Note that Saaris result shows that counter examples can be obtained for all these scoring rules  but it does not directly provide the profile satisfying this choice function  These profiles may involve a large number of voters  For plurality  we exhibit a profile with    voters corresponding to the choice function given in Fig     whose preferences are shown on the left part of the table below  The right part of the table represents P X      dd c b ac ba    d a b c    a b c d    a c b d    a d b c    b c d a    b a c d    c b d a  ab ab ba c c dd  c c d a b  d d a b c  Similar profiles can be obtained for other Saari rules  As for the Borda rule  which is not a Saari rule  it stands as an exception  Proposition    For Borda and m      every candidacy game has an NE  This result was obtained by a translation into an integer linear program  then run on a computer  It relies on the fact that Borda rule can be computed from the weighted majority graph  and by adding the corresponding constraints into the ILP  for the details of this ILP  see Appendix B   The infeasibility of the resulting set of constraints shows that no instances without NE can be constructed  However  it takes only coalitions of pairs of agents to ruin this stability  Indeed  for Borda and m      there are candidacy games without   NE  This can be seen on the following candidacy game       abcd b cdabab cd ddab c caab cac cddcda ab bdabdb c Only s                 and s                 are NE  with bcd   b  and abd   d  From s  the coalition  a  c  has an improving move to s  as they both prefer d to b  From s    if b leaves and c joins  they reach               with acd   c and both prefer c to d      Rules based on successive elimination Let us now focus on plurality with runoff and single transferable vote  For these rules  it is no longer the case that any choice function can be implemented by such rules  For instance  for plurality with runoff  a necessary condition for the choice function to be implementable is that  for any subset of candidates Y    Y       if r Y     x  then   x must win in pairwise comparison against some candidate y  Y    x   For STV  a stronger condition is even required  for any subset of candidates Y   if r Y     x  it must be the case that r Z    x for some set Z  Y such that  Z     Y      We make no claim that these conditions are sufficient to ensure a possible implementation  However  by adding these constraints into our ILP  we generated a choice function that we could in turn implement with a specific profile  thus providing us the following result  Proposition    For plurality with runoff and single transferable vote and m      there are candidacy games without NE  Proof  We exhibit a counter example with   voters  The tie breaking is d  a  c  b     aa cd b b dc    b a c d    b c a d    b d c a    c b d a    c d a b    d a b c    d c a b  ab ab ba dc cd  c c a b d  d d a c b        Condorcet consistent rules We now turn our attention to Condorcet consistent rules  We recall that we assume the number of voters n to be odd  Proposition    For m      and n odd   if r is Condorcet consistent then every candidacy game has an NE  Proof  For any profile P   let GP the complete tournament obtained from the majority graph associated with P   Although we do not assume that r is based on the majority graph  we nevertheless prove our result by considering all possible tournaments on four candidates  we shall get back to this point at the end of the proof   In the proof  when we speak of an NE in G we mean an NE in any candidacy game for which the profile P is associated with the majority graph G  There are four tournaments to consider  all others are obtained from these ones by symmetry   a  b  a  b  a  b  a  b  c  d  c  d  c  d  c  d  G   G   G   G   For G  and G    any subset of X containing the Condorcet winner is an NE  see Proposition     For G    we note that a is a Condorcet loser  That is  N  a  x    N  x  a  for all x   b  c  d   Note that in this case  there is no Condorcet winner in the reduced profile P  b c d  as this would imply the existence of a Condorcet winner in P  case G  or G     W l o g   assume that b beats c  c beats d  and d beats b  W l o g  again  assume   that bcd   b  Then   b  c  is an NE  Indeed  in any set of just two candidates  none has an incentive to leave  Now  a or d have no incentive to join as this would not change the winner  in the former case  observe that b is the  unique  Condorcet winner in P  a b c    and the latter follows by our assumption  There is always an NE for G    The proof for G  is more complex and proceeds case by case  Since r is Condorcetconsistent  we have acd   a  bcd   c  ab   b  ac   a  ad   a  bc   c  bd   d and cd   c  The sets of candidates for which r is undetermined are abcd  abc and abd  We have the following easy facts   i  if abcd   a then acd is an NE   ii  if abcd   c then bcd is an NE   iii  if abc   a then ac is an NE   iv  if abd   a then ad is an NE   v  if abc   c then bc is an NE  The only remaining cases are               abcd   b  abc   b  abd   b  abcd   b  abc   b  abd   d  abcd   d  abc   b  abd   b  abcd   d  abc   b  abd   d   In cases   and    ab is an NE  In case    if a prefers b to c then abc is an NE  and if a prefers c to b  then bcd is an NE  In case    if a prefers c to d  then bcd is an NE  if b prefers a to d  then ad is an NE  finally  if a prefers d to c and b prefers d to a  then abcd is an NE  To conclude  observe that the proof never uses the fact that two profiles having the same majority graph have the same winner     Thus  the picture for four candidates shows a sharp contrast  On one hand  we show that almost all scoring rules       single transferable vote  and plurality with run off  may fail to have an NE  On the other hand  Condorcet consistency alone suffices to guarantee the existence of an NE     The second frontier  five candidates We start with scoring rules  Recall that for four candidates we had the non existence results for most rules  with Borda being a noticeable exception  We now show that five candidates is enough for Borda to lose this guarantee of the existence of NE  Proposition    For the Borda rule  with five candidates  there are candidacy games without Nash equilibria  Proof  The following counterexample has been obtained by applying the same ILP technique as described in the previous section  We do not give the profile but only its majority margin matrix  where the number corresponding to row x and column y is NP  x  y   NP  y  x   by Debords theorem      the existence of a profile P realizing this matrix is guaranteed because all elements of the matrix have the same parity     For instance  we may have two profiles P   P  both corresponding to G    such that r P     a and r P      b  the proof perfectly works in such a case    a b c d e abcde a            a b c d e b            b a a c c c            e e d e d d           c c e a a e             d d b b b Below we give the explicit listing of all    states  introducing a notation that we shall use throughout the paper  the outcome of the choice function  the winner in each state  is given in boldface  and a deviation from this state is given next to each state  where x   respectively x  means that x has a profitable deviation by joining  respectively  by leaving  this state  It can be seen that none of the    states is an NE   a b  b c  c d  d e  e a   ab c  ac d  ad b  ae b  bc d  bd e  be c  cd e  ce a  de a   abc d  abd c  abe c  acd c ace e ade b  bcd e  bce b bde a  cde a   abcd e  abce b abde c  abcde b acde e bcde d    Recall that for Condorcet consistent rules  the existence of NE is guaranteed for four candidates  For the maximin rule and the uncovered set rule  this existence result stops at four  The proof  consisting of two counterexamples  is in Appendix A  Proposition    For the maximin rule and the uncovered set rule  with five candidates  there are candidacy games without NE  However  this negative result does not extend to all Condorcet consistent rules  as shown in Proposition   below  and also in Proposition   in the following section   Proposition    For the Top Cycle rule  with five candidates  every candidacy game has a Nash equilibrium  Proof  Let P be a profile over X    a  b  c  d  e  and without loss of generality  assume that the tie breaking priority ranks a above all other candidates  If  T C P       then consider the restriction P T C P   of P to T C P    It is a q candidate profile for q     therefore by Proposition   the corresponding candidacy game has an NE Z  T C P    Because it is an NE in P T C P     no candidate in T C P   has an incentive to deviate  Now  if a candidate in X   T C P   joins  the outcome does not change  therefore no candidate outside T C P   has an incentive to join  Therefore  Z is an NE for P     Assume now that T C P      a  b  c  d  e   this implies T Ct  P     a  Without loss of generality  assume the majority graph contains a  b  c  d  e  a  For abcde not to be an NE  a withdrawing agent x has to induce a new top cycle not containing a  If this top cycle is a singleton  then X    x  is an NE  Therefore  the top cycle after the withdrawal of x must be of size    it can only be  c  d  e   with b withdrawing because it prefers the most prioritary candidate  let us call it y  among  c  d  e  to a  At this stage  we know that d  a  c  a  e  a  c  d  e  c  and that the winner in acde is y  Observe that  irrespective of the tie breaking winner  a cannot leave because the winner would remain the same  There are thus three cases to consider   Case    y   c  Consider acd   c  Since ac   c  cd   c  and acde   c  acd is not an NE only if b wants to join  but abcd   a  and b prefers c to a  bcd is an NE   Case    y   e  Consider ace   e  Since ae   e  ce   e  and acde   e  ace is not an NE only if b wants to join  For this to be possible  we must have b  e  and then abce   a  But in this case  since abc   a  abe   a  and abcde   a  abce is an NE  Therefore  either ace or abce is an NE   Case    y   d  Consider ade   d  Since ad   d  de   d and acde   d  ade is not an NE only if b wants to join  For this to be possible  it must be that b  d  and b prefers a over d   Thus abde   a  In this case  since abd   a and abcde   a  abde is not an NE only if d wants to leave  This is possible only if e  b  and d prefers e over a   But then abe   e  ae   e  be   e  and abce   e  abde is an NE  Therefore  either ade or abde is an NE       More candidates In this section  we present our results for a general number of candidates      A positive result  Copeland We show the existence of NE for Copeland  under deterministic tie breaking  for any number of candidates  provided n is odd   Proposition    For Copeland  for any number of candidates and an odd number of voters  every candidacy game has an NE  Proof  Let P be a profile and P its associated majority graph  Let C x  P   be the number of candidates y    x such that x P y  The Copeland cowinners for P are the candidates maximizing C   P    Let Cop P   be the set of Copeland cowinners for P and let c be the Copeland winneri e   the most prioritary candidate in Cop P    Consider Dom c     c      y c P y   Note that C c  P Dom c     Dom c        q  C c  P    Also  since any y  Dom c  is beaten by c  we have C y  P Dom c     q     We claim that Dom c  is an NE  Note that c is a Condorcet winner in the restriction of P to Dom c   and a fortiori  in the restriction of P to any subset of Dom c   Hence  c is the Copeland winner in Dom c  and any of its subsets  and no candidate in Dom c  has an incentive to leave      Now  assume there is a candidate z  X  Dom c  such that r P Dom c  z     c  Note that z P c as z does not belong to Dom c   so  C c  P Dom c  z      q  For any y  Dom c  we have C y  P Dom c  z      q           q   C c  P Dom c  z     If C y  P Dom c  z    C c  P Dom c  z     then y is not the     Copeland winner in P Dom c  z    If C y  P Dom c  z    C c  P Dom c  z    then C y  P    C c  P    That is  either c    Cop P    a contradiction  or both y  c are in Cop P    The latter implies c  y  hence  y is not the Copeland winner in P Dom c  z        Hence  r P Dom c  z    z  That is  either     C z  P Dom c  z    q  or       C z  P Dom c  z    q and z  c  If     holds then C z  P     C c  P    which contradicts the fact that c is the Copeland winner in P   If     holds then C z  P     C c  P  i e   both c and z are in Cop P    which implies that c  z  and z cannot win in P Dom c  z    Therefore  the Copeland winner in P Dom c  z  is c  which implies that z has no incentive to join Dom c     Note that not only the existence of an NE is guaranteed  but also the existence of an NE where the winner is the same winner as on the original profile  that is  the Copeland winner of the profile with all candidates running    When n is even  the result carries on if no pairwise majority ties occur  In the general case  however  the result depends on the way ties are taken into account for computing the Copeland score of a candidate  For the variant Copeland  where the Copeland score remains the number of outgoing edges  ties not giving any point   the result still holds  Whether it holds for other variants is an open question      Top Cycle Proposition     For the Top Cycle rule  with six candidates  every candidacy game has an NE  and with seven candidates  there are candidacy games without an NE  Both results have been obtained by computer search  Technically  we first pruned the domain to reduce the number of majority graphs to consider  Then  for each remaining graph  we computed the co winners given by the top cycle rule  and we launched a feasibility problem asking the computer to build an instance without equilibrium  This is similar in spirit to the ones used in previous sections  but including additional decision variables for the tie breaking ordering  and making sure that winners are indeed among the co winners   For the six candidate case  the infeasibility of the program tells us that an equilibrium always exists  but we could not extract any readable proof from the result    The counterexample for seven candidates is given in Appendix A         Note however that this does not imply that the set of all candidates is an NE  For instance  let X    a  b  c  d   and consider the majority graph a  b  a  c  b  c  b  d  d  a  d  c  with the tie breaking priority relation a  b  c  d  The Copeland winner is a  by tie breaking   We only need to specify that b   d  a on top of self supported preferences  X is not an NE  because it is a profitable deviation for b to leave  Note that this positive result holds as well for the Banks rule  since Top Cycle and Banks do coincide up to six candidates            More negative results by induction For all rules that satisfy IBC and for which we have already found a counter example for m  we know that counterexamples exist for any number of candidates  As we previously noted  veto is an example of a rule not satisfying IBC  but an adapted version of Lemma   can easily be designed  see Lemma   in Appendix   As a corollary of these  and of Propositions            and    we get  Corollary    There exists profiles with no NE in the following cases   For all Saari scoring rules satisfying IBC  including plurality   as well as for veto  for all m      For plurality with runoff and single transferable vote  for all m      For Borda  maximin  and the uncovered set  for all m      For TopCycle  and for all m        Strong Equilibria and Link to Control     Strong Nash Equilibria We now prove that the lack of guarantee for the existence of strong Nash equlilibria holds for almost any voting rule and any number of candidates m     Let r be a voting rule defined for a varying set of candidates Y  X  We say that r is majority extending if for any Y  X such that  Y       and if the two candidates in Y are not tied in P Y then r P Y   is the majority winner in P Y  in case of a tie  we dont need to specify the outcome   Proposition     There does not exist any majority extending and IBC rule that guarantees the existence of an SE at every profile  Proof  Let r be a majority extending and IBC rule  Consider the following   voter  k     candidate profile  k        a b c x       xk    b c a x       xk    c a b x       xk  By a repeated application of IBC  for any nonempty Y   a  b  c  and any Z   x            xk   we have r P Y Z     r P Y    We already know that r P  a b c x       xk     a  b  c   Without loss of generality  assume that r P  a b c x       xk       a  For any Z   x            xk    by IBC and majorityextension  the resulting choice function must be  abcZ   a  abZ   a  bcZ   b  acZ   c  aZ   a  bZ   b  cZ   c But then  given the candidates preferences  for any Z   x            xk   we have             abcZ is not an SE  abcZ   a  b leaves   c abZ is not an SE  abZ   a  b leaves and c joins   c acZ is not an SE  acZ   c  a leaves and b joins   b bcZ is not an SE  bcZ   b  a joins   a aZ is not an SE  aZ   a  c joins   c bZ is not an SE  bZ   b  a joins   a cZ is not an SE  cZ   c  b joins   b Z is not an SE  any of a  b or c wants to join      The result applies to most common voting rules        Relation to Control Bartholdi et al      define constructive control by deleting candidates  CCDC  and constructive control by adding candidates  CCAC   an instance of CCDC consists of a profile P over set of candidates C  a distinguished candidate c  an integer k  and we ask whether there is a subset C  of C with  C   C     k such that c is the unique winner in C    An instance of CCAC consists of a profile P over set of candidates C   C    a distinguished candidate c  and we ask whether there is a subset C  of C  such that the unique winner in C   C  is c  Destructive versions of control are defined by Hemaspaandra et al        destructive control by deleting  DCDC  is similar to CCDC  except that we ask whether there is a subset C  of C    c  with  C   C     k such that c is not the unique winner in C   C    and destructive control by adding candidates  DCAC  is similar to CCAC  except that c should not be the unique winner in C    There are also multimode versions of control       e g   CC DC AC  allows the chair to delete some candidates and to add some others  subject to some cardinality constraints   Nash equilibria and strong equilibria in strategic candidacy relate to a slightly more demanding notion of control  which we can call consenting control  and that we find an interesting notion per se  In traditional control  candidates have no preferences and no choicethe chair may add or delete them as he likes  An instance of consenting CCDC consists of an instance of CCDC plus  for each candidate in C  a preference ranking over C  and we ask whether there is a subset C  of C with  C   C     k such that c is the unique winner in C    and every candidate in C   C  prefers c to the candidate which would win if all candidates in C were running  An instance of consenting CCAC consists of an instance of CCAC plus  for each candidate in C    a ranking over C   C    and we ask whether there is a subset C  of C  such that c is the unique winner in C  C  and every candidate in C  prefers c to the candidate which would win if only the candidates in C  were running  Consenting versions of destructive control are defined similarly  here the goal is to have a different candidate from the current winner elected  Clearly  for profile P                  is an SE iff there is no consenting destructive control by removing candidates against the current winner r X   with the value of k being fixed to m  the chair has no limit on the number of candidates to be deleted  the limits come here from the fact that the candidates must consent   and                is an NE iff     A noticeable exception is veto  however  we already know that for veto  there exist profiles without NE  and therefore without SE    there is no consenting destructive control by removing candidates against the current winner r X   with the upper bound of k     on the number of candidates to be deleted  For candidate sets that are different from the set X of all candidates  as some may leave and some other may join   we have to resort to consenting destructive control by removing and adding candidates  as in       Let s be a state and Xs the set of running candidate in s  s is an SE if there is no consenting destructive control by removing and adding candidates against the current winner r Xs    without any constraint on the number of candidates to be removed or added  For an NE  this is similar  but with the bound k     on the number of candidates to be deleted or added     Conclusions We have explored further the landscape of strategic candidacy in elections by obtaining several positive results and several negative results which can be summarized on the following table  where yes  means yes under the assumption that n is odd  or more generally that pairwise ties do not occur  plurality veto pl  runoff STV Borda maximin UC TC Copeland    yes yes yes yes yes yes yes yes yes    no no no no yes yes yes yes yes      no no no no no no no yes yes    no no no no no no no no yes  An important issue for further research is a characterization of all rules for which the existence of a pure Nash equilibrium is guaranteed  at least for an odd number of voters  We know that not only it contains Copeland  as well as the rule defiend by the sophisticated winner of the successive elimination rule  these two rules do not have much in common  which suggests that such a characterization could be highly complex  Another issue is the study of the set of states that can be reached by some  e g  best response  dynamics starting from the set or all potential candidates  In some cases  even when the existence of NE is guaranteed  e g  for Copeland   we could already come up with examples such that none is reachable by a sequence of best responses  But other types of dynamics may be studied  Another issue for further research is the computational complexity of deciding whether there is an NE or SE  Finally  a recent line of research  dealing with a setting where not only candidates  but also voters  are strategic players  has been investigated by Brill and Conitzer       Acknowledgements We would like to thank Markus Brill  Edith Elkind  Michel Le Breton and Vincent Merlin for helpful discussions    
  level  with the condition that violating however many formulas at a given level is always more acceptable  Penalty logic  introduced by Pinkas         than violating only one formula at a strictly higher  as  sociates to each formula of a knowledge base  level   the price to pay if this formula is violated    e    z   Penalties may be used as a criterion for se  apparently very appealing  besides it has already been  consistent knowledge base  thus inducing a  used several times in the literature  consists in weight  A pre  ing formulas with positive numbers called  cise formalization and the main properties of penalty logic and of its associated non  since they are  additive   ties of the rejected formulas  Moreover  inviolable  or unrejectable  formulas are given an infinite penalty  The additive combination of penalties leads to an in  pecially in the infinitesimal case   terpretation in terms of  itarist   Introduction appears when  the available knowledge base   KB for short    here a set of propositional formulas  is inconsistent  Most approaches come up with the inconsistency by select ing among the consistent subsets of KB some  preferred  subsets  the selection criterion generally makes use of uncertainty considerations  sometimes by using explic itly uncertainty measures  such as W ilson ferhat and Smets         expressed qualitatively as back to Rescher       and  priorities   the idea comes        Nebel         Benferhat  Cayrol  Dubois  Lang  Prade  Lehmann          Ben  has been developed by many  authors  among them Brewka                  or more often using measures  Cayrol       and  Although these priorities are gener  ally not given a semantics in terms of uncertainty mea sures  however see       for a comparative study of the  priority based and possibilistic approaches to inconsis tency handling   their intuitive interpretation is clearly in terms of gradual uncertainty  the least prioritary formulas    i e   the  ones which are most likely to be re  jected in case of inconsistency  are clearly the ones we are the least confident in  i e   the least certain ones   cost   thus this criterion is  util  contrarily to priority based approaches which  are rather  inconsistency handling  the global penalty for rejecting  a set of formulas is the sum of the elementary penal  first part  We also show that penalty logic and Dempster Shafer theory ate related  es  The problem of  penalties   Contrarily to priorities  penalties are compensatory  monotonic inference relation are given in the     non compensatory   An alternative approach  more or less empirical but  lecting preferred consistent subsets in an in non monotonic inference relation   thus these approaches are  levels never interact   egalitarist   This additive criterion is very in  tuitive  since rejecting a formula generally causes some  additive  trouble with the experts which provided the f  B with the formulas  or some real financial cost  or  another kind of additive cost  Note that a degenerate case of penalties  all penalties being equal to     prefers  subsets of maximum cardinality  Moreover  and as we will see later  these penalties can sometimes be inter preted as the  probability of fault  of the source which provided us with the information  all sources failing in dependently   up to a logarithmic transformation  In any case  these penalties can be viewed as measuring  uncertainty  since  again  the less expensive to reject   the more uncertain the piece of information  penalty logic  Thus   expresses uncertainty in terms of costs   However a formal connection of penalties with classical theories of uncertainty has not really been made  Penalty based approaches have been already used sev eral times in the literature  first by Pinkas           from  whom we borrowed the terminology  penalty   who uses them for inconsistency handling and for mod elling symmetric neural networks behavior  and also  All aforementioned priority based approaches consist  by Eiter and Gotlob         for cost based abduction  by Sandewall         for cost based minimization of  the set  Satisfaction Problems  Moreover  penalties associated  in ranking the f  B in n priority levels  assume that   is the highest priority and n the lowest  and maximize  or  the number of formulas satisfied at each  surprises in temporal reasoning and by Freuder and Wallace        for tackling inconsistencies in Constraint   Penalty Logic and its Link with Dempster Shafer Theory  to formulas have also been used for guiding the search in randomized algorithms dedicated to the satisfiabil ity problems  such as GSAT            Lastly  there  should clearly be a link between penalties and utility theory  the latter has been recently used in AI  espe cially in decision theoretic planning   see e g         however  in this paper we do not investigate this pos sible link        Since PK is a multi set of pairs  and not a  set   it  is possible for a pair      a   to appear several times in PI    for example  PK     a       a      is not equivalent to PK      a      since using PK  it costs   to delete a   and using P K   it costs only    However  as we will see in        if a formula    appears several times in PK then we may replace all the occur rences of the formula  P by only one occurrence of  P  In this paper we revisit penalties by giving a further  formalization of Pinkas  work  we also go further in the  annotated with the sum of the penalties associated to this formula in the previous base  The new knowledge  theoretical study of penalty based inconsistency han  base obtained is equivalent to the initial base   dling and non monotonic reasoning   We briefly give  a formalization in penalty logic of an additive problem  Lastly  we establish  a  O R   link between penalties  and Dempster Shafer theory  this link is twofold  first  the penalty function  on interpretations  is equivalent  up to a log  transformation  to a contour function  i e   the plausibility function restricted to singletons   then penalty functions on formulas coincide with plausibil ity functions of an infinitesimal t ersion of Dempst er Shafer theory      based on a finite number of propositional variables  T      wi ll be writt e n       j   etc  The set of interpretations attached to     will be de noted by n  and an interpretation by w   P F      and Formulas of   P f l lj  will represent logical consequence and logical equivalence between the formulas  I     P and     respectively   will also be used between an interpretation and a formula to denote satisfiahility  The set of models of a formula  P will be denoted by M    P   the set of for mulas of     satisfied by w  i e     P I w I    P  will be denoted by  w    A classical knowledge base    is a set of formulas of      A sub theory of    is a consistent subset of    A    is a consistent subset of    T  T U    P  is inconsistent  Given  maximal sub theory T of such that  if    E       a formula      T is said  ljl consistent iff T U    j   is c o n sistent  Tis maximal lj  consistent if it is   J consistent  and V P E     T  T U             is inconsistent  w  will be the union of the set of all the strictly positive real particular  if     oo   equipped with the usual order     oo then a     oo    a    in  A penalty knowledge base PK is a finite multi set of pairs   P   a     where      E     and a   E w   a  is the penalty associated to  Pi  it represents intuitively what we s hould pay in order to get rid of  Pi  if we pay the  requested price we do not need any longer to satisfy  Pi  so the larger  a    In particular  if a    move  the p en al ti es ex    Also  in the expressions sub theory of PK  subset of PK and PK  A we will refer to the set of  is  the more important  Pi is        Cost of an interpretation  Let PK  and  l will represent taut ology and contradiction re  numbers and  Lastly  we will say that PK E  JlJc is co nsistent if the set of formulas  Pi of PK is consistent   without mentioning            a    i            n   be a penalty knowl  edge base   following      will be a propositional language  spectively   violated           Formal definitions  In the  logic comes down to classical logic  no formula can be  formulas obtained from PK by ignoring the pena lties   Penalty logic         c will be the set of all the penalty knowledge bases  Note that when the penalties are all infinite  penalty   oo then it is forbidden to re  i p  from PK   Pi is inviolable    Definition    Pinkas          The cost of an in w E Q with respect to PK   denoted by kpK w    is equal to the sum of the penalties of the for  terpretation  mulas zn PK violated by   with  the  w   corn enfion L  P E  a        Definition   A PK preferred interpretation is an in terpretation of minimal cost w r t  PK  i e  an inter pretation minimizing  kpl    As an example  let us consider the following penalty k n owledge base P K     PI  a y   b v c y      b  P      c         oo                            Here are the corresponding interpretations costs   kpr       a  b  c   kpr          a  b        c   kpK   a    b    c   kpK   a b   c   kpK   a b c   kPK   a b c    kpK     a  b c      oo kpK     a  b  c      oo                      If the interpretations are decisions to make  for exam ple if the knowledge base is made of constraints con cerning the construction of a timetable   then a min imum cost interpretation corresponds to the cheapest        Dupin de Saint Cyr  Lang  and Schiex  decision  i e   the most interesting one  The cheapest interpretation is generally not unique  Besides  if the penalties are all equal to   then a cheapest interpreta tion satisfies a maximum consistent subset of PK w  r  t  cardinality         Cost of consistency of a formula    The cost of consistency of a formula r p with respect to PK  denoted by f PK cp   is the mini mum cost with respect to PK of an interpretation sat isfying r p  KpK C O   min kpK w   Definition  wi  P   with the convention min  kPK w       oo   Example   f PK   a   b  KpK  a  c  KPK    a      oo  KpK  f   of a formula r p  is the minimal price to pay in order to make PK consistent with cp  For example  in order to make PK  consistent with a    c  the least expensive way is to remove r o    oo and J PK   T     J PK l    minwEn kPK w    All proofs can be found  in French  in Dupin de Saint Cyr  Lang and Schiex        and in Dupin de Saint Cyr          KPK l      oo is easy to understand  because it is impossible to have PK consistent with      Let us note that   pK   T  is the cost of any PK preferred inter pretation  it is thus the mini mum cost to make PK consistent  Property    KpK T   is inconsistent       oo      cp   E  PK a       oo   This quantity KPK T  is important  because it mea sures the strength of the inconsistency of PK  i e   how expensive it will be to recover the consistency   If the penalties are all equal to  oo then KpK T  can only take two values    if and only if PK is consistent  and  oo if and only if PK is inconsistent  Example  J PK   T       the only minimum cost in terpretation is  a  b    c   To make PK  consistent  the least expensive solution is to take off  or to ignore  the formula  f   Property      pK T          Property    Vi p   E   f    cp f             KpJ   P       Vr o    E      KPK IO         max I pK  P   Kpr            KpK     V       mi n KP K   cp      KpK         f pK l         pK IO     f pK T   Note that  up to its interval of definition and its or dering convention w r t  Proposition          oo         instead of          S      pK is actually a possibil ity measure  Note also that Spohn s ordinal condi tional functions x  verify property      e  x   A U B    min x  A   x  B         Cost of a sub theory  Definition    Pinkas       J  The cost CPK  A  of a sub theory A of PK  is the sum of the penalties of the formulas of PK that are not in A     f        EPK A For instance  considering the knowledge base PK   given A     i pl i p   P   and A     r o  i p    we have CPK   Al    a      and CpK   A           a     oo  Definition     VA  B  PK   B   PK A  B is preferred to A  ifJCPK B  S CPK A    VA  B  PK   B  h A if and only if B   PK A and not A   PK B  Definition    Pinkas          A  PK ferred sub theory relatively to PK  is  a  pre   or   PK preferred  if and only if A is consistent and    B  PK   such that B is consistent and B  f K A   Note that there may be several preferred sub theories  in the previous example    cp    P    p   is the only one    PK  preferred sub theory   Property     VPK  E  fflc   If J pK T    f  oo  then any   PK  preferred sub theory is a maximal sub theory of PK w  r t  inclusion        PK is consistent   Indeed  if KpK T      then there is no need to delete any formula in order to make PK consistent  therefore PK is consistent  and conversely    KPK       Property              The cost  Property  This property is the monotonicity of K with respect to classical entailment     Let us notice that when KPK T     oo  every sub theory of PK has an infinite cost  therefore every sub theory of PK is   PK preferred  but ob viously every sub theory is not necessarily maxi mal w r t  inclusion  Besides  if PK is consistent  then I PK T       and then the only  pK preferred sub theory of PK is PK itself  its Zost is      Example  continued   A     r ol  f    P   is a   PK  preferred sub theory and it is maximal w r t  inclusion         Penalty Logic and its Link with Dempster Shafer Theory  But  although  cp  cp  cp   is a maximalsub t heory of PK   w r t  inclusion   it is not    PK  preferred  be cause its cost is infinite    If we add the formula   cps       a  a       oo   to  PK   Besides  we define a pre ordering relation   c as follows  Definition    then the subset of infinite cost formulas is inconsistent  therefore every sub theory has an infi ni t e cost  and a  every sub theory is  preferred  PK  interpretation cost of the sub  theory of PK composed of all the formulas satisfying  w   As  PK   an example   PK n      A is a maximal sub theory of PK Vw f  A  kpK w    CPK A   Corollary      KPK  P  is equal to the of a    consistent sub theory of PK   Corollary  of a formula  minim  m cost  cp wit h respect to the  base PK is the cost of a cp consist ent  sub theory of      min CrK A    A  PI  A     conHtent  Therefore  the cost  PK     rK preferred      VA  PK   Corollary  A  is  a       cf  corollary  Definition          PK  preferred sub theory  KPK T      with cp      Add PK  cp   CpJ  A    T      PK U     p   oo        ta b   ia   bl J  a  bl l      a       bl  Therefore  the cost to make the knowledge base consis tent with a given formula  can be computed by adding with  an  infinite penalty and then evalu  ating the cost of the new knowledge base consistency   Two  alent  Equivalence between penalty knowledge bases k n o w ledge bases are  semantically equiv if they i n d u ce the same cost function on    i e    penalty  Definition   VPK  PK  E  fie  PK c PK   PK J  PK  as                    and  follows   b                   the fol               So we have PK  c PK  and PK  c is not equivalent to PK     PI     but Pl    N B   the previous example shows th at it is impos sible to transform equivalently a penalty knowledgr  base containing several non equivalent formulas in a penalty knowledge base containing the conjunction of those formulas   But  if a knowledge base contains se  eral times the same form tla  or an eq  ivalent on e   it is possible to transform it equi alent y in a knowhdge base contain ing this formula only one time with a penalty equal to the sum of the penalties of this form ula in the prelious base  Property   VPK  PK  E  JlJc   PK              consider  c  PK       A cpiJ   E  PK  f ll    PiliPi  E  PK    The con verse is obviously false   Property    this formula  b     w     PKpreferred sub theory with respfCI to all the sub theories of PK     us  lowing        KpK rp   let  The cost func t i ons incluceu by those bases are  E     has a minimal cost U   r f  PK  a   w  is  less expensive than PK      kpK   the penalty knowledge bases defined PK    PKa   PI       a      a   a     b  w  is  E  Jic      kpK  a  Vw  PK   PK  sub theory   Property   The cost kpK w  of an w E   with respect to PK is equal to the  Corollary      c  VPK  PK   on      l K is semantically equivalent to PK           kpi       kpw   Inconsistency handling with penalty logic  Using penalties to handle inconsistency is a syntax based approach  in the sense of       which means that  the way a know ledge base be hav es is dependent on the syntax of the input  this is justified by the fact that each formula is considered as an independent piece of  information   for instance   p q      pY   q  will not be have as  p    q       p Y      q   since in the first  case we ca n re  move independently the formulas   p   p and q     p  q    p V   q  and   q       p Y      q  are the maximal sub theories   but in the second case we must rem ove or        whole fo rm ula p    q    p    q  and       p V   q  the maximal sub theories    keep the are  In order to deal with inconsistency  the basic idea de veloped with syntax ba  led approaches is to define a        Dupin de Saint Cyr  Lang  and Schiex  nonmonotonic inference relation as follows    J can be deduced nonmonotonicaly from a knowledge base iff all the maximal sub theories of this base entails  clas sically              Given  Nonmonotonic inference relation induced by a penalty knowledge base  PK  E  Definition  c      r cp   J  E           In this section  we will see that penalty logic is not only a tool for inconsistency handling but also a good way to represent  in a logical language  discrete opti mization problems  for instance issued from operation research   in which minimum cost interpretations cor respond to optimum solutions   We consider an undirected graph      v A  PK  if A is a    PI   preferred cp consistent  sub theory among all the cp consistent sub theories of PK  then AU  cp  f    J   sub graph  N B    r        L Property  In penalty logic we can represent it like this      J   s  that this vertex  f   K  J       v cp    J     if w f   to each vertex  sitional variable         E  E U  we can associate  s  a  propo  which truth assignation means  belongs to  the clique we are look  minimum of vertices  to each vertex we associate the penalty formula  s       f    K   J  cp  we are searching for a set of vertices which is max imum for cardinality  so we have to exclude the       and w is a    PI   preferred interpretation satisfying  p  then w f     J  E  every vertex is connected with every  ing for    P   r w  then A F    i e    other vertex   Finding a maximum cardinality clique is a classical N P ha rd problem in operational research   In particular  if cp   T  the definition becomes  f     K  J     if A is a    PK preferred sub theory among  PK   G  i e   a set of ver  tices U and a set of edges V connecting those vertices  A clique of G is a subset of V which define a complete  cp f    K  J  all the sub theories of  An application of penalty logic  maximum clique in a graph  the resulting set   x  y   graph  must be a clique so for each pair  of vertices that are not connected in the  G  i e    x  y   V   at least either  x  y  or  This property shows that the nonmonotonic inference  does not belong to the clique  In consequence  we  relation  can associate to each pair  f    K  belongs to the set of relations based on  preferential models in the sense of       As Pl  is a complete pre ordering  we immediately get the follow ing result   Property  Let  f    K      relation   Property  P     Given         zs  a  comparative  inference       x V   y   oo    formula  PK G        s  l  s  E   x  y    V the penalty  U U      xV    y  oo   x y     V        see      Every minimum cost inter pretation with respect to PI   G  corresponds to a max imum clique of G and conversely   Property PK E  c and cp    J  E      with  Example   For instance   let us consider the following penalty  knowledge base  e    a   l  b  l  c      d  l  e               c  The minimum cost interpretation       a f    I    al b   f   K  is    a  b  c  d    e    This example shows the ability of penalty logic to en  It can be checked that   f    I   c  b     c   a    a V c   oo       a V     d   oo    a V e   oo     b V e   oo       c V e   oo      oo       av   b        b           code discrete optimization problems  One could ar gue that  in operation research  algorithms for solv  c  c  ing classical problems  as maximum clique  minimum vertex cover      do already exist  Those algorithms are probably more efficient than the one consisting in  c  comparative inference relation      is a rational rela  tion      that also satisfies supraclassicality  if  P   Pb  K f     d  PK     a V b       a   A  a  F       then  finding the best interpretation oped in         in penalty logic  devel  However  the logical representation of this  kind of problems presents at least two advantages  the        Penalty Logic and its Link with Dempster Shafer Theory  great power of expression of logi c allows us to spec ify many complicated problems which could not easily be specified within the operational research language  and the best solution search method is independent of the given problem      Relating penalties to Dempster Shafer theory  In this section we are going to show   ties are used to induce a preference r el at ion on    first  that the cost of an interpretation kpK   rl      oo  induced by a penalty knowledge base PK c ons i s t ing of n weighted formulas corresponds ac tually to the contour function pl   rl             induced by Dempster s combination of n simple support functions  one for each formula rpi      th en   that moreover  the f unc tion Kp               f           oo  corresponds to a plausibility me as ur e in an infinitesimal version of Depmster Shafer the ory        Interpretation costs and contour functions  Let PK      rp   a    i          n  be a penalty kn owl edge base  Let us define  for each i  the body of evi dence m    m  rp         e a  m   T    e  a     By convention we take e     S ince a  E      oo   it can be seen that m  cpi  E        and m  T  E          note that lim     co m  cp        m  is called a simple support functi on       Let m   m  EfJ EBmn be the result of Dempster s combination of the m   s     without re normalization  The contour func tion pl   n        associated to m i s the restriction  M oreover     of  the      plausibility function to sin g le ton s    pl w  Now      P l     w        L  i e    m  rp   it is well known      that    IT Pl   w      II        IT  i wl          II  i wl   cp   i wl cp   e   port functions in order to rank interpretations can be  d on e a lt erna ti vely with penalty logic   This also brings to light  a relation bet ween penalties and      where each formula  Pi of the knowledge base is considered to be given by a distinct source  this source having the pro bability p  to be faulty  i e   the infor mation it provides us with is not pertinent   and all  so u rces being independent  which gives the simple sup port function m  cpi        p   and m  T    p     So if the task is only to find the most plausible interpre tation  as in      which i s the C o ns tr aint Satisfaction counterpart of        it can thus be done equivalently with penalti  Ps        Formula costs as infinitesimal plausibilities  Let us consider an infinitesimal version of Dempster  Shafer theory  where the masses involved are all in finitely close to   or to    Let c be an infinitely small quantity    Again  let PK     cp  a   i         n   Let us define  for each i  the infinitesimal body of evi dence m      i l  where P l  is the plausibility function induced by m   Moreover  Pl  w      if w f   Pi and Pl  w    e c   if w f     Pi  Thus   pl w   rl  a nd  then possibly to select one of the  or all   cheapest in t erpretat ion s   Namely  this is eno ugh for inducing the inference relation      K  for solving discrete op timization proble m s  and also for applying p en alties to constraint satisfaction problems or abduction  So  ha ndlin g penalties in su ch a purpose is nothing but performing Dempster s combination on s impl e sup port functions  Reciprocally  combining simple sup  m     r o         ca  m    T    ca   n  Pl  w    Therefore  kpK w     ln p  w    up to a logarithmic transformation  kPK is a contour function  or mo re pre cisely  the process consisting in computing kpr  corre sponds to applyin g Dempster s combination without re norma lization on simple support functions  Thi s equivalence does not extend to an equivalence between   pK and a plausibility function  see subsec ti on       but this result is already significant  since in most prac t ic al applications of penalty logic  only the contour function kpK is useful  this is the case when penal  e c    Lt  t     Pi O i  e kPK w   e Ct   Let m    m     tfl   ffi m  n be the result of Dempster s combination f the m   s      without re normalization  Let us show now that J PK has the same or d er of mag nitude  w r t  c   as ln P     where ln Pl   is the plau sibility function induced by m   Let us note that the set of focal elements of exactly    iEI Pi  It            n     m   is   More formally  this consists in considering a family of  e s tending towards    indeed what we are interested in is only the limit of the considered  We recall that ft e      f  I    when  h e  iff lim  o  I   tends to       i j                Dupin de Saint Cyr  Lang  and Schiex     Now  let us define R PK  w       I    l    n   J    p    i      w consistent   iEI  Now  II m   p    II m  T  i l  IER PK t J  iE   Pl   j    IER PK  j   iEJ  As c  is infinitely small and    a  R      therefore  PI    R    I  is always finite  f  E       ER PK t J    J  E  as  R PK   J    La  is minimum  i ll  and let r PK   J   Since  c  is     IRminpen PK       infinitely small  we have  PI    R     ERm      PK  P   r PK    j   maxiER PI         L er a  r PK   Used to handle inconsistency and perform non monotonic inferences  penalty logic has shown to have interesting properties  Using penalties for selecting preferred sub theories of an inconsistent knowledge base not only allows to distinguish between the degree of importance of various formulas  as usual priority based approaches do  but also to express possible com pensations between formulas  The non monotonic in ference relation defined satisfies the usual postulates      and is  logarithmically  related to an infinitesimal version of Dempster Shafer theory  Furthermore  the complexity of the penalty non monotonic deduction problem has been considered in     and is ranked as one of the most simple non monotonic inference problem  in     ER PK  f   i tl  Let us now define Rminpen PK       Conclusion    c miniER PK   Z v a   Now   Penalty logic may also been considered as a logical lan guage for expressing discrete optimiza tion problems  The search for a preferred interpretation has been im plemented using an A  like variant of Davis and Put nam p ro ced u re     and has been tested on small ex amples  Randomized search algorithms such as GSAT          could also be considered  but they do not guar antee that an optimum is actually reached    As shown in      solving the problem of searching a preferred interpretation allows to simply solve the non monotonic inference problem  without any restriction on the language of the formulas expressed   Any way  even the limited ll  complexity can be consid ered as excessive when faced to practical applications  A reasonable approach would then consist in defining a gradual inference relation and in trying only to solve an approximation of the resulting gradual inference problem  Among the other possible extensions of penalty logic   minJER PK tiJ   La  i l   min  BCPK  BAtjJ    c onsistent  min  BPK BAtjJ consitent  La    Pi lB  CpJ  B   one could consider associating many unrelated penal ties to a single formula  Partially ordered penalty vec tors would then replace penalties  Another possible ex tension consists in taking into account not only penal ties caused by violations but also profits associated to satisfactions  which could be expressed using negative penalties   Acknowledgements  Therefore   Note that r PK    does not depend on      and more r PK          So  up to a logarithmic transformation and a multiplicative constant  in other terms  if we consider only the orders of magnitude w  r  t  c     Kpl  is equivalent to an infinitesimal plausi bility function   We would like to express our thanks to Didier Dubois and Henri Prade for helpful suggestions concerning the link between penalties and Dempster Shafer the ory  and Michel Cayrol for having found an error in a preliminary version  This work has been partially supported by the ESPRIT BRA project DRUMS     over that     Using an ATMS for computing candidates and pre  ferred sub theories could also be considered  but the re sulting complexity is more important in the general case          Penalty Logi c and its Link w ith Dempster Shafer Theory  
 We view the syntax based approaches to de fault reasoning as a model based diagnosis problem  where each source giving a piece of information is considered as a component  It is formalized in the ATMS framework  each source corresponds to an assumption   We assume then that all sources are indepen dent and  fail  with a very small probability  This leads to a probability assignment on the set of candidates  or equivalently on the set of consistent environments  This probability assignment induces a Dempster Shafer belief function which measures the probability that a proposition can be deduced from the evi dence  This belief function can be used in several different ways to define a nonmono tonic consequence relation  We study ans compare these consequence relations  The case of prioritized knowledge bases is briefly considered      Introduction  Syntax based approaches to inconsistency handling  default reasoning and belief revision have been pro posed and studied in various forms  e g                                          and especially      and       They assume that the input  the knowledge base KB for short  consists of a set of logical sentences  possibly equipped with a priority ordering  when this knowledge base is inconsistent  these approaches select among the consistent sub bases of the KB some pre ferred sub bases  the selection criterion can be for in stance maximality w r t  set inclusion  or cardinality   A consequence relation is then generally defined by taking the intersection of the logical closures of these preferred sub bases  Each formula of the KB is con sidered as a distinct piece of information  which can   In this case the preferred sub bases coincide with the extensions of default logic      restricted to normal defaults without prerequisites   be kept in the knowledge base or rejected from it in dependently from the others  therefore  it may happen that two semantically equivalent knowledge bases may be revised differently and thus lead to different conclu sions   this is why they are called syntax based  Con sider for instance K     p  p  q  and K     pl q  p   q holds in all maximal consistent sub bases of Kt but this is not the case for K   When cardinality is used to select preferred subbases  even the number of oc currences of identical  or logically equivalent  formu las in K matters  for instance   p    p  has two consis tent sub bases of maximum cardinality    p  and     p   where as  p  p    p  has only one       p  p    Now  in model based diagnosis  the consistency based approaches  see                   proceed in a very sim ilar manner  since they look for preferred candidates  i e  minimal  w r t  a given selection criterion  sets of faulty components  such that the description of how the non faulty components work is consistent with the observations   The link between default reasoning and model based diagnosis has already been well studied  e g                           indeed  the principles be hind consistency based diagnosis and syntax based ap proaches are basically the same  there is a correspon dance between a source providing us with a piece of information and a component of a diagnosis problem  a faulty component corresponds to an erratic source which gives a piece of information which is not rele vant  by analogy  we will say that the source is faulty   When the component is working correctly  the formula describing its normal behaviour must be satisfied  and analogously  when the source is not faulty  the formula associated to it must be true in the real world  Then  a candidate in a diagnosis problem  i e  a set of compo nents consistent with the observations  corresponds to a candidate in a syntax based default reasoning prob lem  i e  a set of formulas whose deletion restores the consistency of the knowledge base   In the well known diagnosis system GDE  De Kleer and Williams      propose a probabilistic criterion to  The principle of minimizing the set of faulty compo nents w r t  a given criterion is generally called principle of parsimony  see e g                Lang  rank candidates  each component has an initial prob ability of fault  and it is assumed that components fail independently  then  the a posteriori probability that a given candidate is the real candidate is computed via Bayes  rule  conditioning by the observations  This principle of ranking candidates w  r t  their probability assumes the initial probabilities of fault are available  W hen it is not the case  De Kleer      proposes to as sume that all components have a very small probability of fault  W hat we propose to do here is to use a similar assumption for syntax based default reasoning  which induces probabilities of the consistent sub bases of the KB  which comes down to compute the probabilities of the candidates   a candidate specifies which pieces of information have to be rejected and thus which ones remain in the KB   We will check that  as expected  the consistent sub bases of maximal cardinality are the most probable ones  This probability distribution in duces then a Dempster Shafer belief function  which evaluates the probability that a formula can be proved from the available evidence  which consists only in the KB and the assumptions of independence and small probabilities of fault   The most original contribution of this paper is to propose  and to compare  many different ways to define a syntax based consequence relation from this induced belief function  An inter esting point is that we will then recover some already known syntax based consequence relations  but with a new justification  and obtain a few new ones  Lastly  we propose briefly a generalization to the case of pri oritized knowledge bases     Inconsistent knowledge bases as systems to diagnose  From now on   denotes a propositional language gen erated by a finite number of propositional variables  Formulas will be denoted by greek letters rp    etc  T denotes t autology  F  classical entailment and Cn logical closure  A knowledge base  KB  intuitively consists of a set  F of hard facts which cannot be rejected  and a multiset  of default formulas which can be rejected if necessary   To distinguish each default from the others  we create a set of assumptions A    A        An   with as many assumptions as defaults  and label each default with a distinct assumption  We define a knowledge base as in      and we then recall well known definitions of the ATMS and model based diagnosis literatures                         Definition   A knowledge base K is defined as a couple K     F  Ll  where  We recall that in a multiset several occurrences of the same element are distinguished  this obviously has to be the case for syntax based approaches where several occur rences of the same default constitute several distinct pieces of information      F is a finite set of formulas  hard facts     Ll     Pl          Pn  a finite multiset of formulas  de faults    The assumption set A  K  associated to K  denoted by A when no confusion is possible  is defined by A     A         An  where each assumption is associated to a default by the mapping    Vi  l   n    Ai    Pi Definition   A subset of A is called an environ ment  The context of an environment E is defined by Context  E    Cn  F U  rp  lA  E E       An envi ronment E is consistent iff Context E  is consis tent  It is irredundant iff no proper superset of E is consistent  It is consistent with maximal cardinality  or  for short  maxcard consistent  iff for any con sistent E  we have lEI    IE  I A nogood is an inconsistent environment  A candi date C is the complementary of a consistent environ ment  It is minimal iff no proper subset of C is a candidate  it is a candidate of minimal cardinality  or mincard for short  iff for any candidate C  we have ICI  IC I    Pursuing the analogy with model based diagnosis  the source of information corresponding to the assumption A  can be viewed as a component  rp  is then the log ical description of how the component works  If A  is true then the source is  non faulty  and the associated formula  Pi is satisfied in the real world  if A  is false then the source is  faulty  and then we don t know whether the associated formula is satisfied or not in the real world  in terms of diagnosis  it corresponds to the assumption that we don t know how behaves a faulty component   As in      a nogood  Ait         Ai   will also be written logically by   A    V     V    A  P     a candidate  Ah        AJ   will also be written logically by   Ail        I    AJ  The nogood base  denoted by   N  ts the conjunction of all irredundant nogoods  it is well known to be equivalent to the conjunction of all mini mal nogoods  and as well to the disjunction of all  irre dundant  candidates       A detailed example is given in Section   and continued in Section      Instead of this we could have equivalently generated the set of ATMS justifications A        p   Note that Context A  K   This is called an interpretation in        Obviously  a minimal  resp  mincard  candidate is the complementary of an irredundant  resp  maxcard  consis tent environment   Note that   A   corresponds to De Kleer et al  s      notation AB  c i  meaning that the component c   is faulty      Syntax based Default Reasoning as Probabilistic Model based Diagnosis           I        t n k l   From syntactical knowledge bases to     belief functions         Computing the probability of environments  As in        we make the two following basic assump  tions   I  each assumption is independent from the oth ers  This means t ha t each default piece of infor mation is kept or rejected independently from the others   which is in accordance with the spirit of syntax based approaches to default reasoning      S  all assumptions are assigned the same initial        of more than two C  s  P r  C    C   k Thus  Pr   N    pt n    O e n Hl   Now   probability  the sources have the same prior prob ability of fault   and this probability of fault is very small  Vi  Prob   A     t   with    This leads to define a probability assignment on the en vironment set  A  Thus  the prior probability of an en vironment E of cardinality k is P r E    t Tl k l  c k  which is approximated by c Tl k when c        Pr   E  is the prior probability that E is the real environment  i e  the environment corresponding to the real world  Now  this real environment must be consistent  to en sure that inconsistent environments are given a zero probability  the prior probability is conditioned on the consistent environments  see e g   E f     N    n IEI t   EI    so Pr E I   N    P r   N      li               th ere ore P if  EI   k  Pr EI  N       O t    and if lEI   k  Pr EIN    O e J       Computing the probability of the consistent environ ments is exactly the same task as computing the proba bilities of candidates in consistency based model based diagnosis                     Proposition   tells that the only consistent environments whose probability does not tend to     when t          are those of maximal car  dinality  This is in accordance with a version of the principle of parsimony consisting in considering only the candidates of minimum cardinality                   It is also interesting to compute the probability of fault  of a single source  namely  Pr   Ad  N    Proposition   As before  assume that there are e r actly p maxcard consistent environments and let k be their cardinality  Let A  be an assumption    if A  is absent of r  ronments  then    if A  appears in all maxcard consistent environ ments  and is absent of r  irredundant consistent     maxcard consistent envi         i e   environments of cardinality k     then  p max card consistent environments  let k be their cardinality  Let E be any consistent environment  Then   Proposition   Assume that there are exactly    if  E    k then Pr E   N      if  E  Proof      l    p  O t    k then Pr EI  N    O t k IEI   us prove first prove that Pr    N  Let C        Cp be the mincard candidates  they are the complementary of the max  k pen     let  O t Tl k      card consistent environments  so their cardinality is n   k  Let Cp l          Cq be the other irredundant can didates  P r    N     Pr C  v       v Cq     Pr Ct          Pr Cp   Pr Cp t           Pr Cq   Li i Pr C      Ci     E    Ii UI ifl Pr C I Ci   Cf         Now  Pr C           Pr Cp   cn k  Vi  p   l   q  Pr C     t Tl k l  and Vi  j such that i  j   j  C     C  contains at most n   k     l iterals    A  s  if it contained only n   k  since n   k is the m aximum cardinality of a con sistent environment  one of the two candidates C  and Cj would be contained in the other one  which  would contradict the fact they are irredundant   thus  Pr  C     C    e    k l  A fortiori  for all conjunctions  We recall that the notation O gk  denotes any function  f of  g  such that   IJl    c o      The proof uses the same kind of considerations as the proof of Proposition     Remark  if A  appears in all irredundant consistent environments  then r      and Proposition   gi ves  Pr   A  N      Indeed  in this case    A  never appears in   N and therefore   A  and N are inde pendent  thus Pr   A    N   Pr A           Example  F       a  and to contains the following for mulas  with their respective Ai  s   b    e    f  A   a     A    e   b       c      e    g b      c    d        e      g  A  a   c    d Aa    b v   d As As  Here are the irredundant consistent environments  their probability and their context      We omit the Cn notation in the context culumn  so for instance it should be read Context  A  A  A   Cn   a  b  c  d  e  f   etc           Lang  E    Pr E   N  l  Context E      O e      O e    b  d  e  f    b  c  d  e a  b     c  e  g a  b  c  d    e    g   At Aa A    A  Aa A     A  Asl  As  Here are the  a   Be lx  t J    a   O e   O e  t   Pr    A IN    The  maxcard consistent environments  At A  A     At A  A   and  A  A  A     are  How probabilities of candidates induce a belief function  We have seen that the knowledge base K induces a probability assignment of the environment see   A  This probability assignment of the assumption set in duces a Dempster Sha fer belieffunction  see  f                            for a study of this connection between ATMS and belief functions   As studied in detail by Smets       this belief function represents a probability of deductibility  i e  the probability that the evidence is sufficient to prove the proposition  see also              This belief function is given by    Pr E I  N  EE    P IE Context E  Proposition    Belx   t J        iff  F  I  t J  Proof if  F I   j  for any environment E   E Context E  and therefore Belx        Reciprocally  if Belx       then consider the environment    it has a non zero probability and its context is only  F  therefore  F F  t J  Let k  p be the maximum cardinality of a consistent environment E such that t J E Context E   if any  and let U fi be the number of such environ ments  as before  let k be the cardinality of a maxcard consistent environment  Then  Proposition      if k        k then  Be K     if k        u  p      p     O e    k then  Belx       O e k k       An equivalent expression of stance           B e I               Belg I J         The proof comes immediately from Proposition     Pr   A    N    Pr   A     Pr   Aa       O e    Pr   A    N         k e    O e      c           Pr A    N    Pr A    N       O c         if there is no consistent environment E such that  j  E Conte ct E  then    is  see for in  Pr  la b e l     J  A   N  Pr    N   where label    J  is the logical expression of the set of all ir redundant consistent env ironments in which   J is provable   Example  continued   Belx  b V c        Belx b       O s   Be lx g    O s   Belx g    O e     Belx   f           Inducing consequence relations  We have seen that  given a knowledge base K  and assuming small fault probabilities and independence of the sources  we obtain a belief function Belx on  induced by K  Be K    is the probability that  be deductible from K from the evidence  Now  we can use this generated belief function to define nonmonotonic consequence relations  CR  on   We are going to investigate several proposals of CRs  many of which will appear to be well known  We define the CRs in the syntax as Pinkas and Loui       namely K f     means that the formula is inferred from the knowledge base  K     As in      we define a scenario of K     F    as a consistent subset S of  F U containing  F  note that Cn S  is the context of a consistent environment   A scenario is said irredundant  resp  maxcard  iff it is maximal w r t  set inclusion  resp  cardinality   Definition    K h  iff Belx    Proposition    S of K  S f  t J              o    K f   t  j  iff for any maxcard scenario  The proof comes easily from the fact that only max card consistent environments have a probability which does not tend to    This kind of CR is known as a strong CR  More precisely  f     has been studied in a more general setting  and with priorities  in      and        This result gives thus a n ew interpretation of this well known inference relation    Note that  in spite of the syntax K f      J  f    is actu ally a unary CRs  a binary CR induced by K would be f    K where rp f   K   J means that with respect to the background knowledge represented by K  if we assume rp then we infer nonmonotonically   J  and the unary case is recovered when rp   T   For the sake of simplicity  in this paper we define only the unary restrictions of the CRs  however this restric tion is not essential  indeed  syntax based CRs generally satisfy tp f   K   J iff f   Add K        J  where Add K rp      F U  p   t     see          As shown in      and      the binary and prioritized version a f     is a rational inference relation which is fur thermore well adapted to the handling of default rules    Syntax based Default Reasoning as Probabilistic Model based Diagnosis    such that       Proposition   K r     J iff there is a maxcard sce nario S such that S f        A sufficient condition for K f      to hold is when the number of maxcard s ce n ari os entail ing     is greater than the number of maxcard scenarios ent ailin g      J  However this condition is n ot necessary  the exact characterization is more complex   Again  the proof comes from the fact that the consis tent environments with a non infinitely small belief are the maxcard ones  This CR is the weak   existential  counterpart of f       Proposition    Let u k     J  be the number of sce narios of K of cardinality k entailing   Let diff   I J        Max k  u k           u k    J    Then K f        J iff u diff l J      J          u diff  I J       J        J    Definition   K  BelK l J               o  a  r      J iff        K f   a   J iff a and BelK     J    c o     Definition a         s t  BelK l J   Proposition   K f       J iff K f               and K J v         o       J   The proof comes straightforwardly from Propositions   and    This kind of CR  called argumentative in      is intermediate between weak and strong CRs   Definition   K f       J iff BelK     J      Proposition   K f       J iff there is a scenario S of K such that S f    J  or equivalently  iff there JS an irredundant scenario S of K such that S f     J  The proof comes from the fact that all consistent en vironments have a non zero probability  This well known weak CR corresponds to the provability in at least one extension of a normal default theory without prerequisites     Definition   K BelK I         f       J iff BelK     J        and  Proposition   K r      J iff there is a scenario of K  entailing    J and if there is no scenario of K entailing    rjJ  This result is a corollary of Propositi on      This CR is  another argumentative CR   Definition   K  f   s     iff BelK          K f      rjJ iff    J is provable in the ma jority  more than one half  of the maxcard scenarios of K   The proof comes directly from the fact that all max card consistent environments have all the same proba b ility   namely l  and that the non maxcard ones have  infinitely  been called  p  small probability  This kind of  majority  CR has  CR in        Definition   K f      rjJ iff BelK  IfJ    BelK  I J        The corresponding strong CR provability in all exten sions   which is more interesting and which has received many improvements in the literature  seems to have no     nice characterization in our framework   y  this case  let     k   be the cardinality of the maxcard consistent environments  then u k     J    u p  u k         u   p and diff  I J     rjJ    k    u   p      in  O ek   and BelK    rjJ    O ek  with BelK     J       in this case  u k k     J       u k   k     J      and diff  I J      J    k   kt    BelK rP    O c k   and BelK     J    O c k   as well  in this case  we have to develop further the expres sion of Pr EI   N  in Proposition     which would show    BelK I        k    k      or  that if among the consistent environments of cardinal ity k p   k     p   there are more entailing     than en tailing     J  but if there are exactly as many  then it depends on the number of c onsist ent environments of cardinality k p      and so on   that this CR has a lexi indeed  Prop ositi on    co uld have stated equ ivalently by   It is dear from this proof  co grap hic spirit    L  I J  L        u k        k     u  k      J   k   n     l  and then K f        J iff L    lex L     J   where  lex is the lexicographic or dering   Proposition    Let  Definition    K BeiK    p BeiK   J            O     n      l   f   s  iff BelK l J        and    Proposition    K f   a  iff k p   k   p  where k p is been defined like in Proposition    with the convention    Proposition     an  Here is a s ke t ch of the proof  there are   situations where BelK l J L   Be K     J     BelK rP    and BelK I      where u p    kl i    oo iff environment   appears  in the context of no consistent  The proof comes easily from Proposition     Definition    K r   w iff BelK  l J       Proposition    K f        J iff  F This is  a  f        cl one of P ro p osit i on   and has thus  already  been proved  This CR is very strong and it is even monotonic since it accepts only the consequences of hard facts   Proposition    Let     be the relation between CR  s  as in       defined by h    h iffVK     K h  rjJ     K      J   J  This relation between our f      s is depicted by the graph on Figure           Lang  llh  a  bvc c  b  f    d g  J        g      f    Figure    the      relation between l   i s  The proof would be long and tedious but does not present any particular difficulty  Note that the exam ple at the end of the Section gives counterexamples corresponding to almost all couples of CR s such that hi h  Pinkas and Loui      define a safe CR as a CR      such that    K       J  K J v   J or K J v   tjJ  It can be checked easily that       and l     are generally unsafe while the other ones are safe  Proposition     When K is consistent  all f     s ex cept f      collapse to classical entailment  i e  K r   tjJ iff  F UA f  t J   Proof  when K is consistent  there is only one maxcard scenario  K itself  Therefore K       if  iff K f       and a fortiori  all h below in the graph collapse to f   It remains to show it for f       which is straightforward   This list of CR s is of course not exhaustive and one could think of giving other definitions  possibly parametrized by a given a      The interest of such a list of CR s is to enable the user to use the most adapted CR to her specific problem  knowing that whichever CR she chooses  it will have an interpre tation in terms of the belief function induced by the KB and assumptions  I  and  S   While very cautious CR s such as r   and very adventurous ones such as r   or r s are often considered as too extreme in practice  the more quantitative CR s r s         and r s which is maybe a bit less quantitative  seem to be good com primises inbetween  and furthermore their DS inter pretation is appealing  Example  continued    Let      b V c V   e      g  In the following table  the sign x  resp  the sign     means that the formula is  resp  is not  entailed w r t  h There is no column for r    obviously  only a is a r   consequence of K    X X     hlhhhFrlh X X X X     X X X  X     X X X X X X     X X X  X  X X X X X        X X  X X        X  X  X     h X X X X X X X X X     Extension to the prioritized case  Many syntax based approaches to default reasoning assume that the knowledge base is partitioned into priority levels  namely K    Kt        Kn     being by convention the most prioritary level   these levels are qualitative and generally it is more acceptable to vi olate any number of formulas of a lower priority level then violate one formula of a higher priority level  A generalization of the maximum cardinality princi ple to the prioritized case is defined both in     and in       a sub base A of a prioritized knowledge base  K         Kn  is lexicographically strictly preferred to a sub base B iff there exists a i E l  n such that    j   i  lA n Sj I   IB n Sj I and lA n Sd   IB n si I  the same selection criterium has been used in diagnosis by DeKleer         Now  it is possible to character ize lexicographically preferred subtheories in terms of probabilities of fault  following De Kleer       for any piece of information in Ki we assign an initial proba bility of fault of t   to its source  with the constraint that    i and    j   i  J  i  more precisely  that j   c ma r  where fmax is an upper bound of the maximum number of formulas of a priority level   we may take for instance fmax   IKJ   Then it can be shown that the only consistent environments of K hav ing an a posteriori probability which does not tend to   when        correspond exactly to the lexicograph ically preferred subbases  which generalizes Proposi tion       and that   J is lexicographically deduced from K iff Belx  I J   t o    which generalizes Proposition         Related work and conclusion  We have strengthened the already known connections between syntax based default reasoning  model based diagnosis and ATMS  and belief functions  by building on deKleer s infinitesimal probabilities of fault  We have followed the following steps      syntax based nonmonotonic entailment is viewed as diagno sis  by considering each piece of information as the description of how a component works  and the source which provided us with it as the component      we assume that all sources have very small  and equal  initial probabilities of fault  and that they are   Syntax based Default Reasoning as Probabilistic Model based Diagnosis  independent        we compute the probabilities of each candidate  and then a belief function on the language which can be interpreted as a probability of provability       we use this belief function to define syntax based nonmonotonic consequence relations      lastly  we position these definitions in the litera ture of syntax based approaches to nonmonotonic en tailment  Our work integrates various subfields of AI and thus there are many rel ated works  more so bacause the links between these subfliels had already received a lot of attention in the literature  Many authors assign prior probabilities to assumptions or components and compute then posterior probabilities of candidates  and some of them compute a belief function                          but generally the initial probabilities are as sumed to be given by the user  De Kleer      uses the same basic assumptions as us     but he computes then posterior probabilities of candidates conditioned by a measurement  in order to find the best measurement to do next   which diverges from our step      Furthermore        definitions given in Section   still make sense in the case we start with non infinitesimal user given proba bilities of failure  but the results do not hold any longer and the characterization of these inference relations is thus much less interesting  We would like to emphasize that our contribution does not really propose a new formalism nor a new way to perform nonmonotonic reasoning  but rather puts together the  already known  links between syntax based default reasoning on one side  and ATMS  di agnosis and belief functions on the other side  and as sumes further independence of the pieces of informa tion and infinitely small probabilities of failure  Now  although the theoretical complexity of syntax based entailment relations has received recently some atten tion           up to now  the more practical algorithmic and implementation issues have been less studied in the literature of syntax based default reasoning than in the literature of ATMS and model based diagnosis  Therefore  our conclusion  and our hope  is that that syntax based default reasoning should benefit from ex isting works on the aforementioned fields  such as the characterization of tractable subclasses  e g        ex perimental results etc   it is worth noticing that the  non  trivial   i e  other than   and    belief weights we obtain when        are obtained from a completely syntactic knowledge base without explicit numbers  A related work which shares this feature is the Dempster Shafer handling of default rules of Benferhat and  Smets      they start from a set of ranked default rules  where the ranking comes either from the user or from the ranking procedure of Goldszmidt and Pearl s Sys tem Z       they associate then to each def ault of rank i the mass   Ei  with Ei    and Ei    ci  and com pute then a belief function assuming independence be  cf  cJ    tween the defaults  Note that and as well as ar bitrary products of   s  are not comparable  The com puted belief function is used to define an inference re lation  in the same way as f   I  which solves the prop erty inheritance blocking problem  The common point to their work and ours is the generation of a belief function from a knowledge base  in their approach  a ranked set of default rules   but the objective pursued is different  while they search for a consequence rela tion solving the blocking inheritance problem  we want to characterize consequence relations in terms of prob abilities of fault of the sources  Other authors have used infinitesimal probabilities in nonmonotonic rea soning  following Adams   semantics  especially Pearl       Goldszmidt et al         in these approaches the default rule a    f  is translated by Pr f  a       e   with      The main difference with our use of in finitesimal probabilities relies in their interpretation  in the latter approaches they are conditional probabil ities qualifying default rules while in ours they qualify the relevance of a piece of information   Obviously  steps     and     can be done without as suming infinitely small prior probabilities  Thus  the  Acknowledgements This work has been supported by the ESPRIT BRA Research Project  DRUMS     Def e asible Reasoning and Uncertainty Management Systems   Thanks to Salem Benferhat  Didier Dubois and Henri Prade for helpful discussions and comments on earlier versions  and to the anonymous reviewers for helpful criticisms   
 We investigate the computational complexity of testing dominance and consistency in CP nets  Previously  the complexity of dominance has been determined for restricted classes in which the dependency graph of the CP net is acyclic  However  there are preferences of interest that define cyclic dependency graphs  these are modeled with general CP nets  In our main results  we show here that both dominance and consistency for general CP nets are PSPACE complete  We then consider the concept of strong dominance  dominance equivalence and dominance incomparability  and several notions of optimality  and identify the complexity of the corresponding decision problems  The reductions used in the proofs are from STRIPS planning  and thus reinforce the earlier established connections between both areas      Introduction The problems of eliciting  representing and computing with preferences over a multi attribute domain arise in many fields such as planning  design  and group decision making  However  in a multi attribute preference domain  such computations may be nontrivial  as we show here for the CP net representation  Natural questions that arise in a preference domain are  Is this item preferred to that one   and Is this set of preferences consistent  More formally  a set of preferences is consistent if and only if no item is preferred to itself  We assume that preferences are transitive  i e   if  is preferred to   and  is preferred to   then  is preferred to   An explicit representation of a preference ordering of elements  also called outcomes  of such multi variable domains is exponentially large in the number of attributes  Therefore  AI researchers have developed languages for representing preference orderings in a succinct way  The formalism of CP nets  Boutilier  Brafman  Hoos    Poole        is among the most popular ones  A CP net c      AI Access Foundation  All rights reserved    G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON  provides a succinct representation of preference ordering on outcomes in terms of local preference statements of the form p   xi   x j   where xi   x j are values of a variable X and p is a logical condition  Informally  a preference statement p   xi   x j means that given p  xi is strictly preferred to x j ceteris paribus  that is  all other things being equal  The meaning of a CP net is given by a certain ordering relation  called dominance  on the set of outcomes  derived from such reading of preference statements  If one outcome dominates another  we say that the dominant one is preferred  Reasoning about the preference ordering  dominance relation  expressed by a CP net is far from easy  The key problems include dominance testing and consistency testing  In the first problem  given a CP net and two outcomes  and   we want to decide whether  dominates   The second problem asks whether there is a dominance cycle in the dominance ordering defined by an input CP net  that is  whether there is an outcome that dominates  is preferred to  itself  We study the computational complexity of these two problems  The results obtained prior to this work concerned only restricted classes of CP nets  all requiring that the graph of variable dependencies implied by preference statements in the CP net be acyclic  Under certain assumptions  the dominance testing problem is in NP and  under some additional assumptions  even in P  Domshlak   Brafman        Boutilier  Brafman  Domshlak  Hoos    Poole      a   We show that the complexity in the general case is PSPACE complete  and this holds even for the propositional case  by exhibiting in Section   a PSPACE hardness proof for dominance testing  We then turn to consistency testing  While acyclic CP nets are guaranteed to be consistent  this is not the case with general CP nets  Domshlak   Brafman        Brafman   Dimopoulos         In Section    we show that consistency testing is as hard as dominance testing  In the following two sections we study decision problems related to dominance and optimality in CP nets  First  we consider the complexity of deciding strict dominance  dominance equivalence and dominance incomparability of outcomes in a CP net  Then  we study the complexity of deciding the optimality of outcomes  and the existence of optimal outcomes  for several notions of optimality  To prove the hardness part of the results  we first establish the PSPACE hardness of some problems related to propositional STRIPS planning  We then show that these problems can be reduced to CP net dominance and consistency testing by exploiting connections between actions in STRIPS planning and preference statements in CP nets  The complexity results in this paper address CP nets whose dominance relation may contain cycles  Most earlier work has concentrated on the acyclic model  However  as argued earlier  for instance by Domshlak and Brafman         acyclic CP nets are not sufficiently expressive to capture human preferences on even some simple domains   Consider  for instance  a diner who has to choose either red or white wine  and either fish or meat  Given red wine  they prefer meat  and conversely  given meat they prefer red wine  On the other hand  given white wine  they prefer fish  and conversely  given fish they prefer white wine  This gives a consistent cyclic CP net  and there is no acyclic CP net giving rise to the same preferences on outcomes  So  such cyclicity of preference variables does not necessarily lead to a cyclic order on outcomes      We do not mean to say that cyclic CP nets are sufficient to capture all possible human preferences on simple domains  this is obviously not true  However  we note that every preference relation extends the preference relation induced by some CP net with possibly cyclic dependencies  Not only is this property no longer true when cyclic dependencies are precluded but  in the case of binary variables  the number of linear orders that extends some acyclic CP net is exponentially smaller than the number of all linear orders  Xia  Conitzer    Lang                T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS  We assume some familiarity with the complexity class PSPACE  We refer to Papadimitriou        for details  In particular  we later use the identities NPSPACE   PSPACE   coPSPACE  In several places  we will consider versions of decision problem  in which input instances are assumed to have some additional property  Such problems are usually formulated in the following way  Q  given R    We first note that Q  given R is not the same problem as Q and R  Let us recall the definition of a decision problem as presented by Ausiello et al          A decision problem is a pair P   hIP  YP i where IP is a set of strings  formally  a subset of    where  is a finite alphabet   The decision problem P   hIP  YP i reads as follows  given a string x  IP   decide whether x  YP   A problem hIP  YP i is in a complexity class C if the language YP   is in C  this does not depend on IP    A problem hIQ  YQ i is reducible to hIP  YP i if there is a polynomial time function F such that     for every x  IQ   F x   IP   and     for every x  IQ   x  YQ if and only if F x   YP   Thus  if P is the decision problem Q  given R  then IP is the set of all strings satisfying R  while YP is the set of all strings satisfying R  Q  For all such problems  it is granted that the input belongs to R  to solve them we do not have to check that the input string is indeed an element of R  Such problems Q  given R are widespread in the literature  However  in most cases  R is a very simple property  that can be checked in polynomial  and often linear  time  such as decide whether a graph possesses a Hamiltonian cycle  given that every vertex has a degree at most    Here  however  we will consider several problems Q  given R where R itself is not in the class P  unless the polynomial hierarchy collapses   However  as we said above  the complexity of recognizing whether a given string is in R does not matter  In other words  the complexity of Q  given R is the same  whether R can be recognized in unit time or is PSPACE complete  We will come back to this when the first such problem appears in the paper  cf  the proof of Proposition     In no case that we consider is the complexity of R greater than the complexity of Q  A part of this paper  up to Section    is an extended version of our earlier conference publication  Goldsmith  Lang  Truszczynski    Wilson         Sections   and   are entirely new      Generalized Propositional CP Nets Let V    x            xn   be a finite set of variables  For each variable x  V   we assume a finite domain Dx of values  An outcome is an n tuple  d            dn   of Dx       Dxn   In this paper  we focus on propositional variables  variables with binary domains  Let V be a finite set of propositional variables  For every x  V   we set Dx    x  x   thus  we overload the notation and write x both for the variable and for one of its values   We refer to x and x as literals  Given a literal l we write l to denote the dual literal to l  The focus on binary variables makes the presentation clearer and has no impact on our complexity results  We also note that in the case of binary domains  we often identify an outcome with the set of its values  literals   In fact  we also often identify such sets with the conjunctions of their elements  Sets  conjunctions  of literals corresponding to outcomes are consistent and complete  A conditional preference rule  sometimes  a preference rule or just a rule  over V is an expression p   l   l  where l is a literal of some atom x  V and p is a propositional formula over V that does not involve variable x     In the literature one often finds the following formulation  Q  even if R  which does not have exactly the same meaning as Q  given R  Specifically  when saying Q is NP complete  even if R  one means Q is NP complete  and Q  given R is NP complete as well         G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON  In the rest of the paper  we need to refer to two different languages  a conditional preference language where for every  binary  variable x  the conditional preference table for x needs to specify a preferred value of x for every possible assignment of its parent variables  and a more general language where the tables may be incomplete  for some values of its parents  the preferred value of x may not be specified  and or locally inconsistent  for some values of its parents  the table may both contain the information that x is preferred and the information that x is preferred   We call these languages respectively CP nets and GCP nets  for generalized CP nets   Note that GCP nets are not new  as similar structures have been discussed before  Domshlak  Rossi  Venable    Walsh         The reason why we use this terminology  CP nets and GCP nets  is twofold  First  even if the assumptions of completeness and local consistency for CP nets are sometimes relaxed  most papers on CP nets do make them  Second  we could have used CP nets and locally consistent  complete CP nets instead of GCP nets and CP nets  but we felt our notation is simpler and more transparent  Definition    Generalized CP net  A generalized CP net C  for short  a GCP net  over V is a set of conditional preference rules  For x  V we define pC   x  and pC  x   usually written just  p   x  and p  x   as follows  pC   x  is equal to the disjunction of all p such that there exists a rule p   x   x in C  pC  x  is the disjunction of all p such that there exists a rule p   x   x in C  We define the associated directed graph GC  the dependency graph  over V to consist of all pairs  y  x  of variables such that y appears in either p   x  or p  x   In our complexity results we will also need the following representation of GCP nets  a GCPnet C is said to be in conjunctive form if C only contains rules p   l   l such that p is a  possibly empty  conjunction of literals  In this case all formulas p  x   p   x  are in disjunctive normal form  that is  a disjunction of conjunctions of literals  including   the empty conjunction of literals   GCP nets determine a transitive relation on outcomes  interpreted in terms of preference  A preference rule p   l   l represents the statement given that p holds  l is preferred to l ceteris paribus  Its intended meaning is as follows  If outcome  satisfies p and l  then  is preferred to the outcome  which differs from  only in that it assigns l to variable x  In this situation we say that there is an improving flip from  to  sanctioned by the rule p   l   l  Definition   If             m is a sequence of outcomes with m    and each next outcome in the sequence is obtained from the previous one by an improving flip  then we say that             m is an improving sequence from   to m for the GCP net  and that m dominates     written    m   Finally  a GCP net is consistent if there is no outcome  which is strictly preferred to itself  that is  such that     The main objective of the paper is to establish the complexity of the following two problems concerning the notion of dominance associated with GCP nets  sometimes under restrictions on the class of input GCP nets   Definition   GCP   DOMINANCE   given a GCP net C and two outcomes  and   decide whether    in C  that is  whether  dominates  in C  GCP   CONSISTENCY   given a GCP net C  decide whether C is consistent        T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS  GCP nets extend the notion of CP nets  Boutilier et al          There are two properties of GCP nets that are essential in linking the two notions  Definition   A GCP net C over V is locally consistent if for every x  V   the formula pC  x   pC   x  is unsatisfiable  It is locally complete if for every x  V   the formula pC  x   pC   x  is a tautology  Informally  local consistency means that there is no outcome in which both x is preferred over x and x is preferred over x  Local completeness means that  for every variable x  in every outcome either x is preferred over x or x is preferred over x  Definition    Propositional CP net  A CP net over the set V of  propositional  variables is a locally consistent and locally complete GCP net over V   It is not easy to decide whether a GCP net is actually a CP net  In fact  the task is coNPcomplete  Proposition   The problem of deciding  given a GCP net C  whether C is a CP net is coNPcomplete  Proof  Deciding whether a GCP net C is a CP net consists of checking local consistency and local completeness  Each of these tasks amounts to n validity tests  one for each variable   It follows that deciding whether a GCP net is a CP net is the intersection of  n problems from coNP  Hence  it is in coNP  itself  Hardness comes from the following reduction from UNSAT  To any propositional formula  we assign the CP net C    defined by its set of variables Var   z   where z   Var    and the following tables      for any variable x    z  pC    x      pC    x          z       z      pC    pC          z      There z   pC    x      moreover  pC    x   pC   For any variable x    z  we have pC      fore  C   is locally consistent  Now  for any variable x    z  we have pC    x   pC    x         Moreover  pC    z   pC    z      Thus  C   is locally complete if and only if  is unsatisfiable  It follows that C   is a CP net if and only if  is unsatisfiable     Many works on CP nets make use of explicit conditional preference tables that list every combination of values of parent variables  variables on which x depends  exactly once  each such combination designating either x or x as preferred   Clearly  CP nets in this restricted sense can be regarded as CP nets in our sense that  for every variable x  satisfy the following condition  if y            yk are all the atoms appearing in p   x  and p  x  then every complete and consistent conjunction of literals over  y            yn   appears as a disjunct in exactly one of p   x  and p  x      There are exceptions  Some are discussed for instance by Boutilier et al       a  in Section   of their paper         G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON  Under this embedding  the concepts of dominance and consistency we introduced here for GCP nets generalize the ones considered for CP nets as defined by Boutilier et al       a   Problems CP   DOMINANCE and CP   CONSISTENCY are defined analogously to Definition    In the paper we are interested in the complexity of dominance and consistency problems for both GCPnets and CP nets  Therefore  the matter of the way in which these nets  especially CP nets  as for GCP nets there are no alternative proposals  are represented is important  Our representation of CP nets is often more compact than the one proposed by Boutilier et al       a   as the formulas p   x  and p  x  implied by the conditional preference tables can often be given equivalent  but exponentially smaller  disjunctive normal form representations  Thus  when defining a decision problem  it is critical to specify the way to represent its input instances  as the representation may affect the complexity of the problem  Unless stated otherwise  we assume that GCP nets  and thus  CP nets  are represented as a set of preference rules  as described in Definition    Therefore  the size of a GCP net is given by the total size of the formulas p  x   p   x   x  V   We now note a key property of consistent GCP nets  which we will use several times later in the paper  Proposition   If a GCP net C is consistent then it is locally consistent  Proof  If C is not locally consistent then there exists a variable x and an outcome  satisfying pC  x   pC   x   Then    can be shown by flipping x from its current value in  to the dual value and then flipping it back  since  satisfies pC  x   pC   x   and since pC  x   pC   x  does not involve any occurrences of x  both flips are allowed    Finally  we conclude this section with an example illustrating the notions discussed above  Example   Consider a GCP net C on variables V    x  y  with four rules  defined as follows  x   y   y  x   y   y  y   x   x  y   x   x  We have p   y    x  p  y    x  p   x    y and p  x    y  Therefore C is locally consistent and locally complete  and so is a CP net  There is a cycle of dominance between outcomes  x  y  x  y  x  y  x  y  x  y  and so C is inconsistent  This shows that consistency is a strictly stronger property than local consistency      Propositional STRIPS Planning In this section we derive some technical results on propositional STRIPS planning which form the basis of our complexity results in Sections   and    We establish the complexity of plan existence problems for propositional STRIPS planning under restrictions on input instances that make the problem of use in the studies of dominance and consistency in GCP nets  Let V be a finite set of variables  A state over V is a complete and consistent set of literals over V   which we often view as the conjunction of its members  A state is therefore equivalent to an outcome  defined in a CP nets context  Definition    Propositional STRIPS planning  By a propositional STRIPS instance we mean a tuple hV        ACTi  where    V is a finite set of propositional variables        T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS       is a state over V   called the initial state      is a state called the goal      ACT is a finite set of actions  where each action a  ACT is described by a consistent conjunction of literals pre a   a precondition  and a consistent conjunction of literals post a   a postcondition  or effect    An action a is executable in a state  if     pre a   The effect of a in state   denoted by eff  a     is the state  containing the same literals as  for all variables not mentioned in post a   and the literals of post a   We assume that an action can be applied to any state  but that it does not change the state if its preconditions do not hold  if      pre a   given that states are complete  this is equivalent to     pre a   then eff  a        This assumption has no influence as far as complexity results are concerned  The PROPOSITIONAL STRIPS PLAN EXISTENCE problem  or STRIPS PLAN for short  is to decide whether for a given propositional STRIPS instance hV        ACTi there is a finite sequence of actions leading from the initial state   to the final state   Each such sequence is a plan for hV        ACTi  A plan is irreducible if every one of its actions changes the state  We assume  without loss of generality  that for any action a  no literal in post a  appears also in pre a   otherwise we can omit the literal from post a  without changing the effect of the action  if post a  then becomes an empty conjunction  the action a can be omitted from ACT as it has no effect  We have the following result due to Bylander         Proposition    Bylander         STRIPS PLAN  is PSPACE complete   Typically  propositional STRIPS instances do not require that goals be states  Instead  goals are defined as consistent conjunctions of literals that do not need to be complete  In such a setting  a plan is a sequence of actions that leads from the start state to a state in which the goal holds  We restrict consideration to complete goals  This restriction has no effect on the complexity of the plan existence problem  it remains PSPACE complete under the goal completeness restriction  Lang             Acyclic STRIPS Definition    Acyclic sets of actions  A set of actions ACT  we use the same notation as in Definition    is acyclic if there is no state  such that hV      ACTi has a non empty irreducible plan  that is to say  if there are no non trivial directed cycles in the graph on states induced by ACT  We will now establish the complexity of the following problem  ACTION   SET ACYCLICITY    given a set ACT of actions  decide whether ACT is acyclic   Proposition   ACTION   SET ACYCLICITY is PSPACE complete     Note that in standard STRIPS the goal can be a partial state  This point is discussed just after Proposition       We emphasize that we allow negative literals in preconditions and goals  Some definitions of STRIPS do not allow this  This particular variant of STRIPS is sometimes called PSN  propositional STRIPS with negation  in the literature         G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON  Proof  The argument for the membership in PSPACE is standard  we nevertheless give some details  We will omit such details for further proofs of membership in PSPACE  The following nondeterministic algorithm decides that ACT has a cycle  guess             repeat guess an action a  ACT       eff  a          until        This algorithm works in nondeterministic polynomial space  because we only need to store      and     which shows that ACTION   SET ACYCLICITY is in NPSPACE  and therefore in PSPACE  since NPSPACE   PSPACE  Thus  ACTION   SET ACYCLICITY is in coPSPACE  hence in PSPACE  since coPSPACE   PSPACE  We will now show that the complement of the ACTION   SET ACYCLICITY problem is PSPACEhard by reducing the ACYCLIC STRIPS PLAN problem to it  Let PE   hV        ACTi be an instance of the ACYCLIC STRIPS PLAN problem  In particular  we have that ACT is acyclic  Let a be a new action defined by pre a     and post a        It is easy to see that ACT   a  is not acyclic if and only if there exists a plan for PE  Thus  the PSPACEhardness of the complement of the ACTION   SET ACYCLICITY problem follows from Proposition    Consequently  the ACTION   SET ACYCLICITY problem is coPSPACE hard  Since PSPACE   coPSPACE  the ACTION   SET ACYCLICITY problem is PSPACE hard  as well    Next  we consider the STRIPS planning problem restricted to instances that have acyclic sets of actions  Formally  we consider the following problem  ACYCLIC STRIPS PLAN   Given a propositional STRIPS instance hV        ACTi such that ACT is acyclic and        decide whether there is a plan for hV        ACTi  This is the first of our problems of the form Q  given R that we encounter and it illustrates well the concerns we discussed at the end of the introduction  Here  R is the set of all propositional STRIPS instances hV        ACTi such that ACT is acyclic  and Q is the set of all such instances for which there is a plan for hV        ACTi  Checking whether a given propositional STRIPS instance is actually acyclic is itself PSPACE complete  this is what Proposition   states   but this does not matter when it comes to solving ACYCLIC STRIPS PLAN  when considering an instance of ACYCLIC STRIPS PLAN   we already know that it is acyclic  and this is reflected in the reduction below   Proposition   ACYCLIC STRIPS PLAN  is PSPACE complete   Proof  The argument for the membership in PSPACE is standard  cf  the proof of Proposition     To prove PSPACE hardness  we first exhibit a polynomial time reduction F from STRIPS PLAN  Let PE   hV        ACTi be an instance of STRIPS PLAN  The idea behind the reduction is to introduce a counter  so that each time an action is executed  the counter is incremented  The counter may count up to  n   where n    V    making use of n additional variables  The counter is initialized to       T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS     Once it reaches  n    it can no longer be incremented and no action can be executed  Hence  the set of actions in the resulting instance of STRIPS PLAN is acyclic  we are guaranteed to produce an instance of R  To describe the reduction  we write V as  x            xn    We define F PE    PE   hV           ACT  i as follows   V     x            xn   z            zn    where zi are new variables we will use to implement the counter          z       zn         z       zn    for each action a  ACT  we include in ACT  n actions ai      i  n  such that    pre ai     pre a   zi  zi        zn  for i  n      post ai     post a   zi  zi        zn   and   pre an     pre a   zn  for i   n   post an     post a   zn    Furthermore  we include in ACT  n actions bi      i  n  such that    pre bi     zi  zi        zn  for i  n      post bi     zi  zi        zn   and   pre bn     zn  for i   n   post bn     zn   We will denote states over V  by pairs    k   where  is a state over V and k is an integer     k   n     We view k as a compact representation of a state over variables z            zn   assuming that the binary representation of k is d        dn  with dn being the least significant digit   k represents the state which contains zi if di     and zi   otherwise  For instance  let V    x    x    x     Then we have V     x    x    x    z    z    z     and the state x   x   x   z   z   z  is denoted by  x   x   x        We note that the effect of ai or bi on state    k  is either void  or increments the counter  eff  ai      k          eff  a     k      if ai is executable in    k     k  otherwise  eff  bi      k            k      if bi is executable in    k     k  otherwise  Next  we remark that at most one ai and at most one bi are executable in a given state    k   More precisely   if k    n     then exactly one bi is executable in    k   denote by i k  the index such that bi k  is executable in    k   this index depends only on k   We also have that ai k  is executable in    k   provided that a is executable in    if k    n     then no ai and no bi is executable in    k         G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON  Now we show that PE is acyclic  Assume  is an irreducible plan for hV          ACT  i  Let      k   If k    n     then  is empty  since any action in ACT  in any state either is nonexecutable or increments the counter  and an irreducible plan contains only actions whose effect is non void  If k    n     then no action of ACT  is executable in  and again  is empty  Thus  there exists no non empty irreducible plan for hV          ACT  i  and this holds for all    Therefore PE is acyclic  We now claim that there is a plan for PE if and only if there is a plan for PE   First  assume that there is a plan in PE  Let  be a shortest plan in PE and let m be its length  the number of actions used   We have m   n     since no state along  repeats  otherwise  shorter plans than  for PE would exist   Let                 m    be the sequence of states obtained by executing   Let a be the action used in the transition from k to k     Since k    n     because m   n    and k  m      there is exactly one i     i  n  such that the action ai applies at the state    k  over V    Replacing a with ai in  yields a plan that when started at         leads to  m   m       m   Appending that plan with appropriate actions bi to increment the counter to  n    yields a plan for PE   Conversely  if  is a plan for PE   the plan obtained from  by removing all actions of the form b j and replacing each action ai with a is a plan for PE  since ai has the same effect on V as a does  Thus  the claim follows      We emphasize that this reduction F from STRIPS PLAN to ACYCLIC STRIPS PLAN  or  equivalently  to STRIPS PLAN given ACTION   SET ACYCLICITY  works because it satisfies the following two conditions     for every instance PE of STRIPS PLAN  F PE  is an instance of ACYCLIC STRIPS PLAN  this holds because for every PE  F PE  is acyclic      for every PE of STRIPS PLAN  F PE  is a positive instance of ACYCLIC only if PE is a positive instance of STRIPS PLAN   STRIPS PLAN  if and      Mapping STRIPS Plans to Single Effect STRIPS Plans Versions of the STRIPS PLAN and ACYCLIC STRIPS PLAN problems that are important for us allow only actions with exactly one literal in their postconditions in their input propositional STRIPS instances  We call such actions single effect actions   We refer to the restricted problems as SE STRIPS PLAN and ACYCLIC SE STRIPS PLAN   respectively  To prove PSPACE hardness of both problems  we describe a mapping from STRIPS instances to single effect STRIPS instances   Consider an instance PE   hV        ACTi of the STRIPS PLAN problem  where ACT is not necessarily acyclic  For each action a  ACT we introduce a new variable xa   whose intuitive meaning is that action a is currently being executed  V We set X   aACT xa   That is  X is the conjunction of negative literals of all the additional V variables  In addition  for each a  ACT we set Xa   xa  bACT a  xb   We now define an instance PE   hV           S ACT i of the SE STRIPS PLAN problem as follows     Such actions are also called unary actions in the planning literature  We stick to the terminology single effect although it is less commonly used  simply because it is more explicit     PSPACE completeness of propositional STRIPS planning with single effect actions was proved already by Bylander         However  to deal with acyclicity we need to give a different reduction than the one used in that paper         T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS   Set of variables  V    V   xa   a  ACT    initial state         X   goal state       X   set of actions  S ACT     ai   a  ACT  i                post a         Let a be an action in ACT such that post a    l       lq   where l            lq are literals   For i              q  we define an action ai by setting  pre ai     pre a   X  li   post ai     xa   The role of ai is to enforce that Xa holds after ai is successfully applied  and in this way to enable starting the execution of a  provided that no action is currently being executed  that the ith effect of a is not already true  and that the precondition of a is true   For i   q               q  we define action ai by setting  pre ai     Xa   post ai     li   The role of ai is to make the ith effect of a true   Finally  we define a q   by setting  pre a q       Xa  l       lq   post a q       xa   Thus  a q   is designed so that X holds after a q   is successfully applied  that is  a q   closes the execution of a  thus allowing for the next action to be executed  Let  be a sequence of actions in ACT  We define S   to be the sequence of actions in S ACT  obtained by replacing each action a in  by a            a q     where q    post a    Now consider a sequence  of actions from S ACT   Remove from  every action ai such that i      post a        and replace actions of the form a  post a     by a  We denote the resulting sequence of actions from ACT by S     We note that S  S        The following properties then hold  Lemma   With the above definitions   i  if  is a plan for PE then S   is a plan for PE    ii  if  is an irreducible plan for PE then S    is an irreducible plan for PE   iii  ACT is acyclic if and only if S ACT  is acyclic  Proof   i  Let a  ACT be an action  let  be a state and let  be the state obtained from  by applying a  Let  be the V   state obtained by applying the sequence of actions ha            a q   i  where q    post a    to the state   X of PE   We will show that      X  We note that if for each i              q  state   X does not satisfy pre ai   then the sequence of actions ha            a q   i has no effect  so the state is still   X  For this to happen  either  doesnt satisfy pre a   or all of l            lq already hold in  so post a  holds in   In either case       and so      X        G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON  Suppose now that for some i              q    does satisfy pre ai    Then the first such action causes xa and hence Xa to hold  After applying actions aq             a q   l       lq holds  and so post a  holds  After applying a q   both post a  and X hold  No other variable in V has changed  so      X  as required  Applying this result iteratively implies that if  is a plan for PE then S   is a plan for PE    ai   ii  Let  be an irreducible plan for PE   so that every action in  changes the state  which implies that every action in  is performed in a state where its precondition is true  We will show that S      When         S           too  and the assertion follows  is a plan for PE  We will assume that        j  Write the first action in  as a   where a  ACT  and let  be the maximal initial subsequence of  consisting of all actions of the form ai   We must have j   post a    since X holds in    by our assumption above  action a j does apply  and X is inconsistent with the precondition of ai for each i    post a    Also  pre a j   and l j hold in   and so  in   as well  Thus    satisfies pre a   and applying a changes the state  since l j holds in   and post a     l j   Let us denote by  the state resulting from applying a to     As we noted          Let  be the state resulting after applying  to     If  is the goal state  then X holds in    If  is not the goal state then        Let bi be the action in  directly following the last action in    By the definition of    a    b  After applying a j   Xa holds  so in  either Xa holds or X holds  Thus  Xb does not hold  as a    b  Since bi changes the state  i must be in              post b     so X holds in  in this case  too  Hence the last action in  is a q     where q    post a    Since the only variables in V which can be affected by actions ai are those that appear in the literals in post a  and since the action a q   can be executed  otherwise it would not belong to    it follows that      X  Applying this reasoning repeatedly  we show that applying S    to   yields   and that each action in S    changes the state  so S    is an irreducible plan for PE  which is non empty if and only if  is non empty   iii  Suppose ACT is not acyclic  so that there exists state  and a non empty irreducible plan  for PE   hV      ACTi  Then  by  i   S   is a plan for PE   hV      X    X  S ACT  i  Because  is non empty and irreducible  it changes some state  so S   also changes some state  and hence can be reduced to a non empty irreducible plan for PE   Therefore S ACT  is not acyclic  Conversely  suppose that S ACT  is not acyclic  Then there exists a state  and a non empty irreducible plan  for hV          S ACT i  We will first prove that X holds at some state obtained during the execution of this plan    By Suppose that X holds at no such state  and let a j be the first action in   We note that        our assumption  X does not hold either before or after applying a j   Therefore q      j   q  where q    post a    Since  is irreducible  a j changes the state  Thus  l j holds in  and l j holds in the state resulting from  after applying a j   By our assumption  Xa holds before and after applying a j   Thus  the next action  if there is one  must also be of the form ai for q      i   q  Repeating this argument implies that all actions in  are of the form ai where q      i   q  Since the set of literals in post a  is consistent  l j is never reset back to l j   Thus  the state resulting from  after applying  is different from    a contradiction  Thus  X holds at some state reached during the execution of   Let us consider one such state  It can be written as   X  for some state  over V   We can cyclically permute  to generate a non empty irreducible plan  for hV      X    X  S ACT i  By part  ii   S     is a non empty       T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS  irreducible plan for hV      ACTi  Therefore ACT is not acyclic      Proposition   SE STRIPS PLAN  and ACYCLIC SE STRIPS PLAN are PSPACE complete   Proof  Again  the argument for the membership in PSPACE is standard  PSPACE hardness of ACYCLIC SE STRIPS PLAN is shown by reduction from ACYCLIC STRIPS PLAN   The same construction shows that STRIPS PLAN is reducible to SE STRIPS PLAN  and thus SE STRIPS PLAN is PSPACE complete  Let us consider an instance PE   hV        ACTi of ACYCLIC STRIPS PLAN  We define PE    hV          S ACT i  which by Lemma   iii  is an instance of the ACYCLIC SE STRIPS PLAN problem  By Lemma   i  and  ii  there exists a plan for PE if and only if there exists a plan for PE   This implies that ACYCLIC SE STRIPS PLAN is PSPACE hard        Dominance The goal of this section is to prove that the GCP   DOMINANCE problem is PSPACE complete  and that the complexity does not go down even when we restrict the class of inputs to CP nets  We use the results on propositional STRIPS planning from Section   to prove that the general GCP DOMINANCE problem is PSPACE complete  We then show that the complexity does not change if we require the input GCP net to be locally consistent and locally complete  The similarities between dominance testing in CP nets and propositional STRIPS planning were first noted by Boutilier et al          They presented a reduction  discussed later in more detail by Boutilier et al       a   from the dominance problem to the plan existence problem for a class of propositional STRIPS planning specifications consisting of unary actions  actions with single effects   We prove our results for the GCP   DOMINANCE and GCP   CONSISTENCY problems by constructing a reduction in the other direction  This reduction is much more complex than the one used by Boutilier et al          due to the fact that CP nets impose more restrictions than STRIPS planning  Firstly  STRIPS planning allows multiple effects  but GCP nets only allow flips x   x or x   x that change the value of one variable  this is why we constructed the reduction from STRIPS planning to single effect STRIPS planning in the last section  Secondly  CP nets impose two more restrictions  local consistency and local completeness  which do not have natural counterparts in the context of STRIPS planning  For all dominance and consistency problems we consider  the membership in PSPACE can be demonstrated similarly to the membership proof of Proposition    namely by considering nondeterministic polynomial space algorithms consisting of repeatedly guessing appropriate improving flips and making use of the fact that PSPACE   NPSPACE   coPSPACE  Therefore  from now on we only provide arguments for the PSPACE hardness of problems we consider      Dominance for Generalized CP Nets We will prove that the GCP   DOMINANCE problem is PSPACE complete by a reduction from the problem SE STRIPS PLAN  which we now know to be PSPACE complete        G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON        M APPING S INGLE  E FFECT STRIPS P ROBLEMS P ROBLEMS  TO  GCP N ETS D OMINANCE  Let hV        ACTi be an instance of the SE STRIPS PLAN problem  For every action a  ACT we denote by la the unique literal in the postcondition of a  that is  post a    la   We denote by pre  a  the conjunction of all literals in pre a  different from la  we recall that by a convention we adopted earlier  pre  a  does not contain la    We then define ca to be the conditional preference rule pre  a    la   la and define M ACT  to be the GCP net C    ca   a  ACT   which is in conjunctive form  A sequence of states in a plan corresponds to an improving sequence from   to   which leads to the following result  Lemma   With the above notation   i  there is a non empty irreducible plan for hV        ACTi if and only if  dominates   in M ACT    ii  ACT is acyclic if and only if M ACT  is consistent  Proof  We first note the following equivalence  Let a be an action in ACT  and let  and  be different outcomes  or  in the STRIPS setting  states   The action a applied to  yields  if and only if the rule ca sanctions an improving flip from  to   This is because a applied to  yields  if and only if  satisfies pre a  and  and  differ only on literal la   with  satisfying la and  satisfying la   This is if and only if  satisfies pre  a  and  and  differ only on literal la   with  satisfying la   and  satisfying la   This  in turn  is equivalent to say that rule ca sanctions an improving flip from  to   Proof of  i   Suppose first that there exists a non empty irreducible plan a            am for hV        ACTi  Let                 m    be the corresponding sequence of outcomes  and  for each i              m  action ai   when applied in state i    yields different state i   By the above equivalence  for each i              m  cai sanctions an improving flip from i  to i   which implies that                 m is an improving flipping sequence in M ACT   and therefore  dominates   in M ACT   Conversely  suppose that  dominates   in M ACT   so that there exists an improving flipping sequence                 m with m     and m     For each i              m  let cai be an element of M ACT  which sanctions the improving flip from i  to i   Then  by the above equivalence  action ai   when applied to state i  yields i  which is different from i     and so a            am is a non empty irreducible plan for hV        ACTi  Proof of  ii   ACT is not acyclic if and only if there exists a state  and a non empty irreducible plan for hV      ACTi  By  i  this is if and only if there exists an outcome  which dominates itself in M ACT   which is if and only if M ACT  is not consistent     Theorem   The GCP   DOMINANCE problem is PSPACE complete  Moreover  this remains so under the restrictions that the GCP net is consistent and is in conjunctive form  Proof  PSPACE hardness is shown by reduction from ACYCLIC SE STRIPS PLAN  Proposition     Let hV        ACTi be an instance of the ACYCLIC SE STRIPS PLAN problem  By Lemma   ii   M ACT  is a consistent GCP net in conjunctive form  Since        imposed in the definition of       T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS  the problem ACYCLIC SE STRIPS PLAN   there is a plan for hV        ACTi if and only if there is a non empty irreducible plan for hV        ACTi  which  by Lemma   i   is if and only if  dominates   in C    Theorem   implies the PSPACE completeness of dominance in the more general conditional preference language introduced by Wilson      b   where the conditional preference rules are written in conjunctive form      Dominance in CP Nets In this section we show that GCP   DOMINANCE remains PSPACE complete under the restriction to locally consistent and locally complete GCP nets  that is  CP nets  We refer to this restriction of GCP   DOMINANCE as CP   DOMINANCE   Consistency of a GCP net implies local consistency  Proposition     Therefore  the reduction in the proof of Theorem    from ACYCLIC SE STRIPS PLAN to GCP   DOMINANCE restricted to consistent GCP nets  is also a reduction to GCP   DOMINANCE restricted to locally consistent GCP nets  PSPACE hardness of ACYCLIC SE STRIPS PLAN  Proposition    then implies that GCP DOMINANCE restricted to locally consistent GCP nets is PSPACE hard  and  in fact  PSPACEcomplete since membership in PSPACE is easily obtained with the usual line of argumentation  We will show PSPACE hardness for CP   DOMINANCE by a reduction from GCP   DOMINANCE for consistent GCP nets        M APPING L OCALLY C ONSISTENT GCP N ETS  TO  CP N ETS  Let C be a locally consistent GCP net  Let V    x            xn   be the set of variables of C  We define   We define a GCP net C over V    which we V    V   y            yn    where  y            yn    V      will show is a CP net  To this end  for every z  V  we will define conditional preference rules q   z    z   z and q  z    z   z to be included in C by specifying formulas q   z  and q  z   First  for each variable xi  V   we set q   xi     yi and q  xi     yi   Thus  xi depends only on yi   We also note that the formulas q   xi   and q  xi   satisfy local consistency and local completeness requirements  Next  for each variable yi      i  n  we define ei    x   y          xi   yi      xi    yi           xn  yn    fi    ei  p   xi   and fi   ei  p  xi    Finally  we define q   yi     fi     fi  xi   and q  yi     fi    fi   xi    Thus  yi depends on every variable in V  but itself  We note that by the local consistency of C  formulas fi   fi      i  n  are unsatisfiable  Consequently  formulas q   yi    q  yi       i  n  are unsatisfiable  Thus  C is locally consistent        G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON  Finally  q   yi    q  yi   is equivalent to fi   xi  fi  xi   so is a tautology  Thus  C is locally complete and hence a CP net over V    Let  and  be outcomes over  x            xn   and  y            yn    respectively  By  we denote the outcome over V  obtained by concatenating n tuples  and   Conversely  every outcome for C can be written in this way  Let  be an outcome over V   We define  to be the outcome over  y            yn   obtained by replacing in  every component of the form xi with yi and every component xi with yi   Then for every i     i  n      ei   Let s be a sequence             m of outcomes over V   Define L s  to be the sequence of V  outcomes                                  m m   Further  let t be a sequence                 m of V  outcomes with      and m     Define L  t  to be the sequence obtained from t by projecting each element in t to V and iteratively removing elements in the sequence which are the same as their predecessor  until any two consecutive outcomes are different   Lemma   With the above definitions   i  if s is an improving sequence for C from  to  then L s  is an improving sequence for C from  to    ii  if t is an improving sequence from  to  then L  t  is an improving sequence from  to    iii  C is consistent if and only if C is consistent  Proof  Let e   ni    xi  yi    The definitions have been arranged so that the GCP net C and the CP net C have the following properties   a  If e does not hold in an outcome  over V    then every improving flip applicable to  changes the value of some variable xi or yi so that xi  yi holds after the flip  Indeed  let us assume that there is an improving flip from  to some outcome  over V    If the flip concerns a variable xi   then xi  yi holds in   Consequently  xi  yi holds in    Thus  let us assume that the flip concerns a variable yi   If ei holds in  then  since e does not  xi  yi holds in   Thus  xi  yi holds in    If ei does not hold in  then neither fi  nor fi does  Thus  if xi  xi   respectively  holds in   yi  yi   respectively  holds in    Since the flip concerns yi   it follows that xi  yi holds in     b  No improving flip from  changes any variable xi   Indeed  for any variable xi   since e holds in   xi  yi holds in   too  Thus  no improving flip changes xi    c  There is an improving flip in C that changes variable yi in an outcome  if and only if there is an improving flip for the GCP net C from outcome  that changes variable xi   After applying the improving flip  changing variable yi   to   there is exactly one improving flip possible  It changes xi and results in an outcome   where  is the outcome over V resulting from applying to  the improving flip changing the variable xi   To prove  c   let us first assume that yi holds in  and observe that in such case xi holds in   too  It follows that q   yi   holds in  if and only if p   xi   holds in   Consequently  changing yi in  is an improving flip in C if and only if changing xi in  is an improving flip in C  The argument in the case when yi holds in  is analogous  but involves q  yi   and p  xi     Thus  the first part of  c  follows  V        T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS  Let  be the outcome obtained by applying an improving flip to xi in   It follows that the improving flip changing the value of yi in  results in the outcome   In this outcome  by  a   an improving flip must concern x j or y j such that x j  y j holds after the flip  Since for every j    i  x j  y j holds in   the only improving flips in  concern either xi or yi   By the local consistency of C   yi cannot be flipped right back  Clearly  changing xi is an improving flip that can be applied to   By our discussion  it is the only improving flip applicable in  and it results in the outcome   This proves the second part of  c   Proof of  i   The assertion follows by iterative application of  c   Proof of  ii   Suppose that t is an improving sequence                 m of V   outcomes with      and m     Since e holds in      b  implies that the first flip changes some variable yi   and  c  implies that the second flip changes variable xi to make xi  yi hold again  Hence   can be written as   By  c  there is an improving flip in C from outcome  changing variable xi   that is  leading from  to   Iterating this process shows that L  t  is an improving sequence from  to   Proof of  iii   Suppose that C is inconsistent  Then there exists some outcome  and an improving sequence s in C from  to   By  i   L s  is an improving sequence from  to   proving that C is inconsistent  Conversely  suppose that C is inconsistent  so there exists an improving sequence t for C from some outcome to itself  By  a   any improving flip applied to an outcome in which e does not hold increases  by one  the number of i such that xi  yi holds  This implies that e must hold in some outcome in t  because t is not acyclic  Write this outcome as   We can cyclically permute t to form an improving sequence t  from  to itself  Part  ii  then implies that L  t    is an improving flipping sequence for C from  to itself  showing that C is inconsistent     Theorem   CP   DOMINANCE is PSPACE complete  This holds even if we restrict the CP nets to being consistent  Proof  We use a reduction from PSPACE hardness of the GCP   DOMINANCE problem when the GCP nets are restricted to being consistent  Theorem     Let C be a consistent  and hence locally consistent  GCP net over V   and let  and  be outcomes over V   Consider the CP net C over variables V  constructed above  Lemma   i  and  ii  imply that  dominates  in C if and only if  dominates  in C   Moreover  C is consistent by Lemma   iii   Consequently  the hardness part of the assertion follows    Note that PSPACE hardness obviously remains if we require input outcomes to be different  because the reduction for Theorem   uses a pair of different outcomes  Notice the huge complexity gap with the problem of deciding whether there exists a nondominated outcome  which is only NP complete  Domshlak et al                    Consistency of GCP Nets In this section we show that the from Sections   and     GCP   CONSISTENCY       problem is PSPACE complete  using results   G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON  Theorem   GCP   CONSISTENCY is PSPACE complete  This holds even under the restriction to GCP nets in conjunctive form  Proof  PSPACE hardness is shown by reduction from ACTION   SET ACYCLICITY  We apply function S from Section     followed by M from Section      This maps instances of ACTION   SET ACYCLICITY to instances of GCP   CONSISTENCY in conjunctive form  By Lemma   iii  and Lemma    ii   an instance of ACTION   SET ACYCLICITY is acyclic if and only if the corresponding instance of GCP   CONSISTENCY is consistent  proving the result    We now show that consistency testing remains PSPACE complete for CP nets  GCP nets that are both locally consistent and locally complete   Theorem    CP   CONSISTENCY  is PSPACE complete   Proof  We use a reduction from GCP   CONSISTENCY under the restriction that the GCP net is in conjunctive form  Let C be a GCP net in conjunctive form  We define a CP net C as follows  Because C is in conjunctive form  local consistency can be decided in polynomial time  as it amounts to checking the consistency of a conjunction of conjunctions of literals  If C is not locally consistent we set C to be a predetermined inconsistent but locally consistent CP net  such as in the example in Section    Otherwise  C is locally consistent and for C we take the CP net we constructed in Section      The mapping from locally consistent GCP nets to CP nets  described in Section      preserves consistency  Lemma    iii    Since local inconsistency implies inconsistency  Proposition     we have that the GCP net C is consistent if and only if the CP net C is consistent  Thus  PSPACE hardness of the CP   CONSISTENCY problem follows from Theorem          Additional Problems Related to Dominance in GCP Nets Having proved our main results on consistency of and dominance in GCP nets  we move on to additional questions concerning the dominance relation  Before we state them  we introduce more terminology  Let  and  be outcomes in a GCP net C  We say that  and  are dominance equivalent in C  written  C   if      or  C  and  C   Next   and  are dominance incomparable in C if       C  and C   Finally   strictly dominates  if  C  and  C   Definition   We define the following decision problems  SELF   DOMINANCE   given a GCP net C and an outcome   decide whether  C   that is  whether  dominates itself in C  STRICT DOMINANCE   given a GCP net C and outcomes  and   decide whether  strictly dominates  in C  DOMINANCE EQUIVALENCE   given a GCP net C and outcomes  and   decide whether  and  are dominance equivalent in C  DOMINANCE INCOMPARABILITY   given a GCP net C and outcomes  and   decide whether  and  are dominance incomparable in C        T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS  When establishing the complexity of these problems  we will use polynomial time reductions from the problem GCP   DOMINANCE  Let H be a GCP net with the set of variables V    x            xn    and let  be an outcome  We define a GCP net G      H    with the set of variables W   V   y  by setting the conditions for flips on variables xi   i              n  and y as follows     if xi      p  G  xi     pH  xi    y  p G  xi     pH  xi    y    if xi      p  G  xi     pH  xi    y  p G  xi     pH  xi    y    p  G  y        p G  y      The mapping   can be computed in polynomial time  Moreover  one can check that if H is a locally consistent GCP net     H    is also locally consistent  Finally  if H is a CP net     H    is a CP net  as well  For every V  outcome   we let       y and      y  We note that every W  outcome is of the form   or    To explain the structure of the GCP net G  we point out that there is an improving flip in G from   into   if and only if there is an improving flip in H from  to   thus  G restricted to outcomes of the form   forms a copy of the GCP net H   Moreover  there is an improving flip in G from  into  if and only if  agrees with  on exactly one more variable xi than  does  Finally  an improving flip moves between outcomes of different type if and only if it transforms  to     or   to  for some       We now formalize some useful properties of the GCP net G      H     We use the notation introduced above  Lemma   For every V  outcome    G   and  if         G    in other words    dominates every other W  outcome   Proof  Consider any V  outcome       Then   y C   y since  given y  changing a literal to the form it has in  is an improving flip  By the definition  we also have   y C   y and   y G   y  as        It follows that  G   and   G  G     Thus  the assertion follows     Lemma   For arbitrary V  outcome  different from   the following statements are equivalent      H        G          G           G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON  Proof  By Lemma      G     Thus  the conditions     and     are equivalent           Clearly  recall our discussion about the structure of G   if there is an improving flip from  to  in H  then there is an improving flip from   to   in G  Thus  if there is an improving sequence in H from  to   there is an improving sequence in G from   to              Let us assume   G     and let us consider an improving sequence of minimum length from   to     By the minimality  no internal element in such a sequence is     Thus  no internal element equals  either  as the only improving flip from  leads to      Since an improving flip from  to   requires that      all outcomes in the sequence are of the form     By dropping y from each outcome in this sequence  we get an improving flipping sequence from  to  in H  Thus   H     Lemma   Let H be consistent and let  and  be different V  outcomes  Then    G   if and only if  H   Proof  Suppose there exists an improving sequence from   to itself  There must be an outcome in the sequence of the form   y  otherwise  dropping y in every outcome yields an improving sequence from  to  in H  contradicting the consistency of H   To perform an improving flip from y to y we need  to hold  which implies that   appears in the sequence  Thus    G     By Lemma     H   Conversely  let us assume that  H   Again by Lemma      G     By Lemma      G     Thus    G       The next construction is similar  Let H be a GCP net on variables V    x            xn    and let  be an outcome  We define a GCP net F      H    as follows  As before  we set W   V   y  to be the set of variables of F  We define the conditions for flips on variables xi   i              n  and y as follows       p  G  xi     pH  xi    y     p G  xi     pH  xi    y     p  G  y        p G  y      Informally  outcomes of the form   form in F a copy of H  There are no improving flips between outcomes of the form    There is an improving flip from   to  and  for every       from  to     In particular  if F is consistent then    H    is consistent  The mapping   can be computed in polynomial time and we also have the following property  Lemma   Let  be a V  outcome different from   Then the following conditions are equivalent      H      strictly dominates  in F     and  are not dominance incomparable in F        T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS  Proof  If there exists an improving sequence from  to  then the first improving flip in the sequence changes  to     Moreover  there is an improving flip from   to  if and only if      Thus   F  if and only if  H   Since  F  all three conditions are equivalent     Proposition   The following problems are PSPACE complete  SELF   DOMINANCE  STRICT INANCE   DOMINANCE EQUIVALENCE   and DOMINANCE INCOMPARABILITY    DOM    Proof  For all four problems  membership is proven easily as for the problems in earlier sections  For the PSPACE hardness proofs  we use the problem CP   DOMINANCE in a version when we required that the input CP net be consistent and the two input outcomes different  The problem is PSPACE hard by Theorem    Let H be a consistent CP net on a set V of variables  and let  and  be two different V  outcomes  By Lemma     H  can be decided by deciding the problem DOMINANCE EQUIVALENCE for   and   in the GCP net    H     Thus  the PSPACE hardness of DOMINANCE EQUIVALENCE follows  Next  the equivalence of Lemma      G     H   which holds due to consistency of H  shows that the problem SELF   DOMINANCE is PSPACE hard  Finally  by Lemma     H  can be decided either by deciding the problem STRICT DOMI NANCE for outcomes  and  in    H     or by deciding the complement of the problem DOM INANCE INCOMPARABILITY for  and  in the GCP net    H     It follows that STRICT DOM INANCE and DOMINANCE INCOMPARABILITY  the latter by the fact that coPSPACE PSPACE  are PSPACE complete      Corollary   The problems SELF   DOMINANCE and DOMINANCE EQUIVALENCE are PSPACE complete under the restriction to CP nets  The problems STRICT DOMINANCE and DOMINANCE IN COMPARABILITY remain PSPACE complete under the restriction to consistent CP nets  Proof  Since in the proof of Proposition   we have that H is a CP net  the claim for the first two problems follows by our remarks that the mapping   preserves the property of being a CP net  For the last two problems  we observe that since H in the proof of Proposition   is assumed to be consistent  F      H    is consistent  too  Thus  it is also locally consistent and the mapping F to F  we used for the proof of Theorem   applies  In particular  F  is a consistent CP net and has the following properties  implied by Lemma         strictly dominates  in F if and only if  strictly dominates  in F      and  are dominance incomparable in F if and only if  and  are dominance incomparable in F    Since F  is a consistent CP net  the claim for the last two problems follows  too         For STRICT DOMINANCE  the result could have been also obtained as a simple corollary of Theorem    since in consistent GCP nets dominance is equivalent to strict dominance         G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON     Problems Concerning Optimality in GCP Nets The dominance relation C of a GCP net C determines a certain order relation  which gives rise to several notions of optimality  We will introduce them and study the complexity of corresponding decision problems  We first observe that the dominance equivalence relation is indeed an equivalence relation  reflexive  symmetric and transitive   Thus  it partitions the set of all outcomes into non empty equivalence classes  which we call dominance classes  We denote the dominance class of an outcome  in a GCP net C by   C   The relation C induces on the set of dominance classes a strict order relation  a relation that is irreflexive and transitive   Namely  we define   C Cdc   C if   C      C  equivalently    C   and  C   One can check that the definition of the relation Cdc on dominance classes is independent of the choice of representatives of the classes  Definition    Non dominated class  optimality in GCP nets  Let C be a GCP net  A dominance class   C is non dominated if it is maximal in the strict order Cdc  there is no dominance class   C such that   C Cdc   C    A dominance class is dominating if for every dominance class   C     C     C or   C Cdc   C   An outcome  is weakly non dominated if it belongs to a non dominated class  If  is weakly non dominated and is the only element in its dominance class  then  is non dominated  An outcome  is dominating if it belongs to a dominating class  An outcome  is strongly dominating if it is dominating and non dominated  Outcomes that are weakly non dominated  non dominated  dominating and strongly dominating capture some notions of optimality  In the context of CP nets  weakly non dominated and nondominated outcomes were proposed and studied before  Brafman   Dimopoulos         They were referred to as weakly and strongly optimal there  Similar notions of optimality were also studied earlier for the problem of defining winners in partial tournaments  Brandt  Fischer    Harrenstein         We will study here the complexity of problems to decide whether a given outcome is optimal and whether optimal outcomes exist  First  we note the following general properties  simple consequences of properties of finite strict orders   Lemma   Let C be a GCP net     There exist non dominated classes and so  weakly non dominated outcomes     Dominating outcomes and nondominated outcomes are weakly non dominated     A strongly dominating outcome is dominating and non dominated     The following conditions are equivalent   a  C has a unique non dominated class   b  C has a dominating outcome   c  weakly non dominated and dominating outcomes in C coincide  For consistent GCP nets only two different notions of optimality remain        T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS  Lemma   Let C be a consistent GCP net  Then     Each dominance class is a singleton  C is a strict order  and C and Cdc coincide  modulo the one to one and onto correspondence      C      If  is a weakly non dominated outcome   is non dominated  weakly non dominated and non dominated outcomes coincide     If  is a dominating outcome   is strongly dominating  strongly dominating and dominating outcomes coincide      Finally   is a unique  weakly  non dominated outcome if and only if  is strongly dominating  Next  we observe that all concepts of optimality we introduced are different  To this end  we will show GCP nets with a single non dominated class that is a singleton  with multiple non dominated classes  each being a singleton  with a single non dominated class that is not a singleton  and with multiple non dominated classes  each containing more than one element  We will also show a GCPnet with two non dominated classes  one of them a singleton and the other one consisting of several outcomes  Example   Consider the following GCP net C with two binary variables a and b   a   a   b   b This GCP net determines a strict preorder on the dominance classes  in which  ab  is the only maximal class  in fact  all dominance classes are singletons   Thus  ab is both non dominated and dominating and so  it is strongly dominating  Example   Consider the following GCP net C with two binary variables a and b b   a   a b   a   a a   b   b a   b   b This GCP net determines a strict preorder  in which  ab  and  ab  are two different non dominated classes  Thus  ab and ab are non dominated and there is no dominating outcome  Example   Consider a GCP net with variables a  b and c  defined as follows  a   b   b a   b   b b   a   a b   a   a ab   c   c        G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON  There are two dominance classes  Sc    abc  abc  abc  abc  and Sc    abc  abc  abc  abc   Every outcome in Sc strictly dominates every outcome in Sc   therefore  Sc is the unique non dominated class and every outcome in Sc is dominating  Because Sc is not a singleton  there are no nondominated outcomes  and so  no strongly dominating outcome  either   Example   Let us remove from the GCP net of Example   the preference statement ab   c   c  Then Sc and Sc are still the two dominance classes  but now every outcome is Sc is incomparable with any outcome in Sc   Thus  Sc and Sc are both non dominated  Since there are two non dominated classes  there is no dominating outcome  Since each class has more than one element  there are no non dominated outcomes  All outcomes are weakly non dominated  though  Example   Let us modify the GCP net of Example   by changing the preference statement b   a   a into bc   a   a  The dominance relation  of this GCP net satisfies the following properties   i  the four outcomes in Sc dominate each other   ii  abc  abc  abc  abc   iii  any outcome in Sc dominates abc  and  a fortiori  abc   One can check that there are five dominance classes  Sc    abc    abc    abc  and  abc   Two of them are non dominated  Sc and  abc   Since there are two nondominated classes  there is no dominating outcome  On the other hand   abc  is a non dominated outcome  a unique one   We will consider the following decision problems corresponding to the notions of optimality we introduced  Definition    For a given GCP net C  WEAKLY NON   DOMINATED OUTCOME   given an outcome   decide whether  is weakly nondominated in C NON   DOMINATED OUTCOME   given an outcome   decide whether  is non dominated in C DOMINATING OUTCOME   given an outcome   decide whether  is dominating in C STRONGLY DOMINATING OUTCOME   given an outcome   decide whether  is strongly dominating in C EXISTENCE OF A NON   DOMINATED OUTCOME   decide whether C has a non dominated outcome EXISTENCE OF A DOMINATING OUTCOME   decide whether C has a dominating outcome EXISTENCE OF A STRONGLY DOMINATING OUTCOME   decide whether C has a strongly dominating outcome  In some of the hardness proofs  we will again use the reductions   and     described in the previous section  We note the following additional useful properties of the GCP net G      H     Lemma    For arbitrary V  outcome  different from   the following statements are equivalent       G        is weakly non dominated in G      is a dominating outcome in G        T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS  Proof  Since   is dominating in G  Lemma     weakly non dominated outcomes and dominating outcomes coincide  Lemma     It follows that the conditions         are equivalent to each other     Proposition   The following problems are PSPACE complete  WEAKLY NON   DOMINATED OUTCOME and DOMINATING OUTCOME   The result holds also for the problems restricted to CP nets  Proof  The membership is easy to prove by techniques similar to those we used earlier  For the PSPACE hardness proofs  we use reductions from CP   DOMINANCE for consistent CPnets  in the version where the two input outcomes are different   Let H be a CP net  and  and  two different V  outcomes  By Lemmas   and      H  can be decided by deciding either of the problems WEAKLY NON   DOMINATED OUTCOME and DOMINATING OUTCOME for the GCPnet G      H    and the outcome     We observed earlier  that if H is a CP net  then so is G      H     Thus  the second part of the assertion follows    Next  we will consider the problem STRONGLY DOMINATING OUTCOME  We will exploit the reduction F      H     which we discussed in the previous section  We observe the following property of F  Lemma    Let H be a GCP net and F      H     Then  is strongly dominating in F if and only if  is dominating in H  Proof  Let us assume that  is dominating in H  From the definition of F  it follows that for every V  outcome         F   and  F     Since   F     is dominating in F  Since there is no improving flip leading out of     is strongly dominating  Conversely  let us assume that  is strongly dominating in F and let  be a V  outcome different from   Let us consider an improving sequence from   to    All outcomes in the sequence other than the last one     are of the form     Moreover  the outcome directly preceding  is     Dropping y from every outcome in the segment of the sequence between   and   yields an improving sequence from  to  in H    We now have the following consequence of this result  Proposition   The problem STRONGLY stricted to CP nets   DOMINATING OUTCOME  is PSPACE complete  even if re   Proof  Let H be a CP net  over the set V of variables  and  an outcome  By Lemma     the problem DOMINATING OUTCOME can be decided by deciding the problem STRONGLY DOMINATING OUTCOME for F      H    and    Thus  the PSPACE hardness of STRONGLY DOMINATING OUTCOME follows by Proposition    The membership in PSPACE is  as in other cases  standard and is omitted  Since H is a CP net  it is locally consistent and so  F is locally consistent  too  As in the proof of Corollary   we use the mapping from GCP net F to CP net F  defined in Section      By Lemma     is a strongly dominating outcome in F if and only if  dominates every outcome of the form   which is if and only if  is a strongly dominating outcome in F    since any F   outcome is dominated by an outcome of the form   using the rules q   xi     yi and q  xi     yi    Therefore       G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON  for F and  can be decided by deciding for F  and   Thus  the second part of the claim follows   STRONGLY DOMINATING OUTCOME NATING OUTCOME  STRONGLY DOMI    The problem NON   DOMINATED OUTCOME is easier  It is known to be in P for CP nets  Brafman   Dimopoulos         The result extends to GCP nets  Indeed  if H is a GCP net and  an outcome   is non dominated if and only if there is no improving flip that applies to   The latter holds if and only if for every variable x in H  if x  respectively  x  holds in   then p  x   respectively  p   x   does not hold in   Since the conditions can be checked in polynomial the claim holds and we have the following result  Proposition    The problem NON   DOMINATED  OUTCOME  for GCP nets is in P   Next  we will consider the problems concerning the existence of optimal outcomes  Let H be a GCP net on the set of variables V    x            xn    and let  and  be two different V  outcomes  For every i                 n  we define formulas i as follows  If xi    then i is the conjunction of all literals in   except that instead of xi we take xi   Similarly  if xi    then i is the conjunction of all literals in   except that instead of xi we take xi   Thus  i is the outcome that results in  when the literal in corresponding to xi is flipped into its dual  We now define a GCP net E      H      by taking W   V   y  as the set of variables of E and by defining the flipping conditions as follows       p  E  xi      pH  xi    y    y    i     pE  xi     pH  xi    y     p  E  y        p E  y      The GCP net    H      has the following properties  The outcomes of the form        y  form a copy of H  There is no improving flip for the outcome       y   Next  there is no improving flip into  from an outcome of the form    To see this  let us assume that such a flip exists and concerns a variable  say  xi   It follows that    i   By the definition of flipping conditions  an improving flip for  that involves xi is impossible  a contradiction  Thus  the only improving flip that leads to  originates in     We also have that for every outcome  other than  and    E    It follows from the fact that for every outcome  other than  and    has an improving flip  Indeed  for each such  there is a variable xi such that  i  xi is false in   and  ii  flipping the literal of xi to its dual does not lead to   that is   is not i     For even if    i for some i  then  because         there exists i    i such that  and  differ on xi   so that xi satisfies  i  and  ii    Thus  a flip on that variable is improving  As all improving flips between outcomes containing y result in one more variable xi assigned to true  thus having the same status as it has in    E  follows  Finally  we have  E   and  for every outcome  other than     E    This leads to the following property of E      H       Lemma    Let H be a GCP net and let  and  be two different outcomes  Then  H  if and only if    H      has a  strongly  dominating outcome        T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS  Proof   Only if  Based on our earlier remarks    E    Moreover  since  H   we have   E     In addition  for every  different from  and     E  E  E     Thus   is both dominating and strongly dominating  the latter follows from the fact that no improving flips lead out of      If  Let us assume that  is dominating  and so  the argument applies also when  is strongly dominating   Then there is an improving sequence from   to    Let us consider a shortest such sequence  Clearly    is the outcome just before  in that sequence  as we pointed out  no improving flip from an outcome of the form  to  is possible   Moreover  by the definition of    H      and the fact that we are considering a shortest sequence from   to    every outcome in the sequence between   and   is of the form     By dropping y from each of these outcomes  we get an improving sequence from  to      Proposition    The problem EXISTENCE OF DOMINATING OUTCOME and the problem EXISTENCE OF STRONGLY DOMINATING OUTCOME are PSPACE complete  even if restricted to CP nets  Proof  We show the hardness part only  as the membership part is straightforward  To prove hardness we notice that by Lemma     given a consistent CP net H and two outcomes  and    H  can be decided by deciding either of the problems EXISTENCE OF DOMINATING OUTCOME and EXISTENCE OF STRONGLY DOMINATING OUTCOME for    H       To prove the second part of the assertion  we note that if H is consistent  E      H      is consistent  too and so  the mapping from locally consistent GCP nets to CP nets applies  Let us denote the result of applying the mapping to E by E    Then  using the same argument as in the proof of Proposition    E has a  strongly  dominating outcome if and only if E  has a strongly dominating outcome  Thus  one can decide whether  H  in a consistent CP net H by deciding either of the problems EXISTENCE OF DOM INATING OUTCOME and EXISTENCE OF STRONGLY DOMINATING OUTCOME for E      We also note that the problem EXISTENCE standard complexity theory assumptions    OF NON   DOMINATED OUTCOME  Proposition    The problem EXISTENCE OF NON   DOMINATED  OUTCOME  is easier  under  is NP complete   Proof  We note that in the case of GCP nets in conjunctive form the problem is known to be NP hard  Domshlak et al                Thus  the problem is NP hard for GCP nets  The membership in the class NP follows from Proposition       If we restrict to consistent GCP nets  the situation simplifies  First  we recall  Lemma    that if a GCP net is consistent then weakly non dominated and non dominated outcomes coincide  and the same is true for dominating and strongly dominating outcomes  Moreover  for consistent GCP nets  non dominated outcomes exist  and so  the corresponding decision problem is trivially in P   Thus  for consistent GCP nets we will only consider problems DOMINATING OUTCOME and EXISTENCE OF DOMINATING OUTCOME   Proposition    The problems DOMINATING OUTCOME and COME restricted to consistent GCP nets are in coNP       EXISTENCE OF DOMINATING OUT    G OLDSMITH   L ANG   T RUSZCZY NSKI   W ILSON  Proof  Using Lemmas   and     is not a dominating outcome if and only if there exists an outcome      which is non dominated  Similarly  there is no dominating outcome in a consistent GCP net if and only if there are at least two non dominated outcomes  Thus  guessing non deterministically an outcome       and verifying that  is non dominated  is a non deterministic polynomial time algorithm deciding the complement of the problem DOMINATING OUTCOME  The argument for the other problem is similar    We do not know if the bounds in Proposition    are tight  that is  whether these two problems are coNP complete  We conjecture they are      Concluding Remarks We have shown that dominance and consistency testing in CP nets are both PSPACE complete  Also several related problems related to dominance and optimality in CP nets are PSPACE complete  too  The repeated use of reductions from planning problems confirms the importance of the structural similarity between STRIPS planning and reasoning with CP nets  This suggests that the welldeveloped field of planning algorithms for STRIPS representations  especially for unary operators  Brafman   Domshlak         could be useful for implementing algorithms for dominance and consistency in CP nets  Our theorems extend to CP nets with non binary domains  and to extensions and variations of CP nets  such as TCP nets  Brafman   Domshlak        Brafman  Domshlak    Shimony        that allow for explicit priority of some variables over others  and the more general language for conditional preferences  Wilson      a      b   where the conditional preference rules are written in conjunctive form  The complexity result for dominance is also relevant for the following constrained optimisation problem  given a CP net and a constraint satisfaction problem  CSP   find an optimal solution  a solution of the CSP which is not dominated by any other solution of the CSP   This is computationally complex  intuitively because a complete algorithm involves many dominance checks when the definition of dominance under constraints allows for dominance paths to go through outcomes violating the constraints  Boutilier  Brafman  Domshlak  Hoos    Poole      b    The problem of checking whether a given solution of a CSP is non dominated can be seen to be PSPACE complete by a reduction from CP dominance that uses a CSP that has exactly two solutions  Our results reinforce the need for work on finding special classes of problems where dominance and consistency can be tested efficiently  Domshlak   Brafman        Boutilier et al       a   and for incomplete methods for checking consistency and constrained optimisation  Wilson      a         Several open problems remain  We do not know the complexity of deciding whether the preference relation induced by a CP net is complete  We do not know whether dominance and consistency testing remain PSPACE complete when the number of parents in the dependency graph is bounded by a constant  We also do not know whether these two problems remain PSPACE complete for CP nets in conjunctive form  the reduction used to prove Theorems   and   yields CP nets that are not in conjunctive form   Two additional open problems are listed at the end of Section       With another possible definition  where going through outcomes violating the constraints is not allowed  Prestwich  Rossi  Venable    Walsh         dominance testing is not needed to check whether a given solution is non dominated         T HE C OMPUTATIONAL C OMPLEXITY OF D OMINANCE AND C ONSISTENCY IN CP N ETS  Acknowledgments Jerome Langs new address is  LAMSADE  Universite Paris Dauphine        Paris Cedex     France  The authors are grateful to the reviewers for their excellent comments  and to Pierre Marquis for helpful discussions  This work was supported in part by the NSF under Grants ITR          IIS         and KSEF      RDE      by the ANR Project ANR  BLAN     Preference Handling and Aggregation in Combinatorial Domains  by Science Foundation Ireland under Grants No     PI   C    and    IN I     and by Enterprise Ireland Ulysses travel grant FR           
  A key issue in the handling of temporal data is the treatment of persistence  in most approaches it consists in inferring defeasi ble conlusions by extrapolating from the ac tual knowledge of the history of the world  we propose here a gradual modelling of per sistence  following the idea that persistence is decreasing  the further we are from the last time point where a fluent is known to be true  the less certainly true the fluent is   it is based on possibility theory  which has strong relations with other well known ordering based approaches to nonmonotonic reasoning  We compare our approach with Dean and Kanazawa s probabilistic projec tion  We give a formal modelling of the decreasing persistence problem  Lastly  we show how to infer nonmonotonic conclusions using the principle of decreasing persistence     Introduction  The use of persistence in order to draw nonmonotonic conclusions has been widely studied  Most approaches select models having the minimal set of changing flu ents  Thus  in these approaches  a propositional fluent f true at a given time point will tend to remain true indefinitely  provided that no other proposition being contradictory with f is observed at a later time point  this is an extremely adventurous choice  and it may be often unrealistic  because some fluents have only a lim ited tendency to persist  for instance  given that it is raining at t   it is not reasonable to infer that it is still certainly raining one week later   Let us now consider a second typical case  where a fluent f is known to be true at time to and known to be false at a later time point it  nothing being known inbetween  for instance  it is raining at    am  and it is not raining at   pm   In this figure  there must be a time point h in  t   h   Much of this work  was done  iting Linkoping University  while this author was vis  Jerome Lang     IRIT Universite Paul Sabatier F       Toulouse Cedex France email  lang irit fr when f changes its truth value from true to false  this is known as the clipping problem   Chronological min imization  Shoham     and similar approaches prefer models where fluents change at the latest possible time point  this has been argued as being often unreason able  see  Sandewall     for a discussion  and several other approaches have been proposed which reject the latter principle  and  cautiously  do not conclude any thing about f within  t   tt   For instance  the logic for time of action proposed in  Sandewall     will con clude that the truth value of f is occluded during  t   t    Borillo   Gaume s      three valued extension of Kowalski   Sergot s event calculus will also give a cautious result  We argue that these cautious results assuming complete ignorance within the whole inter val are not always realistic  since we are not always completely ignorant of what happens at time points being very close to one of the bounds of the interval  thus  in our example it is rather sure it is still raining at       am and rather sure it is not raining at      pm   The transition model given in  Cordier   Siegel     enables to specify explicitely whether fluents tend to persist or not depending on some applications con ditions  and has thus a rich expression power  but how ever it cannot express that persistence may decrease gradually  The reason why all these approaches cannot model de creasing persistence is clearly their lack of graduality  consider again the first raining example  forward pro jection   one is likely to believe that rains is almost certainly true a short time after        and not to be lieve anything at all after a very long time  say  one week later   note that in this latter case   f should not be believed either  we are too far from a time point when the truth value off is known for assuming any thing  we are thus in a state of complete ignorance about the truth value of f  Between these two ex treme states of knowledge  there is a lot of intermedi ary states  since the further from        the less cer tain we are that it is still raining  as time goes on  the amount of ignorance increases  This principle will be called increasing ignorance about persistence  or  for the sake of brevity  decreasing persistence  al though we prefer the former formulation  indeed  what        Driankov and Lang  is gradually decreasing is not persistence of truth but persistence of our belief about truth  see  Asher     for a study of persistence of truth vs  persistence of be lief  This graduality in persistence can be expressed in a qualitative way using ordering relations or in a more quantitative way using numerical measures of uncer tainty   and also with bounded projection  see Section     After recalling the bases of possibility theory and its use in nonmonotonic reasoning  we will give a formal presentation of our approach  and lastly we will show how to use decreasing persistence in order to infer non monotonic conclusions   To our knowledge  there has been essentially one ap proach to modelling persistence in a gradual way  namely Dean and Kanazawa s probabilistic projection  Dean   Kanazawa   a b   see also  Haddawy     for a temporal probability logic for reasoning about ac tions   They distinguish between   kinds of proposi tions  namely facts  or fluents  and events  a fact is a proposition which  once true  tends to persist  i e  to remain true for some time without additional effort  events are instantaneous  and they do not persist  but they tend to change the truth value of some fluents  Note that all facts have a starting point and an ending point  possibly infinite   if a fluent is true  becomes false and then becomes true again  it must be consid ered as two different instances   tokens   of the same fact  Dean and Kanazawa propose an elaborate prob abilistic model for persistence  taking account for each fact of its natural tendency to persist  represented by a survivor function S      p holds f  t iholds f  t       probability that f survives at least for   time units   and of the probabilities of events changing the truth value of the fluent  Thus probabilistic prediction comes down to computing the probability of f being still true at t  or equivalently  the density function of the clipping point of f  i e  the time point when it becomes false      However  probabilistic prediction is not well suited to dealing with fluents which may change their value sev eral times  besides  a probabilistic modelling of persis tence does not express that we become more and more ignorant about the truth value of a formula when time goes on  Let us consider the following example  where we know that it is raining at time t   and that we do not know anything about what will happen after wards   Dean and Kanazawa s approach will conclude that the probability of  raining  at t    f is close to   iff is close to    which is intended  however  it will also conclude that if we are very far from t   raining is false  which is of course not intended  A first idea for treating this case correctly would be to model per sistence with an asymptotic probability  which is ac tually the probability a priori that it is raining  inde pendently from earlier and later observations   but it still does not express increasing ignorance  since prob ability theory is well suited to modelling chance  but can not deal correctly with ignorance  see  Dubois   Prade       possibility theory  Zadeh     is much more adapted to the representation of states of partial or complete ignorance  A last point is that Dean and Kanazawa s probabilistic projection is only done forwards  our possibilistic ap proach also deals with backwards projection problems   Background on possibilistic logic  Let L be a classical propositional language  where T and     denote tautology and contradiction  respec tively  and n be the classical set of interpretations associated with L  A possibility distribution is a map ping  r from n to          r is said to be normalized iff  w E   such that  r w       By convention   r rep resents some background knowledge about where the real world is  in particular   r  w      means that w   that nothing prevents is not possible  and  r w   w from being the real world  When  r w      r w    w is a preferred candidate to w  for being the real world  A possibility distribution leads to evaluate in duces two mappings on L  namely a possibility mea sure II tp    Supwl cp r w   which evaluates the extent to which tp is consistent with the available knowledge expressed by  r  and a necessity  or certainty  mea sure N cp    Infwl   cp     r w        II   tp   which evaluates the extent to which tp is entailed by the available knowledge  We have Vtp     J  N  p      lj     min N tp  N  lj     Note that while N cp      means that  p is certainly true  N cp      means only that cp is not certain at all Complete ignorance about  p is expressed by N   p    N    tp       Since pos sibility distributions are not required to be normal ized  it may be the case that N  l        Note that we have V p  min N cp   N   cp     N  l    Note that what is essential in possibility theory is not the pre cise value of certainty degrees  but their ordinal na ture  indeed certainty degrees can be used to rank formulas of L  Namely  it is equivalent to work with necessity measures or with  qualitative  necessity re lations  see  Dubois  Prade      defined by    N defined by V p     J   p    N  ljJ iff N  p      N  lj    meaning that  p is at least as certain as  lj      A possibilistic knowledge base  Dubois et al    a  is a finite set of necessity valued formulas K      Pi a     i      n  where ai represents a lower bound of the necessity degree N  pi  A possibility distribution  r on n satisfies K iff Vi  N    p       a   where N is the necessity measure induced by  r  Logical consequence is then defined by K F  e     iff any possibility dis tribution satisfying K satisfies  E      The fuzzy set of models of a possibilistic knowledge base has for mem bership function the least specific possibility distribu tion satisfying the constraints N   pi      a   i      n  This possibility distribution  rK is defined by  Vw E n   r K w     mini l n     a  w F   cpi    Possibilistic logic allows for partial inconsistency  occuring there is no normalized possibility distribution satisfying I   which means that K F           for some strictly positive   Possibilistic decreasing persistence      The quantity Max f   I  F    l       is called incon sistency degree of I   denoted by I ncons I     It can be shown that I ncons I     Nk l       Supwen rf  w    persistence consists in extrapolating N free  in the in terval          oo   an example of persistence function is shown on Figure     In  Dubois et al    b   possibilistic logic was extended to a timed version which handles both uncertainty and time  basically  a timed possibilistic knowledge base consists in a collection of possibilistic knowledge bases indexed by time points varying on a given time scale T  so  instead of considering possibility distributions  resp  necessity measures   we consider collections of possibility distributions   rt  t E T   resp  collections of necessity measures   Nt  t E T    From a possibilistic knowledge base K  it is possi ble to define a nonmonotonic inference relation  see  Dubois Prade        x by   p   x t J iff NK  cp      tf     Nk   cp   Note that in the particular case where  p   T  we get the following  abbreviating T I t tf  in I t tf       t J iff Nk t J    Nk l   iff Nt  tf     I ncons  I    It has been shown that   K en joys all  desirable  properties that nonmonotonic in ference relations  should  satisfy  including rational monotonicity  Dubois  Prade         Possibilistic decreasing persistence  the extrapolation problem       Informal presentation of the extrapolation problem  The general principle of decreasing persistence is  given a factual temporal knowledge base and some in formation about the persistence of some given fluent f  to derive uncertain information about f in the in tervals when the truth value off is unknown  Let us start with motivating examples  Example    unbounded forward extrapolation   let us consider the fluent free of a given parking place which may or may not be free at any time point t  Sup pose that all we know about free is that it holds up to to          and we do not anything about it af terwards   We would like to extrapolate  using some knowledge describing how our ignorance about the persistence of free increases  the following uncertain facts  the certainty  necessity  degree of free  which is   at        since free is known to be true   should be close to   when t is close to        we recall that N free  expresses to which point free is entailed by the knowledge of reference  here it is obvious that at time points close to        free is entailed  to some certainty degree close to    by both the fact that it holds at       and the general principle of decreasing persistence   then  the further t is from        the less certain we are that free is true  and there should also be a point from which on we are too far from       to be even weakly certain that free still holds  i e  from which on N free       then we are in a state of com plete ignorance about free  i e  we haveN   free      too   So  in this example the principle of decreasing       tO  Figure    unbounded forward extrapolation Example    unbounded backward extrapolation   as sume now that free is known to be true from       on  we do not know anything about it before  and we have to infer uncertain facts about the past of the flu ent  this problem is also called postdiction    This case is very similar to forward extrapolation  in a symmet ric way   and all previous remarks hold  Example    bounded extrapolation without change   now  assume that free is known to be true up to        and from       on  nothing is known about f ree during the interval                 Traditional non gradual approaches to persistence are too optimistic since they conclude by default that free holds every where in                 since nothing tells us that a change ocurred  However this is not always realistic  especially if the considered interval is long  relatively to the considered fluent   The most intuitive kind of extrapolation on                tells that the further from one of the two reference time points       and        the less certain we are that free still holds  see figure     The fact that free holds at the two extrem ities of the interval should be a confirmation that free holds in any arbitrary point of the interval  in other words  for instance  we should be at least as certain that free holds at       in this situation than in the situation of Example    In some cases  the interval length may be too long for us to be somewhat certain that the fluent does not change within the interval  for instance  consider free within                 See Figure     Nt  f   Nt  f  f  Figure    bounded extrapolation without change Example    bounded extrapolation with change   now  assume free is true up to        and false from       on  again  nothing is known during                 Traditional non gradual approaches are too cautious since they conclude that free is unknown within        Driankov and Lang                  however  a more realistic  and more in formative  extrapolation would tell that free is rather certainly true if we are very close to        the closer  the more certain  but it should nevertheless decrease faster than in Examples   and     and rather certainly false if we are very close to        again  the closer  the more certain   See Figure     base is maintained consistent  or by considering all contingent formulas as Unknown at inconsistent time points  The partial history H induced by   is the logical clo sure of     i e  the collection of all Cn  Kt   for t vary ing in T  We will denote the belief status  True  False or Unknown  of  p at to by Ht  p          tO  t   Figure    bounded extrapolation with change      Formalizing possibilistic decreasing persistence  First  it is primordial to state the distinction be tween factual knowledge and knowledge about persis tence  The first one expresses what we know about the world during the time scale of reference and en ables us only to draw certain  monotonic conclusions  for instance  it was raining from       to        and it was not raining at          while the second one expresses what we know about the general behaviour of fluents  for instance   raining tends to persist but usually no more than a couple of hours   and  together with factual knowledge  enables us to draw uncertain and defeasible conclusions         Factual knowledge  Factual knowledge consists in an generally incomplete knowledge about the the world at every time point  It will be represented in a traditional way  by reify ing time  Let T    co   co  be the time scale of reference  Let L be a propositional logical language  atomic propositions which are allowed to vary along time are called ftuents  A timed knowledge base    is a finite set of timed formulas T    p  where T is a subset of T  generally an interval  and  p a well formed formula of L  T    p expresses that  p holds for any time point t in T  The cut of   at t  is the classical knowledge base Kt     T    p E K I to E K    clearly  a formula  p is known to be true at t  iff  p E Cn Kt    where Cn denotes logical closure  and known to be false at to iff    p E Cn Kt    if  p is neither True nor False at t  then  p is said to be unknown at to  Note that there is a fourth possible status for  p at to  due to the possibility that Kt  be inconsistent  in which case  p is both True and False   note that the set   True  False  Unknown  Inconsistent   is the well known   valued lattice of  Belnap      However  for the sake of clarity  in this paper we will deliberately ignore inconsistent time points  i e  time points t such that Kt is incon sistent   either by assuming that the timed knowledge  Persistence extrapolation problems  Let f be a propositional fluent  and let H be a partial history on the time scale T  A time point t will said to be informative for f iff Ht    True or Ht f  False  The set of all informative time points off is denoted by ITP f   For practical reasons we need to require that partial histories satisfy the following property  H is said to be closed iff for any elementary fluent f  ITP  p  is a closed subset of T  i e  a  possibly infi nite  union of intervals of T which have one of these   forms   a  b   possibly a  b    a   co     co  b  or   co   co   H being a closed partial history  a time point tis said to be a reference time point for f w r t  H iff t is at the leftest or at the rightest extremity of one of the intervals constituting ITP     The com plementary of ITP f   i e  the set of all time points t when Ht     Unknown  is a  possibly infinite  union of airwise disjoint open intervals  called maximal non informative intervals off w r t  H  if ITP     f     their form is either   co  t   or  tn   co  or  t   ti l   where all t  s are reference time points forf w r t  H  it may be the case that t   t      From now on we exclude the trivial case ITP f       i e  the truth value of f is always unkwown  since it is completely uninteresting  persistence cannot apply   A persistence extrapolation problem consists in a closed history H  an elementary fluent f and a maximal non informative interval I for f w r t  H  The various examples presented informally in Section     suggest the following classification of persistence extrapolation problems        a persistence extrapolation problem  H  f  I  is an unbounded extrapolation problem iff I   tn   co   forward extrapolation   or I     co  t    back ward extrapolation   a persistence extrapolatioa problem  H  f  I  is a bounded extrapolation problem without change iff I   t   ti l  and Ht    f    Ht        a persistence extrapolation problem  H  f  I  is a bounded extrapolation problem with change iff I   t   ti l  and Ht  f   f  Ht     p           Decreasing persistence functions and decreasing persistence schemata for fluents  Having stated persistence extrapolation problems  we are now giving a general methodology for solving them    Possibilistic decreasing persistence  Informally  extrapolation based on decreasing persis tence consists in inferring by default a truth value  with some certainty degree  to a fluent at time points where its truth value is not definitely known  Of course  the way to cope with it may depend not only on the involved fluent  but on the class  backward  forward       of the extrapolatim problem and when it occurs  Let I be a maximal non informative inter val for f w r t  H  A persistence function for     I  is a mapping from I to        which associates to any t in I the necessity degree N     of f at t  Thus  persistence functions extrapolate uncertain knowledge from factual knowledge by using the general princi ple of decreasing persistence  Obviously  the prob lem is tractable only if the user can specify persis tence functions in a general way  for instance   in a forward extrapolation problem starting at to the ne cessity degree of free decreases linearly and reaches   at t         if t  is during the day and at to        if t  is during the night    This is a decreasing persis tence schema  Once applied to a given partial history  a persistence schema is  instanciated  to persistence functions  If H is a partial history and Pers denotes a set of persistence schemata for a subset of the flu ents involved in H  then Apply Pers  H  denotes the application of Pers to H  Note that Apply Pers  H  is a collection of possibilistic knowledge bases  one for each t  denoted by Apply Pers  H     In next Sec tion we investigate some of the properties that persis tence schemata should preferably satisfy in order to be in accordance with the general principle of decreasing pereistence  and we propose some examples of persis tence schemata     From qualitative to quantitative axioms for persistence schemata       is  Dl should sometimes not be required  for instance  for periodic or   usually periodic  fluents with a known period  like  sleep     j ull infinite persistence   l  ymptotic persistence       asymptotically      t  limited persistence   L         Jo      limited persistencet no persistence at all  Figure    some forward persistence functions On Figure   we have represented continuous functions satisfying D   except no persistence at al   note that any persistence function satisfying Dl and continuity is of one of the four following types shown on figure    Among other possible requirements  one could require the persistence function to be strictly decreasing on  t    oo   which rules out limited persistence func tions  or  which is weaker  strictly decreasing in the right neighbourhood of to  These requirements can be formulated in very simi lar ways for all other classes of extrapolation problems  for the sake of brevity we will omit doing it   Backward extrapolation This is very analogous to the case of forward persis tence  except that persistence is  increasing   but  of course  still decreasing with respect to the distance to the nearest reference time point   given a backward extrapolation problem  H f     oo  t    D   N  f  is non decreasing on    oo  t    Independently from the exact shape of the persistence function of a fluent f im an interval I  there are some very general properties that is may be desirable to im pose  We give a first set of very basic axioms which are completely qualitative  since they do not use the met ric nature of T and          we propose then a second set of more debatable properties  which are qualitative with respect to necessity degrees but quantitative with respect to time   Bounded extrapolation without change Let  H  f   to  t    be a bounded extrapolation prob lem without change  without loss of generality  f be ing True at both to and tl   D    t  E  to  t   such that N     is is non increasing in  to  t   and non decreasing in  h  ti   Strictness in the neighbourhoods of t  and t  would ensure that t  E  to  t     Note that the persistence function needs not to be symmetrical  Some admissi ble functions are shown on figure          When the persistence function is continuous  it is nec essarily of one of the   following types  shown on figure    depending on the minimal value of N     on  to  t    full persistence  where   t E  to  t    Nt f       elastic persistence  where Min e to t  N     E         and par tially elastic persistence  where Min e t  tt Nt          Elastic persistence should occur whenever the interval  t   tl  is short enough for the fluent to always remain somewhat certain  if the interval is too long  then we only have partially elastic persistence  and there are some time points within the interval when it cannot be guaranteed that the fluent is still somewhat cer   Basic axioms for persistence functions  These very basic axioms just ensure that persistence is well respecting the principle of increasing ignorance  Forward extrapolation Let   H f  t    oo   be a forward extrapolation prob lem  Dl  N  f  is non increasing on  t    oo  Obviously  Dl does not restrict a lot the possible per sistence functions  typical examples of functions satis fying Dl are shown in Figure    But  however basic it        Driankov and Lang  full persistence  f  f  no persistence at all  Figure    some functions for bounded extrapolation without change tain  Consider for example the fluent free  again the parking place   if it is known that free holds at       and at        nothing being about its truth value in between  it is reasonable to consider the case of elas tic persistence  for it is almost certain that the place has remained free for the whole interval   now  if it is known that free holds January  st at       and at May  st at        nothing being known about its truth value inbetween  then it is of course not reasonable to assume the same  since for time points far from both January  st       and May  st       it should be ab solutely not certain that free still holds  Bounded extrapolation with change Let  H f   to ti   be a bounded extrapolation problem with change  without loss of generality  f being True at to and False at t    If we assume we do not want to generate partially inconsistent time points  which is very reasonable   it must be always the case that min N  f   Nt   J        thus the following axiom  D    t   t   with to S t  S t  S t  such that N  f  is non increasing in  to t    N   f       in  t  t    Nt   J      in  to   t   and N      f   is non decreasing in  t  t         Semi quantitative axioms for decreasing persistence  The axioms we have given so far are very weak  in this subsection we give stronger axioms which do not use the metric properties of the certainty scale        but which use the metric properties of the temporal scale         Homogeneity  The main condition for a fluent being homogeneous is that the way it behaves with respect to decreasing per sistence depends only on the class of the extrapolation problem and the time length of the interval  but not on when the interval starts  For instance  while the fluent  ra ining  may well be considered homogeneous on a time scale of    hours  it cannot be the case for the free parking place which will more certainly remain free after some period of time  say  at    pm than at    am  So  homogeneity should not always be required  However  in many cases  even if a fluent is definitely not homogeneous on the whole time scale  it can often  be considered homogeneous on some shorter subinter vals  The exact formulation of homogeneity is however more complex and expresses monotonicity conditions with respect to interval lengths  Let us now write for mally some of the numerous homogeneity conditions  From now on  f is a homogeneous fluent over the whole time scale  Case    monotonicity for two bounded extrapolation problems without change Let H be a partial history  let  H f   t  t    and  H f  tz  t    be two bounded extrapolation problems without change  the truth value of f at the bounds of both intervals being identical  say  Tr ue    Homo  geneity tells us that the shorter the interval  the more certain of the persistence of f in the interval  For in stance  if free is homogeneous over                and is known to be true at                   and        free holding at      should be at least as certain than free holding at        and similarly  free holding at      should be at least as certain than free holding at        for rather obvious reasons  Assume without loss of generality that t   to S t   tz  and let     t  t   then Hl  Vx E       Nto x f  S Nt  x  f  and Vx E         N t  x f  S Nt  x f  As an immediate consequence  if t  t     t  t  then Vx E       Nto x f    Nt  xCf   i e  the persistence function is exactly the same within two intervals of the same length    Case    monotonicity between forward extrapolation and bounded extrapolation without change Let  H  f   to t    be a bounded extrapolation prob lem without change and  H  f  t   oo   be a forward extrapolation problem   being True at t  t  and t    Let     t   to  Then homogeneity tells that persis tence should decrease at least as fast within  t   oo  as in  to  tl    which writes H   Vx E        Nto x f      Nt  x f   Case    bounded with change  bounded with change Suppose we have two bounded extrapolation problems with change concerning the same fluent f  within the two intervals  to   t   and  tz  t    the truth value off at to and t  being the same  say  True   T hen  homo geneity tells us that the shorter the interval  the faster persistence decreases f in the interval  contrarily to what happens in the case of bounded persistence with out change where the shorter the interval  the slower persistence decreases   Let us assume without loss of generality that t   to S t   t  and let     t   to   then we get H   Vx E       Nto x  f      Nt   x   f   and Vx E        Nt  x      f   S Nt  x   f     For the sake of brevity  we omit writing monotonic ity conditions for the other cases  bounded without change  backward  bounded with change  bounded without change  bounded with change  forward     Possibilistic decreasing persistence         Other metric axioms  Among the other axioms we may require for some fiu ents  we can consider for instance forward backward symmetry  which means that the fluent behaves sym metrically with respect to forward and backward ex trapolation  Note that a lot of fiuents don t  for instance  consider the well known fluent alive of the Yale Shoooting Problem   Assuming both for ward backward symmetry and homogeneity for f im plies that backwards and forwards extrapolation func tions are symmetric of each other  that functions for bounded persistence without change are symmetric relatively to the middle of the considered interval  and a symmetry property concerning bounded persistence  A stronger possible requirement  often too strong  is symmetry with respect to negation  the truth value  true  of the fluent tends to persist exactly the same way as the truth value  false   Among other things  it implies that  for a bounded persistence with change problem  the increasing functions for f  resp  f  and the increasing function for g  resp  f  are symmetric of each other       Quantitative persistence functions  All the previous requirements do not enforce precise persistence functions  This last step  necessary for practical application  has to be done by the user  For instance  a reasonable choice for a family of persistence schemata consists in piecewise linear functions     Inferring nonmonotonic conclusions from decreasing persistence  In Section    we have seen how  from a possibilistic knowledge base  it is possible to define a nonmono tonic inference relation  So  since the application of decreasing persistence principles to a partial history gives us a possibilistic knowledge base  it is then pos sible to draw some non monotonic inferences  More formally  let H be a partial history on a time scale T  and let Pers be a set of persistence schemata for a sub set of the fluents involved in H  Let App y Pers  H  be the application of Pers to H as defined in Section    Now  for any t  let Nt be the necessity measure obtained by the application of the principle of mini mum specificity  as in Section    to Apply Pers  H t Then  for any t E T  we can define the nonmonotonic inference relation l  t as in Section    Let us now give a detailed exampl e  Example  Let us consider two machines A and B which may be either working or in failure at any time point  Let A and B be propositional fiuents  A  resp  B  being true iff A  resp  B  is working  Both machines are considered equivalent with respect to persistence  fur thermore we assume that A and B are homogeneous       on T  and the persistence functions of A and A are represented on figure    the time unit being the day         I I I I I I I                      I  tO  t      tO  t     F igure    Let us briefly comment these two persistence func tions  The asymptotic value of     in the forward per sistence function of works means that the certainty degree by default of works is      i e  it is somewhat certain that machine work  independently from persis tence considerations  The fastly decreasing persistence of works is due to the existence of repairmen  failing machines tend to be repaired in short delays   Let I  be the following timed knowledge base  machine A is known to be working from   to     machine B is known to be working from    to    and we know that at least one of the two machines is not in a failure state at time     formally  K             A          A v B            B   Now  consider the fluent A  We have successively a backward extrapolation problem on    co      and then a forward extrapolation problem on       oo    Applying the decreasing persistence schemata  we get the following certainty degrees at time     Ni  A         Ni  B        and  without needing persis tence schemata  Ni  A V B       We have also Ni  A    min Ni  AVB   Ni  B          More over we get Ni  j     min Ni  A   Ni  B   Ni  A V B          hence  the knowledge has an inconsistency degree at time     Since Ni      A              Ni  j    we have       A  similarly we have       B  but we do not have       A  or l   s B  This is due to the fact that the closest time point when B is true is closer to    than the clos est time point where A is true  Note also that at t       we have Nj  B        and N   j         so we have       B     Concluding remarks  In this paper we have shown that possibility theory is well suited for modelling gradually decreasing per sistence  mainly because it is adequate to represent ing   tates of partial or complete ignorance  More over  since necessity orderings and similar construc tions have been proved to be well suited for perform ing nonmonotonic deductions  this framework provides us with a general methodology for inferring uncertain  defeasible conclusions from a  hard facts  knowledge base and some persistence schemata describing  for each fluent  how ignorance increases with respect to        Driankov and Lang  its persistence   J M Dunn  eds           We think of pursuing our work in many directions  First of all  in this paper we considered decreasing per sistence schemata only for atomic fluents  this leads to some problems when only disjunctions of fluents are known  see  Schrag     for a study of problems cre ated by disjunction in reasoning about persistence   For instance  consider the partial history where f V g is True at t   nothing else being known  Since both fluents I and g have the Unknown status at t   we can apply persistence schemata to none of them  and since there is no persistence schema for I V g  we will get Nto f f V g       If      i e  no persistence at all for I V g  This could be avoided by applying persistence to non atomic formulas as well  however  this leads to many technical problems  because per sistence schemata of different formulas sharing fluents obviously interact  This is a topic left for further re search   Salem Benferhat  Didier Dubois  Henri Prade         Representing default rules in possibilistic logic  Proc  KR               We could also generalize our study to non propositional fluents  i e  whose domain is not True  False   which should not cause any trouble  we also think to incorporate decreasing persistence principles with non gradual approaches dealing not only with persistence but more generally with time and action  such as in  Sandewall      Another easy generalisa tion of our work would consist in starting from a timed knowledge base already pervaded with uncertainty  i e  from a possibilistic knowledge base  and to extrapolate necessity measures in a similar way  Moreover  work of Section   can be extended  in particular  it would be interesting to make a classification of fluents with re spect to how they behave w r t decreasing persistence  adding other properties such as periodicity        Then  it would be interesting to generalize the prin ciple of decreasing persistence to spatial reasoning  extrapolating the truth value of a fluent at a point  x  y  z  by considering some close points where its truth value is known   Integrating both temporal and spatial  persistence  could enable us to infer defeasible conclusions from knowledge about time  space and mo tion  Next step would be a formal logical study of such a methodology  which could use notions of distances or similarity measures between worlds as in  Ruspini      Acknowledgements  We would like to thank Patrick Doherty  Didier Dubois and Henri Prade for helpful discussions  This work has been supported by the European ESPRIT Basic Re search Action        entitled  Defeasible Reasoning and Uncertainty Management Systems  DRUMS      
GROUP ACTIVITY SELECTION PROBLEM  arXiv          v   cs GT     Jan       ANDREAS DARMANN    EDITH ELKIND    SASCHA KURZ    JEROME LANG    JOACHIM SCHAUER    AND GERHARD WOEGINGER   A BSTRACT  We consider a setting where one has to organize one or several group activities for a set of agents  Each agent will participate in at most one activity  and her preferences over activities depend on the number of participants in the activity  The goal is to assign agents to activities based on their preferences  We put forward a general model for this setting  which is a natural generalization of anonymous hedonic games  We then focus on a special case of our model  where agents preferences are binary  i e   each agent classifies all pairs of the form  activity  group size  into ones that are acceptable and ones that are not  We formulate several solution concepts for this scenario  and study them from the computational point of view  providing hardness results for the general case as well as efficient algorithms for settings where agents preferences satisfy certain natural constraints      I NTRODUCTION There are many real life situations where a group of agents is faced with a choice of multiple activities  and the members of the group have differing preferences over these activities  Sometimes it is feasible for the group to split into smaller subgroups  so that each subgroup can pursue its own activity  Consider  for instance  a workshop whose organizers would like to arrange one or more social activities for the free afternoon   The available activities include a hike  a bus trip  and a table tennis competition  As they will take place simultaneously  each attendee can select at most one activity  or choose not to participate   It is easy enough to elicit the attendees preferences over the activities  and divide the attendees into groups based on their choices  However  the situation becomes more complicated if ones preferences may depend on the number of other attendees who choose the same activity  For instance  the bus trip has a fixed transportation cost that has to be shared among its participants  which implies that  typically  an attendee i is only willing to go on the bus trip if the number of other participants of the bus trip exceeds a threshold li   Similarly  i may only be willing to play table tennis if the number of attendees who signed up for the tournament does not exceed a threshold ui   as there is only one table  the more participants  the less time each individual spends playing  Neglecting to take the number of participants of each activity into account may lead to highly undesirable outcomes  such as a bus that is shared by two persons  each of them paying a high cost  and a    participant table tennis tournament with one table  Adding constraints on the number of participants for each activity is a practical  but imperfect solution  as the agents preferences over group sizes may differ  while some attendees  say  senior faculty  may be willing to go on the bus trip with just    other participants  others  say  graduate students  cannot afford it unless the number of participants exceeds     A more fine grained approach is to elicit the agents preferences over pairs of the form  activity  group size   rather than over activities themselves  and allocate agents to    Some of the co authors of this paper had to deal with this problem when co organizing a Dagstuhl seminar       ANDREAS DARMANN    EDITH ELKIND    SASCHA KURZ    JEROME LANG    JOACHIM SCHAUER    AND GERHARD WOEGINGER   activities based on this information  In general  agents preferences can be thought of as weak orders over all such pairs  including the pair  do nothing      which we will refer to as the void activity  A simpler model  which will be the main focus of this paper  assumes that each agents classifies all pairs into ones that are acceptable to him and ones that are not  and if an agent views his current assignment as unacceptable  he prefers  and is allowed  to switch to the void activity  so the assignment is unstable unless it is acceptable to all agents   The problem of finding a good assignment of agents to activities  which we will refer to as the Group Activity Selection Problem  GASP   may be viewed as a mechanism design problem  or  more narrowly  a voting problem  or as a coalition formation problem  depending on whether we expect the agents to act strategically when reporting their preferences  Arguably  in our motivating example the agents are likely to be honest  so throughout the paper we assume that the central authority knows  or  rather  can reliably elicit  the agents true preferences  and its goal is to find an assignment of players to activities that  informally speaking  is stable and or maximizes the overall satisfaction  This model is closely related to that of anonymous hedonic games      where  just as in our setting  players have to split into groups and each player has preferences over possible group sizes  The main difference between anonymous hedonic games and our problem is that  in our setting  the agents preferences depend not only on the group size  but also on the activity that has been allocated to their group  thus  our model can be seen as a generalization of anonymous hedonic games  On the other hand  we can represent our problem as a general  i e   non anonymous  hedonic game         by creating a dummy agent for each activity and endowing it with suitable preferences  see Section     for details   However  our setting has useful structural properties that distinguish it from a generic hedonic game  for instance  it allows for succinct representation of players preferences  and  as we will see  has several natural special cases that admit efficient algorithms for finding good outcomes  In this paper  we initiate the formal study of GASP  Our goal is to put forward a model for this problem that is expressive enough to capture many real life activity selection scenarios  yet simple enough to admit efficient procedures for finding good assignments of agents to activities  We describe the basic structure of the problem  and discuss plausible constraints of the number and type of available activities and the structure of agents preferences  We show that even under a fairly simple preference model  where agents are assumed to approve or disapprove each available alternative  finding an assignment that maximizes the number of satisfied agents is computationally hard  however  we identify several natural special cases of the problem that admit efficient algorithms  We also briefly discuss the issue of stability in our setting  We do not aim to provide a complete analysis of the group activity selection problem  rather  we view our work as a first step towards understanding the algorithmic and incentive issues that arise in this setting  We hope that our paper will lead to future research on this topic  to facilitate this  throughout the paper we highlight several possible extensions of our model as well as list some problems left open by our work     F ORMAL M ODEL Definition      An instance of the Group Activity Selection Problem  GASP  is given by a set of agents N               n   a set of activities A   A  a    where A    a            ap    and a profile P   which consists of n votes  one for each agent   P    V            Vn    The vote of agent i describes his preferences over the set of alternatives X   X    a    where   GROUP ACTIVITY SELECTION PROBLEM     X    A              n   alternative  a  k   a  A   is interpreted as activity a with k participants  and a is the void activity  The vote Vi of an agent i  N is  also denoted by  i   is a weak order over X    its induced strict preference and indifference relations are denoted by i and i   respectively  We set Si     a  k   X     a  k  i a    we say that voter i approves of all alternatives in Si   and refer to the set Si as the induced approval vote of voter i  Throughout the paper we will mostly focus on a special case of our problem where no agent is indifferent between the void activity and any other alternative  i e   for any i  N we have  x  X    x i a        and each agent is indifferent between all the alternatives in Si   In other words  preferences are trichotomous  the agent partitions X into three clusters Si    a   and X    Si   a     is indifferent between two alternatives of the same cluster  prefers any  a  k  in Si to a   and a to any  a  k  in X    Si   a     we denote this special case of our problem by a GASP  It will be convenient to distinguish between activities that are unique and ones that exist in multiple copies  For instance  if there is a single tennis table and two buses  then we can organize one table tennis tournament  two bus trips  we assume that there is only one potential destination for the bus trip  so these trips are identical   and an unlimited number of hikes  again  we assume that there is only one hiking route   This distinction will be useful for the purposes of complexity analysis  for instance  some of the problems we consider are easy when we have k copies of one activity  but hard when we have k distinct activities  Formally  we say that two activities a and b are equivalent if for every agent i and every j              n  it holds that  a  j  i  b  j   We say that an activity a  A is k copyable if A contains exactly k activities that are equivalent to a  including a itself   We say that a is simple if it is   copyable  if a is k copyable for k  n  we will say that it is  copyable  note that we would never need to organize more than n copies of any activity   If some activities in A are equivalent  A can be represented more succinctly by listing one representative of each equivalence class  together with the number of available copies  However  as long as we make the reasonable assumption that each activity exists in at most n copies  this representation is at most polynomially more succinct  Our model can be enriched by specifying a set of constraints   One constraint that arises frequently in practice is a global cardinality constraint  which specifies a bound K on the number of activities to be organized  More generally  we could also consider more complex constraints on the set of activities that can be organized simultaneously  which can be encoded  e g   by a propositional formula or a set of linear inequalities  We remark that there can also be external constraints on the number of participants for each activity  for instance  a bus can fit at most    people  However  these constraints can be incorporated into agents preferences  by assuming that all agents view the alternatives that do not satisfy these constraints as unacceptable       Special Cases  We now consider some natural restrictions on agents preferences that may simplify the problem of finding a good assignment  We first need to introduce some additional notation  Given a vote Vi and an activity a  A   let Sia denote the projection of Si onto  a               n   That is  we set Sia    k    a  k   Si     Example      Let A    a  b  and consider an agent i whose vote Vi is given by  a     i  a     i  b     i  a     i  b     i  b     i  a     i  b     i a i       Then Si    a            b          and Sia                  We are now ready to define two types of restricted preferences for a GASP that are directly motivated by our running example  namely  increasing and decreasing preferences     ANDREAS DARMANN    EDITH ELKIND    SASCHA KURZ    JEROME LANG    JOACHIM SCHAUER    AND GERHARD WOEGINGER   Informally  under increasing preferences an agent prefers to share each activity with as many other participants as possible  e g   because each activity has an associated cost  which has to be split among the participants   and under decreasing preferences an agent prefers to share each activity with as few other participants as possible  e g   because each activity involves sharing a limited resource   Of course  an agents preferences may also be increasing with respect to some activities and decreasing with respect to others  depending on the nature of each activity  We provide a formal definition for a GASP only  however  it can be extended to GASP in a straightforward way  Definition      Consider an instance  N  A  P   of a GASP  We say that the preferences of agent i are increasing  INC  with respect to an activity a  A if there exists a threshold lai              n      such that Sia    lai   n   where we assume that  n      n       Similarly  we say that the preferences of agent i are decreasing  DEC  with respect to an activity a  A if there exists a threshold uai              n  such that Sia       uai    where we assume that             We say that an instance  N  A  P   of a GASP is increasing  respectively  decreasing  if the preferences of each agent i  N are increasing  respectively  decreasing  with respect to each activity a  A   We say that an instance  N  A  P   of a GASP is mixed increasingdecreasing  MIX  if there exists a set A   A such that for each agent i  N his preferences are increasing with respect to each a  A  and decreasing with respect to each a  A   A   A    A recently proposed model which can be embedded into GASP with decreasing preferences is the ordinal version of cooperative group buying       Section     the model has a set of buyers and a set of items with volume discounts  buyers rank all pairs  j  pj   for any item j and any of its possible discounted prices  where the discounted price is a function of the number of buyers who are matched to the item  For some activities  an agent may have both a lower and an upper bound on the acceptable group size  e g   one may prefer to go on a hike with at least   other people  but does not want the group to be too large  so that it can maintain a good pace   In this case  we say that an agent has interval  INV  preferences  note that INC DEC MIX preferences are a special case of interval preferences  Definition      Consider an instance  N  A  P   of a GASP  We say that the preferences of agent i are interval  INV  if for each a  A there exists a pair of thresholds lai   uai              n  such that Sia    lai   uai    where we assume that  i  j     for i   j   Other natural constraints on preferences include restricting the size of Si  or  more liberally  that of Sia for each a  A    or requiring agents to have similar preferences  for instance  one could limit the number of agent types  i e   require that the set of agents can be split into a small number of groups so that the agents in each group have identical preferences  We will not define such constraints formally  but we will indicate if they are satisfied by the instances constructed in the hardness proofs in Section           GASP and Hedonic Games  Recall that a hedonic game        is given by a set of agents N   and  for each agent i  N   a weak order i over all coalitions  i e   subsets of N   that include i  That is  in a hedonic game each agent has preferences over coalitions that he can be a part of  A coalition S  i  S  is said to be unacceptable for player i if  i   i S  A hedonic game is said to be anonymous if each agent is indifferent among all coalitions of the same size that include him  i e   for every i  N and every S  T  N    i  such that  S     T   it holds that S   i  i T   i  and T   i  i S   i     GROUP ACTIVITY SELECTION PROBLEM     At a first glance  it may seem that the GASP formalism is more general than that of hedonic games  since in GASP the agents care not only about their coalition  but also about the activity they have been assigned to  However  we will now argue that GASP can be embedded into the hedonic games framework  Given an instance of the GASP problem  N  A  P   with  N     n  where the i th agents preferences are given by a weak order  i   we construct a hedonic game H N  A  P   as follows  We create n   p players  the first n players correspond to agents in N   and the last p players correspond to activities in A   The last p players are indifferent among all coalitions  For each i              n  player i ranks every non singleton coalition with no activity players as unacceptable  similarly  all coalitions with two or more activity players are ranked as unacceptable  The preferences over coalitions with exactly one activity player are derived naturally from the votes  if S  T are two coalitions involving player i  x is the unique activity player in S  and y is the unique activity player in T   then i weakly prefers S to T in H N  A  P   if and only if  x   S       i  y   T        and i weakly prefers S to  i  in H N  A  P   if and only if  x   S       i a   We emphasize that the resulting hedonic games are not anonymous  Further  while this embedding allows us to apply the standard solution concepts for hedonic games without redefining them  the intuition behind these solution concepts is not always preserved  e g   because activity players never want to deviate   Therefore  in Section    we will provide formal definitions of the relevant hedonic games solution concepts adapted to the setting of a GASP  We remark that when A consists of a single  copyable activity  i e   there are n activities in A   all of them equivalent to each other   GASP become equivalent to anonymous hedonic games  Such games have been studied in detail by Ballester      who provides a number of complexity results for them  In particular  he shows that finding an outcome that is core stable  Nash stable or individually stable  see Section   for the definitions of some of these concepts in the context of a GASP  is NP hard  Clearly  all these complexity results also hold for GASP  However  they do not directly imply similar hardness results for a GASP     S OLUTION C ONCEPTS Having discussed the basic model of GASP  as well as a few of its extensions and special cases  we are ready to define what constitutes a solution to this problem  Definition      An assignment for an instance  N  A  P   of GASP is a mapping    N  A   i    a means that agent i does not participate in any activity  Each assignment naturally partitions the agents into at most  A  groups  we set       i    i    a   and  j    i    i    aj   for j              p  Given an assignment   the coalition structure CS  induced by  is the coalition structure over N defined as follows      CS     j   j              p   j       i    i       Clearly  not all assignments are equally desirable  As a minimum requirement  no agent should be assigned to a coalition that he deems unacceptable  More generally  we prefer an assignment to be stable  i e   no agent  or group of agents  should have an incentive to change its activity  Thus  we will now define several solution concepts  i e   classes of desirable assignments  We will state our definitions for a GASP only  though all of them can be extended to the more general case of GASP in a natural way  Given the connection to hedonic games pointed out in Section      we will proceed by adapting the standard hedonic game solution concepts to our setting  however  this has to be done carefully to preserve intuition that is specific to our model     ANDREAS DARMANN    EDITH ELKIND    SASCHA KURZ    JEROME LANG    JOACHIM SCHAUER    AND GERHARD WOEGINGER   The first solution concept that we will consider is individual rationality  Definition      Given an instance  N  A  P   of a GASP  an assignment    N  A is said to be individually rational if for every j     and every agent i   j it holds that  aj     j     Si   Clearly  if an assignment is not individually rational  there exists an agent that can benefit from abandoning his coalition in favor of the void activity  Further  an individually rational assignment always exists  for instance  we can set  i    a for all i  N   However  a benevolent central authority would usually want to maximize the number of agents that are assigned to non void activities  Formally  let         i    i     a    denote the number of agents assigned to a non void activity  We say that  is maximum individually rational if  is individually rational and            for every individually rational assignment     Further  we say that  is perfect  if       n  We denote the size of a maximum individually rational assignment for an instance  N  A  P   by   N  A  P    In Section    we study the complexity of computing a perfect or maximum individually rational assignment for a GASP  both for the general model and for the special cases defined in Section      Besides individual rationality  there are a number of solution concepts for hedonic games that aim to capture stability against individual or group deviations  such as Nash stability  individual stability  contractual individual stability  and  weak and strong  core stability  see  e g         In what follows  due to lack of space  we only provide the formal definition  and some results  for Nash stability  We briefly discuss how to adapt other notions of stability to our setting  but we leave the detailed study of their algorithmic properties as a topic for future work  Definition      Given an instance  N  A  P   of a GASP  an assignment    N  A is said to be Nash stable if it is individually rational and for every agent i  N such that  i    a and every aj  A it holds that  aj     j          Si   If  is not Nash stable  then there is an agent assigned to the void activity who wants to join a group that is engaged in a non void activity  i e   he would have approved of the size of this group and its activity choice if he was one of them  Note that a perfect assignment is Nash stable  The reader can verify that our definition is a direct adaptation of the notion of Nash stability in hedonic games  if an assignment is individually rational  the only agents who can profitably deviate are the ones assigned to the void activity  The requirement of Nash stability is much stronger than that of individual rationality  and there are cases where a Nash stable assignment does not exist  the proof is omitted due to space limits   Proposition      For each n     there exists an instance  N  A  P   of a GASP with  N     n that does not admit a Nash stable assignment  This holds even if  A       and all agents have interval preferences  In Definition     an agent is allowed to join a coalition even if the members of this coalition are opposed to this  In contrast  the notion of individual stability only allows a player to join a group if none of the existing group members objects  We remark that if all agents have increasing preferences  individual stability is equivalent to Nash stability  no group of players would object to having new members join   The terminological similarity with the notion of perfect partition in a hedonic game     is not a coincidence   there a perfect partition assigns each agent to her preferred coalition  here a perfect assignment assigns each agent to one of her equally preferred alternatives    GROUP ACTIVITY SELECTION PROBLEM     A related hedonic games solution concept is contractual individual stability  under this concept  an agent is only allowed to move from one coalition to another if neither the members of his new coalition nor the members of his old coalition object to the move  However  for a GASP contractual individual stability is equivalent to individual stability  Indeed  in our model no agent assigned to a non void activity has an incentive to deviate  so we only need to consider deviations from singleton coalitions  The solution concepts discussed so far deal with individual deviations  resistance to group deviations is captured by the notion of the core  One typically distinguishes between strong group deviations  which are beneficial for each member of the deviating group  and weak group deviations  where the deviation should be beneficial for at least one member of the deviating group and non harmful for others  these notions of deviation correspond to  respectively  weak and strong core  We note that in the context of a GASP strong group deviations amount to players in    forming a coalition in order to engage in a non void activity  This observation immediately implies that every instance of a GASP has a nonempty weak core  and an outcome in the weak core can be constructed by a natural greedy algorithm  we omit the details due to space constraints     C OMPUTING G OOD O UTCOMES In this section  we consider the computational complexity of finding a good assignment for a GASP  We mostly focus on finding perfect or maximum individually rational assignments  towards the end of the section  we also consider Nash stability  Besides the general case of our problem  we consider special cases obtained by combining constraints on the number and type of activities  e g   unlimited number of simple activities  a constant number of copyable activities  etc   and constraints on voters preferences  INC  DEC  INV  etc    Note that if we can find a maximum individually rational assignment  we can easily check if a perfect assignment exists  by looking at the size of our maximum individually rational assignment  Thus  we will state our hardness results for the easier perfect assignment problem and phrase our polynomial time algorithms in terms of the harder problem of finding a maximum individually rational assignment       Individual Rationality  Hardness Results  We start by presenting four NP completeness results  which show that finding a perfect assignment is hard even under fairly strong constraints on preferences and activities  We remark that this problem is obviously in NP  so in what follows we will only provide the hardness proofs  Our first hardness result applies when all activities are simple and the agents preferences are increasing  Theorem      It is NP complete to decide whether a GASP admits a perfect assignment  even when all activities in A are simple and all agents have increasing preferences  sketch  We provide a reduction from E XACT C OVER BY   S ETS  X C   Recall that an instance of X C is a pair hX  Yi  where X                q  and Y    Y            Yp   is a collection of   element subsets of X  it is a yes instance if X can be covered by exactly q sets from Y  and a no instance otherwise  Given an instance hX  Yi of X C  we construct an instance of a GASP as follows  We set N                q  and A    a            ap    For each agent i  we define his vote Vi so that the induced approval vote Si is given by Si     aj   k    i  Yj   k      and let P    V            Vn    Clearly   N  A  P   is an instance of a GASP with increasing preferences  It is not hard to check that hX  Yi is a yes instance of X C if and only if  N  A  P   admits a perfect assignment         ANDREAS DARMANN    EDITH ELKIND    SASCHA KURZ    JEROME LANG    JOACHIM SCHAUER    AND GERHARD WOEGINGER   Our second hardness result applies to simple activities and decreasing preferences  and holds even if each agent is willing to share each activity with at most one other agent  Theorem      It is NP complete to decide whether a GASP admits a perfect assignment  even when all activities in A are simple  all agents have decreasing preferences  and  moreover  for every agent i  N and every alternative a  A we have Sia          sketch  Consider the following restricted variant of the problem of scheduling on unrelated machines  There are n jobs and p machines  An instance of the problem is given by a collection of numbers  pij   i              n  j              p   where pij is the running time of job i on machine j  and pij            for every i              n and every j              p  It is a yes instance if there is a mapping                n               p  assigning jobs to machines so that the makespan is at most    i e   for each j              p it holds that P i  i  j pij     This problem is known to be NP hard  see the proof of Theorem   in       Given an instance  pij   i              n  j              p  of this problem  we construct an instance of a GASP as follows  We set N               n   A    a            ap    Further  for each agent i  N we construct a vote Vi so that the induced approval vote Si satisfies a a a Si j       if pij      Si j          if pij      and Si j    if pij      Clearly  these preferences satisfy the constraints in the statement of the theorem  and it can be shown that a perfect assignment for  N  A  P   corresponds to a schedule with makespan of at most    and vice versa      Our third hardness result also concerns simple activities and decreasing preferences  However  unlike Theorem      it holds even if each agent approves of at most   activities  The proof proceeds by a reduction from M ONOTONE   SAT  Theorem      It is NP complete to decide whether a GASP admits a perfect assignment  even when all activities in A are simple  all agents have decreasing preferences  and  moreover  for every agent i  N it holds that   a   Sia           Our fourth hardness result applies even when there is only one activity  which is copyable  and every agent approves at most two alternatives  however  the agents preferences constructed in our proof do not satisfy any of the structural constraints defined in Section      The proof proceeds by a reduction from X C  Theorem      It is NP complete to decide whether a GASP admits a perfect assignment  even when all activities in A are equivalent  i e   A consists of a single  copyable activity a  and for every i  N we have  Sia            Individual Rationality  Easiness Results  The hardness results in Section     imply that if A contains an unbounded number of distinct activities  finding a maximum individually rational assignment is computationally hard  even under strong restrictions on agents preferences  such as INC or DEC   Thus  we can only hope to develop an efficient algorithm for this problem if we assume that the total number of activities is small  i e   bounded by a constant  or  more liberally  that the number of pairwise non equivalent activities is small  and the agents preferences satisfy additional constraints  We will now consider both of these settings  starting with the case where p    A   is bounded by a constant  Theorem      There exist an algorithm that given an instance of a GASP finds a maximum individually rational assignment and runs in time  n     p poly n     GROUP ACTIVITY SELECTION PROBLEM     Proof  We will check  for each r              n  if there is an individually rational assignment  with       r  and output the maximum value of r for which this is the case  Fix an r              n   For every vector  n            np                n p that satisfies n         np   r we will check if there exists an assignment of agents to activities such that for each j              p exactly nj agents are assigned to activity aj  with the remaining agents being assigned to the void activity   and each agent approves of the resulting assignment  Each check will take poly n  steps  and there are at most  n     p vectors to be checked  this implies our bound on the running time of our algorithm  For a fixed vector  n            np    we construct an instance of the network flow problem as follows  Our network has a source s  a sink t  a node i for each player i              n  and a node aj for each aj  A   There is an arc of unit capacity from s to each agent  and an arc of capacity nj from node aj to the sink  Further  there is an arc of unit capacity from i to aj if and only if  aj   nj    Si   It is not hard to see that an integral flow F of size r in this network corresponds to an individually rational assignment of size r  It remains to observe that it can be checked in polynomial time whether a given network admits a flow of a given size      Moreover  when A consists of a single simple activity a  a maximum individually rational assignment can be found by a straightforward greedy algorithm  Proposition      Given an instance  N  A  P   of a GASP with A    a   we can find a maximum individually rational assignment for  N  A  P   in time O s log s   where s   P iN  Si    Proof  Clearly   N  A  P   admits an individually rational assignment  with       k if and only if    i    a  k   Si      k  Let R     i  k     a  k   Si    note that  R    s  We can sort the elements of R in descending order with respect to their second coordinate in time O s log s   Now we can scan R left to right in order to find the largest value of k such that R contains at least k pairs that have k as their second coordinate  this requires a single pass through the sorted list      Now  suppose that A contains many activities  but most of them are equivalent to each other  for instance  A may consist of a single k copyable activity  for a large value of k  Then the algorithm described in the proof of Theorem     is no longer efficient  but this setting still appears to be more tractable than the one with many distinct activities  Of course  by Theorem      in the absence of any restrictions on the agents preferences  finding a maximum individually rational assignment is hard even for a single  copyable activity  However  we will now show that this problem becomes easy if we additionally assume that the agents preferences are increasing or decreasing  Observe first that for increasing preferences having multiple copies of the same activity is not useful  if there is an individually rational assignment where agents are assigned to multiple copies of an activity  we can reassign these agents to a single copy of this activity without violating individual rationality  Thus  we obtain the following easy corollary to Theorem      Corollary      Let  N  A  P   be an instance of a GASP with increasing preferences where A contains at most K activities that are not pairwise equivalent  Then we can find a maximum individually rational assignment for  N  A  P   in time nK poly n   If all preferences are decreasing  we can simply eliminate all  copyable activities  Indeed  consider an instance  N  A  P   of a GASP where some activity a  A is copyable  Then we can assign each agent i  N such that  a      Si to his own copy      ANDREAS DARMANN    EDITH ELKIND    SASCHA KURZ    JEROME LANG    JOACHIM SCHAUER    AND GERHARD WOEGINGER   of a  clearly  this will only simplify the problem of assigning the remaining agents to the activities  It remains to consider the case where the agents preferences are decreasing  there is a limited number of copies of each activity  and the number of distinct activities is small  While we do not have a complete solution for this case  we can show that in the case of a single k copyable activity a natural greedy algorithm succeeds in finding a maximum individually rational assignment  Theorem      Given a decreasing instance  N  A  P   of a GASP where A consists of a single k copyable activity  i e   A    a            ak    and all activities in A are pairwise equivalent   we can find a maximum individually rational assignment in time O n log n   Proof  Since all activities in A are pairwise equivalent  we can associate each agent i  N with a single number ui              n   which is the maximum size of a coalition assigned to a non void activity that he is willing to be a part of  We will show that our problem can be solved by a simple greedy algorithm  Specifically  we sort the agents in non increasing order of ui s  From now on  we will assume without loss of generality that u       un   To form the first group  we find the largest value of i such that ui  i  and assign agents            i to the first copy of the activity  In other words  we continue adding agents to the group as long as the agents are happy to join  We repeat this procedure with the remaining agents until either k groups have been formed or all agents have been assigned to one of the groups  whichever happens earlier  Clearly  the sorting step is the bottleneck of this procedure  so the running time of our algorithm is O n log n   It remains to argue that it produces a maximum individually rational assignment  To show this  we start with an arbitrary maximum individually rational assignment  and transform it into the one produced by our algorithm without lowering the number of agents that have been assigned to a non void activity  We will assume without loss of generality that  assigns all k copies of the activity  even though this is is not necessarily the case for the greedy algorithm   First  suppose that  i    a    j    al for some i   j and some l              k   Then we can modify  by setting  i    al    j    a   Since i   j implies ui  uj   the modified assignment is individually rational  By applying this operation repeatedly  we can assume that the set of agents assigned to a non void activity forms a contiguous prefix of            n  Next  we will ensure that for each l              k the group of agents that are assigned to al forms a contiguous subsequence of            n  To this end  let us sort the coalitions in  according to their size  from the largest to the smallest  breaking ties arbitrarily  That is  we reassign the k copies of our activity to coalitions in  so that l   r implies   l      r    Now  suppose that there exist a pair of players i  j such that i   j   i    al    j    ar   and l   r  and hence   l      r     We have uj    r      l    ui  uj    r    so if we swap i and j  i e   modify  by setting  j    al    i    ar    the resulting assignment remains individually rational  Observe that every such swap increases the quantity    Pk P t   s t  s  t  by at least    prior to the swap  the contribution of i and j to  is il   jr  ans after the swap it is ir   jl   il   jr  Since for any assignment we have   kn n         eventually we arrive to an assignment where no such pair  i  j  exists  At this point  each  l   l              k  forms a contiguous subsequence of            n  and  moreover  l   r implies i  j for all i   l   j   r   Now  consider the smallest value of l such that  l differs from the l th coalition constructed by the greedy algorithm  let us denote it by  l    and let i be the first agent in  l     The description of the greedy algorithm implies that  l is a strict subset of  l and agent   GROUP ACTIVITY SELECTION PROBLEM      i belongs to  l   Thus  if we modify  by moving agent i to  l   the resulting allocation remains individually rational  since i is happy in  l    By repeating this step  we will gradually transform  into the output of the greedy algorithm  possibly discarding some copies of the activity   This completes the proof      The algorithm described in the proof of Theorem     can be extended to the case where we have one k copyable activity a and one simple activity b  and the agents have decreasing preferences over both activities  For each s              n we will look for the best solution in which s players are assigned to b  we will then pick the best of these n solutions  For a fixed s let Ns    i  N    b  s   Si    If  Ns     s  no solution for this value of s exists  Otherwise  we have to decide which size s subset of Ns to assign to b  It is not hard to see that we should simply pick the agents in Ns that have the lowest level of tolerance for a  i e   we order the agents in Ns by the values of uai from the smallest to the largest  and pick the first s agents  We then assign the remaining agents to copies of a using the algorithm from the proof of Theorem      Indeed  any assignment can be transformed into one of this form by swapping agents so that the individual rationality constraints are not broken  It would be interesting to see if this idea can be extended to the case where instead of a single simple activity b we have a constant number of simple activities or a single k   copyable activity   We conclude this section by giving an O  n  approximation algorithm for finding a maximum individually rational assignment in a GASP with a single  copyable activity  Theorem      There exists a polynomial time algorithm that given an instance  N  A  P   of a GASP where A consists of a single  copyable activity a  outputs an individually rational assignment  with          n    N  A  P    Proof  We say that an agent i is active in  if  i     a   a coalition of agents is said to be active if it is assigned to a single copy of a  We construct an individually rational assignment  iteratively  starting from the assignment where no agent is active  Let N     i    i    a   be the current set of inactive agents  initially  we set N    N    At each step  we find the largest subset of N  that can be assigned to a single fresh copy of a without breaking the individual rationality constraints  and append this assignment to   We repeat this step until the inactive agents cannot form another coalition  Now we compare the number of active agents in  with the number of active agents in a maximum individually rational assignment     To this end  let  us denote the active coalitions of  by B            Bs   where  B             Bs    If  B     n  we are done  so assumethat this is not the case  Note that since B  was chosen greedily  this implies that  C   n for every active coalition C in     Let C be the set of active coalitions in     We partition C into s groups by setting   C    C  C   C  B       and C i    C  C   C  Bi      C   C j for j   i  for i              s  Note that every active coalition C    intersects some coalition in   otherwise we could add C to   Therefore  each active coalition in   belongs to one of the sets C             C s   Also  by construction  the sets C             C s are pairwise disjoint  Further  since the coalitions in C i are pairwise disjoint and each of them intersects Bi   we have  C i     Bi   for each i              s  Thus  we obtain X X X X           C   n i       s CC i    X i       s  i       s CC i  X     C   n   Bi   n      n  i  i       s         ANDREAS DARMANN    EDITH ELKIND    SASCHA KURZ    JEROME LANG    JOACHIM SCHAUER    AND GERHARD WOEGINGER          Nash Stability  We have shown that a GASP does not not always admit a Nash stable assignment  Proposition       In fact  it is difficult to determine whether a Nash stable assignment exists  The proofs of the next two results are omitted due to space constraints  Theorem       It is NP complete to decide whether a GASP admits a Nash stable assignment  However  if agents preferences satisfy INC  DEC  or MIX  a Nash stable assignment always exists and can be computed efficiently  Theorem       If  N  A  P   is an instance of a GASP that is increasing  decreasing  or mixed increasing decreasing  a Nash stable assignment always exists and can be found in polynomial time  Moreover  the problem of finding a Nash stable assignment that maximizes the number of agents assigned to a non void activity admits an efficient algorithm if A consists of a single simple activity  Theorem       There exist a polynomial time algorithm that given an instance  N  A  P   of a GASP with A    a  finds a Nash stable assignment maximizing the number of agents assigned to a non void activity  or decides that no Nash stable assignment exists  Proof  For each k   n             we will check if there exists a Nash stable assignment  with       k  and output the largest value of k for which this is the case  For each i  N   let Si   Sia   For k   n a Nash stable assignment  with       n exists if and only if n  Si for each i  N   Assigning every agent to a is Nash stable if and only if      Si for each i  N   Now we assume    k  n    and set U     i  N   k  Si   k        Si    U     i  N   k    Si   k      Si    and U     i  N   k  Si   k      Si    If  U       U      k  there does not exist an individually rational assignment  with       k  If U       no Nash stable assignment  with       k can exist  since each agent from U  would want to switch  If  U      k  no Nash stable assignment  with       k can exist  since at least one agent in U  would not be assigned to a and thus would be unhappy  Finally  if  U       U     k   U     k  U      we can construct a Nash stable assignment  by assigning all agents from U  and k   U    agents from U  to a  Since we have  i    a for all i with k   Si and  i     a for all i with k      Si   no agent is unhappy         C ONCLUSIONS  AND  F UTURE W ORK  We have defined a new model for the selection of a number of group activities  discussed its connections with hedonic games  defined several stability notions  and  for two of them  we have obtained several complexity results  A number of our results are positive  finding desirable assignments proves to be tractable for several restrictions of the problem that are meaningful in practice  Interesting directions for future work include exploring the complexity of computing other solution concepts for a GASP and extending our results to the more general setting of GASP  Acknowledgments This research was supported by National Research Foundation  Singapore  under Research Fellowship NRF         by the project ComSoc  ANR    BLAN          and by the Austrian Science Fund  P      G   and P      N     This project was initiated during the Dagstuhl seminar       Computation and Incentives in Social   GROUP ACTIVITY SELECTION PROBLEM      Choice  and the authors are very grateful to Dagstuhl for providing a great research environment and inspiration for this work  We thank Craig Boutilier and Michel Le Breton for helpful comments  Part of this work was done when the second author was visiting Universite Paris Dauphine  
  While plausible reasoning has been applied to a vari  This article deals with plausible reasoning  about spatial information  On the other hand  it has  ety of domains  it has rarely been applied to reasoning been applied to reasoning about  from incomplete knowledge about large scale  tial information   consisting of a set of pointwise observations   fluents  do not change and therefore that their value  belief functions to represent the influence of  persist from one time point to the subsequent one  un  the knowledge at a given point to another  less the contrary is known  from an observation  for  point  the quantitative strength of this in  instance  or inferred  this implies some minimization  fluence decreases when the distance between  of change  Now  the latter persistence paradigm can  These influences are  be transposed from temporal to spatial reasoning  In  aggregated using a variant of Dempster s rule  the very same line of reasoning  when reasoning about  of combination taking into account the rela  properties in space  it is  often  intuitively satisfactory  tive dependence between observations   to assume that  knowing from an observation that a given property r p holds at a given point  Introduction  as well at points  close enough  to  This article aims at handling knowledge about large scale spatial properties  e g   soil type  weather   in  contexts where this knowledge is only partial  i e  some piece of information is known only at some given lo  cations of space  We have investigated some means to perform plausible reasoning on this kind of informa tion at any point in the considered space  Several studies can be related to the question of usually consider the question of representing incom plete knowledge about the location of spatial ob jects  using relational theories  more or less related to the seminal work of  Randell  et al          or us         or about vague re        rather than about static  ing fuzzy locations  Bloch  gions  Cohn and Gotts   properties and their distribution over a given space   et al          apply revision strategies to in  consistency removing in geographical information sys tems   A completely different line of work  in the  robotics literature  deals with map building using oc cupancy grids  see e g    Iyengar and Elfes   will be briefly discussed in Section        x   then it holds  x   What we precisely mean by  close enough  depends on the nature of the region as well as on the property r p involved  Moreover  it is clear that the belief that r p  persists  from point  x  to point y is gradually de  creasing  the closer y to  x   the more likely r p observed  at  x  is still true at y  This graduality can be modelled  by order relations or by quantitative measures such as probability  However  as we explain in Section    pure  imprecise knowledge in spatial databases  but they   Wiirbel  Plausible reasoning about systems  that evolve over time usually consists in assuming that  is extrapolated to neighbour points  We use  both points increases   temporal information   which gives some hints about how to do it for spa  spatial properties  The available information      France           it  probabilistic reasoning is not well suited to this kind of  reasoning  unless very specific assumptions are made  We therefore model persistence with the help of the  belief function theory   also known as the Dempster  Shafer theory  Belief functions  and their duals  plau sibility functions  generalize probability measures and enable a clear distinction between randomness and ig norance that probability measures fail to do  After giving some background on belief functions  we show how to infer plausible conclusions  weighted by belief degrees  from spatial observations   Then  we  relate computational experiments  evoke information theoretic and decision theoretic issues  and conclude   A  fluent is  a  proposition  which  evolves over time    LANG   MULLER       Background on belief functions     UAI      well suited to the combination of information from dif ferent sources  The  The  DempsterShafer   Dempster          theory   Shafer          of  evidence  is a generalization of  Dempster combination m  ffi m  of  two  normalized  mass functions defined by  m   probability theory enabling an explicit distinction between randomness and ignorance  Let  S  mt  ffi m  A     be a finite set of possible states of the world   taken to be the set for possible values for a given vari able  for the sake of simplicity    one of which corre  L X YS XnY A  and  m   on S is  m  X m  Y  R m   m    where  sponds to the real world  A  normalized   mass assign m        and LACS m A       The condition that m        is sometimes omitted  see  Smets and Kennes          if m        then we say that m is an unnormalized mass assignment  The int erest of having a mass assignment ment  is a mapping  m       t          such that  unnormalized is the ability to keep track of a degree of conflict  The subsets of S with a nonempty mass are called the  focal elements of m  m  simple support function iff it there is a nonempty subset A of S and a a E        such that m A   a and m  S      a  by convention  when specifying  is a  ssignmen t we omit subsets  a ma ss a  with an empty mass   A mass assignment  Plm  Plm B   from    to         Belrn  B   m  induces two set functions  Belm     the belief function Belm and the plausibility function Plm are defined respec tively by     B  S  Belm B    L ACB m  A  and and  LAnB t   m A    When  m is  normalized   represents the probability of existence of at  least one true piece of evidence for A  while  Plm B   represents the probability of existence of at least one true piece of evidence which does not contradict A  When all focal elements are singletons   m  can be  viewed as a probability distribution on S  in this case  X Y    S XnY    Importantly  this operation is associative  which en  m  ffi m  ffi      ffi of mass assignments   ables its extension to the combination  mn of an  arbi t r ary number n  When unnormalization is allowed  we define the t m   normalized Dempster combination or not  mass assignments  m   and  of two  normalized  m   on  S  by  X Y   S XnY A  The resulting  m  ffiu m      m  and m    measures the degree of  conflict between  Lastly  in some cases it is needed to transform a mass assignment into a probability distribution  This is the case for instance when performing decision theoretic tasks  place  Importantly  this transformation should take  after combination has been performed  and not  before  as argued in  Smets and Kennes        who in troduce the  pignistic transform T m   of a normalized  m  being the probability distribution by  Vs E S  T m  s       L A   S EA    mass assignment on S defined    Alternatives to the pignistic transform for decision  Belm  A    Plm A    LsEA m s   hence  Belm and Plm coincide and are identical to the probability mea  making using belief functions are given in  Strat          sure induced by     m   Therefore Dempster Shafer theory  Extrapolation from observations  generalizes probability theory on finite universes  The Dempster Shafer theory of evidence enables an explicit distinction between randomness and ignorance  that probability theory cannot   Another crucial ad vantage of the theory of belief functions is that it is  This is clear from the following two mass functions   mi head tails       m   head     m   tails       m  represents a true random phenomenon such as toss  ing a regular coin  while m  would correspond to a case where it is not reasonable to define prior probabilities on imagine for instance that you were just   head  tails     given a parrot with the only knowledge that the two words knows are   head  and  tails   there is absolutely no reason to postulate that it says  heads  and  tails  ran domly with a probability  nor with any other probabil  it  i ty     it may  head       well be the case  for instance  that it always say This state of complete ignorance about the out  come of the event is well represented by the neutral mass       Observations  From now on we consider a space E  i e   a set of  spatial points   which could be seen as either Eu  clidean points or atomic regions   E is equipped with a distance   d   We are interested in reasoning on the evolution  in space  of some properties  For the sake of simplicity  the property of interest merely consists of the value of function     Recall that a distance is a mapping E   t JR  such as  i      if and only if  ii  and  iii    z     z   However we do not really require the triangular inequality  iii   hence our formal framework only requires d to be a pseudo distance but these technical details will not be discussed further   m S     d y  x   d x  y  d x  y   d y   d  x   y  d x   d x  y      UAI       LANG   MULLER  a given variable  whose domain is a finite set S  S is  furthermore assumed to be purely qualitative  i e   S is  not a discretized set of numerical values  S may be for instance a set of possible soil types  or a set of weather types  The simplest case is when S may is binary  i e    the property of interest is a propositional variable the  truth value of which we are interested in  for instance S    rain   rain    An  observation function    is  a  mapping  from  Dom O   E to the set of nonempty subsets of S     intuitively consists of a set of pointwise observations  x  O x   where x E E and O x  is a nonempty subset  of S  such a pointwise observation means that it has been observed that the state of the world at point  longs to  x  be  O x      is said to be complete at x ifO x  is a  singleton and  trivial at x ifO x     S  The  range R O   of   is the set of points where a nontrivial observation has been performed  i e        R O       x O x  f  S    degree which is all the higher  y is close to x  In  O y  has a maximal  and absolute  impact on  while   x  when y gets too far from x  this impact becomes null   By default  and like to  Dean and Kanazawa        for  temporal persistence   we will use exponential decay  functions  f obs  a      exp        bs    where  is a  J   obs   real strictly positive number expressing the  persis tence power  of the observation  obs   such a function is  called an exponential decay function     This deserves further comments   We first consider the case of complete observations   i e    obs  is a singleton   v   J    v     written  J   v   with  out any risk of misunderstanding  characterize the per  sistence degree of the value  J    v      the lower  v   stronger the spatial persistence of the property V  The two limit cases for  The question is now how to extrapolate from an ob servation function     as  particular  if x   y  thus d x  y       then O x       Spatial persistence       J   v   is  As explained in the introduc     exp             v    J    v   are   the     v   by passage to the limit we write      and therefore the property V  non persistent         v  as soon as d x  y       the fact  that V   v holds at point y does not support  tion  the spatial persistence principle stipulates that  the belief that V     v  should hold at  x  too  As  as long as nothing contradicts it  a property observed  an example  consider the property  the  th dec  with a quantity of belief decreasing with the distance  this property is non persistent  provided that the  at a given point is believed to hold at points nearby   imal of the temperature at x is even    to the observation  This principle is now formally en coded in the framework of belief functions  Let x be a given point of E  called the  focus point   What we are interested in is to infer some new  plau sible  beliefs about what holds at x  For this we con  sider a set of mass assignments   my y z    y  E  R O    where each myYx is the simple support function de fined by    my   x O y   myyx S   where  f IS  a mapping from  X  JR  to        s t      f is non increasing in its second argument  a f  implies f X a      f obs         f obs  a       f  f obs  a         if and only if  a   i e    decay function   modelling decreasing beliefs over  used in  Dean and Kanazawa          have first been  The intuitive reading of the mass assignment     oo  is    tv          by passage to the limit we write    and  therefore the property V  strongly persistent     v  as soon as it is true some  where in space  it is true everywhere in E   How J    v   is determined depends on the variable V and the value  v  involved  It may be determined by expe  relevant persistence  of  V   v from y to x  which may sometimes be under  stood as the probability of  continuous persistence from  x to y   this will be discussed later   according to the formula above  is exp    d l  V   v   t         In particular  if  is the  half persistence  of V    tence is equal to  Decay functions for  time  J    v   exp    v   i e   the  dfstance for which the probability of  relevant  persis         a Hoo    will be called a    to hold  the probability of the  f O y   d x  y              granularity of space is coarse enough    rience  Considering a point x where V   v is known    f O y   d x  y         Clearly     then  we have J    v     t f    Now  when V is not a singleton  the persistence decay  function of  V  will be taken to be the persistence func  tion of the most weakly persistent element of  v   The critical point is the reference to  persis  J   V    minvEV J   v    my      is the following  the fact that O y  is observed at y  supports the belief that O y  holds at x as well  to a   as noticed by a referee  there are intuitive cases where this condition could be weakened   relevant  tence rather than with simple persistence   i e    Assume  that we try to build an approximately valid weather map and that the property rain     true observed at  point x  Clearly  this property being known to have a        LANG   MULLER  UAI        significant spatial persistence  this piece of knowledge  explanation of this value  is a strong evidence to believe that it is also raining at  pieces of evidence that it is raining at y and not rain  a very close pointy  such as  say   ing at  d  r  y      k m   This  is not at all an evidence to believe that is raining at  x and are in conflict   y and the z both can be considered as informa the first one telling that it is raining at x  absence of rain at  may well be the case that it is raining at  r  but in this  and the second one that it is not  the reliability of the  z  d x  z        km   hence  the impact of  have a strong impact on  An analogy with information merging from multiple  x on This does not mean that the probability of raining at z is  almost  zero  It  z  where  z  is the following  the two  regarding rain is  almost   zero   z is   almost certainly   unrelated to the fact that it is raining at x  because  for  case  the fact that it is raining at  sources is worthwhile  the rain observed at tion sources   sources being function of the distance between them and the focus point  In the absence of a reason to  x   instance  the air masses and the pressure at these two  believe more one source than the other one  the prob  points  ability that it is raining at  pact  do with the prior probability of p ersi st enc e  had this    at the same time  are independent  The im   rain  d x  z    true of x on z regarding rain  can be interpreted as the probability that  knowing  prior been  that it is raining at  would still have been  x   it is also raining at  z and  two points are in the same  raining region    these  Hence  the terminology  relevant persistence   which may also be interpreted as  continuous persistence   i e   persis tence along a continuous path  if we assume moreover that a raining region is self connected           x is    This has nothing to  the probability that it is raining at  x    w as the focus point  w being very far y and z  their impact is almost zero and the prob ability of rain at w is  extremely close to  the prior  Consider now from  probability of rain  i e   and comes from    ignorance  This value of   is a  prior  rather than with conflict   This is where the difference between pure probability  Therefore  probability cannot distinguish from what  and be li e f  happens at  ability  tween  functions  recall that they generalize prob theory   is the most significant  in a pure prob  abilistic framework  this impact degree  or probability  x and  at  w   i e   it cannot distinguish be  confiictual information and lack of information   Belief functions  on the other hand  would do this dis  of relevant persistence  cannot be distinguished from  tinction  while the belief of raining at  a usual probability degree  If we like to express prob  been close to  abilities of persistence in a pure probabilistic frame  the belief of not raining at         s t  Prob H olds x  rain IH olds y  r ain      rain d  c  y    This mapping g is different from f  More precisely   to  work  we need a mapping   rain     E        g    f holds  and g and f are closer and closer to f  d x  y  is  as  d x y  becomes large   with respect to the persistence degree of rain   the impact g tends to   while g tends to the prior prob ability of raining at x  From this we draw the follow ing conclusion  a pure probabilistic modelling of spatial persistence needs not only some knowledge about how properties persist over space but also a prior probabil ity that the property holds at each point of space  the latter  which may be hard to obtain  is not needed with the belief function modelling of persistence          the belief of raining at w   x would have w  as well as  would have been dose  Hence the second conclusion   a pure probabilis tic modelling of spatial persistence does not allow for a distinction between confiictual information and lack of information  while the belief function modelling does   smaller and smaller  when       Combination  Once each observation is translated into a simple sup port function  my   x   the bel i ef about the value of the  variable V is computed by combining all mass assign ments my   x for  y  E  R O    A first way of combining them consists in applying mere Dempster combination  i e    The second drawback of a pure probabilistic modelling of spatial persistence is the lack of distinguishability  between ignorance and conflict  Suppose   without loss  of generality   that the persistence is  where  x is  both  and    prior probability of  Consider the four points  very close to  w   uniform   x and y  is very far from  x   z   Suppose that it has  y  and that it is  The probability  as well  lief  that it is raining at   r   y  z  and half way between  been observed that it is raining at not raining at  w  x   as  are very close to  the be     The   and  in a stronger way  by  linearly continuous per sistence  if we assume that a raining region is not only self connected but also convex   If one wishes to keep explicitly track of the measure of conflict then one may use unnormalized Dempster combination instead  However  a naive use of Demp ster combination has a severe drawback  Consider the      x y z w  where d x y       d x  w    d y  w        d z  w         d x  z    d y  z       and the observation function   concern ing rain  O x    O y    true  O z    false  The  following space E  focus point is w We take an exponential decay func tion with a uniform     mx  tw  my   w         The  mass  assignments  and mx   w are the following    UA       LANG   MULLER  X  E and for any xE E  X  J l xiX    min     J    X U  x    J t  X   where J l            J l X      if lXI     and for any X of cardinality n           J l X       n L y z X y tz e    where    IS a pos   X         lP   w w z                                             y  itive real number   mx   w   true   mx   w    true  false        exp       m   w                 exp      my  tw  true   mx   w   true  false   mz   w  false   mx   w   true  false   The combination  mx   w      Ef     In particular we have J l  xl       and Ji  xi Y      d  r y    e       r    Takmg          on the exampie of figure   we have J l   yl x           and J t    z l  x                  Now                    R             sort the points in  x   and at  y  x  and y      by increasing order of  i e   let  mx  tw       to n do Yi I Yl   Yi d     J l    J li f  et m  m o ill           f O i   d x  y      mHS         f  O i   d x   y     for  i  f     I  are clearly not inde  pendent  and thus the mass assignments  R O   Lo x  be the ordered  Yt   Yn   where R O   Yt  Yn  and d x  yl              d x  Yn    being close to each other  the pieces of information z  the focus point and  list                Clearly  this is not what we expect  because that it is raining at  x be  the points where a nontrivial observation has  been performed   my   w Ef  mz  t w    mass assignments  n  with respect to J   is done by  the following algorithm  Let  the distance to  m   w    true   m   w  false   mx  tw   true  false    and         should not be combined as if they were inde  pendent  On the other hand  on the following figures   mx  tw  mx  tw and mx   w are identical to those above but x is no longer close to y  the above result m  t w   mx  tw  my  tw EBmz  tw is intuitively correct  where  To remedy this problem  we introduce a  factor  the aggregation of the  my   x  y E R        x    yields  my  tw       discounting  when combining mass assignments   The dis  count grows with the dependence between the sources  i e   with the proximity between the points where ob servations have been made      ffiio  l   n mi  This way of combining by first reranking and then us ing interaction factors is reminiscent of the aggrega tion operator known in multi criteria decision theory called  Choquet integral   Formal analogies will not be  discussed further here  In practice  it is often the case that each pointwise  We use here a method inspired from multi criteria decision making  where positive or negative interac tions between criteria have to be taken into account when aggregating scores associated to the different cri  Assuming that E is fin ite  for X  E and xE E  X  we introduce a conditional importance de gree J t  xiX  E        expressing the importance of the knowledge gathered at point x once the points in X have been taken into account  The quantity   J t  xiX  is therefore a discount due to the dependence with the teria     information at x and the information already gath ered Intuitively  it is desirable that  the further  x from  X   the higher J l xiX   When xis sufficiently far from X  there is no discount and J l  xiX  is taken to be    Several possible choices are possible for     compute mx  J l  In the im  plementation we chose the following function   for any   lts intuitive justification  which is based on  an  anal   observation is precise  i e   y  E  R O    O  yi        v    for each  In this case  the above combination op  eration can be written in a much simpler way  the mass of a value   v   can be expressed as follows  given  Vm     J j  Vj E V  a     m   vj   f     Vi E  l  p  P     k E  l  n  mk  v    f      Vi E  l  p  P     k E  l  n  mk  v          In a few preliminary notations    that case  it is easy to show that combination without discount yields   m v              kEP      a c        kEP       a c       Whereas combination with discount yields   m v            kEP       o c  k        xEP       ac k    ogy with fuzzy measures and interaction indexes in multi criteria decision making  would be rather long and compli cated to explain without introducing further several defi nitions  We omit it because this is not the main scope of the paper    LANG   MULLER       Experiments     UAI      reveals no information  and a purple one would reveal conflicting values   Since color is not possible in this  We recall that what we focus on is the plausible ex  article we will show figures in shades of gray   trapolation of information  given a set of observations  observation point will be in black or white  and the  Each  on E  what is the likelihood of the truth of a formula  shade of gray for each interpolation will be a difference  on a point outside of the set of observations   For the  between the combined mass of the two values  normal  experiments  we used a binary value domain  namely  S      white  black    likely a point is to have a value close to a black obser  We compute the overall mass assignment for each lo cation  x  in the space E  by combining the mass as  signment induced by every point y in the observation set  R O    We have two courses of action from here   Either we make a plain Dempster combination of all the simple support functions ther we make  a  mx     EByER O  my   x   ei  correction based on a Choquet integral  applied to the exponents  as explained at the end of Section         ized   In order to see the observations points  the more  to lower the influence of close concurring  observations  for which the independance hypothesis cannot hold   After this combination is performed  we can decide whether to normalize the results  by as signing the mass of the null set to the other possible sets  or to keep a non zero mass for contradictory in formation  Keeping un normalized resulting mass as signments helps visualizing the conflictual regions   vation  the more white it is  and conversely  A middle gray will indicate similar levels of both values   For  instance  figure   shows the result for three close con curring  black  observations next to a single  white  observation  In one case the information is corrected to take into account the fact that close points are related and do not express independent sources  In the other one we have made a plain Dempster combination  We can see that the three black points combined have an influence similar to a single point   In the limit case  where the three points are exactly identical we would have exactly the same result as with only one point  illustrating this would not be very spectacular   Fig ure   nonetheless shows different levels of interpolation varying with the distance between concurring observa tions  with or without the Choquet like correction   We chose the following experimental framework  we consider a space of pixels E  ordered along two axes  and for which a distance relation is the Euclidean dis tance  The distance unit is then one and the factors      white       black   are uniformly fixed at  took the same value of            and we  used for the coefficient of  interaction between observations      The best way to  Figure      Corrected  normalized   left   and  non  corrected normalized  right  interpolation  with vary ing distances between observations with identical val ues  Figure      Corrected left  and non corrected  right  in  terpolation  with conflicting values and three concur     decision theoretic issues  ring  close observations illustrate our results would be to assign a color to each pixel  assigning a red intensity to one value  a blue in tensity to the other  and eventually a green intensity to the belief in the empty set  if one want to keep track of the level of contradiction   This way a black pixel   This settings proved empirically to give visual results that illustrates well the principled we use here  Obviously  these factors should be tailored for specific spatial proper ties with respect to the scale of the actual observed space  Moreover  other distances could be considered where the interaction and persistence of relevance would take into account other factors   Informationtheoretic and  Plausible information can be very useful in the context of decision making  when decisions have to be made on the basis of uncertain information       Information intensity maps  Our framework can be used to measure the variations of the quantity of information over space   In order  to do so  we may compute a probability distribution on S at each point of E  using for instance the pig  nistic transform  and the information level at each  point can then be computed using usual information    UAI      LANG   MULLER  theoretic measures such as entropy   build a map where each point  x  Hence we can  as a set of observations on a larger space  what lo  is associated to the  cations are the most informative when one want to  entropy of its final probability distribution  Entropy increases as information decreases  in other words  the quantity  of  p   H  p        measure the quantity of information  Minimal entropy is obtained at points at which  at a complete observation has been made   Maximal  entropy is obtained at points associated with a uni form probability distribution  if any   Note that this uniform probability distribution may come either from conflictual observations or from a lack of information  as explained in Section      once the combined mass assignment has been transformed into a probability distribution  there is no longer a way to distinguish  switch to a finer grained representation  An information intensity map already gives some hints about where it should be interesting points to make new measures  measures seem more useful in regions in which the information quantity is low   However   picking the point of E with the lowest amount of in formation is not sufficient in general   Especially  it  is relevant to make a difference between points where nothing is known because the observations are too far  and the ones where there is conflict between observa tions at points nearby   conflict from lack of knowledge   If one is interested in choosing  This is true independently of the number of values  classical heuristics is the maximum expected entropy loss   This  however  works well if     only one more  we consider for a spatial fluent  but to illustrate the process  we show on figure   the level of information using as before the   valued set S      white  black    In this case  the quantity of information      H p     H Information is minimal when p white    p black     and maximal when p white      p black      or p white    O p black       The shade of gray is proportional to IP white    grows with IP  white   This way  a black point corresponds to a low amount of information and a white point to a high one  Again we show the results both with and without correction   one  measurement  a  measurement has to be made      the measurements have uniform costs      the utility of a gain of infor mation does not depend on the value observed nor on the location of the measurement   The more gen  eral problem of determining an optimal measurement policy over a given number of steps can be cast in   the framework of Partially Observable Markov De cision Processes   This requires the specification not  only of measurement costs but also a utility function which grows with the global amount of information  and which possibly takes account of the relative im portance of some values or of some regions   This point is left for further research  and should be positioned to the recent work of  D  Kortenkamp and Murphy        extending the idea of occupancy grids with the use of MDP  Once a series of measurements has been done  one may decide either to stop the measurements  or  if the quan tity information is considered high enough  relatively to the expected cost of new measurements   we can then easily compute a  plausible map  from the re  Figure      Corrected  normalized   left   and  non  corrected normalized  right  level of information  sult of the combination step  by assigning each point of the space a value with the highest probability  in order to represent the most likely distribution of the spatial property considered  Figure     shows the result  on a sample observation set  with two different levels      Decision theoretic  map  construction  We are now interested in the following problem  given a set of observations    where  and what  is it worth while to measure next  This problem  already consid ered in the field of robotics  where it has received a pure probabilistic treatment   is relevant not only for exploring geographical data but also for the question of granularity dependent representations  Indeed  given a coarse grain representation of spatial information seen   We recall that the entropy of a probability distribution L  ES  p s  lnp  s    p over a finite setS is defined as H p      of gray for each value  One can again observe that the correction decreases the likeliness of a value near con curring measures   In practise  it would probably be  better to decide of a threshold under which the belief in a value is irrelevant before pignistic transformation  If we know indeed that the belief in value   is       and belief in value   is        thus the belief in the set       is        we don t want to assume it is more likely that value   holds and thus we would like the map to remain undetermined at this point    This heuristics is widely used in model based diagnosis when choosing the next test to perform    LANG   MULLER        UAI       
  A semantics is given to possibilistic logic  a logic that handles weighted classical logic formulae  and where weights are interpreted as lower bounds on degrees of certainty or possibility  in the sense of Zadeh s possibility theory  The proposed semantics is based on fuzzy sets of interpretations  It is tolerant to partial inconsistency  Satisfiability is extended from interpretations to fuzzy sets of interpretations  each fuzzy set representing a possibility distribution describing what is known about the state of the world  A possibilistic knowledge base is then viewed as a set of possibility distributions that satisfy it  The refutation method of automated deduction in possibilistic logic  based on previously introduced generalized resolution principle is proved to be sound and complete with respect to the proposed semantics  including the case of partial inconsistency     INTRODUCTION  Possibilistic logic is a logic of uncertainty tailored for reasoning under incomplete information  At the syntactic level  it handles formulas of propositional or first order logic to which lower bounds of degrees of necessity  i e  certainty  or possibility are attached  The degrees of possibility follows the rules of possibility theory  Zadeh         Dubois and Prade        and the degrees of necessity are defined from degrees of possibility through a classical duality relationship  A possibilistic knowledge base can thus be viewed as a stratified  or layered  classical knowledge base  where some formulae are more certain  or more possible than others  Resolution rules have been derived in accordance with the axioms of possibility theory  Dubois and Prade            a  and a refutation technique has been implemented for necessity valued formulas  Dubois Prade and Lang        further on extended to both possibility and necessity valued formulas  Lang         The main ideas behind possibilistic logic are  i  the degree attached to a proof path in a possibilistic knowledge base is the least degree attached to a formula in this proof path  and the degree attached to a consequence of a possibilistic  knowledge base is the greatest degree attached to proof paths yielding this consequence   ii  when two antagonistic propositions p and    p can be derived  the one with the highest degree inhibits the other one  The latter point indicates that possibilistic logic can handle partial inconsistencies  Moreover possibilistic logic proposes a way of handling uncertainty based on the idea of ordering rather than counting  contrary to probabilistic logic  This paper presents a semantics for possibilistic logic in a fairly general situation  i e  possibility or necessity valued clauses  and the presence of partial inconsistency  are allowed  It extends a previous semantics dedicated to necessity valued propositional clauses only  Dubois et a           This semantics is based on an extension of the satisfiability notion from sets of interpretations to fuzzy sets of interpretations  The idea of a fuzzy set of interpretations is that some interpretations are preferred to others and enable non trivial inferences that could not be made if interpretations were equally considered  In this sense  possibilistic logic belongs to the family of non monotonic logics based on preferential models  whose general setting has been devised by Shoham         see Dubois and Prade        on this point  Possibility distributions are viewed here as a convenient way of encoding a preference relation by attaching a weight to each interpretation of a set of formulas  Possibilistic logic completely contrasts with Ruspini        s so called  fuzzy logic  where the semantics relies on the idea of similarity rather than ordering  Ruspini s logic is one of graded indiscernibility between worlds  in the spirit of Pawlak        s rough sets  while possibilistic logic is a logic of preference between interpretations  Possibilistic logic is closely related to Shackle        s degrees of potential surprize  and Spohn        s ordinal conditional functions  See Dubois and Prade      b  on this latter point  Possibility measures can also be viewed as consonant belief functions  Shafer         However  possibilistic logic is not a truth functional many valued logic and is not a logic of vagueness  as is fuzzy logic  because it primarily pertains to non fuzzy propositions the truth of which is uncertain due to incomplete information  In the next section  a language and a semantics are presented for possibilistic logic  a logic of necessity and   A Logic of Graded Possibility and Certainty Coping with Partial Inconsistency  possibility valued  classical  formulas  A version of the semantics  in terms of a possibility distribution on a set of interpretations for the case of consistent knowledge bases is first presented  where consistency refers to the proper assignment of the possibility and necessity degrees  with respect to the axioms of possibility and necessity measures   A generalized semantics  where an extra element representing the absurd interpretation is added to the referential of the possibility distribution  is then introduced in order to allow for inconsistencies  Section   describes an automated deduction procedure based on extended resolution and refutation  Completeness of the deduction procedure holds  with respect to the proposed semantics         POSSIBILISTIC LOGIC   LANGUAGE AND SEMANTICS LANGUAGE  A possibi istic formula is either a pair  q   N a   where q  is a classical first order formula and aE         a should be StriCtly positive  or a pair  q   fl   whereE          p  N a   expresses that  p is certain at least to the degree a  i e  N  p   a   and   p err    expresses that  p is possible at least to the degree  i e  IT cp   where rr and N are dual measures of possibility and necessity modelling our incomplete state of knowledge  Zadeh         Dubois and Prade         The right part of a possibilistic formula  i e   N a  or err   is called the valuation of the formula  and is denoted val  p   The basic axiom of a possibility measure IT is fl  p v  p     max  IT  p   IT  cp     on a finite language     on which formulas are defined   Informally  fl  p     means that  p is impossible while IT  p    I means that  p is consistent with current knowledge  Particularly fl  p     when  p is a contradiction  The necessity measure N is defined as N  p       ITCcp   and is such that N  p     p    min N  p  N cp     N  p    means that  p is sure   for instance N  p     when cp is a tautology  Since V  p  N  p v cp      we only have N  p v cp    max N  p  N  p     indeed  for  p    cp  we may have N cp  N  p      i e  IT cp  IT cp        It can be shown that N  p   IT cp   generally  More specifically  IT cp      as soon as N  p       This is due to the axioms that force IT cp v cp      max IT  p  IT cp    When fl  p  IT cp      we capture a state of ignorance about  p  Hence since we use lower bounds on possibility or necessity measures  various cases of relative ignorance can be captured ranging from the case where we know that we do not know  IT  p  rrccp      to the case where we do not know if we know errCcp      TI    p       Let CJ f be the set of all possible valuations of possibilistic formulas  Since N  p      entails TI cp       and the valuations act as lower bounds    p  N a   is stronger than   p err   for any a           this leads us to define the following ordering among valuations    N a   N  iff a    err a  err  iff a    IT a   N  Va  V      Hence the maximal and minimal elements of o  are respectively  N     expressing that a formula is completely                certain  and en     corresponding to the strongest form of ignorance  since fl  p     only   A possibilistic knowledge base is then defined as a finite set  a conjunction  of possibilistic formulae  ff   will denote the set of classical formulae obtained from a set of possibilistic formulae fF  by ignoring the weights  A possibilistic formula whose valuation is of the form  N a   resp  err a   will be called a necessity valued  resp  possibility valued  formula  Let LP    resp  LP   denote the language consisting of only necessity valued formulae  resp  where possibility valued formulae are also allowed        SEMANTICS  UNDER  CONSISTENCY  Let     be a classical language associated with the set ff   of classical formulae obtained from a set fF of possibilistic formulae  and let Q be the set of  classical  interpretations for       Let       be the set of closed formulae of       Then we define a possibility distribution  t as a mapping from Q to       such that   ro E Q  n ro        normalization   This possibility distribution represents the description of an incomplete state of knowledge  such that n ro      means that ro is forbidden while n ro     n ro  means that ro  is an interpretation preferred to ro  The normalization constraint expresses the natural requirement that there should exist at least one fully possible interpretation in Q with respect to a consistent  possibly incomplete  state of knowledge  The possibility measure IT  induced  in the sense of Zadeh         by the possibility distribution  t is the function from      to       defined by V cpE        IT cp   Sup n ro   ro F   p    where ro F   p means  ro is a model of cp   The dual necessity measure N induced by  t is defined by V  pE        N cp        Il   cp   Inf      n ro   ro F    cp     Then  it can be seen that expressing constraints of the form N  p  a or Il cp    is equivalent to specify a set of possibility distributions over Q which are compatible with the corresponding possibilistic formulae  A possibility distribution  t on Q is said to satisfy the possibilistic formula   p  N a    iff N  p  a  where N is the necessity measure induced by n  We shall then use the notation  t F    p  N a    In the same manner  we write  t F    p err   iff Il cp   where IT is the possibility measure induced by l      n  be a set of possibilistic n  Then  let fF    Pi   i    formulae  l i    p i vi   where  p iE      and ViE o   a possibility distribution  t is said to satisfy ff   i e   t F  ff   iff V i           n   t satisfies  l i   Then  a possibilistic formula  l  is said to be a logical consequence of the set of possibilistic formulae fF iff any possibility distribution satisfying fF also satisfies  l   i e  V  t    t F  ff        t F   l    Example  let fF   p  N           pv q  n              Sup    and Inf    denote the least upper bound and greatest lower bound respectively of the subset of real numbers defined between                Lang  Dubois  and Itade   t    ff  iff N p       and fl   p v q       iffinf      t CO   co      p       and Sup  t ro   co      p v q        Let  p  q      p  q    p    q  and    p    q  be the   different interpretations for the propositional language generated by  p  q   where  p  q  gives the value True to p and q  etc    Then  it comes down to  t I  ff iff  t     p  ql            t     p    q             t   p  ql        max   t   p  q     t   p    q          Indeed fl   p          and fl   p v q          max  t   p  q    t   p    q            max  t p   q    t   p  q    t   p    q         max  t p  q    t   p  q    t p   q    t   p    q          t   p    q             t   p      q             t p    q        max  t p  q    t p    q        It is then obvious that ff     q  Il        Indeed  any possibility distribution  t satisfying ff is such that  t   p  ql        and thus verifies fl q    max  t   p  q     t     p  ql          hence  t satisfies  q  Il         It is worth noticing that in LP  there is an equivalence between the consistency of the classical set of formulae ff  and the existence of a greatest normalized possibility distribution  t satisfying ff  as shown in  Dubois et al          Indeed if  t is normalized it can be easily checked that  v  p  min N  p  N    p       where N is defined from  t  in other words it is impossible that there exists  p such that both  p and    p have a strictly positive lower bound for their necessity degrees  i e  that both  p and    p appear in the deductive closure of ff    Our semantics is similar to Nilsson s        probabilistic logic semantics  Indeed this author considers a set of probability distributions on the set of interpretations n  defining probability measures on the set of closed formulas      which are compatible with bounds constraining the probability of formulae in the knowledge base  The notions of logical consequences are similar in both approaches        EXTENDING THE SEMANTICS T O PARTIAL INCONSISTENCIES  Let us first take an example let         p v r  N               q v       r  N         p  N         q  N        It can be checked that  t    y iff  t   p  q  r             t   p  q       r              t   p    q  r              t   p    q    r             t     p  q  r             t     p  q    r             t     p    q  r             t     p    q    r            Sup  t ro   co E Q    I  This set of constraints being unsatisfiable  because of the normalization constraint   there is no possibility distribution over n satisfying       which comes down to say that y is inconsistent  As a consequence  any possibilistic formula is a logical consequence of y   However  it would not be fully satisfactory to define a logic which handles degrees of uncertainty without allowing for degrees of  partial  inconsistency  Indeed  if we consider the above example where we suppose that p  q  and r respectively express  the hostages will be freed   p    Peter is going to be the victim of an affair   q     Peter will be elected   r  respectively  Then the formulas contained in ff express that it is moderate  y certain that if the hostages are freed then Peter will be elected  that it is almost certain that if Peter is victim of an affair then he will not be elected  that it is rather certain that the hostages are going to be freed and that it is weakly certain that Peter will be the victim of an affair  The inconsistency comes from the beliefs of the experts who gave the information stored in the knowledge base  However  the expert who gave the last formula was only weakly certain of what he said  so that the inconsistency should be relativized Since the first three formula of    are strictly more certain than the last one  we would like our logic to behave as if the set of formulas were only partially inconsistent  its inconsistency degree being the valuation of the weakest formula involved in the contradiction   then  the deduction of a formula with a valuation strictly greater than this inconsistency degree should still be permitted   since this deduction would involve only a consistent part of the knowledge base made here of the most certain pieces of information in the example  we should still be able to deduce  r  N       non trivially  this is done inSection    However a conclusion deduced from a partially inconsistent knowledge base should be regarded as more brittle than what is derived from a consistent one  We are now going to give a semantics which handles such partial inconsistencies  The problem with the first semantics is that according to the definition of possibility and necessity measures we have  if  l denotes the contradiction   fl  l    Sup  t ro   OJ     l   Sup       and N  l    Inf l    t CO   co I     l        Sup  t ro   co E Q       Hence the solution requires that non zero values for fl  l  and N  l  be allowed  The solution we propose consists in adding to the set of interpretations Q an extra element  noted OJ  l in which any formula is  true   i e  V  p E   co  Li   p which corresponds to the idea of an  absurd interpretation  discussed by Stalnaker         Let Q l   Q u  OJ Ll A possibility distribution on n  l is a mapping ii from n  l to       such that    CO E Q  l  ii CO    I  normalization over n L  Then we define two functions from  to           induced by  t  fl  p    Sup  t CO       E n l     I   p   N   p    Inf l   n ro   co E Q  l co FF  p   Note that N   p  does not take ii OJ L  into account  while n  p  does   A  A   The idea of adding an extra element to the referential of a possibility distribution has been already used for dealing with the case of an attribute which does not apply to an item of a data base  However the extensions of the possibility and necessity measures which are used for the evaluations of queries in incomplete information databases differ from the extensions defined here   see chapter   of Dubois and Prade           A Logic of Graded Possibility and Certainty Coping wifu Partial Inconsistency  particularly   p    inf l  it ro   ro E Q  ro F    cp   and   l       sup it ro   ro E Q           note also that ro Fj   p is no longer equivalent to ro F    cp  since ro    F   p and ro l F    cp    As it can be easily seen  we have  d  p E  t    n  p    maxm  l   I       p   Note that n and  are not possibility and necessity measures with respect to Q  but only with respect to Q l  We now give the inconsistency tolerant semantics of possibilistic logic  Each possibilistic formula   p  Il a   or   p  N a    is now considered as meaning n  p     a  respectively   p      a   i e  we take into account the absurd interpretation in our understanding of expert statement  For instance    p  IT a   expresses that  it is possible at least to the degree a that either  p is true or we are in an absurd situation   This leads us to the following definitions   s a tisfaction   it    p  I  a   iff n   p      a   it    p  N a   iff   p      a  where nand  are the extended possibility and necessity measures induced by it   it  fF iff it satisfies all formulae of fF     logical consequence   fF   l  iff   lit  it fF implies it   l   The inconsistency tolerant semantics is more general than the first one we introduced  In the case of a consistent possibilistic knowledge base fF  i e   there exists a possibility distribution  t over Q satisfying fF according to the first semantics   then the two logical consequence relations F  and  are equivalent  This is no longer true if fF is inconsistent  this is the property we wished   For instance  let us consider again l J       p v r  N           q v   r  N         p  N         q  N       which is inconsistent according to the first semantics   then  according to the inconsistency tolerant semantics  l J is consistent since we can find a possibility distribution on Q     satisfying l J   For example the possibility distribution   fio defined by  it o   p  q  r   O l   ito   p    q  r              it     p  q  r             ito     p    q  r           it   roj         it    p  q    r            going to show it  we can distinguish between two different types of partial inconsistencies  Let fF be a set of possibilistic formulae   considering the possibility distributions on Q     satisfying fF   three situations may occur     it  fF such that it ro           in this case  fF is  i    ii   consistent in both semantics   fF is then said to be completely consistent  V it  fF  it roj       but   it  fF such that  I   then  for any it satisfying fF   we have n  l     it OO j       and             Sup  it ro   ro   ro       o  Thus fF S u p   it ro    ro  possibility distributions it on Q    satisfying fF gives the inconsistency  degree of fF   Let  a  Inf  n  l    it  fF    then Incons fF     I  a    iii  V it  fF  Sup it  ro   ro   roj        which entails that V it  fF  neroj         In this case  for any it satisfying fF   we have n  l     it OO j       and   l        Sup it ro   ro   OO j     o  Thus fF  induces a   somewhat  necessary inconsistency    the minimal value of        among the possibility distributions it on Q    satisfying fF will give us the inconsistency degree of fF   Let a   Inf   l   it  fF    then Incons fF     N a   fF is thus characterized by its inconsistency degree which is a valuation of the form  I  a  or  N a    if fF is completely consistent then Incons fF      IT     If V it  fF  Sup it ro   ro   ro         then Incons fF      N    and fF is completely inconsistent  If Incons fF     I  a  with a     or Incons fF     N   with    I then fF is partially inconsistent  The following scale shows inconsistencies   see Figure      N     ito     p  q    r           satisfies lJ   Moreover  since y is not inconsistent according to the inconsistency tolerant semantics  any formula can no longer be derived from y contrary to what happened with the first semantics  For example we have lJ   r  N       but we do not have g   r  N         indeed it o  lJ but we do not have no   r  N        Hence the new semantics is definitely more tolerant to inconsistencies than the former one  When a set of possibilistic formulae fF is inconsistent in the sense of the first semantics but not in the sense of the second  then we shall say that fF is partially inconsistent  As we are  roj      induces a  possible inconsistency   contradiction being possible to a strictly positive degree   The minimal value of n  l     it roj   among the  ito   p    q    r            ito     p    q        r               the  hierarchy  of  complete inconsistency   Na  Incons S     partial inconsistency   Il l    I  a   IT     Figure  complete consistency     The knowledge base y gives an example of a degree of inconsistency equal to  N       An example of a knowledge base with a degree of inconsistency of the form  I  a  is given by     p  IT           p  N         Clearly n satisfies    Il p         and N   p            Il p          and Il p            a contradiction in the first semantics  Using the inconsistency tolerant semantics              Lang  Dubois  and frade  we get for W             d WI  p  n   O           and   WI     p  it w      it w j          Hence Incons     TI           inf it w j   under the constraints N  pi      ai  i     m n max   wJ    TI  pj       j j   m             n Since        d  t  ff     k such that TI  pk     k  and Incons ff    k for some k In order to minimize this value  let us maximize it over Q  so as to make the set  j I TI  pj    jl as small as possible  Let it be defined by n w    min     ai   w I   fl i w    OJ       Clearly  it       p i  N ai    i   l  m     wE Q  it w       since there is no inconsistency among the N valued formulas   and  dn    it      p i  N ai     i     m       d wE Q  it  w      it w   The only parameter le ft is it   w        Let  k   max j I I   flj    j  where I  is based on it  Note that the maximality of it over Q minimizes the number of   flj  I  j   with I   flj    j  The examples indicate that the inconsistency degree of a possibilistic knowledge base ff is the valuation of the least formula  in the sense of the ordering in  f  involved in the strongest contradiction in ff  Let wE  f such that I n c o n s   ff     w  It is easy to see that  d  l  E ff   Incons ff     I         w  Let ff   ff such that Incons ff     Incons ff  and  d  I  E ff   Incons ff      l      Incons ff    ff  is called a smallest maximally inconsistent subset of ff  Then the following result holds    Proposition I   The inconsistency of a possibilistic knowledge base ff is the smallest weight of possibilistic formulas in any smallest maximally inconsistent subset ff of ff  More precisely  if Incons ff     N a  then there exists at least one formula   p  N a    E ff  and  d   p  w E ff   w       N a   If Incons ff     I    then there is a unique possibility valued formula in ff  of the form   p  I      Proof  i  Incons   fF     N a   Assume ff      p i  N a i     i     m  u    fl j  I   j   j   m             n   The inconsistency degree is a      SUPw  W j  n w   under the constraints    fl       a   i     m i i n   flj      j j   m              n Since a     n w         and the constraints n   flj       j are ever satisfied  Hence Incons ff      Incons   fli  N ai    i   l  m   The minimality of ff  is thus contradictory with the presence of possibility valued formulas in ff    Thus ff   is of the form    fli  N ai    i     n   By assumption any possibility distribution it satisfying ff  is such that n w         a for all w   w     Assume a    mini    m ai   Let us prove that a    a   t satisfies ff  if and only if  d i  n w         ai   d w I   fl i w   w j    in other words   dit  it ff implies  d w I   fl  v   fl  v  fln it   w        max     a       a   Hence  since i   i   fl   v  fl    v  fl n   T  where T denotes the tautology  otherwise ff  would not be inconsistent    d wE Q  n w          a  is due ton  ff    Hence the inequalitya    a  Now let  t be defined by it w       a  if w     fl     fl    fl n w    OJ   n w          ai if w I   fli w   w    Because  fl     fl     fln  o  l    w  it w       a   and it ff Hencea a    ii  lncons fF      J      It is obvious that ff  contains at least one possibility valued formula  Let us show that it is unique  The inconsistency degree is now of the form    For simplicity assume  k    m   Let us put it w j      m       Then clearly  it  ff    since  d j   m a x   m      I   fl j        j by construction  Thus Incons ff        m    Now   d flj such that TI  pj      j Incons ff       p  I  j      Incons ff     the same thing is true for all  flj such that I   flj    j    m    If there is another formula   fli  I  i   such that i   m   dropping one of these formulas still requires it   O j     m    for ensuring it  ff   Hence  if ff  is really minimal it contains only one possibility valued formula  i e    flm  l   I  m     and Incons ff      I  m     Incons ff  acts as a threshold inhibiting all deductions of ff with a valuation     Incons ff   Indeed  deductions such as ff    p w  where w      Incons ff  are trivial since ff    p w  comes directly from ff   J  w  and the inequalities n   p      n J       p             it easy to check that if for any classical formulae  p and  jf  if  p     jl then n  p      n  j      p         j     On the contrary  deductions with a valuation strictly greater than Incons ff  are not caused by the partial inconsistency   these deductions are called non trivial deductions  Lastly  the following results are easy to prove  Lang          If ff is a set of possibilistic formulae and w a valuation of  f  let us note ff w      p v   v     w  and ff w      p v   v  w    then  i  ff  pw  iff ffw  pw   ii  If Incons ff    w  ff is equivalent to ff w and to ffw u       w       AUTOMATED DEDUCTION IN POSSIBILISTIC LOGIC  Two well known automated deduction methods have been generalized to possibilistic logic   i  resolution  Dubois   A Logic of Graded Possibility and Certainty Coping with Partial Inconsistency  and Prade      a  and ii  the Davis and Putnam semantic evaluation procedure for propositional logic  Lang         Here we focus only on resolution for which we give soundness and completeness results   where R q  c   is a classical resolvent of q and c   and   is defined by  N a     N      N min a      en  if a        N a     IT r t    f     err    if a        err a    en    en             CLAUSAL FORM  In order to extend resolution to possibilistic logic  a clausal form is first defined  A possibilistic clause is a possibilistic formula  c w  where c is a first order or propositional clause and w is a valuation of  V   A possibilistic clausal form is a conjunction of possibilistic clauses  If a possibilistic formula fF contains only necessity valued classical formulae  then there exists a clausal form G of fF such that Incons G    Incons ff   which generalizes the result holding in classical logic about the equivalence between the inconsistency of a set of formulae and the inconsistency of its clausal form  Indeed possibilistic clausal form G of ff can be obtained by the following method  if ff     ljli  N ai    i       n   then put each IPi into clausal form  i e  IPi    V  j Ci j  where C ij is a universally quantified classical clause   then  V  i  j  C ij  N a i     is the possibilistic clausal form equivalent to fF     If fF contains also possibility valued formulae  then generally we cannot compute from fF a clausal form having the same inconsistency degree as fF  even in propositional possibilistic logic  For instance  the closest clausal form we can compute from ff     p   q  IT a        p v   q  N       a      is C      p  TI a     q  TI a       p v   q  N       but it can be checked that Incons ff   ena  whereas Incons G     IT     This negative result comes from the non compositionnality of possibility measures for conjunction  Indeed  p  q ena   is much stronger than  pena     q en a    since  p    q en a   means ncr    q   a  i e    co E Q l such that co    p  q and ii co  a  whereas  p en a       q en a    means  leo  co  E Q l SUCh that co    p  co     q and ii co  a  ii co   a  This problem  also appears in modal logics  Farinas and Herzig  I     and can be similarly solved in our framework by  coloring  the  IT  valuations  We denote respectively by CLPI  resp  CLP   the language consisting in necessity valued clauses only  resp  necessity  and possibility valued clauses        POSSIBILISTIC RESOLUTION RULES  The following possibilistic resolution rule  between two possibilistic clauses  q W I   and  c  w    has been established by Dubois and Prade                CJ w    C  w    R     Indeed  N r i Cij      a is equivalent to min  N Cij      a and thus to   j N c j     a   fF is then equivalent to    i   j  cij  N a       i e   ij  Cij  N a       The similarity between  R  and resolution patterns existing in modal logics has been pointed out   see  Dubois and Prade         The following result can be easily checked Proposition    soundness of rule  R     let G be a set of possibilistic clauses  and C a possibilistic clause obtained by a finite number of successive applications of  R  to C   then C  C  Proof   i  If C    q  N a    C     c   N     the application of rule R yields C   R c l  c    N min a     Then Vrc satisfying C C  we have l l c I   a and N c         and then l l cJ c     min N q  l l c    min a    and finally N R q c       l ci  c    min a    Thus rule R is sound in this case   ii  If C    Cj  N a    C     c  en    rule R yields C     R q c   en a        if a      a        and then trivially C  C   C   If a         Vii satisfying C  C  we have l l q  a and D c      but ncc     max ii co L   Il c     then   either ii co L    and then D R ci  c     and finally ii  C      or ii co L     then ncc     Il c     in this case Il c     max Il   cl c    Il q c  l   but l l q  a entails Il   q   I   a    then Il q c    and DCR ci  c     Il R c l  c     Il q c    and finally ii  C    Then rule  R  is sound         REFUTATION BY RESOLUTION  In this section we consider a set ff of possibilistic formulae  the knowledge base  and a formula ljl   we want to know the maximal valuation with which ff entails  p  i e  Val ff  p   Sup  wE  f  ff    p w    This request can be answered by using refutation by resolution  which is extended to possibilistic logic as follows   Refutation by resolution      Put ff in clausal form C       Put ljl in clausal form   let CJ        C m be the obtained clauses      C   C u   q  N I          en  N         Search for a proof of   l w  with w maximal   by repeatedly applying the resolution rule  R  from C      Val fJ  p    w             Lang  Dubois  and B ade  When the knowledge base consists of both necessity valued and possibility valued formulae  then since the transformation into clausal form is not complete  it does not preserve the inconsistency degree   we shall suppose that  F is a set of possibilistic clauses   in this case  C   ff and step   is omitted  Soundness and completeness results hold for possibilistic resolution  Let ff be a set of possibilistic clauses   p a classical formula  C  the set of possibilistic clauses obtained as explained precedently  Then we have the following results  Proposition   Soundness and completeness of refutation in clausal possibilistic logic    ff     p w      Incons ff         p  N      w or equivalently  Incons ff        p  N        Val ff  p   See the proof in Annex   This result allows us to compute Val ff  p  by proving the inconsistency of ff        p  N       Note that in Proposition   we are not making use of resolution  The two following propositions relate the resolution procedure to the computation of the degree of inconsistency  Proposition   Soundness and completeness of refutation by resolution in LP   Dubois  Lang and Prade          let ff be a set of necessity valued first order formulae and C the set of necessity valued clauses obtained from ff   then the valuation of the optimal refutation by resolution from C  i e  the greatest valuation of the obtained empty clause  is the inconsistency degree of ff   Corollary   let  p be a classical formula and C  the set of possibilistic clauses obtained from ff u      p  N        then the valuation of the optimal refutation by resolution from C  is Val ff  p   This corollary derives immediately from Propositions   and     Prwosition   Soundness and completeness of refutation  by resolution in propositional CLP    if C is a set of propositional necessity  or possibility valued clauses  then  the valuation of the optimal refutation by resolution from C is the inconsistency degree of ff   Corollary   let  p be a classical formula and C  the set of possibilistic clauses obtained from C u      p  N        then the valuation of the optimal refutation by resolution from C  is Val C  p   Proposition   is a consequence of Propositions   and   together with the expression of the resolution rule  N B    Proposition   does not hold for first order possibilistic clauses  for instance  if C     p x   Il a     x being a  universally quantified  variable and a     and  p   p a  A p b   then there is no  Il a  refutation by resolution from C A     p a  v   p b   N       whereas C   p a     p b   I  a    It does not hold either for possibilistic general formulas  since the tranlation into clausal form does not preserve the inconsistency degree if the knowledge base contains possibility valued formulas  Completeness can be recovered by indexing the  IT  symbols in the   Il a  valuations  in the same spirit as in modal logics  Farinas and HeiZig               ILLUSTRATIVE EXAMPLE  We now give an illustrative example  Let C be the following knowledge base  concerning an election whose two candidates are Mary and Peter    Elected Peter  vElected Mary   N     C       Elected Peter  v  Elected Mary   N     C     Former president x  v Elected x   N       C  C   Former president Mary   N I      Supports John x  v Elected x   N       C   Supports John  Mary   I        C  C     Victim of an affair x  v  Elected x   N       We cannot find any refutation from C   hence  C is consistent  i e  Incons C     Il     Let us now find the best possibility or necessity degree of the formula  Elected Mary    Let C   C u     Elected Mary   N       then there exist two distinct refutations by resolution from C   which are     Elected  Mary   N     C                Former president  Mary   N                 N       I OPTIMAL      Elected  Mary   N     C        C       Sup        I        NON OPTIMAL Hence we conclude that C   Elected Mary   N        i e  it is moderately certain that Mary will be elected   this degree  N      is maximal  i e  Val  C  Elected Mary      N       Then  we learn that Mary is being the victim of an affair  which is a completely certain information   This leads us to update the knowledge base by adding to C the possibilistic clause C      Victim of an affair Mary   N      Let C   be the new knowledge base  C    C u  C      Then  we can find a  N      refutation from cl   C  C  C  C               Elected  Mary   N                 Elected  Mary   N                   N        Hence ff  is partially inconsistent  with Incons  CJ     N       The refutation which had given N  Elected Mary       can always be obtained from ff   but since its valuation is not greater than Incons ff J   it has become a trivial deduction    A Logic of Graded Possibility and Certainty Coping with Partial Inconsistency  On the contrary  adding to fF   the possibilistic clause  Elected Mary   N      we find this time a  N      refutation  And  since  N        Incons fF    we have the non trivial deduction fF      Elected Mary   N        and it could be shown that we also have fF    Elected Peter   N        CONCLUSION  Possibilistic logic drastically differs from probabilistic logic since the former is based on the ideas of ordering and preference  only the ordering of numbers is used  while the latter is bsed on the ideas of measure and counting    a logic of incomplete information Possibiiistlc logic Is   more robust than classical logic  because it is that Is tolerant to inconsistency  Besides  as advocated elsewhere possibilistic logic is in full accordance with current theories of belief revision based on epistemic entrenchment  Dubois and Prade      b   and with the principles of non monotonic reasoning  Dubois and Prade         One of the strength of possibilistic logic is that the proof methods in lassical logic still apply  even in the presence of partial mconsistency  and keep all their power  as indicated by the completeness results of this paper  This is would not be the case with a similar probabilistic extension of logic  Moreover efficient strategies for refutation methods have also been implemented  Dubois et a           Current applications of possibilistic logic include hypothetical reasoning  Dubois  Lang and Prade         logic programming  Dubois  Lang and Prade         the automated resolution of combinatorial optimization problems with bottleneck like objective functions  Lang        and belief revision  Among topics for further research is the study of the links between the semantics presented here and the Kripke like semntics previously proposed for necessity and possibility measures by Dubois  Prade and Testemale         Another issue is to bridge the gap between possibilistic logic  especially the handling of possibility degrees  Il a    and the semantics proposed by Yager        in default logic for defaults such as  if p is certain and q is possible then r    It would require to allow for disjunctions of weighted formulas in the language  Acknowledgements  This work is partially supported by the DRUMS project  Defeasible Reasoning and Uncertainty Management Systems   funded by the Commission of the European Commumues under the ESPRIT Basic Research Action Number       
  We propose an integration of possibility the ory into non classical logics  We obtain many formal results that generalize the case where possibility and necessity functions are based on classical logic  We show how useful such an approach is by applying it to reasoning un der uncertain and inconsistent information     IRIT Paul Sabatier     route de Narbonne        Toulouse Cedex France  U niversite  Now  possibility theory brings in something more that should be fruitfully exploited as complementary to such aspects of reasoning  Hence  we study how to integrate possibility theory with non classical logics  Our work comes from the following two facts    even when the involved uncertainty has a possi bilistic nature   classical  possibility theory may not be well suited to the addressed problem  due to shortcomings  not of possibility theory itself but of classical logic  on which possibility theory is defined  For example  some problems require a formalization with a local view of inconsistency  this is impossible with classical possibility theory  we need a paraconsistent approach  cfSection        on the ot her hand  non standard logics su ch as intuitionistic logic  paraconsistent logics       are not expressive enough to express uncertainty in a gradual way   Introduction  Possibility theory has been widely used in Artificial In telligence to represent uncertain knowledge in a more qualitative way than  for example  probability theory  indeed  it is equivalent to work with  quantitative  possibility theory  which means using possibility and necessity measures and possibility distributions  which map formulas or worlds to         or with its qualitative counterpart  where qualitative necessity and possibil ity relations are preorders on the logical language and qualitative possibility distributions are just preorders on the set of worlds   Besides  its connection to vari ous qualitative formalisms in logic and Artificial Intel ligence has been established  notably with epistemic entrenchment relations in  DP  la   conditional logics in  Bou      F HL      System Z in  BDP      The use of possibility theory in Artificial Intelligence covers non monotonic reasoning  DP   b   belief revision  incon sistency handling  inheritance and default rules han dling  temporal reasoning  constraint satisfaction        In Knowledge Representation  many non classical log ics have been used  note that in this paper we consider only non classical logics sharing the same language as classical logic   Each of them was intended for some particular focus  a specific aspect of reasoning  E g  paraconsistent logics have been used to deal with con tradictory knowledge bases  Or  intuitionistic logic has been used to take into account some subtle distinctions between statements involving double negation for ex ample  Or  Kleene s   valued logic  and other many valued logics  has been used to cope with statements for which neither truth nor falsity make sense   These arguments show that it is generally valuable to integrate non classical logics with a numerical theory of uncertainty  Now  the reason why we focus in this paper on possibility theory rather than another theory of uncertainty  is its qualitative nature  as it amounts to a  numerical account  of preordering relations over formulas or worlds   which should make it a priori sim pler to generalize than more quantitative approaches such as probability theory or belief functions  The methodology we follow in this paper consists of going from the general case to the particular case    in Section    we investigate whether  and under which conditions  important properties of possi bility theory remain valid when generalized  We state the results in the most general case to make the study  reusable   though the applications de veloped in Section   focus on paraconsistency     in Section    we take a case study  that is  we choose a paraconsistent logic  namely Ct  and dis cuss more practical applications to reasoning with uncertain and inconsistent information    Research supported by CNRS in proj ect  Gestion de l evolutif et l incertain dans une ba  e de connaissances     Besnard and Lang      Non classical necessity and     possibility functions      Necessity  possibility functions  The natural presentation of necessity and possibility functions  see  Zad     for instance  shows that pos sibility theory consists in meta level definitions over classical logic  which respect completely the structure of classical logic  This suggests that similar functions could be defined on other logics than classical logic  so  replacing   C I   by   C  f   L  where L is a given non classical logic  we can look for a definition of possibility necessity functions on the logic L  We deal with classical propositional  languages  built from a list of propositional variables   sometimes required to be finite    and the connec tives         V         where   L        t   is a shorthand for   L      t   and   L t           The only vary ing parameter is then the consequence relation f L  We now give a generic definition of non classical ne cessity  possibility functions  of which the usual ne cessity  possibility functions correspond to the special case where L is classical logic  Section   deals with the special case where L is the paraconsistent logic Cr    Definition  let  C be a classical propositional language and   L a consequence relation  L being a given  maybe non classical  logic  A L necessity function is a map ping N from  C to        satisfying the following axioms   Taut  if  f   L    N      then        The dual functions of necessity functions are called possibility functions  They can be defined by   axioms about contradiction  equivalence and disjunction   Definition  A L possibility from C to        such that  function is a mapping II   Contr  if   L     then II         Eqn  if l  L       t   then II If     II t     Disj  II   V     max II If    II t     Whatever the logic L  the next property entails  Eq n    Domn  iff L        t   then II  P     II t     Proposition     Domrr  is entailed by  Eqrr  and  Disj  on condition that f  L satisfies    L              Some properties of non classical necessity  possibility functions  W hen L is classical logic   L  possibility functions can be defined from  L  necessity functions by means of  lip E   ll lf        N     r p  and  L  necessity func tions can be defined from  L  possibility functions by V  J E  C N        II      That is   classical  neces sity and possibility functions enjoy the  double  dual ity property   Dl  II is a possibility function iff d n              defined by drr  r p     II     P  is a necessity func tion   D   N is a necessity function iff dN   C           de fined by dN         N      is a possibility func tion      Eq  if   L        t   then N  P    N t     Conj  N      t      min N     N t     When L is classical logic  we recover the classical ne cessity functions  Whatever the logic L is  the follow ing property always entails  Eq    Dom  if f   L  P   t   then N  P     N  t     Some questions we may ask are  how can  D   and  D   carry over to L necessity and L possibility func tions  When are  Dl  and  D   equivalent   Proposition     Dom  is entailed by  Eq  and  Conj   Proposition    if   L  on condition that l L satisfies   Proposition    if L satisfies  f L     J Hence  for all logics  L  fulfilling the latter condition  a as a func tion N   C             satisfying  Taut    Conj    Dom    necessity function can then be characterized    For  the sake of simplicity  we  consid er     p   tra axiom  Contr  if f   p then N for example  in the quantity    but not all  N        reflects    a degree of  partial  inconsistency  Note that requiring  Contr  or not  and the same for  Taut   does not make much difference since  Dam  ensures that contradictions  resp  tautologies  have anyway the lowest  resp  highest  necessity degree  Now  the reason why we require  Taut  and not  Contr  concerns the characterization of necessity functions in terms of possibility distributions       r p        then  D           D          L r p             J       L        t           V    ljJ      f L  tp V    J      r p        p      and the following inference rules    L     only the propo  sitional level throughout the paper    Many definitions of necessity functions include the ex   DLP         J    Llp  tj     J  j  L  f   L        J   L    ljJ      r p  then  D   and  D   hold  Note that among non classical logics admitting         and the above two inference rules  modus ponens and contraposition   there are various relevant logics such as the logic E  AB      Let us now have a look on necessary conditions for having  D    or  D      Proposition    if there exists   such that f L r p and r p then  Dl  does not hold  IfL        Possibility and Necessity Functions over Non Classical Logics  Proposition  and lfL     if there exists I   such that rL  D   does not hold    p then              Next  we investigate a few issues related to the con dition under which a function from C to        can be both a necessity and a possibility function  a truth functional valuation is a fun c tion f from C to        such that there exist two non  Definition   decreasing operators EB and from         to        such that  V p  t J  f  P V t J    f cp  ffi f t J  and    P    t J    f cp    f  P   Definition  a logic L is said to admit trivialisation of truth functional valuations iff any truth functional valuation f satisfying  Dom   i e  f L  p    t J implies f   p   f  t J   we will also say that f is monotonic w r t    L  is a classical valuation  i e  there are two values O  and    such that Vip   IP  E  o l   and f   IP  f  f IP It is well know n that trivialisation of truth functional va luations holds in the case of classical propositional logic   Wes      DP       see also  DP     for a discus sion on the implications of this result   To study the condition under which this property also holds in the case of non classical logics  Je t us consider the follow ing assumptions      r Lip  ipVt J     f  LI  I   J          f L   P           Semantics of L necessity  possibility functions  With the assumption that C is built from a finite number of propositional variables   classic al   neces sity  possibility functions can be semantically defined by means of possibility distributions  a possibility dis tribution  r is simply a fun cti on from the set n of all in  terpretations for L to         The necessity function in duced by  r is defined by N    P    inf    r w   w f    P   with the convention inf       th at we take in all the paper as well as sup         It can then be proved that N is a necessity measure  and that any necessity measure is induced by a possibility distribution  We now turn to the general case of a logic L f or which the class of L m ode ls is wri tten nL   a L possibility distribution is a mapping from h to           It is said to be normalized iff sup v E  i L  r v       Definition   r  In classical logic  due to the equivalence between v li   P   cp  the two following defini ti ons for inducing a C necessity function from a C possibility distribution a re e qui valent   and v f   N cp  N cp   V cp    I        rL   P       j          j      P     f   L  cp V   J       t J V cp  II cp  ll cp   let L be a logic satisfying     to     and f a truth functional valuation mon otonic w  r  t  f L  Then we have ffi   max and    min   Proposition        let L be a logic satisfying     to     and excluded middle  and f a truth functional valua tion on L mo notonic w r t  f  L Then  Vcp f  p       or f   cp       where     sup     P    cp E C   Proposition  Proposition    let L be a logic satisfying         and non contradiction and f a truth functional valuation monotonic w r t      Then Vcp   cp       or f   IP    o where      inf f cp  ip E    Corollary     any logic satisfying     to      excluded middle and non contradi c tion admits trivialisation of truth functional valuations      sup  r v  v   P  sup  r v  v f    P   JI  r       r    a  r       r  are the map pings from  C to        induced from  r by   Definition       r L  cpl t J I      cpi    J        rL  P Vt J Y   cp V t JY     f  L cp V   cp  exc luded middle      f  L    cp    cp   non contradiction  Again  an example of a logic satisfying these properties is the logic E  AB      On the other hand  intuitionistic logic and paraconsistent logics do not      sup  r v  v li  cp     sup  r v  v F   P   Analogously  for p ossibitity functions    P    I        r L I        ft  r  cp  f   r  cp   a  r   P      r  cp         sup  r v  v    sup  r v lv sup  r v  v FL     sup    r  v   I v  L  L cp  FL  P  cp    cp   It is straightforward from these definitions that the following duality properties hold           r   P       ft  r    cp  f   r    P       fa  r  cp   Proposition     if L is such that v  i L cp    v FL   cp  or equivalent y  v L   P    v f  L  P    then     r  cp   fl  r  cp   and     r  cp       r  cp   Proposition     ft is a L necessity function  pro vided that the following conditions hold    if    V    V  then v FL cp for all v  Soundness  FL  P     t J iff   V F L  P         V F tj   F L  P      J iff V FL I   and V F L   J f L cp   Either  v L cp    v I L   cp  or  v L cp    v FL cp  basically amounts to the validity of cp V cp in the logic L        Besnard and Lang  Proposition     h is a   necessity function  pro vided that the following conditions hold   rp then v L   rp for all v v FL rp  c t     iff  v FL   rp       v FL    lj    v FL     rp       J  i ff v FL   rp or v FL   tf Proposition     h is a   possibility function    if I L    pro  vided that the following conditions hold      v L   rp for all v v FL rp  c t     iff  v FL  P       v FL    J  v F L rp V    J iff v F  L cp or v F  L tP if I  L cp then  Proposition     J  is a   possibility function  pro vided that the following conditions hold      f  L  P for all v  Soundness  v FL  P  c t     iff  v FL    P       v FL    lj   v FL     cp V tf  iff v FL   P and v FL     if I L       rp  then  v  L necessity orderings  It has been shown  Dub     that necessity and possi bility functions can be equivalently expressed in purely qualitative terms  with preordering relations  We briefly give a generalization of this result  for the case of necessities  the case for possibilities is similar   Definition  A   necessity ordering is a relation on  C satisfying the following properties   rp                   then rp       transitivity          rp  dominance  or rp    tjJ     J  conjunctiveness     if    if I  L  P       J then  and    rp    tP   rp   Dub      a relation     on C is said to agree strictly with a mapping f from C to        iff Vrp      E  C  we have  P     tP       rp      f    J    Definition  Proposition     correspondence between   necessity functions and   necessity orderings   the only map pings from  C to        agreeing strictly with   necessity orderings and also satisfying  Taut  are   necessity functions      Application to reasoning with uncertain and inconsistent information       Motivations  Possibility theory  as well as its qualitative counter parts such as epistemic entrenchment relations  GM      ranked knowledge bases  Pea     or rational clo sure   eh     provide a relativized treatment of incon sistency  since the latter becomes a gradual notion  I e   a possibilistic knowledge base  D P     consists of a set of constraints KB     cp  ai  i   l  n   where  cp  a   is a syntactic notation for the semantical con straint N rp       a    A possibilistic knowledge base is partially inconsis tent if it leads to enforce N  l       stated oth erwise  the inconsistency degree of K B is defined by Incons KB    maxs KB Sl  min  p a  es a    min N  l   N satisfies KB   Any formula below this level  i e  any rp  where a      Incons KB   is then in hibited  it is  drown  by the inconsistency  BCD P       This shows that the notion of inconsistency in possibilistic logic and its qualitative counterpart is gradual but global  The inconsistency level measures to what extent the knowledge base is inconsistent  but do not locate the inconsistency  The aforementioned  drowning effect  is a consequence of this global treat ment of inconsistency  One way to cope with it is to consider the knowledge base syntactically  Bre      Neb      BCD P      by selecting among maximal sub bases of KB using a criterion involving the a  s  However  these syntactical approaches do not have  yet  any semantics in terms of uncertainty measures  Now  using paraconsistent logics for handling incon sistent knowledge bases enables a local treatment of inconsistency  by locating the inconsistency on some formulas  Yet  these paraconsistent approaches do not allow for any graduality in the inconsistency  which im plies some loss of information if the initial knowledge was pertained with uncertainty  While possibilistic logic allows for a gradual but global treatment of inconsistency  where conflicts are solved only by comparing the uncertainty level of the pieces of information with the inconsistency level of the knowl edge base  the pure paraconsistent approach localizes inconsistency  but conflicts cannot be ranked accord ing to uncertainty  importance  priority  normality as done in rank based systems  Thus paraconsistency is not able to  solve  the conflicts  What we propose here is to apply the results of Section   to a given paraconsistent logic  namely C   daC      to handle both uncertain and inconsistent knowledge  and with a local treatment of inconsistency  We now give two motivating examples  one about fusion of uncertain information  multi source reasoning  and one about reasoning with default rules  Example    multisource reasoning  This example is borrowed from  Cho      Two witnesses report their observations about a mur derer  Witness    noted W   is certain that the mur derer was a woman with blond hair  and believes  with some uncertainty  that she was wearing a Chanel suit  glasses  and was driving a BMW  Witness    noted W   is certain that the murderer was a woman with brown hair and that she was not wearing glasses  and believes  with some uncertainty  that she was driving a Fiat   W  female  sure   blond hair  sure   drives BMW  unsure   wear glasses  unsure   wear Chanel sui t  unsure  W  female  sure   brown hair  sure   drives Fiat  unsure   wear glasses  sure    Possibility and Necessity Functions over Non Classical Logics  What would we like to conclude about the following statements    Both witnesses agree that the murderer was fe male and are completely sure  so we want to con clude the murderer was female     No contradiction either about wear Chanel suit since witness   does not know anything     Strong contradiction about the colour of the mur derer s hair  we wish to conclude neither blond nor brown but we want to keep in mind that these literals are  strongly subject to inconsis tency   knowing the constraint  blond hair    brown hair         Contradiction about wear glasses  the contradic tion is weaker than the one above since witness   is unsure  moreover  since witness   s information is prioritary to witness    s we would like to solve the conflict  by concluding wear glasses   Weak contradiction again  about the car  however  since both witnesses are equally certain  we do not want to conclude anything   Example     drowning effect  Here  applying Pearl s ranking procedure of default rules to          penguin          bird  penguin bird fly  b ird      wings          fly              A case study  C  necessity functions         The paraconsistent logic C   C   daC      is a paraconsistent logic  that is  a logic in which a contradiction  p      IP fails to entail other arbitrary contradictions   J       ljJ cl retains all infer ence patterns of classical logic that are not based on negation  For instance     IP    J   pi  is valid in C   By contrast  some inference patterns of classical logic that do appeal to negation are not preserved  For instance    J  IP     p V  I J  is not valid in C   The idea is that positive informa tion is fundamental  positive formulas and inferences contribute to state what the facts are whereas negative formulas and inferences are merely constraints  in the sense of integrity constraints for databases   Accord ingly  cl allows us to elicit all and only the formulas responsible for a given contradiction   CL      BL       A valuation based semantics for C   Alv     is given in Section       as we now reproduce the original ax iomatic presentation of C  that consists of the next ten axioms     p       J      p       p        J                   J      g ves                     penguin          bird  penguin      fly     bird      fly  bird      wings    Adding the fact penguin to     enables us to infer fly but wings is not deduced  it is  drown  by the incon sistency appearing at rank     This particular case of the drowning effect is known as the property of  in heritance blocking   Considering     as a set of formulas for the logic C   we obtain AU   penguin  f c   fly  fly  wings    Thus  we avoid the drowning effect but we do not take into account priorities  induced by specificity  such as penguin          fly over bird          fly and we conclude that fly is not well behaved  What we would like is to take advantage of the lo calisation of inconsistency  as done by paraconsistent entailment  and the priority between formulas  which would lead us to infer  fly  wings  but not fly  Note that prioritized syntax based approaches based on the selection of maximal consistent subsets of the knowledge base guided by the priorities solve the drowning effect but do not tell anything about where the contradictions are localized  so  for instance  the conclusion wear glasses is not relativised by the fact that it is  weakly  subject to inconsistency       u                     u                    p      J      p  tf    p       p V    J  p       JV p  IP      CT         J                    p V tf                             J                   P    J    J      P v     P                 p  together with the single inference rule   f r   f  C  has the following basic features   First  the con nectives are not interdefinable  For instance   p V    J cannot be defined as     p       J   Second  the re placement of equivalent formulas does not hold  For instance    p v    J          p       jJ              J  is valid in C  but   p V   J               P      J         J  is not  Third   neither modus tollens  p nor disjunctive syllogism     are valid in C           v   J   J  Regarding notation  we use  p  as an abbreviation for       p     p    In the next two sections  we also use   to denote any of     V              Besnard and Lang         C  Mnecessity functions  definition and  basic properties Definition  like for L necessity functions  replacing    L by    c   Some properties enjoyed by C  necessity functions are  Dam  If     c  t p      P   N t p        P then N t p   N   P   N t p   or N t p           N  t p      P   N   P      min N t p   N t p     P                 N   J       min  l  n N  Pi   P   N   t p      min N t p    N t p       J   N t p    if    P   N t p v    J      max N t p   N   P    P   N     t p    N  P    P    Pl        Pn    c    J   P   N t p         P   N   P    J     min N t p    N   P     P   N is a classical necessity function if and only if N t p       for all t p min N  P   N   t p   is the necessity of t p N   t p    behaving badly   it can be seen as a measure of the inconsistency inherent in t p  C  necessity functions en able us to rank the formulas not only with respect to their certainty  but also with respect to their inherent inconsistency  N    Po  gives a notion of inconsistency which is both local and gradual  We recover of course as particular cases         Classical necessity functions  so that N    Po    N  l  for all t p  The notion of inconsistency is still gradual but global  Classical C  valuations  which verify N    t p       or N     t p        for all t p  The notion of inconsis tency is still local but not gradual          C  necessity functions  semantics  At first  a  paraconsistent  Ct valuation  Alv     is a mapping from  C to        such that                 v    IP    v      P          v t p      v  l       v t p        J    v tp      J    I      v IP  v lf        J          v lf       or v   P      v t p                   v tp      and v  I J          v tpV  P          v lf       or v   j       v tp     v  l              v   f   l          v t p               from the set of all C  valuations to          Due to Proposition     the function fi   r  defined  fl  r              sup     v  v          Reasoning with C  Mnecessity functions Generalizing the principle of minimum specificity  The principle of minimum specificity  DP     or equiv alently minimum compact ranking  Pea     and ratio nal closure  Leh       all these being equivalent  up to the language on which they are defined  induces  from a possibilistic knowledge base  a particular necessity function i e  the smallest among all necessity functions satisfying the knowledge base  Thanks to the prop erty  P    we are able to generalize the principle of minimum specificity to C  necessity functions   Definition  a C  possibilistic knowledge base is a fi nite set KB     tp  a         i  n  where if   E  C and a  E     l   A C  necessity function N is said to satisfy KB iff Vi l  n  N lf i       a      Definition  the minimum specificity closure NKB of a  C  possibilistic knowledge base KB is the C  necessity function defined by  Vtj  where KB    E      C  Nxs   P   lf     f   ai      E  sup  BIKB  I  c     J   KB and a            Proposition     principle of minimum specificity for C  necessities   For any Ct necessity function N  N satisfies KB iff N     NxsMore generally  the minimum specificity closure could be extended to any logic L satisfying the property  P    Applying the principle of minimum specificity enables us to draw conclusions that taking into account the uncertainty and the inconsistency of the knowledge base  We propose the following definition of a conse quence relation   Definition  KB f       J iff Nxs     P      Nxs            Proposition     KB f     rP iff Nxs t     Definition  a C  possibility distribution is a mapping  r  We could have also defined C  possibility functions  C  necessity and possibility orderings  that we do not discuss for the sake of brevity  C  necessity functions are sufficient to deal with the next section  devoted to the application to reasoning with uncertain and incon sistent knowledge   as      is a Ct necessity function  since Ct obeys the condi tion stated in Proposition      the soundness of the semantics coming from the soundness and complete ness of C  established in  Alv           Nxs     j     Intuitively  we deduce    J from KB iff the certainty of    J is higher than the inconsistency inherent to    J  or equivalently  iff the certainty of  lj  is higher than the certainty of   The binary version of f    would be defined by if  f   KB    J iff Nxs t p        Nxs l      if    or equivalently iff Nxs t p        Nxs IP       CjJ   Note that f   is nonmonotonic  a more complete study of the properties of f    a Ia Kraus  Lehmann and Magidor  KLM      is possible with respect to the  monotonic  logic cl instead of classical logic  Note that when N collapses to a classical necessity measure  we haveVt  Nx     P     N   L  and f    is the classi cal possibilistic consequence relation  DP    b     Possibility and Necessity Functions over Non Classical Logics   multi source reasoning   let us return to the example of Section      Taking some a E            Example      W   witness     N female       N brown       N BMW    a  N Chanel    a   N glasses    u   W   witness     N female       N   brown       N   BMW   a  N    glasses       The fusion K B of these two knowledge bases gives the following minimum specificity closure    NKB female       NKB   female       NxB   female           NxB brown       NKs   brown      NxB   brown       NxB BMW  u   NxB   BMW   a  NxB Chanel   a  NKB Chanel       NxB Chanel        NxB glasses    a  NKB   glasses     NxB   glasses     a              Therefore  we have K B f    female  K B f    Chanel  KB f      glasses  however  KB lt  BMW  KB lt  BMW  K B lt  brown  K B lt    brown       Therefore  we have K B f    fly  which is intended   K B f      wings  which is intended   f    avoids the drowning effect  contrarily to the classical minimum specificity closure  System Z  and similar systems  but also K B f    live in Antarctica  which is not intended   Due to NKB fly        the rule fly    live in Antarctica applies   Here is a revised definition  more suited to handling default rules  Definition  Let K B   FULl  where F is a set of facts and Ll     Pi        i  i   l  n  a set of default rules  where each rule is assigned a necessity degree corresponding to its Z ranking  We define  G  Ll   FuLl and Vk         ck l Ll  F u    p          E Gk Ll  I NGk f     Pi    NGk f      pi   F u   Pi         E Gk Ll  I Gk Ll   r          k Ll   Then Ll f        iff Lastly  let G   Ll    n  oG kG   Ll   r                    Handling default rules  Example   Consider the fact penguin and the rules      penguin     bird  penguin     fly  bird      fly  bird      wings  fly      live in Antarctica   Applying the Z ranking procedure to Ll  written with the possibilistic ranking convention  gives the ranking   for any a   j  such that     j    a       penguin    bird  penguin        fly  fly       live in Antarctica   f     bird      fly  bird     wings    Lla     Then  taking the C  minimum specificity closure of K B    penguin  U  leads to      NxB penguin       NxB bird  u   NxB fly   a  NKB fly    live in Antarctica   a  NxB fly        NxB fly         NxB wings  j   NxB   live in Antarctica        NKB   bird      NxB   bird        NxB   penguin       NxB    penguin       NxB   wings     NxB wings        NxB live in Antarctica      NKB    live in Antarctica                   Example   We apply the usual ranking procedure       bird     fly  bird      wings  penguin      bird  penguin        fly  fly     live in Antarctica    G   Ll     penguin  bird     fly  bird    wings  penguin      bird  penguin        fly   Clearly  G   Ll    G       Therefore  Ll f    fly  Also  Ll r  bird and    f     wings  Contrastedly  Ll  live in Antarctica     Conclusion  We have given some basic results describing what re mains and what changes when switching from classi cal possibility theory to possibility theory over a non classical logic  We have then focused on a case study  namely the paraconsistent logic C   and showed how to use it to reason with inconsistent and uncertain infor mation  W hat has been left aside in this paper is the other possible applications of possibility theory over non classical logics  first  one could think of applying the general results of Section   to other non classical logics  for instance  introducing possibility and ne cessity valuations into intuitionistic logic could model gradual strengths of proofs  or  introducing them to Kleene s logic  or more generally to a multi valued logic  would enable us to handle both uncertainty and partial truth        Besnard and Lang  Another topic for further research would be a parallel study for other numerical theories of uncertainty  For instance  paraconsistent probabilities would lead to a more quantitative framework for reasoning with un certain and conflictual information  in this framework  noticing that Prob   p    Prob     p    Pro b   p v    p    Prob   pi     p        Prob     p   relaxing the constraint Prob     p       would make P r ob   p    Prob     p      possible for some formulas  then one could think of searching for the  least inconsistent  probability dis tribution satisfying a set of constraints  which could be useful for instance when rectifying a set of inconsistent probabilistic data     
