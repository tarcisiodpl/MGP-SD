 Computing the probability of evidence even with known error bounds is NP hard  In this paper we address this hard problem by settling on an easier problem  We propose an approximation which provides high confidence lower bounds on probability of evidence but does not have any guarantees in terms of relative or absolute error  Our proposed approximation is a randomized importance sampling scheme that uses the Markov inequality  However  a straight forward application of the Markov inequality may lead to poor lower bounds  We therefore propose several heuristic measures to improve its performance in practice  Empirical evaluation of our scheme with stateof the art lower bounding schemes reveals the promise of our approach      Introduction  Computing the probability of evidence even with known error bounds is NP hard  Dagum and Luby         In this paper we address this hard problem by proposing an approximation that gives high confidence lower bounds on the probability of evidence but does not have any guarantees of relative or absolute error  Previous work on bounding the probability of evidence comprises of deterministic approximations  Dechter and Rish        Leisink and Kappen        Bidyuk and Dechter      a  and sampling based randomized approximations  Cheng        Dagum and Luby         An approximation algorithm for computing the lower bound is deterministic if it always outputs an approximation that is a lower bound  On the other hand  an approximation algorithm is randomized if the approximation fails with some probability       The work in this paper falls under the class of randomized approximations   Randomized approximations  Cheng        Dagum and Luby        use known inequalities such as the Chebyshev and the Hoeffding inequalities  Hoeffding        for lower  and upper  bounding the probability of evidence  The Chebyshev and Hoeffding inequalities provide bounds on how the sample mean of N independently and identically distributed random variables deviates from the actual mean  The main idea in  Cheng        Dagum and Luby        is to express the problem of computing the probability of evidence as the problem of computing the mean  or expected value  of independent random variables and then use the mean over the sampled random variables to bound the deviation from the actual mean  The problem with these previous approaches is that the number of samples required to guarantee high confidence lower  or upper  bounds is inversely proportional to the probability of evidence  or the actual mean   Therefore  if the probability of evidence is arbitrarily small  e g            a large number of samples  approximately        are required to guarantee the correctness of the bounds  We alleviate this problem  which arises from the dependence of the Hoeffding and Chebyshev inequalities on the number of samples N  by using the Markov inequality which is independent of N  Recently  the Markov inequality was used to lower bound the number of solutions of a Satisfiability formula  Gomes et al         showing good empirical results  We adapt this scheme to compute lower bounds on probability of evidence and extend it in several ways  First  we show how importance sampling can be used to obtain lower bounds using the Markov inequality  Second  we address the difficulty associated with the approach presented in  Gomes et al         in that with the increase in number of samples the lower bound is likely to decrease by proposing several parametric heuristic methods  Third  we show how the probability of evidence of belief networks with zero probabilities can be efficiently estimated by using the Markov inequality in conjunction with a recently proposed SampleSearch scheme  Gogate and Dechter         Finally  we provide empirical results demonstrating the potential of our new scheme by        GOGATE ET AL   comparing against state of the art bounding schemes such as bound propagation  Leisink and Kappen        and its improvements  Bidyuk and Dechter      b   The rest of the paper is organized as follows  In section    we discuss preliminaries and related work  In section    we present our lower bounding scheme and propose various heuristics to improve it  In section    we describe how the SampleSearch scheme can be used within our lower bounding scheme  Experimental results are presented in section   and we end with a summary in section        Preliminaries and Previous work  We represent sets by bold capital letters and members of a set by capital letters  An assignment of a value to a variable is denoted by a small letter while bold small letters indicate an assignment to a set of variables  Definition     belief networks  A belief network  BN  is a graphical model P   hZ  D  Pi  where Z    Z            Zn   is a set of random variables over multi valued domains D    D            Dn    Given a directed acyclic graph G over Z  P    Pi    where Pi   P Zi  pa Zi    are conditional probability tables  CPTs  associated with each Zi   The set pa Zi   is the set of parents of the variable Zi in G  A belief network represents a probability distribution over Z  P Z    ni   P Zi  pa Zi     An evidence set E   e is an instantiated subset of variables  Definition    Probability of Evidence   Given a belief network P and evidence E   e  the probability of evidence P E   e  is defined as  n  P e       P Z j  pa Z j    E e       Z E j    To compute the probability of evidence by importance sampling  we use the substitution  n  f  x    P z  e      P Z j  pa Z j    E e   j    X   Z E       For the rest of the paper  assume M   P e  and f  x    nj   P Z j  pa Z j    E e   Several choices are available for the proposal distribution Q x  ranging from the prior distribution as in likelihood weighting to more sophisticated alternatives such as IJGP Sampling  Gogate and Dechter        and EPIS BN  Yuan and Druzdzel        where the output of belief propagation is used to compute the proposal distribution  As in prior work  Cheng and Druzdzel         we assume that the proposal distribution is expressed in a factored product form dictated by the belief network  Q X    ni   Qi  Xi  X            Xi      ni   Qi  Xi  Yi    where Yi   X            Xi     Qi  Xi  Yi     Q Xi  X            Xi    and  Yi     c for some constant c  When Q is given in a product form   we can generate a full sample from Q as follows  For i     to n  sample Xi   xi from the conditional distribution Q Xi  X    x            Xi    xi    and set Xi   xi   This is often referred to as an ordered Monte Carlo sampler       Related Work   Dagum and Luby        provide an upper bound on the number of samples N required to guarantee that for any b computed using Equation   ap         the estimate M proximates M with relative error  with probability at least       Formally  b  M               Pr M        M       The specific bound on N that the authors derive is  The notation h Z  E e stands for a function h over Z   E with the assignment E   e       N  Importance sampling  Rubinstein        is a simulation technique commonly used to evaluate the following sum  M   xX f  x  for some real function f   The idea is to generate samples x            xN from a proposal distribution Q  satisfying f  x       Q x       and then estimate M as follows   b    M N  N   w xi     where  i    w xi      f  xi   Q xi        ln M          These bounds were later improved by  Cheng        to yield   Computing Probability of Evidence Using Importance Sampling  f  x  f  x  Q x    EQ     M    f  x     Q x  Q x  xX xX  N            w is often referred to as the sample weight  It is known b   M  Rubinstein         that the expected value E M         ln M        ln                 In both these bounds  Equations   and    N is inversely proportional to M and therefore when M is small  a large number of samples are required to achieve an acceptable confidence level               A bound on N is required because  Dagum and Luby        Cheng        use Chebyshev and Hoeffding inequalities which depend on N for correctness  Instead  we could use the Markov inequality which is independent of N and still achieve high confidence lower bounds  The independence from N allows us to use even a single sample to derive lower bounds  The only caveat is that our proposed method does not have any guarantees in terms of relative error    We describe our method in the next section    GOGATE ET AL      Markov Inequality to lower bound P e   Definition    Markov Inequality   For any random variable X and k      Pr X  kE X     k  Gomes et al         show how the Markov inequality can be used to obtain probabilistic lower bounds on the number of solutions of a satisfiability constraint satisfaction problem  Using the same approach  we present a small modification of importance sampling for obtaining lower bounds on the probability of evidence  see Algorithm     The algorithm generates k independent samples from a proposal  x  distribution Q and returns the minimum fQ x   minCount in Algorithm    over the k samples  Algorithm   Markov LB   f   Q  k                           minCount   for i     to k do Generate a sample xi from Q f  xi   IF minCount    Q xi   THEN minCount   end for Return minCount  f  xi    Q xi    T HEOREM    Lower Bound   With probability of at least       k   Markov LB returns a lower bound on M   P e  Proof  Consider an arbitrary sample xi   It is clear from the discussion in section   that the expected value of f  xi   Q xi   is equal to M  Therefore  by the f  xi   Pr   Q x i   Markov inequality  we have   M         Since  the generated k samples are independent  the f  xi   k probability Pr minki    Q x i     M       and therefore i  f  x     Pr minki      Q x i      M        k    The problem with Algorithm   is that unless the variance of f  x  Q x  is very small  we expect the lower bound to decrease with increase in the number of samples k  In practice  given a required confidence of     k   one can decrease  as k is increased  Note that each sample in Algorithm   provides a lower bound with probability             We can replace the sample by any procedure that provides a lower bound with probability            and therefore in the following we propose several heuristic methods to compute a lower bound with probability                            Using the maximum over N samples  We can even use the maximum instead of the average over the N i i d samples and still achieve a confidence of         Given a set of N independent events such that each event occurs with probability             the probability that all events occur is           N   Consequently  we can prove that  Proposition    Given N i i d  samples generated from Q   xi   N Pr maxNi     fQ x i       M               Therefore  by setting         N          i e                     N    and recording the maximum value of f  xi    Q xi   over the N samples  we can achieve a lower bound on M with confidence           Again the problem with this method is that increasing the number of samples increases  and consequently the lower bound decreases  However  when the variance of the random variables f  xi   Q xi   is large  the maximum value is likely to be larger than the sample average  Another approach to utilize the maximum over the N samples is to use the martingale inequalities       Using the martingale Inequalities  In this subsection  we show how the martingale theory can be used to obtain lower bounds on P e   Definition    Martingale   A sequence of random variables X            XN is a martingale with respect to another sequence Z            ZN defined on a common probability space  iff E Xi  Z            Zi      Xi  for all i  Given i i d  samples  x            xN   generated from Q  note i  p f  x   that the sequence             N   where  p   i   MQ xi   forms a martingale as shown below   E  p  x           x p     E  p      p  f  x     p         E  MQ x p    x           x  Because   we  have   x            x p     E  p    p  as required  The expected value E         and for such martingales which have a mean of     Breiman        provides the following extension of the Markov inequality  Pr maxN i   i        Using Average over N samples  One obvious way is to use the importance sampling estimab Because E M  b   M  by Markov inequality M  b  is a tor M  lower bound of M with confidence         As the number of samples increases  the average becomes more stable and is likely to increase the minimum value over the k iterations of Algorithm     f  x p    x           x p    M  Q x p   f  x p    p   E   x           x p    M  Q x p                and therefore  i  f  x j            j  MQ x  j    Pr  maxN i          From Inequality    we can see that f  x j     i   i N maxi       j     Q x j      is a lower bound on M with a        GOGATE ET AL   confidence of           In general one could use any randomly selected permutation of the samples  x            xN   and apply inequality    Another related extension of Markov inequality for martingales deals with the order statistics of the sample  Let f  x      MQ x        N        f  x   f  x    MQ x               MQ x N    be the order statistics of the sample  Using martingale theory   Kaplan        proved that the random variable  f  x N j       i     maxN i     j    N  i  M  Q x N j        satisfies the inequality Pr             Therefore  f  x N j       i  Pr  maxN i     j    From maxNi        M  Q x N j        Inequality       f  x N j      ij     Q x N j      N     i      N  i  we is          can a            see  that  lower  bound  i  on M with a confidence of           To summarize in this section  we have proposed four heuristic ways to improve Algorithm       The average method      The max method and     The martingale random permutation method and     The martingale order statistics method      In the following example  we show how constraints can be extracted from the CPTs   Overcoming Rejection  Using SampleSearch with Markov LB  One problem with importance sampling based algorithms is the so called rejection problem and in this section we discuss how to alleviate this problem in MarkovLB by using the recently proposed SampleSearch scheme  Gogate and Dechter              The rejection problem has been largely ignored in the importance sampling community except the work on adaptive importance sampling techniques  Hernandez et al         Cheng and Druzdzel        Yuan and Druzdzel         In  Gogate and Dechter         we initiated a new approach of reducing the amount of rejection by using constraint processing methods  The main idea is to express the zero probabilities in the belief network using constraints  Definition    constraint network   A constraint network  CN  is defined by a   tuple  R   hZ  D  Ci  where Z is a set of variables Z    Z            Zn    associated with a set of discrete valued domains  D    D            Dn    and a set of constraints C    C           Cr    Each constraint Ci is a relation RSi defined on a subset of variables Si  Z  The relation denotes all compatible tuples of the cartesian product of the domains of Si   A solution is an assignment of values to all variables z    Z    z            Zn   zn    zi  Di   such that z belongs to the natural join of all constraints i e  z  RS          RSr   The constraint satisfaction problem  CSP  is to determine if a constraint network has a solution  and if so  to find one  When we write R z   we mean that z satisfies all the constraints in R   Rejection Problem  Given a positive belief network that expresses the probability distribution P Z    ni   P Zi  Z            Zi    and an empty evidence set  all full samples generated by the ordered Monte Carlo sampler along the ordering Z            Zn are guaranteed to have a non zero weight  However  in presence of both zero probabilities and evidence the ordered Monte Carlo sampler may generate samples which have zero weight because the sample may conflict with the evidence and zero probabilities  Formally  if the proposal distribution Q is such that the probability of sampling an assignment from the set  x  f  x       is substantially larger than the probability of sampling an assignment from the set  x  f  x        a large number of samples generated from Q will have zero weight  In fact  in the extreme case if no positive weight samples are generated  the lower bound reported by the Markov LB scheme will be trivially zero   Figure    An example Belief Network  Example    Figure   presents a belief network over   binary variables  The CPTs associated with C and G have zero probabilities  The constraint extracted from the CPT of C is the relation RA C                            while the CPT of G yields the constraint relation RD F G                                               Namely  each   tuple in a CPT corresponds to a no good  and therefore does not appear in the corresponding relation  Our importance sampling scheme called IJGP Sampling  Gogate and Dechter        uses constraint propagation to reduce rejection  Given a partial sample  x            x p    constraint propagation prunes values in the domains of future variables Xp             Xn which are inconsistent with  x            x p    However  we observed recently that when a substantial number of zero probabilities are present or when   GOGATE ET AL  there are many evidence variables  the level of constraint propagation achieved by IJGP is not effective and often few no consistent samples will be generated  Therefore in  Gogate and Dechter         we proposed a more aggressive approach that searches explicitly for a non zero weight sample yielding the SampleSearch scheme  Algorithm   SampleSearch Input  The proposal distribution Q x    ni   Qi  xi  x           xi     hard constraints R that represent zeros in f  x  Output  A sample x    x           xn   satisfying all constraints in R    i      Di   Di  copy domains   Qi  Xi     Qi  Xi    copy distribution   x       while    i  n do    if Di is not empty then    Sample Xi   xi from Qi and remove it from Di    if  x           xi   violates any constraints in R then    set Qi  xi  x           xi        and normalize Qi    Goto Step      end if    x   x  xi   i   i      Di   Di   Qi  Xi  x           xi      Qi  Xi  x           xi        else     x   x xi        set Qi   Xi    xi   x           xi        and normalize      set i   i        end if     end while     Return x       The SampleSearch scheme  An ordered Monte Carlo sampler samples variables in the order hX            Xn i from the proposal distribution Q and rejects a partial or full sample  x            xi   if it violates any constraints in R  R models zero probabilities in f    Upon rejecting a  partial or full  sample  the sampler starts sampling anew from the first variable in the ordering  Instead  we propose the following modification  We can set Qi  Xi   xi  x            xi         to reflect that  x            xi   is not consistent   normalize Qi and re sample Xi from the normalized distribution  The newly sampled value may be consistent in which case we can proceed to variable Xi   or it may be inconsistent  If we repeat the process we may reach a point where Qi  Xi  x            xi    is   for all values of Xi   In this case   x            xi    is inconsistent and therefore we need to change the distribution at Xi  by setting Qi   Xi    xi   x            xi         normalize and resample Xi    We can repeat this process until a globally consistent full sample that satisfies all constraints in R is generated  By construction  this process always yields a globally consistent full sample  Our proposed SampleSearch scheme is described as Algorithm    It is a depth first backtracking search  DFS  over the state space of consistent partial assignments searching for a solution to a constraint satisfaction problem R  whose value selection is guided by Q        It can be proved that SampleSearch generates independently and identically distributed samples from the backtrack free distribution which we define below  Definition    Backtrack free distribution    Given a distribution Q X    Ni   Qi  Xi  X            Xi     an ordering O   hx            xn i and a set of constraints R  the backtrack free distribution QR is the distribution  n  QR  x     QRi  xi  x           xi           i    where QRi  xi  x            xi    is given by  QRi  xi  x           xi       Qi  xi  x           xi       xi Bi Qi  xi  x           xi           where Bi    xi  Di   x            xi    xi   can not be extended to a solution of R  and xi    Bi   Note that by definition  f  x       QR  x      and vice versa   T HEOREM     Gogate and Dechter        SampleSearch generates independently and identically distributed samples from the backtrack free distribution  Given that the backtrack free distribution is the sampling distribution of SampleSearch  we can use SampleSearch within the importance sampling framework as follows  Let  x            xN   be a set of i i d samples generated by SampleSearch  Then we can estimate M   xX f  x  as  N i b      f  x   M N i   QR  xi          Although SampleSearch was described using the naive backtracking algorithm  in principle we can integrate any systematic CSP SAT solver that employs advanced search schemes with sampling through our SampleSearch scheme  Since the current implementations of SAT solvers are very efficient  we represent the zero probabilities in the belief network using cnf  SAT  expressions and use Minisat  Sorensson and Een        as our SAT solver  Computing QR  x  given a sample x  From Definition    we notice that to compute the components QRi  xi  x            xi    for a sample x    x            xn    we have to determine the set Bi    xi  Di   x            xi    xi   can not be extended to a solution of R   The set Bi can be determined by checking for each xi  Di if the partial assignment  x            xi    xi   can be extended to a solution of R  To speed up this checking at each branch point  we use the Minisat SAT solver  Sorensson and Een         Minisat should be invoked a maximum of O n   d      times where n is the number of variables and d is the maximum domain size  In  Gogate and Dechter         we found that the SampleSearch based importance sampling scheme outperforms all competing approaches when a substantial number of zero        GOGATE ET AL   probabilities are present in the belief network  Therefore  we employ SampleSearch as a sampling technique within Markov LB when a substantial number of zero probabilities are present  It should be obvious that when Samplei Search is used  we should use QfR x x i   as a random variable instead of         f  xi   Q xi    P c         cq   e   q    C   for a polynomial number of partially instantiated tuples of subset C  resulting in  h  k  i    i    L P e    P ci   e     PBP  ci         ciq   e         L  c        c   e  is obtained using where lower bound PBP q   bound propagation  Although bound propagation bounds marginal probabilities  it can be used to bound any joint probability P z  as follows   in the Markov LB scheme   Empirical Evaluation Competing Algorithms  L L PBP  z     PBP  zi  z         zi           i  Markov LB with SampleSearch and IJGP sampling  The performance of importance sampling based algorithms is highly dependent on the proposal distribution  Cheng and Druzdzel        Yuan and Druzdzel         It was shown that computing the proposal distribution from the output of a Generalized Belief Propagation scheme of Iterative Join Graph Propagation  IJGP  yields better empirical performance than other available choices  Gogate and Dechter         Therefore  we use the output of IJGP to compute the proposal distribution Q  The complexity of IJGP is time and space exponential in its i bound  a parameter that bounds cluster sizes  We use a i bound of   in all our experiments  The preprocessing time for computing the proposal distribution using IJGP  i      was negligible      seconds for the hardest instances   We experimented with four versions of Markov LB  a  Markov LB as given in Algorithm     b  Markov LB with the average heuristic   c  Markov LB with the martingale random permutation heuristic and  d  Markov LB with the martingale order statistics heuristic  In all our experiments  we set      and k     which gives us a correctness confidence of                on our lower bounds  Finally  we set N       for the heuristic methods  Also note that when the belief network is positive we use IJGP sampling but when the belief network has zero probabilities  we use SampleSearch whose initial proposal distribution Q is computed from the output of IJGP  Bound Propagation with Cut set Conditioning We also experimented with the state of the art any time bounding scheme that combines sampling based cut set conditioning and bound propagation  Leisink and Kappen        and which is a part of Any Time Bounds framework for bounding posterior marginals  Bidyuk and Dechter      a   Given a subset of variables C  X E  we can compute P e  exactly as follows  k  P e     P ci   e         i    The lower bound on P e  is obtained by computing P ci   e  for h high probability tuples of C  selected through sampling  and bounding the remaining probability mass by computing a lower bound PL  c         cq   e  on  L  z  z        z where lower bound PBP i   i    is computed directly by bound propagation  We use here the same variant of bound propagation described in  Bidyuk and Dechter      b  that is used by the AnyTime Bounds framework  The lower bound obtained by Eq     can be improved by exploring a larger number of tuples h  After generating h tuples by sampling  we can stop the computation at any time after bounding p   k out of k partially instantiated tuples and produce the result   In our experiments we run the bound propagation with cutset conditioning scheme until convergence or until a stipulated time bound has expired  Finally  we should note that the bound propagation with cut set conditioning scheme provides deterministic lower and upper bounds on P e  while our Markov LB scheme provides only a lower bound and it may fail with a probability               Evaluation Criteria We experimented with six sets of benchmark belief networks  a  Alarm networks  b  CPCS networks   c  Randomly generated belief networks   d  Linkage networks   e  Grid networks and  f  Two layered deterministic networks  Note that only linkage  grid and deterministic networks have zero probabilities  On each network instance  we compare log relative error between the exact probability of evidence and the lower bound reported by the competing techniques  Formally  if Pexact is the actual probability of evidence and Papp is the approximate probability of evidence  we compute the logrelative error as follows     Abs   log Pexact    log Papp     log Pexact          Note that the exact P e  for most instances is available from the UAI competition web site     The exact P e  for the two layered deterministic networks was computed using AND OR search  Dechter and Mateescu         We compute the log relative error instead of the usual relative error because when the probability of evidence is   http   ssli ee washington edu bilmes uai  InferenceEvaluation    GOGATE ET AL   Table    Results on various benchmarks  The columns Min  Avg  Per and Ord give the log relative error  for the minimum  the average  the martingale random permutation and the martingale order statistics heuristics respectively  The last two columns provide log relative error  and time for the bound propagation with cut set conditioning scheme  In the first column N is the number of variables  D is the maximum domain size and E is the number of evidence variables  Time is in seconds  The column best LB reports the best lower bound reported by all competing scheme whose log relative error is highlighted in each row    N  D   E   Alarm                                                        CPCS                                                                                         Random                                                     Exact P e   IJGP sampling Markov LB Bound Min Avg Per Ord Propagation     Time  Time  Best LB     E       E       E       E       E                                                                                                                                                                                                              E       E       E       E       E        E       E       E       E       E       E       E       E                                                                                                                                                                                                                                                                                                                                E       E       E       E       E       E       E       E                                                                                                                                                 SampleSearch Markov LB Exact Min Avg Per Ord P e      Time     E       E       E       E       E                                                         Bound Propagation  Time   N  D   E   Grid                 E                                                      E                                                      E                                                      E                                                      E                                                      E                                      Linkage                E                                                       E                                                        E                                                         E                                                         E                                                       E                                                       E                                                        E                                                          E                                       Two layered                 E                                                       E                                                      E                                                      E                                                       E                                           E       E       E       E       E    Best LB                               E       E       E       E       E       E                                                      E       E       E        E        E        E       E        E        E                                  E       E       E       E       E     extremely small the relative error between the exact and the approximate probability of evidence will be arbitrarily close to   and we would need a large number of digits to determine the best performing competing scheme       Results  Our results are summarized in Table    We see that our new strategy of Markov LB scales well with problem size and provides good quality high confidence lower bounds       on most problems  It clearly outperforms the bound propagation with cut set conditioning scheme  We discuss the results in detail below  The Alarm networks The Alarm networks are one of the earliest belief networks designed by medical experts for monitoring patients in intensive care  The evidence in these networks was set at random  These networks have between         binary nodes  We can see that Markov LB is slightly superior to the bound propagation based scheme accuracy wise  but is far more efficient time wise  Among the different versions of Markov LB  the average heuristic performs better than the martingale heuristics  The minimum heuristic is the worst performing heuristic  The CPCS networks The CPCS networks are derived from the Computer based Patient Case Simulation system  Pradhan et al          The nodes of CPCS networks correspond to diseases and findings and conditional probabilities describe their correlations  The CPCS   b and CPCS   b networks have     and     variables respectively  We report results on the two networks with          and    randomly selected evidence nodes  We see that the lower bounds reported by the bound propagation based scheme are slightly better than Markov LB on the CPCS   b networks but they take far more time  However  on the CPCS   b networks  Markov LB has better performance than the bound propagation based scheme  The martingale heuristics  the random permutation and the order statistics  have better performance than the average heuristic  Again  the minimum heuristic has the worst performance  Note that we stop each algorithm after   mins of run time if the algorithm has not terminated by itself  Random networks The random networks are randomly generated graphs available from the UAI competition website  The evidence nodes are generated at random  The networks have between    and    nodes and the maximum domain size is     We see that Markov LB is better than the bound propagation based scheme on all random networks  The random permutation and the ordered statistics martingale heuristics are slightly better than the average heuristic on most instances  Grid Networks The Grid instances are also available from the UAI competition web site  All nodes in the Grid are binary and evidence nodes are selected at random  The Grid networks have substantial amount of determinism and therefore we employ the SampleSearch based importance sampling scheme to compute the lower bound  Here  we stop each algorithm after    minutes if it has not terminated by itself  We notice that the performance of MarkovLB is significantly better than the bound propagation based scheme on all instances  Linkage networks The linkage instances are generated by converting a Pedigree to a Bayesian network  Fishelson and Geiger         These networks have be         GOGATE ET AL   tween          nodes with a maximum domain size of    and are much larger than the Alarm  the CPCS  and the random networks  On these networks  we ran each algorithm until termination or until a time bound of  hr expired  The Linkage instances have a large number of zero probabilities which makes them hard for traditional importance sampling based schemes because of the rejection problem  Therefore  in all our experiments on linkage instances we used the SampleSearch based importance sampling scheme  On Linkage instances  IJGP sampling did not return a single non zero weight sample  not shown in Table    in more than one hour of run time yielding a lower bound of    We see that the bound propagation based scheme yields inferior lower bounds as compared to the SampleSearch based Markov LB scheme  However  we notice that the log relative error is significantly higher for Markov LB on the linkage instances than the Alarm  the CPCS  and the random instances  We suspect that this is because the quality of the proposal distribution computed from the output of IJGP is not as good on the linkage instances as compared to other instances  Finally  we notice that the average and the martingale heuristics perform better than the min heuristic on all instances with the martingale order statistics heuristic being the best performing heuristic   using the SampleSearch scheme  Our experimental results on a range of benchmarks show that our new lower bounding scheme outperforms the state of the art bound propagation scheme and provides high confidence good quality lower bounds on most instances   Deterministic two layered networks Our final domain is that of completely deterministic two layered networks  Here  the first layer is a set of root nodes connected to a second layer of leaf nodes  The CPTs of the root node are such that each value in the domain is equally likely while the CPTs associated with the leaf nodes are deterministic i e  each CPT entry is either one or a zero  All nodes are binary  The evidence set is all the leaf nodes instantiated to a value  We experimented with   randomly generated      variable two layered networks each with     leaf nodes which are set to true  evidence   We employ the SampleSearch based importance sampling scheme for these networks because these instances have zero probabilities  We see that the average and the martingale heuristics are the best performing heuristics while the min heuristic performs the worst  The SampleSearch based Markov LB scheme shows significantly better performance than the bound propagation based scheme    Dechter and Mateescu        Dechter  R  and Mateescu  R          Mixtures of deterministic probabilistic networks and their and or search space  In UAI      Conclusion and Summary  In this paper  we proposed a randomized approximation algorithm  Markov LB for computing high confidence lower bounds on probability of evidence  Markov LB is based on importance sampling and the Markov inequality  A straight forward application of the Markov inequality may lead to poor lower bounds and therefore we suggest various heuristic measures to improve Markov LBs performance  We also show how the performance of Markov LB can be improved further on belief networks with zero probabilities by  ACKNOWLEDGEMENTS This work was supported in part by the NSF under award numbers IIS         and IIS           
  width of the network whose instantiated variables  evidence and sampled  are removed   The paper extends the principle of cutset sampling over Bayesian networks  presented previously for Gibbs sampling  to likelihood weighting  LW   Cutset sampling is motivated by the Rao Blackwell theorem which implies that sampling over a subset of variables requires fewer samples for convergence due to the reduction in sampling variance  The scheme exploits the network structure in selecting cutsets that allow efficient computation of the sampling distributions  In particular  as we show empirically  likelihood weighting over a loop cutset  abbreviated LWLC   is time wise cost effective  We also provide an effective way for caching the probabilities of the generated samples which improves the performance of the overall scheme  We compare LWLC against regular liklihood weighting and against Gibbsbased cutset sampling   We defined previously an efficient parametrized Gibbs cutset sampling scheme  called w cutset sampling         where the complexity of generating a single sample is bounded exponentially by w  In this paper  we extend the cutset sampling principle to likelihood weighting  LW            which is a form of importance sampling       focusing on sampling from a loop cutset  The resulting scheme  which we call LWLC  computes a sample over a loop cutset C in O   C     E    N    where E is evidence and N is the size of the input network  While we present our scheme for LW  it is applicable to other importance sampling schemes   Introduction  Stochastic sampling is a popular approach for estimating answers to Bayesian queries when exact inference is intractable  Based on the generated samples  we can obtain estimates that converge to the exact values as the number of samples increases  However  convergence may be slow in large networks due to increase in sampling variance  This is the problem we address in this paper  Based on Rao Blackwell theorem  we can reduce sampling variance and speed up convergence by sampling only a subset of the variables  a cutset   However  the efficiency of sampling from lower dimensional spaces is hindered by the overhead of computing the sampling distributions  The latter is equivalent to performing exact inference which is exponential in the induced  While both cutset schemes  one based on Gibbs sampling and one based on likelihood weighting  exploit the network structure to manage the complexity of exact inference  they compute different sampling distributions  Gibbs sampler draws a new value of variable Xi from distribution P  Xi  x xi    Likelihood weighting samples a new value from P  Xi  x         xi     Furthermore  while both schemes benefit from reducing the size of the sampling space  it is hard to predict which of the two schemes is superior  The convergence speed of Gibbs sampling depends on the maximum correlation between the sampled variables  The convergence of likelihood weighting is affected by the distance between the sampling and the target distributions and  thus  depends also on the nature of evidence  Finally  Gibbs estimates converge only when all Markov Chain transition probabilities are positive  The advantages of cutset based importance sampling  also known as Rao Blackwellised importance sampling  were demonstrated previously in a few special cases            Our scheme automates the cutset selection process based on the Bayesian network structure  We demonstrate empirically that LWLC is efficient timewise and has a lower rejection rate in networks with determinism  We achieve additional improvements by caching the probabilities of the generated samples    Our scheme can be generalized to other importance sampling schemes      Background  Definition      belief networks  Let X  X         Xn   be a set of random variables over multi valued domains D X          D Xn    A belief network is a pair  G  P  where G is a directed acyclic graph on X and P  P  Xi  pai   Xi  X  is the set of conditional probability tables  CPTs   conditioned on parents pai of Xi   An evidence e is an instantiated subset of variables E  A network is singlyconnected  also called a poly tree   if its underlying undirected graph has no cycles  Otherwise  it is multiply connected  Definition      loop cutset  A loop in G is a subgraph of G whose underlying graph is a cycle  A vertex v is a sink with respect to a loop L if the two edges adjacent to v in L are directed into v  Every loop contains at least one vertex that is not a sink with respect to that loop  Each vertex that is not a sink with respect to a loop L is called an allowed vertex with respect to L  A loop cutset of a directed graph G is a set of vertices that contains at least one allowed vertex with respect to each loop in G  The queries over a singly connected network can be processed in time linear in the size of the network       In general  the complexity of queries can be reduced by restricting G to a relevant subnetwork  Definition      Relevant Subnetwork  A variable Xi in DAG G over X is irrelevant  barren  w r t  a subset ZX if Xi Z   and Xi only has irrelevant descendants  if any   The relevant subnetwork of G w r t  a subset Z is the subgraph of G obtained by removing all variables that are irrelevant w r t Z       Likelihood Weighting  Likelihood weighting          belongs to a family of importance sampling schemes that draw independent samples from a trial distribution Q X   The trial distribution is different from the target distribution P  X   Generally  Q X  is selected so that it is easy to compute  A typical query in Bayesian networks is to estimate the posterior marginals P  xi  e  which can be obtained from the sampling estimates of P  e  and P  xi   e   Let Y   X E  Then   Consequently  the sampling estimate P  e  of P  e   based on T samples from Q X   is obtained by  P  e     T T   X  t    X P  y  t    e    w T t   Q y  t    T t          t    y  e   t    In a where w t    PQ y  t    is the weight of sample y similar manner  but counting only those samples where Xi   xi   we can obtain an expression for the sampling estimate P  xi   e  of P  xi   e  for Xi  X E by  PT P  xi   e    T  t   w t   xi   x t         t   where  xi   x t      iff xi  xi and  xi   x t      otheri  e  wise  Since P  xi  e    PP x e    we get  PT  T X w t   xi   x t    w t   xi   x t      PT  t  w t   t       where  is a normalization constant  These sampling estimates are guaranteed to converge to their target values as T increases as long as the support for Q X  includes all support for P  X   Namely  the condition x  X  P  x        Q x       must hold  Eq      yields a biased estimate of P  xi  e   However  when the sample size is large enough  bias can be ignored        P  xi  e     t    Likelihood weighting draws samples from a distribution Q X  that is close to the prior distribution  It begins with a network without evidence and assigns values to nodes in topological order  First  root nodes are sampled from their prior distributions  Then  the values of all other nodes Xi X E are sampled from the distribution P  Xi  pai    Evidence variables Ei E are assigned their observed value  Thus  the sampling distribution of likelihood weighting can be described as follows  Q Q X    Xi X E P  Xi  pai    E e     We therefore compute the weight w t  of sample t by  Q  t   t  P  x t    Xi X P  xi  pai    t        w   Q  t   t  Q x t    P  x  pa   Xi X E  i  i  All factors in the numerator and denominator of the fraction cancel out except for P  ei  pai    leaving  w t     Q   t   Ei E  P  ei  pai         Thus  during sampling  we compute the weight w t  of sample t by initializing w t    and updating  t  w t  w t   P  ei  pa   whenever we encounter an eviX X P  y  e  P  y  e  dence E   e   Thei posterior marginals estimates are i i Q y    EQ     EP  P  e     P  y  e    Q y  Q y  obtained by plugging the sample weights in Eq      y y   The convergence of importance sampling schemes can be slow when Q X  is very different from P  X   Consequently  many importance sampling schemes focus on finding an improved sampling distribution by either changing the variable sampling order      or updating the sampling distribution based on previously generated samples              We can also improve convergence by reducing the dimensionality of the sampling space as implied by Rao Blackwell theorem      Rao Blackwellised Likelihood Weighting  Give a Bayesian network over a set of variables X with evidence EX  E e  S let CX E be a subset of variables in X  Z C E  and m  Z   Let o  Z         Zm   be a topological ordering of the variables  We can define likelihood weighting over Z as follows  Processing variables in order o  we sample value z  from distribution P  Z     z  from P  Z   z     and so on  For each Zi C  we sample a value zi from the distribution P  Zi  z         zi     If Zi E  we assign Zi its observed value  The sampling distribution Q C  is  Y Q C    P  Zi  z         zi     E e     Zi C  The weight w t  of sample t is given by  Q  t   t   t  P  z  t    Zi Z P  zi  z         zi     t       Q w    t   t   t  Q z  t    P  z  z         z   Zi Z E  i  i   After cancelling out the common factors in denominator and numerator  we get  Q  t   t      w t    Zi E P  ei  z         zi    During sampling  the weight  initialized to    is updated every time we encounter an evidence variable Zi  E with observed value ei using  w t   w t   P  ei  z         zi     Theorem     Given Bayesian network over X  evidence E  X  and cutset C  X E  let Z   C  E be a loop cutset  If Z is topologically ordered  then Zj  Z the relevant subnetwork of Z         Zj is singlyconnected when Z         Zj are observed  Proof  Proof by contradiction  Assume that the relevant subnetwork of Z         Zj contains a loop L with sink S  Then  either S   Zq or S has a descendant Zq    qj   otherwise S is irrelevant   By definition of loop cutset  Cm L s t  Cm   S and Cm  C  Z  Threfore  Cm is an ancestor of Zq   Since variables are topologically ordered and all loop cutset nodes preceding Zq are observed  Cm must be observed  thus  breaking the loop  yielding a contradiction    Conclusion  if C is a loop cutset  we can compute the distributions P  Zi  z         zi    for every Zi Z over the relevant subnetwork of Zi in linear time and space  Therefore  the complexity of computing a new sample is proportional to the number of variables in Z and the size of the input N   In summary  Theorem      Complexity  Given a Bayesian network over X  evidence E  and a loop cutset CX E  the complexity of generating one sample using likelihood weighting over a cutset C is O  Z   N   where Z   C  E and N is the size of the input network  Once a sample c t  is generated  we apply belief propagation algorithm one more time to obtain the posterior marginals  P  Xi  c t    e   for each remaining variable  Once T samples are generated  we obtain the posterior marginals estimates  similar to Eq       by  P  ci  e       T X t    P  xi  e       T X  Consider the special case when C  E is a loopcutset  In this case  we can compute the probability P  z  P  c  e  in linear time and space using Pearls belief propagation algorithm  We can show that we can also compute P  Zi  z         zi    efficiently if we order the variables in Z topologically and restrict our attention to the relevant subnetwork of Z         Zi    w t  P  xi  c t    e   Xi  X C  E  t          The main difference between likelihood weighting over cutset C and sampling over all variables X is in computing the sampling distributions  In the latter case  the distribution P  Xi  x         xi      P  Xi  pai   is readily available in the conditional probability table of Xi   However  the sampling distribution P  Zi  z         zi    for LWLC needs to be computed   w t   ci   c t     Ci  C       Convergence  Likelihood weighting on a loop cutset  LWLC  has a higher overhead in computing the distributions P  Zi  z         zi    for Zi  Z  compared with sampling on a full variable set  However  as mentioned earlier  it converges faster  In general  importance sampling convergence rate is affected by the sampling variance and the distance between the sampling and the target distributions  The estimates obtained by sampling from a lower dimensional space have lower variance due to Rao Blackwell theorem  That is  V ar   P  C  P  Y  C     V ar    Q Y  C  Q C    P P where P  C    y P  Y  C  and Q C    y Q Y  C          A proof can be found in     and       Consequently  fewer LWLC samples are needed to achieve the same accuracy as LW  The information distance between target distribution P  C e  and sampling distribution Q C  in LWLC is smaller than the distance between P  X e  and sampling distribution Q X   We can show this for the KL distance       KL P  X   Q X      X x  P  x  log  P  x  Q x         Theorem      Reduced Information Distance  Given a Bayesian network expressing probability distribution P  X   evidence E e  and a cutset C  X E  let Q X  and Q C  E  denote the likelihood weighting sampling distribution over X and over C  E respectively  Then  KL P  C e   Q C  E    KL P  X e   Q X   We outline the proof in the Appendix  The details are available in           Caching Sampling on a Cutset  Often  we can reduce the computation time of a sampling scheme by caching the generated samples and their probabilities  Caching LW values is of limited benefit since it uses probabilities stored in CPTs  However  in the case of LWLC  caching may compensate in part for the computation overhead  A suitable data structure for caching is a search tree over the cutset C with a root node C    As new variable values are sampled and a partial assignment to the variables C         Ci is generated  LWLC traverses the search tree along the path c         ci   Whenever a new value of Ci is sampled  the corresponding tree branch is expanded and the current sample weight and the sampling distribution P  Ci  z         zi    are saved in the node Ci   In the future  when generating the same partial assignment c         ci   LWLC saves on computation by reading saved distributions from the tree  We will use LWLC BUF to denote LWLC sampling scheme that uses a memory buffer to cache previously computed probabilities  LWLC BUF can also update the sampling distributions P  Ci  z         zi    when dead ends are discovered  Namely  if the algorithm finds that a partial instantiation z         zi   cannot be extended to a full tuple with non zero probability  then we set P  Ci  z         zi        and normalize the updated distribution          Experiments Methodology  In this section  we compare empirically the performance of full likelihood weighting  LW   sampling over all the variables  against likelihood weighting on a loop cutset  LWLC  and buffered likelihood weighting on a loop cutset  LWLC BUF   In networks with positive distributions  we compare likelihood weighting side by side with Gibbs sampling  Gibbs  and Gibbsbased loop cutset sampling  LCS       For reference  we also compare with the estimates obtained by Iterative Belief Propagation  IBP   Belief propagation computes the exact posterior marginals in poly trees       When applied to networks with loops  it computes approximate marginals when it converges  IBP is fast and often produces good estimates           The quality of the approximate posterior marginals is measured by the Mean Square Error  MSE   P P   Xi X E D Xi    P  xi  e   P  xi  e   P M SE   Xi X E  D Xi    The exact posterior marginals P  Xi  e  are obtained by bucket tree elimination         We also measure the rejection rate R of each sampling scheme  Table    Benchmarks characteristics  N  number of nodes  w  induced width   LC  loop cutset size  P  e average probability of evidence  over    instances   TBE  exact computation time by bucket elimination  N w  LC  P e  TBE cpcs   b            E      min cpcs   b              E      min Pathfinder                 sec Pathfinder                    sec Link                     sec Our benchmarks are taken from Bayesian network repository  They include two subsets of Pathfinder network  Pathfinder  and Pathfinder   Link  and two CPCS networks  cpcs   b and cpcs   b  The benchmarks properties are summarized in Table    Pathfinder is an expert system for identifying disorders from lymph node tissue sections       Link is a model for the linkage between two genes       The exact posterior marginals for those networks were easy to compute by bucket elimination  However  they are hard for sampling because of the large number of deterministic relationships  cpcs   b and cpcs   b are derived from the Computer Based Patient Care Simulation system       They are more challenging for exact inference because of their large induced widths  All experiments were performed on a     GHz CPU               Results Sampling Speed  We generated    instances of each network with different random observations among the leaf nodes  In Table    we report the speed of generating samples using LW  LWLC  and LWLC BUF sampling schemes  As expected  LWLC generates far fewer samples than LW  Notably  the relative speed of LW and LWLC remains the same in the two Pathfinder networks and in Link network  By the time LW generates          samples  LWLC generates      samples  Table   also shows an order of magnitude improvement in the speed of generating samples by LWLC BUF in cpcs   b  Pathfinder   and Pathfinder   a factor of   improvement in cpcs   b  and no change in the Link network  The improvement depends on the ratio of unique samples  The number of unique tuples in Pathfinder networks is only    of the total number of samples and  thus      of the computation is redundant  However  in Link network  nearly all samples are unique  Hence  buffering was not beneficial  Table    Average   of samples generated by LWLC and LWLC BUF by the time LW generates          samples  LW LWLC LWLC BUF cpcs   b                   cpcs   b              Pathfinder                    Pathfinder                    Link                   the rejection rate R to denote the percentage of samples of weight    When the evidence is rare  we may need to generate a very large number of samples before we find a single sample of non zero weight  When all samples are rejected  we will say that the rejection rate is      and call the network instance unresolved  The rejection rates of the three likelihood weighting schemes over Pathfinder   Pathfinder   and Link are summarized in Table    For each benchmark  we report the number of instances k  out of      where the rejection rate        As we can see  LW resolved all    instances of Pathfinder  but only    instances of Pathfinder  and only    instances of Link  LWLC and LWLC BUF resolved all network instances  Table   also reports the rejection rate R averaged over those instances where all three algorithms generated some samples with non zero probabilities  As we can see  LW has high rejection rates in all benchmarks  The corresponding LWLC rejection rates are a factor of   or more smaller  Although lower rejection rate alone does not guarantee faster convergence  it helps compensate for generating fewer samples  The rejection rate of LWLC BUF is two orders of magnitude lower than LWLC in Pathfinder networks but it is the same as LWLC in Link network  also because most of the samples are unique   The rejection rate of LW and LWLC does not change with time  However  as LWLC BUF learns zeros of the target distribution  its rejection rate may decrease as the number of samples increases  Figure   demonstrates this on the example of Pathfinder networks  LWLC BUF Rejection Rates  Rejection Rates  Table    Average rejection rates for different benchmarks  k    instances  out of     where rejection rate        R   average rejection rate  LW LWLC LW BUF k R    k R    k R    PF                     PF                      Link                   When target distribution P  X  has many zeros where sampling distribution Q X  remains positive  many samples with weight   may be generated which do not contribute to the sampling estimates  Hence  we call them rejected  This is not an issue in cpcs   b and cpcs   b where all probabilities are positive  However  in deterministic networks  many samples may be rejected  contributing to slow convergence  We will use  Rejection Rate         Pathfinder        Pathfinder                                                                                        samples  Figure    LWLC BUF average rejection rate over    network instances in Pathfinder  and Pahfinder  as a function of the number of samples         Accuracy of the Estimates  The MSE results for PathFinder   Pathfinder   and Link are shown in Figure   as a function of time  The comparative behavior of LW  LWLC  and LWLCBUF sampling schemes is similar in all three networks  LWLC consistenly converges faster than LW and out    LW  LW  PathFinder    N      w      LC      E      cpcs   b  N       E       LC      w      LWLC         LWLC Gibbs  LWLC BUF   E     IBP          LCS  MSE  MSE  IBP                   E                                       E       Time  sec                              Time  sec  LW  PathFinder   N       LC      E      LW LWLC Gibbs LCS IBP  cpcs   b  N       LC       E      LWLC           E     LWLC BUF    E           MSE  MSE  IBP    E                            E                        Time  sec                       Time  sec  LW  Link  N      w       LC        E      LWLC         IBP  MSE         Figure    MSE as a function of time for full Gibbs sampling  Gibbs   Gibbs loop cutset sampling  LCS   LW  LWLC  and IBP in cpcs   b and cpcs   b                                 Time  sec   Figure    MSE as a function of time for LW  LWLC  LWLC BUF  and IBP over    network instances of Pathfinder   top      instances of Pathfinder   middle   and    instances of Link  bottom   performs IBP within   seconds  LW outperforms IBP within   seconds in Pathfinder  and within   seconds in Pathfinder   However  LW is considerably worse than IBP in Link network  LWLC BUF converges faster than LWLC in Pathfinder  and Pathfinder  because it generates more samples and has a lower rejection rate  In Link network  their performance is the same and  thus  we only show the LWLC curve  The PathFinder  network was also used as a benchmark in the evaluation of AIS BN algorithm      an adaptive importance sampling scheme  Although we experimented with different network instances  we can make a rough comparison  Within    seconds  AIS BN computes MSE          Adjusting for the difference in processor speed  the corresponding MSEs of LWLC and LWLC BUF are       and          obtained in   seconds  Hence  AIS BN and LWLC BUF produce comparable results   The accuracy of LW and LWLC for cpcs   b and cpcs   b networks is shown in Figure    Overall  results are similar  The LWLC outperforms LW by a wide margin in both benchmarks  Since all probabilities are positive  we also show the results for two Gibbs sampling schemes  Gibbs outperforms full likelihood weighting  Gibbs based loop cutset sampling  LCS  outperforms LWLC  Figure   focuses on the buffered cutset sampling schemes  Both LWLC BUF and LCSBUF improve substantially over the plain LWLC and LCS  And again  the Gibbs based LCS BUF is better than LWLC BUF   cpcs   b  N       E       LC      w       E     LWLC LWLC BUF LCS LCS BUF    E     MSE           E       E                                  Time  sec   Figure    MSE in cpcs   b as a function of time for LCS and LWLC vs  buffered LCS and LWLC BUF    Although Gibbs sampling schemes outperformed likelihood weighting methods in cpcs   b and cpsc   b  where evidence was selected among leaf nodes  the two methods are likely to switch places when fewer leaf nodes are observed  In particular  likelihood weighting outperforms Gibbs sampling in cpcs   b and cpcs   b without evidence          Related Work and Conclusions  In this paper we presented a cutset based likelihood weighting  By reducing the dimensionality of the sampling space  we achieve reduction in th esampling variance and also reduce the information distance  KLdistance  between the sampling and the target distributions  Therefore  the cutset sampling scheme requires fewer samples to converge  In the past  Rao Blackwellised importance sampling was made efficient by exploiting the properties of the conditional probability distributions  e g   when the distributions for the marginalised variables could be computed analytically using a Kalman filter           or when the marginalised variables in a factored HMM became conditionally independent  when sampled variables are observed  due to the numerical structure of the CPTs      In contrast  our method bounds the complexity of computing the sampling distributions by exploiting the structure of the network  We demonstrated empirically that cutset based likelihood weighting is time wise effective  Namely  it computes more accurate estimates than likelihood weighting as a function of time  We improve the convergence of cutset based likelihood weighting by caching previously computed samples  The buffered scheme reduces the average sample computation time since it does not re compute the probabilities of previously generated tuples and since it allows modifying the cached distributions dynamically  In this paper  we only updated the saved distributions when a partially instantiated cutset tuple could not be extended to a full cutset tuple with non zero probability  However  we can additionally update cached distributions based on the weight of previously generated samples as adaptive importance sampling techniques do  The proposed cutset based likelihood weighting can be generalized to other importance sampling schemes   
  of our approach on a complex dynamic domain of a persons transportation routines   This paper describes a general framework called Hybrid Dynamic Mixed Networks  HDMNs  which are Hybrid Dynamic Bayesian Networks that allow representation of discrete deterministic information in the form of constraints  We propose approximate inference algorithms that integrate and adjust well known algorithmic principles such as Generalized Belief Propagation  Rao Blackwellised Particle Filtering and Constraint Propagation to address the complexity of modeling and reasoning in HDMNs  We use this framework to model a persons travel activity over time and to predict destination and routes given the current location  We present a preliminary empirical evaluation demonstrating the effectiveness of our modeling framework and algorithms using several variants of the activity model   Focusing on algorithmic issues  the most popular approximate query processing algorithms for dynamic networks are Expectation propagation EP   Heskes and Zoeter        and Rao Blackwellised Particle Filtering  RBPF   Doucet et al          We therefore extend these algorithms to accommodate and exploit discrete constraints in the presence of continuous probabilistic functions  Extending Expectation Propagation to handle constraints is easy  extension to continuous variables is a little more intricate but still straightforward  The presence of constraints introduces a principles challenge for Sequential Importance Sampling algorithms  however  Indeed the main algorithmic contribution of this paper in presenting a class of Rao Blackwellised Particle Filtering algorithm  IJGP RBPF for HDMNs which integrates a Generalized Belief Propagation component with a Rao Blackwellised Particle Filtering scheme     INTRODUCTION Modeling sequential real life domains often requires the ability to represent both probabilistic and deterministic information  Hybrid Dynamic Bayesian Networks  HDBNs  were recently proposed for modeling such phenomena  Lerner         In essence  these are factored representation of Markov processes that allow discrete and continuous variables  Since they are designed to express uncertain information they represent constraints as probabilistic entities which may have negative computational consequences  To address this problem  Dechter and Mateescu        Larkin and Dechter        introduced the framework of Mixed Networks  In this paper we extend the Mixed Networks framework to dynamic environments  allow continuous Gaussian variables  yielding Hybrid Dynamic Mixed Networks  HDMN   We address the algorithmic issues that emerge from this extension and demonstrate the potential  Our motivation for developing HDMNs as a modeling framework is a range of problems in the transportation literature that depend upon reliable estimates of the prevailing demand for travel over various time scales  At one end of this range  there is a pressing need for accurate and complete estimation of the global origins and destinations  O D  matrix at any given time for an entire urban area  Such estimates are used in both urban planning applications  Sherali et al         and integrated traffic control systems based upon dynamic traffic assignment techniques  Peeta and Zilaskopoulos         Even the most advanced techniques  however  are hamstrung by their reliance upon out dated  pencil and paper travel surveys and sparsely distributed detectors in the transportation system  We view the increasing proliferation of powerful mobile computing devices as an opportunity to remedy this situation  If even a small sample of the traveling public agreed to collect their travel data and make that data publicly available  transportation management systems could significantly improve their operational efficiency  At the   other end of the spectrum  personal traffic assistants running on the mobile devices could help travelers replan their travel when the routes they typically use are impacted by failures in the system arising from accidents or natural disasters  A common starting point for these problems is to develop an efficient formulation for learning and inferring individual traveler routines like travelers destination and his route to destination from raw data points  The rest of the paper is organized as follows  In the next section  we discuss preliminaries and introduce our modeling framework  We then describe two approximate inference algorithms for processing HDMN queries  an Expectation Propagation type and a Particle Filtering type  Subsequently  we describe the transportation modeling approach and present preliminary empirical results on how effectively a model is learnt and how accurately its predictions are given several models and a few variants of the relevant algorithms  We view the contribution of this paper in addressing a complex and highly relevant real life domain using a general framework and domain independent algorithms  thus allowing systematic study of modeling  learning and inference in a non trivial setting     PRELIMINARIES AND DEFINITIONS Hybrid Bayesian Networks  HBN   Lauritzen        are graphical models defined by a tuple B    X  G  P   where X is the set of variables partitioned into discrete and continuS ous ones X      respectively  G is a directed acyclic graph whose nodes corresponds to the variables  P    P         Pn   is a set of conditional probability distributions  CPDs   Given variable xi and its parents in the graph pa xi    Pi   P xi  pa xi     The graph structure G is restricted in that continuous variables cannot have discrete variables as their child nodes  The conditional distribution of continuous variables are given by a linear Gaussian model  P xi  I   i  Z   z    N  i     i   z   i  xi   where Z and I are the set of continuous and discrete parents of xi   respectively and N     is a multi variate normal distribution  The network represents a joint distribution over all its variables given by a product of all its CPDs  A Constraint Network  Dechter        is a graphical model R    X  D C   where X    x            xn   is the set of variables  D    D            Dn   is their respective discrete domains and C    C   C           Cm   is the set of constraints  Each constraint Ci is a relation Ri defined over a subset of the variables Si  X and denotes the combination of values that can be assigned simultaneously  A Solution is an assignment of values to all the variables such that no constraint is violated  The primary query is to decide if the constraint network is consistent and if so find one or all solutions   The recently proposed Mixed Network framework  Dechter and Mateescu        for augmenting Bayesian Networks with constraints  can immediately be applied to HBNs yielding the Hybrid Mixed Networks  HMNs   Formally  given a HBN B    X  G  P  that expresses the joint probability PB and given a constraint network R    X  D C  that expresses a set of solutions   an HMN is a pair M    B   R    The discrete variables and their domains are shared by B and R and the relationships are those expressed in P and C  We assume that R is consistent  The mixed network M    B   R   represents the conditional probability PM  x    PB  x x    i f x   and   otherwise  Dynamic Bayesian Networks are Markov models whose state space and transition functions are expressed in a factored form using Bayesian Networks  They are defined by a prior P X    and a state transition function P Xt    Xt    Hybrid Dynamic Bayesian Networks  HDBNs  allow continuous variables while Hybrid Dynamic Mixed Networks  HDMNs  also permit explicit discrete constraints  D EFINITION     A Hybrid Dynamic Mixed Network  HDMN  is a pair  M    M    defined over a set of variables X    x         xn    where M  is an HMN defined over X representing P X     M is a   slice network defining the stochastic process P Xt    Xt    The   time slice Hybrid    Mixed network    THMN  is an HMN defined over X    X      such that X and X are identical to X  The acyclic graph   of the probabilistic portion is restricted so that nodes in X are root nodes and have no CPDs associated with them  The constraints are defined the usual way  The   THMN      represents a conditional distribution P X  X    The semantics of any dynamic network can be understood by unrolling the network to T time slices  Namely  T P X  t     P X     t   P Xt  Xt    where each probabilistic component can be factored in the usual way  yielding a regular HMN over T copies of the state variables  The most common task over Dynamic Probabilistic Networks is filtering and prediction Filtering is the task of determining the belief state P Xt  e  t   where Xt is the set of variables at time t and e  t are the observations accumulated at time slices   to t  Filtering can be accomplished in principle by unrolling the dynamic model and using any stateof the art exact or approximate reasoning algorithm  The join tree clustering algorithm is the most commonly used algorithm for exact inference in Bayesian networks  It partitions the CPDs and constraints into clusters that interact in a tree like manner  the join tree  and applies messagepassing between clusters  The complexity of the algorithm is exponential in a parameter called treewidth  which is the maximum number of discrete variables in a cluster  However  the stochastic nature of Dynamic Networks restricts the applicability of join tree clustering considerably  In the discrete case the temporal structure implies   tree width which equals to the number of state variables that are connected with the next time slice  thus making the factored representation ineffective  Even worse  when both continuous and discrete variables are present the effective treewidth is O T   when T is the number of time slices  thus making exact inference infeasible  Therefore the applicable approximate inference algorithms for Hybrid Dynamic Networks are either sampling based such as Particle Filtering or propagation based such as Expectation Propagation  In the next two sections  we will extend these algorithms to HDMNs     EXPECTATION PROPAGATION In this section we extend an approximate inference algorithm called Expectation Propagation  EP   Heskes and Zoeter        from HDBNs to HDMNs  The idea in EP  forward pass  is to perform Belief Propagation by passing messages between slices t and t     along the ordering t     to T   EP can be thought of as an extension of Generalized Belief Propagation  GBP  to HDBNs  Heskes and Zoeter         For simplicity of exposition  we will extend a GBP algorithm called Iterative Join graph propagation  Dechter et al         to HDMNs and call our technique IJGP i  S where S denotes that the process is sequential  The extension is rather straightforward and can be easily derived by integrating the results in  Murphy        Dechter et al         Lauritzen        Larkin and Dechter         IJGP  Dechter et al         is a Generalized Belief Propagation algorithm which performs message passing on a join graph  A join graph is collection of cliques or clusters such that the interaction between the clusters is captured by a graph  Each clique in a join graph contains a subset of variables from the graphical model  IJGP i  is a parameterized algorithm which operates on a join graph which has less than i     discrete variables in each clique  The complexity of IJGP i  is bounded exponentially by i   also called the i bound  In the message passing step of IJGP i   a message is sent between any two nodes that are neighbors of each other in the join graph  A message sent by node Ni to N j is constructed by multiplying all the functions and messages in a node  except the message received from N j   and marginalizing on the common variables between N j and Ni  see  Dechter et al           IJGP i  can be easily adapted to HDMNs  which we call IJGP i  S  and we describe some technical details here rather than a complete derivation due to lack of space  Note that because we are performing online inference  we need to construct the join graph used by IJGP i  S in an online manner rather than recomputing the join graph every time new evidence arrives  Murphy  Murphy        describes a method to compute a join tree in an online manner by pasting together join trees of individual time slices using  special cliques called the interface   Dechter et al         describe a method to compute join graphs from join trees  The two methods can be combined in a straightforward way to come up with an online procedure for constructing a join graph  In this procedure  we split the interface into smaller cliques such that the new cliques have less than i     variables  This construction procedure is shown in Figure    Message passing is then performed in a sequential way as follows  At each time slice t  we perform message passing over nodes in t and the interface of t with t    and t      shown by the ovals in Figure     The new functions computed in the interface of t with t     are then used by t      when we perform message passing in t      Three important technical issues remain to be discussed  First  message passing requires the operations of multiplication and marginalization to be performed on functions in each node  These operators can be constructed for HDMNs in a straightforward way by combining the operators by  Lauritzen        and  Larkin and Dechter        that work on HBNs and discrete mixed networks respectively  We will now briefly comment on how the multiplication operator can be derived  Let us assume we want to multiply a collection of probabilistic functions P  and a set of constraint relations C   which consist of only discrete tuples allowed by the constraint  to form a single function PC  Here  multiplication can be performed on the functions in P  and C  separately using the operators in  Lauritzen        and  Dechter        respectively to compute a single probabilistic function P and a single constraint relation C  These two functions P and C can be multiplied by deleting all tuples in P that are not present in C to form the required function PC  Second  because IJGP i  S constructs join graphs sequentially  the maximum i bound for IJGP i  S is bounded by the treewidth of the time slice and its interfaces and not the treewidth of the entire HDMN model  see Figure      Figure    Schematic illustration of the Procedure used for creating join graphs and join trees of HDMNs   Algorithm IJGP RBPF  Input  A Hybrid Dynamic Mixed Network  X  D  G  P C   T and a observation sequence e  T Integer N  w and i   Output  P XT  e  T    For t     to T do  Sequential Importance Sampling step     Generalized Belief Propagation step Use IJGP i  to compute the proposal distribution app    Rao Blackwellisation step Partition the Variables Xt into Rt and Zt such that the treewidth of a join tree of Zt is w     Sampling step For i     to N do  a  Generate a Rti from app    b  reject sample if rti is not a solution  i i     c  Compute the importance weights wti of Rti   ci      Normalize the importance weights to form w t  Selection step   Resample N samples from Rbti according to the normalized importance weights ci to obtain new N random samples  w t   Exact step   for i     to N do i   e   Rbi and Use join tree clustering to compute the distribution on Zti given Zt  t t d i R   t   Figure    IJGP RBPF for HDMNs Third  IJGP i  guarantees that the computations will be exact if i is equal to the treewidth  This is not true for IJGP i S in general as shown in  Lerner         It can be proved that  T HEOREM     The complexity of IJGP i  S is O    t     n   d i  t     T   where  t   is the number of discrete variables in time slice t  d is the maximum domain size of the discrete variables  i is the i bound used  n is the number of nodes in a join graph of the time slice  t is the maximum number of continuous variables in the clique of the join graph used and T is the number of time slices     RAO BLACKWELLISED PARTICLE FILTERING In this section  we will extend the Rao Blackwellised Particle filtering algorithm  Doucet et al         from HDBNs to HDMNs  Before  we present this extension  we will briefly review Particle Filtering and Rao Blackwellised Particle Filtering  RBPF  for HDBNs  Particle filtering uses a weighted set of samples or particles to approximate the filtering distribution  Thus  given a set of particles Xt            XtN approximately distributed according to the target filtering distribution P Xt   M e  t    the filtering distribution is given by P Xt   M e  t       N Ni    Xti   M  where  is the Dirac delta function  Since we cannot sample from P Xt   M e  t   directly  Parti   cle filtering uses an appropriate  importance  proposal distribution Q X  to sample from  The particle filter starts by generating N particles according to an initial proposal distribution Q X   e     At each step  it generates the next state i for each particle X i by sampling from Q X i Xt   t    Xt   e  t    t It then computes the weight of each particle based given by wt   P X  Q X  to compute a weighted distribution and then re samples from the weighted distribution to obtain a set of un biased or un weighted particles  Particle filtering often shows poor performance in highdimensional spaces and its performance can be improved by sampling from a sub space by using the RaoBlackwellisation  RB  theorem  and the particle filtering is called Rao Blackwellised Particle Filtering  RBPF    Specifically  the state Xt is divided into two sets  Rt and Zt such that only variables in set Rt are sampled  from a proposal distribution Q Rt     while the distribution on Zt is computed analytically given each sample on Rt  assuming that P Zt  Rt   e  t   Rt    is tractable   The complexity of RBPF is proportional to the complexity of exact inference step i e  computing P Zt  Rt   e  t   Rt    for each sample Rtk   w cutset  Bidyuk and Dechter        is a parameterized way to select Rt such that the complexity of computing P Zt  Rt   e  t   Rt    is bounded exponentially by w  Below  we use the w cutset idea to perform RBPF in HDMNs  Since exact inference can be done in polynomial time if a HDBN contains only continuous variables  a straightforward application of RBPF to HDBNs involves sampling only the discrete variables in each time slice and exactly inferring the continuous variables  Lerner         Extending this idea to HDMNs  suggests that in each time slice t we sample the discrete variables and discard all particles that violate the constraints in the time slice  Let us assume that we select a proposal distribution Q that is a good approximation of the probabilistic filtering distribution but ignores the constraint portion  The extension described above can be inefficient because if the proposal distribution Q is such that it makes non solutions to the constraint portion highly probable  most samples from Q will be rejected  because these samples Rti will have P Rti       and so the weight will be zero   Thus  on one extreme sampling only from the Bayesian Network portion of each time slice may lead to potentially high rejection rate  On the other extreme  if we want to make the sample rejection rate zero we would have to use a proposal distribution Q  such that all samples from this distribution are solutions  One way to find this proposal distribution is to make the constraint network backtrack free  using adaptive consistency  Dechter        or exact constraint propagation  along an ordering of variables and then sample along the reverse ordering  Another approach is to use join tree clustering which combines probabilistic and deterministic information and then sample from the join    tree  However  both join tree clustering and adaptiveconsistency are time and space exponential in treewidth and so they are costly when the treewidth is large  Thus on one hand  zero rejection rate implies using a potentially costly inference procedure while on the other hand sampling from a proposal distribution that ignores constraints may result in a high rejection rate  We propose to exploit the middle ground between the two extremes by combining the constraint network and the Bayesian Network into a single approximate distribution app using IJGP i  which is a bounded inference procedure  Note that because IJGP i  has polynomial time complexity for constant i  we would not eliminate the samplerejection rate completely  However  by using IJGP i  we are more likely to reduce the rejection rate because IJGP i  also achieves Constraint Propagation and it is well known that Constraint Propagation removes many inconsistent tuples thereby reducing the chance of sampling a nonsolution   Dechter         Another important advantage of using IJGP i  is that it yields very good approximations to the true posterior  Dechter et al         thereby proving to be an ideal candidate for proposal distribution  Note that IJGP i  can be used as a proposal distribution because it can be proved using results from  Dechter and Mateescu        that IJGP i  includes all supports of P Xt  e  t   Xt     i e  P Xt  e  t   Xt        implies that the output of IJGP i  viz  Q      Note that IJGP i  we use here is different from the algorithm IJGP i  S that we described in the previous section  This is because in our RBPF procedure  we need to comk  e   pute an approximation to the distribution P Rt  Rt    t k given the sample Rt  on variables Rt  and evidence e  t   IJGP i  as used in our RBPF procedure works on HMNs and can be derived using the results in  Dechter et al         Lauritzen        Larkin and Dechter         For lack of space we do not describe the details of this algorithm  see a companion paper  Gogate and Dechter        for details   The integration of the ideas described above into a formal algorithm called IJGP RBPF is given in Figure    It uses the same template as in  Doucet et al         and the only step different in IJGP RBPF from the original template is the implementation of the Sequential Importance Sampling step  SIS   SIS is divided into three steps      In the Generalized Belief Propagation step of SIS  we first perform Belief Propagation using IJGP i  to form an approximation of the posterior  say app   as described above      In the Rao Blackwellisation step  we first partition the variables in a  THMN into two sets Rt and Zt using a method due to  Bidyuk and Dechter         This method  Bidyuk and Dechter        removes minimal variables Rt from Xt such that the treewidth of the remain   Figure    Car Travel Activity model of an individual ing network Zt is bounded by w      In the sampling step  the variables Rt are sampled from app   To generate a sample from app   we use a special data structure of ordered buckets which is described in a companion paper  Gogate and Dechter         Importance weights are computed as usual  Doucet et al          Finally  the exact step computes a distribution on Zt using join tree clustering for HMNs  see a companion paper  Gogate and Dechter        for details on join treeclustering for HMNs   It can be proved that  T HEOREM     The complexity of IJGP RBPF i w  is O  NR  d w            n    d i           T   where    is the number of discrete variables  d is the maximum domain size of the discrete variables  i is the adjusted i bound  w is defined by w cutset  n is the number of nodes in a joingraph   is the number of continuous variables in a  THMN  NR is the number of samples actually drawn and T is the number of time slices      THE TRANSPORTATION MODEL  In this section  we describe the application of HDMNs to a real world problem of inferring car travel activity of individuals  The major query in our HDMN model is to predict where a traveler is likely to go and what his her route to the destination is likely to be  given the current location of the travelers car  This application was described in  Liao et al         in a different context for detecting abnormal behavior in Alzheimers patients and they use a Abstract Hierarchical Markov Models  AHMM  for reasoning about this problem  The novelty in our approach is not only a more general modeling framework and approximate inference algorithms but also a domain independent implementation which allows an expert to add and test variants of the model  Figure   shows a HDMN model for modeling the car travel activity of individuals  Note that the directed links express the probabilistic relationships while the undirected  bold    edges express the constraints  We consider the roads as a Graph G V  E  where the vertices V correspond to intersections while the edges E correspond to segments of roads between intersections  The variables in the model are as follows  The variables dt and wt represent the information about time of day and dayof week respectively  dt is a discrete variable and has four values  morning  a f ternoon  evening  night  while the variable wt has two values  weekend  weekday   Variable gt represents the persons next goal  e g  his office  home etc   We consider a location where the person spends significant amount of time as a proxy for a goal  Liao et al          These locations are determined through a preprocessing step by noting the locations in which the dwell time is greater than a threshold     minutes   Once such locations are determined  we cluster those that are in close proximity to simplify the goal set  A goal can be thought of as a set of edges E   E in our graph representation  The route level rt represents the route taken by the person to move from one goal to other  We arbitrarily set the number of values it can take to  gt      The persons location lt and velocity vt are estimated from GPS reading yt   ft is a counter  essentially goal duration  that governs goal switching  The Location lt is represented in the form of a two tuple  a  w  where a    s    s    a  E and s    s   V is an edge of the map G V  E  and w is a Gaussian whose mean is equal to the distance between the persons current position on a and one of the intersections in a  The probabilistic dependencies in the model are straightforward and can be found by tracing the arrows  see Figure     The constraints in the model are as follows  We assume that a person switches his goal from one time slice to another when he is near a goal or moving away from a goal but not when he is on a goal location  We also allow a forced switch of goals when a specified maximum time that he is supposed to spend at a goal is reached  This is modeled by using a constant D  These assumptions of switching between goals is modeled using the following constraints between the current location  the current goal  the next goal and the switching counters     If lt    gt  and Ft      Then Ft   D      If lt    gt  and Ft      Then Ft   Ft          If lt     gt  and Ft      Then Ft     and     If lt     gt  and Ft      Then Ft          If Ft      and Ft     Then gt is given by P gt  gt         If Ft     and Ft     Then gt is same as gt        If Ft      and Ft     gt is same as gt  and     If Ft      and Ft     gt is given by P gt  gt        EXPERIMENTAL RESULTS The test data consists of a log of GPS readings collected by one of the authors  The test data was collected over a six month period at intervals of     seconds each  The data consist of the current time  date  location and veloc   ity of the persons travel  The location is given as latitude and longitude pairs  The data was first divided into individual routes taken by the person and the HDMN model was learned using the Monte Carlo version of the EM algorithm  Liao et al         Levine and Casella         We used the first three months data as our training set while the remaining data was used as a test set  TIGER Line files available from the US Census Bureau formed the graph on which the data was snapped  As specified earlier our aim is two fold   a  Finding the destination or goal of a person given the current location and  b  Finding the route taken by the person towards the destination or goal  To compare our inference and learning algorithms  we use three HDMN models  Model   is the model shown in Figure    Model   is the model given in Figure   with the variables wt and dt removed from each time slice  Model  is the base model which tracks the person without any high level information and is constructed from Figure   by removing the variables wt   dt   ft   gt and rt from each timeslice  We used   inference algorithms  Since EM learning uses inference as a sub step  we have   different learning algorithms  We call these algorithms as IJGP S     IJGPS    and IJGP RBPF     N  and IJGP RBPF     N  respectively  Note that the algorithm IJGP S i   described in Section    uses i as the i bound  IJGP RBPF i w N   described in Section    uses i as the i bound for IJGP i   w as the w cutset bound and N is the number of particles at each time slice  Three values of N were used           and      For EM learning  N was      Experiments were run on a Pentium       GHz machine with  G of RAM  Note that for Model    we only use IJGP RBPF      and IJGP    S because the maximum i bound in this model is bounded by    see section         FINDING DESTINATION OR GOAL OF A PERSON The results for goal prediction with various combinations of models  learning and inference algorithms are shown in Tables      and    We define prediction accuracy as the number of goals predicted correctly  Learning was performed offline  Our slowest learning algorithm based on GBP RBPF      used almost   days of CPU time for Model    and almost   days for Model  significantly less than the period over which the data was collected  The column Time in Tables      and   shows the time for inference algorithms in seconds while the other entries indicate the accuracy for each combination of inference and learning algorithms  In terms of which model yields the best accuracy  we can see that Model   achieves the highest prediction accuracy   of     while Model   and Model   achieve prediction accuracies of     and     respectively or lower  For Model    to verify which algorithm yields the best learned model we see that IJGP RBPF      and IJGP   S yield an accuracy of     and     respectively while for Model    we see that the average accuracy of IJGPRBPF      and IJGP    S was     and     respectively  From these two results  we can see that IJGP RBPF      and IJGP    S are the best performing learning algorithms  For Model   and Model    to verify which algorithm yields the best accuracy given a learned model  we see that IJGP    S is the most cost effective alternative in terms time versus accuracy while IJGP RBPF yields the best accuracy  Table    Goal prediction  Model   N                          Inference IJGP RBPF      IJGP RBPF      IJGP RBPF      IJGP RBPF      IJGP RBPF      IJGP RBPF      IJGP    S IJGP    S Average  Time                                          LEARNING IJGP RBPF IJGP S                                                                                                                                                    FINDING THE ROUTE TAKEN BY THE PERSON To see how our models predict a persons route  we use the following method  We first run our inference algorithm on the learned model and predict the route that the person is likely to take  We then super impose this route on the actual route taken by the person  We then count the number of roads that were not taken by the person but were in the predicted route i e  the false positives  and also compute the number of roads that were taken by the person but were not in the actual route i e  the false negatives  The two measures are reported in Table   for the best performing learning models in each category  viz GBP RBPF      for Model   and Model   and GBP RBPF      for Model    As we can see Model   and Model   have the best route prediction accuracy  given by low false positives and false negatives    Table    Goal Prediction Model   N              Inference IJGP RBPF      IJGP RBPF      IJGP RBPF      IJGP    S Average  Time                     LEARNING IJGP RBPF      IJGP    S                                       RELATED WORK  Liao et al         and  Patterson et al         describe a model based on AHMEM  Bui        and Hierarchical Markov Models  HMMs  respectively for inferring highlevel behavior from GPS data  Our model goes beyond their model by representing two new variables day of week and time of day which improves the accuracy in our model by about     A mixed network framework for representing deterministic and uncertain information was presented in  Dechter and Larkin        Larkin and Dechter        Dechter and Mateescu         These previous works also describe exact inference algorithms for mixed networks with the restriction that all variables should be discrete  Our work goes beyond these previous works in that we describe approximate inference algorithms for the mixed network framework  allow continuous Gaussian nodes with certain restrictions in the mixed network framework and model discrete time stochastic processes  The approximate inference algorithms called IJGP i  described in  Dechter et al         handled only discrete variables  In our work  we extend this algorithm to include Gaussian variables and discrete constraints  We also develop a sequential version of this algorithm for dynamic models  Particle Filtering is a very attractive research area  Doucet et al          Particle Filtering in HDMNs can be inefficient if non solutions of constraint portion have high probability of being sampled  We show how to alleviate this difficulty by performing IJGP i  before sampling  This algorithm IJGP RBPF yields the best performance in our settings and might prove to be useful in applications in which particle filtering is preferred   Table    Goal Prediction  Model   N                          Inference IJGP RBPF      IJGP RBPF      IJGP RBPF      IJGP RBPF      IJGP RBPF      IJGP RBPF      IJGP    S IJGP    S Average  Time                                            LEARNING IJGP RBPF IJGP S                                                                                                                                             Table    False positives  FP  and False negatives for routes taken by a person  FN  N                   INFERENCE IJGP    IJGP    IJGP RBPF      IJGP RBPF      IJGP RBPF      IJGP RBPF       Model  FP FN                                      Model  FP FN                                      Model  FP FN                       CONCLUSION AND FUTURE WORK In this paper  we introduced a new modeling framework called HDMNs  a representation that handles discrete timestochastic processes  deterministic and probabilistic information on both continuous and discrete variables in a systematic way  We also propose a GBP based algorithm called IJGP i  S for approximate inference in this framework  The main algorithmic contribution of this paper is presenting a class of Rao Blackwellised particle filtering algorithm  IJGP RBPF for HDMNs which integrates a generalized belief propagation component with a RaoBlackwellised Particle Filtering scheme for effective sampling in the presence of constraints  Another contribution of this paper is addressing a complex and highly relevant real life domain using a general framework and domain independent algorithms  Directions for future work include relaxing the restrictions made on dependencies between discrete and continuous variables and developing an efficient EM algorithm   ACKNOWLEDGEMENTS The first and third author were supported in part by National Science Foundation under award numbers         and          The second author was supported in part by the NSF grant IIS           
