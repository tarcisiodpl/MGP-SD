 We formulate in this paper the mini bucket algorithm for approximate inference in terms of exact inference on an approximate model produced by splitting nodes in a Bayesian network  The new formulation leads to a number of theoretical and practical implications  First  we show that branchand bound search algorithms that use minibucket bounds may operate in a drastically reduced search space  Second  we show that the proposed formulation inspires new minibucket heuristics and allows us to analyze existing heuristics from a new perspective  Finally  we show that this new formulation allows mini bucket approximations to benefit from recent advances in exact inference  allowing one to significantly increase the reach of these approximations      INTRODUCTION  Probabilistic reasoning tasks in Bayesian networks are typically NPhard  and approximation algorithms are often sought to address this apparent intractability  One approach to approximate inference is based on mini buckets  a scheme that has been successfully employed by branch and bound algorithms for computing MPEs  Most Probable Explanations   Dechter   Rish        Marinescu  Kask    Dechter         Roughly speaking  mini buckets is a greedy approach to approximate inference that applies the variable elimination algorithm to a problem  but only as long as computational resources allow it  When time and space constraints keep us from progressing  a mini buckets approach will heuristically ignore certain problem dependencies  permitting the process of variable elimination to continue  Zhang   Poole        Dechter         Mini buckets will therefore give rise to a family  of approximations that  in particular  are guaranteed to produce upper bounds on the value we seek  and further whose quality depends on the heuristic used to ignore dependencies  In this paper  we make explicit in the most fundamental terms the dependencies that mini bucket approximations ignore  In particular  we reformulate the mini bucket approximation using exact inference on an approximate model  produced by removing dependencies from the original model  We refer to this process of removing dependencies as node splitting  and show that any mini bucket heuristic can be formulated as a node splitting heuristic  This perspective on mini buckets has a number of implications  both theoretical and practical  First  it shows how one can significantly reduce the search space of brand and bound algorithms that make use of mini bucket approximations for generating upper bounds  Second  it provides a new basis for designing mini bucket heuristics  a process which is now reduced to specifying an approximate model that results from node splitting  We will indeed propose a new heuristic and compare it to an existing heuristic  which we reformulate in terms of node splitting  Third  it allows one to embed the mini bucket approximation in the context of any exact inference algorithmfor example  ones that exploits local structure  Chavira   Darwiche       which could speed up the process of generating mini bucket bounds  without affecting the quality of the approximation  We will illustrate this ability in some of the experiments we present later  This paper is organized as follows  In Section    we review the MPE task  as well as algorithms for finding MPEs  In Section    we define node splitting operations for Bayesian networks  and show in Section   how mini bucket elimination is subsumed by splitting nodes  In Section    we examine mini buckets as a node splitting strategy  and introduce a new strategy based on jointrees  In Section    we consider branchand bound search for finding MPEs  and show how       CHOI ET AL   we can exploit node splitting to improve the efficiency of search  In Section    we provide empirical support for the claims in Section    and conclude in Section    Proofs and other results appear in the Appendix      MOST PROBABLE EXPLANATION  We will ground our discussions in this paper using the problem of computing MPEs  which we define formally next  Let N be a Bayesian network with variables X  inducing distribution Pr   The most probable explanation  MPE  for evidence e is then defined as  MPE  N  e   def     arg max Pr  x   xe  where x  e means that instantiations x and e are compatible  they agree on every common variable  Note that the MPE solution may not be unique  in which case MPE  N  e  denotes a set of MPEs  One can also define the MPE probability  MPE p  N  e   def     max Pr  x   xe  A number of approaches have been proposed to tackle the MPE problem  when a Bayesian network has a high treewidth  These include methods based on local search  Park        Hutter  Hoos    Stutzle        and max product belief propagation  e g   Pearl        Weiss         including generalizations  e g   Yedidia  Freeman    Weiss        Dechter  Kask    Mateescu        and related methods  Wainwright  Jaakkola    Willsky        Kolmogorov   Wainwright          Although these approaches have been successful themselves  and can provide high quality approximations  they are in general non optimal  An approach based on systematic search can be used to identify provably optimal MPE solutions  although the efficiency of a search depends heavily on the problem formulation as well as the accompanying heuristics  In particular  it is quite common also to use branchand bound search algorithms for computing MPEs and their probability  e g   Marinescu et al         Marinescu   Dechter         The use of these search algorithms  however  requires the computation of an upper bound on the MPE probability to help in pruning the search space  The mini buckets method is the state of the art for computing such bounds  Dechter   Rish         In fact  the success of mini buckets is most apparent in this context of computing MPEs  which is the reason we will use this application to drive our theoretical analysis and empirical results   X  X  Figure    When we split a variable X  left   we create a clone X that inherits some of the children  right       SPLITTING NODES  We will define in this section a method for approximating Bayesian networks by splitting nodes  An operation that creates a clone X of some node X  where the clone inherits some of the children of X  see Figure    Definition   Let X be a node in a Bayesian network N with children Y  We say that node X is split according to children Z  Y when it results in a network that is obtained from N as follows   The edges outgoing from node X to its children Z are removed   A new root node X with a uniform prior is added to the network with nodes Z as its children  A special case of node splitting is edge deletion  where a node is split according to a single child  i e   splitting also generalizes edge deletion as defined in Choi   Darwiche      a      b   Definition   Let X  Y be an edge in a Bayesian network N   We say that node X is split along an edge X  Y when the node X is split according to child Y   The following case of node splitting will be the basis of a splitting strategy that yields a special class of minibucket approximations with implications in search  Definition   Let X be a node in a Bayesian network N   We say that node X is fully split when X is split along every outgoing edge X  Y   Thus  when we fully split a node X  we create one clone for each of its outgoing edges  Figure   illustrates an example of a network where two nodes have been split  Node C has been split according to children  D  E   and Node A has been split along the edge A  D  A network N   which results from splitting nodes in network N has some interesting properties  To explicate these properties  however  we need to introduce a function which  given an instantiation x of variables in network N   gives us an instantiation of clones in N   that agrees with the values given to variables in x    CHOI ET AL       Algorithm   ve N  e   returns MPE p  N  e      i       S   f e   f e is a CPT  incorporating e  of N      while S contains variables do    ii      X  a variable appearing in S    Si  all factors Y in S that contain X    fi  max f X  Figure    A Bayesian network N  left  and an approximation N    right  found by splitting C according to  D  E   and splitting A according to D  Definition   Let N be a Bayesian network  and let N   be the result of splitting nodes in N   If x is an  instantiation of variables in N   then let  x be the compatible instantiation of the corresponding clones in N     For example  in the split network in Figure    an instantiation x    A   a    B   b    C   c    D   d    E   e     is compatible with instantiation  x    A   a    C   c     Moreover  x is not compatible with  A   a    C   c     To see the effect that splitting a node can have on a network  consider a simple two node network A  B with binary variables  where a        b   a        and b   a        After splitting A according to B  we have  x a  b   a  b   a  b   a  b       Pr  x                       x a  a  b  a  a  b  a  a  b  a  a  b  a  a  b  a  a  b  a  a  b  a  a  b            Pr  x                                            x a  a  b  a  a  b  a  a  b  a  a  b  a  a  b  a  a  b  a  a  b  a  a  b         Pr  x                                            where     A         We see that whenever A  and its clone A  are set to the same value  we can recover the original probabilities Pr  x  after splitting  by using Pr    x     This includes the value of the MPE in N   which may no longer be the largest value of Pr    x     This intuition yields the key property of split networks  Theorem   Let N be a Bayesian network  and let N   be the result of splitting nodes in N   We then have  MPE  N  e   MPE  N     e   e    Q  Here     network N      p  CC  p   C   where C is the set of clones in  That is  the MPE probability with respect to a split network provides an upper bound on the MPE probability with respect to the original network  We note that the probability of evidence is also upper bounded in the split network  see Theorem   in the Appendix   f Si     S  S  Si   fi      return product of factors in S  Algorithm   mbe N  e   returns an upper bound on MPE p  N  e     Identical to Algorithm    except for Line         Si  some factors in S that contain X  The following corollary shows that splitting degrades the quality of approximations monotonically  Corollary   Let network N  be obtained by splitting nodes in network N    which is obtained by splitting nodes in network N    We then have MPE p  N    e       MPE p  N    e   e        MPE  N   e  e       p          where       and  e     e  are as defined by Theorem        MINI BUCKET ELIMINATION  We discuss in this section the relationship between the approximations returned by split networks and those computed by the mini buckets algorithms  Dechter   Rish         In particular  we show that every minibuckets heuristic corresponds precisely to a node splitting strategy  where exact inference on the resulting split network yields the approximations computed by mini buckets  Our discussion here will be restricted to computing MPEs  yet the correspondence extends to probability of evidence as well  We start first by a review of the mini buckets method  which is a relaxed version of the variable elimination method given in Algorithm    Zhang   Poole        Dechter         According to this algorithm  variable elimination starts with a set of factors corresponding to the CPTs of a given Bayesian network  It then iterates over the variables appearing in factors  eliminating them one at a time  In particular  to eliminate a variable X  the method multiplies all factors that contain X and then max out X from the result  The bottleneck of this algorithm is the step where the factors containing X are multiplied  as the resulting       CHOI ET AL                      Figure    An execution trace of ve on N  left  and mbe on N  right   The network is defined in Figure     factor may be too big for the computational resources available  The mini bucket method deals with this difficulty by making a simple change to the variable elimination algorithm  also known as the bucket elimination algorithm    This change concerns Line   in which all factors containing variable X are selected  In minibuckets  given in Algorithm    Dechter   Rish         one chooses only a subset of these factors in order to control the size of their product  Which particular set of factors is chosen depends on the specific heuristic used  Yet  regardless of the heuristic used  the answer obtained by the mini buckets method is guaranteed to be an upper bound on the correct answer   One should note here that the simple change from all to some on Line   implies the following  The number of iterations performed by Algorithm   is exactly the number of network variables  since each iteration will eliminate a network variable  However  Algorithm   may only partially eliminate a variable in a given iteration  and may take multiple iterations to eliminate it completely  To help us visualize the computations performed by Algorithms   and    consider their execution trace  Definition   Given an instance of ve or mbe run on a given network N   we define its execution trace T as a labeled DAG which adds  for each iteration i   a node i  labeled by the factor set Si   and  directed edges j  i  for all factors fj  Si   each labeled by the corresponding factor fj      More precisely  bucket elimination is a particular implementation of variable elimination in which one uses a list of buckets to manage the set of factors during the elimination process  Although the use of such buckets is important for the complexity of the algorithm  we ignore them here as the use of buckets is orthogonal to our discussion    This is also true for versions of the algorithm that compute the probability of evidence   Figure   depicts traces of both algorithms on the network in Figure    left   Variable elimination  whose trace is shown on the left  eliminates variables from A to E  and performs five iterations corresponding to the network variables  Mini buckets  however  performs seven iterations in this case  as it takes two iterations to eliminate variable A and two iterations to eliminate variable C  Note that an execution trace becomes a rooted tree after reversing the direction of all edges  Given an execution trace T   we can visually identify all of the network CPTs used to construct any factor in Algorithms   and    For mini buckets  we also want to identify a subtrace of T   but one that covers only those network CPTs that are relevant to a particular attempt at eliminating variable X at iteration i  A CPT is not relevant to iteration i if X is eliminated from it in a later iteration  or if X has already been eliminated from it in some previous iteration  Given a trace T   we thus define the subtrace Ti relevant to an iteration i as the nodes and edges of T that are reachable from node i  including itself   but only by walking up edges j  i  and only those edges labeled with factors fj mentioning variable X  For example  in Figure    right   the subtrace Ti for iteration i     is the chain          In the same trace  the subtrace Ti for iteration i     is the chain          Given a subtrace Ti   we can identify only those CPTs that are relevant to a partial elimination of X  but further  the set of variables those CPTs belong to  Definition   Let i be an iteration of mbe where we eliminate variable X  and let Ti be the subtrace of T that is relevant to iteration i  The basis B of an iteration i is a set of variables where Y  B iff   Y  U  Sj for some node j of Ti   and  X   Y    U  where Y  U are CPTs in N   For example  in Figure    right   the basis of iteration i     is  D  E   since C is eliminated from the CPTs of D and E at iteration    Given this notion  we can show how to construct a network with split nodes  that corresponds to a particular execution of the mini bucket method  In particular  exact variable elimination in N   will be able to mimic mini bucket elimination in N   with the same computational complexity  This is given in Algorithm   which returns both a network N   and an ordering    of the variables in N    this includes the variables in original network N and their clones in N      Figure   shows a trace corresponding to a split network  and the associated variable order    CHOI ET AL  Algorithm   split mbe N  e   returns a split network N   and variable ordering      corresponding to a run of mbe N  e      N    N    for each iteration i of mbe N  e  do    X  as chosen on Line   of mbe    Si  as chosen on Line   of mbe    B  basis of iteration i    if X  B then        i   X    else    split node X in N   according to children B         i   clone X of X resulting from split     return network N   and ordering                       NODE SPLITTING STRATEGIES  Given the correspondences in the previous section  every mini bucket heuristic can now be interpreted as a node splitting strategy  Consider for example the mini bucket heuristic given in  Dechter   Rish         which is a greedy strategy for bounding the size of the factors created by mbe  This heuristic works as follows  given a bound on the size of the largest factor   A particular variable order is chosen and followed by the heuristic   When processing variable X  the heuristic will pick a maximal set of factors Si whose product will be a factor of size within the given bound   The above process is repeated in consecutive iterations and for the same variable X until variable X is eliminated from all factors   Once X is completely eliminated  the heuristic picks up the next variable in the order and the process continues         Figure    An execution trace of mbe on N  left  and ve on N    right   For simplicity  we ignore the priors of clone variables in N     Networks are defined in Figure     We now have our basic correspondence between minibuckets and node splitting  Theorem   Let N be a Bayesian network  e be some evidence  and let N   and    be the results of split mbe N  e   We then have   mbe N  e    MPE  N     e   e    Q  p  where    CC  C  and C are the clone variables in N     Moreover  variable elimination on network N   using the variable order    has the same time and space complexity of the corresponding run mbe N  e   Note that the ordering    returned by Algorithm   may not be the most efficient ordering to use when running exact variable elimination in a split network  there  may be another variable order where ve N     e   e   produces smaller intermediate factors than mbe N  e   Indeed  we need not restrict ourselves to variable elimination when performing inference on the split network  as any exact algorithm suffices for this purpose  This property can have significant practical implications  a point we highlight in Section   where we exploit recent advances in exact inference algorithms   This heuristic tries then to minimize the number of instances where a proper subset of factors is selected in Line   of Algorithm    and can be interpreted as a heuristic to minimize the number of clones introduced into an approximation N     In particular  the heuristic does not try to minimize the number of split variables  We now introduce a new node splitting strategy based on fully splitting nodes  where a variable is split along every outgoing edge  The strategy is also a greedy algorithm  which attempts to fully split the variable that contributes most to the difficulty of running a jointree algorithm in the approximate network N     This process is repeated until the network is sufficiently simplified  In particular  the method starts by building a jointree of the original network  It then picks a variable whose removal from the jointree will introduce the largest reduction in the sizes of the cluster and separator tables  Once a variable is chosen  it is fully split  One can obtain a jointree for the split network by simply modifying the existing jointree  which can then be used to choose the next variable to split on   In our empirical evaluation  we go further and construct a new jointree for the simpler network  and choose the next variable to split from it  This process is repeated until the largest jointree cluster is within our bound  We now have two strategies for splitting nodes in a network  The first is based on the classical mini bucket heuristic that tries to minimize the number of clones    In particular  one can simply adjust the separators and clusters without changing the structure of the jointree        CHOI ET AL   Algorithm   split bnb  z and q   are global variables      q  MPE p  N     z   z       if q   q then    if z is a complete instantiation then    q   q    else    pick some X   Z    for each value x of variable X do    z  z   X   x     split bnb       z  z   X   x   and the second one is based on reducing the size of jointree tables and tries to minimize the number of split variables  Recall that Corollary   tells us that the quality of the MPE bound given by a split network degrades monotonically with further splits  As we shall see in Section    and empirically in Section    it may sometimes be more important to minimize the number of split variables  rather than the number of clones  in the context of branch and bound search      SEARCHING FOR MPES  When computing the MPE is too difficult for traditional inference algorithms  we can employ systematic search methods to identify provably optimal solutions  Suppose now that we are given network N and evidence e  and that we want to compute MPE p  N  e  using depth first branch and bound search  We want then to select some network N   using a node splitting heuristic from the previous section to allow for exact inference in N    say  by the jointree algorithm   Theorem   gives us the upper bound  MPE p  N  e   MPE p  N     e   e    Moreover  one can easily show that if z is a complete variable instantiation x of N   we then have  MPE p  N  x    MPE p  N     x   x    see Lemma    These two properties form the basis of our proposed search algorithm  split bnb  which is summarized in Algorithm    Throughout the search  we keep track of two global variables  First  z is a partial assignment of variables in the original network that may be extended to produce an MPE solution in MPE  N  e   Second  q   is a lower bound on the MPE probability that is the largest probability of a complete instantiation so far encountered  The search is initiated after setting z to e and q   to      we use evidence e as the base instantiation   and     as a trivial lower bound  Upon completion of the search  we have the optimal MPE probability q     MPE p  N  e   At each search node  we compute a bound on the best completion of z by performing exact inference in the approximate network N     If the resulting upper bound q is greater than the current lower bound q     then we must continue the search  since it is possible that z can provide us with a better solution than what we have already found  In this case  if z is already a complete instantiation  it is easy to show that q is equal to Pr  z   by Lemma    in the Appendix  and that we have found a new best candidate solution q     If z is not a complete instantiation  we select some variable X that has not been instantiated  For each value x of X  we add the assignment  X   x  to z and call split bnb recursively with the new value of z and our candidate solution q     Upon returning from the recursive call  we retract the assignment  X   x   and continue to the next value of X       REDUCING THE SEARCH SPACE  Consider now the following critical observation  Proposition   Let N be a Bayesian network  and let N   be the result of splitting nodes in N   If Z contains all variables that were split in N to produce N     then  MPE p  N  z    MPE p  N     z   z    where     Q  CC   C  and C are all the clones in N      According to this proposition  once we have instantiated in z all variables that were cloned  the resulting approximation is exact  This tells us that during our search  we need not instantiate every one of our network variables X  We need only instantiate variables in a smaller set of variables Z  X containing precisely the variables that were split in N to produce N     Once the bound on the MPE probability becomes exact  we know that we will not find a better solution by instantiating further variables  so we can stop and backtrack  This observation allows us to work in a reduced search space  rather than searching in a space whose size is exponential in the number of network variables X  we search in a space whose size is exponential only in the number of split variables  Moreover  if our variable splitting strategy seeks to minimize the number of split variables  rather than the number of clones introduced  we can potentially realize dramatic reductions in the size of the resulting search space  As we shall see in the following section  this can have a drastic effect on the efficiency of search    CHOI ET AL   In our experiments  we compared the splitting strategy based on a jointree  JT  with the strategy based on a greedy mini bucket elimination  MB   both described in Section    In particular  we asserted limits on the maximum cluster size for JT  and equivalently  the size of the largest factor for MB  We then compared the two strategies across a range of cluster and factor size limits from   to     where   corresponds to a fully disconnected network and    corresponds to exact inference  no splits   In all of our experiments  to emphasize the difference between splitting strategies  we make neutral decisions in the choice of a search seed  we use a trivial seed        variable ordering  random  and value ordering  as defined by the model   First  consider Figure    which compares the effectiveness of node splitting strategies in minimizing the number of variables split and the number of clones  Recall that the heuristic based on jointrees  JT  seeks to minimize the number of split variables  while the greedy mini bucket  MB  strategy would seek to minimize the number of clones  We see that in Figure    on    In particular  each network is associated with its own piece of evidence corresponding to a codeword received via transmission through a  simulated  noisy Gaussian channel  with standard deviations ranging from        to        in steps of       JT MB                JT MB                     log  max cluster size        log  max cluster size   Figure    Comparing splitting heuristics               JT MB                   log  max cluster size     search nodes  We begin with experiments on networks for decoding error correcting codes  see  e g   Frey   MacKay        Rish  Kask    Dechter         We first consider simpler networks  that correspond to codes containing    information bits and    redundant bits  Each of our plot points is an average of    randomly generated networks    networks for each of   levels of noise   Here  an MPE solution would recover the most likely word encoded prior to transmission  Our method for exact inference in the approximate model is based on compiling Bayesian networks  Chavira   Darwiche         an approach that has already been demonstrated to be effective in branch and bound search for MAP explanations  Huang  Chavira    Darwiche            of vars split  We present empirical results in this section to highlight the trade offs in the efficiency of search based on the quality of the bound resulting from different node splitting strategies  and the size of the resulting search space  We further illustrate how our framework allows for significant practical gains with relatively little effort  by employing state of the art algorithms for exact inference in the approximate  node split network  Thus  our goal here is  not to evaluate a completely specified system for MPE search  but to illustrate the benefits that our node splitting perspective can bring to existing systems         of clones created  EMPIRICAL OBSERVATIONS  search space size                               log  max cluster size     Figure    Evaluating the efficiency of search  On the right  the top pair searches in the full space  and the bottom pair searches in the reduced space   the left  our jointree  JT  method can split nearly half of the variables that the mini bucket  MB  strategy splits  On the other hand  we see that on the right  the mini bucket  MB  strategy is introducing fewer clones  Note that on both extremes  no splits and all split   MB and JT are identical  To see the impact that reducing the number of split variables has on the efficiency of search  consider Figure    On the left  we see that JT can get an order of magnitude savings over MB in the size of the reduced search space  which is exponential only in the number of split variables  see again Figure     Consider now  on the right  the number of nodes visited while performing split bnb search  The top pair plots the efficiency of search using the full search space  JTF and MB F   while the bottom pair plots the efficiency of using the reduced search space  JT R and MB R   We see that both JT R and MB R experience several orders of magnitude improvement when using the reduced search space versus the full search space  When we compare JT F and MB F  top pair   we see that MB F is in fact more efficient in terms of the number of nodes visited  In this setting  where both methods are searching in the same space  we see that the number of clones introduced appears to be the dominant factor in the efficiency of search  This is expected  as we expect that the upper bounds on the MPE probability should be tighter when fewer clones are introduced  When we now compare JT R and MB R  bottom pair   we see that the situation has       CHOI ET AL  JT MB    of clones created    of vars split                     log  max cluster size   JT MB                       log  max cluster size        JT MB  search nodes  search space size  Figure    Comparing splitting heuristics                                 log  max cluster size            log  max cluster size   Figure    Evaluating the efficiency of search   Table    Compilation versus Variable Elimination Network                                                                                   Search Nodes                                                        AC Time  s                            VE Time  s                                                   Imp                                           reversed  and that JT R is now outperforming MB R  Here  each method is performing search in their own reduced search spaces  A strategy based on reducing the number of split variables reduces the size of the search space  and this reduction now dominates the quality of the bound  Figures   and   depict similar results but for larger coding networks  in which we have a rate    code with    information bits and    redundant bits  Note that only the reduced space was used for search here  Our approach based on node splitting has another major advantage  which we have only briefly mentioned thus far  By formulating mini buckets as exact inference in an approximate network  the evaluation of the mini bucket approximation need not rely on any specific exact inference algorithm  We mention here that  the arithmetic circuit  AC  approach we have been using to compute the bound indeed has a key advantage over mainstream algorithms  in that it is able to effectively exploit certain types of local structure  Chavira   Darwiche         To highlight the extent to which using a different algorithm can be significant  we constructed another set of experiments  In each  we used a different grid network  first introduced in  Sang  Beame    Kautz         and constructed a single MPE query  Each grid network has treewidth in the low thirties  just out of reach for traditional algorithms for exact inference  We ran our search twice  each time using a different algorithm to compute the mini bucket bound  the first using AC and the second using standard variable elimination  that does not exploit local structure   Table   shows the results for each network  including the number of search nodes visited and  for each algorithm  the total search time  For each network  we performed two identical searches for each algorithm  the only difference being in how the bound was computed  Consequently  the dramatic differences we observe reflect the ability of the AC approach to exploit local structure  showing how advances in exact inference can be easily utilized to extend the reach of mini bucket approximations      CONCLUSION  We presented in this paper a new perspective on minibucket approximations  formulating it in terms of exact inference in an approximate network  but one found by splitting nodes  This perspective has led to a number of theoretical and practical insights  For one  it becomes apparent that a branch and bound search using a mini bucket bound may operate in a drastically reduced search space  This suggests a heuristic for identifying a mini bucket approximation that is explicitly based on minimizing this search space  rather than the quality of the resulting bound  Empirically  we observe that a reduced search space can have more impact than a better bound  in terms of the efficiency of branch and bound search  Moreover  as our approach is independent of the algorithm used for exact inference in the resulting approximate network  we can effortlessly employ state of the art algorithms for exact inference  including those that can exploit compilation and local structure   A  PROOFS  Lemma   Let N be a Bayesian network  and let N   be the result of splitting nodes in N   We then have  Pr  x    Pr    x   x      CHOI ET AL  Q Here    CC  C   where C is the set of clones in network N      Proof of Lemma   Note first that  x is an instantiation of only root variables  and that all clones have uniform priors  i e   c    C     We then have that Y Y  Pr     x    c    C           c x  CC   Since instantiation x is compatible with  x   where a variable and its clones are set to the same value  we  find in Pr    x    x   that clone variables act as selectors for the CPT values composing Pr  x   Thus    Pr  x   x     Pr    x    x  Pr     x     Pr  x        and we have Pr  x    Pr    x   x    as desired      Proof of Theorem   Suppose for contradiction that there exists an instantiation z  MPE  N  e  such that  Pr  z    MPE p  N     e   e    By Lemma    the instan  tiation z gives us   Pr  z    Pr    z   z     MPE p  N     e   e     contradicting the optimality of MPE p  N     e   e        Proposition   is in fact a generalization of Lemma   from a complete instantiation x to a partial instantiation z where Z contains all nodes that have been split in N     Note that splitting a node X when the value of X has already been fixed corresponds to a common preprocessing rule for Bayesian networks given evidence  In particular  when a given piece of evidence z fixes the value of variable Z  any edge Z  Y can be pruned and a selector node Z can be made a parent of Y   Node Z is then set to the value that instantiation z assigns to Z  This pruning process yields a simpler network which corresponds exactly to the original network for any query of the form    z   Proof of Proposition   From the correspondence to pruning edges outgoing instantiated variables  we know that queries of the form    z   including complete instantiations  x  z   are equivalent in N condi tioned on z and N   conditioned on  z   z    Thus the MPEs of each network must also be the same    Proof of Theorem   Given the trace of an instance of mbe N  e   algorithm split mbe N  e  returns a network N   and an ordering    of variables in N     We show  by induction  that each iteration of ve on N   mimics each iteration of mbe on N   We can then conclude that the product of factors returned by both must be the same  and further  that they are of the same time and space complexity  In particular        we show how ve N  e   e   mimics mbe N  e  first on Line    and then Lines      and    in Algorithms   and    For simplicity  we ignore the constant factor  that the clone CPTs contribute to the MPE value of N     On Line    iteration i       by construction  the CPTs in N are the same as the CPTs in N     after relabeling  For iterations i      assume for induction that the factors available to both ve and mbe are the same  On Line    if mbe picked variable X on Line    then algorithm ve picks variable X         i   which is either X or a clone X  by construction  Lines   and    of Algorithm     On Line    each factor in the set Si is either    a CPT mentioning X  or    a factor that is composed of a CPT mentioning X  The variables that these CPTs belong to are the variable set B  the basis of iteration i  Algorithm   decides to split  or not split   so that each variable in B will have a CPT in N   that mentions X         i   We know by induction  that all factors f selected by mbe are available for selection by ve in N     Since Algorithm   ensures that each of these factors f now mention X     and since ve picks all factors mentioning X     we know ve picks the same factors mbe picked  On Line    consider any variable Z mentioned in Si   Let j  i be the iteration where Z is eliminated in mbe  The relevant CPTs mentioning Z at iteration i are among the relevant CPTs of the basis at iteration j  Thus  Algorithm   ensures that they all mention the same instance of Z in N     Thus  the resulting product of factors fi must be the same after relabeling    A node split network also upper bounds Pr  e   The following theorem corresponds to a mini bucket bound on the probability of evidence  Dechter   Rish         Theorem   Let N be a Bayesian network  and let N   be the result of splitting nodes in N   We then have  Pr  e   Pr    e   e    Q Here     CC  C   where C is the set of clones in network N     Proof of Theorem   By Lemma    we know that  Pr  x    Pr    x   x    Therefore  X X  Pr  e    Pr  x     Pr    x   x  xe    X  xe   Pr  x     Pr    e   e         x  e  e  where x  is an instantiation of variables in N     but where the values of the original network variables are not necessarily compatible with the values of the clone  variables  as they are in x and  x            CHOI ET AL   B  LOOP CUTSET CONDITIONING  The loop cutset conditioning algorithm and split bnb search are closely related when our splitting strategy performs only full splits  see Definition     This correspondence reveals the difficulty of answering the following decision problem  D FS  Given k and   does there exist a set Z of size  k such that fully splitting nodes Z in network N results in an approximate network N   with treewidth    We now state the following negative result  Theorem   Decision problem D FS is NPcomplete  Hardness can be shown by reduction from the loopcutset problem  which is NPcomplete  Suermondt   Cooper         In particular  when we fully split enough variables Z to render N   a polytree  then Z also constitutes a loop cutset of N      If N is rendered a polytree  and we ignore the bound during split bnb search and further employ the reduced search space over split variables Z  then splitbnb reduces to loop cutset conditioning  More generally  when we split enough variables Z so that network N   has treewidth   split bnb reduces to cutset conditioning  Bidyuk   Dechter           Assuming that for exact inference in N   we use an algorithm that is exponential in the treewidth  of N     this correspondence tells us that the worst case time and space complexity of split bnb search is precisely that of cutset conditioning  In particular  say that n is the number of variables in N   value m is the number of variables cloned in N     and value  is the treewidth of network N     The worst case time complexity of split bnb search is thus O n exp    exp m     O n exp    m    since we spend O n exp    time at each of at most exp m  search nodes  Note that the space complexity of split bnb search is only O n exp     m    Choi  A     Darwiche  A       b   A variational approach for approximating Bayesian networks by edge deletion  In UAI  pp        Dechter  R          Bucket elimination  A unifying framework for probabilistic inference  In UAI  pp          Dechter  R   Kask  K     Mateescu  R          Iterative join graph propagation  In UAI  pp          Dechter  R     Rish  I          Mini buckets  A general scheme for bounded inference  J  ACM                   Frey  B  J     MacKay  D  J  C          A revolution  Belief propagation in graphs with cycles  In NIPS  pp          Huang  J   Chavira  M     Darwiche  A          Solving map exactly by searching on compiled arithmetic circuits  In AAAI  pp          Hutter  F   Hoos  H  H     Stutzle  T          Efficient stochastic local search for MPE solving  In IJCAI  pp          Kolmogorov  V     Wainwright   M  J          On the optimality of tree reweighted max product message passing  In UAI  Marinescu  R     Dechter  R          AND OR branchand bound for graphical models  In IJCAI  pp           Marinescu  R   Kask  K     Dechter  R          Systematic vs  non systematic algorithms for solving the MPE task  In UAI  pp          Park  J  D          Using weighted max sat engines to solve MPE  In AAAI IAAI  pp          Pearl  J          Probabilistic Reasoning in Intelligent Systems  Networks of Plausible Inference  Morgan Kaufmann Publishers  Inc   San Mateo  California  Rish  I   Kask  K     Dechter  R          Empirical evaluation of approximation algorithms for probabilistic decoding  In UAI  pp          Sang  T   Beame  P     Kautz  H          Solving Bayesian networks by weighted model counting  In AAAI  Vol     pp          AAAI Press  Suermondt  H  J     Cooper  G  F          Probabilistic inference in multiply connected networks using loop cutsets  IJAR             Wainwright  M  J   Jaakkola  T     Willsky  A  S          Map estimation via agreement on trees  messagepassing and linear programming  IEEE Transactions on Information Theory                      
 We consider in this paper the formulation of approximate inference in Bayesian networks as a problem of exact inference on an approximate network that results from deleting edges  to reduce treewidth   We have shown in earlier work that deleting edges calls for introducing auxiliary network parameters to compensate for lost dependencies  and proposed intuitive conditions for determining these parameters  We have also shown that our earlier method corresponds to Iterative Belief Propagation  IBP  when enough edges are deleted to yield a polytree  and corresponds to some generalizations of IBP when fewer edges are deleted  In this paper  we propose a different criteria for determining auxiliary parameters based on optimizing the KL divergence between the original and approximate networks  We discuss the relationship between the two methods for selecting parameters  shedding new light on IBP and its generalizations  We also discuss the application of our new method to approximating inference problems which are exponential in constrained treewidth  including MAP and nonmyopic value of information      INTRODUCTION  The complexity of algorithms for exact inference on Bayesian networks is generally exponential in the network treewidth  Jensen  Lauritzen    Olesen        Lauritzen   Spiegelhalter        Zhang   Poole        Dechter        Darwiche         Therefore  networks with high treewidth  and no local structure  Chavira   Darwiche        can be inaccessible to these methods  necessitating the use of approximate algorithms  Iterative Belief Propagation  IBP   also known as Loopy  Belief Propagation  Pearl        Murphy  Weiss    Jordan         is one such algorithm that has been critical for enabling certain classes of applications  which have been intractable for exact algorithms  e g   Frey   MacKay         We have proposed in previous work a new perspective on this influential algorithm  viewing it as an exact inference algorithm on a polytree approximation of the original network  Choi   Darwiche        Choi  Chan    Darwiche         The approximate polytree results from deleting edges from the original network  where the loss of each edge is offset by introducing new parameters into the approximate network  We have shown that the iterations of IBP can be understood as searching for specific values of these parameters that satisfy intuitive conditions that we characterized formally  Choi   Darwiche         This has led to a number of implications  On the theoretical side  it provided a new  networkspecific  characterization of the fixed points of IBP  On the practical side  it has led to a concrete framework for improving approximations returned by IBP by deleting fewer edges than those necessary to yield a polytree  that is  we delete enough edges to obtain a multiply connected network which is still tractable for exact inference  In this paper  we consider another criterion for determining the auxiliary parameters introduced by deleting edges  which is based on minimizing the KL divergence between the original and approximate network  This proposal leads to a number of interesting results  First  we provide intuitive  yet necessary and sufficient  conditions that characterize the stationary points of this optimization problem  These conditions suggest an iterative procedure for finding parameters that satisfy these conditions  leading to a new approximate inference method that parallels IBP and its generalizations  Second  the sufficiency of these conditions lead to new results on IBP and its generalizations  characterizing situations under which these algorithms will indeed be optimizing the KLdivergence  We seek to optimize the form of the KLdivergence   U  U  SE U   S  PM U   U  X  X  Figure    Deleting edge U  X by adding a clone U   of U and a binary evidence variable S     that uses weights from the original distribution  and as it turns out  the update equations for our new method are more expensive than those for IBP and its generalizations  requiring the availability of true node marginals in the original network  This means that the method as described is  in general  applicable only to networks whose treewidth is manageable  but whose constrained treewidth is not   That is  this approximation will typically be useful for problems which remain hard even if treewidth is manageable  This includes MAP  Park   Darwiche         inference in credal networks  Cozman  de Campos  Ide    da Rocha         and the computation of nonmyopic value of information  Krause   Guestrin         In complexity theoretic terms  computing node marginals is PP complete  while computing MAP is NPPP complete  Hence  our proposed method can be used to approximate NPPP complete problems  while IBP and its generalizations approximate PPcomplete problems  This paper is structured as follows  Section   reviews the framework of approximating networks by edge deletion  Section   treats the characterization of auxiliary parameters introduced by deleting edges  discussing the new characterization proposed in this paper  and comparing it to the one corresponding to IBP and its generalizations  Section   considers the problem of selecting which edges to delete in order to optimize the quality of approximations  Section   presents empirical results  Section   discusses related work  and Section   closes with some concluding remarks  Proofs of theorems are sketched in Appendix A      DELETING AN EDGE  Let U  X be an edge in a Bayesian network  and suppose that we wish to delete this edge to make the network more amenable to exact inference algorithms  This deletion will introduce two problems  First  variable X will lose its direct dependence on parent U      Networks may admit elimination orders with manageable treewidths  but certain queries may constrain these orders  leading to constrained treewidths   Second  variable U may lose evidential information received through its child X  To address these problems  we propose to add two auxiliary variables for each deleted edge U  X as given in Figure    The first is a variable U   which is made a parent of X  therefore acting as a clone of the lost parent U   The second is an instantiated variable S   which is made a child of U   meant to provide evidence on U in lieu of the lost evidence   Note that the states u  of auxiliary variable U   are the same as the states u of variable U   since U   is a clone of U   Moreover  auxiliary variable S   is binary as it represents evidence  The deletion of an edge U  X will then lead to introducing new parameters into the network  as we must now provide conditional probability tables  CPTs  for the new variables U   and S     Variable U     a root node in the network  needs parameters u  representing the prior marginal on variable U     We will use PM  U     to denote these parameters  where PM  u      u    Variable S     a leaf node in the network  needs parameters s   u representing the conditional probability of s  given U   We will use SE  U   to denote these parameters  where SE  u    s   u   Moreover  we will collectively refer to PM  U     and SE  U   as edge parameters  Figure   depicts a simple network with a deleted edge  together with one possible assignment of the corresponding edge parameters  We have a number of observations about our proposal for deleting edges   The extent to which this proposal is successful will depend on the specific values used for the parameters introduced by deleting edges  This is a topic which we address in the following section   If the deleted edge U  X splits the network into two disconnected networks  one can always find edge parameters which are guaranteed to lead to exact computation of variable marginals in both subnetworks  Choi   Darwiche          The auxiliary variable S   can be viewed as injecting a soft evidence on variable U   whose strength is defined by the parameters SE  U    Note that for queries that are conditioned on evidence s    only the relative ratios of parameters SE  U   matter  not their absolute values  Pearl        Chan   Darwiche         Our goal now is to answer the following two questions  First  how do we parametrize deleted edges  Second  which edges do we delete    Our proposal for deleting an edge is an extension of the proposal given by  Choi et al          who proposed the addition of a clone variable U   but missed the addition of evidence variable S       A  A s   A s   a s   a  S A  B  C  B  C  D  A  a  a   SE  A                PM  A                   D  Figure    A network N  left   an approximate network N   found after deleting A  B  center   along with parameters for auxiliary evidence variable S   and clone A   right       PARAMETRIZING EDGES  Finally  these update equations lead to fixed points characterized by the following conditions   Given a network N and evidence e  our proposal is then to approximate this network with another N   that results from deleting some edges U  X as given earlier  Moreover  when performing inference on network N     we will condition on the augmented evidence e    composed of the original evidence e and all auxiliary evidence s  introduced when deleting edges  More formally  if Pr and Pr   are the distributions induced by networks N and N     respectively  we will use Pr    X e    to approximate Pr  X e  where X is a set of variables in the original network N   To completely specify our approximate network N     we need to specify parameters PM  u    and SE  u  for each edge that we delete  We have proposed in  Choi   Darwiche        an iterative procedure that uses the following update equations to parametrize edges  PM  u       SE  u      Pr    e    s   u Pr    e      u        where  is a normalizing constant   This procedure  which we call ed bp  starts with some arbitrary values for PM  U     and SE  U    leading to an initial approximate network N     This network can then be used to compute new values for these parameters according to the update equations in      The process is then repeated until convergence to a fixed point  if at all   We have also shown that when deleting enough edges to yield a polytree  the parametrizations PM  U     and SE  U   computed in each iteration correspond precisely to the messages passed by IBP  Moreover  if the edges deleted do not yield a polytree  edbp corresponds to a generalization of IBP  simulated by a particular choice of a joingraph  see also Aji   McEliece        Dechter  Kask    Mateescu           This is an alternative  but equivalent  formulation of the update equations given by  Choi   Darwiche          Pr    u e    Pr    u e    s       Pr    u   e       Pr    u           The first condition says that variables U   and U should have the same posterior marginals  The second condition  in light of the first  says that the impact of evidence s  on variable U is equivalent to the impact of all evidence on its clone U     Indeed  these conditions correspond to the intuitions that motivated ed bp       A VARIATIONAL APPROACH  We propose now a variational approach to parametrizing deleted edges  based on the KLdivergence  Pr  w e  def X   KL Pr    e   Pr      e       Pr  w e  log Pr    w e    w where w is a world  denoting an instantiation over all variables  Note that the KLdivergence is not symmetric  the divergence KL Pr    e   Pr      e     is weighted by the true distribution while the divergence KL Pr      e     Pr    e   is weighted by the approximate one  Common practice weighs the KLdivergence using the approximate distribution  which is typically more accessible computationally  e g   Yedidia  Freeman    Weiss         In contrast  we will weigh by the true distribution in what follows  Before we proceed to optimize the KLdivergence  we must ensure that the domains of the distributions Pr    e  and Pr      e    coincide  One way to ensure this is to use the following construction  demonstrated in Figure    Given a Bayesian network N     we can replace each edge U  X to be deleted with a chain U  U    X  where the equivalence edge U  U   denotes an equivalence constraint  u   u     iff u    u  The resulting augmented network N will then satisfy three important properties  First  it is equivalent to the original network N   over common variables  Second  it has the same treewidth as N     Finally  when   U  U  U  SE U   S U  X  For the remainder of this paper  we will only be dealing with augmented networks N   leaving the original network N   implicit  PM U   U  X       Figure    The edge U  X in N   is replaced with a chain U  U    X in N   We delete the equivalence edge U  U   in N to get N     we delete equivalence edges U  U   from N   we get an approximate network N   that does not require the introduction of clone variables U   as they are already present in N      We can therefore compute the KL divergence between the augmented network N and its approximation N      Lemma   Let N be an  augmented  Bayesian network and N   be the network that results from deleting equivalence edges U  U     Then   U U   u u   Pr    e          log u  s   u Pr  e   Since Pr    e    is a function of our edge parameters  the KLdivergence is thus also a function of our edge parameters  This result will be used later to derive update equations for our variational method  and to develop a heuristic for choosing edges to delete  Before we proceed though  we observe the following  Let X be the variables of the original network N   and U  be the clone variables introduced via the equivalence edges U  U   in N   The KL divergence of Lemma   is then over the variables XU    One would normally prefer to optimize the KLdivergence KL Pr  X e   Pr    X e     over the original variables X  but our method will seek to optimize KL Pr  XU   e   Pr    XU   e     instead  In fact  the properties of the KLdivergence tell us that KL Pr  X e   Pr    X e      KL Pr  XU   e   Pr    XU   e            In our experimental results in Section    we will report results on both versions of the KLdivergence  referring to KL Pr  X e   Pr    X e     as the exact KL  and to KL Pr  XU   e   Pr    XU   e     as the KL bound  We still need to add a new child S   for each U however  Since variables S   are observed  they do not prohibit us from computing the KLdivergence between N and N   even though they are not present in network N      We have the KLdivergence KL Pr    e   Pr      e     as a function of our edge parameters PM  u      u  and SE  u    s   u   If we set to zero the partial derivatives of the KLdivergence with respect to each edge parameter  we get the following  Theorem   Let N be a Bayesian network and N   be the network that results from deleting equivalence edges U  U     The edge parameters of N   are a stationary point of KL Pr    e   Pr      e     if and only if Pr    u e      Pr    u   e      Pr  u e         for all deleted edges U  U      We can now state the following key result   KL Pr    e   Pr      e     X X Pr  uu   e  log    THE APPROXIMATE NETWORK  X  That is  if we delete the edge U  U     then the marginals on both U and U   must be exact in the approximate network N     Note  however  that this does not imply that other node marginals must be exact in N     only those corresponding to deleted edges need be  Theorem   has a number of implications  First  the necessity of Condition     will be exploited in the following section to provide an iterative method that searches for parameters that are a stationary point for the KLdivergence  Second  the sufficiency of Condition     implies that any method that searches for edge parameters  regardless of the criteria chosen  will yield parameters that are a stationary point for the KLdivergence  if the parameters give rise to exact marginals for variables corresponding to deleted edges  For example  if we search for parameters using ed bp  Choi   Darwiche         and the parameters found lead to exact marginals  then these parameters will indeed be a stationary point for the KLdivergence  Before we show how to identify parameters satisfying Condition      we note that parameters satisfying Condition     do not necessarily satisfy Condition     and  hence  are not necessarily a stationary point for KL Pr    e   Pr      e      We provide a simple network with four nodes in Appendix B demonstrating this point  Recall that Condition     characterizes IBP and some of its generalizations  Choi   Darwiche              SEARCHING FOR PARAMETERS  Having characterized stationary points of the KL divergence  we now proceed to develop an iterative procedure for finding a stationary point  Our method is based on the following result    Theorem   Let N be a Bayesian network and N   be the network that results from deleting equivalence edges U  U     The edge parameters of N   are a stationary point of KL Pr    e   Pr      e     if and only if      Pr    e                PM  u     Pr  u e  Pr  e    u      Pr    e    SE  u    Pr  u e  Pr    e           s   u We have a number of observations about this theorem  First  if we have access to the true marginals Pr  u e   then this theorem suggests an iterative method that starts with some arbitrary values of parameters PM  u    and SE  u   leading to some initial approximate network N     Using this network  we can      e     e    and Pr compute the quantities Pr    e     Pr u  s   u   which can then be used to compute new values for the parameters PM  u    and SE  u   one set at a time  The process can then be repeated until convergence  if at all   We will refer to this method as ed kl  to be contrasted with ed bp given earlier  Choi   Darwiche         Note that since the KLdivergence is non negative  there exists a set of edge parameters that are globally minimal  However  a stationary point of the KLdivergence is not necessarily a global minima  Second  the availability of the true marginals Pr  u e  typically implies that the network treewidth is small enough to permit the computation of these marginals  Hence  ed kl is in general applicable to situations where the treewidth is manageable  but where the constrained treewidth is not  In these situations  the goal of deleting edges is to reduce the network constrained treewidth  making it amenable to algorithms that are exponential in constrained treewidth  such as MAP  Park   Darwiche         inference in credal networks  Cozman et al          and the computation of nonmyopic value of information  Krause   Guestrin         Third  we have the following result which is critical for the practical application of ed kl  Theorem   Let N be a Bayesian network and N   be the network that results from deleting a single equivalence edge U  U     We then have Pr    e       Pr  e    u   u  X  s   u u      X  s   u     X  u   uu   which implies  Pr    e    u  Pr    e    s   u  u  u   Pr  e    u   u  Pr  e    u   u  The main observation here is that Pr  e  u   u is a function of the original network and  therefore  is independent of the parameters u  and s   u this is why the second and third equations above follow immediately from the first  Given the above equations  we can apply ed kl to a single deleted edge  without the need for inference  That is  assuming that we have computed Pr  e  u   u   we can use the above equations to compute updated values for edge parameters from the old values in constant time  This result will have implications in the following section  as we present a heuristic for deciding which edges to delete      CHOOSING EDGES TO DELETE  Our method for deciding which edges to delete is based on scoring each network edge in isolation  leading to a total order on network edges  and then deleting edges according to the resulting order  For example  if we want to delete k edges  we simply delete the first k edges in the order  The score for edge U  U   is based on the KL divergence between the original network N and an approximate network N   which results from deleting the single edge U  U     The KLdivergence is computed using Lemma    This lemma requires some quantities from the original network N   which can be computed since the network is assumed to have a manageable treewidth  The lemma also requires that we have the parameters u  and s   u for the deleted edge U  U     and the corresponding probability Pr    e     These can be computed relatively easily using Theorem    assuming that we have computed Pr  e  u   u as explained in the previous section  Given these observations  all edge parameters  together with the corresponding KL scores  can be computed simultaneously for all edges using a single evaluation of the original network  Moreover  the computed parameters have another use beyond scoring edges  when used as initial values for ed kl  they tend to lead to better convergence rates  We indeed employ this observation in our experiments      EMPIRICAL ANALYSIS  We present experimental results in this section on a number of Bayesian networks  to illustrate a number of points on the relative performance of ed kl and edbp  We start with Figure   which depicts the quality of computed approximations according to the exact KLdivergence    see Equation    For each approximation scheme  we consider two methods for deleting edges  For ed kl  we delete edges randomly  ed kl  To compute the exact KLdivergence  see  for example   Choi et al            alarm  win  pts            EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided      avg KLdivergence  exact       avg KLdivergence  exact   emdec    EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided                             avg KLdivergence  exact                         EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided                                             edges deleted                         tcc                                             edges deleted          edges deleted                                             EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided  EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided                           chain      EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided  avg KLdivergence  exact   avg KLdivergence  exact       grid                edges deleted  avg KLdivergence  exact                         edges deleted                                   edges deleted              Figure    Comparing ed kl and ed bp using the exact KL  with two methods for edge deletion  alarm  win  pts        avg KLdivergence  bound   avg KLdivergence  bound      emdec     EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided                   EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided  EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided      avg KLdivergence  bound                                                     edges deleted                      edges deleted                            edges deleted            Figure    Comparing ed kl and ed bp using the KL bound  with two methods for edge deletion  alarm  win  pts               EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided                                           EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided           iterations  iterations           iterations      emdec      EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided                               edges deleted                      edges deleted                            edges deleted  Figure    Comparing ed kl and ed bp according to number of iterations to converge              tcc                                           EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided                                                          edges deleted  grid    relative difference     relative difference  relative difference  win  pts    EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided                              edges deleted          EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided                  edges deleted                 Figure    Approximating MAP using ed kl and ed bp  win  pts  tcc         EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided                                      EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided     constrained treewidth  constrained treewidth     constrained treewidth  grid     EDBPRand EDBPMI EDKLRand EDKLGuided EDBPGuided             edges deleted                          edges deleted                           edges deleted                 Figure    Reducing constrained treewidth by deleting edges  The horizontal line denotes network treewidth  as approximated using a min fill heuristic  rand  and according to the heuristic of Section    edkl guided   For ed bp  we delete edges randomly  ed bp rand  and according to a heuristic based on mutual information  ed bp mi  given in  Choi   Darwiche         As is clear from the figures  ed kl is overwhelmingly superior as far as minimizing the KL divergence  sometimes even using random deletion of edges  Figure   depicts sample results for the quality of approximations according to the KLdivergence bound  see Equation    As mentioned earlier  ed kl searches for stationary points of this bound instead of stationary points of the exact KLdivergence  yet empirically one does not see much difference between the two on these networks  Figures   and   depict another approximation scheme  ed bp guided  which deletes edges based on the heuristic of Section    but then uses ed bp to search for parameters instead of ed kl  This is a hypothetical method since the mentioned heuristic assumes that the network treewidth is manageable  a situation under which one would want to apply ed kl instead of ed bp  Yet  our results show that ed bp is consistently very close to ed kl in this case as far as minimizing the KLdivergence  This observation is critical  as it highlights the great importance of heuristics for deleting edges  In particular  these results show that ed bp can do quite well in terms of minimizing the KLdivergence if the right edges are deleted  Figure   depicts sample results on the speed of convergence for both ed kl and ed bp  again using the different methods for edge deletion  In two of these networks  ed kl consistently converges faster than edbp  In the three omitted figures  due to space limitations  ed kl is also superior to ed bp  We consider also sample results from using approximations identified by ed kl to approximate MAP  Figure   depicts the relative difference p q  where p is the value of the MAP solution found in the approximate network N   and q is the value of a MAP solution in the original network N   It is clear from the figure that ed kl guided produces the superior approximations  and can provide accurate solutions even when many edges are deleted  Again  based on the hypothetical method ed bp guided  we see that it is possible for ed bp to produce good MAP approximations as well if the right edges are deleted  Figure   highlights how effective deleting edges is in reducing the constrained treewidth  approximated using a min fill heuristic   and thus how effective deleting   edges is in reducing the complexity of computing MAP  We see that good approximations can be maintained even when the constrained treewidth is reduced to the network treewidth  When we further delete every network edge  we have a fully factorized approximation of MAP  where the constrained  and network  treewidth corresponds to the size of the largest network CPT   ture from ed kl and can lead to much worse behavior for less likely evidence  That is  these approaches approximate a network once for all queries  while ed kl can approximate a network for each specific query   The plots given in this section correspond to averages of at least    instances per data point  where each instance correspond to evidence over all leaf nodes drawn from the network joint  We have also experimented with evidence drawn randomly  not from the joint   leading to similar results  Networks tcc and emdec are courtesy of HRL Labs  LLC  The grid and chain networks are synthetic and available from the authors  Networks alarm and win  pts are available at http   www cs huji ac il labs compbio Repository   We proposed a method  ed kl  for approximating Bayesian networks by deleting edges from the original network and then finding stationary points for the KLdivergence between the original and approximate networks  while weighing the divergence by the true distribution   We also proposed an efficient heuristic for deciding which edges to delete from a network  with the aim of choosing network substructures that lead to high quality approximations      RELATED WORK  Many variational methods pose the problem of approximate inference as exact inference in some approximate model  often seeking to minimize the KL divergence  but weighing it by the approximate distribution  e g   Jordan  Ghahramani  Jaakkola    Saul        Jaakkola        Wiegerinck        Geiger   Meek         One example is the meanfield method  where we seek to approximate a network N by a fully disconnected N    Haft  Hofmann    Tresp         If we delete all edges from the network and try to parametrize edges using ed kl  we would be solving the same problem solved by meanfield  except that our KLdivergence is weighted by the true distribution  leading to more expensive update equations  Other variational approaches typically assume particular structures in their approximate models  such as chains  Ghahramani   Jordan         trees  Frey  Patrascu  Jaakkola    Moran        Minka   Qi         or disconnected subnetworks  Saul   Jordan        Xing  Jordan    Russell         In contrast  ed kl works for any network structure which is a subset of the original  In fact  the efficient edge deletion heuristic of Section   tries to select the most promising subnetworks and is quite effective as illustrated earlier  Again  most of these approaches weigh the KL divergence by the approximate distribution for computational reasons  with the notable exceptions of  Frey et al         Minka   Qi         Other methods of edge deletion have been proposed for Bayesian networks  Suermondt        Kjrulff        van Engelen         some of which can be rephrased using a variational perspective  All of these approaches  however  approximate a network independent of the given evidence  which is a dramatic depar      CONCLUSION  The update equations of ed kl require exact posteriors from the original network  This means that edkl is  in general  applicable to problems that remain hard even when treewidth is manageable  including MAP  nonmyopic value of information  and inference in credal networks  This is to be contrasted with our earlier method ed bp  which updates parameters differently  coinciding with IBP and some of its generalizations  Our empirical results provide good evidence to the quality of approximations returned by ed kl  especially when compared to the approximations returned by ed bp  Moreover  our results  both theoretical and empirical  shed new and interesting light on edbp  and  hence  IBP and some of its generalizations   showing that it can also produce high quality approximations  from a KLdivergence viewpoint   when deleting the right set of network edges  Acknowledgments This work has been partially supported by Air Force grant  FA               P      and by JPL NASA grant            A  Proof Sketches  Note that u  w signifies that u and w are compatible instantiations  Proof of Lemma   Deleting edges U  U     we have  KL Pr    e   Pr      e        X w  Pr  w e  log  Pr  w e  Pr    w e     Pr    e    Pr  w  e    log   Pr  w e  log     Pr  w  e   Pr  e  w X Y u   u Pr    e      log   Pr  w e  log u  s   u Pr  e    w X  uu w      X X  Pr  w e  log  w uu  w     X X X  u   u Pr    e      log u  s   u Pr  e   Pr  w e  log  U U   uu  w  uu      X X  Pr  uu   e  log  U U   uu      u   u Pr    e      log u  s   u Pr  e     Pr    e    Pr  uu   e  log     log u  s   u Pr  e     U U   u u  The last equation follows  since when u does not agree with u    we have that Pr  uu   e  log u   u     log    which we assume is equal to zero  by convention    Proof of Theorem   Note that when u   u    we have Pr  uu   e    Pr  u e    Pr  u   e   First direction of theorem  Let f be the KLdivergence as given in Lemma    Setting f  u  to zero  we get     Pr    u    e    u  Pr    e        Pr    u   e        Pr  e   u  Pr    e     Similarly  to show Pr  u e    Pr    u e     Note that constraints such as normalization are inactive here  Second direction of theorem  Given a network N   where marginals on U and U   are exact  we want to verify that the edge parameters are stationary points  If we take the partial derivative with respect to u        f u  Pr    e      Pr  u e      u  u  Pr    e    u        Pr    u    e      Pr  u e    u  Pr    e       Pr  u e    Pr    u   e         u  We are given Pr    u   e      Pr  u e   thus f  u       Similarly  to show f  s   u        Proof of Theorem   Equation   follows easily from Equation    Equation   follows from f  s   u     Proof of Theorem   First  we have  X Pr    e      Pr    uu    e    uu   uu   s   u u   X   U   X   S  U   X   X Pr    u  e     Pr    e        s   u u  s   u u  u    uu  Note that the distribution induced by a network where a single edge U  U   has been deleted is equivalent to  U   Figure    An example network N  left  where deleting a single edge  right  may have infinitely many ed bp fixed points   the distribution induced by another network N   that is identical in structure to N   except that u   u   u  for all u  We then have        where u agrees with u    We then have     U   Pr    e          Pr  u e    Pr  e   f          u  u  Pr    e    u   X  X   u   u Pr    e      log u  s   u Pr  e   X X  Pr  u e     U   X  s   u u   uu   Pr    e  X Pr  e      s   u u  u   u u   u    The other relations follow easily   B  uu     Example  We demonstrate here an example where ed bp fixed points are not necessarily stationary points of the KLdivergence  This example also shows that even if we delete a single edge  ed bp can have infinitely many parametrizations satisfying Condition      even though there exists an ed bp  and ed kl  fixed point minimizing the KL bound  KL Pr    e   Pr      e      as well as minimizing the exact KL   This example also corresponds to an instance of IBP  with a particular message passing schedule   since edge deletion renders the network a polytree  Choi   Darwiche         Our example is depicted in Figure    Variables Ui have parameters ui   ui        Variables Xj are fixed to states xj   and assert the equivalence of U  and U    xj  u  u      iff u    u    Conditioning on evidence e   x  x    we have Pr  u   e    Pr  u   e         If we delete the edge U   X   implicitly  we delete an edge U   U      then any non zero parameterization of our edge parameters satisfies the ed bp fixed point conditions given by Condition      For example  when s   u    s   u         and u     u          the KLdivergence is zero and thus minimized  yielding parent and clone marginals that are exact  By Theorem    edges parameters are then a stationary point of the KLdivergence  However  when u           the parent and clone marginals are not exact  and thus edges parameters are not a stationary point of the KL divergence  again by Theorem      
 We propose an approach for approximating the partition function which is based on two steps      computing the partition function of a simplified model which is obtained by deleting model edges  and     rectifying the result by applying an edge by edge correction  The approach leads to an intuitive framework in which one can trade off the quality of an approximation with the complexity of computing it  It also includes the Bethe free energy approximation as a degenerate case  We develop the approach theoretically in this paper and provide a number of empirical results that reveal its practical utility      INTRODUCTION  We presented in prior work an approach to approximate inference which is based on performing exact inference on a simplified model  Choi   Darwiche      a      b   We proposed obtaining the simplified model by deleting enough edges to render its treewidth manageable under the current computational resources  Interestingly enough  the approach subsumes iterative belief propagation  IBP  as a degenerate case  and provides an intuitive framework for capturing a class of Generalized Belief Propagation  GBP  approximations  Choi   Darwiche      a  Yedidia  Freeman    Weiss         We show in this paper that the simplified models can also be used to approximate the partition function if one applies a correction for each deleted edge  We propose two edge correction schemes  each of which is capable of perfectly correcting the partition function when a single edge has been deleted  The first scheme will have this property only when a particular condition holds in the simplified model  and gives  rise to the Bethe free energy approximation when applied to a tree structured approximation  see Yedidia et al         for more on the Bethe approximation and its relationship to IBP   The second correction scheme does not require such a condition and is shown empirically to lead to more accurate approximations  Both schemes can be applied to the whole spectrum of simplified models and can therefore be used to trade off the quality of obtained approximations with the complexity of computing them  This new edge correction perspective on approximating the partition function has a number of consequences  First  it provides a new perspective on the Bethe free energy approximation  and may serve as a tool to help identify situations when Bethe approximations may be exact or accurate in practice  Next  it suggests that we do not necessarily need to seek good approximations  but instead seek approximations that are accurately correctable  To this end  we propose a heuristic for finding simplified models that is specific to the task of correction  Finally  it provides the opportunity to improve on edge deletion approximations  and certain GBP approximations   with only a modest amount of computational effort  In particular  we show empirically how it is possible to correct only for a small number of edges that have the most impact on an approximation  Proofs of results appear in the Appendix      EDGE DELETION  We first review our edge deletion framework in probabilistic graphical models  For simplicity  we consider pairwise Markov random fields  although our framework can easily be extended to general Markov networks as well as to factor graphs  For an application to directed models  see  Choi   Darwiche      a   Let a pairwise Markov random field  MRF  M have a graph  E  V  with edges  i  j   E and nodes i  V    function will be denoted by Z      and its distribution will be denoted by Pr          When choosing a particular value for edge parameters   we will drop reference to   using only M    Z   and Pr         Figure    An MRF  left   after edge deletion  right     Xi   X j    i   Xi   Xk    i  j   Xk   X j   k   Xk   X j    i  k   Xi     Xk    j j  Figure    To delete edge  i  j   top   we introduce auxiliary node k  middle   and delete equivalence edge  i  k   adding edge parameters  bottom   where each node i of the graph is associated with a variable Xi taking on values xi   Edges  i  j  are associated with edge potentials  xi   xj   and nodes i with node potentials  xi    The  strictly positive  distribution Pr induced by M is defined as follows  Pr  x   def     Y   Y  xi   xj    xi    Z  i j E  iV  where x is an instantiation x            xn of network variables  and where Z is the partition function  Z  def     X Y x  i j E   xi   xj    Y   xi     iV  The basic idea behind our framework is to delete enough edges from the pairwise MRF to render it tractable for exact inference  Definition   Let M be a pairwise MRF  To delete edge  i  j  from M we remove the edge  i  j  from M and then introduce the auxiliary potentials  Xi   and  Xj   for variables Xi and Xj    Note that while the distribution Pr     and partition function Z of the original pairwise MRF M may be hard to compute  the distribution Pr         and partition function Z      of M     should be easily computable due to edge deletion  Note also that before we can use Pr         and Z      to approximate Pr     and Z  we must first specify the edge parameters   In fact  it is the values of these parameters which will control the quality of approximations Pr         and Z       Without loss of generality  we will assume that we are only deleting equivalence edges  i  j   which connect two variables Xi and Xj with the same domain  and have a potential  xi   xj   that denotes an equivalence constraint   xi   xj       if xi   xj   and  xi   xj       otherwise  The deletion of any edge in an MRF can be formulated as the deletion of an equivalence edge   As for the values of the edge parameters  we proposed  and justified  in  Choi   Darwiche      a  the following conditions on  xi   and  xj     xi       and   xj       Z    xi         where  is a normalizing constant  Note that the partial derivatives of Equation   can be computed efficiently in traditional inference frameworks  Darwiche        Park   Darwiche         Equation   can also be viewed as update equations  suggesting an iterative method that searches for edge parameters  which we called ed bp  Choi   Darwiche      a   Starting with an initial approximation M   at iteration t      say  with uniform parameters   we can compute edge parameters t  xi   and t  xj   for an iteration t     by performing exact inference in the approximate network M t    We repeat this process until we observe that all parameters converge to a fixed point satisfying Equation    if ever   Note that Equation   does not specify a unique value of edge parameters  due to the constants   That is  each value of these constants will lead to a different set of edge parameters  Yet  independent of which constants we use  the resulting pairwise MRF M  will    Figure   provides an example of deleting an edge  When deleting multiple edges  note that we may introduce multiple  yet distinct  potentials  Xi   for the same node Xi   We shall refer to auxiliary potentials  Xi   and  Xj   as edge parameters and use  to denote the set of all edges parameters  The resulting pairwise MRF will be denoted by M      its partition  Z    xj    To delete an MRF edge  i  j  that is not an equivalence edge  we use the technique illustrated in Figure    we introduce an auxiliary node k between i and j  introduce an equivalence constraint on the edge  i  k   copy the original potential of edge  i  j  to  k  j   and delete the equivalence edge  i  k   Note that the original model and the extended one will      have the same treewidth      agree on the distribution over their common variables  and     have the same partition function values    have an invariant distribution Pr       that satisfies the following properties  First  Pr    xi     Pr    xj          xi   xj    zij       P where zij   xi  xj  xi   xj    Next  if the pairwise MRF M  has a tree structure  the node and edge marginals of distribution Pr       will correspond precisely to the marginals obtained by running IBP on the original model M  Moreover  if the pairwise MRF M  has loops  the node marginals of distribution Pr   will correspond to node marginals obtained by running generalized belief propagation  GBP  using a particular joingraph for the original model M  Yedidia et al         Choi   Darwiche      a       EDGE CORRECTION  the exact partition function Z  Moreover  the result of this correction is invariant to the constants  used in Equation    From now on  we will use MI  Xi   Xj   to denote the mutual information between two variables Xi and Xj   computed in the simplified MRF M    Moreover  when MI  Xi   Xj        we will say that the deleted edge  i  j  is a zero MI edge  Note that while an edge may be zero MI in M    the mutual information between Xi and Xj in the original MRF M may still be high  Let us now consider the more realistic situation where we delete multiple edges  say E     from M to yield the model M    We propose to accumulate the above correction for each of the deleted edges  leading to a corrected partition function Z    z    where z   Y  i j E    While the edge parameters specified by Equation   are guaranteed to yield an invariant distribution Pr        they are not guaranteed to yield an invariant partition function Z   as this function is sensitive to the choice of constants   Hence  while these edge parameters will yield an interesting approximation of node marginals  they do not yield a meaningful approximation of the partition function  We will show in this section  however  that one can apply an edge by edge correction to the partition function Z     leading to a corrected partition function that is invariant to the choice of constants   This seemingly subtle approach leads to two important consequences  First  it results in a semantics for the Bethe free energy approximation as a corrected partition function  Second  it allows for an improved class of approximations based on improved corrections       ZERO EDGE CORRECTION  We will now propose a correction to the partition function Z     which gives rise to the Bethe free energy and some of its generalizations  Proposition   Let M  be the result of deleting a single equivalence edge  i  j  from a pairwise MRF M  If the parameters of edge  i  j  satisfy Equation    and if the mutual information between Xi and Xj in M  is zero  then  Z   Z        zij  where  zij    X   xi   xj     xi  xj  That is  if we delete a single edge  i  j  and find that Xi and Xj are independent in the resulting model M    we can correct the partition function Z   by zij and recover  zij    Y  X   i j E    xi  xj   xi   xj          We will refer to this correction as a zero MI edge correction  or ec z  This correction is no longer guaranteed to recover the exact partition function Z  even if each of the deleted edges is a zero MI edge  Yet  if the pairwise MRF M  has a tree structure  applying this correction to the partition function Z   gives rise to the Bethe free energy approximation  To review  the Bethe free energy F   is an approximation of the true free energy F of a pairwise MRF M  and is exact when M has a tree structure  Yedidia et al          In this case  F    log Z  so we can in principle use F as an approximation of the partition function Z  even when M does not have a tree structure  i e   we can use Z   exp F    Theorem   Let M  be the result of deleting equivalence edges from a pairwise MRF M  If M  has a tree structure and its edge parameters are as given by Equation    we have Z   Z    z    Hence  the Bethe approximation of Z is a degenerate case of the ec z correction  Thus  IBP and the closely related Bethe approximation  which are exact when an MRF M is a tree  are naturally characterized by treestructured ed bp approximations M    In particular  exact inference in the simplified network M  yields      node and edge marginals that are precisely the approximate marginals given by IBP  Choi   Darwiche      a   and now     a rectified partition function that is precisely the Bethe approximation  cf   Wainwright  Jaakkola    Willsky            Wainwright et al  proposed tree based reparametrization  TRP   an algorithm that iteratively reparameterizes the node and edge potentials of a pairwise MRF  At convergence  the node and edge potentials of a tree  any tree    Since the ec z correction is specified purely in quantities available in the model M    it will be easily computable as long as the model M  is sparse enough  i e   it has a treewidth that is manageable under the given computational resources   Hence  this correction can be practically applicable even if M  does not have a tree structure  In such a case  the correction will lead to an approximation of the partition function which is superior to the one obtained by the Bethe free energy  We will illustrate this point empirically in Section         GENERAL EDGE CORRECTION  Proposition   gives us a condition that allows us to correct the partition function exactly  but under the assumption that the single edge deleted is zero MI  The following result allows us  in fact  to correct the partition function when deleting any single edge  Proposition   Let M  be the result of deleting a single equivalence edge  i  j  from a pairwise MRF M  If the parameters of edge  i  j  satisfy Equation    then  Z   Z    yij   zij  where  yij    X  Pr    xi   xj     xi  xj  Note that when the deleted edge  i  j  happens to be zero MI  factor yij is    and thus Proposition   reduces to Proposition    We can also use this proposition as a basis for correcting the partition function when multiple edges are deleted  just as we did in Equation    In particular  we now propose using the correction Z    yz   where z is the same factor given in Equation    and Y X Y Pr    xi   xj        yij   y   i j E     i j E   xi  xj  which we refer to as a general edge correction  or ec g  We note that when every edge is deleted in an ed bp network M    every deleted edge becomes a zero MI edge  Thus  in this case  ec g reduces to ec z  and both yield the Bethe free energy  as in Theorem    As we recover more edges  we may expect ec g to offer embedded in the reparametrized MRF induces a distribution whose exact node and edge marginals are consistent with the corresponding marginals given by IBP  In contrast to ed bp  TRPs embedded tree distributions are already normalized  i e   their partition function is    Moreover  generalizations of TRP appeal to auxiliary representations  via reparametrization in joingraphs and hypergraphs  In contrast  the semantics of ed bp suggest that we simply delete fewer edges  As we shall see in Section    the semantics of edge correction further suggest intuitive edge recovery heuristics for choosing more structured approximations     X         X  X                        Figure    An MRF  left   after deleting edge         as in Figure    right   improved approximations over ec z  as it relaxes the zero MI assumption for deleted edges  Accordingly  we may want to delete different edges for ec g than we would for ec z      AN EXAMPLE  We provide here an illustrative example of our edge correction techniques  Consider a network of three nodes X    X  and X  that form a clique  with the following edge potentials  Xi xi xi xi xi  Xj xj xj xj xj   X    X                  X    X                  X    X                         Suppose now that we delete the edge        by replacing        with a chain                      and deleting the equivalence edge           see Figure    Using ed bp to parameterize this deleted edge  we have  to   digits   Xi xi xi   X                  X                  and we compute Z            In this example  edge          happens to be a zero MI edge  so yij     and zij          Further  we know that both Propositions   and   allow us to recover the true partition function Z   Z    z ij          Now  suppose that we replace the potential on edge        with     X    X     In this case  ed bp gives us edge parameters  to   digits   Xi xi xi   X                  X                  and we compute Z            In this case  edge          is not a zero MI edge  Here  we find that yij         and zij          Since we only delete a single edge  Proposition   recovers the true partition function Z   yij           whereas Proposition   gives only an Z    zij approximation Z    z ij               EDGE RECOVERY  noisyor  ECZ      k       Suppose we already have a tree structured approximation M  of the original model M  but are afforded more computational resources  We can then improve the approximation by recovering some of the deleted edges  However  which edges recovery would have the most impact on the quality of the approximation  Edge Recovery for EC Z  Since ec z is exact for a single deleted edge when MI  Xi   Xj        one may want to recover those edges  i  j  with the highest mutual information MI  Xi   Xj    In fact  this is the same heuristic proposed by  Choi   Darwiche      a  for improving marginal approximations  We will indeed show the promise of this heuristic for ec z corrections  in Section    On the other hand  we also show that it turns out to be a poor heuristic for ec g corrections  Edge Recovery for EC G  Consider the situation when two equivalence edges are deleted   i  j  and  s  t   In this case  we use the approximate correction  Z    yij yst y   Z     z zij zst  y  ij where zij is the single edge correction for edge  i  j  yst and zst is the single edge correction for edge  s  t    The question now is  When is this double edge correction exact  Intuitively  we want to identify a situation where each edge can be corrected  independently of the other  Consider then the case where variables Xi   Xj are independent of variables Xs   Xt in M       Proposition   Let M be the result of deleting two equivalence edges   i  j  and  s  t   from a pairwise MRF M  If the edge parameters of M  satisfy Equation    and if MI  Xi Xj   Xs Xt       in M    then  Z   Z    yij yst   zij zst  This suggests a new edge recovery heuristic for ec g approximations to the partition function  Initially  we start with a tree structured network M    We assign each deleted edge  i  j  a score  X MI  Xi Xj   Xs Xt     s t E     i j   We then prefer to recover the top k edges with the highest mutual information scores      EXPERIMENTS  Our goal here is to highlight different aspects of edgecorrection  edge recovery  and further a notion of partial correction  Starting from a random spanning tree  relative error      k                    k            k            edges recovered         Figure    Edge correction in noisy or networks   dropping instances where ed bp and hence IBP  do not converge   we rank each deleted edge  and recover edges k at a time until all edges are recovered  At each point  we evaluate the quality of the approximab  Z  Z  where tion by the average relative error  Z b Z denotes the designated approximation  Remember that in a tree structured approximation  when no edge is recovered  ec z corresponds to the Bethe approximation  Likewise  when every edge is recovered  both ec z and ec g are exact  Although  for simplicity  we presented our edge correction framework in the context of pairwise MRFs  some of our experiments are run on Bayesian networks  to which all of our results also apply   In these cases  observations are generated from the joint distribution over all leaves  unless otherwise specified  Noisy or  We consider first random two layer noisyor networks  Deleting an edge in this network effectively disconnects a cause variable C from an effect variable E  where a clone C replaces C as a a cause of E   In this situation  we may use edge correction to reason how well ec z and the Bethe approximation may perform  With no positive findings  for example  we know that all causes are pairwise mutually independent  including a cause C and its clone C in a noisy or network where edges have been deleted  Starting from a tree structured approximation  corresponding to the Bethe approximation  every recoverable edge is zeroMI and will remain zero MI up to the point where all edges are recovered  Thus we may infer ec z to be exact throughout  and thus also that the Bethe approximation is exact  Consider now Figure    which compares the quality of ec z corrections as edges are recovered randomly  We generated over     random noisy or networks   where    Most of the Bayesian networks used here are available at http   www cs huji ac il labs compbio Repository    As in Section    we replace edge C  E with a chain C  C  E  and delete the equivalence edge C  C    Each network was given    roots and    sinks  where   for each network  we randomly chose k of    effect variables as positive findings and the remaining effect variables as negative findings  We have   cases here measuring the quality of the ec z approximation  each an average over a range of positive findings                    As predicted  the ec z and Bethe approximations are exact with   positive findings  Given this  we expect  and observe  that with more positive findings  and fewer zero MI edges  the ec z and Bethe approximations tend to be less accurate  Edge recovery  Consider now Figure    where we compare ec z corrections to ec g corrections  but also the impact that different edge recovery heuristics can have on an approximation  Here  plots are averages of over    instances  In the first plot  we took random    grid networks  where pairwise couplings were randomly given parameters in            or             First  when we compare ec z and ec g by random edge recovery  we see that ec g is a notable improvement over ec z  even when no edges are recovered  When we use the mutual information heuristic  MI  designed for ec z  the ec z approximations also improve considerably  However  ec g approximations are worse than when we randomly recovered edges  Although ec g approximations still dominate the ec z ones  this example illustrates that ec z approximations  based on the Bethe approximation  and ec g approximations  based on exact corrections for a single edge  are of a different nature  and suggest that an alternative approach to recovery may be needed  Indeed  when we use the mutual information heuristic  MI   designed for ec g  we find that ec g easily dominates the first four approximations  We see similar results in the win  pts and water networks  Partial corrections  Although the individual edgecorrections for ec z are trivial to compute  the corrections for ec g require joint marginals  In the case where we need to correct for many deleted edges  the ec g corrections of Equation   may become expensive to compute  We may then ask  Can we effectively improve an approximation  by correcting for only a subset of the edges  Consider then Figure    where we plot how the quality of our approximation evolves over time  averaged over    instances   over two steps      the ed bp parametrization algorithm  and after convergence     ec g edge correction  On the first half of each plot  we start with a tree structured approximate network  and compute the ec z approximation as ed bp  and equivalently  IBP  in this case  runs for a fixed number of iterations  Eventually  the edge corrected partition function converges  to the Bethe approximation   at sinks are given   random parents  Network parameters were also chosen randomly   which point we want to compute the edge corrections for ec g  We can compute the corrections for an edge  one by one  applying them to the ec z approximation as they are computed  Since edge corrections are invariant to the order in which they are computed  we can then examine a notion of a partial ec g approximation that accumulates only the correction factors for a given subset of deleted edges  On the right half of each plot  we compute the error in a partial ec g approximation given two separate orderings of deleted edges  The first ordering  which we consider to be optimal  pre computes corrections for all edges and sorts them from largest to smallest  In the win  pts network  we find that in fact  most of the edges have very little impact on the final ec g approximation  Moreover  the time it took to compute the most important corrections required only as much time as it took ed bp  IBP  to converge  This suggests that it is possible to improve on the Bethe approximation  with only a modest amount of additional computation  in the time to compute corrections for the important edges   Of course  such an approach would require a way to identify the most important corrections  without actually computing them  In  Choi   Darwiche         we proposed a soft extension of d separation in polytree Bayesian networks that was shown to be effective in ranking edges for the process of edge recovery  as in ec z   Applying it here to the task of ranking edgecorrections  we find that it is also effective at identifying important edges for correction  For example  in the win  pts network  soft d separation  sd sep  is nearly as competitive with the optimal at producing partial ec g approximations  Moreover  soft d separation is much more efficient  requiring only node and edge marginals to rank all deleted edges  We see a similar story in the pigs and mildew network  In the mildew network  where many deleted edges have an impact on the approximation  the quality of the approximation tends to improve monotonically  on average   so we may still desire to perform as many individual corrections as resources allow      EDGE CORRECTIONS AND FREE ENERGIES  As the Bethe free energy is an edge corrected partition function  ec z and ec g approximations can be viewed also from the perspective of free energies  When the model M  is a tree  ec z yields the influential Bethe free energy approximation  Yedidia et al          When the model M  has cycles  it can be shown that ec z corresponds more generally to jo          ECZ rand ECG rand ECZ MI ECG MI ECG MI       relative error  relative error        water  win  pts       ECZ rand ECG rand ECZ MI ECG MI ECG MI                                                                      ECZ rand ECG rand ECZ MI ECG MI ECG MI         relative error   x  grid       edges recovered           edges recovered         edges recovered      Figure    ec z versus ec g  and edge recovery  win  pts                   mildew EDBP ECG opt ECG sdsep      relative error  relative error       pigs     EDBP ECG opt ECG sdsep                                                  EDBP ECG opt ECG sdsep       relative error                time  ms             time  ms                                time  ms          Figure    Time to parametrize by ed bp  and compute ec g corrections  ingraph free energy approximations  Aji   McEliece        Dechter  Kask    Mateescu         see  Choi   Darwiche      a  for the connection to iterative joingraph propagation  The ec g correction can also take the form of another free energy approximation  Note first that when multiple equivalence edges are deleted  we can compute the   partition function Zij of a model M ij where the single edge  i  j  has been recovered  keeping edge parameyij     Therefore  ters for all other edges fixed   Zij   Z    zij we have that    Y yij Y Zij y     Z   Z     Z   z zij Z       i j E   i j E    y This yields a  dual  P energy of  the form  log Z  z        n   log Z   i j E   log Zij   where n is the number of equivalence edges  i  j  deleted  Whereas we fixed  somewhat arbitrarily  our edge parameters to satisfy Equation    we could in principle seek edge parameters optimizing the above free energy directly  giving rise to EP and GBP free energy approximations with higher order structure  Welling  Minka    Teh         On the other hand  edge recovery heuristics for ec g could possibly serve as a heuristic for identifying improved EP and GBP free energies  directly  This is a perspective that is currently being investigated   While we are concerned mostly with IBP and the closely related Bethe free energy approximation  we expect that an edge correction perspective may be use   ful in improving other reasoning algorithms  particularly those that can be formulated as exact inference in simplified models  These include  as we have shown here  IBP and some of its generalizations  Yedidia et al          but also numerous variational methods  Jordan  Ghahramani  Jaakkola    Saul        Wiegerinck        Geiger  Meek    Wexler        and their corresponding free energy approximations  Also related  is tree reweighted belief propagation  TRW   Wainwright  Jaakkola    Willsky         which provides upper bounds on the log partition function  and can be thought of as a convexified form of the Bethe free energy  Mean field methods and its generalizations are another well known class of approximations that provide lower bounds on the partition function  e g   Saul   Jordan        Jaakkola         Although the latter have been found to be useful  others have found that the Bethe free energy can often provide better quality approximations   e g   Weiss         Similarly  comparing ec z approximations and mean field bounds derived from approximations with the same structure  we find that ec z  which does not guarantee bounds  offers better approximations      CONCLUSION  We proposed an approach for approximating the partition function which is based on two steps      computing the partition function of a simplified model which is obtained by deleting model edges  and     rectifying   the result by applying an edge by edge correction  The approach leads to an intuitive framework in which one can trade off the quality of an approximation with the complexity of computing it through a simple process of edge recovery  We provided two concrete instantiations of the proposed framework by proposing two edge correction schemes with corresponding heuristics for edge recovery  The first of these instantiations captures the well known Bethe free energy approximation as a degenerate case  The second instantiation has been shown to lead to more accurate approximations  more so when edge recovery is targeted towards accurate correction  We further highlighted  in our experiments  how edge correction could be used as a conceptual tool to help identify situations where the Bethe approximation may be exact  or accurate  Finally  we suggested a notion of partial correction  that can improve on the Bethe approximation with only a modest amount of computational effort   This work has been partially supported by Air Force grant  FA               and by NSF grant  IIS          PROOFS  Note that Proposition   follows from Proposition    Proof of Theorem   When a given model is a tree  the Bethe free energy is exact  We then consider the exact energy of a tree structured M  where F      log Z     Our goal then is to show that Z   Z    z    or equivalently  F     F  log z  Let E      denote expectations and H     denote entropies with respect to IBP beliefs  and equivalently  ed bp marginals in M   Choi   Darwiche      a   First  note that F   U  H where U is the Bethe average energy X X U    E  log  Xi   Xj      E  log  Xi     iV   i j E  and where H is the Bethe approximate entropy H    X  i j E  H  Xi   Xj     The average energy U   and the entropy H   for M  is X  U      E  log  Xi   Xj       X    X  H    X   ni    H  Xi    iV  where ni is the number of neighbors of node i in M  for details  see Yedidia et al          It will be convenient to start with the case where every edge  i  j  in the unextended model is replaced with a chain   i  i      i    j       j     j    We then delete all equivalence edges  i  i      j     j   E     Note that the resulting  E  log  Xi      E  log  Xi   Xi        i i   E      X iV   i   j    E  H  Xi   Xj      X  H  Xi     iV   i   j    E    Since  xi   xj     zij Pr  xi    see Equation     we have E  log  Xi   Xi        log zij  H  Xi          We can show through further manipulations that X  E  log  Xi   Xi        log z   X  ni H  Xi     iV   i i   E    Acknowledgments  A  network M  has n    m nodes  n nodes i  V  and   clone nodes i    j   for each of the m edges  i    j      E   After substituting into U    and some rearrangement  F     U    H     U  H  log z   F  log z as desired  To show this correspondence continues to hold for any tree structured M    we note first that IBP beliefs continue to be node and edge marginals for any tree structured ed bp approximation M    Next  when we recover an edge into a tree approximation that yields another tree approximation  we lose an expectation over edge parameters  Equation     The corresponding node entropy H  Xi   that is lost in the average energy U   is canceled out by a node entropy gained in the entropy H     Finally  the term log zij that is lost is no longer needed in the correction factor z after recovery  Thus  we can recover edges into our fully disconnected approximation  and conclude that F     F  log z continues to hold for any treestructured approximation M      Proof of Proposition   In an extended network M with equivalence edge  i  j  and potential  xi   xj    Z   X xi  xj  X  Z   Z    xi   xj   x  x  xi   xj   i  j  X Z   Pr    xi   xj   X Z   Pr    xi   xj        xi   xj   zij Pr    xj   x  x x  x i  j        Z zij  X  i  j  Pr    xi   xj    xi  xj y  ij which is simply Z    zij   Note that the fourth equality follows from Equation        Proof of Proposition   In an extended network M with equivalence edges  i  j  and  s  t  and edge potentials  xi   xj   and  xs   xt    X  Z Z  xi  xj  xi   xj   xs   xt   xs  xt     X xi  xj xs  xt      Z    xi   xj   xs   xt    X Z   Pr    xi   xj   xs   xt   xi  xj  xi   xj   xs   xt   X Z   Pr    xi   xj   xs   xt       xi  xj zij Pr  xj  zst Pr  xt    Saul  L  K     Jordan  M  I          Exploiting tractable substructures in intractable networks  In Advances in Neural Information Processing Systems  NIPS   pp           by Eq     xs  xt     Wainwright  M  J   Jaakkola  T     Willsky  A  S          Tree based reparameterization framework for analysis of sum product and related algorithms  IEEE Transactions on Information Theory                     Z   X Pr    xi   xj  Pr    xs   xt   zij zst xi  xj Pr    xj  Pr    xt   xs  xt  X Z  X Pr    xs  xt   Pr    xi  xj     zij zst x  x x  x i  j     yij yst zij zst    which is simply Z   s  Jordan  M  I   Ghahramani  Z   Jaakkola  T     Saul  L  K          An introduction to variational methods for graphical models  Machine Learning                  Park  J     Darwiche  A          A differential semantics for jointree algorithms  Artificial Intelligence                xs  xt     Jaakkola  T          Tutorial on variational approximation methods  In Saad  D     Opper  M   Eds    Advanced Mean Field Methods  MIT Press   t     
  optimal solution  by simply reasoning about the behavior of its underlying inference method   We propose a method called EDML for learning MAP parameters in binary Bayesian networks under incomplete data  The method assumes Beta priors and can be used to learn maximum likelihood parameters when the priors are uninformative  EDML exhibits interesting behaviors  especially when compared to EM  We introduce EDML  explain its origin  and study some of its properties both analytically and empirically   Even though EDML originates in a rather involved approximate inference scheme  its update equations can be intuitively justified independently  We therefore present EDML initially in Section   before delving into the details of how it was originally derived in Section     INTRODUCTION  We consider in this paper the problem of learning Bayesian network parameters given incomplete data  while assuming that all network variables are binary  We propose a specific method  EDML   which has a similar structure and complexity to the EM algorithm  Dempster  Laird    Rubin        Lauritzen         EDML assumes Beta priors on network parameters  allowing one to compute MAP parameters  When using uninformative priors  EDML reduces to computing maximum likelihood  ML  parameters  EDML originated from applying an approximate inference algorithm  Choi   Darwiche        to a meta network in which parameters are explicated as variables  and on which data is asserted as evidence  The update equations of EDML resemble the ones for EM  yet EDML appears to have different convergence properties which stem from its being an inference method as opposed to a local search method  For example  we will identify a class of incomplete datasets on which EDML is guaranteed to converge immediately to an    EDML stands for Edge Deletion MAP Learning or Edge Deletion Maximum Likelihood as it is based on an edge deletion approximate inference algorithm that can compute MAP or maximum likelihood parameters   Intuitively  EDML can be thought of as relying on two key concepts  The first concept is that of estimating the parameters of a single random variable given soft observations  i e   observations that provide soft evidence on the values of a random variable  The second key concept behind EDML is that of interpreting the examples of an incomplete data set as providing soft observations on the random variables of a Bayesian network  As to the first concept  we also show that MAP and ML parameter estimates are unique in this case  therefore  generalizing the fundamental result which says that these estimates are unique for hard observations  This result is interesting and fundamental enough that we treat it separately in Section   before we move on and discuss the origin of EDML in Section    We discuss some theoretical properties of EDML in Section    where we identify situations in which it is guaranteed to converge immediately to optimal estimates  We present some preliminary empirical results in Section   that corroborate some of the convergence behaviors predicted  In Section    we close with some concluding remarks on related and future work  We note that while we focus on binary variables here  our approach generalizes to multivalued variables as well  We will comment later on this and the reason we restricted our focus here      TECHNICAL PRELIMINARIES  We use upper case letters  X  to denote variables and lower case letters  x  to denote their values  Variable   sets are denoted by bold face upper case letters  X  and their instantiations by bold face lower case letters  x   Since our focus is on binary variables  we use x  positive  and x  negative  to denote the two values of binary variable X  Generally  we will use X to denote a variable in a Bayesian network and U to denote its parents  A network parameter will therefore have the general form x u   representing the probability Pr  X   x U   u   Note that variable X can be thought of as inducing a number of conditional random variables  denoted Xu   where the values of variable Xu are drawn based on the conditional distribution Pr  X u   In fact  parameter estimation in Bayesian networks can be thought of as a process of estimating the distributions of these conditional random variables  Since we assume binary variables  each of these distributions can be characterized by the single parameter x u   since x u    x u   We will use  to denote the set of all network parameters  Given a network structure G in which all variables are binary  our goal is to learn its parameters from an incomplete dataset  such as  example        X x   x  Y y y    Z     z  We use D to denote a dataset  and di to denote an example  The dataset above has three examples  with d  being the instantiation X   x  Z   z  A commonly used measure for the quality of parameter estimates  is their likelihood  defined as  QN L  D    i   Pr   di    where Pr  is the distribution induced by network structure G and parameters   In the case of complete data  each example fixes the value of each variable   the ML parameters are unique  Learning ML parameters is harder when the data is incomplete  where EM is typically employed  EM starts with some initial parameters     called a seed  and successively improves on them via iteration  EM uses the update equation  PN P rk  xu di   k   x u   Pi     N i   P r k  u di   which requires inference on a Bayesian network parameterized by k   in order to compute P rk  xu di   and P rk  u di    In fact  one run of the jointree algorithm on each distinct example is sufficient to implement an iteration of EM  which is guaranteed to never decrease the likelihood of its estimates across iterations  EM also converges to every local maxima  given that it starts with an appropriate seed  It is common to run  EM with multiple seeds  keeping the best local maxima it finds  See  Darwiche        Koller   Friedman        for recent treatments on parameter learning in Bayesian networks via EM and related methods  EM can also be used to find MAP parameters  assuming one has some priors on network parameters  The Beta distribution is commonly used as a prior on the probability of a binary random variable  In particular  the Beta for random variable Xu is specified by two exponents  Xu and Xu   leading to a density   x u  Xu       x u  Xu     It is common to assume that exponents are      the density is then unimodal   For MAP parameters  EM uses the update equation  see  e g    Darwiche          PN Xu      i   Pr k  xu di   k     x u   PN Xu   Xu      i   Pr k  u di   When Xu   Xu      uninformative prior   the equation reduces to the one for computing ML parameters  When computing ML parameters  using Xu   Xu     leads to what is usually known as Laplace smoothing  This is a common technique to deal with the problem of insufficient counts  i e   instantiations that never appear in the dataset  leading to zero probabilities and division by zero   We will indeed use Laplace smoothing in our experiments  Our method for learning MAP and ML parameters makes heavy use of two notions      the odds of an event  which is the probability of the event over the probability of its negation  and     the Bayes factor  Good         which is the relative change in the odds of one event  say  X   x  due to observing some other event  say    In this case  we have the odds O x  and O x    where the Bayes factor is    O x   O x   which is viewed as quantifying the strength of soft evidence  on X   x  It is known that    Pr   x  Pr   x  and          When       the soft evidence reduces to hard evidence asserting X   x  When      the soft evidence reduces to hard evidence asserting X   x  When       the soft evidence is neutral and bears no information on X   x  A detailed discussion on the use of Bayes factors for soft evidence is given in  Chan   Darwiche             AN OVERVIEW OF EDML  Consider Algorithm    which provides pseudocode for EM  EM typically starts with some initial parameters estimates  called a seed  and then iterates to monotonically improve on these estimates  Each iteration consists of two steps  The first step  Line    computes marginals over the families of a Bayesian network that is parameterized by the current estimates  The second step  Line    uses the computed probabilities to   Algorithm   EM  Algorithm   EDML  input  G  A Bayesian network structure D  An incomplete dataset d            dN   An initial parameterization of structure G Xu   Xu   Beta prior for each random variable Xu    while not converged do    Pr  distribution induced by  and G    Compute probabilities   input  G  A Bayesian network structure D  An incomplete dataset d            dN   An initial parameterization of structure G Xu   Xu   Beta prior for each random variable Xu    while not converged do    Pr  distribution induced by  and G    Compute Bayes factors   Pr  xu di        and  for each family instantiation xu and example di Update parameters  x u   Xu      Xu   Xu  ix u   Pr  u di    Pr  xu di   Pr  x u   Pr  u di       Pr  xu di   Pr  x u   Pr  u di        for each family instantiation xu and example di Update parameters       PN  Pr  xu di   PN      i   Pr  u di   i       return parameterization        x u  argmax  p Xu       p Xu   p  N Y   ix u  p  p       i           return parameterization   update the network parameters  The process continues until some convergence criterion is met  The main point here is that the computation on Line   can be implemented by a single run of the jointree algorithm  while the update on Line   is immediate   random variable X are unique in this case and characterized by x   Nx  N   If one further assumes a Beta prior with exponents  and  that are     it is also known that the MAP parameter estimates are unique x    and characterized by x   NN       Consider now Algorithm    which provides pseudocode for EDML  to be contrasted with the one for EM  The two algorithms clearly have the same overall structure  That is  EDML also starts with some initial parameters estimates  called a seed  and then iterates to update these estimates  Each iteration consists of two steps  The first step  Line    computes Bayes factors using a Bayesian network that is parameterized by the current estimates  The second step  Line    uses the computed Bayes factors to update network parameters  The process continues until some convergence criterion is met  Much like EM  the computation on Line   can be implemented by a single run of the jointree algorithm  Unlike EM  however  the update on Line   is not immediate as it involves solving an optimization problem  albeit a simple one  Aside from this optimization task  EM and EDML have the same computational complexity   Consider now a more general problem in which the observations are soft in that they only provide soft evidence on the values of random variable X  That is  each soft observation i is associated with a Bayes factor ix   O x i   O x  which quantifies the evidence that i provides on having observed the value x of variable X  We will show later that the ML estimates remain unique in this more general case  if at least one of the soft observations is not trivial  i e   with Bayes factor ix        Moreover  we will show that the MAP estimates are also unique assuming a Beta prior with exponents     In particular  we will show that the unique MAP estimates are characterized by Equation   of Algorithm    Further  we will show that the unique ML estimates are characterized by the same equation while using a Beta prior with exponents      This is the first key concept that underlies our proposed algorithm for estimating ML and MAP parameters in a binary Bayesian network   We next explain the two concepts underlying EDML and how they lead to the equations of Algorithm              ESTIMATION FROM SOFT OBSERVATIONS  Consider a random variable X with values x and x  and suppose that we have N     independent observations of X  with Nx as the number of positive observations  It is well known that the ML parameter estimates for  EXAMPLES AS SOFT OBSERVATIONS  The second key concept underlying EDML is to interpret each example di in a dataset as providing a soft observation on each random variable Xu   As mentioned earlier  soft observations are specified by Bayes factors and  hence  one needs to specify the Bayes factor ix u that example di induces on random variable   x X   X        XN  Figure    Estimation given independent observations   Xu   EDML uses Equation   for this purpose  which will be derived in Section    We next consider a few special cases of this equation to highlight its behavior  Consider first the case in which example di implies parent instantiation u  i e   the parents U of variable X are instantiated to u in example di    In this case  i  Equation   reduces to ix u   O x u d O x u    which is the relative change in the odds of x given u due to conditioning on example di   Note that for root variables X  which have no parents U  Equation   further reduces i  to ix   O x d O x    The second case we consider is when example di is inconsistent with parent instantiation u  In this case  Equation   reduces to ix u      which amounts to neutral evidence  Hence  example di is irrelevant to estimating the distribution of variable Xu in this case  and will be ignored by EDML  The last special case of Equation   we shall consider is when the example di is complete  that is  it fixes the value of each variable  In this case  one can verify that ix u           and  hence  the example can be viewed as providing either neutral or hard evidence on each random variable Xu   Thus  an example will provide soft observations on variables only when it is incomplete  i e   missing some values   Otherwise  it is either irrelevant to  or provides a hard observation on  each variable Xu   In the next section  we prove Equation   of Algorithm    In Section    we discuss the origin of EDML  where we go on and derive Equation   of Algorithm        ESTIMATION FROM SOFT OBSERVATIONS  Consider a binary variable X  Figure   depicts a network where x is a parameter representing Pr  X   x  and X             X N are independent observations of X  Suppose further that we have a Beta prior on parameter x with exponents     and      A standard estimation problem is to assume that we know the values of these observations and then estimate the parameter x   We now consider a variant on this problem  in which we only have soft evidence i about each obser   vation  whose strength is quantified by a Bayes factor ix   O x i   O x   Here  ix represents the change in odds that the i th observation is positive due to evidence i   We will refer to i as a soft observation on variable X  and our goal in this section is to compute  and optimize  the posterior density on parameter x given these soft observations             N   We first consider the likelihood  QN Pr              N  x     i   Pr  i  x   QN   i    Pr  i  x  x  Pr  x x     Pr  i  x  x  Pr  x x    QN   i    Pr  i  x x   Pr  i  x     x    QN  i    ix  x  x       The last step follows because ix   O x i   O x    Pr  i  x  Pr  i  x   The posterior density is then   x              N     x  Pr              N  x   QN   x        x    i    ix  x  x       This is exactly Equation   of Algorithm   assuming we replace the random variable X with the conditional random variable Xu    The second derivative of the log posterior is X    i            x    i          x        x      x x i which is strictly negative when ix      for at least one i  This remains true when          Hence  both the likelihood function and the posterior density are strictly log concave and therefore have unique modes  This means that both ML and MAP parameter estimates are unique in the case of soft  independent observations  which generalizes the uniqueness result for hard  independent observations on a variable X      THE ORIGIN OF EDML  This section reveals the technical origin of EDML  showing how Equation   of Algorithm   is derived  and providing the basis for the overall structure of EDML as spelled out in Algorithm    EDML originated from an approximation algorithm for computing MAP parameters in a meta network  Figure   depicts an example meta network in which   The case of ix    needs to be handled carefully in Equation    First note that ix    iff Pr  i  x      in the derivation of this equation  In this case  the term Pr  i  x x  Pr  i  x   x   equals cx for some constant c          Since the value of Equation   does not depend on constant c  we will assume c      Hence  when ix     the term  ix  x  x      evaluates to x by convention    h H   S   H   E   s h  S   H   E   s h  e h  S   E   e h  Figure    A meta network induced from a base network SHE  The CPTs here are based on standard semantics  see  e g    Darwiche        Ch        parameters are represented explicitly as nodes  Darwiche         In particular  for each conditional random variable Xu in the original Bayesian network  called the base network  we have a node x u in the meta network which represents a parameter that characterizes the distribution of this random variable  Moreover  the meta network includes enough instances of the base network to allow the assertion of each example di as evidence on one of these instances  Assuming that  is an instantiation of all parameter variables  and D is a dataset  MAP estimates are then      argmax   D     where  is the density induced by the meta network  Computing MAP estimates exactly is usually prohibitive due to the structure of the meta network  We therefore use the technique of edge deletion  Choi   Darwiche         which formulates approximate inference as exact inference on a simplified network that is obtained by deleting edges from the original network  The technique compensates for these deletions by introducing auxiliary parameters whose values must be chosen carefully  and usually iteratively  in order to improve the quality of approximations obtained from the simplified network  EDML is the result of making a few specific choices for deleting edges and for choosing values for the auxiliary parameters introduced  which we explain next       INTRODUCING GENERATORS  Let X i denote the instance of variable X in the base network corresponding to example di   The first choice     H   H   E   E         Eh      Eh         Eh  Eh  Eh  Eh  e h  e h  e h  e h   a  Adding generators   b  Deleting copy edges  Figure    Introducing generators into a meta network and then deleting copy edges from the resulting meta network  which leads to introducing clones   of EDML is that for each edge x u X i in the meta network  we introduce a generator variable Xui   leading to the pair of edges x u Xui X i   Figure   a  depicts a fragment of the meta network in Figure    in which we introduced two generator variables for edges e h E   and e h E     leading to e h Eh  E   and e h Eh  E     Variable Xui is meant to generate values of variable X i according to the distribution specified by parameter x u   Hence  the conditional distribution of a generator Xui is such that Pr  xiu  x u     x u   Moreover  the CPT of variable X i is set to ensure that variable X i copies the value of generator Xui if and only if the parents of X i take on the value u  That is  the CPT of variable X i acts as a selector that chooses a particular generator Xui to copy from  depending on the values of its parents U  For example  in Figure   a   when parent H   takes on its positive value h  variable E   copies the value of generator Eh    When parent H   takes on its negative value h  variable E   copies the value of generator Eh    Adding generator variables does not change the meta network as it continues to have the same density over the original variables  Yet  generators are essential to the derivation of EDML as they will be used for interpreting data examples as soft observations       DELETING COPY EDGES  The second choice made by EDML is that we only delete edges of the form Xui X i from the augmented meta network  which we shall call copy edges  Figure   b  depicts an example in which we have deleted   h  the root and generators Xui as children  When soft evidence is asserted on these generators  we get the estimation problem we treated in Section     H   H  S   H   H  E   S   S   E   S h   E h   E   EDML can now be fully described by specifying     the soft evidence on each generator Xui in a paramei ter island  and     the CPT of each clone Xu  in an example island  These specifications are given next       S h  S h  s h  S h  S h   s h  e h  E h   e h  Figure    An edge deleted network obtained from the meta network in Figure   found by      adding generator variables      deleting copy edges  and     adding cloned generators  The figure highlights the island for example d    and the island for parameter s h    the two copy edges from Figure   a   Note here the addition of another auxiliary variable i Xu    called a clone  for each generator Xui   The addition of clones is mandated by the edge deletion framei is chosen work  Moreover  if the CPT of clone Xu  carefully  it can compensate for the parent to child information lost when deleting edge Xui X i   We will later see how EDML sets these CPTs  The other aspect of compensating for a deleted edge is to specify soft evidence on each generator Xui   This is also mandated by the edge deletion framework  and is meant to compensate for the child to parent information lost when deleting edge Xui X i   We will later see how EDML sets this soft evidence as well  which effectively completes the specification of the algorithm  We prelude this specification  however  by making some further observations about the structure of the meta network after edge deletion       PARAMETER   EXAMPLE ISLANDS  Consider the network in Figure    which is obtained from the meta network in Figure   according to the edge deletion process indicated earlier  The edge deleted network contains a set of disconnected structures  called islands  Each island belongs to one of two classes  a parameter island for each network parameter x u and an example island for each example di in the dataset  Figure   provides the full details for one example island and one parameter island  Note that each parameter island corresponds to a Naive Bayes structure  with parameter x u as  CHILD TO PARENT COMPENSATION  The edge deletion approach suggests the following soft evidence on generators Xui   specified as Bayes factors  ix u    O xiu   di   P ri  di  xiu        O xiu    P ri  di  xiu          where P ri is the distribution induced by the island of example di   We will now show that this equation simplifies to Equation   of Algorithm    i from the Suppose that we marginalize all clones Xu  island of example di   leading to a network that induces a distribution Pr   The new network has the following properties  First  it has the same structure as the base network  Second  Pr  x u    P ri  xiu     which means that the CPTs of clones in example islands correspond to parameters in the base network  Finally  if we use u to denote the disjunction of all parent instantiations excluding u  we get   ix u         P ri  di  xiu    P ri  di  xiu    Pr  di  xu Pr  u    Pr  di  u Pr  u  Pr  di  xu Pr  u    Pr  di  u Pr  u  Pr  xu di   Pr  x u   Pr  u di         Pr  xu di   Pr  x u   Pr  u di        This is exactly Equation   of Algorithm    Hence  we can evaluate Equation   by evaluating Equation   on the base network  as long as we seed the base network with parameters that correspond to the CPTs of clones in an example island       PARENT TO CHILD COMPENSATION  We now complete the derivation of EDML by showing how it specifies the CPTs of clones in example islands  which are needed for computing soft evidence as in the previous section  In a nutshell  EDML assumes an initial value of these CPTs  typically chosen randomly  Given these CPTs  example islands will be fully specified and EDML will compute soft evidence as given by Equation    The   h H   S   H   E   s h  S   s h  H   E   e h  S   E   e h  Figure    A pruning of the meta network in Figure   given H     h  H     h and H     h   computed soft evidence is then injected on the generators of parameter islands  leading to a full specification of these islands  EDML will then estimate parameters by solving an exact optimization problem on each parameter island as shown in Section    The estimated parameters are then used as the new values of CPTs for clones in example islands  This process repeats until convergence  We have shown in the previous section that the CPTs of clones are in one to one correspondence with the parameters of the base network  We have also shown that soft evidence  as given by Equation    can be computed by evaluating Equation   of Algorithm    with parameters  corresponding to the CPTs of clones in an example island   EDML takes advantage of this correspondence  leading to the simplified statement spelled out in Algorithm        SOME PROPERTIES OF EDML  Being an approximate inference method  one can sometimes identify good behaviors of EDML by identifying situations under which the underlying inference algorithm will produce high quality approximations  We provide a result in this section that illustrates this point in the extreme  where EDML is guaranteed to return optimal estimates and in only one iteration  Our result relies on the following observation about parameter estimation via inference on a meta network  When the parents U of a variable X are observed to u in an example di   all edges x u  X i in the meta network become superfluous and can be pruned  except for the one edge that satisfies u    u  Moreover   edges outgoing from observed nodes can also be pruned from a meta network  Suppose now that the parents of each variable are observed in a dataset  After pruning edges as indicated earlier  each parameter variable x u will end up being the root of an isolated naive Bayes structure that has some variables X i as its children  those whose parents are instantiated to u in example di    Figure   depicts the result of such pruning in the meta network of Figure    given a dataset with H     h  H     h and H     h  The above observation implies that when the parents of each variable are observed in a dataset  parameters can be estimated independently  This leads to the following well known result  Proposition   When the dataset is complete  the ML estimate for parameter x u is unique and given by D  xu  D  u   where D  xu  is the number of examples containing xu and D  u  is the number of examples containing u  It is well known that EM returns such estimates and in only one iteration  i e   independently of its seed   The following more general result is also implied by our earlier observation  Proposition   When only leaf variables have missing values in a dataset  the ML estimate for each parameter x u is unique and given by D  xu  D    u   Here  D    u  is the number of examples containing u and in which X is observed  We can now prove the following property of EDML  which is not satisfied by EM  as we show next  Theorem   When only leaf variables have missing values in a dataset  EDML returns the unique ML estimates given by Proposition   and in only one iteration  Proof Consider an example di that fixes the values of parents U for variable X and consider Equation    First  ix u     iff example di is inconsistent with u or does not set the value of X  Next  ix u     iff example di contains xu  Finally  ix u    iff example di contains xu  Moreover  these values are independent of the EDML seed so the algorithm converges in one iteration  Given these values of the Bayes factors  Equation   leads to the estimate of Proposition      We have a number of observations about this result  First  since Proposition   is implied by Proposition    EDML returns the unique ML estimates in only one iteration when the dataset is complete  just like EM   Next  when only the values of leaf variables are missing in a dataset  Proposition   says that there is a unique ML estimate for each network parameter  Moreover    Theorem   says that EDML returns these unique estimates and in only one iteration  Finally  Theorem   does not hold for EM  In particular  one can show that under the conditions of this theorem  an EM iteration will update its current parameter estimates  and return the following estimates for x u     D  xu    D   u Pr  x u    D  u  Here  D   u  is the number of examples that contain u and in which the value of X is missing  This next estimate clearly depends on the current parameter estimates  As a result  the behavior of EM will depend on its initial seed  unlike EDML  When only the values of leaf variables are missing  there is a unique optimal solution as shown by Proposition    Since EM is known to converge to a local optimum  it will eventually return the optimal estimates as well  but possibly after some number of iterations  In this case  the difference between EM and EDML is simply in the speed of convergence  Theorem   clearly suggests better convergence behavior of EDML over EM in some situations  We next present initial experiments supporting this suggestion      MORE ON CONVERGENCE  We highlight now a few empirical properties of EDML  In particular  we show how EDML can sometimes find higher quality estimates than EM  in fewer iterations and also in less time  We highlight different types of relative convergence behavior in Figure    which depicts example runs on a selection of networks  spect  win  pts  emdec g  and tcc e  Network spect is a naive Bayes network induced from a dataset in the UCI ML repository  with   class variable and    attributes  Network win  pts     variables  is an expert system for printer troubleshooting in Windows     Networks emdec g      variables  and tcc e     variables  are noisy or networks for diagnosis  courtesy of HRL Laboratories   We simulated datasets of size  k   using the original CPT parameters of the respective networks  and then used EDML and EM to learn new parameters for a network with the same structure  We assumed that certain variables were hidden  latent   in Figure    we randomly chose    of the variables to be hidden  Hidden nodes are of particular interest to EM  because it has been observed that local extrema and convergence rates can be problematic for EM here  see  for example  Elidan   Friedman        Salakhutdinov  Roweis    Ghahramani           EDML              EM     e     EDML  spect       iteration       spect EDML                          win  pts       EM       e                                     EM      e     EDML                             EM           e     EDML                             EM                iteration                           e                                                 tcc e       iteration       emdec g       iteration       EDML  EM  time            win  pts                           emdec g  e  EDML                                 EM                        EDML  time  tcc e  EM      time  time  Figure    Quality of parameter estimates over iterations  left column  and time  right column   Going right on the x axis  we have increasing iterations and time  Going up on the y axis  we have increasing quality of parameter estimates  EDML is depicted with a solid red line  and EM with a dashed black line  In Figure    each plot represents a simulated data set of size       where EDML and EM have been initialized with the same random parameter seeds  Both algorithms were run for a fixed number of iterations       in this case  and we observed the quality of the parameter estimates found  with respect to the log posterior probability  which has been normalized so that the maximum log probability observed is       We assumed a Beta prior with exponents    EDML damped its parameter updates by a factor of      which is typical for  loopy  belief propagation algorithms     The simple bisection method suffices for the optimization sub problem in EDML for binary Bayesian networks  In our current implementation  we used the conjugate gradient method  with a convergence threshold of         In the left column of Figure    we evaluated the quality of estimates over iterations of EDML and EM  In these examples  EDML  represented by a solid red line  tended to have better quality estimates from iteration to iteration  curves that are higher are better   and further managed to find them in fewer iterations  curves to the left are faster    This is most dramatic in network spect  where EDML appears to have converged almost immediately  whereas EM spent a significant number of iterations to reach estimates of comparable quality  As most nodes hidden in network spect were leaf nodes  this may be expected due to the considerations from the previous section  In the right column of Figure    we evaluated the quality of estimates  now in terms of time  We remark again that procedurally  EDML and EM are very similar  and each algorithm needs only one evaluation of the jointree algorithm per distinct example in the data set  per iteration   EDML solves an optimization problem per distinct example  whereas EM has a closed form update equation in the corresponding step  Line   in Algorithms   and     Although this optimization problem is a simple one  EDML does require more time per iteration than EM  The right column of Figure   suggests that EDML can still find better estimates faster  especially in the cases where EDML has converged in significantly fewer iterations  In network emdec g  we find that although EDML appeared to converge in fewer iterations  EM was able to find better estimates in less time  We anticipate in larger networks with higher treewidth  the time spent in the simple optimization sub problem will be dominated by the time to perform jointree propagation  We also performed experiments on networks learned from binary haplotype data  Elidan   Gould         which are networks with bounded treewidth  Here  we simulated data sets of size       where we again randomly selected    of the variables to be hidden  We further ran EDML and EM for a fixed number of iterations       here   For each of the    networks available  we ran EDML and EM with   random seeds  for a total of     cases  In Figure    we highlight a selection of the runs we performed  to illustrate examples of relative convergence behaviors  Again  in the first row  we see a case where EDML identifies better estimates in fewer iterations and less time  In the next two rows  we highlight two cases where EDML appears to converge to a superior fixed point than the one that EM appears to converge to  In the last row  we highlight an instance where EM instead converges to a superior estimate  In Figure    we compare the estimates of    We omit the results of the first    iterations as initial parameter estimates are relatively poor  which make the plots difficult to read    e                                        greedy      EDML EM   e                                        bounded u      EDML   e                                        bounded u      EDML   e   greedy     EM EDML             iteration  greedy             e                                        bounded u             e                                        bounded u             e                                        e   greedy     EM EDML  EM       iteration  EM       iteration                                iteration             EDML EM            time  EDML EM            time  EDML EM       time       time                 Figure    Quality of parameter estimates over iterations  left column  and time  right column   Going right on the x axis  we have increasing iterations and time  Going up the y axis  we have increasing quality of parameter estimates  EDML is depicted with a solid red line  and EM with a dashed black line  EDML and EM at each iteration  computing the percentage of the             cases considered  where EDML had estimates no worse than those found by EM  In this set of experiments  the estimates identified by EDML are clearly superior  or at least  no worse in most cases   when compared to EM  We remark however  that when both algorithms are given enough iterations to converge  we have observed that the quality of the estimates found by both algorithms are often comparable  This is evident in Figure    for example  The analysis from the previous section indicates however that there are  very specialized  situations where EDML would be clearly preferred over EM  One subject of future study is the identification of situations and applications where EDML         of     cases  EDML favored                    iteration       Figure    Quality of EDML estimates over    networks    cases each  induced from binary haplotype data  Going right on the x axis  we have increasing iterations  Going up the y axis  we have an increasing percentage of instances where EDMLs estimates were no worse than those given by EM   izes to multivalued variables since edge deletion does not require a restriction to binary variables and the key result of Section   also generalizes to multivalued variables  The resulting formulation is less transparent though when compared to the binary case since Bayes factors no longer apply directly and one must appeal to a more complex method for quantifying soft evidence  see  Chan   Darwiche         We expect our future work to focus on a more comprehensive empirical evaluation of EDML  in the context of an implementation that uses multivalued variables  Moreover  we seek to identify additional properties of EDML that go beyond convergence  
 We consider the problem of deleting edges from a Bayesian network for the purpose of simplifying models in probabilistic inference  In particular  we propose a new method for deleting network edges  which is based on the evidence at hand  We provide some interesting bounds on the KL divergence between original and approximate networks  which highlight the impact of given evidence on the quality of approximation and shed some light on good and bad candidates for edge deletion  We finally demonstrate empirically the promise of the proposed edge deletion technique as a basis for approximate inference      INTRODUCTION  Classical algorithms for exact probabilistic inference have a complexity which is parameterized by the network topology  Jensen et al         Lauritzen and Spiegelhalter        Zhang and Poole        Dechter        Darwiche         In particular  it is well known that exact inference can be performed exponential only in the treewidth of a given network  where treewidth is a graph theoretic parameter that measures network connectivity  When the treewidth is high  one may then consider simplifying the network by deleting some edges to reduce its treewidth and then run exact inference on the simplified network  This approach would then lead to a class of approximate inference algorithms  which result from applying exact inference to an approximate network  Clearly  the quality of approximate inference in this case would depend on the quality of approximate networks one constructs as a result of edge deletion  In previous work on edge deletion  most results focused on the quality of approximation between the prior distributions induced by the original and approximate  networks  typically by considering the KLdivergence between the two  Cover and Thomas         However  it is known that the KLdivergence may be small between two distributions  yet blow up when conditioning on a particular evidence  Koller         Therefore  bounding the KLdivergence would not necessarily provide guarantees on conditional queries  In this paper  we propose an edge deletion method which is sensitive to the available evidence  The method was motivated by the following observations  First  by deleting an edge Y  X from a network  we are in essence changing the conditional probability table  CPT  of variable X  since X will have one less parent in the new network  Moreover  it is known that if the current evidence e fixes the value of variable Y   then the edge Y  X can be deleted and the CPT for X can be modified  while yielding a simpler network which corresponds exactly to the original network for any query of the form   e  The question now is  what if the current evidence does not fix the value of Y   but the probability of Y is extreme given evidence e  Can we in this case delete Y  X and still expect to get a good approximate network  In particular  would the approximate results converge to the exact ones as the posterior of Y given e converges to an extreme distribution  We will indeed provide a bound and analysis that give some interesting insights on this matter  We also empirically evaluate the edge deletion methods as a basis for approximate inference  by running exact inference on the approximated network  This method of approximate inference is interesting as it provides a tradeoff between efficiency and quality of approximation  through control over the deleted edges  It is therefore in the same spirit as generalized belief propagation  Yedidia et al          except that it is independent of the specific method used for exact inference  As we shall see  the formulation based on edge deletion appears to provide new grounds for analysis  This paper is structured as follows  In Section    we define the semantics of edge deletion  In Section      we introduce some interesting bounds on the KL divergence between the original and approximate networks  for both deleting a single edge  and deleting multiple edges  In Section   we address one of the key subtleties relating to our edge deletion method  and in Section   we present empirical results on an approximate inference method based on edge deletion  Section   discusses previous work in edge deletion  and Section   closes with some concluding remarks  Proofs of Theorems are included in the Appendix      DELETING EDGES  Deleting an edge Y  X from a network entails more than simply removing an edge from the graph  one must also have a way of updating the CPT of variable X  which has one less parent after deletion  Other notions of edge deletion studied in the past  which we will review in Section    motivated their deletion by asserting  in a particular sense  a conditional independence between Y and X  However  as these methods did not specifically take evidence into account  an approximation may look good before conditioning on evidence  but could potentially be a bad one afterwards  Consider a variable Y in a network N and some evidence e that fixed the value of Y   We can then delete each outgoing edge of Y   and assume the fixed value of Y in the CPT of each of its children X  This method will give a network with exact results for queries of the form   e  But what if the value of a variable is almost determined by evidence e  Then perhaps we can try to weight the CPT for X by the posterior probability distribution of the parent Y   Assume that we have a network N in which node X has parents Y and U  where U may be empty  We want to approximate this network by another  say N     which results from removing the edge Y  X  This approximation will be done given a piece of evidence e  by replacing the CPT X Y U of variable X in network N by the CPT  X U as defined below  Definition    Edge Deletion  Let N be a Bayesian network with node X having parents Y and U  The network N   which results from deleting edge Y  X from N given evidence e is defined as follows   N   has the same structure as N except that edge Y  X is removed   The CPT for variable X in N   is given by  X def   x yu Pr  y e   x u   y   The CPTs for variables other than X in N   are the same as those in N    Note that this approximation assumes that we have the posteriors Pr  Y  e  in the original network N   This probability is typically not available  as the network N must already be difficult  for us to be interested in deleting some of its edges  We will indeed address this point in Section    but for now we will pretend that we have this posterior probability  Note also that the probabilities Pr    Y  e  in the approximate network may not equal the original probabilities Pr  Y  e  when the edge Y  X is cut as given above  Intuitively  this edge deletion method is equivalent to creating an auxiliary root node Y   whose CPT Y   is Pr  Y  e  and then replacing the original parent Y with the new node Y     This can be shown by eliminating variable Y   from the new network  which leads to replacing the CPT of X by the one proposed in Definition        QUALITY OF APPROXIMATION  We consider in this section the quality of networks generated by the proposed edge deletion method  In particular  we provide bounds on the KLdivergence between the conditional distributions Pr    e  and Pr      e  induced by the original and approximate networks N and N     where KL is defined as follows  Cover and Thomas         KL Pr   Pr      X  def     Pr  w  log  w       Pr  w    Pr    w   DELETING A SINGLE EDGE  Our intuition suggests that deleting an edge out of a variable whose value is almost determined given the evidence may yield a reasonable approximation  The following bound lends some support to that intuition  Theorem   Let N and N   be two Bayesian networks as given in Definition    We then have  KL Pr    e   Pr      e    log  Pr    e    ENT  Y  e   Pr  e   where ENT  Y  e  is the entropy of Y given e  and is defined as follows  ENT  Y  e   def       X  Pr  y e  log Pr  y e    y  Note that the ENT  Y  e      if and only if Pr  y e      for some y  that is  the entropy of Y given e is zero if and only if the value of Y is determined  Now consider the following condition in which our bound becomes an equality    Theorem   Let N and N   be two Bayesian networks as given in Definition    If the CPT for variable X is deterministic  x yu             and x yu   x y  u     only if y   y         then KL Pr    e   Pr      e     log  Pr    e    ENT  Y  e   Pr  e   Note that Condition   is satisfied when the CPT for X has no contextspecific independence  Moreover  both conditions are satisfied if X is a parity function of its parents  as one typically finds  for example  in networks for error correcting codes  Frey and MacKay         The more certain we are of the value of Y given e  the more extreme Pr  Y  e  is  and the lower ENT  Y  e  is  This suggests that if the value of Y is almost determined  then the ENT  Y  e  term in the bound on the KLdivergence is negligible  and we may get a good approximation  Moreover  the log Pr    e  Pr  e  term may be negative  and the entropy term need not be small for us to get a good approximation  However  as we demonstrate in Appendix B  there are particular situations where ENT  Y  e  can be arbitrarily close to zero  but where log Pr    e  Pr  e  can be unbounded       DELETING MULTIPLE EDGES  We can extend the bound given in Theorem   about a single edge deletion  to a bound on multiple deletions  where the entropy term is additive  Theorem   Let N   be a network obtained from network N by deleting multiple edges Y  X as given by Definition    deleting at most one incoming edge per node X  Then X Pr    e  ENT  Y  e     KL Pr    e   Pr      e    log Pr  e  Y X  Moreover  if the CPTs for each X satisfy Conditions   and    then X Pr    e    KL Pr    e   Pr      e     log ENT  Y  e   Pr  e  Y X     FIXED POINTS  Deleting edges Y  X by Definition   assumes that we know the distribution on Y given e  If we are interested in approximating our network N   then computing Pr  Y  e  is itself likely to be difficult computationally  In the approximated network  however  computing the posteriors of Y is likely to be easy  We will  therefore use the approximate network to approximate Pr  Y  e  using an iterative method as discussed below  b is the network that we obtain by deletSuppose that N c t    Y  e  is ing edges  We first assume that each Pr uniform  and then cut edges Y  X by setting the b as follows  CPT for variable X in N X   c t    y e   x u   x yu Pr y  We then apply exact inference to the approximate netc t  Y  e  are the posteriors of Y at iteration work  If Pr t in the approximate network  then the CPT for X is updated as follows  X   c t  y e   x yu Pr x u   y  We repeat this process until we find that for all edges c t  Y  e    Pr c t    Y  e   or that that we delete  all Pr they are within some threshold   from one iteration to the next  At this point  we say that we have converged  c  Y  e  are a fixed point for N b  and that Pr  We will compare in the following section the quality of our approximations when computed based on the true posteriors Pr  Y  e  and the one obtained by the above iterative method  showing that the fixed point method tends to work quite well on the given benchmarks      EMPIRICAL ANALYSIS  We discuss here experimental results on edge deletion  In particular  we compare iterative belief propagation  Pearl        Murphy et al         as an approximate inference algorithm  with exact inference on a network with deleted edges  Moreover  we compare the deletion of edges Y  X based on the true probabilites c  Y  e   Pr  Y  e  and the fixed point probabilites Pr  We use the jointree algorithm to perform exact inference on the network with deleted edges  Moreover  we make the following choices in our experiments  Cost of computation  We use the largest cluster size in the jointree to measure the difficulty of exact inference  For belief propagation  we assume that difficulty depends on the number of loops to observe convergence  where the complexity of each loop depends on the number and sizes of the network CPTs  and in particular  the size of the largest CPT  Deleted edges  For each network we consider  we cut different sets of edges to control the size of the largest cluster in the corresponding jointree  We do this by fixing a variable order that induces a jointree   We    We use min fill min size heuristics  or by using orders found otherwise  For example  orders are available for networks in Aalborg DSSs repository    Evidence  For each of a given number of trials  typically    to     trials   we set evidence on all leaves by sampling based on the prior probabilities of each individual variable  to approximately simulate evidence that we may likely observe  Convergence  For each piece of evidence  we approximate inference by belief propagation and by edge deletion for a given set of thresholds on the largest cluster size  When appropriate  we decide on convergence when the marginal of every variable of an iteration is within     of the previous iteration  trying at most     iterations  If we do not observe convergence within this many iterations  we evaluate the instance based on the state of the network in its last iteration   son  the iterative version of edge deletion always converged within     iterations for all trials  and took    iterations on average for this network  When we use a threshold on the maximum cluster size of log                  or smaller  the largest tables computed during belief propagation and edge deletion are of comparable sizes  but edge deletion still needs only    iterations on average to converge  barley   average KL Pr X e  Pr X e        average KL Pr X e  Pr X e    then delete edges to find an approximated network which has a jointree whose largest cluster is smaller than given thresholds  using the same variable ordering  We decide on edges to delete based on a heuristic based on reducing bucket sizes to satisfy a given threshold in a bucket elimination procedure  Dechter          edge deletion iterative deletion belief prop                                       max cluster size          barley   average number of iterations      Figure    Quality of approximation in barley network  average number of iterations  iterative deletion belief prop                                      max cluster size          Figure    Loops until convergence in barley network First consider the barley network  which has a jointree with a normalized maximum cluster size of about        which is the log  of the number of entries in the largest table of a cluster  The barley network also has a large CPT containing         entries  Although the largest cluster in the jointree still has     times more entries then the largest CPT in the network  if belief propagation takes many iterations to converge  we get an approximation of posterior marginals  but with less attractive benefits in time savings  Consider Figure    which compares the average number of loops required until convergence  In    trials  belief propagation converges in less than half the instances when given     iterations to converge  taking    iterations on average overall  In compari   We judge the quality of approximation with two measures  One measure is in terms of the average number of flips observed in a trial  We say that a flip occurs when the most likely state of an individual variable with respect to the original posterior distribution is no longer the most likely state in the approximated one  The other measure is in terms of the average KL divergence between the true and approximated conditional probabilities of non evidence variables  Note that in our figures  curves are not always smooth  since different thresholds yield different sets of edges deleted  and smaller sets of edges deleted do not necessarily yield more accurate approximations  Consider first Figure    which compares the quality of the approximation given by edge deletion and belief propagation in the barley network  based on the KL divergence  We see in this case  both methods of edge deletion compare favorably to belief propagation for all given thresholds on the cluster size  At a threshold of     we find that the largest cluster size of the approximation is        and so the number of entries in that cluster table is     the size of that in the original network  With a threshold of     the largest table is       the size  with a threshold of     it is           the size  Figures   and   compare the quality of approximations in the munin  and munin  networks  We observe that the quality of approximation tends to degrade with a stricter threshold on the largest cluster size  Note that   munin    average number of flips  munin    average KL Pr X e  Pr X e              average KL Pr X e  Pr X e    average number of flips  edge deletion iterative deletion belief prop                                  max cluster size                                              edge deletion iterative deletion belief prop                 max cluster size              Figure    Quality of approximation in munin  network  munin    average number of flips  munin    average KL Pr X e  Pr X e              average KL Pr X e  Pr X e    average number of flips  edge deletion iterative deletion belief prop                               max cluster size  edge deletion iterative deletion belief prop                                           max cluster size  Figure    Quality of approximation in munin  network  we are deciding on which edges to delete without regard to the particular instantiation of evidence  and we see that our approximation schemes compare favorably to belief propagation to a point  with varying degrees of computational savings  In munin   both methods of edge deletion compare favorably against belief propagation  in both measures  up until a threshold of     The largest normalized cluster size in the original network is       compared to       in the approximated network at that threshold  Thus  the largest table in the jointree for the approximated network is       of that of the original network  In most of our experiments  we tend to observe that the iterative version of edge deletion is very close to the version that uses the true probabilities Pr  Y  e  for larger thresholds  and typically fewer edges deleted  and become less comparable for smaller and smaller thresholds  In munin   they perform similarly over most of the given thresholds  In munin   we see that both versions of edge deletion are comparable up to a  point  where the iterative method tends to fare worse for smaller thresholds  Figure   provides a summary of the comparisons between our methods of approximation  In these tables  we measure how belief propagation performs in terms of the average percentage of flips observed  and by average KL Pr  X e   Pr    X e   over all non evidence variables  We then find the threshold on the maximum cluster size in which edge deletion using true probabilities Pr  Y  e  compares favorably to belief propagation  and report the savings in cluster size with respect to the cluster size of the original network  We also report the quality of approximation for the iterative version of edge deletion that uses fixed point c  Y  e   for the same threshold  We find probabilities Pr that both versions of edge deletion compare well with belief propagation  and can do so with substantial degrees of computational savings in terms of reduction of the largest cluster size  Further  we see that when deletion with true probabilities Pr  Y  e  does well  deletion   network munin  munin  munin  munin  barley pigs  cluster   size                                         average   flips BP ED ID                                                                                                                 network munin  munin  munin  munin  barley pigs  cluster   size                                         BP                                            average KL ED ID                                                                                      Figure    Savings in maximum cluster size    size  at the point where edge deletion  ED  outperforms belief propagation  BP   in terms of flips and average KLdivergence  KL for iterative version of edge deletion  ID  also shown  In barley  ED compares favorably in terms of the KL to BP for all thresholds down to our limit of     with fixed point probabilties also tends to do well      putations  Further  approximations may not be good after conditioning on unlikely evidence   PREVIOUS WORK    Prior work in approximating Bayesian networks by edge deletion focused primarily on the effects of deletion on the prior distribution  In  Kjrulff         edges are deleted  not in the model itself  but on the moralized independence graph induced by the network  and its simplifications are specific to jointree based algorithms  Weak dependencies are sought between pairs of variables within particular cliques of the jointree  and a conditional independence is asserted based on the variables that appear in the clique  The author showed that the KLdivergence between the original distribution and the one where a conditional independence is asserted is equal to the conditional mutual information  Cover and Thomas        of the variables involved  He further showed that the KL divergence is additive  and that for each conditional independence asserted  the divergence is computable locally  It is possible to recover a model from the approximated jointree  but the structure may not be unique  and the parameterization for it may not be easily determined  The divergence is for prior distributions  and a form for the posterior distribution was cited as future work  More recently   Paskin        effectively employed this simplification in a Gaussian graphical model for simultaneous localization and mapping for mobile robotics  In  van Engelen         edges are deleted in the model  as we did here  For a node X with parents Y U  we can cut edge Y  X by replacing each x yu with   x u   Pr  x u   essentially  we are asserting that X and Y are conditionally independent given U  The KLdivergence between the prior distributions is again the conditional mutual information  and is additive if we delete at most a single incoming edge per node  However  to make this approximation  one must be able to compute the quantities Pr  x u   Although these are local quantities  they may require global com   CONCLUSION  We proposed a method for deleting edges from a Bayesian network  which is sensitive to the evidence at hand  We provided some bounds on the KL divergence between the original and approximated network  given evidence  The bounds shed light on when this method is expected to provide good approximations  We also evaluated empirically an approximate inference algorithm which is based on deleting edges against belief propagation  and showed that the edge deletion method holds good promise  The method we used to decide on which edges to delete is a bit primitive  as it is based on a fixed variable order and does not exploit the given evidence for making its choices  We are currently working on a more sophisticated scheme for this purpose  which may significantly improve the quality of approximations obtained by the proposed method of edge deletion  Acknowledgments This work has been partially supported by Air Force grant FA               and MURI grant N                
