 The paper describes aHUGIN  a tool for cre ating adaptive systems  aHUGIN is an exten sion of the HUG IN shell  and is based on t he methods repo r ted by Spiegelhalter and Lau r itzen      a   The adaptive systems resu lt ing from aHUGIN are able to adj u s t the con ditional probabi lities in the modeL A short analysis of the adap tation task is gi ven and the fe atures of aHUGIN are des cribed  Fi nally a sess i on with experiments is reported and the results are discussed      Introduction  With the revival of Bayesian methods in decision sup  port systems   Shachter       Pearl        Shafer and Pearl       Andreassen ei al      b  mainly due to  the construction of e ffi cien t methods for belief re vi  sion in causal probabilistic networks  Pearl       L au ritzen and Spiegelhalter       Andersen d a          et al        Shenoy and Shafer        the process of knowledge acq uisit ion under the Bayesi an Jensen  paradigm has become increasingly important  Wh en construc ti ng causal probabilistic network models  var ious sources may be used  ranging from ignorance over experts  subjective assessments to well established sci entific theories and statistical models based on large database s   Very often a mod el is a mixtu re of contri butions from sources of different epistemological char acter   Sometimes these contributions do not coin ci de   and  the model is a mediation between them  sometimes the  ignorance has  for ex ample  forced crude  guesses  on certain distributions   sometimes the model must vary with contexts which cannot be specified beforehand  sometimes the domain is drifting ov er time   requiring the mo del to drift  r esu lt in g model is incomplete  along with i t  and sometimes the model quite s i mply does not reflect the real world pr op erly  All the proble ms listed above call for pr ocedures which enable the sy stem to mod ify the mo d el t h ro ugh ex p eri   Finn V    Tens en  ence  We call such an a ctiv ity adaptation  and sy stems  p erfo rm in g automatic adaptation tems  we  Note that  we  call adaptwe  sys  have chosen t o distinguish adaptation  which we usc to describe the activity or creat in g models by hatch pmccssing of large data  from training       D    bases  In Spiegelhalter el rd  called  leaming and they  arc  both activities are  dist inguished as sequent i a l  learning and batch learning   W h en using adaptat ion  we  He us i ng the analogy to tlw n ot i on  of adaptive reg u lato rs in control t h eo r y   llopefully  t h is abundance of te rm i n o logy will not  confuse the reader completely  The present paper descri hes all UG IN  a tool for cre ating adaptive systems  Tlw system  which is an ex tension of  IJUGIN   Andersen  ct a        J   is based  on methods reported in Spiegellta lt er  Hid Lau ntzen  l  l  lOa   see also Spiegelhaltcr and Lamit zcn      b    and th e adapt ive s y s te ms result in g from aliUGIN arc able to adjust the con d i t i on a l probabilities in mo d el    sented  the  In a l l UGIN the mo d el is compactly repre  by  a  contingency  table of i m a gi nary counts   the adaptation p roced u re is counts in this table   a  and  proccs of    odifying  the  In se ction   we give a short analysis of the adaptation discuss various simple adapt ation methods lead ing up to a dcscri ption of the one used in all U GIN   task and  In section    we  d cscri h e the f caturcs ofalllJCJN  a  d  in section    a session with txpcrillwnts the  results  ar    disciiSSt d   i rportrd  and       JU    rnd Cowell   I J J   clt  difl erent ma in difl ercnre bctii   CII t  h is sys  Spiegclhalt cr and Cc    cll  scribe  a similar systt lll a nd rt sult s of s l ig h tly  experiments   The  tem and t he i r system  is that  we allow an extra facilit y   ailed fadwy  that  makf s the systcrn forget  t h   past at  an ex p onenti a l rate  t herel y    aking them       e prone  to adapt in changing cnvir onmcnt s      Analysis of adaptation  CPN m o dels have both a quantit at ive a n d a  qualita tive aspect  Througl  t hc eli reeled aTcs  the networ k reflects the only ways in which variables mny have im         Olesen  Lauritzen  and Jensen pact on each other  The st rengt h of the impact is mod e ll ed through conditional probability tables  We shall here describe how the probabil ity tables are modifi ed in the adaptation process  So  consider a causal probabilistic network into which information on the state of the variables can be en t ered If the state of only some of the variables is known  then the probability distributions for the re maining variables are calculated  Each time this is done  we have described a case  Now  a large number of cases is at hand  an d we want to improve the model    by adjusting the conditional probability tables to the set of cases       Direct modelling of table uncertRinty  In Fig u re     a     the state of the variable A is influenced direct ly by the states of B and C  and the strength  of this influence is modelled by P AIB  C   If the this may  for exam stren gth is subject to doubt ple  be due to d ifferent estimates from experts  or it may be due to a context influence not mod elled  like soil quality of corn fields or ge ne t i c disposition for a disease  then this doubt may be modelled directly by introducing an extra parent  T  for A   F igu re     b     This variable can be c onsi d e r ed as a ty pe vari able modelling  for example  types of context or differ ent experts  assessments  To reflect credibility of the experts or frequencies of the co ntext types  a prior dis tribution forT could be given  When a case is entered       ma y be neces  ary  These  lrffirenl  t ypes rnay  w lw n ily interdependent  for example  assessments from Vilr ious intersecting sets of experts  and it  may he neces sar y to construct a COirlplcx t ype nel work with t he risk  A simplifying assump ti o n would be global independence  the context depen dence for the conditional probabilities are mutually in dependent  In that case  each variable can he given its own parent of ty p es and retrieval and dissemination are completely lo c al  perfonned as above   However  the pro ce d u re is still v u l nera b l e t o combinatorial PX plosion  Take for instance the variahlc A in Figure I  For each parent configurat ion a type dcpcnclcncc on the distribu tion for A shall be described  These de pe nden c ies may vary a lot with tile p a rticu la r parent con figu rations and all kinds of intcr dcpcndrncics rnay  of a combinatorial explosion      be prcsellt   Tlw d or    WI     orc d     Y lw  in  l          to  the p mbabil i ty tables by a  factor which is the prodtrct of the number of states in l  c parents  So  a further  simplification wo uld he lorn  independence  tlw ron text dependence for the various p HCII  coni gtrratinns ar e mutually independent   Indirect moddliug of table    H  rtaint y       If nothing is known  a p ossibl e       t  w structure of llw  inadequacy of the rnodello  the  GlliSIS  case  for  set  the  uncertainty can not he represented directly through a  network of discr e t e types   and we rnust  leave  roorn  for all kinds of types witlt  dl kinds of distrdartions   The learning process h e re is  as  everywhere else in t he  B ayesi a n p ar a d igm   Specif y a prior distribution  of the  ty pes and calculate the posteri or given the case ob served   It remai ns to find a natural way of spccifyi  g    and  such a p robabil i ty model  Sricgelh a ltc r   Hl  a   give  a  Lauritun  range of pos  ihi ities  incl  ding normal  l og istic models   The simplest probability n odel which is convenient  f or cue I   a   case    b   Figure    Ad apt ation th ro ugh a type variable  to the CPN  the calculation of updated probabilities will yield a new distribution on T  an d we may say that the change of these probabi litie s reflects what we have learnt from the case  This process is called retrieval of experience  The new dist ri bution may now be used as prior probabilities for the next case and its impact on the conditional probabilities found by summing out the type variable  This process is called dzssemination of experience  The technique has  for example  been used in Andreassen et al      la   where the system con tain s a model for metab ol i sm in patients suffering from diabetes  Through a type variable  the syst em adapts to the characteristics of the individual patient  Several conditional probabilities in the CPN may be context dependent  and a whole set of type variables  th is  situation assu rncs that each set of entries i    the  conditional probability tahlcs for  configuration follows     Johnson  and Kotz  distribution has   sit y  f pt Pk ll for  p        I  atl   The simplicity is p ro p er    a  so called  a  part icular parent   Jmchlr  rhslnhulnm  l li    A k  dilll  nsiOJd Dirichl  t paJ It  cVrs   n           rq    ttd d  ll   X     k J      LJil    k     I  k    II            I        k  I L    p   I  in  the  distribution with  itt  crprcl a tion tri       for all  lf  i  the  im  is  consid  specified may be interpreted a  representing past exper ie nce as a coni ingency iable  cl J         nk  of counl  of pas  casrs   ered  a  noninformativc prior  the distribution  s   L  rt  i   thcreforc refetred to as   ic equivalent sample size  The updating p roced ure con  The quanti ty  sists of modifying the cou nt s as new cases observed   We shall  not give details   hut  just  state  arc  that  bci   g  the frac    aHUGIN  A System Creating Adaptive Causal Probabilistic Networks  tion a   s   m  is t he mean for the ith outcome  and for each i the variance of the probability for the ith outcome is  m  l  m    v                     s  l  Hence v  is a measure of the uncertainty of the prob ability m   Using this interpretation we also have a tool to model expert opinion s of the type  the probability is some where between p and q  but I believe it is about      In the case of two states a and b  consider  for example  the statement that the probability of a is between     an d     and that it is about      If we  as in Spiegel halter et al           interpret the statement so that the mean is      and the standard deviation is       then it can be modelled by a   dimensional Dirichlet distribution  which is called a Beta distribution   We then have to determine two counts na an d Ob whi ch satisfy the equations Oa        aa ab       and                aa ab l                  which we solve to get Oa        and Ob         This can be an attractive alternative to modelling second order u n certainty by intervals of lower and upper prob abilities  learning  Let  m           mn  and a sample size s be a given specification of the conditional probabil ity table P Aib  c    We can then act as if we had a contingency table of counts  sm          smn  lf we ge t a case in the configuration  b  c   and a   then retrieval qu ite simply consist in adding   to the count for a   and dissemination is just to calculate the new frequen cies  If global and local independence can be assumed the scheme is applicable to all tables  Back to  The scheme only works if both the states of A an d its parents are known  In general we may anticipate that the provided evidence  E  may leave uncertainty on both the states of A and of its parents  A nai ve approach in the general case could be to add a count of P  a   b  cl E  to the counts for a   This scheme is known as fractional updating  Titterington        However  the scheme has several drawbacks  For ex ample  if P A I b  c    P A I E  then the scheme may give unjustified counts yielding a false accuracy  If  for example  E    b  c   then nothing can be learned on the distribution of A  but nevertheless the sample size will be increased by one  See further discussion of this issue in Spiegelhalter and Lauritzen      a  as well as in Spiegelhalter and Cowell         A mathematically correct updating of the distribu tions under our interpretation results in a mixture of Dirichlet distributions rather than in a si ngl e one  a mixture is a linear combination with non negative co efficients summing to     This complicates the calcu lations intractably   in particular when adapting from the next case where mixtures of Dirichlet distributions are to be updated  Eventually the process will yet  agam result in a combinatorial explosion  Instead  the correct distribution is approximated by a single Dirichlet distribution  keeping the approach of modi fying counts   First of all  we want the approximated distribution to have the correct means  and the new set of probabilities  mj        m   is set to be the means of the correct distribution  Secondly  it would be prefer able also to give the distrihu t ion t he c orrect varian cPs  However  this is not possible since only one free parant eter is left  namely the equivalent sam ple size  Instead  the equivalent sample size is give n a value such t h  tt  t he   average v riancc   v    L         v   i l        ts correct  The r csu lt i ng chcrnc  wh ich is used i   aHUGIN  is t hc followittg      in t  the ltwans art  chang  d as if a full count W    oht aitwd   mi     m s  P a   b c II      w   I  P b  c I         s l  The last term   rl   be undcrst oocl so that it clistr ibut  cs that  fJ and C arc not in st ates  b  c  according to their present p ro babili t ies   may  the probability  over the  a    s  Next  the sam pie size is determined  s       L l rn        mi        k     L    i l  ll   V     i   where v  is the variance of l i in t he mixture  the for mulae may be found in Spiegelhalt er and Lauritzen       a    The new r ounts iii C s mi     Features of aHUGIN  The program a ii U G IN   wltich is currently     der int plementation  is an ex t cnsion of II U GIN  A nders  n et at         JIUGIN is a shell which allows the user to edit CPNs over finit e st at c variahlcs  and wh en t ll   CPN is specified  TIUG N creates     runtime sysl  llt for entering findings and ttpd t inr  prohahilit i s of tlw variables in the network  In aiJUGIN each variable lllilY be declared t o be in adaptation mode  If  for cx mplc  the variab le A with states a           an has parents B          C  th e n the con ditiona  probability table P  A I B         C  is modified by declaring A of ndapt at ion t y p e   The t ahle is i n  terpreted as a contingency table such that for ead  parent configuration b         c  the set P Ajb        c  is interpreted as a set of frequencies based on a sampl e of cases  Therefore the user will for each p arent config uration be prompted t o specify F QUIVALENT SAMPLE SIZE  The l arger the ESS  t hc more conservative t hc adaptation will be  The default val l     of ESS is Gk  where k is the number of states in      Alternatively t h e ttscr will he M ked t o specify an in terval for cac   of the prohahililics in t  conditional             Olesen  Lauritzen  and Jensen  probability tables  These in terva ls will th en be trans lated to sample sizes using the equivalent of      The ESS used for the given parent configur at io n will now be chosen as the minimum of the t r anslate d sam p le sizes for the individual entries        Fading  Variables in ada p tati on mode have an extra feature  fading  which makes them tend to ignore th in gs they have learnt a long time ago  considering them as less relevant  Each time a new case is taken into account  the equivalent sample si ze is discounted by a fading factor q  which is a re al number less than one but typ ically close to one  From the expression      for the Dirichlet density  it is seen that the fading scheme es sentially corresponds to flattening the density by r ais ing it to the power q  known as power steady d ynamic modelling  Smith       Smith         SIZE  In the case o f a change from accumulating to fading the EQUIVALENT SAMPLE SlZE is kept but the MAXIMAL SAMPLE SIZE provided by the user  ually claim its influence      Experiments with aHUGIN  To  in v es tigate  the  strengths  and  will grad  limitations  of  se r ies of experiments were carried out   The investigation was designed as a complete fa  lo rial simulation experilllent     t IH  now classical  Chest  aiiUGIN  a  clinic  example  Figure    originat ing frorn  and Spiegelhalt er            Laurit n  Each experiment simulates  If s is the initial ESS  then the maximal ESS after adaptation from a case is qs      Running n cases will result in a maximal ESS of    q  q s           q  This gives that        q  is the maximal sam ple size in the long run  Therefore the user is given the choice between ACCU MULATING  fading factor    and FADING  If fa din g is selected  the user is prompted for MAXIMAL SAMPLE SIZE  MSS  and the fading factor is then computed as  MSS     MSS  Defau lt value is lOOm  w h e re m is the number of entries in the table  Note  The result of fad in g is not only that the sample  size is reduced  Consider namely an entry with count a  and with samp le size s  an d suppose that ret r ie va l of a case results in an increase of the sample size by   and o f the count by x  Without fading the ratio between counts from present and past is x   a   but with fading the ratio is xjqa   This tells us that with fading the  present counts are given more weight  This can also be seen by assuming that the entry wilt never receive more counts  Without fadi n g the p roba bili ty will vanis h at the speed of a f s   n   while wi th fadi ng  the speed of vanishing is in the order of a f s   q          Runtime mode  Figure            cases   The   Ciwst clinic   X llllpk   and fo ur factors  dc   I l d ll     P  are considered  Tine r ndom  ated from  Rl  Probabilities  close to the  R   Probabilities v ry  san pks  R   o rigi n a l  are  and  L   enn  ones   difk renL from the migina  o ws   R   Probabilities  drifting over time   starting as the original ones   To control difTerences due t o chance va riat ions   the samples are reused   Thus  for example  all experimcTit s with probabilities as in Rl are based on identical dat a  Two different observational schemes      are investi gated  the first one is lll lillly included for control pur poses       Complete observations   The ad a pta tion starts with the CPN in the initial con figuration  Findings are entered  and wh en all infor mation on the case has been entered   the adaptation takes place changing the tables for the variables of      Data observed only on the variables  Visit  t o Asia     Smoker     Positive X   r ay     and   Dys  adaptation type   The P factor des c ribes difl erent weights on the prior distributions  expressed as v a ryi n g eq  ivalcnt  sR rnpk sizes  Two cases are considrcd  At any time between two cases the user can choose to change the adaptation type of any variable  When the adaptation type of a variable has been chan ge d   the user is prompt ed for p ossibl e mi s s i n g information on EQUIVALENT SAMPLE SIZE and MAXIMAL SAMPLE  pnoea     PI  Low precision  P   ll igh pncision   ESS ESS            I Oll   aHUGIN  A System Creating Adaptive Causal Probabilistic Networks  Finally  three different learning schemes  L  are inves  the random s amp le    tigated      All variables except ac c u mu latin g mode     Th ber c ulos i  s or cancer  in  Experiment      a      As    for the first      cases  then t he mod e is  postet ior probability intervals or p bls                                     A s     b ut with short memory  MSS          Tuberculosis or can ce r   is always in fixed mode as it is a pure logical tran sit ion   As can be seen  the whole in ves tigati on consists of   x   x   x        experiments   For each experiment a plot is generate d   sho w in g the current value of th e conditional probabil ities after each case has been processed  t ogether with ap proximate     p oste ri o r probability intervals   Results in accumulating mode           change d to fading  with long memory  MSS                                              d           ooo  Experiment       b           sooo  I             posterior probability intervals tor p bls   These experiments are very similar to those performed  by Spie gelhalter and Cowell         However  we al low uncertainty on all conditional probability tables  In general our results show the same pattern  For com  plete data the correct values are obtained quite fast  and the influence of the initial specifications vanishes after a f e w hundred cases  Figures    a  and    a  show an interesting phe  nomenon w h en learning from incomplete data        In these experiments  it can only be observed from t he given data that a maj ori ty of smokers suffer f rom dys pnoea  shortness of breath   It can not be inferred f rom the data whether this correlation is due to the presence or absence of bronchitis  In the fi rst exper iment  where all variables are in accumulating mode  th e frequency of bronchitis is overestimated  Figure    a    To compensate for th is   the condition al pr oba bility for dy spn oe a given bronchitis and none of the other diseases  is underestimated   F igure   a    Thus t he correlation b etw een what can a ct u ally be observed in the data is determined correctly  but the intermedi ate expl an ation is slightly incorrect  From these experiments we conclude  not su rpri singly   that the method has difficulties learning about con  ce pts on which dat a are indirect  In such situations the system rel ies str ongly on p ri or k nowledge   This con clusion was also reached by Spiegelhalter and Cowell                Results in fading mode  Figures    b   c  and    b   c  dis p l ay the results for the same exp er i m ent s as in F ig ures    a  and    a   but with the variab l es ch anged to fading with l ong memory after the first      cases  The same effect on esti mat ing intermediate variables can be observed  Note also  that the two curves vary syn ch rono u sly  Most proba bly this is a r e s u l t of variations in freq uenc ies due to           r                 Experimenl I      c        poslerior probabilily  intervals tor p bjs           i                       r                         j              Figure    Exp erimen ts with in c ompl ete data  The con diti on al probability of btonchitis given the p a t ient  is a smo k e r is learnt in  a   lccurnulating mode   b  fading m ode with long memory   c  fading mode with short  memory  ln the  third experiment   Figures     c  and     c    the  maximal samplesizes are reduced to      ThisexJwri ment reveals the mode  Figure    limit of the applicability of the frtdin     c  shows t hat t lw dat     He lwst  l X ass u ming t hat    II pa tients wi t  h bronchit is  plained by suffer from dyspnoea  To  naint ain t he consistP ncy with the d ata   the frequency of s nokcrs sufT ering from b ronchitis is  underestimated acc o r dingly  This pat t ern          H  Olesen   Lauritzen  and  Jensen  is general for fading with short memory for high and low probabilities  We conclude that special attention must be directed towards systematically m issi ng data and the choice of MSS if such variables are fading  Figure   shows a series of experiments with a declin  Experiment       a    ing probability of being a smoker  The first      cases are identical for the three plots  the variable being in         posterior probability intervals tor p s   accumulating mode  In Figure    a  the variable re  mains in this mode and it is seen how the probability is becomin g increasingly conservative as the ESS m creases   Experiment       a        posterior probabili y  ntervals for p djnot e b         b  Experiment           o posterJor probabilrty interva s for p s   c  Exp rimen              g poslerior probability lnervals tor p s   eooo  Experiment           posterio r probability intervals lor p djnot e b   b  I                r     gl  Q                          c  Experiment                    posterior  probabili y intervals for p dlnot e b          Figure    Learning about  bei ng a smoker       J    a  declining probability of       I    I                            Figure    The same experiment as in Figure   but for  Dyspnoea  given the patient has bronchitis but none of the other diseases   In Fig u re    b  the variable is changed to fading with lo ng memory  MSS   lOOO  after t he first      caes  This i n creases the dynami   behaviour of the system an d an almost correct adaptation is obtained  De  creasing the MSS to      Figure    c   increases the dynamic behaviour further  re  ult ing in stronger fluc tuations around the correct value  The general expe r i e nc e is that the  V SS shonld not he sd too low  nnd  that the experiments confirm th    of aiiUGIN   expected behaviour   aHUGIN  A System Creating Adaptive Causal Probabilistic Networks  To s u mmarize  aH U G I N seems to be able to adapt to chang i n g environments  thereby extending H U G I N with a valuable fun ctional i ty   Howeve r   special atten tion must be directed to the choice of M SS and to var i ables with systematically missing d ata   Andersen  S   K     O lesen   K  G     Jensen   F   V     and J ensen  F            H U G I N   A she l l for building Bayesian belief u ni verses for expert systems  In Proceedings of t h e     t h int ern ational joint confe r ence o n artificial intellig e n ce   p p    reprinted i n S hafer and Pearl                     Also  Andreassen   S   Benn   J   J     Hovorka  R     Olesen   K   G     and Carso n   E   R           a     A probabilis tic approach to glucose prediction and i nsulin dose adj us t ment   Techn i c al report   Inst i t u te for Elec tronic Sys tems   A a l b org U n i versity    A n d reassen  S     J ensen  F  V     and O lesen   K   G          b    Medical expert systems b ased on causal probabilistic networks  In ternational Journ al of Bi omedical Computation                  Cowell  R  G            BAlES   a probab i l i s t i c ex pert system shell with qual i tative and quantita tive learning   In Bayesian st a tistics      ed   J   M  Bern ardo   J      Berger  A   P  D awi d   and A   F  M   Smith    p   i n press  Clarendon Press  Oxford   UK   Jensen  F   V     Lauri tzen   S   L     and Olese n   K   G             Bayesian up dat i n g i n causal probabil istic networks by local c o mpu tations   Co m p u t a t ion a l St atistics Q u a rt e rly      Johnson   N   L   and Kotz            S             Distri b u t ions i n  statistics  Co ntinu ous multivariate dis t ri b u ti o n s    J oh n Wiley and Sons  New York   Lauritzen  S   L   and S p iegel h a l t er   D  J            Lo cal computations with probabilities on graphical st r u ctures and their appli cation to expert systems   with discussi on     Journ al of the Royal Sta tistical Society  Series B                               Probab ilis t i c inference  m  i n t ellig e n t  syste ms  Morgan Kaufmann   San Mateo   Shachter  R  D           Eval u at i n g influence d i agrams  Opera t i o ns Research                           Sh afer   G   R  and Pearl   J    ed      Rea dmg s  in u n certain reas on ing  Morgan Kaufm an n   San  M ateo   Califor n i a  Shenoy  P  P  and Shafer   G   R              Axioms for probab i l i ty and belief fu nction propagation   In Uncert a inty in artificial intelligence I V    ed   R  D   Shachter  T   S   Le v i t t   L  N   K an a    an d J   F   Lem mer    pp            North   Hol l and   Amsterdam   Smith  J   Q             A general ization of the Bayesian steady forecasting mo d el   Journal of t h e Royal Statistical So ci e t y  Series B         Smith  J   model    Q                          The m u l ti parameter st ead y  Journal of t h e Ro yal St atistical Society   Series B         Spiegel halter  D   and Lau r i tzen   S   L               Tech n i ques fo r Bayesi a n a n alysis i n e x p e r t  syste m s   A n n als of  
  As Bayesian networks are applied to larger and more complex problem domains  search for flexible modeling and more efficient in ference methods is an ongoing effort  Mul tiply sectioned Bayesian networks  MSBNs  extend the HUGIN inference for Bayesian networks into a coherent framework for flexible modeling and distributed inference  Lazy propagation extends the Shafer Shenoy and HUGIN inference methods with reduced space complexity  We apply the Shafer Shenoy and lazy propa gation to inference in MSBNs  The combina tion of the MSBN framework and lazy propa gation provides a better framework for mod eling and inference in very large domains  It retains the modeling flexibility of MSBNs and reduces the runtime space complexity  allow ing exact inference in much larger domains given the same computational resources     Introduction  Bayesian networks  BNs  provide a coherent frame work for inference with uncertain knowledge  and as more complex domains are being tackled  search for flexible modeling and more efficient inference meth ods is an ongoing effort  Multiply Sectioned Bayesian Network s  MSBNs       extend the HUGIN inference method      The framework allows a large domain to be modeled modularly and inference to be performed distributedly  It supports object oriented modeling     and multi agent paradigm       Lazy propagation     extends the Shafer Shenoy  S S      and the HUGIN methods  resulting in much reduced runtime space complexity  We extend the lazy propagation to inference in an MSBN  The contribution is an inference scheme for  MSBNs that has much reduced space complexity com pared to the S S and HUGIN based scheme  The new scheme allows coherent inference in much larger MS BNs given the same computational resources  We extract common aspects of tree based inference in Section    We review the S S and lazy propagation in Section    A distributed triangulation for MSBN compilation is presented in Section    We overview MSBNs in Sections    In Section    we present a new MSBN compilation  We extend the S S and lazy prop agations for inference with MSBNs in Sections   and    We compare alternative MSBN inference methods in Section    We focus on the new methods without detailing most formal properties  A few necessary formal results are included with the proofs omitted due to space limit  These proofs will be included in a longer version     Communication in trees  Consider a connected tree T where each node has its  internal  state and can receive send a message from to a neighbor  The exchange follows the con straints     Each node sends one message to each neighbor     Each node can send a message to a neighbor after it has received a message from each other neigh bor  A message sent by a node is prepared on the basis of the messages received and its internal state  If the state may change as a result of messages received  then the message passing is called dynamic  see Fig    and Section     otherwise called static  see     and       We shall refer to all the processing  outgoing message preparation and state change  taking place between re ceiving messages and sending a message to a particular neighbor as a generic operation called SetMsgState    Inference in MSBNs with Extended S S and Lazy Propagation  We refer to the combined activity of nodes according to the constraints as  message  propagation  Based on the constraints  initially only leaves can send and at any time there is a subset of nodes ready to send a mes sage  Depending on the sending order of nodes  two regimes of propagation can be identified  asynchronous and rooted  In asynchronous propagation  no additional rules gov ern the sending order  In rooted propagation  a node r is arbitrarily chosen as the root  and T is directed from r to the leaves  All nodes except r has exactly one parent  First a recursive operation CollectMessage is called in r  For each node x  when CollectMessage is called in x  x calls CollectMessage in all children  When each child has finished with a message sent to x  x sends a message to its parent  if any   We shall refer to this stage of rooted propagation as a  rooted  collect propagation  After CollectMessage has terminated in r  another re cursive operation DistributeMessage is called in r  For each node x in T  when DistributeMessage is called in x  x sends a message to each child and calls Dis tributeMessage in the child  We shall refer to this stage as a  rooted  distribute propagation  It is easy to show that each asynchronous propagation corresponds to a rooted propagation   Figure    Dynamic propagation in a tree   Consider Figure    a   Each node stores a pair  x  y   where x is a local constant and y is a sum initialized to x  To sum x at all nodes  we call CollectMessage from any root  b   SetMsgState consists of adding incoming numbers toy  and setting the message to a neighbor V as the sum of x and all incoming numbers except that from V  The sum can now be retrieved from the root  Next  we call DistributeMessage at the same root  c   The sum can now be retrieved from any node     Probability propagation in JTs  Various methods for inference in BNs have been con structed                     Several           use ajunction tree  JT  as mntime structure  We review how to con vert a BN into a JT and then consider two of them       Conversion of a BN into a JT  A BN S is a triplet  N  D  P  where N is a set of variables  D is a DAG whose nodes are labeled by el ements of N  and P is a joint probability distribution        jpd  over N  D encodes independence inN through d separation      and hence P N    DxEN P xj r x    where  r x  is the parents of x in D  Conversion of a BN starts with moralization  It con verts a DAG into an undirected graph by completing the parents o f each node and dropping direction of links  The result is called a moral graph  Then trian gulation  see Section    converts the moral graph into a chordal graph      A JT over N is a tree where each node is labeled by a subset  called a cluster  of N and each link is labeled by the intersection  called a sepset  of its incident clus ters  such that the intersection of any two clusters is contained in every sepset on the path between them    A maximal complete set of nodes in a graph is called a clique  After the triangulation step  a JT for a BN is created with nodes labeled by cliques of the chordal graph  Such a JT exists iff the graph is chordal  After a JT is created  distributions in the BN are as signed to the clusters  For each x E N  P xj r x   is assigned to a cluster containing x and  r x        Shafer Shenoy propagation  S S propagation     is static  where each cluster holds a belief table over its variables  defined as the product of all distributions assigned to it  Hence the product of the belief tables in all clusters is the jpd  During propagation  each message sent over a sepset is a belief table over the variables in the sepset  SetMs gState consists of multiplying the local table with in coming tables from other neighbors and marginalizing the product down to the corresponding sepset  For each cluster  after the propagation  the product of the local tables and all incoming tables is the marginal probability distribution over the variables of the clus ter       Lazy propagation  Lazy propagation     is also static  where each cluster C holds the assigned distributions as a set rather than as a product  The belief table of C is defined the same as above but the product is not explicitly computed  hence the reduced space complexity over the S S and HUGIN methods   Each message sent over a sepset is a set of tables each of which is over a subset of the sepset  SetMsgState to a given neighbor consists of taking the union of local tables and incoming tables from other neighbors  and then marginalizing out each variable not in the sepset    The  property is a lso known  as  running intersection         Xiang and Jensen  Figure     a  G is the union of the graphs in  b     b  G is sectioned into four subgraphs   c  A hypertree over G               B d g  B e    c e   B  c e    B a d     a d   a c d e g B a g  B c e    d e g   Figure    Message passing in lazy propagation  Figure   illustrates lazy propagation  The cluster  a c d e g  has sepsets  a d    c e  and  d e g   It has local tables  B a g  B c e   and receives the tables B  c e  and B a d   It sends out B d g     I  B a d B a g  and B e     LcB c e B  c e   Triangulation as tree propagation     We consider triangulating an undirected graph orga nized as a  hyper  tree   Let G      N   E    i             n    be n graphs  The graph G     U N   U E   is the union of G s  denoted by G    U G   Definition    If for each i and j  l j    N  n Nj spans identical sub graphs in G  and Gj  then G is sectioned into G s  l j is the separator between G  and Gj  The graph in Figure    a  is sectioned in  b    Each node in a separator is highlighted by a dashed circle   Let G     N  E  be a connected graph sectioned into  G      N   E     Let the G s be orga nized as a connected tree H where each node is labeled by a G  and each link is labeled by a separator such that for each i and j  N  n Ni is contained in each subgraph on the path between G  and Gj in H    Then H is a hypertree overG  Each G  is a hypernode and each separator is a hyperlink   some N   Then the triangulation is constrained by H  A node x in an undirected graph is eliminated by adding links such that all of its neighbors are pair wise linked and then removing x together with links incident to x  The added links are called fill ins  Theorem          A graph is chordal iff all its nodes can be eliminated one by one without adding fill ins   Let a hypertree H overG be rooted at a given hyper node G   An elimination order p of G is constrained by H if p consists of recursively eliminating nodes that are only contained in a single leaf hypernode of H  Proposition   An elimination order of G con strained by a hypertree H over G produces a trian gulation of G constrained by H   Triangulation constrained by H can be performed as a  dynamic  rooted collect propagation of fill ins  LetG  be the child of Gj in H with separator I j    N  n Nj  The message sent from G  toGj is a set of fill ins over l j  SetMsgState consists of the following  Algorithm    SetMsgState for propagating fill ins   add to G  fill ins received from each neighbor except G   eliminate N    N  and add fill ins to G   set message to G  as all fill ins over l j obtained above   Definition    Figure    c  shows a hypertree H over G in  a    Note that the above concepts are applicable to both directed and undirected graphs  Definition   Let H be a hypertree over a graph G sectioned into   G    Let G  be a graph from a trian gulation of G such that each clique in G  is a subset of    Note the similarity to JTs    f g h    f h     J    g  k  h  I  u     G k  G I         fj    Figure    Hypernode G   i       receives fill ins from two hyperlinks    i j  and  j k l   After SetMs gState  fill ins  dashed lines  are added toG  and the message       h   is sent to the parent over the hyper link  f g h   Suppose H is rooted at G   ForG   SetMsgState is simplified   Gj    null  Nj     and the last step is not applicable    Figure   illustrates the collect propaga tion of fill ins    Inference in MSBNs with Extended S S and Lazy Propagation   a   b   j    k        I                 rn  Gj    i    f               G          G       g  a  G      h                              G                                        k       I     l    G  I        c    g    h   e    c   d         J         j                 I  G                   c       G   o           g  h   h                           b  G I     t   tp        rn  G    Figure    Illustration of propagation of fill ins   It can be shown that fill ins sent during collect propa gation of fill ins is independent of the elimination order used by SetMsgState in each hypernode and are deter mined uniquely by the chosen root  Hence if H has n hypernodes  potentially n different triangulations of G  assuming each local elimination is optimized without ties  can be obtained each from a collect propagation at a distinct root  To obtain then triangulations  how ever  we do not have to perform collect propagationn times  Instead  a full propagation in H is sufficient  CollectMessage will be performed as above  Dis tributeMessage will be performed with the same SetMsgState  Algorithm     Finally  each non root performs SetMsgState as if it is a root  Figure   illustrates the full propagation with H in Fig ure    The root is G   During CollectMessage  SetMs gState is first performed in Go and G  Suppose the elimination order in G  is  n  m     The fill ins produced are    j  k    j      as shown in  a  with dashed links  The resultant chordal graph is labeled Gij     Ga sends the above fill ins to G   Similar operations then occur in Go  b  and G   c   Since G  is the root  it performs a simplified SetMs gState  After adding the fill in     h   the resultant graph Gi is chordal as shown in  d    CollectMessage now terminates  DistributeMessage follows as shown in  e  to  g   Each non root hypernode performs one more SetMsgState as if it is a root with the results shown in  b     c  and  h   Note that in  h    since the received fill in is  j  k  and the elimination can be per formed in any order  G  is simpler than G             Overview of MSBNs  An MSBN M is a collection of Bayesian subnets that together defines a BN           M represents proba bilistic dependence of a total universe partitioned into  multiple subdomains each of which is represented by a subnet  Just as the structure of a BN is a DAG  the structure of an MSBN is a multiply sectioned DAG  MSDAG  with a hypertree organization   A hypertree MSDAG  J   U D    where each D  is a DAG  is a connected DAG such that     there exists a hypertree over     and     each hyper ink d separates     the two subtrees that it connects   Definition    The second condition requires that nodes shared by two subnets form a d sepset     Let D     N  E    i        be two DAGs such that D   Do U D  is a DAG  The in tersection I   No n N  is a d sepset for Do and D  if for every x E I with its parents  r x  in D   either  r x     N  or  r x     N   Each x E I is called a  Definition  d sepnode   This is established as follows  Proposition   Let D     N   E    i         be two DAGs such that D   Do U D  is a DAG  No   N  and N    N  are d separated by I   No  l N  iff I is a d sepset   It can be shown that the above definition of MSDAG is equivalent to the constructive definition in       An MSBN is defined as follows  Definition    An MSBN M is a triplet M    N   J   P   N   U  N  is the total universe where each N  is a set of variables       U  D   a hypertree MSDAG  is the structure where nodes of each DAG D  are labeled by elements of N   Let x be a variable and      x  be all parents of x in     For each x   exactly one of its occurrences  in a D  containing  x  U  r x   is assigned P x  r x    and each occurrence in other        Xiang and Jensen  DAGs is assigned a constant table  P   Il  Pn  is the jpd  where each Pn  is the product of the prob ability tables associated with nodes in D   A triplet S     N   D   Pn   is called a subnet of M  An example MSBN is shown in Figure     j gVo P oll   oSo li p   P  d l P s  e c  r  P M  P glh   P bjb   a   f     P ilf g   i        h   P h          j  P mti  k P Jk l            rz    but incomplete in Gi         By using Gi tj the message from sl to s  can be decomposed into two submes sages  one over    g  and the other over  g  h   This results in a more compact message representation  For each Gi  i  we organize its cliques into a set of JTs  a JF  so that each submessage can be obtained directly from one cluster of each JT  Without formally pre senting the general algorithm  we illustrate using the example in Figure     n      P l   m  s   Figure    An MSBN     Compilation of MSBNs  So far  inference in MSBNs          has been an exten sion to the HUG IN method       which works with one triangulation and one decomposition of messages for the entire propagation  As demonstrated in Section   and below  it is possible to let the triangulation and decomposition depend on the direction of messages  The resultant clusters can be smaller than obtained by the HUGIN method  Below we explore this idea for inference in MSBNs using the S S and lazy propa gation       Local structure for message inference  First moralization is performed as a full dynamic prop agation on the hypertree  A message sent from a hy pernode to another consists of  moral  links over their d sepset  During CollectMessage  SetMsgState con sists of the following      For each hypernode  parents of each node in D  are completed and directions of links are dropped      Moral links from each child hypernode are then added      Set the message to the parent hypernode as the moral links over their d sepset  For DistributeMessage  SetMsgState consists of     and      Figure    b  is the moralization of the MSBN in Figure    Next triangulation is performed as in Section    Then we convert each Gi into a JT for local inference  as in Section      and convert each Gi  tj into a junction forest  JF  for computing messages from subnet S  to Sj for inter subnet belief propagation  We present the conversion of Gi tj into a message JF below  To see the need of multiple structures for each subnet  observe that Gi is generally more densely connected than Gi tj  In Figure    the d sepset is complete in Gi   The HUGIN propagation is dynamic whereas S S as well as lazy propagation are static   Figure    Junction forests for message computation  First  consider G       Since the d sepset is complete  no opportunity for message decomposition    we or ganize the cliques of G        into a JT Ta t  shown in Figure        During inference  the message from Sa to s  can then be obtained from the cluster  j  k  l  m   Similarly  JTs To t   T  tl and T  to can be obtained  Next  consider G t       Since the d sepset is incomplete  the message is decomposable    we create a JF con sisting of two JTs as in      During inference  the submessage over  f g  can be computed using the up per JT from the cluster  e f g   The submessage over  g h  can be obtained from the cluster  g  h  of the lower JT  The JF is constructed as follows  For each clique in the subgraph of Gi        spanned by the d sepset  create an isolated node labeled by the clique  Hence we obtain the two clusters at the bottom of      They are the candidate clusters from which the submessages will be obtained  We then complete the d sepset in Gi       and create a JT out of it as shown in the top of      We split this JT into two and merge each with one of the candidate clusters as follows  We delete the d sepset cluster  f g  h    breaking the JT into two subtrees  For one subtree  the cluster  b  h  was adjacent to  f g h   Since the candidate cluster  g h  satisfies  g  h n b  h     f g  h n b h   we connect  g  h  with  b  h   For the other subtree  the cluster  e f g  was adjacent to  f g  h   Since the candidate cluster  f  g  is a subset of  e  f g   we remove the candidate cluster    g   The resultant JF is the one in      Similarly  JF T  t  can be obtained  Without confusion  we refer to message JFs and in ference JTs collectively as JFs  In the next section  we define a data structure to guide message passing between local JFs at adjacent subnets    Inference in MSBNs with Extended S S and Lazy Propagation       Linking message  JFs and  inference  JTs  Inference in an MSBN can be performed as a full prop agation in the hypertree consisting of message passing among JFs  SetMsgState will be detailed later   When a message is to be sent from S  to Sj  it is computed using T   j  When Sj receives the message  it will be processed by Tj and each Tj  k  k     i   Figure       illustrates directions of messages during collect propa gation with root sl  and     illustrates distribute prop agation   Figure    Directions of messages during propagation  As each submessage is obtained from a cluster of the sending JF and absorbed into a cluster of the receiving JF  we create a linkage that links the pair of clusters         I   g        e f g                                     c d  d e  Figure    Linkages between two message JFs  Figure   shows the two linkages from Tl    to T   o used during distribute propagation  It reflects the fact that the d sepset     g  h  can be decomposed into two independent subsets  f  g   and  g  h  conditioned on their intersection  g   Each linkage  shown as a dashed arc  is labeled by the intersection of the two end clusters  We shall call the two clusters the hosts of the linkage  Once linkages are determined  the set of all JFs forms a linked junction forest  LJF        Belief assignment  Next  we assign conditional probability tables  CPTs  in the MSBN to clusters in the LJF  For each JF of each subnet  the assignment is performed as follows  For each variable  r  if a CPT is associated with it  then assign the CPT to a cluster in the JF that contains  r and its parents  The joint system belief of the LJF is then defined as B  N    fl  flj flk f i j k  where i is the index of infer ence JTs  j is the index of clusters in a given JT  f i j denotes the set of CPTs assigned to the jth cluster in the ith JT  and f i j k is the kth CPT in the set  It is easy to see that B N  is identical to the jpd of the MSBN        Since CPTs are assigned in the same way in inference JTs and message JFs  the belief of all JFs from the same subnet are identical  Although each subnet is associated with multiple JFs  only one copy of each CPT needs to be physically stored  For each CPT  it suffices to store a pointer at the assigned cluster in each JF     Shafer Shenoy propagation in LJF  We extend the S S propagation  Section      for infer ence in a linked junction forest  For each cluster in each JF of each subnet  a belief ta ble is created by multiplying the CPTs assigned to the cluster  Inference is performed as a full propagation over the hypertree during which messages are sent be tween JFs in adjacent subnets  When a message JF has multiple linkages to an adjacent JF  the message consists of multiple submessages  otherwise the mes sage consists of a single submessage  each of which is sent across a distinct linkage  Each linkage is used for message passing in a unique direction  Each submessage is prepared at a distinct JT in a mes sage JF  A local collect S S propagation is started at the linkage host and the submessage is then obtained at the host  The propagation involves incoming link ages and their hosts in the adjacent JFs  as illustrated in Figure      Figure     To compute the submessage from T     to is extended  dotted box  to include link age hosts  j  k   l   m   from T     and     i j p  from To     The collect propagation starts at linkage host  f g  h  i   Now we define SetMsgState for preparing the message from S  to Sj sent by message JF T   j   T   T      Algorithm    SetMsgState for S S propagation in LJF   for each junction tree of Ti tj start collect S S propagation at the host of linkage to S   set submessage as marginal of host belief to the linkage   To analyze the effect of the propagation  we define the belief tables associated with different identities in an LJF  For each cluster C with a local belief table    and incoming messages      i               the belief table Be  C  is the product     f        Note that the messages        Xiang and Jensen  include messages from sepsets as well as submessages from linkages  For each inference JT T over N  the be lief table BT N  is the product BT N    IJ  Be   C    where i indexes clusters ofT  It can be shown that the extended S S propagation is coherent  After the extended S S propagation in the LJF  a S S propagation needs be performed at an inference JT to answer local queries  Note that the collect stage of the propagation should be performed on the extended JT to count the incoming messages from adjacent message JFs  Also note that when evidence is available on a variable in a subnet  it should be entered to a relevant cluster in each JF of the subnet     Lazy propagation in LJF  The extended S S propagation can be directly modified into extended lazy propagation in LJFs as follows  For each cluster in each JF of each subnet  its belief table is defined in the same way as the extended S S propagation  but multiplication of assigned CPTs is not performed explicitly  The S S propagation per formed in each JF is replaced by lazy propagation  Sec tion       Each message over a sepset and each sub message over a linkage will in general be a set of belief tables over a subset of variables of the sepset linkage without being multiplied together  Theorem    shows that the extended lazy propagation ensures coherent inference  Theorem     After a full extended lazy propagation in an LJF  for each subnet S  over N   its inference JT    satisfies BT   N     I  N  N  Ilj BT   Nj     where j indexes inference JTs  As for normal BNs  the main advantage of lazy propagation is its decomposed representation of be lief tables messages  The decomposition leads to re duced space complexity  which is particularly signifi cant when the problem domain is very large     Conclusion  We presented how to construct a linked junction for est  LJF  from a multiply sectioned Bayesian network  MSBN    and how to extend Shafer Shenoy and lazy propagation for inference in such an LJF  It is worth while to compare the new methods with earlier work on the construction of LJF and the HUG IN based in ference method           First of all  the new method constructs multiple JFs for each subnet  one for local inference and the oth ers for inter subnet message computation  The previ ous method  on the other hand  creates a single JT at  each subnet for both local inference and inter subnet message computation  With the new method  since each message JF is dedicated to the computation of messages to a particular subnet  its structure is less constrained and is generally more sparse  With the previous method  a JT must function correctly at all conditions  send and absorb messages to from each adjacent subnet  and it is thus more constrained  re sulting in generally more densely connected JT struc tures  Although we have extended the S S and lazy propaga tions in the LJF constructed by the new method  they can be modified to perform in an LJF constructed by the previous method as well  G iven what we have pre sented  the modification is straightforward  To the S S propagation  the benefit of using the new construction is more compact belief representation and more effi cient inference computation due directly to the sparser JF structure  To lazy propagation  the benefit is that the sparser structures provide better guidance to the propagation  To see this  imagine that if an entire mes sage JF is a single cluster  the burden of finding an effective marginalization order for computing a mes sage will be placed entirely at runtime  Hence  each message JF in the new construction can be viewed as a concise recording of a set of effective marginalization orders ready for runtime exploitation    On the other hand  the LJF by the previous method needs not to maintain multiple JFs at each subnet  Inter subnet message computation and local inference computation can then be completed by just one propagation in the only JT at a subnet  instead of several propagations one at each JF    This observation suggests a tradeoff between using an LJF constructed by the new method and that by the previous method  One factor in making a choice is the relative sparseness of the LJF obtained by each method  which depends on the topology of the MSBN in question  Another factor in practice is the empha sis placed on simplicity in control  which translates to development time  and efficiency in runtime computa tion  Secondly  the extended lazy propagation has much lower space complexity than the previous HUGIN based inference for MSBNs due to the factorized stor age of belief  With the lazy propagation  for each CPT in the MSBN  only one copy needs to be stored in the LJF  Hence the total number of independent param eters stored in the LJF is    for the example MSBN  If full CPTs are stored to save the on line derivation   A  marginalization order specifies the order in which  each variable is to be marginalized out  Two such orders are equally effective if their computational complexity are the same    Inference in MSBNs with Extended S S and Lazy Propagation     values should be stored  With the HUGIN based method  the total storage of all belief tables for all clusters in the sparsest LJF has a size of      As the MSBN grows in size and connectivity  the sizes of clus ters of the LJF grow  The belief storage per cluster in an LJF grows exponentially with the cluster size with the HUGIN based method  while with the extended lazy propagation it grows only linearly  Therefore  the extended lazy propagation will allow much larger MS BNs to be constructed and used than possible with the HUGIN based inference  given one s computational re source  Acknowledgement  We thank the anonymous reviewers for helpful com ments  The support of Research Grant OGP        to the first author from NSERC of Canada is acknowl edged  
  We present a method for calculation of my opic value of information in influence dia grams  Howard   Matheson        based on the strong junction tree framework  Jensen et al          An influence diagram specifies a certain or der of observations and decisions through its structure  This order is reflected in the corre sponding junction trees by the order in which the nodes are marginalized  This order of marginalization can be changed by table ex pansion and use of control structures  and this facilitates for calculating the expected value of information for different information scenarios within the same junction tree  In effect  a strong junction tree with expanded tables may be used for calculating the value of information between several scenarios with different observation decision order  We compare our method to other methods for calculating the value of information in in fluence diagrams  Influence diagrams  value of in formation  strong junction tree  table expan sion  dynamic programming   Keywords      INTRODUCTION  Influence diagrams were introduced by Howard   Matheson         as a formalism to model decision problems with uncertainty for a single decision maker  An influence diagram can be considered a Bayesian network augmented with decision variables and a util ity function  The decision variables  D           Dn  in the influence diagrams are partially ordered and the chance variables are divided into information sets              In The information set      is observed immedi ately before decision D  is made  and the information set In consists of the chance variables that are observed later than the n th decision is made  if ever   Let v  be the set of variables preceding D   t hat is  v  contains the past relevant for D   The solution of a decision problem modeled by an influence dia gram is a sequence of decisions that maximizes the expected utility  Shachter        describes a method to solve an influence diagram without unfolding it into a decision tree  rather  the influence diagram is transformed through a series of node removal and arc reversal operations  Shenoy        describes an other approach to the problem of solving influence dia grams by conversion into valuation networks  This ap proach is slightly more efficient than that of  Shachter          Shachter   Ndilikilikesha        and  Ndiliki likesha        modified the node removal arc reversal algorithm and achieved a method that is equivalent to the algorithm presented in  Shenoy        with respect to computational efficiency  Jensen et al         describes an efficient method for solving influence diagrams using strong junction trees  This is an extension to the junction trees used for com putation in pure Bayesian decision analysis  It is on this framework we base the present work  We are about to choose among a set of k options  These options are packed into the decision node D  We have already received some information e  and now we can either choose among the options or we can look for more information  The  looking for more information  is to consult some source which will provide the state of a chance variable  Let the chance variables in ques tion be the set r    AlI      Am   We want to calcu late what we can expect to gain from consulting the information source  For all the considerations in this paper we deal with the myopic value of information question  At any time  we can ask for the state of at most one of the variables in r    Myopic Value of Information in Influence Diagrams  As basis for the considerations we have expected utilities for  D  EU Die         the  given the evidence e  and the  decision d of maximal expected utility is chosen  If A  E r is observed to be in state a  then EU Die  A    a   is the new basis  Now  before observing A  we have probabilities P A  le   and the expected utilities of the optimal action after having observed A  is  EUO A   Die   LP A  e  mgxEU Die  A    F igure  The  value of observing A       The scenario with one non intervening deci  sion node   A   is the difference  VOI A   Die   EUO A   Die   maxEU Die   For this scenario we have  D   Value of information is a core element in decision anal ysis  and a method for efficient calculation of myopic value of information in Bayesian networks  augmented  VOI A   Die    L H P HIA   e  U D  H    mgx  P Hie   U D H    with a utility function  is described by  Jensen   Jiangmin              Also   Beckerman et al      LP Ade            max  A   describes a method for calculating the utility based myopic value of information  Methods for computing the value of information in influence diagrams have been described by  Ezawa          based on the arc reversal node removal meth  ods   Poh   Horvitz         approach a notion of qual  itative value of information through graph theoretic considerations yielding a partial order of the chance nodes in the model   For  the  P HIA   e   calculation  of  for all variables  VOI A   Die  A  in r  These  The value of information can be viewed as the dif differing in the observation decision sequence in the influence diagram  We present a single model frame work for calculating the exact value of information of a chance node   need  probabilities can be achieved through entering and propagating each state of  A    Using Bayes  rule  the  requirement is transformed to a need for  ference in expected value between two models only  we  conditional  all  A   P A  IH  e  for  in r  They can be achieved all by entering and  propagating the states of  H   So  the number of propa  gations necessary for solving the value of information task for this scenario is the minimum of the number of states of in r   H and  the sum of the states of the variables  For the considerations in this paper  the network is of considerable size so that a propagation in the network is a heavy  but feasible  task        THE NUMBER OF H IS LARGE  This means that the  methods presented shall be evaluated in the light of  The assumptions in Section  their propagation demand   we would like to relax them  Often       are very crude and  D has an impact P H D   Also   on H and in that case we will need     the number of states of  SIMPLE SCENARIOS  We shall first describe a couple of simple scenar ios which have efficient solutions   The first scenario  is standard and has been treated more detailed by  Jensen   H  as well as the sum of all  states of r may be very large           H may be  propagations  see Figure       The following method reduces the number of propa gations to the number of states in  D   is a modification of a trick by Cooper      ONE NON INTERVENING DECISION  There is one decision node  D  which has no impact  on any of the chance nodes in the model  The utility function  U is a function of D  and the chance variable H  which may actually be a set of variables  see Figure       a large set of  variables   and we will look for methods requiring less  The method           The  utility function is transformed to a normalized util ity NV through a linear transformation such that    S NU S    NU  is represented in the influence dia  gram by a binary node NU with the argument vari  ables H  which might include D  as parents P NU   yiH   NU H   see Figure      and with        Dittmer and Jensen  ENU Die  can be NU   y   calculated by entering and propa  gating  Now  let A be a variable in r  Assume that A is ob  served to be in the state  a   Then we have  ENU Dia  e      P NU     YID  a  e   P aiNU   y  D  e    P NU   y ID e   P aJD  e  P aiNU   y  D  e    ENU Die   P aiD  e  Figure      A scenario where the method of Section       is inadequate   and the expected normalized utility after observing A  is     A  maxn ENU DIA  e   P AID  e      The required probabilities  P AID  e   P AINU   y  D  e   and  can be achieved by entering and propagat  ing the states of Din a network conditioned one and in  one conditioned on   e  NU   y    Hence  the number of  propagations required for this calculation is twice the number of states in  D   that is  with   k  propagations  we can calculate the value of observation for all vari  ables  It should be noted that there were no structural assumptions for this result   In most cases the information e as well as the variables  D are not descendants P AID  e    P Aie  and the  which may be observed prior to  Figure      in Figure  The Cooper transformation of the scenario      of  D  In  method only requires    The normalized value of information is defined as  NVOI A   Die     A     x and   L  H P HIA   D  e  NU D    L   P HID e  NU H     L P A Ie   VOl   mtx    H  can be calculated from  NVOI  transformation   by the inverse  The expected normalized utility of a decision d  given  the evidence  e  can be calculated as  ENU LNU H       P HJd e   H    L P  NU   yiH   P Hid e  H     L P NU     y  Hid  e   H     P NU     D  The  propagations   k  A SEQUENCE OF DECISIONS next  scenario  to  consider  is  the  following   We have a sequence of decisions and observations Io  D    I           Dn  In where each I  is a set of chance  variables   In  observed    is the set of variables which are never  The variables are structured in an influ  ence diagram  see Figure     for an example   We are  in the middle of this sequence  we have observed       and are about to decide on  ther option of observing Let  VOI X  Di   jiVi   one   where  D   but we have a fur  variable of the set r    i     j   denote the dif  ference in maximal expected utility for  D   between  observing chance node X immediately before deciding  D  and immediately before deciding on Dj  That is VOI X  Di jJVi  denotes the difference between hav ing X in      and in Ij   at the time of deciding on D   on  The standard dynamic programming technique for solving an influence diagram is to perform a sequence  of marginalizations in reverse order  Shenoy   Shachter   Peat   yid  e   Using Bayes  rule and giving  these cases                 Chance nodes are marginal  ized through a summation and decision nodes are  the even distribution   maximized   Since summation and maximization do  not commute  the order of marginalization is impor         Myopic Value of Information in Influence Diagrams  Figure    A strong junction tree for the influence dia gram in Figure    The strong root is the c lique G  at the far left  the chance variable B  The model for this observation decision sequence is shown in Figure    Figure    An influence diagram with the observation decision sequence Dt  C  D    A E   Da  B  Note that A and E may be observed in mutually arbitrary order but both will be observed   B r         tant and it is performed in the following order  First marginalize In  in any order   then D      then In    in any order    etc  When    has been marginalized  we have a representation of the expected utility of the various options of D  given the past  It is tempting to use this technique to condense the future into a utility function over a subsei  of the cur rently unknown variables and the decision node D  and to use this condensed future for the calculation of value of information  However  the condensed future contains max expected utility decisions  and observing a variable from r may affect these decisions  This can be avoided by assuming that the future is independent of r given D   and the past    Such an assumption will rarely hold  and instead we will introduce a technique which does not have that kind of assumption  In  Jensen et al         the junction tree technique is used to solve influence diagrams  A so called strong junction tree is constructed with a so called strong root  This means that there is a clique Co such that when a collect operation to Co is performed  then all marginalizations can be performed in the proper order  see Figure     Note that the strong junction tree in itself does not ensure that marginalizations are per formed in a proper order  When marginalizing in a clique we need a control structure giving the order of rnarginalizations  The   proper order  need not be the reversed temporal order  It is sufficient that each vari able is eliminated in reverse temporal order with re spect to its Markov blanket  The Markov blanket of a node X is the minimal set of nodes covering X from influence from other nodes  that is  the Markov blan ket for node X consists of X  s parents  children  and children s parents  In Figures   and    B is not observed  or rather  B is not observed until after the last decision is made   Now  assume that before deciding on D   we observe  Figure    An influence diagram with the observation decision sequence B  D   C  D    A E   D   The difference in expected utility when solving the two influence diagrams is VOI B  D   oolv    that is  the value of observing B before D  rather than never ob serving B  The difference between the two scenarios can be seen on the strong junction trees in Figures  a and  b   a  b  c  Figure    Strong junction trees for the two scenarios of Figures   and    and a junction tree adequate for both scenarios  It is possible to construct a junction tree capable of        Dittmer and Jensen  solving both scenarios and in effect calculate the value of information between the two information scenarios  The crucial thing about a strong junction tree is that it allows marginalization in a proper  reverse  tem poral order and this can be done for both temporal orders in the strong junction tree shown in Figure  c  This strong junction tree is obtained from the junction tree in Figure  a by adding B to the cliques down to  D   C   This observation can be used in general  To obtain a strong junction tree with strong root Co for calculat ing VOI A  D   jiVi   construct a strong junction tree for the scenario with A in Ij     Then Co imposes a  partial  order   for the cliques  such that C   C  if and only if C is on the path from C  to C   Identify the cliques C  and CA   C  is the clique closest to the Co containing D   and CA is the clique closest to Co containing D   Let C A be the  greatest lower bound  of C  and CA   That is  C A is the clique furthest away from Co such that C A   C  and C A   CA  when the temporal order is strict  then C A   C    Finally  ex tend all cliques on the path between C A and CA with the variable A  As mentioned earlier  a control structure is associated with the  strong  junction tree  This structure handles the order of marginalization  and therefore we can use the expanded junction tree  and the associated con trol structure  in Figure  c to marginalize B from any clique of our chaise  After B has been marginalized from a clique  the table space reserved for B in cliques closer to the strong root is obsolete  Clever use of the control structures will prevent calculations to take place in the remaining table expansions  and the num ber of table operations in the remaining subtree equals that of an ordinary strong junction tree       Figure    An influence diagram with temporal order from left to right  no forgetting arcs are not included    It discloses temporal independence between D  and  D   D     From  Jensen et al           a  NON STRICT TEMPORAL ORDERS  As mentioned previously  a proper elimination order of an influence diagram is an order where the elimi nation order of each node and its Markov blanket is a reverse temporal order  This means that although the influence diagram in the offset requires a linear tem poral order of the decisions  then the actual diagram may disclose temporal independencies which can be exploited when solving it  The influence diagram in Figure   has a temporal order of the decision nodes with increasing index  However  when f has been observed  then Da can be decided at any time independently of the observations and deci sions on e  g  D   and D   This is also reflected in the strong junction tree in Figure  a where the branch containing D  can be marginalized independently of the other branches   b  Figure    Strong junction trees  derived from Figure   illustrating the difference between never observing h  a  and observing h immediately before decision D   b  when decisions are not strictly ordered    Myopic Value of Information in Influence Diagrams  The value of information technique is illustrated on the influence diagram in Figure   through Figures  a and  b  The strong junction tree in Figure  a can also be used to solve an influence diagram with h observed before deciding on D   The difference between the two scenaria is reflected in the control structure for the collect operation rather than in the junction tree  A strong junction tree also being able to handle the situation where h is observed before deciding on D  is shown in Figure  b       NOTATION  In Figure     we present an extended version of the in fluence diagram from  Jensen et al          The origi nal influence diagram notation has been extended with triangular nodes  observation nodes  An observation node designates that the chance node associated with it will be observed within some interval of information sets   g       would have the observation interval   h  Is         ALTERNATIVE METHODS  There are other methods for calculating the value of information in influence diagrams  These can be sep arated into multiple model methods and single model methods  The value of information in influence diagrams can be viewed as the difference in expected utility between a set of influence diagrams each implementing a specific scenario of the desired observation decision sequences  In that view Ezawa        creates and solves multi ple models for calculating the value of information in influence diagrams  However  as the construction of strong junction trees is a complex task it is preferable to reduce the number of different junction trees  Also  to cover all desired observation decision sequences the decision analyst may be facing a considerable task in constructing the needed influence dia grams   Instead  the different decision models in Figure   and Figure   can be combined into a single influence dia gram which gives us the power to calculate whether or not to observe B  Such a model is shown in Figure      Figure     Influence diagram from  Jensen et al         with extended notation  Though there may not be any computational difficul ties associated with observing variables at an earlier time than modeled  there may be some conceptual problems  It does not make sense to observe  say  the state of a fungus attack on your crop in May before deciding whether or not to apply fungicide in April  In other words  We cannot observe a variable prior to making a decision that influences it  Hence  a variable is modeled in the influence dia gram as belonging to the last information set possible  and the observation node is associated with a  lower boundary  for the observation  For node c in Figure    the lower boundary is     yielding the observation in terval to be          whereas the lower boundary for node j is h and hence the observation interval for j is          If associated with an observation node  node  Figure     General model capable of handling the sce narios of Figures   and     The resulting model consists of the original model without observation on B  f ro m Figure    with an ad ditional two nodes  a decision node  Do and the chance node B   Do will consist of the decisions  B  and     B  and the  observed node  B  will have the same states as its un observed counterpart  B  plus an additional state   No observation   If the optimal decision  d   is  B   then B   is observed and set to the true state of B  if the op timal decision is    B   B  is set to  No observation   The probability table for B is equal to the one specified in Figures   and   and the behavior of B  is specified        Dittmer and Jensen  as B  B      No observation     B otherwise  for  d         B   This type of modeling cannot be called neither simple nor intuitive  Furthermore  as can be seen from Figure     the junction tree for the general model in Figure    is larger than the junction tree produced by expansion  Figure  c    Figure     Strong junction tree constructed from the general model of Figure     It is also worth noting that the model in Figure    and its corresponding junction tree in Figure    are made for the case where B is either unobserved or ob served before D   The junction tree in Figure  c is capable of calculating the expected utility for the de cision problem with B belonging to any information set  Should the model in Figure    be extended to the same flexibility  we are facing a larger and consider ably less intuitive model with little resemblance to the original decision problem     CONCLUSION  For specific influence diagrams  such as scenarios with non intervening decisions  we have presented a simple method for calculating the value of information  This method is simple in construction and cheap in terms of time and space requirements  but is restricted in the structure of the influence diagram  It is based on methods developed by  Cooper        and   Jensen   Jiangmin L          For certain  well defined tasks there may be advantages in using this method but in the general case we propose to use the method pre sented for influence diagrams with sequences of inter vening decisions  In strong junction trees constructed for decision prob lems formulated as general influence diagrams we are able to calculate the value of information for a given chance node  that is  the gain in expected utility from observing variable X before making a decision In other words  we can calculate the differ Di  ence in expected utility between models that differ in observation decision sequence  using the same junction tree structure with only a number of tables expanded but not recalculated  We find this method far more in tuitive than modeling all possible outcomes in a gen eral influence diagram as the structure of the model  will not change even when chance nodes  within lim its  are observed prior to the latest possible observa tion time  Also  modeling observations as intervening decisions may seem unappealing to decision analysts  In addition to this  we experienced that the junction trees produced from the general models are larger than those produced by table expansion  Using our method is not for free as in its worst case  modeling a chance node as never observed and ob serving it before the first decision D   all tables in the junction tree will be expanded  assuming that the de cisions are strictly ordered   This means that with a states in the node in question  the resulting junction tree will be almost a  times larger than the original junction tree  This corresponds to performing a  prop agations in the strong junction tree and the gain is therefore minimal  However  the method presented will only expand the tables needed  that is  only part of the junction tree becomes larger  by a factor of a    which consequently reduces the number of operations performed during a propagation  Also  clever use of the control struc tures associated with the strong junction tree will pre vent excess operations in the expanded tables after marginalization of the node in question  Still  if for example r is very large and if all A E r are placed in In  we may very well face an intractable problem as we expand the cliques beyond the capacity of computers  Topics for further research include the possibility for utilizing independence assumptions in order to further reduce complexity  
  When using Bayesian networks for modelling the behavior of man made machinery  it usu ally happens that a large part of the model is deterministic  For such Bayesian networks the deterministic part of the model can be represented as a Boolean function  and a cen tral part of belief updating reduces to the task of calculating the number of satisfying configurations in a Boolean function  In this paper we explore how advances in the calcu lation of Boolean functions can be adopted for belief updating  in particular within the context of troubleshooting  We present ex perimental results indicating a substantial speed up compared to traditional junction tree propagation     INTRODUCTION  When building a Bayesian network model it frequently happens that a large part of the model is determinis tic  This happens particularly when modelling the be havior of man made machinery  Then the situation is that we have a deterministic kernel with surrounding chance variables  and it seems excessive to use stan dard junction tree algorithms for belief updating  First of all  the calculations in the deterministic kernel are integer calculations and double precision calculations are unnecessary complex  However  there may be room for further improvements  If the deterministic part of the model is represented as a Boolean function  we may exploit contemporary advances in calculation of Boolean functions  A major advance in Boolean calculation is Binary Decision Diagrams  particularly Reduced Ordered Bi nary Decision Diagrams  ROBDDs Bryant         An ROBDD is a DAG representation of a Boolean func tion  The representation is tailored for fast calculation  Uffe Kjcerulff  of values  but the representation can also be used for fast calculation of the number of satisfying configura tions given an instantiation of a subset of the variables  To be more precise  let B X  be a Boolean function over the Boolean variables X  and let Y  X with X Y  Define Cards      on a configuration iJ Z of y as the number of configurations z over Z such that B   j  z  true      It turns out that given iJ an ROBDD representation of B can be constructed such that Cards can be calculated in time linear in the num ber of nodes in the ROBDD  However  the number of nodes in an ROBDD may be exponential in the num ber of variables in the domain of the Boolean function        In this paper we exploit the ROBDD representation for propagation through a Boolean kernel in a Bayesian network  and we illustrate that a central part of this propagation is to calculate Cards  i    We use the tech nique on models for troubleshooting  These models are particularly well suited for ROBDD calculation as the size of the ROBDD is quadratic in the size of the domain  In section   we illustrate the use of Cards for prob  ability updating in Bayesian networks  Section   is a brief introduction to ROBDDs and in section   we show how to calculate Cards in an ROBDD  Section   introduces the troubleshooting task and the type of Bayesian network models used  In section   the de terministic kernel of these models is represented as an ROBDD and it is shown that the size of this represen tation is quadratic in the number of Boolean variables  In section   we outline the propagation algorithms for various troubleshooting tasks  and in section   we re port on empirical results indicating a substantial speed up compared to traditional junction tree propagation     TWO MOTIVATING EXAMPLES  To illustrate the special considerations in connection with Boolean kernels we shall treat a couple of exam         UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS          ples  First consider the situation in Figure     BOOLEAN FUNCTIONS AND ROBDDS  This section is a survey of classical logic in the context of binary decision diagrams  Figure    The Boolean variable A has a parent net work of proper chance variables and a child network representing a Boolean function B  For the situation in Figure   we have  U P  U         WUVU A     Q  W A I t B  V A    where   l      Lvu A  B  V A  is a normalization con stant  Assume we have evidence e ew u ev   where ev is a configuration y of the variables Y  V  then     P A e     l    l  L L w w  Q W ew A  L B Z y A  z  If we extend the example s t  a Boolean variable C E V has a child network R  T  C  of proper chance variables  we get   the normalization constant is omitted    P  U    Q  W A B  V A R  T C  Assume we have evidence e   ew u ev u er  where ev is a configuration y of the variables Y  V  If er is empty then R does not contribute  and the calculations are as for Figure    If not  we have   L L  L w  Q W ew A     B  Z y  A  C   Z  C  L     T  w   L L  B  Z y A C     y   Z     T  B  Z y A  C  n    Z    L Q W ew A   R  T e  C  n       T   w     CardB y A  C   y      Card  Y A  C   n   R  T er  C    R  T er  C     y    n    All operators in propositional logic can be expressed using only this operator and this can be done s t  tests are only performed on unnegated variables  Definition    An If then else Normal Form  INF  is a Boolean function built entirely from the if then else operator and the constants   and   s t  all tests are performed only on variables   B  R  T er C   y    L L  Let X     Y   Y  denote the if then else operator  Then X     Y    Y  is true if either X and Y  are true or X is false and Y  is true  the variable X is said to be the test expression  More formally we have   Consider the Boolean function B and let B X H    denote the Boolean function produced by substituting   for X in B  The Shannon expansion of B w r t  X is defined as   R  T e   C   L Q  W ew A      A truth assignment to a Boolean function B is the same as fixing a set of variables in the domain of B  i e   if X is a Boolean variable in the domain of B  then X can be assigned either   or     denoted  X H    and  X H     respectively    A Boolean function is said to be a tautology if it yields true for all truth assignments  and it is satisfiable if it yields true for at least one truth assignment   Q W ew A CardB  y A    As the example illustrates  an efficient procedure for calculating CardB is central for probability updating   P A e     The classical calculus for dealing with truth assign ments consists of Boolean variables  the constants true     and false     and the operators     conjunction   V  disjunction       negation       implication  and        bi implication   A combination of these entities form a Boolean function and the set of all Boolean functions is known as propositional logic      Again  calculation of Card  is part of belief updating       X  t B      H      B  X H     From the Shannon expansion we get that any Boolean function can be expressed in INF by iteratively using the above substitution scheme on B  By applying the Shannon expansion to a Boolean func tion B w r t  an ordering of all the variables in the do main of B we get a set of if then else expressions which can be represented as a binary decision tree  The de cision tree may contain identical substructures and by  collapsing  such substructures we get a binary deci sion diagram   BDD  which is a directed acyclic graph  The ordering of the variables  corresponding to the order in which the Shannon expansion is performed         UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS  is encoded in the BDD hence  we say that the BDD is an ordered binary decision diagram  OBDD   the variables occur in the same order on all paths from the root  If all redundant tests are removed in an OBDD it is said to be reduced and we have a reduced ordered binary decision diagram  ROBDD   Definition    A reduced ordered binary decision di agram  ROBDD  is a rooted  directed acyclic graph with         ROBDD  The algorithm basically propagates a num ber    n   where n is the number of distinct variables in the corresponding Boolean function  from the root of the ROBDD to the terminal node  The value sent from a node  including the root  to one of its children is the value associated with that node divided by    The value associated with a node  except the root  is the sum of the values sent from its parents  see Fig ure      one or two terminal nodes labeled   and   respec tively  a set of non terminal nodes of out degree two with one outgoing arc labeled   and the other    a variable name attached to each non terminal node s t  on all paths from the root to the ter minal nodes the variables respect a given linear ordering  no two nodes have isomorphic subgraphs   We will use Eo to denote the set of   arcs  drawn as dashed arcs  and    to denote the set of l ares  drawn as solid arcs   Theorem     Bryant          For any Boolean function f      l n           there is exactly one ROBDD B with variables X    X      Xn s t  B X  H b   X  H b        Xn H bnJ f  b  b       bn    i  b  b       bn  E    l n    Figure    There are   satisfying configurations for the Boolean function  Exactly one variable among A    A    A   is true  represented by this ROBDD  Definition    Let B    U   be an ROBDD  Propa gation in B is the computation of v  u   where u E U and v   U     lR is defined as      From Theorem   we have that in order to calculate the number of satisfying configurations in a Boolean function B we can produce an ROBDD equivalent to B and then count in this structure  In the remainder of this paper we assume that an ROBDD has exactly one terminal node labeled    as we are only interested in the number of satisfying configu rations  in this situation we allow non terminal nodes with out degree one  Additionally  we will use the term  nodes  in the context of ROBDDs and  variables  when referring to a Boolean function or a Bayesian network BN   nodes and variables will be denoted with lower case letters and upper case letters  respectively  the nodes representing a variable Xi will each be de noted Xi if this does not cause any confusion            CALCULATION OF CARDB USING ROBDDS  Given an ROBDD representation of a Boolean func tion B  the number of satisfying configurations can be calculated in time linear in the number of nodes in the      v  r    n   where r is the root in B and n is the number of distinct variables in B  LpEnd  v p    where nu repre iu E U  r   v  u        sents the set of parents for u in B   So  in order to determine Cards for some Boolean function B  U  we only need one propagation in the corresponding ROBDD since Cards v  l   In case evidence y has been received on the variables Y  U we simply modify the algorithm s t  configurations  in consistent with y  does not contribute to the propaga tion  i e   given a configuration y the function v  u y is defined as      iu E U  r    v  u y       LvEna v p y      where nR    p E nul p  j  Yl or  y p    i and  p  u  E i    y p  is the state ofp E Y under y and v  r   n  n being the number of distinct variables in B including those on which evidence has been received  In partic ular we have that Cards  i i    v    y  Notice  that the structure of the ROBDD is not changed when evidence is received     The size of the ROBDD has a significant impact on the performance of the algorithm and the problem of        UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       identifying a minimal sized ROBDD is NP complete  Thus  in the remainder of this paper we shall mainly focus on troubleshooting models as it turns out that the structure of such a model ensures that the size of the corresponding ROBDD is at most quadratic in the size of the domain     TROUBLESHOOTING  Definition    A troubleshooting model is a con nected BN T     U  Us U Uc U UA    P   where      The set Us contains a distinct variable   with no successors  and for each    E Us     there exists a directed path from    to    For each variable C EUc there exists an    EUs s t  C Ens  and nc       When troubleshooting a device which is not working properly we wish to determine the cause of the problem or find an action sequence repairing the device  At any time during the process there may be numerous differ ent operations that can be performed e g  a component can be repaired replaced or the status of a component can be investigated  Because such operations can be expensive and may not result in a functioning device  it is expedient to determine a sequence of operations that minimizes the expected cost and  eventually  re pairs the device   Breese and Heckerman        presents a method to myopicly determine such a sequence  The method as sumes a BN representing the device in question  and the BN is assumed to satisfy the following properties     There is only one problem defining variable in the BN and this variable represents the functional sta tus of the device      The device is initially faulty     Exactly one component is malfunctioning causing  the device to be faulty  single fault   A central task of troubleshooting  within the frame work of  Breese and Heckerman         is the calcula tion of Pi  P  C i  faulty e  which denotes the prob ability that component ci is the cause of the problem given evidence e  So we are looking for a way to exploit the logical structure of the model when calculating the probabilities Pi As such a scheme is strongly depen dent on the structure of the troubleshooting model we give a syntactical definition of this concept  The def inition is based on BNs  a BN consists of a directed acyclic graph G   U    and a joint probability dis tribution P U   where U is a set of variables and  is a set of edges connecting the variables in U  we use sp X  to denote the state space for a variable X E U  The joint probability distribution P U  factorizes over U s t     P U            For each variable A EUA there does not exist an X EU s t  A E nx  sp X    ok  ok   VX EUs U Uc  For each X E Us  P xly     or P xly  sp X  and Vy E sp nx          Vx E  The variable   is termed the problem defining variable and the variables Us are termed system variables  The variables Uc  termed cause variables  represent the set of components which can be repaired  and the vari ables in UA  termed action variables  represent user performable operations such as observations and sys tem repairing actions  notice that UA is not part of the actual system specification  In the remainder of this paper we shall extend the single fault assump tion to include the system variables also  That is  if a system variable  i is faulty  then there exists ex actly one variable X E ns  which is faulty also  see  Skaanning et al         for further discussion of this extension and how the single fault assumption can be enforced using so called  constraint variables     Figure   depicts a troubleshooting model  where A is an action variable and   represents the problem defin ing variable  The variables      z    and    repre sent subsystems  which should be read as  the sys tem   can be decomposed into two subsystems    and  z  and subsystem    can be decomposed into    and     Component C   can cause either    or    to fail  whereas C z can cause either  z or    to fail  neither C   nor C z can cause two subsystems to fail simultane ously   Notice that A is not part of the actual system model   IJ P XInx    XEU  where nx is the parents of X in G  The set of con ditional probability distributions factorizing P U  ac cording to G is denoted P   Figure    A troubleshooting model with five system variables  two cause variables and one action variable    UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            From assumption     and     we have that   P C   y  e   P C    J  Cz  n          Cm  n  e  m   P C   y  P Ci n  i    tB C    y  Cz n         Cm  n  Us  e   II      L      Us  II P Ci     i    n    tCard s  C    y  e     where B Us  Uc  is a Boolean function  specified in the following section  and J t is a normalization constant  Now  P C  el   P C   e  P e  and P e  is given by   m      IJ P Cd   B C      Cm  S  S          Sn  el u  i    In the remainder of this paper we omit the normaliza tion constant       m    P C   y   P e      and only one  of its subsystems  Sc  is faulty  if a cause is not present we can not say anything about its subsystems   M says that there can be either zero or at most one cause present  consistent with the system state   B U  is the Boolean function representing the system as a whole  Note that   ROBDDS AS TROUBLESHOOTING MODELS    The Boolean function is a list of expressions for local constraints and it can therefore be built in an incremental fashion  The Boolean function can easily be modified to represent any logical relation between the compo nents  The expression ensures the single fault assump tion based on the structure of the model  i e   it is not necessary to introduce  constraint variables     Example    The Boolean function representing the troubleshooting model depicted in Figure   is specified by B     SA S  l l Sz   V  SA        Sz   B A  S A S  l l S    V  S As S     In what follows we shall assume single fault and use the truth values   and   to denote the state of a com ponent subsystem    indicates a fault    B A Cz      Sz Zl S      A  SA C  IZl Cz   V  SAC ACz    Now  let nsi be the subsystems which immediately compose Si E Us and let Sc  Us be the subsys tems that component C E Uc can cause to fail  Sc is the immediate successors of C  The Boolean func tion representing the logical kernel of a troubleshoot ing model TS    Us UUc UUA     P  is then given by B U   Us UUc    Given the ordering S  S   Sz  S   S   C   C   the ROBDD corresponding to B is depicted in Figure    Note that all paths from the root S to the terminal node are consistent with the ordering above   D  F T   G C        TA       s  v rA  S EnT  Q  T  C        s   S EnT  TESc  M           f      f  c  sA  v  sA  CEUc  B U    F T  A  TEUs     CEUc  c           G C  AM   CEUc  where     xi denotes an exclusive or between the variables  X           Xn   F T  specifies that if the sys tem Tis malfunctioning then one  and only  of its sub systems is faulty  and if the system is functioning prop erly then all of its subsystems are functioning properly also  G C  states that if a cause is present then one  Figure    An ROBDD representation of the trou bleshooting model depicted in Figure     The ROBDD was generated by the software tool http   fwww cs auc dk behrmann iben    iben         UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       Now  as indicated in Section    the size of the ROBDD is dependent on the ordering of the variables  So we are looking for a general  rule of ordering  producing ROBDDs of  small  size  Consider an ordering of the variables where each sys tem variable occurs before all the variables repre senting its subsystems  and where all the cause vari ables occur last in the ordering  By constructing the ROBDD according to this ordering we get the node representing the problem defining variable as root and the nodes representing the cause variables at the bot tom  see Figure     Moreover  we get an upper bound on the size of the ROBDD as stated in the following theorem  note that the action variables are not part of the logical kernel  Theorem    Let TS   U  UAUUsUUc    P  be a troubleshooting model  Then the size of the ROBDD  representing the Boolean function B Us U Uc   is O IUsi   Ucl    if the ordering a  UsUUc H IUsUUcl satisfies      VX E Us  a X    a Y  for each Y E nx  VZ E Uc there does not exist an X a Z    a X    E  Us s t   Proof  Assume an indexing of the layers in the ROBDD s t  the layers containing the root node and the terminal node have index   and IUs U Ucl      re spectively  a layer is the set of nodes representing a distinct variable  Now  consider the layers consisting of system nodes but no cause nodes  The number of nodes in the i th layer either equals the number of nodes in the i th     layer or it has exactly one more node than the i th    layer  This is the same as saying that at most one node in the i th    layer branches in two  if two differ ent nodes in a layer branched into two we would have two distinct paths from a node at a higher level to these nodes however  this contradicts the single fault assumption due to the ordering of the nodes  Thus  the number of nodes in the layers containing system   nodes is at most L  Z     i  IUs l ls I     For the cause nodes  there can be at most one distinct path for each of their possible configurations  This means that the number of nodes in the layers contain ing cause nodes is at most IUcl  cl     Ucl   Hence  D the size of the ROBDD is O IUsl    IUcl    In the ROBDDs  we have an all false path from the root to the terminal node  Indeed the Boolean function is true when the model has no fault  However  we can force S to be true  faulty  to avoid this path      PROPAG ATION USING ROBDDS  For our context  we need to compute the number of satisfying configurations for each instantiation of the cause variables  see Section     Now  if we order the variables as described in Theorem   we get an ROBDD where the nodes representing the cause variables are the nodes closest to the terminal node  This means that after one propagation we can determine all the values needed  i e   the number of configurations con sistent with ci  J and evidence e is given by   CardB C y e    c     v   ie    L  CtECt     where Ci is the set of nodes Ci with an outgoing   arc and   li is the number of arcs on the path li from the Ci in question to the terminal node  the single fault assumption ensures that there exist exactly one path from each Ci to the terminal node which include the   arc emanating from Ci  However  this scheme does not take user performable operations  i e  UA  into account  and in the follow ing section we extend the algorithm to include such scenarios       Inserting evidence  After an action has been performed we may gain new knowledge about the system  This knowledge is incor porated into the model by instantiating the appropri ate variable  If either a system variable or a cause vari able is instantiated we can use the method described in Section    So  let A E UA be a binary variable associ ated with a proper conditional probability distribution P AISi  and assume that A  y is observed  In order to take the state of A into consideration we get   P C   y  A y   P Cl   J Cz n       Cm n  A y   P C   y  IT P Ci n  L  P A yiSd Us B C   y  Cz n        Cm  n Us   By expanding the sum in the above equation we get   L P A yiSi B Cl  y  Cz n        Cm  n Us  Us  P A yiSi y CardB C   y  Si y   P A yiSi n CardB Cl   J Si n       Thus  with one piece of evidence we can retrieve the probabilities with two propagations  However  if we have a set of actions u      UA with parents u   Us   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            we need to count the number of satisfying configura tions consistent with each configuration of U   So  by using the above approach  the number of times we need to count is exponential in the number of variables on which evidence has been received  In what follows we will consider a different algorithm  where all values can be found after one propagation  Initially we assume that evidence has been received on exactly one variable  but the algorithm can easily be generalized to any number of variables  In order to prove the soundness of the algorithm we will use the following notation  If B is an ROBDD with root r  then l     v i r   v           V     vis a directed path in B  is termed the i th layer of B  the layers l  and ln    contain the root node and the terminal node  respectively  So  given a Boolean function over the variables U    X    Xz          X n   or dered by index   the corresponding ROBDD can be   specified as B   Us   U  lk       U o   assum ing that the variable X   is represented by the layer l     Now  let f   sp W   t IR be a function where W   Xi          Xi   U  and assume that the variables are ordered by index  We define the following parti   tioning of B   Us   u    lk    w r t  f           The root part of B w r t  f is given by BT      Uf   f    where Uf    u   lk  The conditioning part of B w r t  f is given by lk  Be   U      where U    ul i  The terminal part of B w r t  f is given by Bt      U     where U   u  i   lk   For ease of exposition  we shall in the remainder of this section assume that no evidence has been received on any variable in Us UUc  the results presented can easily be generalized to this situation also  Algorithm    Let B   U   U  li     U o  be an ROBDD corresponding to a Boolean function over the variables U    X    Xz          Xn   and assume that the variables are ordered by index  Let f   sp W   t IR be a function with W  U and let Q  W  Xj   where X i E W is the variable with highest index     i  Propagate from the root to the terminal nodes in the root part of B  ii  Use the values obtained in step  i  to perform a propagation in the conditioning part of B  i  e    for each q E sp  Q    a  Propagate to layer li  b  If there exists an arc  p  u  E Ci from a node p E lj to a node u E li    add the value to the value ofu   c ii X   i v p q   iii  Use the values obtained in step  ii  to propagate in st   Note  that the number of variables in the domain off determines the number of iterations performed by the algorithm  In particular  if IWI     we only need one iteration  Theorem    Let B    U   U   li       Uo  be an ROBDD and let f   sp W   t IR be a function where W  U  If Algorithm   is invoked on B  then      v l      L f w Cards w   wEsp W   Proof  Let Q  W  Xj   where X i E W is the variable i with highest index  Let q E sp  Q  and let nq       p E nuiP f   W or  p  u  E      Then  v u E li  we have      LqEsp Q   v u   LqEsp Q    L bE      pEn i b l v p qf q  bl      L bE O l  pEn l bl v p   q b f q  bl       LwEsp W   L vEn v p wf wl    f     LwEsp Wl w LvEn v p w   L f w v u w wEsp W        t     Let u E lt  for l   j      Suppose that  v p E lv p    LwEsp W  f w v P lw  Then  v p  LvEnu LwEsp W  f w v p w   v u  LvEnu        In particular we have that for l  n       v      LwEsp W  f w  LvEnu v p w    L f w Card  w  wEsp W  Thereby completing the proof   D  By performing induction in the number of operations the algorithm can easily be extended to handle multi ple functions  assuming that the variables in the do main of the functions do not overlap  the variables in the domain of two functions f and g are said to over lap w r t  the ordering a if a Xd   a X k     a Xj    where xk is a variable in the domain of g  and xi and Xi are the variables in the domain of f with lowest and highest index  respectively  If the variables of two functions overlap we can multiply these functions and consider the resulting function         UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       Example    Consider the troubleshooting model de picted in Figure    and assume that action A E UA is associated with the conditional probability distribu tion specified in Table    nA     z        B   B   C                    Table    The conditional probability function P AI z       Sz Sz                                        The ROBDD corresponding to this specification is de picted in Figure    In the naive approach  if A   y is observed  we perform three propagations to the termi nal node  one propagation for each configuration of  z and    except for   z            due to the single fault assumption   The resulting counts are weighted with the appropriate values and then added  see equa tion                                                        When using algorithm   we start off by propagating to the layer l   the nodes representing  z   after propa gation  each node in l  is associated with     We then perform two propagations to the layer ls  the nodes representing      each propagation is conditioned on the state of  z  i e     and    respectively  After each propagation  the resulting value is multiplied with the appropriate value from the conditional probability ta ble and then added to the value associated with its child  So  the final value can be found with less than two full propagations  see Figure     note that we only D perform one propagation in W and in Bt  Step  ii  of Algorithm   can be optimized by start ing the iteration with the variable with highest in dex  and then iterate in reverse order of their in dex  That is  when iterating over the variables  X   Xz          Xt    Xt  we can start off by propagat ing to the layer containing Xt  for some configuration of  X   Xz          Xt     The values associated with the nodes Xt   can then be used when propagating from the nodes Xt  for each instance of Xt  The same ap plies when considering variables of lower index  i e   we can reuse previous computations  For instance  in Figure   we can use the value from the first iteration when computing the value        associated with c   consistent with   z                        RESULTS  We have measured the performance of the ROBDD algorithm by comparing it to the Shafer Shenoy algo rithm  Shafer and Shenoy        and the Hugin algo rithm  Jensen et al         w r t  the number of opera tions performed during inference  the number of opera               B                                              r  a       Q                                                 i            bl  Figure    Figure  a  depicts the ROBDD after propa gation w r t  the configuration   z               Fig ure  b  depicts the ROBDD after the full propagation  no propagation is performed w r t   Sz          due to the single fault assumption        tions refers to the number of additions  multiplications and divisions  The tests were performed on     randomly generated troubleshooting models  see Definition    which dif fered in the number of system variables  cause vari ables and action variables  the total number of vari ables varied from    to     and for a fixed set of vari ables    different troubleshooting models were gener ated  As the single fault assumption is not ensured in the troubleshooting models we augmented these mod els with constraint variables when using the Hugin al gorithm and the Shafer Shenoy algorithm  the single fault assumption is naturally ensured in the ROBDD architecture   Finally  evidence were inserted on the problem defining variable and on the constraint vari ables  Figure   show plots of the number of operations per formed as a function of the number of variables in the models  Note that we use a logarithmic scale on the y axis and that the numbers on the x axis do not rep resent the actual number of variables in the models  The plots show that  w r t  the number of operations  propagation using ROBDDs is considerably more ef ficient than both Shafer Shenoy and Hugin propaga tion  Moreover  as indicated in Section    the tradi tional tradeoff between time and space is less apparent in the ROBDD architecture  as the space complexity is O IUcl    IUsl     It should be noted that the tests were designed to        UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS                  I       ll  I    I  I  I  I  I     I  I       K         I                         I    Variable       Variable Sluorer Sheuoy  Figure    A plot of the number of operations per formed by Hugin  Shafer Shenoy and ROBDD prop agation as a function of the number of variables in randomly generated troubleshooting models  logarith mic scale   compare ROBDD propagation with Shafer Shenoy and Hugin propagation  and they should not be seen as a comparison of Shafer Shenoy propagation and Hugin propagation  In particular  we have only considered troubleshooting models and not Bayesian networks in general  The efficiency of the ROBDD architecture is partly based on the single fault assumption  However  this assumption can also be exploited in certain trou bleshooting models by compiling the original model TS   Us UUc UUA    P  into a secondary Bayesian network BN   UA U CU    S      P    where Cis a variable having a state for each cause variable in the original model together with a state representing the situation where no fault is present  S is a problem defining variable having Cas parent  and UA is the set of action variables in the original model each having C as parent  We have compared the ROBDD architec ture with this approach using the randomly generated troubleshooting models from the previous tests  see Figure        By using this secondary representation the speed up is less apparent  However  if we allow multiple faults then this representation can not be used  Moreover  a troubleshooting model allowing multiple faults will in general not be simpler than a model with no con straints on the number of faults  In the case of ROB DDs  assume that the single fault assumption still ap plies to the system variables and consider the case where exactly m components can fail simultaneously  m is generally  small    In this situation the number of nodes in the layers containing system nodes does not change but the number of nodes in the layers con taining cause nodes do  there can be a distinct path for each configuration of the cause nodes so the num   Figure    A plot of the number of operations per formed by ROBDD propagation and Hugin propaga tion with a single cause node  ber of nodes in the layers containing cause nodes is at most IUcl l    Hence the size of the ROBBD is O IUsl    IUcl l     note that in an ROBDD there does not exist two nodes having isomorphic subgraphs so the size of the ROBDD is usually much smaller  Now  as the complexity of propagation in an ROBDD is linear in its size  the maximum number of operations performed for m     increases by a factor of n l   with m faults the maximum number of operations increases i  This corresponds to adding a by a factor of constant value to the ROBDD plots in Figure   since we use a logarithmic scale on the y axis   n    Furthermore  if we redefine the m faults assump tion to cover at most m faults then the number of nodes in the layers containing cause nodes is at most IUcl Ll euicl   Again  it should be noticed that the actual number of nodes is usually significantly smaller as isomorphic subgraphs are collapsed  In case m faults is extended to include system vari ables also  it can be shown that the variables can be ordered s t  the number of nodes in the layers contain ing system nodes is exponential in m but quadratic in the number of system variables if m  maxsEUs Ins   see Figure     Finally  as the single fault assumption no longer ap plies  the number of configurations consistent with Ct  y and evidence y is given by  Cards Ct  y   y      v c     L    iy  Ci ECi li E Ci  L  where Ct is the set of nodes Ct with an outgoing   arc  Lt is the set of distinct paths from the Ct in question to the terminal node and   lt is the number of arcs on such a path  Having multiple faults also supports other frame    UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            be ordered s t  the size of the ROBDD is quadratic in the size of the domain           so       Numb rofy  emvuiableinlhed omaoll  Figure    The number of nodes in the layers containing system nodes as a function of the number of system variables  works like  de Kleer and Williams        and  Williams and Nayak         For instance  in cir cuit diagnosis  de Kleer and Williams        uses a logical model of the system to be diagnosed and determines the next action based on expected Shan non entropy  To calculate the expected Shannon entropy they require the conditional probability of a set of failed components  termed a candidate in  de Kleer and Williams         given some observa tion  As their framework does not yield an easy way to obtain this probability they use an approximation  In our framework the logical circuits can be represented as ROBDDs which makes the necessary probabilities easily available  So far we have not established a practical upper bound on the size of ROBDDs with m faults  but all the examples we have worked with until now have been of a  small  size  Moreover  several heuristic methods have been devised for finding a good order ing of the variables  see e g   Malik et al         and  Fujita et al              CONCLUSION  When modelling the behavior of man made machinery using Bayesian networks it frequently happens that a large part of the model is deterministic  In this pa per we have reduced the task of belief updating in the deterministic part of such models to the task of calculating the number of configurations satisfying a Boolean function  In particular  we have exploited that a Boolean function can be represented by an ROBDD  and in this particular framework the number of satisfying configurations can be calculated in time linear in the size of the ROBDD  The use of ROBDDs for belief updating was exempli fied in the context of troubleshooting  which is partic ular well suited as it was shown that the variables can  The performance of ROBDD propagation was com pared with Shafer Shenoy and Hugin propagation us ing randomly generated troubleshooting models  The results showed a substantial speed up and it was argued that the single fault assumption  underlying troubleshooting models  can be weakened without sig nificantly affecting the performance of the algorithm in case the number of faults is  small    
  This paper deals with the representation and solution of asymmetric Bayesian decision problems  We present a formal framework  termed asymmetric influence diagrams  that is based on the influence diagram and al lows an efficient representation of asymmet ric decision problems  As opposed to exist ing frameworks  the asymmetric influence di agram primarily encodes asymmetry at the qualitative level and it can therefore be read directly from the model  We give an algorithm for solving asymmetric influence diagrams  The algorithm initially decomposes the asymmetric decision problem into a structure of symmetric subproblems organized as a tree  A solution to the de cision problem can then be found by propa gating from the leaves towards the root using existing evaluation methods to solve the sub problems      INTRODUCTION  The power of an influence diagram  both as an analysis tool and a communication tool  lies in its ability to con cisely and precisely describe the structure of a decision problem Smith et al          However  influence dia grams can not efficiently represent the so called asym metric decision problems  decision problems are usu ally asymmetric in the sense that the set of possible outcomes of a chance variable may vary depending on the conditioning states  and the set of legitimate deci sion options of a decision variable may vary depending on the different information states  Qi et al          Various frameworks have been proposed as alterna tives to the influence diagram when dealing with asym metric decision problems   Covaliu and Oliver         extends the influence diagram with another diagram  termed a sequential decision diagram  which describes the asymmetric structure of the problem as comple mentary to the influence diagram which is used for specifying the probability model   Smith et al         introduces the notion of distribution trees within the framework of influence diagrams  The use of distribu tion trees allows the possible outcomes of an observa tion to be specified  as well as the legitimate decision options of a decision variable  However  as the distri bution trees are not part of the influence diagram  the structure of the decision problem can not be deduced directly from the model  Moreover  the sequence of decisions and observations is predetermined  i e   pre vious observations and decisions can not influence the temporal order of future observations and decisions  Finally  distribution trees have a tendency of creating large conditionals during the evaluation since they en code both numeric information and information about asymmetry  To overcome this problem  Shenoy        presents the asymmetric valuation network as an ex tension of the valuation network for modelling sym metric decision problems Shenoy         The asym metric valuation network uses indicator functions to encode asymmetry  thereby separating it from the numeric information  However  asymmetry is still not represented directly in the model and  as in  Smith et al          the sequence of observations and decisions is predetermined   In this paper we present the asymmetric influ ence diagram which is a framework for represent ing asymmetric decision problems  The asymmet ric influence diagram is based on the partial influ ence diagram Nielsen and Jensen      b   and encodes structural asymmetry at the qualitative level  struc tural asymmetry has to do with the occurrence of vari ables in different scenarios as opposed to functional asymmetry which has to do with the possible out Further details and comparisons of these methods can be found in  Bielza and Shenoy           UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       comes decision options of the variables  As a mod elling language  the syntactical rules of the asymmet ric influence diagram allow decision problems to be described in an easy and concise manner  Further more  its semantic specification supports an efficient evaluation algorithm  An outline of this paper is as follows  In Section   we describe the partial influence diagram  together with the terms and notation used throughout this pa per  In Section   we formally introduce the asym metric influence diagram and illustrate this framework by modelling a highly asymmetric decision problem termed  the dating problem   Finally  in Section   we present an algorithm for solving asymmetric influence diagrams     PRELIMINARIES  The partial influence diagram  PID  was defined in  Nielsen and Jensen      b  as an influence diagram  ID  with only a partial temporal order over the deci sion nodes  That is  a PID is a directed acyclic graph I    U     where the nodes U can be partitioned into three disjoint subsets  chance nodes Uc  decision nodes U  and value nodes Uv  The chance nodes  drawn as circles  correspond to chance variables  and represent events which are not under the direct control of the de cision maker  The decision nodes  drawn as squares  correspond to decision variables and represent actions under the direct control of the decision maker  We will use the concept of node and variable interchangeably if this does not introduce any inconsistency  and we assume that no barren nodes are specified by the PID since they have no impact on the decisions   With each chance variable and decision variable X we associate a finite discrete state space W x which de notes the set of possible outcomes decision options for X  For a set U  of variables we define the state space as Wu    x WxiXE U    The set of value nodes  drawn as diamonds  defines a set of utility potentials with the restriction that value nodes have no descendants  Each utility potential in dicates the local utility for a given configuration of the variables in its domain  the domain of a utility poten tialljJx  for a value nodeX  is denoted dom ljJx   nx  where nx is the immediate predecessors of X  The to tal utility is the sum or the product of the local utilities  see  Tatman and Shachter          in the remainder of this paper we assume that the total utility is the sum of the local utilities    A chance node or a decision node is said to be barren if it does not precede any other node  or if all its descendants are barren        The uncertainty associated with a variable X E Uc is represented by a conditional probability potential  Px   P XInx    W xunx   t         The domain of a conditional probability potential  Px is denoted dom  J  xl   X unx  The arcs in a PID can be partitioned into three dis joint subsets  corresponding to the type of node they go into  Arcs into value nodes represent functional dependencies by indicating the domain of the associ ated utility potential  Arcs into chance nodes  denoted dependency arcs  represent probabilistic dependencies  whereas arcs into decision nodes  denoted informa tional arcs  imply information precedence  if DE U  and  X  D  E  then the state of X is known when decision D is made  The set of informational arcs induces a partial order    on Uc U U  as defined by the transitive closure of the following relation    Y   Di  if  Y Dd is a directed arc in I  DiE Uo       Di    Y  if  Di X  Xz         Xm Y  is a directed path in I  Y E Uc UU  and DiE Uo      Di    A  if A     Dj for all Di E U   AE Uc and DiE Uo      Di    A  if A     Di and   Di E U  s t  Di    Di and A   Di  AE Uc and DiE Uo    In what follows we say that two different nodes X and Y are incompatible if X     Y and Y     X  We define a realization of a PID I as an attachment of potentials to the appropriate variables in I  i e   the chance nodes are associated with conditional probabil ity potentials and the value nodes are associated with utility potentials  So  a realization specifies the quan titative part of the model whereas the PID constitutes the qualitative part  Evaluating a PID amounts to computing a strategy for the decisions involved  A strategy can be seen as a prescription of responses to earlier observations and decisions  and it is usually performed according to the maximum expected utility principle  the max imum expected utility principle states that we shall always choose a decision option that maximizes the expected utility  However  the strategy for a deci sion variable may depend on the variables observed thus  we define an admissible total order for a PID I to describe the relative temporal order of incompati ble variables  an admissible total order is a bijection      Uo UUc H              IUo U Ucl  s t  if X    Y then I  X      Y   where    is the partial order induced by I  In what follows   will be used to denote the total ordering    s t  X  Y if P   X   P   Y   Notice  that an   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            admissible total ordering of a PID I implies that I can be seen as an ID  Given an admissible total ordering    we define an admissible strategy relative to  as a set of functions          E Uo    where     is a decision function given by     and pred D     XIX  D   the index  in pred D   will be omitted if this does not introduce any confu sion   Given a realization of a PID I  we term an ad missible strategy relative to   an admissible optimal strategy relative to  if the strategy maximizes the ex pected utility for I  two admissible optimal strategies are said to be identical if they yield the same expected utility  A decision function      contained in an ad missible optimal strategy relative to    is said to be an optimal strategy for D relative to    Note that an optimal strategy for a decision variable D relative to  does not necessarily depend on all the variables observed  Hence  we say that an observed variable X is required for D w r t    if there is a realization of I s t  the optimal strategy for D relative to  is a non constant function over X  By this we mean that there exists a configuration y over dom S     X  and two states x  and xz of X s t  S   x   y      S   xz  y    Definition     A realization of a PID I is said to define a decision problem if all admissible optimal strategies for I are identical  A PID is said to define a decision problem if all its realizations define a decision problem  The above definition characterizes the class of PIDs which can be considered welldefined since the set of admissible total orderings for a PID I corresponds to the set of legal elimination sequences for I  However  it also conveys the problem of only having a partial temporal ordering of the decision variables  the rela tive temporal order of a chance variable  eliminated by summation  and a decision variable  eliminated by maximization  may vary under different admissible or derings and summation and maximization does not in general commute  So  in order to determine whether or not a PID defines a decision problem we introduce the notion of a significant chance variable   Definition    Let I be a PID and let A be a chance variable incompatible with a decision variable D in I  Then A is said to be significant for D if there is a realization and an admissible total order  for I s t        A occurs immediately before D under   The optimal strategy for D relative to  is differ ent from the one achieved by permuting A and D in    Based on the above definition we have the following theorem which characterizes the constraints necessary and sufficient for a PID to define a decision problem   Theorem     Nielsen and Jensen      b    The PID I defines a decision problem if and only if for each decision variable D there does not exist a chance variable A significant for D  See  Nielsen and Jensen      b  for a structural char acterization of the chance variables being significant for a given decision variable     ASYMMETRIC INFLUENCE DIAGRAMS   Qi et a          states that decision problems are usu ally asymmetric in the sense that the set of possible outcomes of a chance variable may vary depending on the conditioning states  and the set of legitimate decision options of a decision variable may vary de pending on the different information states  Equiva lently   Bielza and Shenoy        characterizes a deci sion problem as being asymmetric if  in its decision tree representation  the number of scenarios is less than the cardinality of the Cartesian product of the state spaces of all chance and decision variables  However  both of these characterizations fail to recognize deci sion problems in which the relative temporal order of two variables vary w r t  to previous observations and decisions  this is for example very common for trou bleshooting problems  Thus  we define an asymmetric decision problem as follows   Definition    A decision problem is said to be asym metric if  in its decision tree representation  either    the number of scenarios is less than the cardinality of the Cartesian product of the state spaces of all chance and decision variables or    there exists two scenarios in which the relative temporal order of two variables differ   In order to deal with such asymmetric decision prob lems we introduce the asymmetric influence diagram  AID   An AID is a labeled directed graph I  U   F   where the nodes U can be partitioned into four disjoint subsets  test decision nodes  UT   action decision nodes  UA   chance nodes  Uc  and value nodes  Uv    we will sometimes omit the distinction between test decisions and action decisions by simply referring to a node in Uo   UT UUA as a decision node     The chance nodes and value nodes are similar to the chance nodes and value nodes in a PID  The deci sion nodes correspond to decision variables and rep resent actions under the direct control of the decision        UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       maker  A test decision  drawn as a triangle  is a de cision to look for more evidence  whereas an action decision  drawn as a rectangle  is a decision to change the state of the world  The arcs  in an AID can be partitioned into four dis joint subsets  An arc into a value node or a chance node is semanticly defined as in the PID framework if  in case of the latter  it does not emanate from a test decision node  Arcs into decision nodes  termed informational arcs  imply a possible information prece dence  if there is an arc from a node X to a decision node   then the state of X may be known when de cision   is made  This redefinition is needed since we deal with asymmetric decision problems  i e   the set of variables observed immediately before decision   is taken may dependent on previous decisions and observations  If there exists an arc  termed a test arc  from a test decision node   to a chance node X  then the state of   determines whether or not X is eventually observed  having an arc from a test decision node to a chance node represents a logical relation and does not imply probabilistic dependence  Note that in the trivial case  where X is observed no matter the state of    the arc     X  implies information precedence only  If there exists an arc  D       from a test decision node   to another decision node     then         implies infor mation precedence            is an informational arc  however            is termed a test arc if the state of   determines whether or not     is eventually decided upon  whether we are referring to an informational arc or a test arc is conveyed by the label associated with      in the remainder of this paper we let I denote the graph obtained from I by removing all test arcs and informational arcs  The asymmetry of a decision problem is graphically represented in the AID by a set of restriction arcs and by a set of labels  F  The set of restriction arcs  drawn as dashed arcs  is a subset of the informational arcs  A restriction arc  X     indicates that the set of legit imate decision options for   may vary depending on the state of X  in which case we say that X is restrictive w r t     or X is restricting     The set of labels  F is associated with a subset of the nodes and informa tional arcs  A label specifies under which conditions the associated node or informational arc occurs in the decision problem  The following rules informally sum marize the semantics of labels when specifying asym metry in the AID  in the remainder of this section they will be referred to as rule  i   iii   respectively  i  Let X be a node labelled with fx and let Y be the variables observed before X is observed  or decided upon   If fx is unsatisfied w r t  the state configuration Y y observed  then X is not in   eluded in the scenario  ii  Let  X     be an informational arc labeled with f X DJ and let Y be the variables observed be fore X is observed  or decided upon   If f x o  is unsatisfied w r t  the state configuration Y y observed  then  X  D  is not included in the sce nario     iii  If there exists a directed path from a node X to a node Y in I  then whenever X is not included in the scenario Y is not included in the scenario either  Based on the rules above we require that if the label of a node Z is a function of a node X  then there must exist an arc from X to Z  See Figure             fz X     fz X   Figure    There must exist a directed arc from X to Z since fz is a function of X      The dating problem  Joe has to de cide whether or not to ask a girl he has recently met on a date  If Joe decides not to ask her out he can choose either to stay at home and watch TV or visit a night club  before taking that decision Joe observes what programs will be on TV that night  The plea sure of staying at home is influenced by his liking of the program watched  whereas the pleasure of going to a night club is dependent on the comfort of going to that night club and the entrance fee  comfort is depen dent on whether Joe likes the night club and whether he meets any friends there   Example  If Joe decides to ask her out her response will depend on her feelings towards him  If she declines the date  Joe can decide to go to a night club or stay at home and watch TV  we assume that the two  staying at home scenarios  are the same  If she accepts to go on a date with him  Joe will ask her whether she wants to go to a restaurant or to the movies  The choice of movie  decided by Joe  may influence her mood which in turn may influence Joe s satisfaction concerning the evening  Similarly  the choice of menu  decided by Joe  might influence Joe s satisfaction  This decision problem is represented by the AID de picted in Figure    The variable Date  is represented as a test decision since it has no impact on the value of Accept   In the evaluation of whether or not to ask for a date  the distribution of Accept  is relevant and Accept  is therefore always part of the entire decision problem  The decision Night Club  is decided upon if Joe ini         UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       Figure    The dating problem if Date  n   Figure    An AID representing  the dating problem   tially chooses not to ask the girl for a date  the label as sociated with Night Club  specifies a logical or and is therefore satisfied by the state configuration Date  n  If Joe chooses to go to a night club the chance vari ables Meet Friends and Likes Club influence Joe s com fort which in turn influences the pleasure of going to that club  the chance variable Liking is excluded from the decision problem since Liking is only included if Club  n  rule  i    Notice that this property could also be modelled by introducing a redundant state in the variable Liking  However  having redundant states tends to obscure the asymmetric structure of the de cision problem  and is in general computationally de manding   Satisfaction which has the mutually exclusive variables Menu and Movie as predecessors  As no descendant of an excluded variable can be included  rule  iii    we would unintentionally exclude Satisfaction whenever Menu or Movie are included  This problem can be solved by duplicating Satisfaction and its descendants or by adding an extra state  no decision  to the vari ables Menu and Movie  In order to minimize redun dancy in the representation we have chosen the latter  D       THE QUALITATIVE LEVEL  Now  from rule  iii  we can infer the following syn tactical simplification  If there exists a directed path from a node X to a node Y in I  then Y  inherits  the label associated with X  i e   Y is  effectively  la beled with fx I  fv  where fx and fv are the labels explicitly associated with X and Y  respectively  This means that we need not explicitly associate Y with the label fx I  fv  see Figure  a   The set of vari ables from which a chance variable X  inherits  labels is given by dep X  Y  where Y is the set of vari ables from which there exists a directed path to X in I  to ensure consistency it should be noted that de cision nodes  value nodes and informational arcs  in herit  labels from the empty set  E g  in Figure   the variable Meet Friends is  effectively  conditioned on  Night club  y I   Accept  n V Date  n   since dep  Meet Friends  Night club      Since Date  n the informational arcs from Accept  are excluded  rule  ii   meaning that her potential re sponse is never observed  as previously mentioned  Ac cept  is still part of the decision problem as opposed to e g  Liking if Club  y  Now  as Accept  is never observed the variables only labeled by the state of Ac cept  are removed  rule  i    together with all their successors  rule  iii    The resulting decision problem is depicted in Figure    the variables Accept and Likes me  are included in the figure for the purpose of the AID being a tool for communication  If Joe on the other hand chooses to ask the girl for a date he will observe her response  Accept     If she declines the invitation he can choose either to go to a night club or stay at home  If she accepts the in vitation the variable To do  will be observed which can restrict the possible decision options for Menu and Movie  There is a small technical problem with the variable          fx fx   fy  fx  fy  Figure    The figure illustrates the use of labels when specifying asymmetry  The AID allows the specification of directed cycles with the restriction that before any of the nodes in a cycle are observed the cycle must be  broken   i e   no matter the variables observed there must exist at least one unsatisfied label associated with a node or an   v vt K   AINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS  informational arc in the cycle  This syntactical con straint compensates for the traditional constraint that the graph should be acyclic  Having cycles in an AID supports the specification of decisions for which the temporal order is dependent on previous observations and decisions  For instance  in Figure   decisionDz is taken beforeD   if X   x butD   is taken beforeD  if X  f  x   Xfx  Figure    The figure illustrates the use of cycles in the AID   Formally  a label is a Boolean function defined as a combination of Boolean variables  the constants true      and false     and the operators     conjunction   V  disjunction       negation      implication  and  bi implication   The Boolean variables are used to represent the con ditioning on states e g  if a node Y is conditioned on X   x then X   x should be represented as a Boolean variable in the label associated with Y  However  for ease of notation we shall use e g  X   x directly in the label  without creating an actual Boolean variable   a Boolean variable in the context of labels must there fore denote a state configuration of some node in the AID  A truth assignment to a Boolean function f is the same as fixing a set of variables in the domain of f  i e   if X   x represents a Boolean variable in the domain of f  then X   x can be assigned either true or false by associating X with some state x  E Wx  denoted f X H x     E g   X   x  X H x       if x   x  and  X  x   X H x       otherwise   n the remainder of this paper  we assume that each   de X is associated with a label fx  i e   if X is not  ssociated with a label in I    U   F   then we extend   with the label fx      Moreover  we will use dom f   denote the domain of the label f  the domain of a bel is the set of nodes referenced by the label  chance variable X is said to be present in I given c onfiguration c over a set of variables C  if   fx     Edep X  fy   C H c      in I given c  A chance vari e X is said to be unresolved in I given a configura  c over a set of variables C if dom fx  C H c    f    fx C H c       i Vi E          or  Y E dep X  s t  l fv C H c    f    and fv C H c  t i Vi E                      The concepts present and unresolved are similarly de fined for value nodes  decision nodes and informational arcs        THE QUANTITATIVE LEVEL  A decision variable D is associated with a set of re strictive functions  a restrictive function is given by y    Wn  y  Wo and specifies the legitimate deci sion options forD given a configuration of n   n  where n denotes the set of variables which can re strict the legitimate decision options forD  In Figure   the restrictive function associated with Movie specifies that the state no decision is the only legitimate deci sion option if To do  restaurant  similar for Menu if To do  movie   The uncertainty associated with a chance variable X is represented by a partial conditional probability po tential tPx   P XIInx    Wxun Y         where nx   nx  UT  by definition  a test decision variable has no probabilistic influence on a chance variable  A partial probability potential can specify that given a configuration of the conditioning set for a chance vari able X  some states of X are impossible  denoted  L   we make a conceptual distinction between an impos sible state and a state having zero probability  Note that if all the states of X are impossible for some con figuration of the conditioning set  then this must be reflected in the labeling of X e g  if P XIY  is only de fined for Y    J  then Y    J must occur in the label of X  A value node X is associated with a partial utility po tential   x   Wnx Y JR  U      requiring that the par tial utility potential does not take on negative values is not an actual restriction as any utility potential can be transformed s t  it adheres to this assumption  Fur thermore  as for the PID we assume that the total utility is the sum of the local utilities  The combination of partial potentials  addition  multi plication and division  is defined similarly to the com bination of total functions by treating the undefined value   L  as an additive identity and a multiplica tive zero  In particular  this ensures consistency when defining the total utility as being the sum of the local utilities  As for the PID we define a realization of an AID as an attachment of probability and utility potentials to the appropriate variables  The probability and utility potentials associated with an AID I is denoted ll r and  l r  respectively  Given a realization ll r U Jlr of an AID I the set of probability potentials with X E X in the domain will be denoted ll x  i e   ll x     P E ll ri X E X  X E dom  jl                UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       SPLIT CONFIGURATIONS AND DECISIONS IN CONTEXT  iii   Definition    Let I be an AID and let  F be the set  of labels associated with I  A variable X is said to be a split variable in I if there exists a label f E  F s t  X E dom f   The set of split variables in I is denoted  Sr   Now  the partial order    induced by an AID I is found by initially treating I as a PID  ignoring any labels  and then refining the partial order       induced by the PID s t  for any pair of variables X andY  where X f   Y andY f   X we have X   Y if X E Sr  see Figure     if  X  Y    Sr we have X f Y andY f  X    b   Figure    In figure  a  the AID induces the partial order X     Y     D  and in figure  b  the AID induces the partial order X    Y     D         In what follows we assume that an AID has exactly one split variableS   termed the initial split variable  satisfying that WE Sr  S   S     Y  Date  is the initial split variable in the AID depicted in Figure    Obviously  the set of variables succeeding the initial split variable s is dependent of the state of s hence  we define the concept of a missing variable   Definition    Let I be an AID and let S be the initial split variable in I  The chance variable X is said to be missing in I given s S  if     i   fx S H s       or  ii   Y E dep X  s t  y is missing givens      S      X       S  and X is unresolved given     When taking a decision in an asymmetric decision problem  previous observations and decisions may de termine the variables observed before the decision in question  For both semantic and computational rea sons it is important to identify the variables actually observed before taking a particular decision  For in stance  in the AID depicted in Figure   it would not be meaningful to have an optimal strategy for Menu con ditioned on both Date  n and Accept  y since this is an impossible state configuration  So  in order to reason about the different informational states when taking a decision D we must associate D with a con text describing the variables observed  That is  we need to identify the possible temporal orderings of the variables and in particular  the variables which influ ence the occurrence of future variables    l  VS E Sr   S  s s    or  The above definition is easily adopted to value nodes  decision nodes and informational arcs and will there fore not be described further  The following definition specifies the AID obtained from another AID I by instantiating the initial split variable in I     Let I  U    F  be an AID and let be the initial split variable in I  The AID I I  U      F   is said to be myopicly reduced from I given s   s  if   Definition     s       U    X E UIX is not missing givenS    sJ             X Y  E   X  Y   X Y  is not missing in I given s  C     S      U       F     fx S H s   fx E  F and X E U    f x v  S H SJ if X Yl E  F and  X Y  E      U  That is  we myopicly reduce an AID I by removing the missing nodes and the missing arcs  However  the removal of arcs might render additional nodes missing thus  for all missing nodes and arcs to be removed we need to remove them iteratively  The AID I  obtained from I by iteratively removing missing nodes and arcs is said to be reduced from I given s   S  and is denoted I S H s    Figure   illustrates the AID which has been reduced from the AID in Figure   given Date  n  Notice that reducing an AID w r t  its initial split variable S is the same as instantiating s hence  s is not a split variable in I S H s    In the remainder of this paper we restrict our atten tion to AIDs having exactly one initial split variable  This restriction also applies to AIDs which have been reduced from other AIDs that is  we do not consider AIDs which can be reduced to an AID that does not adhere to this restriction  having a unique initial split variable ensures that the reduction is unambiguous and it does not seem to exclude any natural decision problems  actually  decision trees have the same prop erty  Furthermore  for ease of notation we shall treaJ restrictive variables as split variables unless stated oth erwise  Sf denotes the union of Sr and the set of H strictive variables in     However  we do not requir the occurrence of a unique restrictive variable as tf order in which the restrictive variables are instantiat  is of no importance  i e   the syntactical constraint   the split variables does not extend to the restricti variables  Now  based on the requirement about a unique SJ variable in an AID I we can identify the possible st        UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS       configurations in I  These configurations are found by going in the temporal order specified by I  That is  we iteratively identify the initial split variable in the AID reduced from the AID in the previous step and assign this split variable a configuration consistent with the previous one   The set of contexts in which a decision variable   can occur is denoted Oo   The initial split variable S in I is identified as de scribed previously  In general the k  th split variable in I w r t  the configurations   s  sz      sk d  de noted Sk    is the initial split variable in I S H s   S  H Sz    S    H Sk     where Si   is the initial split variable in I w r t  the configuration Si    s  sz       S t       Obviously  if I   has been re duced from I w r t  s     then    must be a possible state for S  i e   each time an AID is reduced the pos sible outcomes decision options for the split variables are  updated    In what follows we let I Si   H sd     denote the AID I SV  H s   S    H sz    S i   H sd   Solving an AID is the same as determining an optimal strategy for the decisions involved  However  as op posed to the PID we can not restrict our attention to the variables being required for the decision variable in question  the variables being required for   may vary depending on the context in which   appears  Thus we define a strategy as follows      Definition    Let  C Sf and S   subsets of the split vari ables contained in the AID I  A configuration s    s  sz      st  over the variables S   is said to be a split configuration for S  over S   if    S  Sz       St     S  S  be    Si is the i th split variable in I w r t  the configu ration S t      s  sz       S t    and    S is not S  Sf   a split variable in          H  sr    r   E  If S    Sf thens is said to be an exhaustive split configuration for I over S    For notational convenience  we will sometimes use to denote the AID reduced from the AID I w r t  the split configuration s over the variables S     I S   H s   Example    Consider the AID depicted in Figure    The configuration  Date  y  is a split configura tion  whereas  Date  y Accept  y  To do   movie  is an exhaustive split configuration  The configuration  Date  n Club  n  is an exhaustive split configura tion also since Date  n implies that Accept  is never observed  thereby rendering the variables Movie  Menu D and To Do  missing  Based on the notion of a split configuration we can de termine the contexts in which a decision variable can occur  A context for a decision variable   is a config urations   w  x   where       s is a split configuration for S  over the variables S   satisfying that there does not exist a split vari able S E Sr S  Hs  s t  S      in I  S   H s      x is a configuration over the restrictive variables for   in I  S   Hs       SOLVING ASYMMETRIC INFLUENCE DIAGRAMS  Definition    A strategy for an AID I is a set of func tions       olD E Uo   where bo is a decision func tion given by  bo   Wpred D s        j  Wo  Vs E Oo   where pred D ls is the set of variables preceding   un der the partial order induced by the AID which has been reduced from I w r t s  A strategy that maximizes the expected utility is termed an optimal strategy  and a decision function    that maximizes the expected utility for decision   w r t  each context s E Oo is termed an optimal strategy for    A well defined AID  specified in the following section  can in principle be solved by unfolding it into a de cision tree  and then use the  average out and fold back  algorithm on that tree  the partial probability potentials specified by the realization of the AID can be seen as a model of the uncertainty associated with the chance variables  this is somewhat similar to the approach found in  Call and Miller          However  this  brute force  approach would create an unneces sary large decision tree in case the original decision problem specifies symmetric subproblems        DECOMPOSING ASYMMETRIC INFLUENCE DIAGRAMS  In this section we present an algorithm for solving AIDs  The main idea underlying the algorithm is to decompose the decision problem into a collection of symmetric subproblems organized in a tree struc ture  and then propagate from the leaves towards the root using existing evaluation methods to solve the  smaller  symmetric subproblems  The decomposition is performed by reducing the AID w r t  the possible states of its initial split variable  This reduction is then applied iteratively to the AIDs produced in the previous step until no split variables remain  For instance  Date  is the initial split variable   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS            in  the dating problem  depicted in Figure   so by decomposing the problem w r t  Date  no we obtain the AID depicted in Figure    where the initial split variable is Night Club   An optimal strategy can then be found by iteratively eliminating the so called free variables in each of the subproblems   Definition    Let I S  H s   be the AID reduced I  The variable X is said to be free in S    X and VS E Sr S  s l   X    S  where   is the partial order induced by I S H s    If X is not free in I S H s   then X is said to be bound in I S H s     from the AID I S H s   if  The evaluation of an AID I is initiated by invoking the algorithm Evaluation on I  note that in the follow ing algorithms we exploit that instantiating the initial split variable in an AID produces another AID with a unique initial split variable   Algorithm    Evaluation   Let I be an AID and let  S  be the initial split variable in invoked on I  then i  Invoke Evaluation on  I S  ii  Absorb the potentials from  W      H  I   If Evaluation is  s    Vs  E W    I S  v  H  s    to  of probability potentials and utility potentials ob tained   E     remove i  from I S  H Sj  and associate  Dj S  s  U l j So  s  with I S    Hsj  for  iii  For each i   J     alll  j  i   The algorithm below describes the elimination of variables  and is inspired by the lazy evaluation architecture  Madsen and Jensen          However  any elimination algorithm can in principle be used   Algorithm    Elimination   Let I be an AID and let  D I and  I be the sets of probability and utility po tentials associated with I  If Elimination of variable X is invoked on  D I U  l I  then    Dx  cl   E  l IIX E dom cl      l IIX E dom         i  Set     and   l x           E  ii  Calculate     I  Vs  E  v  where M is a marginalization operator depending on the type of X  i e   M denotes a summation if X is a chance variable and a maximization if X is a decision variable   iii  Let     be a utility potential absorbed  Algorithm    from I S H s  s t  S rf  dom       If  Jj    i s  t     is not absorbed from I  S H S  to I then condition     on S s  see Figure        iii  Return  l i       f  Figure    The occurrence of     is dependent on state of S thus  the utility potential produced by elimination of     A and     is dependent on S  relative temporal order of A and   vary w r t  state of S   the the the the  Algorithm    Absorption   Let I S t    H Si  be an AID and let S be the initial split variable in I S i   H sil If Absorption is invoked on I S i    H Si  S H s  from I S t   H si   then   X be the free variables I S i   H Si  S H s  and set     i  E  Drrsi     sd S  sl U  l rrsi    stHS  sli JX EX s t  X E dom i      i  Let     ii  Eliminate the variables X from    w r t  the par tial order induced by I St   H si  S H s   Al gorithm     Let  I i So  s  and    irs  sl be the sets      l r  l x U  cl  x   and   l i      l I  l x U  During the evaluation  the decision option maximizing the utility potential from which a decision variable   is eliminated should be recorded as the optimal strategy for   w r t  to the context in question  Now  based on the algorithms above we define the con cept of a well defined AID  The definition is based on the notion of a significant chance variable  which can be adopted from the PID framework by consider ing the admissible total orderings of the free variables in each of the AIDs produced during the decompo sition  the structural characterization of the chance variables being significant for a given decision variable   see  Nielsen and Jensen      b   can also be adopted to an AID I  except that we have to investigate each of the AIDs reduced from I w r t  the exhaustive split configurations for I   Definition     Well defined   An AID I is said to define a decision scenario if    for all split configurations s  there does not exist a free chance variable A and a free decision variable   UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS         in I  S   H s  s t  A is significant for    s is a configuration over the variables S    Sf   for any decision variable   and for each context s   w  x  for   there does not exist two restric tive functions Y b and Yb s t  dom y b    nls    and dom yb    nls  where nls is the set of restrictive variables which are present in I given  s   Theorem    Sound   If Algorithm   is invoked on an AID I which define a decision scenario  then Algo rithm   computes an optimal strategy for each decision variable in I   Proof  The idea of the proof is t o initially treat non split variables as split variables  thereby obtaining a decision tree representation of the decision problem when reducing the AID  each subproblem contains ex actly one free variable which corresponds to a node in the decision tree  Note that from Algorithm   we have that treating non split variables as split variables has no impact on the evaluation  Finally  we exploit that the set of partial probability potentials constitutes a model of the uncertainty as sociated with the chance variables  and from this it can be shown that the calculations performed by Al gorithm   are equivalent to the calculations peformed when solving the corresponding decision tree  For fur D ther detail see  Nielsen and Jensen      a      CONCLUSION  In this paper we have presented a framework  termed asymmetric influence diagrams  for representing asym metric decision problems  The asymmetric influence diagram is based on the partial influence diagram and uses labels  associated with nodes and informational arcs  to encode structural asymmetry at the qualita tive level  Asymmetry which deals with the possible outcomes of an observation or the legitimate decision options of a decision variable is represented in partial probability potentials and restrictive functions  respec tively  We have presented an algorithm for solving asymmet ric influence diagrams  The algorithm decomposes the asymmetric decision problem into a collection of sym metric subproblems which can be solved using existing methods for solving influence diagrams  As part of the future work  the class of asymmetric de cision problems which can be modeled effectively using AIDs needs to be determined  We claim that the lan guage of AIDs is as strong as that of decision trees  but the amount of redundancy in the models should be determined        
 Influence diagrams serve as a powerful tool for modelling symmetric decision problems  When solving an influence diagram we de termine a set of strategies for the decisions involved  A strategy for a decision variable is in principle a function over its past  How ever  some of the past may be irrelevant for the decision  and for computational reasons it is important not to deal with redundant vari ables in the strategies  We show that current methods  e g  the Decision Bayes ball algo rithm  Shachter         do not determine the relevant past  and we present a complete al gorithm  Actually  this paper takes a more general out set  When formulating a decision scenario as an influence diagram  a linear temporal or dering of the decisions variables is required  This constraint ensures that the decision sce nario is welldefined  However  the structure of a decision scenario often yields certain de cisions conditionally independent  and it is therefore unnecessary to impose a linear tem poral ordering on the decisions  In this paper we deal with partial influence diagrams i e  influence diagrams with only a partial tem poral ordering specified  We present a set of conditions which are necessary and sufficient to ensure that a partial influence diagram is welldefined  These conditions are used as a basis for the construction of an algorithm for determining whether or not a partial influ ence diagram is welldefined     INTRODUCTION  Graphical modelling for decision support systems is getting more and more widespread  F irst of all  graph   ical modelling is an appealing way to think of and com municate on the underlying structure of the domain in question  but it also helps the modeller to focus on structure rather than calculations  I nfluence diagmms  ID  serve as a powerful modelling tool for symmet ric decision problems with several decisions  However  IDs require a linear temporal ordering of the decisions  and this is often felt as an unnecessary constraint  E g  if no information is gathered between two deci sions  then these decisions can be taken independently of each other  This type of very obvious temporal in dependence can be handled by a computer system  but temporal independence may be more complicated  For example  observing a variable A immediately before taking a decision D need not have any impact on this particular decision  Hence  we look for an operational characterization of temporal independence in IDs  The advantages of having an operational charac terization of temporal independence are twofold  To take the most obvious advantage first  When a computer system solves an ID it basicly elimi nates the variables in reverse temporal order  see  Shachter          Shenoy          Jensen et al         and  Zhang          eliminating a variable produces a table  function  over all non eliminated neighbours  However  the reverse temporal order of elimination has a tendency to create very large tables  usually much larger than for Bayesian networks of the same com plexity   Thus  if we could relax the temporal order to a partial order  we would have more freedom when looking for a good elimination sequence  To say it an other way  When a decision variable D is eliminated we create a strategy for D given its past  If we can reduce the past to contain only the variables required for taking that decision  we have reduced the domain for the strategy function  The second advantage has to do with the modelling process  That is  will we allow two decisions to be taken independently of each other  Or  do we allow an observation to be made independently of a certain   Welldefined Decision Scenarios  decision  Hence  we work with partial specifications of IDs  and would therefore like to know whether or not this partial structure is ambiguous  and if it is ambigu ous we would like the system to give suggestions for further specification of the temporal order  An unam biguous partial influence diagram is said to represent a welldefined decision scenario   In this paper we give a set of operational rules for determining whether or not a partial influence diagram represents a welldefined decision scenario  These rules are used as a basis for an algorithm for answering this question  The algorithm can furthermore be used in a dialogue between computer and user to pinpoint how to change the model in order to make it unambiguous  In section   we formally introduce IDs  and the terms and notations used throughout this paper  In section   we define a partial ID as a generalization of the tradi tional ID  and we give a semantic as well as a syntactic characterization of conditions ensuring that a partial influence diagram is unambiguous      INFLUENCE DIAGRAMS  An ID can be seen as a belief network augmented with decision variables and utility functions  Thus  the nodes in the ID can be partitioned into three dis joint subsets  chance nodes  decision nodes and value nodes  The chance nodes  drawn as circles  correspond to chance variables  and represent events which are not under the direct control of the decision maker  The decision nodes  drawn as squares  correspond to deci sion variables and represent actions under the direct control of the decision maker  In the remainder of this section we assume a total ordering of the decision nodes  indicating the order in which the decisions are made    Furthermore  we will use the concept of node and variable interchangeably if this does not introduce any inconsistency  and we assume that no barren nodes are specified by the ID since they have no impact on the decisions   The set of value nodes  drawn as diamonds  defines a set of utility functions  indicating the local utility for a given configuration of the variables in their domain  The total utility is the sum or the product of the local utilities  in the remainder of this paper we assume that the total utility is the sum of the local utilities    The ordering of the decision nodes is traditionally rep resented by a directed path which includes all decision nodes     A chance node or a decision node is said to be barren if it does not precede any other node  or if all its descendants are barren        With each chance variable and decision variable X we associate a state space Wx which denotes the set of possible outcomes decision alternatives for X  For a set U  of variables we define the state space as Wu    x WxiX E U    The uncertainty associated with each chance variable A is represented by a conditional probability function P A IPA    WAuPA  t         where PA denotes the immediate predecessors of A  The arcs in an ID can be partitioned into three dis joint subsets  corresponding to the type of node they go into  Arcs into value nodes represent functional dependencies by indicating the domain of the associ ated utility function  Arcs into chance nodes  denoted dependency arcs  represent probabilistic dependencies  whereas arcs into decision nodes  denoted informa tional arcs  imply information precedence  if there is an arc from a node X to a decision node D then the state of X is known when decision D is made  Let Uc be the set of chance variables and let Un    D  D         Dn  be the set of decision variables  As suming that the decision variables are ordered by index  the set of informational arcs induces a par titioning of Uc into a collection of disjoint subsets C   C          Cn  The set Ci denotes the chance vari ables observed between decision Dj and Dj   thus  the variables in Cj occur as immediate predecessors of Dj   This induces a partial order   on U   Uc UUn i e  Co    D    C          Dn    Cn   The set of variables known to the decision maker when deciding on D j is called the informational predeces sors of Dj and is denoted pred Dj   Assuming  no forgetting  the set pred Dj  corresponds to the set of variables that occur before Di under     Moreover  based on the  no forgetting  assumption we can as sume that an ID does not specify any redundant no forgetting arcs i e  a chance node can be an immediate predecessor of at most one decision node       EVALUATION  When evaluating an ID we identify a strategy for the decision variables  a strategy can be seen as a prescrip tion of responses to earlier observations and decisions  The evaluation is usually performed according to the maximum expected utility principle  which states that we should always choose an alternative that maximizes the expected utility   I be an ID and let Un denote the decision variables in  I  A strategy is a set of functions      nD i E Un   where  n is a decision function given by   Definition    Let  tln  Wpred D    t  Wn         Nielsen and Jensen  A strategy that maximizes the expected utility is termed an optimal strategy  In general  the optimal strategy for a decision variable Dk in an ID I is given by    v  Co D       Ck    v   c           arg max    P CkiCo D       Ck   Dk Pv        where pv  t is the maximum expected utility function for decision Dk l   PD  Co D    Ck    max L P Ck  ICo D        ck Dk l P Dk   D o   Co l  By continuously expanding Equation    we get the fol lowing expression for the optimal strategy for Dk   where   J          Jl are the utility functions specified by  I   The expression above conveys that the variables are to be eliminated w r t  an elimination sequence which is consistent with the partial order  and in what fol lows we define a legal elimination sequence as a bijec tion a   U B                lUI   where X    Y implies a X    a Y   Note that a legal elimination sequence is not necessarily unique  since the chance variables in the sets Ci can be commuted  Even so  any two legal elimination sequences result in the same optimal strategy since the decision variables are ordered totally and  I   operations commute  the total ordering of the decision variables ensures that the relative elimination order for any pair of variables of opposite type is in variant under the legal elimination sequences  this is needed since a  max  operation and a  I   operation do not commute in general      seen from the optimal strategy for a decision variable  equation     where the elimination order for any two adjacent variables of opposite type may be permuted if the variables do not occur in the same function   REPRESENTING DECISION PROBLEMS UNAMBIGUOUSLY  In the section above we described the evaluation of an ID w r t  the maximum expected utility principle  The underlying assumption was a total ordering of the decision variables ensuring that the optimal strategy is independent of the legal elimination sequences  However  it is in general not necessary to have a to tal ordering of the decision variables  if ck     then Dk and Dk   can be commuted   This can also be  PARTIAL INFLUENCE DIAGRAMS AND DECISION SCENARIOS  Given that a total ordering of the decision variables may not be needed  we define a partial influence dia gram  PID  as a directed acyclic graph consisting of decision nodes  chance nodes and value nodes  assum ing that value nodes have no children  Notice  that chance nodes may have several decision nodes as im mediate successors  and that no ordering is imposed on the decisions  Additionally  we define a realization of a PID as an attachment of functions to the appropriate variables i e  the chance variables are associated with conditional probability functions and the value nodes are associated with utility functions  Since the semantics of a PID correspond to the seman tics of an ID  a PID induces a partial order    on the nodes Uc U Uv  as defined by the transitive closure of the following relation  see figure       Y   D   if  Y  D   is a directed arc ini  D  E Uv      D     D  D        Y  if  D  X   X       Xm  Y  is a directed path in I  Y E Uc U Uv and D  E Uv       A  if A f  Dj for all Di E Uv  A E Uc and  E  Uv    D     A  if A f  D  and Di E Uv s t  D     Di and A   Di  A E Uc and D  E Uv    In what follows we say that two different nodes X and Y in a PID I are incompatible if X f  Y and Y f  X  Note that a chance node A is incompatible with a de cision node D if there exists a decision node D  s t  D and D  are incompatible and  A  D   is an informa tional arc in I and A pred D  see figure     As for the traditional ID we seek to identify an opti mal strategy when evaluating a PID  Since the optimal strategy for a decision variable may be dependent on variables observed  we define a total order  for a PID  Definition    Let I be a PID and let U   Uv U Uc denote the set of decision variables and chance vari ables contained in I  A total ordering of I is a bijec tion j    U B                lUI   A total ordering of I is said to be an admissible total ordering if X    Y im plies that j  X    j  Y   where    is the partial order induced by I   In what follows   J will denote the total ordering j  s t  X     Y if j  X    j  Y   the index j  will be   Welldefined Decision Scenarios       The above definition characterizes the class of PIDs which can be considered welldefined  since the set of admissible total orderings for an PID I can be seen as the legal elimination sequences for I  Note that the traditional ID defines a decision scenario   Moreover  in correspondence with the permutations of chance variables in any legal elimination sequence for an ID  we define the following relation for any admissible total order  Figure    The figure represents a PID which specifies the partial order  B   D     E  F G D  D     C    B     D     E F    D    C    B     D      G     D     C  and D     C   C  denotes the chance vari ables observed  possibly never  after deciding on all the decisions   Thus  D   D  and D  are pairwise in compatible  whereasD  andD  are not  Furthermore  it can be seen that F is incompatible withD   omitted if this does not introduce any confusion   E g  E   F   D    B   D    G   D    D    C  is a total ordering of the PID in figure    but it is not admissible since it contradictsD    D   Notice  that an admissible total ordering of a PID I implies that I can be seen as an ID  assuming that redundant no forgetting arcs have been removed   Based on the informational predecessors for a decision variable  we define a strategy relative to a total order    as a set of functions        l  D E Un   where     is a decision function given by        Wpred D         Wn   where pred  D      XIX   D    the index   in pred D   will be omitted if this does not introduce any confusion   Given a realization of a PID I  we term a strategy relative to   an optimal strategy rela tive to  if the strategy maximizes the expected utility  Likewise we term a decision function      contained in an optimal strategy relative to    an optimal strategy forD relative to   Note that an optimal strategy for a decision variable D relative to   does not necessar ily depend on all the variables observed  Hence we say that an observed variable X is required for D w r t   if there is a realization of I s t  the optimal strategy forD relative to   is dependent on the state of X  Since a total order for a PID need not be admissible  we define an admissible optimal strategy for a realiza tion of a PID as an optimal strategy relative to an admissible total order  Definition    A realization of a PID I is said to de  fine a decision scenario if all admissible optimal strate gies for I are identical  A PID is said to define a de cision scenario if all its realizations define a decision scenario   Definition    Let  be an admissible total order  and  let X and Y be two neighbouring variables under    fulfilling one of the following three conditions    X and Y are both chance variables     X and Y are both decision variables     X and Y are incompatible   The ordering    obtained from   by permuting X and Y according to the rules above is said to be C equivalent with   denoted   c       The transitive closure of equivalence relation   Proposition   c  is an  Theorem    All admissible orderings of a partial or  der    are C equivalent   Proof  It is sufficient to prove the following claim  Let   be an admissible total ordering  and let X and Y be incompatible s t  X  Y  Then the ordering obtained from   by permuting X and Y is C equivalent with    Assume the claim not to be true  Then there exists an admissible total ordering  and a pair of incompatible variables X Y which can not be permuted  Let X and Y be such that the segment between X and Y under  is minimal  That is  it is not possible to find any other admissible total order with an incompatible non permutable pair of variables closer than X and Y under   X  X      Xn   Y       Now  start with X and follow  until we reach an in compatible variable X   we know that at least when we reach Y we will meet an incompatible variable  If X    Y then Y and X    can be permuted  and we have an admissible ordering with an incompatible non permutable pair closer than the closest  If i  S n then X and X  are incompatible  If they can not be per muted we have a pair of incompatible non permutable variables closer than the closest  If they can be per   muted we also obtain a closer pair  So  we are looking for a set of necessary and sufficient conditions ensuring that all admissible orderings yield        Nielsen and Jensen  the same set of strategies  Actually  we will look for conditions ensuring that orderings  C equivalent with an admissible ordering  yield the same strategies  this is a bit broader as we allow permutation of two neigh bouring decision variables  From Theorem   we in fer that we can narrow down the scope to neighbour ing variables of opposite type  in general neighbour ing variables of opposite type can not be permuted without affecting the strategies   Hence  we look for a necessary and sufficient set of conditions granting com mutation of two incompatible neighbouring variables of opposite type  Definition    Let I be a PID and let A be a chance variable incompatible with a decision variable D in I  Then A is said to be significant for D if there is a realization and an admissible total order  for I s t     A occurs immediately before D under   The optimal strategy for D relative to  is differ ent from the one achieved by permuting A and D in    A chance variable is said to be significant for D relative to  if the above conditions are satisfied w r t    Notice that if a chance variable A is significant for D w r t   then A is required for D w r t    Based on the above definitions we present the following theorem which characterizes the constraints necessary and sufficient for a PID to define a decision scenario  Theorem    The PID I defines a decision scenario if and only if for each decision variable D there does not exist a chance variable A significant for D   Proof  Follows immediately from Theorem   and Def inition      So  we have reduced the task to the following  Let I be a PID  and let A be a chance variable incompatible with a decision variable D  Is A significant for D   Shachter        presents an algorithm for determining the so called requisite information for a decision vari able in an ID  Unfortunately  the algorithm does not meet our needs as shown by the following example  Example    When running the algorithm Decision  Bayes ball Shachter        on the ID depicted in fig ure    the chance variable B is marked as requisite for decision D   However  B is not relevant for the opti mal strategy for D   i e  the elimination order of B relative to D  is of no importance when considering the optimal strategy for D      Figure    The algorithm Decision Bayes ball marks the chance variable B as requisite for D   The following method  which corresponds to itera   tively replacing decisions by their strategies  has the same drawback  For an ID we start off with the moral graph i e  informational arcs are removed  undirected arcs are added between nodes with a common child and finally  value nodes are removed together with the directions on the arcs  When eliminating a decision variable D the resulting set of neighbours N D  is a subset of pred D   This set of neighbours is invariant w r t  the legal elimination sequences  and it is charac terized as the set of variables connected in the moral graph to D through a path with no intermediate vari able in pred D   As N D  contains all the information relevant for determining the optimal strategy for D  it is a candidate for the relevant past  However N D  may contain variables insignificant for D as can be seen from the ID depicted in Figure    B is contained in the neighbouring set for D  as the elimination of A produces a fill in between B and D   So  neither Decision Bayes ball nor the elimination method presented above is fine grained enough to de tect all independencies  The problem is that N D  may contain variables relevant for the maximum ex pected utility for D  the maximum expected utility for D may cover utility functions having no influence on the optimal strategy for D  This means that we need to characterize and identify the utility functions on which the optimal strategy for D depends  Definition    The utility function    J is relevant for D w r t  the admissible total order   for I  if there exists two realizations R  and R  of I who only differ on    J s t  the optimal strategies for D relative to  are different in R  and R   We need to determine the structural constraints neces sary and sufficient for a utility function to be relevant for a decision variable  and based on this character ization we shall define the constraints necessary and sufficient for a chance variable to be significant for a given decision variable       RELEVANT UTILITY FUNCTIONS EXAMPLES AND RULES  The optimal strategy for a decision variable D is based on the assumption that we always adhere to the max imum expected utility principle  Hence  if deciding on D can influence a future decision D  then the utility   Welldefined Decision Scenarios  functions relevant for D  may be relevant for D also  From this observation together with the expression for the optimal strategy for D  see equation     we present the following metarules  For notational convenience we shall sometimes treat uninstantiated decision nodes as chance nodes with an even prior distribution  More over  since a utility function is termed relevant w r t  an admissible total order we will mainly consider IDs in the section  Metarule      J is relevant for D in I if there is a real ization of I s t  D has an impact on the expected utility for   J  Metarule      J is relevant for D in I if there is a  realization of I and a future decision D  s t  D has an impact on D   for which   J is relevant   Metarule    If none of the metarules above can be  applied then   J is not relevant for D  The following examples present a set of IDs where we identify the utility functions relevant for a given de cision variable  The properties relating to these ex amples will be generalized to arbitrary IDs  which will serve as a basis for determining the structural con straints necessary for a utility function to be relevant for a given decision variable  Example    Consider the ID depicted in figure   and assume that the conditional probability functions are specified s t  the state of a variable corresponds to the state of its parent   Figure    The figure represents an ID  where the utility function   J is relevant for the decision variable D  It is easy to specify two realizations of   J s t  the op timal strategies relative to those realizations differ i e    J is relevant for D     Now  assume an arbitrary ID I in which there exists a directed path from a decision node D to a value node   J  excluding informational arcs   and assume a realization R of I  Since the conditional probability functions associated with the variables on the path from D to   J can be specified s t  deciding on D has an impact on the expected utility for   J  it follows that   J is relevant for D  Rule    Let I be a PID  and let f denote I without informational arcs  The utility function   J is relevant for the decision variable D if there exists a directed path from D to   J in I  This rule is equivalent to Metarule    as can be seen from the mathematical expression correspond ing to this metarule    J is relevant for D if       Table    The utility function  j   C D               P dom   J ID  pred D   is a function of D  where dom    J  is the chance variables in the domain of    J  uninstantiated decision variables are treated as chance variables   The conditional probability func tion P dom   J Ipred D   D  is a function of D if D is d connected to a variable A E dom   given pred D   However  this implies that there exists a directed path from D to   J in f  Conversely  if there exists a di rected path from D to   J in f  then D is d connected to a variable A E dom  I J  given pred D   The following examples illustrate  that in order to identify all the utility functions relevant for a given decision variable D  it is in general not sufficient only to consider those utility functions to which there exist a directed path from D  Example    When deciding on D  in the ID depicted  in Figure   we want to maximize   J   Now  as the deci sion variable D  is d connected to C given pred D    it follows that the decision made w r t  D  may change our belief in C  when deciding on D   and thereby in fluence D  through   J   D  is required for D    Hence    J  is relevant for D   which is also true for   J as Dz E dom  j    Moreover  knowledge of A may like wise change our belief in C when deciding on D   and since A is influenced by D  it follows that D   has an impact on D  since knowledge of D  can be taken into account when deciding on D   D  is required for D    Thus    J  is relevant for both D  and D  conveying that    J is relevant for D  also   Figure    The figure represents an ID where both   J and    J  are relevant for D   This can also be seen by considering the utility func tion specified by table   together with the functions P C                   I J  D            and  f   D             we assume that the state of A corresponds to the state of D  and that P BID   A  C  is specified s t  the state of C is revealed if the state of A  B and D  are the same  and no knowledge is gained on C if this is not the case          Nielsen and Jensen  These functions define two realizations of I who only differ on    J  and when evaluating I w r t  these real izations we obtain two different optimal strategies for D  i e   n    d  if    J      JJ and  n    d  if  ljJ    I J  From these strategies it can be seen that the utility function  ljJ influences the optimal strategy for D  i e       J is relevant forD    The example above can be seen as an instance of Metarule    Assume an arbitrary ID I and a realiza tion of I in which the conditional probability function for any intermediate variable in a converging connec tion is as specified in the example above  From this structure we may deduce that  if    J  is relevant for a future decision D  andD is required forD   then the utility function    J  is relevant forD  D has an impact anD   Example    When deciding onD  in the ID depicted in figure    we seek to maximize    J   By the arguments given in the example above  it follows that both    J and    J  are relevant for D   Additionally  knowledge of B may change our belief in E when deciding onD   and since B is influenced by A  which in turn is influenced by D    it follows that D  has an impact on D   A is required forD    Thus  both  ljJ and    J  are relevant for DJ   Figure    The figure represents a ID in whichD  may influence the chance variable A required forD   indi cating that both    J and    J  are relevant forD    This can also be seen by assuming the two realizations consisting of the utility functions  I J  D               and  jJ  D            together with functions corresponding to the ones specified in Example   and Example    When evaluating I w r t  these realizations we obtain two optimal strategies which differ on D  i e   n    d  if    J     J  and  n    d  if  ljJ     J   From these strategies it can be seen that the utility function  ljJ may influence the optimal strategy for D  i e   ljJ is   relevant forD    The structural properties relating to the example above can  as for the previous example  be general ized to an arbitrary ID  Thus  based on the example above and the deductions made w r t  Example    we present the following rule  Rule    Let I be a P D I and let   be an admissible total order for I  The utility function  ljJ is relevant  for the decision variable D w  r t    if there exists a decision variableD  s t  i  D D  and  ljJ is relevant forD  w r t     ii  either a  D is required forD  w r t    or b  there exists a directed path in f from D to a chance variable X E pred D    and X is required forD  w r t    This rule is equivalent to Metarule    since the rule covers all the cases where D can have an impact on a future decision D   D has an impact on D  if and only ifD is required forD  orD influences a variable required forD   Note that Rule   is not a complete structural rule as it refers to the term  required   which has not yet been characterized structurally  This is done in the following section       REQUIRED VARIABLES EXAMPLES AND RULES  Having established a method to identify the utility functions relevant for a decision variable  one might think that the required variables could be identified in the following way  Before constructing the moral graph  remove all utility functions not relevant for D and then eliminate the variables as described in Section      However  the resulting neighbouring set ND     may still contain variables which are not re quired as can be seen from Figure    if we add the arc  A D  and remove the arc  D    I J  then A is not required forD but A E N D  when D is eliminated  A variable X is required for a decision variableD if X is observed beforeD and the state of X may influence the optimal strategy forD  Since the optimal strategy forD is dependent on the assumption that we always adhere to the maximum expected utility principle it follows that X is required forD if X has an impact on D or X has an impact on a future decision variableD   on which D also has an impact  Hence  analogously to the metarules specifying the utility functions rele vant for a decision variable  we present three metarules concerning the variables required for a given decision variable  according to the definition of a required vari able we assume an admissible total order   where a variable X occurs before a decision variable D under    Metarule    X is required for D if there is a real  ization s t  when deciding on D the state of X has an impact on the expected utility for a utility function  ljJ relevant for D w r t       Welldefined Decision Scenarios  Metarule    X is required for D if there is a realiza  tion and a future decisionD  s t X has an impact on D   and there exists a utility function   J rele vant for bothD andD  w r t        If none of the metarules above can be applied then X is not required forD   Metarule  The following examples present a set of PIDs in which some of the required variables are identified  The prop erties described by these examples will be generalized to arbitrary PIDs  and they will serve as a basis for a theorem describing the structural constraints nec essary and sufficient for a variable to be required for a given decision variable  In the examples we assume that chance variables  with no immediate predecessors  are given an even prior distribution        in general not sufficient only to consider the variables which directly influence the decision made w r t  D  see Metarule     Example    In the PID I depicted in figure   the chance variable A may be observed before D  More over  A is required for D  since   J is relevant for D  and A is d connected to   J given pred D    Now  since   J is relevant for D also  it follows that ifD D  then A andD may both have an impact on D   Addition ally  if A is observed prior to D then the state of A can be taken into account when deciding onD i e  A is required forD   Example    Consider the PID I depicted in figure     The utility function   J is relevant for D for any admis sible total ordering of I  and since   J is functionally dependent on the chance variable A it follows that A is required forD  as A is incompatible withD there is an admissible total order  with A D   Figure    The figure represents a PID in which the variable A is required forD  This can also be seen by considering the utility func tion specified by Table    assuming that P B A  C  has the properties of P C D    B   E  specified in Ex ample     Figure    The figure represents a PID in which the chance variable A is required forD   Table    The utility function   J  D   C  D        The example above can be generalized to an arbitrary PID I  assuming that I contains a decision variableD and a variable X  If there exists an admissible total order  s t  X occurs before D under   and X is d connected to a utility function   J  relevant for D w r t     given pred D   then X is required for D  we can specify a realization of I s t  the state of X has an impact on the expected utility for   J  Rule    Let I be a PD I and letD be a decision vari  able in I  The variable X is required for D if there exists a utility function   J relevant forD w r t  an ad missible total order  s t  X occurs beforeD under  and X is d connected to   J given pred D   This rule is equivalent to Metarule    as can be seen by expressing the metarule mathematically  X is required for D if P dom    J   D  pred D   is a function ofX  and   J is a utility function relevant for D  The probability function P dom  I J  D pred D   is a function of X if and only if X is d connected to   J given pred D   The following examples show  that in order to identify all the variables required for a decision variable D  it is  The optimal strategy for D relative to A D D  B D  C is given by  n a     d  and  n a     d  which indicate  that D is dependent on   the state of A  A is required forD   In the example above  the conditional probability func tion for B is specified s t  the state of C is revealed if the state of A corresponds to the state of B  and no knowledge is gained on C if the state of A does not correspond to the state of B  Furthermore  the utility function   J relevant for bothD andD  is specified s t  the state of C and the decision made w r t  D influ ences D   Thus  A is required for D  and therefore required forD also  Analogously to the previous examples  we may gener alize this example by considering an arbitrary PID I and an admissible total order for I  where a variableX occurs before a decision variableD and X is required for a future decision D   which has a relevant utility function in common with D  By specifying the real ization of I according to the example above  it follows        Nielsen and Jensen  that the state of X may influence the decision made w r t  D   Moreover  since D and D  have a relevant utility function in common and X is required for D  we have that X is required for D also  the state of X can be taken into account when deciding on D  Example    Consider the PID I depicted in figure    Observing the chance variable A may reveal the state of X  and when deciding on D   the observation of X may change our belief in the state of C  Now  since    J is relevant for both D and Dm the decision made w r t  D has an impact on D    and since the state of A may influence the decision made w r t  Dm  and thereby the optimal strategy for D it follows that the state of A is relevant when deciding on D  That is  A is required for D   i  there exists a decision variable D  D  D   s t     J is relevant for D  w r t     ii  X is required for D  or X is d connected to a chance variable Y E pred  D   given pred  D  and Y is required for D   This rule is equivalent to Metarule    since the obser vation of X can have an impact on a future decision D  if and only if X is required for D  or X influences a variable required for D   The rules   and   represent a set of simultaneous recur sive structural constraints  The recursion terminates because it moves forward in the temporal ordering for each  call   Based on the rules above we present the following theo rem which defines the structural constraints necessary and sufficient for a variable to be required for a given decision variable  Theorem    Let I be an PID and let D be a decision  Figure    The figure represents a PID in which the chance variable A is required for D  This can also be seen by considering a realiza tion of I  where P X A  is a deterministic func tion and    J D C Dm  and P B X  C  correspond to    J  D   C D   and P A  D   B  respectively  see Ex ample   and Table     When evaluating I w r t  A D D  X  D  B Dm c the optimal strategy for D is given by  lv  ai    d  and  lv  a     d  i e  A is D required for D  In the example above  the state of X is determined by the state of A  whereas the state of C is determined by the state of X and B i e  as for the previous examples the state of C is revealed if the state of X corresponds to the state of B whereas no knowledge is gained on C if the state ofX does not correspond to the state of B  Now  consider an arbitrary PID I  and let X denote a variable which occurs before the decision variable D under    and assume that X is d connected to a chance variable Y E pred D   given pred D   If Y is required for D  D  D   and D  has a relevant utility function relevant in common with D w r t   then we can specify a realization  as described in the example above  s t  the optimal strategy for D is dependent on the state of X  That is  X is required for D  Rule    Let I be a PD I and let D be a decision vari able in I  Then the variable X is required for D if there exists a utility function    J relevant for D w r t  an admissible total order   whereX occurs before D and   variable in I  Then the variableX is required for D if and only if Rule   or Rule    and Rule   and Rule    can be applied   Proof  The  if  part of the proof is apparent from the examples above  A mathematial proof of the  only if  part can be performed by closely following the elimi nation process when solving an ID  The basic idea is to postpone the calculations until a maximization is performed in order to calculate a strategy for a deci sion variable  That is  instead of marginalizing out a chance variable a script is produced  and when maxi mizing  the relevant scripts are identified  The details D may be found in  Nielsen and Jensen         Based on the previous rules we present the following rule characterizing the chance variables significant for a given decision variable  this rule is apparent from Rule   and Rule    Rule    Let I be an PID and let D be a decision vari  able in I incompatibel with a chance variable A  Then A is significant for D if there exists a utility function    J relevant forD w r t  an admissible total ordering   whereA occurs immediately before D s t    i  A is d connected to    J given pred D  or ii  there exists a decision variable D  D   D   s t     J is relevant for D  and  a  A is required for D  or b  A is d connected to a chance variable X E pred D   given pred D  andX is required for D     Welldefined Decision Scenarios  Additionally we have the folllowing corollaries as a consequence of theorem     Let I be a PID and let D be a decision variable in I  Then the utility function    J is relevant for D if and only if Rule   or Rule   can be applied   Corollary      Corollary    Let I be a PID and let D be a decision variable in I incompatible with the chance variableA  Then A is significant for D if and only if Rule   can be applied  Corollary    Let I be an ID and let D be a decision  variable in I  Then X is required for D if and only if Rule   or Rule   can be applied      ALGORITHMS       
  quacy of the model and the reliability of data used   After a brief introduction to causal proba  system comes up with  At least there will be kept  Therefore  no expert will blindly accept what the bilistic networks and the HUG IN approach   a critical eye on the data  and mainly one will  I  the problem of conflicting data is discussed   look for conflicts in the data or conflicts with the  A measure of conflict is defined   model   I  MUNIN  Finally it is discussed how to dis  I I I I I I I I I I  and it  is used in the medical diagnostic system tinguish between conflicting data and a rare case   In this paper we present  a  way of building such  a critical eye into a system with a CPN model  Our suggestion requires an easy way of calculating probabilities for specific configurations  We start with a brief introduction to the HUGIN approach      In section   we discuss CPN s and data conflict   Introduction  In section     a measure of conflict is defined  and  it is shown that this measure is easy to calculate It has for many years been widely recognized that  in HUGIN and that it supports a decomposition  causal probabilistic networks  CPN s   have many  of global conflict into local conflicts   Section  virtues with respect to expert systems mainly due  reports on experience with a large CPN  and in     to the transparency of the knowledge embedded  section   we discuss how to distinguish between  and their ability to unify almost all domain knowl  conflicts in data and data originating from a rare  edge relevant for an expert system  Pearl         case   However  the calculation of revised probability dis tributions after the arrival of new evidence was for a long period intractable and therefore an ob      Causal probabilistic Networks  stacle for pursuing these virtues  Theoretical de  and the HUGIN approach  velopments in the   ies have overcome this diffi culty  Kim and Pearl      Lauritzen and Spiegel  A causal probabilistic network  CPN  is con  halter       Schachter       Cooper       Shafer  structed over a  universe   consisting of a set of  With the  states  The variables  The universe is or ganized as a directed acyclic graph  The set of parents of A is denoted by pa A    To each vari  HUGIN approach efficient methods have been im  able is attached a conditional probability table for  plemented for calculation of revised probability distributions for variables in a CPN without di  P Ajpa A     Let V be a set of variables   rected cycles  Andersen et a l          Cartesian product of the state sets of the elements  the results infered from the model rely on the ade   tables are considered as functions and they are de   and Shenoy         The Lauritzen and Spiegel  halter method has been further developed to the HUGIN approach  Andersen et al        Jensen et al       a  Jensen et al      b      As always when modelling real world domains   nodes each node having a finite set of nodes are called  in  V  and is denoted by  The  Sp V    space of V  is the  The probabilitie        noted by greek letters     and   J  If A is a variable  then  A  P A pa A   maps Sp pa A U A   into the unit interval         It is convenient to consider functions which are not normalized and take arbi trary non negative values  So in the sequel   P and   J denote such functions  Evidence can by entered to a CPN in the form of findings  Usually a finding is a statement  that a certain variable is in a particular state  After evidence has been entered to the CPN one should update the probabilities for the variables in the CPN  It would be preferable to have a local method sending messages to neighbours in the net work  However  such methods do not exist when there are multiple paths in the network  The HUGIN approach which is an extension of the work of Lauritzen and Spiegelhalter          Jensen et al     a  Jensen et al     b  repre sents one way of achieving a local propagation method also for CPN s with multiple paths  This is done by constructing a so called junction tree which represents the same joint probability distri bution as the CPN  The nodes in a junction tree are sets of variables rather than single variables  Each node V has a belief table  Pv   Sp V    Ro attached to it  The pair   V   Pv  is called a belief universe  The crucial property of junction trees is that for any pair   U  V  of nodes  all nodes on the path between U and V contain U n V  A belief table is a  non normalized  assessment of joint probabilities for a node  If S C V  then an  non normalized  assessment of joint probabilities for Sp S  can be obtained from  Pv by marginal ization   Ps   E V S  Pv Evidence can be transmitted between belief uni verses through the absorption operation    U   Pu  absorbs from  V   Pv            W   Pw  by modifying  Pu with the functions L  V S  Pv         LW U  Pw  Actually  the new belief function  Pu is defined as    Pu     P u     Evw  Pv  LU V    u     w        E ww  P LU w  Pu  where the product       J is defined as        J  x     x  P x   Based on the local operation of absorption the two propagation operations CollectEvidence and Dis tributeEvidence are constructed  When CollectEv idence in Vis called  from a neighbour W  then V calls CollectEvidence in all its neighbours  except W   and when they have finished their CollectEv idence  V absorbs from them  see figure      I I I I I I    Direction of bsorption   Ca ll of COLLECT EVIDENCE  Figure    The calls and evidence passing in Col lectEvidence When DistributeEvidence is called in V from a neighbour W then V absorbs from W and calls DistributeEvidence in all its other neighbours  Having constructed a junction tree  we need not be as restrictive with findings as in the case of CPN s  Let V be a belief universe in the junction tree  A finding on V is a function Fv     Actually  the more general notion of likelihood can be  entered  Evidence is a function Ev   not pursue this in the present paper   Sp V   I I I I I I I  Sp V           So  a finding is a statement that some configu rations of Sp V  are impossible  Note that the product of two findings f   Sp V           and     Sp W           is a finding f       Sp V U W             and f    corresponds to the conjun cion f    g  Using the HUGIN approach  it is possible to en ter findings to the CPN  or the junction tree    update the probabilities for all variables  and to    with   and   J extended to the relevant space  if necessary    I        We will  I I I I I        I I I I I I I I I I I  I I I I  I I I I  Following the tradition in probabilistic reason achieve joint probability tables for all sets of vari ables which are subsets of nodes in the junction ing to take examples from California  where bur tree  The method has proved itself very efficient glary and earthquake are everyday experiences  we even for fairly large CPN s like MUNIN  see Ole have constructed the following example  sen et al        Andersen et al         When Mr  Holmes is at his office he fre The main theorem behind the method is the fol quently gets phone calls from his neigh lowing  bour Dr  Watson telling him that his burglar alarm has gone off  and Mr  Theorem   Holmes rushing home hears on the ra dio that there has been an earthquake Let T be any junction tree over the universe U  nearby  Knowing that earthquakes have and let  Pu be the joint probability table for U  a tendency to cause false alarm  he then has returned to his office leaving his  a  If CollectEvidence is evoked in any node neighbours with the pleasure of the noise V and  Pv is the resulting belief table  from the alarm  Mr  Holmes has now in then  Pv is proportional to LU  v  Pu  stalled a seismometer in his house with a  b  If further  DistributeEvidence is evoked direct line to the office  The seismometer in V  then for any node W the result has three states  ing belief table  Pw is proportional to LU W U   for no vibrations    Before we proceed with data conflict  we will state an observation proved in Jensen et al       b   but first noted by Lauritzen and Spiegelhalter        in their reply to the discussion     for small vibrations  caused by earthquakes or passing cars      for larger vibrations  caused by ma jor earthquakes or persons walking around in the house    The CPN for this alarm system is shown in figure     Theorem    One afternoon Dr  Watson calls again Let T be a junction tree with all belief tables nor and tells that the alarm has gone off  Mr  malized  and let x        y be findings with prior Holmes checks the seismometer  it is in joint probability P x         y   Enter x          y to state    T and activate CollectEvidence in any belief uni verse for V  Let  l v be the resulting belief universe From our knowledge of the CPN  we would say for V  that the two findings are in conflict  Performing   Then  Z    v  l v   P x          y   an evidence propagation does not disclose that  The posterior probabilities are given in figure    Only in the rare situations of inconsistent data  an CPN s and data conflict   evidence propagation will show that something is A CPN represents a closed world with a finite set wrong  The problem for Mr  Holmes is whether of variables and causal relations between them  he should believe that the data originate from a These causal relations are not universal  but re rare case covered by the model  or he should reject flect relations under certain constraints  Take for that  From a CPN m pdel s point of view there is no example a diagnostic system which on the basis of blood analysis monitors pregnancy  Only diseases difference between a case not covered by the model relevant for pregnant women are represented in and flawed data  So what we can hope for to pro the model  If the blood originates from a man  the vide Mr  Holmes with is a measure indicating pos constraints are not satisfied  and the case is not sible conflicts in the data given the CPN  In MUNIN  Olesen et al        an attempt to covered by the model   A similar situation appears incorporate conflict analysis in the CPN is made  if the test results are flawed  e  g  red herrings            This is done by introducing  other  states and  other  variables  In the example of Mr  Holmes  alarm system  an  other  variable covering lighten ing  flood  baseballs breaking windows etc  could be introduced to represent unknown causes for the alarm to go off  and the Burglar variable could have an  other  state covering Mr  Holmes  mis tress having forgotten the code for switching off the burglary alarm  Though this approach is claimed to be fairly successful  it raises several problems  First of all there is a modelling problem  The effect of an  other  statement is hard to model without know ing what  other  actually stands for   What should the conditional probabilities be  In fact  these Burglary   I B             Earthquake  E         probabilities were in MUNIN constructed by feed ing the network with conflicting data and thereby tuning the tables as to make  other  light up ap E  l s propriately  y N A second problem is that conflict in data is a N                        global property  and the introduction of  other  B statements in the CPN gives only a possibility of y                       evaluating evidence locally  In order to combine Seismometer the local  other  statements to a global one  the CPN has to be extended drastically  E  I A This leads to the third major problem  which N y is more of a technical kind  The introduction of N                  other  statements to the CPN can cause a dra B matic increase in the size of the junction tree  Be y                  Alarm sides  the technique with  other  states is hard to use if the variables are not discrete  Figure    Mr  Holmes  Alarm system with seisAnother approach has been suggested by mometer  Habbena          It consists of calculating a sur prise index for the set of findings  Essentially  the surprise index off  V            is the sum of the probabilities of all findings on V with probabilities no higher thanf s  Habbena suggests that a threshold between    and     should be realistic  In the seismometer E  I E B case  the surprise index for  a  s  is     However  N y the calculation of a surprise index is exponential in N         the number variables in V and must be considered B as intractable in general  y       Figure    Joint probabilities for earthquake and   The conflict measure conf burglary posterior to a    alarm   Y  and s    Seis Our approach to the problem is that correct find mometer       ings originating from a coherent case covered by the model should conform to certain expected pat terns  If x      y are the findings  we therefore  I I I I I I I I I I I I I I I I I I I        I I I I I I  I I  should expect  P x     y      P x   x     x  P y   Hence we define the conflict measure conf as   conf x   y   log  P x  X XP y  P  X     y        where log is with base     This means that a positive conf x    y  is an in dicator of a possible conflict  For the data in section   we have conf a  s          Using theorem    conf x    y  is very easy to calculate in HUGIN  The prior probabilities P x   P y  are available before the findings are entered  and P x   y  is the ratio between the prior and the posterior normalizing constant for any belief universe   I  P x  y   z  u   consists of two sets of findings  namely  x y z  and   u v   Since the product of findings is also a finding  we can say that the two findings x   y   z and u   v meet in V  The conflict in the data meeting in V is therefore composed of the conflict between x y z and u v   the conflict inside  x y z  and inside  u v   It is easy to show that  conf x  y z u v   conf x   y   z  u  z   conf x  y z    conf u v  Furthermore  as indicated at figure    P  x  y   z  and P u   v  can be calculated as ratios between prior and posterior normalizing constants  and therefore conf x y z  and conf u v  as well as conf x   y   z  u   z  are easy to calculate  In general  If evidence is propagated to any belief universe U from neighbours V    W originating from findings  v     v           w    w   respectively  then  vl  conf v    v     W    W       I I  conf v     v     w       w      conf v   v         conf  w    w   All terms are in HUGIN easy to calculate by use of Theorem    We call conf v    v    w     w   the global conflict and conf v      v     w       w   the local conflict  The calculation of conf has been implemented in HUGIN to follow the calls of CollectEvidence  The overhead to the propagation methods m terms of time and space is neglectable   P I  y z   I I t  I  I I I I  t  y  t l  t u  t  v  Figure    A junction tree with findings x  y  z  u v entered  Theorem   provides the joint probabili ties indicated at nodes V  U  W  and W   The conflict analysis can be further refined  In figure   is shown a junction tree with findings x y  z  u  v entered  If CollectEvidence is evoked in the node V  then the evidence flowing to V     Example  APB MUNIN  The conflict measure has been tested on small fictions examples and on a large subnetwork of MUNIN  namely the network for the muscle Ab ductor Pollicis Brevis  APB   The network is shown in figure    The rightmost variables in figure   are finding variables  This means that evidence is entered at the right hand side of the CPN and propagates to the left  However  as described in section    the propagation takes place in a junction tree of belief universes  In the test  CollectEvidence was called        I I I I I I I     The DAG in ductor Pollicis Brevis   Figure  MUNIN for  I  Medianus Ab  The attached numbers in  entered  see figure      I  in universe number     and the call propagates  I  dicate the belief universe to which the finding is  recursively down the junction tree  In figure   is shown the junction tree   I   Only belief universes  where evidence meet are shown   First we asked the model builder  Steen An  I  dreassen  to provide us with a complete set of nor mal findings  They were entered  and global and universal conflict values were calculated  The re sults are shown in figure a global conflict of           for  I  Surprisingly we got the entire set of find  ings and apparently the conflict can be traced to  I  belief universe no      Further  the evidence from    and    looks conflicting   Returning to Steen  Andreassen with our surprise  he recognized that  I  he had given us a wrong value for the finding qual mup amp  which was entered to belief uni verse     It should have been      J LV  rather than      pV   We entered the corrected finding and got a global conflict value        for the entire set of find  ings with local and subglobal values ranging be tween     and         Then typical findings for a patient suffering from moderate proximal myopathy were entered  As can be seen in figure    this resulted in large  Figure    The part of the MUNIN junction tree for APB where evidence meet  The numbers are labels of belief universes  Bold numbers indicate entrance of findings   I I I I         I I  negative conflict values confirming the coherence of the findings   I I I I I I I I I  Figure  I  I I I I I  Typical findings for a patient s uffer ing  Finally  we simulated hypothesizing   We en  tered a set of findings originating from a healthy patient  and we also entered the disease state  I I      from moderate proximal myopathy entered    moderate proximal myopathy   shown in figure Figure    The conflict measures from the first test example  The italiced values are local conflict val  ues and the bold figures are the global ones       The result is  The disease finding is entered to  belief universe     and it can be seen that the dis ease does not contradict a couple of normal find ings  but indeed the whole set      Conflict or rare case   It can happen that typical data from a very rare case might cause a high value of conf  In the case of Mr  Holmes  alarm system a flood  with proba       could be entered to the CPN explaining the data  see figure      For this system we get conf a  s         It is  bility  still indicating a possible conflict  The reason is that though P a  s  is possible  it is under the        rare  Mr   condition of flood   of the window   Holmes looks out  It rains cats and dogs  and he  has resolved the problem  the model gives a  P Flood    I  n ew            The problem above call s for more than a pos analysis    refined conflict  sibility for  We need a  method to point out whether a conflict  can  be ex  plained away through a rare cause    x      y  be findings with a positive conflict H be a hypothesis which could explain the findings  conf   x          y  H      Let  measure  and let  We have  con  r  x          y  H     log  P x  x       x P y  x P H  P  X      Y H       conf x       y   log  P H   P HIx     y    og  then  P Hjx       y  P H   H can    conf  x   explain away the  variables  in  conflict   t he flood example the  value is       This means that there is no need Figure      Findings for a healthy patient  and  the hypothesis  moderate proximal myopathy  en t er ed   for manually to formulate explaining hy pot hesis in terms of states of variables  More complex hy    pot hesis can also be monitored if they can be ex  pressed as findings      Conclusion        y      log  P    P  Y  X        y  x        x  has many promising properties  It is easy to cal  culate in HUGIN  it is independent of the order in  which fi nd ings are entered   it can be used for both global and loc al analysis of conflicts in data  and  it has a natural interpretation which supports the  usual mental way of inspecting data for flaws or for originating from sources outside the scope of the current investigation  Figure     Mr  Holmes  revised CPN   I I I  I I I I  The measure o f confli ct  con f   x   I  I          y   The left hand ratio can be monitored automat ic ally for all  I  I  This means that i f     I  However  still some practical and theoretical work is needed in order to understand the signifi cance of specific positive conflict values  Also  the  I I I I I I        I I I I I I I I I I I I I I I I I I I  detailed conflict analysis a it is nowconnected to Kim  J  H  and Pearl  J          A computational the structure of the junction tree rather than to model for causal and diagnostic reasoning in infer the CPN itself  This should be relaxed  ence systems  In Proceedings of the  th Interna tional Joint Conference on Artificial Intelligence       Acknowledgements            Lauritzen  S  L  and Spiegelhalter  D  J         P  We thank Steffen Lauritzen for many valuable dis Local computations with probabilities on graphi cussions on the subjects of this paper  and Steen cal structures and their applications to expert sys Andreassen for helping with the MUNIN experi tems  with discussion   J  Roy  Statis  Soc  B  ment               Olesen  K  G   Kjrerulff  U   Jensen  F   Jensen  F  V   Falck  B   Andreassen  S  and Andersen  S  K          A MUNIN network for the median nerve Andersen  S  K   Jensen  F  V  and Olesen  K  G    a case study on loops  Applied Artificial Intel         The HUGIN core  preliminary consider ligence             Special issue  Towards Causal ations on systems for fast manipulations of prob AI Models in Practice  abilities  In Proceedings of Workshop on Induc     
    The paper deals with optimality issues in con  these labels are called separators  see Figure la    nection with updating beliefs in networks  We address two processes  triangulation and con struction of junction trees  In the first part     network   In the second part  we argue that  any exact method based on local calculations must either be less efficient than the junction tree method  or it has an optimality problem equivalent to that of triangulation      attaching a pote ntial to all separators  initially  the neutral potential consisting of ones    we give a simple algorithm for constructing an optimal junction tree from a triangulated  giving all links in the junction tree a label con sisting of the intersection of the adjacent nodes     letting the nodes communicate via the separa tors   a message from U to V with separator S  has the form that  Pu is marginalized down to S  resulting in     Psis placed on the separator and   S   S  is multiplied on v  see Figure  b    INTRODUCTION  The junction tree propagation method  Jensen et al         Lauritzen and Spiegelhalter        is designed for propagation in Markov networks    cjl  S  cjl S   cjl  S   an undirected graph with discrete variables as nodes     for each clique  U  in the graph there is a poten  tial  Pu  which is a non vanishing function from the set of configurations of  U  to the set of non  negative reals    a   The compilation part of the method is to   FIGURE     triangulate the graph  i e   add extra links such that every cycle of length greater than three has a chord      construct   a  A junction tree   b  Message passing in junction trees  It is so  that after a finite number of message passes  form a potential  Pu for each c lique  U  of the tri  angulated graph     b   a  junction tree over the cliques   A junction tree over the cliques is characterized by the  so called junction tree property  For each pair U  V of cliques with intersection S  all cliques on the path between U and  V containS   The propagation part of the method consists of  between neighbours in the junction tree  each po tential in the junction tree holds the  possibly non normalized  marginal of the joint probability distribu tion for the entire set of variables  In fact  the message passing can be organized so that it is sufficient with exactly one pass in each direction of the links in the junction tree  Therefore  in complexity considerations for propagation in junction trees  one can associate a local measure  C U  V  to  links   U  V    where  C U  V   indicates time space consumption for the two passes         Optimal Junction Trees  The compilation is not deterministic  Markov net works may have several different triangulations yield ing different sets of cliques  and a triangulated network may have several different junction trees  We therefore would like to have algorithms yielding optimal trian gulations and optimal junction trees with respect to complexity  However  the optimality problem for tri angulations isN J  complete  Arnborg et al          In the first part of the paper  we address the optimal ity problem for junction trees given the triangulated graph  and we present a simple algorithm which is quadratic in the number of cliques  In the last section  we address the triangulation pro cess and ask the question whether it may be possible to come up with a propagation method which does not contain anN J  hard optimality problem  The answer is discouraging  We show that any local calculation method must involve a hidden triangulation  and we use this to conclude that the method is either less ef ficient than the junction tree method  or it has an N J  hard optimality problem     JUNCTION TREES AND MAXIMAL SPANNING TREES  Throughout the remainder of the paper  we consider a  triangulated connected graph G with clique set e  The cliques of G are denoted b I the letters U  V  W  ll   etc  We shall not distinguish between a clique and its set of variables  So we talk of the intersection of cliques meaning the set of variables common to the cliques  Intersections are denoted by letters R S  R   etc  Definition   The junction graph for G has e as nodes  and for each pair U  V of cliques with nonempty inter section R there is a link with label R  Each link has a weight which is the number of variables in the label  Theorem   A spanning tree for the junction graph of G is a junction tree if nd only if it is a spanning tree of maximal weight   Theorem   has been proved independently by Shibata        and Jensen         Here we will give a proof much simpler than the o tiginal ones  Before giving the proof  we shall recall two algorithms for the construc tion of maximal spanning trees             cb FIGURE     Paths in T and T   Prim s algorithm constructs a sequence To   Tn  of maximal spanning trees for the subgraph deter mined byN       Algorithm    Kruskal   Choose successively a link of maximal weight not pro ducing a cycle  Kruskal s algorithm works with a forest of partial max imal weight spanning trees  Whenever a link is cho sen  two partial trees are connected into a new partial spanning tree of maximal weight  Both algorithms result in maximal weight spanning trees  and each maximal weight spanning tree can be constructed through any of the two algorithms   Proofs can be found in many textbooks on graph algorithms  e g    Goudran and Minoux        and  McHugh          Proof of Theorem    Let T be a spanning tree of maximal weight  Let it be constructed by Prim s al gorithm such that T    Tn  T is a sequence of partial maximal weight spanning trees       Assume that T is not a junction tree  Then  at some stage m  we have that Tm  can be extended to a junc tion tree T  while Tm    cannot  Let  U  V  with la belS be the link chosen at this stage  V E Tm      see Figure     Since Tm     cannot be extended to a junction tree  the link  U  V  is not a link in T  So  there is a path in T  between U and V not containing  U  V   This path must contain a link  U   V   with labelS  such that U   E T m  and V   j  Tm   see Figure     Since T   is a junction tree  we must haveS S   and sinceS was chosen through Prim s algorithm at this stage  we also have S l I           Hence  S      Algorithm    Prim      Put N  U   where U is an arbitrary node   Now  remove the link  U   V   from T  and add the link  U  V   The result is a junction tree extending Tm      contradicting the assumption that it cannot be extended to a junction tree       Choose successively a link  W  V  of maximal weight such that W E N and V  j  N  and add V toN   Next  let T be any non maximal spanning tree  We shall prove that T is not a junction tree  Again  let T    T   be a sequence of maximal trees con                     Jensen and Jensen  FIGURE    The thinning task at stage  i     in Kruskal s algorithm   structed through Prim s algorithm  Let the construc  trees of maximal weight  Note that any thinning at a  tion be so that a link from  given stage will result in the same connected compo  ble  Let  m  T is chosen whenever possi  be the first stage where this is not possible   and let   U  V  with separator S be the link actually chosen  U E Tm V  Tm   In T there is a path be tween U and V  As in the first part of the proof  we have that this path contains a link  U    V    with la belS  such that U  E Tm and V   Tm  see Figure     Since  U    V   could not be chosen  we have S I  I   S l I  and thereforeS contains variables not inS    Hence  T does not satisfy the junction tree condition         OPTIMAl JUNCTION TREES  W henever the junction graph has several spanning trees of maximal weight  there are accordingly several junction trees  Assume that there is a real valued mea  sure on junction trees yielding a priority among them  and assume that this measure can be decomposed to a local measure  C U  V   call the measure a  cost   attached to the links   We  We may also assume that  the entire measure is strictly increasing in the local measures  and that an optimal junction tree is one of minimal cost   nents  and therefore the thinning chosen has no impact on the next stage   Hence  if we in the construction  have a secondary priority  cost  say   we can perform the thinning by using Kruskal s algorithm according to cost  In this way we will end up with a maximal weight spanning tree of minimal cost  see Figure       We conclude these considerations with  Theorem    Any minimal cost juncti on tree can be constructed by successively choosing a link of max imal weight not introducing cycles  and if several links may be chosen then a link of minimal cost is selected   A proof of Theorem stages      is an induction proof over the  The induction hypothesis is that at the end  of each stage  the forest consists of partial maximal distance junction trees   Remark    An analoguous algorithm based on Prim s  algorithm will also construct minimal cost junction trees   Let us take a closer look at the construction of junction trees through Kruskal s algorithm  Let w          Wn be the different weights of  G in  decreasing order  The al  gorithm can be considered as running through n stages  Corollary   All juncti on trees over the same triangu lated graph have the same separators  also counting multiplicity    characterized by the weight of the links chosen  At the end of stage  i   all links possible of weight w   have been chosen  and a forest  T              T            Wi  of partial  Proof   Consider stage i     Figure       A cycle can be  broken by removing any link of weight Wi    If   U  V   maximal weight spanning trees has been constructed   with separatorS is removed  then all separators in the  Now  the task at stage  remaining paths between  i     can be considered in the fol  lowing way  Add all links of weight Wi    to the forest   and break the cycles by removing links of weight Wi       Any thinning will result in a forest of partial spanning  U  and  V  must contain S   This means that any separator of weight Wi    on these paths must equalS  By thinning we therefore remove the same separators       Optimal Junction Trees         For each separator  establish links to all cliques and separators containing it     For each separator  with multiplicity n   choose n    links to supersets without introducing cycles   Theorem   Any minimal cost Almond tree can be constructed by successively choosing links for sepa rators of maximal weight  and if several links may be chosen  take one of minimal complexity   A proof of Theorem   b    a     is  an induction proof along the  same line as a proof of Theorem      FIGURE      a  Contraction of the junction tree from Figure     THE NECESSITY OF TRIANGULATION   b  An Almond tree         for constructing optimal junction trees given the tri  In the former sections we gave an efficient algorithm  ALMOND TREES  angulated graph  Thereby all steps from DAG to junc  Almond and Kong         suggest another type of junc  tion tree  Compared to the junction trees in  Jensen et al            they give some reduction in computa  tional complexity   tion tree is covered by efficient algorithms yielding an optimal output except for the triangulation  Since this problem is N P complete  we cannot hope for an efficient algorithm yielding an optimal triangulation  It appears that a one step look ahead heuristic pro  Observation   If n links have the same separator  the  vides the best triangulations  An alternative propaga  communication scheme can be contracted  Figure  a    tion scheme is conditioning  Pearl           The N P  complete part of conditioning is the determination of In junction trees  each separator holds exactly one po  a cut set for the DAG  and Becker and Geiger  tential table where the marginal last communicated  have given an algorithm which guarantees a cut set  is stored   space no larger than the square of the space for an  In contracted junction trees  a separator  with n neighbours must hold at least n        potential  optimal cut set  Other schemes exist  like  e g   arc         however  as has been shown         all known methods do in fact  tables to store marginals communicated from neigh  reversal  Shachter   bours  This means that there is no saving in space   by Shachter et al   There is  however  a saving in time  since a number of  contain a hidden triangulation   marginalizations are avoided           Since belief updating in Bayesian networks is N  P hard  Observation   If a separator is a subset of another sep  arator  they can be linked  Figure   b     Cooper           there is not much hope of finding a  scheme avoiding an N  P hard step  However  Cooper s result does not yield that any scheme will contain such a step   Cooper showed that through belief updat  The type of calculations are the same for links between  ing  the satisfiability problem for propositional calcu  separators as for links between separators and cliques   lus  can  be solved  but it may still be so that a search  S   for an optimal structure for belief updating is poly  the number of supersets to which it shall be linked  and for each link  S  S    we can associate a local cost  nomially solvable  Note namely that the space of the  Due to the corollary  we know for each separator  C S  S     Also  new schemes are proposed  Zhang and Poole   Junction trees simplified through these two observa tions we call  cliques are exponential in their presentation   Almond trees   The construction of an  Almond tree may go as follows          which may seem as if they avoid the triangula  tion problem  We will in this section argue that  any  scheme for belief updating  meeting certain require ments  will contain a hidden triangulation  Then  if    From the triangulated graph  the set of cliques  the complexity ordering of the hidden triangulations  and the set of separators  including multiplicity   follows the ordering in the original scheme  we can con  This can be done through elim  dude that if the scheme has a polynomially solvable  ination in the triangulated graph  but it is not  optimality problem  then the junction tree method ei  important for our considerations   ther provides more efficient solutions or   P  is established      N  P         Jensen and Jensen  The considerations to come are somewhat specula tive and at places they need further precision  Hence  we call the results  statements  rather than theorems  However  a reader looking for alternative propagation methods can use them as guidelines preventing inves tigations of several alternatives  FIGURE     Specifications  A graph representing a general propagation task   U  A          B  is a universe consisting of a finite set of discrete variables  The joint probability P U  is a distribution over the configurations Xu  Ax    x B     A local representation of P U  consists of a set  P U          P Un    where U          lin is a covering of U  and P U    is the marginal distribution of Ui  A local representation can be visualized by a graph G with the variables as nodes and with a link between two variables if there is a Ui containing both  G is called the representing graph  The propagation task can be formulated as follows  Let P   Ui  be substituted forP Uil  ifP  U  P U  x P  Ui  P Ui  is well defined  then calculate the new marginals P  U          P  Unl    By a scene for a propagation task  we understand a universe U together with a covering U         lin such that the covering equals the cliques in the representing graphs  An instance of a propagation task is a pair  G  P   where G is an undirected graph  and P is a set of marginals of a joint distribution P U  to the cliques of G  Let U be a universe  By a local method on U  we un derstand an algorithm working only on subsets of U  More precisely  The algorithm consists of a control structure and a fixed set Pr         Pr   of proce dures such that each Pri only processes information on Vi c  U  We call Vi the scope of Pri  The repre senting graph G  for a local method is defined as the graph with U as nodes  and with links between vari ables if there is a scope containing them  Notice that the cliques of G   need not be scopes  We have defined a local method such that the control structure mainly consists of controlling message pass ing between procedures  Note that between Pr   and Pri only information on Vi n Vi is worth passing   First  we shall transform the problem to propositional calculus  Lemma   Let P U          P Uml be projections of the joint probability table P U   Let Pos U  be the table of possible configurations of U   Pos u        if P u      otherwise     if P  ud     otherwise  Define Pos U    as  Pos u        Then Pos Ui    if and only if Ui is a projection of a possible configuration     Proof  Since P U    is the marginal of P U   we have that P u        if and only if ut is the projection of at least one configuration with positive probability    The lemma shows that any scheme for belief updating has the calculus of possible configurations in proposi tional calculus as a special case  So  if we can prove Statement   for this calculus  we are done  We shall start with an example which is the corner stone of the proof  Example   Let the graph in Figure   represent a gen eral propagation task over the propositional calculus  and let Pas be the potential giving   for possible con figurations and   for impossible ones   Let PrAs  PrAc  Prsn  Prnc be procedures for solv ing the task  the index indicates the scope  see Fig ure      A general local belief updating method for a scene represented by G is a local method solving the propa gation task for each instance  G  P    We shall construct an instance which cannot be solved by the procedures  For each variable we only use the first two states  This means that all other states are impossible   We aim at the following   Initially  we have for i  j        Statement    Let G represent a scene  and let a gen eral local belief updating method be represented by the graph G   Then G  contains a triangulation of G   Pas  at  bj    Pas Ut  Cj     Pos bi  dj    Pos ci dj  l          for all i  j if and only if i if and only if i for all i  j        j j   Optimal Junction Trees       Proof of Statement    Assume that G   does not contain a triangulation of G  Then there is a cycle C in G such that the subgraph of G   consisting of the nodes in C is not triangulated  Let C  be a chordless cycle of length greater than three in that subgraph  Let A           An be the nodes of C    FIGURE     The scopes for the procedures and the communication channels  That is  A and C as well as B and D are forced into the same state  and everything else is possible  Note that the Pas relations above are projections of the Pas relation over the universe   if and only if Pos   U   bi      Pos   ai  ck     Pos bj  df      Pos ck  de         Now  assume we get the information that the config urations  a   b   and  a   b   are impossible  This is equivalent to replacing the relation Pos ai  bj  by Pos  ai  bj         if and only if  i     j   and i j       Now  the propagation task is to determine Pos   A  C   Pos    B   D   and Pos    C  D  such that these local rela tions are projections of the unique universal relation Pos  A  B  C  D   satisfying the relations Pos  A  B   Pos A  C   Pos B  D   and Pos C  D   Clearly  Pos  ai bi ck dt  l if and only if i j e  and therefore Pos  ck de  l if and only    k     k             if  The tool for achieving this result is the set PrA s   PrAc  Prso  and Prco of procedures  Since PrAB can only process information on the variables A and B  and PrAc can only process information on A and C  then the only valuable information to communicate be tween the two procedures is information on A  see Fig ure     That is  between Pr  and Prz with scopes V  and V   respectively  only information on V   n V  need to be communicated  The new relation Pos  A  B  in troduces a constraint between the state of A and the state of B  but since only information on A alone and B alone can be communicated  the constraint cannot be communicated to Prc   Note that if a cycle contains more than   variables  the construction can be extended by clamping the states of further intermediate variables   We now can construct an instantiation  which cannot be propagated correctly      Let a configuration be possible if and only if its projection to A  x    x An is possible      Perform the construction as shown in the example    By the proof of Statement    we see that it can be generalized to systems with other uncertainty calculi like  e g   Dempster Shafer belief functions or fuzzy systems  In fact  the reasoning can be applied to any calculus having propositional calculus as a special case  An axiomatization of these possible calculi is outside the scope of this paper  but the axioms in  Shenoy and Shafer        form a good starting point  Concerning complexity we still have a couple of loose ends  Although a general scheme involves a hidden tri angulation  the computational complexity needs not be of the same kind as for the junction tree scheme  In the junction tree scheme the complexity is propor tional to the number of configurations in the cliques  Therefore a general local scheme has an equivalent computational complexity if it is proportional to the number of configurations in the scopes  This is the case if each configuration has an impact on the mes sages sent in the algorithm  In this paper we shall not give sufficient conditions for this to hold  The second loose end has to do with optimality  A gen eral scheme is  e g   to work with P U  only  This cor responds to working with the complete graph over U  This scheme has a trivial optimality problem  but the junction tree method can do much better even for sub optimal triangulations  Therefore we conclude   Statement   If a general local propagation scheme has a complexity at least proportional to the num ber of configurations in the scopes  and its opti mality problem can be solved in polynomial time  then either the junction tree scheme can do better or  J    N J    Acknowledgements The work is part of the ODIN project at Aalborg Uni versity  and we thank our colleagues in the group for inspiring discussions  The work is partially funded by the Danish Research Councils through the PIFT programme         Jensen and Jensen  
 Decision theoretical troubleshooting is about minimizing the expected cost of solving a certain problem like repairing a complicated man made device  In this paper we consider situations where you have to take apart some of the device to get access to certain clusters and actions  Specifically  we investigate troubleshooting with independent actions in a tree of clusters where actions inside a cluster cannot be performed before the cluster is opened  The problem is non trivial because there is a cost associated with opening and closing a cluster  Troubleshooting with independent actions and no clusters can be solved in O n  lg n  time  n being the number of actions  by the well known P over C algorithm due to Kadane and Simon  but an efficient and optimal algorithm for a tree cluster model has not yet been found  In this paper we describe a bottom up P over C O n  lg n  time algorithm and show that it is optimal when the clusters do not need to be closed to test whether the actions solved the problem      INTRODUCTION  In decision theoretical troubleshooting we are faced with a problem that needs to be solved by applying solution actions and by posing questions that gather information about the problem  The premise is that after each action we can cost free observe whether the problem was solved  The domain is assumed to be uncertain  that is  solution actions may be imperfect and information might be non conclusive  Given a model that describes the uncertainty and the cost of actions and questions  the goal is to compute a strategy for solving the problem with the lowest expected cost   If the model has the following assumptions   a   b   c   d   the problem is due to a single fault  different actions address different faults  costs do not depend on the previous history  and there are no questions   then the problem is solvable in O n  lg n  time where n is the number of actions  This algorithm is the wellknown P over C algorithm by  Kadane and Simon        which was first brought into a troubleshooting context by  Kalagnanam and Henrion         Furthermore  if any of the above assumptions are relaxed without restrictions  the problem becomes NP hard  Vomlelova         If assumption  a  is replaced with an assumption about multiple independent faults  an O nlg n  P over C like algorithm also exists  Srinivas         Troubleshooting without assumption  b  can also be somewhat simplified due to the dependency set algorithm of  Koca and Bilgic          Langseth and Jensen        proposed to relax assumption  c  slightly by considering a model where the actions can be partitioned into a flat set of socalled cost clusters  see Figure     The idea is that in order to access an action in a bottom level cluster Ki   you need to pay an additional cost Coi and to close the cluster you have to pay an additional cost Cci   Thereby it is possible to model e g  the repair of complex manmade devices where you need to take apart some of the equipment to perform certain actions  If we can determine whether an action has solved the problem without assembling the cluster first  Langseth and Jensen said that the cluster has inside information  otherwise the cluster is without inside information  They furthermore describe heuristics for both problems  In this paper we present a proof of correctness of their algorithm for the problem with inside information  We furthermore extend the model to a tree of clusters and give an O n  lg n  time algorithm that is proved optimal   Warnquist et al         describe a slightly more general cost cluster framework  but they do not address the issue of finding an efficient algorithm    conditional cost C    of an action  given evidence  is given by C   CK   if   CA   and by C if   FA     Cluster     Co   Cc   Cluster            Co   Cc   Cluster         Co   Cc   Cluster         Figure    Example of the flat cost cluster model  To open a cluster Ki we pay the cost Coi   and to close a cluster we pay the cost Cci       PRELIMINARIES  In this paper we shall examine troubleshooting problems where the following model parameters are given  F    f            fm   is a set of faults describing the possible causes to the problem  For each fault f  F  we have a probability P f  describing how likely it is that f is present when troubleshooting begins  A                n   is a set of actions that can potentially solve the problem  Each action  has two possible outcomes  namely    yes  the problem was fixed  and    no  the action failed to fix the problem   Each action  has a positive cost C describing the resources required to perform the action  Finally  each action has an associated success probability P    yes   f   the probability of solving the problem by performing the action when f is present  The set of actions A can be partitioned into       clusters K  K            K  where cluster K is the top level cluster and the remaining are bottom level clusters  The cost of opening a cluster Ki is Coi and the cost of closing it again is Cci   We define CKi   Coi  Cci   An action  belongs to cluster K    During the course of troubleshooting we gather evidence i meaning that the first i actions failed to solve the problem  and we have by assumption P       x y because the device as Sy is faulty  We also write  shorthand for i x  i   no   FA   is the set of free actions consisting of all actions  excluding those already performed  from open clusters given evidence   CA   is the set of confined actions consisting of all actions from closed clusters  Note that we have FA    CA    A and FA    CA      for all evidence   By performing an action  from CA   we pay the cost CK   because at this point we are certain that we must both open and close the cluster  In that case  is called an opening action  for K     and all remaining actions of K   are released by removing them from CA   and adding them to FA    The  Throughout this paper we uphold the following simplifying assumptions about the model     The single fault assumption   Initially the problem is known to exist and it is due to the presence of a single fault from F     The idempotent action assumption   Repeating a failed action will not fix the problem     The carefulness assumption   By performing an action or testing the system  we never introduce new faults     The independent actions assumption   Different actions address different faults     The costless system test assumption   Checking whether the problem still exists after performing an action can be done at a negligible cost     The inside information assumption   All clusters have inside information  Due to the single fault assumption we may compute the repair probabilityPof an action given evidence  as P    yes       fF P    yes   f   P f      In a few places we shall abbreviate P    yes     with P       Due to the independent actions assumption P    P     P       P      for all evidence  not involving  or   We shall therefore abbreviate the initial repair probability P    yes  as P   A troubleshooting sequence is a sequence of actions s   h            n i prescribing the process of repeatedly performing the next action until the problem is fixed or the last action has been performed  We shall write s k  m  for the subsequence hk           m i and s k  m  for the subsequence hk             m  i  The index of an opening action in a troubleshooting sequence s is called an opening index  and the set of all opening indices for s is denoted Z with Z              n    Z       To measure the quality of a given sequence we use the following definition  Definition    Let s   h            n i be a troubleshooting sequence  Then the expected cost of repair  ECR  of s is given by ECR  s     n X    P i   Ci  i       i    Formally  our optimization problem is to find a troubleshooting sequence with minimal ECR  Without cost clusters  the problem is easily solved due to the theorem below    Theorem    Kadane and Simon          Let s   h            n i be a troubleshooting sequences in a model without cost clusters  Then s is optimal if and only if Pi Pi  Ci C i  for i              n        If costs are not conditional and actions are independent  the lemma below leads directly to the P over C algorithm  Lemma    Jensen et al           Let s be a troubleshooting sequence and let x and x   be two adjacent actions in s  If s is optimal then    Cx  x         P x   x   Cx    x    Cx    x         P x     x        Cx  x    a     no     With assumption          and   we may simplify computations and notation somewhat because of the following result  Proposition    Let s   h            n i be a troubleshooting sequence  Then the ECR of s may be computed as   i  n X X Pj    Ci  i        ECR  s    j    i    where     Pi   j    Pj      P i     This easy computation of the probabilities can be dated back to  Kalagnanam and Henrion        and  Heckerman et al          Thus  due to our assumptions  we may completely ignore F  P f   and P    yes f  once the repair probabilities have been computed  Therefore  we mainly use P in the rest of this paper  Using the set of opening indices Z  we can rewrite the definition of ECR of a sequence s to   i  X X ECR  s    Ci     Pj  i    j        X zZ  CK z        z  X   Pj       j    where we have decomposed the terms into those that rely on the cost of performing actions and those that rely on the cost of opening and closing a cluster  We define the efficiency of an action  given evidence  as ef        P  C     and we write ef   for the unconditional efficiency P  C   Finally  the cluster P efficiency of an opening action is cef     C  CK      Lemma    Let s   h            n i be an optimal troubleshooting sequence with opening indices zi  Z  Then the       subsequences s     z     s zi   zi     i                     and s z    n   are ordered with respect to descending efficiency  Proof  Between opening indices the costs are not conditional  and so we must sort by descending ef   to be optimal  We have now established that given the opening index for each cluster  it is a simple task of merging ordered sequences to establish an optimal sequence  The difficult part is to determine the opening indices      THE EXTENDED P OVER C ALGORITHM  The standard P over C algorithm works by sorting the actions based on descending efficiency  The extended algorithm works in a similar manner  but it also considers the efficiency of a cluster  if a cluster is more efficient than all remaining actions and clusters  we should perform some actions from that cluster first  Definition    The efficiency of a cluster K is defined as P M P P ef K    max MK CK   M C and the largest set M  K that maximizes the ficiency is called the maximizing set of K  The quence of actions found by sorting the actions of maximizing set by descending efficiency is called maximizing sequence of K   efsethe the  It turns out that it is quite easy to calculate the efficiency of a cluster  The following result is a slightly more informative version of the one from  Langseth and Jensen         Lemma    Let K be a cluster  Then the maximizing set M can be found by including the most efficient actions of K until ef K  starts decreasing  Furthermore  all actions  in the maximizing set M have ef    ef K  and all actions   K   M have ef     ef K   The algorithm is described in Algorithm    If n denotes the total number of actions  we can see that line   takes at most O n  lg n  time  Once the actions have been sorted  line     takes at most O n  time  The loop in line      can be implemented to run in at most O n  lg         time by using a priority queue for the most efficient element of A and the most efficient element of each cluster  Thus the algorithm has O nlg n  worst case running time  In the next section we prove that the algorithm returns an optimal sequence    Algorithm   The extended P over C algorithm  Langseth and Jensen           function ExtendedPOverC K  K            K       Sort actions of K and all Ki by descending ef      Calculate ef Ki   and maximizing sets Mi    for all i                    Let Kclosed    Ki   i                     Let A         K or   Ki   Mi for some i     Let s   hi    repeat    Let  be the most efficient action in A     or cluster in Kclosed     if  is an action then     Add action  to s     Set A   A          else     Add all actions of the maximizing set     of cluster  to s in order of     descending efficiency     Set Kclosed   Kclosed          end if     until Kclosed    and A        Return s     end function  Proof  We shall use the fact that for positive reals we have b a a b a    c d c d c for any weak order   e g   and    Let M consist of actions in K such that ef M  is maximized  Then ef M  equals P P M    P   P M P P P   CK   M C CK   M    C   C    SP   P P   SC   C C  where  is chosen arbitrarily  Let furthermore   K   M  We shall prove P P P    C C C which implies the theorem  We first prove the leftmost inequality  Because ef M  is maximal we have SP   P SP P SP  which is equivalent to  SC   C SC C SC which again is equivalent to  Example    We consider a model with three clusters  where K is the root cluster and K and K are the bottom level clusters  We have CK     and CK      and the following model parameters                P                                C              ef                                     cluster K K K K K K  ef K               The maximizing set for K is          and for K it is           and from this the cluster efficiencies have been calculated  Algorithm   returns the sequence s   h                        i which has ECR ECR  s                                         If we followed the simple P over C algorithm we would get the sequence s    h                      i with ECR   ECR s                                           SP   P P    C SC   C The second inequality is proved similarly  When we look at opening indices we get the following result  Lemma    Let s   h        x   x          i be an optimal troubleshooting sequence  and let Z be the opening indices of s  Then cef x    ef x     if x  Z  x    FA x    ef x    cef x     if x  FA x     x      Z cef x    cef x     if x  Z  x      Z Proof  Apply Lemma   and do some pencil pushing  For example  case    x  Z and x    FA x     In this case we have    Cx   CK x        P x   x   Cx         Cx        P x     x   Cx   CK x   m P x     x          Cx   CK x    P x   x  Cx    m     CORRECTNESS OF THE ALGORITHM  We start with a proof of Lemma     ef x      cef x   because P x    P x      P x      P x       for independent actions    Definition    Let s x  y  be a subsequence of a troubleshooting sequence s  Then the efficiency of s x  y  is given by Py Pi ef s x  y     Py i x i  C   i x i   Definition    Let s   h        x           y        i be a troubleshooting sequence  If all actions of the subsequence s x  y  belong to the same cluster  we say that the subsequence is regular  If furthermore s x  y  is as long as possible while not breaking regularity  we say that the subsequence is a maximal regular subsequence  Remark  Any troubleshooting sequence can be partitioned into a sequence of regular subsequences  and if all the subsequences are maximal  this partition is unique  Lemma    Let s be an optimal troubleshooting sequence  and let s x  x   k  and s y  y       with y   x   k      be two adjacent regular subsequences such that K x      K y   or such that neither x nor y is an opening index  Then ef s x  x   k     ef s y  y          So ECR  s   ECR s     is equivalent to    x k   y   y   x k X X X X Ci  i     Pj   Ci  i     Pj i x  j y  i y  j x  which yields the result  Lemma    There exists an optimal troubleshooting sequence s where for each opening index x  Z  there is a maximal regular subsequence s x  x j   j     that contains the maximizing sequence for cluster K x    Proof  Let s be an optimal troubleshooting sequence  and let x be an opening index  Let s x  x   j  be a maximal regular subsequence and assume that it does not contain the maximizing set  Then there exists y  K x   with y   x   j     such that ef y     ef s x  x   j   Observe that the subsequence s x  y     can be partitioned into m      say  maximal regular subsequences s             s m with s     s x  x   j   By Lemma   we have ef y     ef s      ef s          ef s m    ef y    Proof  We consider the sequence s    h        x    y           y     x           x k        i which is equal to s except that the two regular sequences have been swapped  Since s is optimal we   have ECR  s   ECR s      Because the subsequences are regular and belong to different clusters or do not contain opening indices  the costs are the same in the two sequences in both s and s    Therefore  we   get that the terms of ECR  s   ECR s  equal        Cx  x     P x   P x    y y               x k  x k  Cx k     P   P x k    y y          Cy  y     P y   P x              y    y     P x    y y    Cy       P  since the remaining terms cancel out  Now observe that     P x i   P x i    y y       y   y   x i  x i  X X X X   Pj     Pj  Pj    Pj j    j    j y  j y  and  similarly      P y i   P x    y y i      y i  y i  x  x k X X X X   Pj     Pj  Pj     Pj j    j    j y  j x  where the last inequality follows by the fact that y is not an opening action  so we avoid  cef y     This situation is clearly impossible  Therefore s x  x   j  must contain the maximizing set  By Lemma    it must also contain a maximizing sequence  Remark  In the above proof there is a technicality that we did not consider  there might be equality between the efficiency of an action in the maximizing sequence  the efficiency of the maximizing sequence  and one or more free actions  This problem can always be solved by rearranging the actions  and so for all proofs we shall ignore such details for the sake of clarity  Finally  we have the following theorem  Theorem    Algorithm   returns an optimal troubleshooting sequence  Proof  By Lemma   we know that an optimal sequence can be partitioned into a sequence of maximal regular subsequences which is sorted by descending efficiency  If we consider Lemma   too  then we know that we should open the clusters in order of highest efficiency and perform at least all actions in their maximizing sequences as computed by Lemma    By Lemma   we know that the order of actions in the maximizing sequences is the optimal one  By Lemma   we also know that all free actions  with ef     ef K  must be performed before opening the cluster  and all free actions with ef     ef K  must be performed after opening the cluster and performing all the actions in its maximizing sequence    Cluster     Co     Cc   Co   Cluster      Cc   Cluster      Co         Cc   Cluster     Co     Cc   Cluster          Co   Cc   Cluster           Figure    Example of a tree cost cluster model  To open a cluster Ki when the parent cluster is open we pay the cost Coi and to close a cluster given that all children clusters are closed we pay the cost Cci       THE TREE CLUSTER MODEL  In this section we shall investigate an extension of the flat cluster model where the clusters can be arranged as a tree  We call such a model for a tree cluster model  and an example is given in Figure    In the tree cluster model  the ECR does not admit the simple decomposition of Equation    The complication is that several clusters might need to be opened before performing an action in a deeply nested cluster  We therefore call troubleshooting sequences in the tree cluster model for tree troubleshooting sequences  Unfortunately  it is easy to construct examples that show that Algorithm   will not yield optimal tree troubleshooting sequences  Therefore  we shall present a new algorithm that solves the tree cluster model in O n  lg n  time  First we need some additional definitions  The conditional cost C    of   Ki will now depend on how many clusters that have been opened on the path from the root K to Ki   We therefore let AK Ki     denote the set of ancestor clusters that needs to be opened on the path from the root K to Ki given evidence   We then define X CK   C      C   CK      CKi      KAK Ki      Given this  Definition   is still valid for tree troubleshooting sequences   A single action is called an atomic action  A compound action consists of opening a cluster K and a sequence of actions in which each action may be either atomic or compound  Note that we shall usually not distinguish syntactically between atomic and compound actions  Also note that a compound action corresponds to a subsequence where the first action is an opening action  and the efficiency of a compound action is simply defined as the efficiency of the corresponding subsequence  If T is a tree cluster model and K is an arbitrary cluster in T   then the subtree model induced by K  denoted TK   is a new tree cluster model containing exactly the clusters in the subtree rooted at K  and with K as the open root cluster  If the induced subtree model is a flat cluster model  we call it a flat subtree model  Definition    Let TK    K  K            K    be a flat subtree model  Then the absorbtion of K            K  into K is a new cluster K containing    for each child cluster Ki   a compound action induced by the maximizing sequence for Ki   and    all remaining actions from K K          K    Note that in K all the actions in a child cluster Ki that are not contained in the newly generated compound action will have a lower efficiency than the compound action for Ki   Definition    Let T be a tree cluster model  and let K be any cluster in T   Then TK may be transformed into a single cluster K by repeated absorbtion into the root cluster of flat subtree models  The resulting cluster K is called the model induced by absorbtion into K  Remark  By construction  the compound actions in a model induced by absorbtion into the root cluster K will only contain actions from the subtrees rooted at a child of K  With these definitions we can now present Algorithm    The algorithm works in a bottom up fashion  basically merging leaf clusters into their parents  absorbtion  until the tree is reduced to a single cluster  Then an optimal sequence is constructed by unfolding compound actions when they are most efficient  The algorithm can be made to run in O n  lg n  time by the following argument  Sort the actions of all clusters in the tree T this takes at most O n  lg n  time  During absorbtion  it is important to avoid merging all actions of the child clusters into the parent cluster  Instead  we merge only the compound actions into the parent cluster  takes O    lg n  time overall   and create a priority queue holding the most efficient remaining action of each child cluster  When creating a compound action for a parent cluster  we then   Algorithm   The bottom up P over C algorithm function BottomUpPOverC T   Input  a cluster tree T with root K Compute the model K induced by absorbtion into K  see Definition    Let s   hi while K     do Let  be the most efficient action in K if  is an atomic action then Add action  to s else Add all actions of  to s in the order prescribed by  end if Set K   K      end while Return s end function use actions from the priority queue as needed  and update the priority queue whenever an action is taken out  Therefore  creating all the compound actions can never take more than O n  lg    time  As the absorbtion process moves towards the root  we are forced to merge priority queues from different subtrees  A simple induction argument can establish that it takes at most O    lg    time to merge all these priority queues  In the following we shall prove that Algorithm   computes an optimal tree troubleshooting sequence  The first two lemmas are minor generalizations of previous lemmas  and the proofs are almost identical  Lemma    Lemma   generalizes to tree troubleshooting sequences  Lemma    Lemma   generalizes to subsequences of actions that consists of  i  only free actions  or  ii  actions from the same subtree  Next we shall investigate the special properties of the compound actions generated by the absorbtion process  Definition    Let T be a tree cluster model  and let K be any non leaf cluster in T   A maximizing compound action  for K in T is defined as any most efficient compound action in the model induced by absorbtion into K  Lemma    Let T be a tree cluster model  and let K be any non leaf cluster in T   Let TK be the subtree model induced by K  and let  be a maximizing compound action for K in T   Then ef    ef   where  is any possible compound action in TK not including actions from K   Proof  We proceed by induction  Basis is a flat cluster model T    K  K            K    with compound actions               of K and    maxi i   Let  be any compound action including actions from clusters in T    K   and assume that ef     ef    We shall use the fact Pn n Pi Pi n Pi  max min  Pni     i i Ci Ci C i i  which is also known as Cauchys third inequality   Then by Equation     cannot be formed by any combination of the i s as this would not increase the efficiency  Therefore  must be formed by either a strict subset or a strict superset of one of the i s  If  is a subset of any i   then the maximality of i leads to a contradiction  If  is a superset of any i   then it will include subsets of actions from a set of clusters with subscripts I                  Let us denote the subsets from each Ki as i   We then have P Pi P P   ef   ef     PiI i  max i  max iI C C C i          i iI i i where the first inequality follows by Equation    the second follows by the definition of compound actions formed during absorbtion  and the last equality is by definition of a maximizing compound action  Since the sets i were chosen arbitrarily  we get a contradiction  Hence in all cases ef    ef    Induction step  we assume the Lemma is true for all children Ki           K  of an arbitrary cluster K where the children have maximizing compound actions                 A similar argument as above then shows that the lemma is true for K as well  Lemma     Let T be a tree cluster model with root cluster K  Then there exists an optimal tree troubleshooting sequence s that contains  as subsequences  all the compound actions of the model induced by absorbtion into K  Furthermore  the compound actions in s are ordered by descending efficiency  Proof  Let s   h            x           x k        i be an optimal tree troubleshooting sequence and let x be an opening action  and let s x  x   k   k  x be the sequence of maximal length of actions from the same subtree  Let furthermore s x  x   k  be the first subsequence that contradicts the lemma  that is  s x  x   k  does not contain the compound action  for the cluster K x    Then there exists an atomic action y    with y   x   k      such that y   s x  x   k   We then have ef y     ef     ef s x  x   k   because all atomic actions in a compound action are more efficient than the compound action itself  and because  is the most efficient compound action in the   subtree rooted at K x    Lemma     We can then partition the actions between x k and y into m      say  subsequences  of maximal length  s             s m   If one  or more  of these subsequence is more efficient than y   we immediately get a contradiction to optimality of s because such a subsequence can be moved before s x  x   k   Lemma     So we can assume that all the m subsequences are less efficient than y   Then by successive application of Lemma   we can decrease the ECR by moving y to position x   k      However  this again contradicts that s was optimal  Hence s x  x   k  must contain   By Lemma   it follows that the order of the compound actions must be by descending efficiency  Theorem    Algorithm   returns an optimal troubleshooting sequence  Proof  By Lemma    we only need to establish the order of the free actions between compound actions  By Lemma   it follows that any compound action is preceeded by more efficient free actions and followed by less efficient free actions      CONCLUSION  We have presented an algorithm  which in O n  lg n  time  n being the number of actions  provides an optimal troubleshooting sequence for scenarios where the cost clusters form a tree and have inside information  This is a useful result on its own  but there is more to it  When evaluating algorithms for troubleshooting  you must distinguish between off line and on line activity  If your task is off line  the time complexity of your algorithm may not be particularly important as long as the result can be stored easily  like for example an optimal action sequence   However  if the decision support system is flexible  it must allow the user to interact with the recommendations and have the system calculate an optimal next action based on alternative information  Furthermore  for many scenarios you will request online calculation of an optimal sequence  for example when the model includes questions and tests  For this kind of scenario  a direct representation of an optimal strategy may require too much space  Therefore  a myopic question heuristic usually relies on optimal sequences of actions calculated on line  Finally  our results imply a major improvement for offline methods like AO because the search tree can now be extensively pruned  This is because all subtrees that consist entirely of actions can be replaced with a single sequence of actions      ACKNOWLEDGEMENTS  We would like to thank the three anonymous reviewers for their excellent feedback  Thanks also go to Sven Skyum for help with Lemma     
 We present an approach to the solution of de cision problems formulated as influence dia grams   This approach involves a special tri  angulation of the underlying graph  the con struction of a junction tree with special prop  tials normalized  Ndilikilikesha  Shachter and Ndiliki likesha        Ndilikilikesha        modified the node removal  arc reversal algorithm to avoid these extra di visions  the result is an algorithm that is equivalent to Shenoys algorithm with respect to computational effi ciency   erties  and a message passing algorithm op  Our work builds primarily on the work of Shenoy  erating on the junction tree for computa         and Shachter and Peat         in addition  tion of expected utilities and optimal decision  to our previous work on propagation algorithms for  policies   the expert system shell Hugin  Andersen et al         Jensen et al               INTRODUCTION  Influence diagrams were introduced by Howard and Matheson        as a formalism to model decision     INFLUENCE DIAGRAMS  An  influence diagram is a belief network augmented  problems with uncertainty for a single decision maker   with decision variables and a utility function   The original way to evaluate such problems involved  The structure of a decision problem is determined by  unfolding the influence diagram into a decision tree and using the  average out and fold back  algorithm on that tree  Shachter        describes a way to eval  uate an influence diagram without tranforming it into a decision tree  The method operates directly on the influence diagram by means of the node removal and arc reversal operations  These operations successively transform the diagram  ending with a diagram with only one utility node that holds the utility of the op timal decision policy  the policies for the individual decisions are computed during the operation of the algorithm  when decision nodes are removed   Shenoy        describes another approach to the eval uation of influence diagrams  the influence diagram is converted to a valuation network  and the nodes are removed from this network by fusing the valuations bearing on the node  variable  to be removed  Shenoys algorithm is slightly more efficient than Shachters al gorithm in that it maintains a system of valuations   an acyclic directed graph G  The vertices of G repre sent either random variables  also known as chance or probabilistic variables  or decision variables  and the edges represent probabilistic dependencies between variables  Decision variables represent actions that are under the full control of the decision maker  hence  we do not allow decision variables to have parents in the graph  Let  UR  be the set of random variables  and let the  set of decision variables be  Uo                      Dn    with  the decisions to be made in the order of their index  Let the universe of all variables be denoted by U  UR U Uo   sets lo        We partition    In   for      UR     into a collection of disjoint  Ik is the set of variables Dk and Dk     variables  and In is the set  k    n   that will be observed  between decision  Io is the initial evidence  of variables that will never be observed  or will be observed after the last decision   This induces a partial order     on  U   whereas Shachters algorithm maintains a system of conditional probability functions  in addition to the utility functions   and some extra work  some division op erations  is required to keep the probability paten     By   observed    will be revealed   we  mean that the true state of the variable        Jensen  Jensen  and Dittmer  We associate with each random variable A a condi tional probability function A P AI PA   where  J A denotes the set of parents of A in G   The state space Xv for V  U i s defined a s the Carte sian product of the sets of possible outcomes decision alternatives for the individual variables in V  A po tential v for a set V of variables is a function from Xv to the set of real numbers  The potential  Pv can be extended to a potential  w  V  W  by simply ignoring the extra variables  w w   v v  ifv is the projection ofw on V  Given two potentials   P and tf   The product    tV and the quotient  tf  are defined in the natural way  except that     is defined to be    x   for x       is undefined    The  a priori  joint probability function  Pu is defined as A  Pu    IT  AEUR  For each instance of Uo  i e   each element of  Pu defines a joint probability function on UR   Xu      A solution to the decision problem consists of a series of decisions that maximizes some objective function  Such a function is called a utility function  Without loss of generality  we may assume that the utility func tion tfJ is a potential that may be written as a sum of  possibly  simpler potentials   The independence restriction imposed on the decision problem can be verified by checking that  in the influ ence diagram  there is no directed path from a deci sion Ok to a decision Di  i   k      DECISION MAKING  Assume we have to choose an alternative for deci sion On  i e   the last decision   We have already observed the random variables             In    and we have chosen alternatives for decisions D           n    The maximum expected utility principle  says that we should choose the alternative that maximizes the expected utility  The maximum expected utility for decision Dn is given by  Pn  max L P Inllo      In             Dn    tf   On  I   Obviously  Pn is a function of previous observations and decisions  We calculate the maximum expected utility for decision Dk  k   n  in a similar way   Pk  Df ax L P Ikllo        Ik    o          Dk   Pk   k  I   We note that Pk is well defined because of       By expansion of         we get  Pk  max L P Ikllo       Ik    D          Dk  Dk  m  Ik   max Dk l   max We need to impose a restriction on the decision prob lem  namely that a decision cannot have an impact on a variable already observed  This translates into the property  P Ikllo        Ik    D         On   P Ikllo       Ik             kl       In words  we can calculate the joint distribution for I k without knowledge of the states of Dk           Dn  i e   the future decisions        GRAPHICAL REPRESENTATION  In Figure    an example of an influence diagram is shown  Random variables are depicted as circles  and decision variables are depicted as squares  Moreover  each term of the utility function is depicted as a dia mond  and the domain of the term is indicated by its parent set  The partial order   is indicated by making I k   the parent set of D k  and we shall use the con vention that the temporal order of the decisions are read from left to right         o   L h   P Ik   Io       Ik  D         k      Pk    L max L P Ik  Ik   Io        Ik    l  Dk l  Ik l  D          k     Pk    The last step follows from      and the chain rule of probability theory  P AjB C P BIC   P A BIC   By further expansion  we get  Pk  max L max L P Ik      Inllo        Ik    Dk h Dn DnJ   t J  D   In         From this formula  we see that in order to calculate the maximum expected utility for a decision  we have to perform a series of marginalizations  alternately sum  and max marginalizations   thereby eliminating the variables  When we eliminate a variable A from a function   expressible as a product of simpler functions  we par tition the factors into two groups  the factors that involve A  and the factors that do not  call  the prod uct of  these factors   t  and A  respectively  The marginal LA is then equal to  PA   LA t   LA  Pt  There are good arguments for adhering to this principle  See  e g     Pearl           From Influence Diagrams to Junction Trees       FIGURE    An influence diagram for a decision problem with four decisions  The set of variables is partitioned into the  sets   I       b   I         e  f   Iz         I     g   and I      a  c  d  h  i  j  k  e    four local utilities  three of which are associated with single variables  D     the pair   j  k    then becomes a new factor that replaces the prod uct  cj J t  in the expression for     This also holds true for  max marginalizations  provided  cPA   does not assume  negative values   The utility function is a sum of  D   and    and one associated with  marginalizations  but  in general  we cannot inter change the order of a max  and a sum marginalization  this fact imposes some restrictions on the elimination order   The product cjJ may be represented by an undirected graph  where each maximal complete set  clique  of nodes  the nodes being variables  corresponds to a fac     INFLUENCE DIAGRAMS  tor  or a group of factors  of cjJ with that set as its do main  Marginalizing a variable  A out of   then corre  COMPILATION OF  We first form the moral graph of G  This means adding  sponds to the following operation on the graph  the set   undirected  edges between vertices with a common  A is  child  We also complete the vertex sets corresponding  of neighbors of A in the graph is completed  and  removed  It is a well known result that all variables  to the domains of the utility potentials  Finally  we  can be eliminated in this manner without adding edges  drop directions on all edges   if and only if the graph is triangulated  Rose          Next  we triangulate the moral graph in such a way  Obviously  it is desirable to eliminate all variables  that it facilitates the computation of the maximum  without adding extra edges to the graph since this  expected utility  This is equivalent to the selection of  means that we do not create new factors with a larger  a  domain than the original factors  the complexity of  verse of the elimination order must be some extension  representing and manipulating a factor is exponen  of    to a total order   tial in the number of variables comprising its domain   However  in most cases  this is not possible  we have to add some edges  and the elimination order chosen  special elimination order for the moral graph  the re  Finally  we organize the cliques of the triangulated graph in a strong junction tree   A tree of cliques  optimal elimination order for all reasonable criteria of optimality     C     C l of C  is contained in every clique on the path connecting C  and C   For two adjacent cliques  C  and C   the intersection C  n Cz is called a sepa  W hen we perform inference in a belief network  i e    least one distinguished clique R  called a strong root   will determine how many and hence also the size of the cliques   Unfortunately  it is  N Jl hard to find an  is called a junction tree if for each pair  cliques   C   n  rator  A junction tree is said to be strong if it has at   C   Cz  of adjacent cliques in C  closer to R than C   there exists an ordering of C  that respects    and with the ver tices of the separator C  n Cz preceding the vertices of C  C    This property ensures that the computation  calculation of the marginal probability of some vari  such that for each pair  able given evidence on other variables   the computa  the tree  with  tion only involves sum marginalizations  In this case  we can eliminate the variables in any order  since the order of two marginalizations of the same kind can be interchanged   However  the calculation of the max  imum expected utility involves both max  and sum   of the maximum expected utility can be done by local message passing in the junction tree  see Section            Jensen  Jensen  and Dittmer  that no two cliques have the same index  Moreover  unless index  C       the set    vE C I  X v   index  C    will be a proper subset of some other clique with a  lower index than  C   Let the collection of cliques of the triangulated graph be  C         Cm  ordered in  increasing order according  to their index  As a consequence of the above construc tion  this ordering will have the running intersection property  Beeri et  al           meaning that  k   for all  FIGURE    The moral graph for the decision problem in Figure    Edges added by the moralization process are indicated by dashed lines   k        Sl      C    n  U  Ci  C   for some  i    j   k   It is now easy to construct a strong junction tree  we start with each clique  C   the root   then we successively attach Ck to some clique C  that contains Sl    Consider the decision problem in Figure    Figure     shows the moral graph for this problem  edges have  been added between vertices with a common child  in cluding utility vertices   utility vertices have been re moved  and directions on all edges have been dropped  Note that the time precedence edges leading into de cision vertices are not part of the graph and are thus not shown  Figure  shows the strong triangulation of the graph       generated by the elimination sequence e  j  k  i  fill ins  D     and g      lt  fill in  f      a  c  fill in  b e   d  fill ins     e       f  b f  and e f       g  fill in  e     Oz           f  e      and b  This graph has the fol lowing cliques  C       i e   C s    lt k j   C         lt k   C    b c a   C    b e d c   Cs  Oz  g      i   C   f      lt   Cs  e      g   and C     b O e f d   Using the above algorithm  in Figure            FIGURE            The triangulated graph of the moral graph in Figure    Fill in edges added during triangulation are indicated by dashed lines                  we get the strong junction tree shown in Figure     for  this collection of cliques   There exists another strong      Let  CONSTRUCTION OF STRONG JUNCTION TREES   X be  a numbering of            lUI    U  such that for all  plies  X u      X v     X  U H U  u    v im   i e   a bijection  u v  E  We assume that  X is the elimi  nation order used to produce the triangulated graph  of G  vertices with higher numbers are eliminated be fore vertices with lower numbers  Let C vE C  the edge  Cs       C   by the edge  Cs       C     This tree is  computationally slightly more efficient  but  unfor tunately  it cannot be constructed by the algorithm given in this paper   In general  previous observations and decisions will be relevant when making a decision  However  sometimes only a subset of these observations and decisions are  be a clique of the triangulated graph  and let be the highest numbered vertex such that the   wE C I  X w     X v   have a common neigh bor u  j  C with  X u     X v   If such a vertex v exists  we define the index for Cas index  C   X v   other wise  we define index  C     Intuitively  the index for a clique C identifies the step in the elimination process that causes C to  disappear  from the graph  It is easy to see that the index for a clique C is well defined  and vertices        junction tree for this collection  obtained by replacing  needed to make an optimal decision  For example  for the decision problem in Figure    the variable  e  sum  marizes all relevant information available when deci sion      has to be made  although  before decision        f  is observed just  it has no relevance for that deci  sion  it does  however  have relevance for decision      This fact is detected by the compilation algorithm  the only link from    to past observations and decisions goes to  e         From Influence Diagrams to Junction Trees  FIGURE    A strong junction tree for the cliques of the graph in Figure       USING THE STRONG JUNCTION TREE  Now  letT be a strong junction tree  and let C  and C   FOR COMPUTATIONS  be adjacent cliques with separator S inT  We say that  We perform computations in the junction tree as a spe cial collect  operation from the leaves of the junction  C  absorbs from Cz if and tVc as follows   Q Jc   and tVc  change to     cPc   tree to some strong root of the tree  To each clique  C in the junction tree  we associate a  probability potential QJc and a utility potential tVc defined on  Xc   Let e be the set of cliques  We define  where  the joint potentials q  and tV for the junction tree as  tVs     M  Cz S  cPCz  tV c z    Note that this definition of absorption is  asy mmetric  We initialize the junction tree as follows  each variable  A E U R is assigned to a clique that contains A U PA  T he probability potential for  a  clique is the product of  the conditional probability functions for the variables assigned to it  For cliques with no variables assigned to them  the probability potentials are unit functions  In this way  the joint probability potential for the junc tion tree becomes equal to the joint probability func tion for the influence diagram  Similarly  each utility  in the sense that information only flows in the direc tion permitted by the partial order      It is possible to generalize this definition of absorption to a sym metric definition similar to the one given in  Jensen et  al          for the case of pure probabilistic influence  diagrams  Clearly  the complexity of an absorption operation is  O I Xc l   IXsl    Xc      Note in particular that the contribution from the division operation plays a much smaller role than in  Shenoy         since division op  function tVk is assigned to some clique that can ac commodate it  The utility potential for a clique is the  erations are performed on separators only   sum of the utility functions assigned to it  for cliques  We will need the following lemma  which we shall state  with no utility functions assigned to them  the utility  without proof   potential is a null function  We need a generalized marginalization operation that acts differently on random and decision variables  We denote the operation by   M      For random variable  A  and decision variable D  we define  M q  D  For a set  V of variables   we define     maxQ l  D  Mv q   as a series of  single variable marginalizations  in the inverse order as determined by the relation      Note that although     is only a partial order   Mv q   is well defined   Lemma   Let D be a decision variable  and let  V  a set of variables that includes all descendants of in G   of  D  Then  Mv   D  Q lu   be     considered as a function  alone  is a non negative constant   Let T be a strong junction tree with at least two cliques  let  cPT  be the joint probability potential and  tVT the joint utility potential on T  Choose a strong root R for T and some leaf l   I R   let T   l denote the strong junction tree obtained by absorbing l into  its neighbor N and removing l  denote the separator between N and l by S         Jensen  Jensen  and Dittmer  Theorem   After absorption of l into T  we have  M  Pr  tl r    PT L            Xk  is a decision variable  By induction  we get  tVT L  L S Proof  Let   iJL  IJ       Because of Lemma     P   k  l  considered as a   Pc   function of xk alone  is a non negative constant   CEe  L   and we get Since  PL does not assume negative values  we get   mxax P k  l         L S  L S     maxx   tj lk  l  maxx   j lk    J        k        We have to show that  M  PL L S      ti L   lj L       Ps       S     iJL        i      tj  k   tJ k   L           L       I  By successively absorbing leaves into a strong junction tree  we obtain probability and utility potentials on the intermediate strong junction trees that are equal to the marginals of the original potentials with respect  where  to the universes of these intermediate trees   This is  ensured by the construction of the junction tree in which variables to be marginalized out early are lo We shall prove this by induction  Let X            Xt be  some ordering of l   S that respects     Now  consider  the equation   cated farther away from the root than variables to be marginalized out later   The optimal p olicy for a decision variable can be deter  mined from the potentials on the clique that is closest  to the strong root and contains the decision variable  that clique may be the root itself   since all variables that the decision variable may depend on will also be members of that clique   where  For our example decision problem  Figure     we can determine the optimal policy for    from  the poten tials on  clique C    the root   and the optimal policies for the remaining decisions can be determined from   For k          is equivalent to the desired result   For k   e      is clearly true  for    s k  s e  we have two  cases       Xk  cliques Cs  decision      C   decision      and Cs   decision        If only the maximum expected utility is desired  it is a random variable  By induction  we get  should be noted that only storage for the  active  part of the junction tree during the collect operation needs to be reserved  this means that storage for at most two adjacent cliques and each clique that corresponds to a branch point on the currently active path from  the root to a leaf  must be reserved  Since elimination  of a group of variables can be implemented more effi  ciently than the corresponding series of single variable eliminations  it is still useful to organize the computa tions according to the structure of the strong junction tree as compared to  Shenoy   The correctness of the last step follows from the fact that   P kl  x        implies tj lkl  x         so that  our division by zero convention applies               CONCLUSION  We have described an algorithm to transform a deci sion problem formulated as an influence diagram into a   From Influence Diagrams to Junction Trees  secondary structure  a strong junction tree  that is par ticularly well suited for efficient computation of max  networks by local computations                   Computational  Statistics Quarterly   imum expected utilities and optimal decision policies  The algorithm is a refinement of the work by Shenoy        and Shachter and Peot         in particular  the construction of the strong junction tree and its use for computations has been elaborated upon   Kjcerulff  U          Triangulation of graphs algo rithms giving small total state space  Research Report R        Department of Mathematics and Computer Science  Aalborg University  Denmark   T he present work forms the basis for an efficient com puter implementation of Bayesian decision analysis in the expert system shell Hugin  Andersen et al           Lauritzen  S  L  and Spiegelhalter  D  J          Lo cal computations with probabilities on graphical structures and their application to expert systems   We have not given an algorithm to construct the elim ination sequence that generates the strong triangula tion  However  the triangulation problem is simpler than for ordinary probability propagation  since the set of admissible elimination sequences is smaller  at this stage  it appears that simple adaptations of the heuristic algorithms described by Kjcerulff        work very well  Moreover  even given a triangulation  there might exist several strong junction trees for the collec tion of diques  Besides the use of the strong junction tree for compu tation of expected utilities and optimal decision poli cies  it should be possible to exploit the junction tree for computation of probabilities for random variables that only depend on decisions that have already been made  Ideally  this should be done through a  dis tribute  operation from the root towards the leaves of the junction tree  Work regarding these problems is in progress  Acknowledgements  This work has been partially funded by the Danish research councils through the PIFT programme  
