 When the information about uncertainty cannot be quantified in a simple  probabilistic way  the topic of possibilistic decision theory is often a natural one to consider  The development of possibilistic decision theory has lead to a series of possibilistic criteria  e g pessimistic possibilistic qualitative utility  possibilistic likely dominance   binary possibilistic utility and possibilistic Choquet integrals  This paper focuses on sequential decision making in possibilistic decision trees  It proposes a complexity study of the problem of finding an optimal strategy depending on the monotonicity property of the optimization criteria which allows the application of dynamic programming that offers a polytime reduction of the decision problem  It also shows that possibilistic Choquet integrals do not satisfy this property  and that in this case the optimization problem is N P  hard      Introduction  For several years  there has been a growing interest in the Artificial Intelligence community towards the foundations and computational methods of decision making under uncertainty  This is especially relevant for applications to sequential decision making under uncertainty  where a suitable strategy is to be found  that associate a decision to each state of the world  Several formalisms can be used for sequential decision problems  such as decision trees  influence diagrams or Markov decision processes  A decision tree is an explicit representation of a sequential decision problem  while influence diagrams or Markov decision processes are compact representations  Even in the simple and explicit case of decision trees  the set of potential strategies increases exponentially with the tree size   Wided Guezguez LARODEC Laboratory ISG  University of Tunis Tunisia       widedguezguez gmail com  A popular criterion to compare decisions under risk is the expected utility  EU   model axiomatized by von Neumann and Morgenstern       This model relies on a probabilistic representation of uncertainty  an elementary decision  i e  a one step decision problem  is modeled by a probabilistic lottery over its possible outcomes  The preferences of the decision maker are supposed to be captured by a utility function assigning a numerical value to each outcome  The evaluation of a lottery is then performed through the computation of its expected utility  the greater is the better   In sequential decision making  each possible strategy is viewed as compound lottery  It can be reduced to an equivalent simple lottery  and thus compared to the others according to its expected utility  Although the high combinatorial nature of the set of possible strategies  the selection of an optimal strategy can be performed in polynomial time  polytime  with the size of the decision tree  the EU model indeed satisfies a property of monotonicity that guarantees completeness of a polytime algorithm of dynamic programming  When the information about uncertainty cannot be quantified in a simple  probabilistic way the topic of possibilistic decision theory is often a natural one to consider            Giving up the probabilistic quantification of uncertainty has led to give up the EU criterion as well  The development of possibilistic decision theory has lead a series of possibilistic counterparts of the EU criterion       for instance advocates the use of possibilistic Choquet integrals  which relies on a numerical interpretation of both possibility and utility degrees  On the contrary      have studied the case of a qualitative interpretation and propose two criteria based on possibility theory  an optimistic and a pessimistic one  denoted by Uopt and Upes    whose definitions only require a finite ordinal  non compensatory  scale for evaluating both utility and plausibility  The axiomatization of Uopt and Upes yielded the development of sophisticated qualitative models for sequential decision making  e g  possibilistic Markov decision   processes           possibilistic ordinal decision trees     and even possibilistic ordinal influence diagrams  One of the most interesting properties of this qualitative model is indeed that it obeys a weak form of the monotonicity property  As a consequence  dynamic programming may be used and a strategy optimal with respect to Upes or Uopt can be built in polytime  On the contrary general Choquet integrals are incompatible with dynamic programming  Worst  the problem of determining a strategy optimal with respect to Choquet integrals is NP Hard in the general case       We show in the present paper that the problem of determining a strategy optimal with respect to a possibilistic Choquet integrals is NP Hard as well  More generally  we propose a study of the complexity of the problem of finding an optimal strategy for possibilistic decision trees  which criteria obey the monotonicity property  and then may be solved in polytime thanks to dynamic programming  and which ones lead to NPHard problems  This paper is organized as follows  Section   presents a refresher on possibilistic decision making under uncertainty and especially a survey on most common possibilistic decision criteria  Section   details possibilistic decision trees  Section   is devoted to the complexity study regarding different decision criteria  Finally  Section   presents an extension to order of magnitude expected utility  Proofs are omitted for space reasons but are available at ftp   ftp irit fr IRIT  ADRIA PapersFargier uai   pdf          Background Possibilitic lotteries  The basic building block in possibility theory is the notion of possibility distribution      Let x            xn be a set of state variables whose value are ill known  D        Dn their respective domains and denote    D       Dn the joint domain of x            xn   Vectors    are often called realizations or simply states  of the world   The agents knowledge about the value of xi s is by a possibility distribution                     means that  is totally possible and        means that  is an impossible state  It is generally assumed that there exist at least one state  which is totally possible  i e  that  is normalized  Extreme cases of knowledge are presented by complete knowledge i e    s t           and                and total ignorance i e              all values in  are possible   From   one can compute the possibility  A  and necessity N  A  of an event A     A    sup     A       N  A        A       sup            A     A  evaluates to which extend A is consistent with the knowledge represented by   N  A  corresponds to the extent to which A is impossible  it evaluates at which level A is implied by the knowledge  In possibility theory  conditioning is defined by the following counterpart of the Bayesian rule         min                   In this equation        and    are combined according to a min operation  according to the ordinal interpretation of the possibilistic scale    The following min based definition of the conditioning corresponds to the least specific solution of      see        if         and          if         and             otherwise     Following         a decision can be seen as a possibility distribution over its outcomes  In a single stage problem  a utility function maps each outcome to a utility value in a totally ordered set U    u            un    we assume without loss of generality that u       un    This function models the attractiveness of each outcome for the decision maker  An act can then be represented by a possibility distribution on U   called a  simple  possibilistic lottery  and denoted by h   u            n  un i  i    ui   is the possibility that the decision leads to an outcome of utility ui   In the following  L denotes the set of simple lotteries  i e  the set of possibility distributions over U    A possibilistic compound lottery h   L            m  Lm i  also denoted by     L       m  Lm    is a possibility distribution over a subset of L  The possibility i j of getting a utility degree uj  U from one of its sublotteries Li depends on the possibility i of getting Li and on the conditional possibility ij    uj   Li   of getting uj from Li i e  i j   min j   ij   by equation      Hence  the possibility of getting uj from a compound lottery h   L            m  Lm i is the max  over all Li   of i j   Thus         have proposed to reduce     L            m  Lm   into a simple lottery  denoted by Reduction h   L            m  Lm i   that is considered as equivalent to the compound one  Reduction h   L            m  Lm i    h max min j   j    u            max min j   jn   un i  j    m  j    m         The other  numerical interpretation of possibility theory is the use a product instead of a min operation  but this is out the scope of the present study    Obviously  the reduction of a simple lottery is the simple lottery itself  Since min and max are polynomial operations  the reduction of a compound lottery is polynomial in the size of the compound lottery     We review in the following the different criteria that have been proposed to evaluate and or compare  simple  lotteries  thanks to the notion of reduction  they also apply to compound lotteries  to evaluate compare compound lotteries  simply reduce each to an equivalent simple one  then use one of the criteria proposed for the evaluation the comparison of simple lotteries  Formally  any comparison criterion O  i e  any preference order O defined on simple lotteries can be extended to compound lotteries as follows  L O L  Reduction L  O Reduction L         totally ordered   hu  ui  b hv  vi    u   v     and u  v      or u  v and u   v        or   u   v     and v           Each ui   hui   ui i in the utility scale is thus understood as a small lottery hui    ui  i  A lottery h   u            n  un i can be viewed as a compound lottery  and its P U utility is computed by reduction  P U  h   u            n  un i    Reduction    hu     u   i          n  hun    un  i    h max  min j   uj      max  min j   uj    i j    n  j    n            Possibilistic qualitative utilities  Upes   Uopt   P U    Under the assumption that the utility scale and the possibility scale are commensurate and purely ordinal      have proposed the following qualitative pessimistic and optimistic utility degrees for evaluating any simple lottery L   h   u            n  un i  possibly issued from the reduction of a compound lottery   Upes  L    max min ui   N  L  ui           Uopt  L    max min ui    L  ui           i    n  i    n  where N  L  ui         L   ui        max j j   i   and  L  ui     max j are the necessity and posj    n  sibility degree that L reaches at least the utility value ui   Upes generalizes the Wald criterion and estimates to what extend it is certain  i e  necessary according to measure N   that L reaches a good utility  Its optimistic counterpart  Uopt   estimates to what extend it is possible that L reaches a good utility  Because decision makers are rather cautious than adventurous  the former is generally preferred to the latter  Claiming that the lotteries that realize in the best prize or in the worst prize play an important role in decision making  Giang and Shenoy     have proposed a bipolar model in which the utility of an outcome is a pair u   hu  ui where max u  u       the utility is binary in this sense that u is interpreted as the possibility of getting the ideal  good reward  denoted   and u is interpreted as the possibility of getting the anti ideal  bad reward  denoted    Because of the normalization constraint max u  u       the set U    hu  ui            max          is    The size of a simple lottery is the number of its outcomes  the size of a compound lottery is the sum of the sizes of its sub lotteries plus the number of its sub lotteries   We thus get  for any lottery L a binary utility P U  L    hu  ui in U   Lotteries can then be compared according to Equation      L P U L  Reduction L   b Reduction L         In     Giang and Shenoy show that the order induced by PU collapse with the one induced by Uopt whenever for any lottery  the possibility u of getting the worst utility is equal to    any compound lottery    h     i          n  h   n i reduces to the lottery h   max min i   i  i   max min i   i   is precisely i    n  i    n  the optimistic utility value   In the same way  Giang and Shenoy have shown that the order induced on the lotteries by PU collapse with the one induced by Upes as soon as for any lottery  the possibility u of getting the best utility is equal to    We shall thus say that PU captures Uopt and Upes as particular cases       Possibilistic likely dominance  LN  L   When the scales evaluating the utility and the possibility of the outcomes are not commensurate         propose to prefer  among two possibilistic decisions  the one that is more likely to overtake the other  Such a rule does not assign a global utility degree to the decisions  but draws a pairwise comparison  Although designed on a Savage like framework rather than on lotteries  it can be translated on lotteries  This rule states that given two lotteries L    h    u              n  u n i and L    h    u              n  u n    L  is as least as good as L  as soon as the likelihood  here  the necessity or the possibility  of the event the utility of L  is as least as good as the utility of L  is greater or equal to the likelihood of the event the utility of L  is as least as good as the utility of L    Formally  L  LN L   N  L   L     N  L   L            L  L L    L   L      L   L           where  L   L      supu i  u i s t  u i u i min  i    i   and N  L   L       supu i  u i s t  u i  u i min  i    i    The preference order induced on the lotteries is not transitive  but only quasitransitive  obviously L   N L  and L   LN L  implies L   LN L   resp  L   L L  and L   L L  implies L   L L    but it may happen that L  LN L    L  LN L   resp  L  L L    L  L L    and L   LN L   resp  L   L L          Proposition    Let L    L  be two lotteries such that max ui  max ui   It holds that ui L   i     ui L   i     ChN  Reduction h  L      L  i    ChN  L     No such property holds for Ch   as shown by the following counter example  Counter Example    Let U                      L    h                 i  L    h          i  and L    Reduction h  L      L  i    h                             i  We can check that Ch  L          and Ch  L          Possibilistic Choquet integrals  In presence of heterogeneous information  i e  when the knowledge about the state of the world is possibilistic while the utility degrees are numerical and compensatory the previous models cannot be applied anymore  Following      Choquet integrals appear as a right way to extend expected utility to non Bayesian models  Like the EU model  this model is a numerical  compensatory  way of aggregating uncertain utilities  But it does not necessarily resort on a Bayesian modeling of uncertain knowledge  Indeed  this approach allows the use of any monotonic set function     and thus of a necessity measure  As the qualitative case  but assuming that the utility degrees have a richer  cardinal interpretation  the utility of L is given by a Choquet integrals  Ch  L    i   n  ui  ui       L  ui           If  is a probability measure then Ch  L  is simply the expected utility of L  In the present paper  we are interested in studying the possibilistic framework for decision making  for cautious  resp  adventurous  decision makers  the capacity  is the necessity measure N  resp  the possibility measure    ChN  L    i   n  ui  ui      N  L  ui           Ch  L    i   n  ui  ui       L  ui           From Equations     and       it can be shown that  Proposition    Given a lottery L   h   u            n  un i  an utility ui s t  ui  max uj and a lottery L   uj L j    h   u            n  un i s t  i  i and it holds that ChN  L    ChN  L    j    i  j   j    This emphasizes the pessimistic character of ChN   adding to a lottery any consequence that is not better than its best one decreases its evaluation  As a consequence  we get the following result   This kind of set function is often called capacity or fuzzy measure      Possibilistic decision trees  Decision trees are graphical representations of sequential decision problems under the assumption of full observability  A decision tree is a tree T    N   E  whose set of nodes  N   contains three kinds of nodes   D    D            Dm   is the set of decision nodes  represented by rectangles   The labeling of the nodes is supposed to be in accordance with the temporal order i e  if Di is a descendant of Dj   then i   j  The root node of the tree is necessarily a decision node  denoted by D     LN    LN            LNk   is the set of leaves  also called utility leaves  LNi  LN   u LNi   is the utility of being eventually in node LNi   For the sake of simplicity we assume that only leave nodes lead to utilities   C    C            Cn   is the set of chance nodes represented by circles  For any Xi  N   let Succ Xi    N be the set of its children  For any Di  D  Succ Di    C  Succ Di   is the set of actions that can be decided when Di is observed  For any Ci  C  Succ Ci    LN  D  Succ Ci   is the set of outcomes of the action Ci   either a leaf node is observed  or a decision node is observed  and then a new action should be executed   The size of T is its number of edges  the number of nodes is equal to the number of edges plus     In classical  probabilistic  decision trees the uncertainty pertaining to the possible outcomes of each Ci  C  is represented by a conditional probability distribution pi on Succ Ci    such that N  Succ Ci    pi  N     P  N  path Ci    where path Ci   denotes all the value assignments to chance and decision nodes on the path from the root node to Ci   In this work    For the sake of simplicity  we shall forget about the utility degrees that receive a possibility degree equal to   in a lottery  i e  we write h                 i instead of h                                               i                                                      lottery and can be reduced to an equivalent simple one  Formally  the composition of lotteries will be applied from the leafs of the strategy to its root  according to the following recursive definition for any Ni in N    L  Ni      if Ni  D   Reduction hi  Xj   L Xj    Xj Succ Ni   i  L Ni         if Ni  C h  u Ni  i if Ni  LN                                                              Figure    Example of possibilistic decision tree with C    C    C    C    C    C    C     D    D    D    D    and LN   U                        we obviously use a possibilistic labeling  see Figure     The difference with probabilistic decision trees is that the chance nodes are viewed as possibilistic lotteries  More precisely  for any Ci  C  the uncertainty pertaining to the more or less possible outcomes of each Ci is represented by a conditional possibility distribution i on Succ Ci    such that N  Succ Ci    i  N      N  path Ci     Solving the decision tree amounts at building a strategy that selects an action  i e  a chance node  for each reachable decision node  Formally  we define a strategy as a function  from D to C       Di   is the action to be executed when a decision node Di is observed   Di      means that no action has been selected for Di  because either Di cannot be reached or the strategy is partially defined   Admissible strategies must be    sound   Di  D   Di    Succ Di          complete   i   D        and  ii  Di s t   Di        N  Succ  Di     either  N       or N  LN   Let  be the set of sound and complete strategies that can be built from T   Any strategy in  can be viewed as a connected subtree of T whose edges are of the form  Di    Di     The size of a strategy  is the sum of its number of nodes and edges  it is obviously lower than the size of the decision tree  Strategies can be evaluated and compared thanks to the notion of lottery reduction  Recall indeed that leaf nodes in LN are labeled with utility degrees  Then a chance node can be seen as a simple lottery  for the most right chance nodes  or as a compound lottery  for the inner chance nodes   Each strategy is a compound  Equation      is simply the adaptation to strategies of lottery reduction  Equation       We can then compute Reduction     L D       Reduction   ui   is simply the possibility of getting utility ui when  is applied from D    Since  the operators max and min are polytime Equation      define a polytime computation of the reduced lottery  Proposition    For any strategy  in   an equivalent simple possibilistic lottery can be computed in polytime  We are now in position to compare strategies  and thus to define the notion of optimality  Let O be one of the criteria defined in Section    i e  depending on the application  O is either L   or LN   or the order induced by Upes   or by Uopt   etc    A strategy     is said to be optimal w r t  O iff       Reduction   O Reduction             Notice that this definition does not require the full transitivity  nor the completeness  of O and is meaningful as soon as the strict part of O    O   is be transitive  This means that it is applicable to the preference relations that rely on the comparison of global utilities  qualitative utilities  binary utility  Choquet integrals  but also to LN and L   We show in the following that the complexity of the problem of optimization depends on the criterion at work      On the complexity of decision making in possibilistic decision trees  Finding optimal strategies via an exhaustive enumeration of  is a highly computational task  For instance  in a decision tree with n decision nodes and a branching factorequal to    the number of potential strategies is in O   n    For standard probabilistic decision trees  where the goal is to maximize expected utility  an optimal strategy can be computed in polytime thanks to an algorithm of dynamic programming which builds the best strategy backwards  optimizing the decisions from the leaves of the tree to its root  Regarding possibilistic decision trees      shows that such a method can also be used to get a strategy max    imizing Upes and Uopt   The reason is that like EU  Upes satisfies the key property of weak monotonicity  We formulate it for any criterion O over possibilistic lotteries  O is said to be weakly monotonic iff whatever L  L and L  whatever     such that max          L O L     L      L  O    L       L        This property states that the combination of L  resp  L   with L  does not change the initial order induced by O between L and L   this allows dynamic programming to decide in favor of L or L before considering the compound decision  The principle of backwards reasoning procedure is depicted in a recursive manner by Algorithm   for any preference order O among lotteries  When each chance node is reached  an optimal sub strategy is built for each of its children these sub strategies are combined w r t  their possibility degrees  and the resulting compound strategy is reduced  we get an equivalent simple lottery  representing the current optimal sub strategy  When a decision node X is reached  a decision Y  leading to a sub strategy optimal w r t  O is selected among all the possible decisions Y  Succ X   by comparing the simple lotteries equivalent to each sub strategies  This procedure crosses each edge in the tree only once  When the comparison of simple lotteries by O  Line      and the reduction operation on a   level lottery  Line      can be performed in polytime  its complexity is polynomial w r t  the size of the tree  Then  Proposition    If O satisfies the monotonicity property  then Algorithm   computes a strategy optimal w r t  O in polytime  We will see in the following that  beyond Upes and Uopt criteria  several other criteria satisfy the monotonicity property and that their optimization can be managed in polytime by dynamic programming  The possibilistic Choquet integrals  on the contrary  do not satisfy weak monotonicity  we will show that they lead to NPComplete decision problems  Formally  for any of the optimization criteria of Sections     to      the corresponding decision problem can be defined as follows   DT OPT O   Strategy optimization w r t  an optimization criterion O in possibilistic decision trees  INSTANCE  A possibilistic decision tree T   a level   QUESTION  Does there exist a strategy    such as Reduction   O   For instance DT OPT ChN corresponds to the optimization of the necessity based Choquet integrals  DT OPT Upes and DT OPT Uopt correspond to the optimization of the possibilistic qualitative utilities Upes and Uopt   respectively   Algorithm    Dynamic programming Data  In  a node X  In Out  a strategy  Result  A lottery L begin for i              n  do L ui      if N  LN then L u N       if N  C then   Reduce the compound lottery foreach Y  Succ N   do LY  P rogDyn Y    for i              n  do L ui    max L ui    min N  Y    Ly  ui      Line      if N  D then   Choose the best decision Y   Succ N   f irst foreach Y  Succ N   do LY  P rogDyn Y    if LY  O LY  then Y   Y  Line       N    Y  L  LY  return L end       Possibilistic qualitative utilities  Upes   Uopt   P U    Possibilistic qualitative utilities Upes and Uopt satisfy the weak monotonicity principle  Although not referring to a classical  real valued utility scale  but to a   dimensional scale  this is also the case of P U   Proposition    Upes   Uopt and P U satisfy the weak monotonicity property  As a consequence  dynamic programming applies to the optimization of these criteria in possibilistic decision trees  Although not explicitly proved in the literature  Proposition   is common knowledge in possibilistic decision theory  It is also known that dynamic programming applies to the optimization of Upes   Uopt and P U in possibilistic Markov decision processes and thus to decision trees  see               Corollary    DT OPT Upes   DT OPT  Uopt and DT OPT P U belong to P        Possibilistic likely dominance  LN  L   Fortunately  the optimization of the possibilistic likely dominance criteria also belongs to P  Indeed  Proposition    L and LN satisfy the weak monotony principle Algorithm   is thus sound and complete for L and LN   and provides in polytime any possibilistic decision tree with a strategy optimal w r t  these criteria  Corollary    DT  OP T  LN and DT  OP T  L belong to P     It should be noticed that  contrarily to what can be done with the three previous rules  the likely dominance comparison of two lotteries will be reduced to a simple comparison of aggregated values  Line      Anyway  since only one best strategy is looked for  the transitivity of  L  resp   L   guarantees the correctness of the procedure   the non transitivity on the indifference is not a handicap when only one among the best strategies is looked for  The difficulty would be raised if we were looking for all the best strategies       Possibilistic Choquet integrals  ChN   Ch    The situation is thus very confortable with qualitative utilities  binary possibilistic utility and likely dominance  It is much lesser comfortable for the case of numerical utilities  i e  when the aim is to optimize a possibilistic Choquet integral  either ChN or Ch    The point is that the possibilistic Choquet integrals  as many other Choquet integrals  do no satisfy the monotonicity principle  Counter Example     From         Let L   h                    i  L   h                   i and L   h           i  L       L      L  and L       L       L   with         and       Using Equation     we have  Reduction L      h                    i and Reduction L      h                    i  Computing ChN  L          and ChN  L           we get L ChN L   But ChN  Reduction L               ChN  Reduction L              i e     L      L   ChN    L       L   this contradicts the monotonicity property  Let L   h                    i  L   h                   i and L   h              i  L       L      L  and L       L       L   with      and          Using Equation     we have  Reduction L      h                    i and Reduction L      h                              i  Computing Ch  L          and Ch  L           we get L  Ch L   But Ch  Reduction L                Ch  Reduction L               i e     L      L   Ch    L       L   this contradicts the monotonicity property  Proposition    DT  OP T  ChN and DT  OP T  Ch are NP Complete      Extension to Order of Magnitude Expected Utility  Order of Magnitude Expected Utility theory relies on a qualitative representation of beliefs  initially proposed by Spohn       via Ordinal Conditional Functions  and later popularized under the term kappa rankings         Z        is a kappa ranking if and only if  S  min            A  A         S   A    minA      if    Note that event A is more likely than event B if and only if  A     B   kappa rankings have been termed as disbelief functions  They receive an interpretation in terms of order of magnitude of small probabilities   A    i is equivalent to P  A  is of the same order of i   for a given fixed infinitesimal   There exists a close link between kappa rankings and possibility measures  insofar as any kappa ranking can be represented by a possibility measure  and vice versa  Order of magnitude utilities have been defined in the same way           Namely  an order of magnitude function    X  Z        can be defined in order to rank outcomes x  X in terms of degrees of dissatisfaction  Once again   x     x   if and only if x is more desirable than x    x      for the most desirable consequences  and  x      for the least desirable consequences   is interpreted as   x    i is equivalent to say that the utility of x is of the same order of i   for a given fixed infinitesimal   An order of magnitude expected utility  OMEU  model can then be defined  see          among others   Considering an order of magnitude lottery L   h               n  n i as representing a some probabilistic lottery  it is possible to compute the order of magnitude of the expected utility of this probabilistic lottery  it is equal to mini   n  i   i    Hence the definition of the OMEU value of a  lottery L   h               n  n i  OM EU  L    min  i   ui    i   n        The preference relation OM EU is thus defined as  L OM EU L  OM EU  L   OM EU  L         We shall now define kappa decision trees  for any Ci  C  the uncertainty pertaining to the more or less possible outcomes of each Ci is represented by a kappa degree i  N     M agnitude P  N  past Ci      N  Succ Ci    with the normalization condition that the degree      is given to at least one N in Succ Ci     According to the interpretation of kappa ranking in terms of order of magnitude of probabilities  the product of infinitesimal the conditional probabilities along the paths lead to a sum of the kappa levels  Hence the following principle of reduction of the kappa lotteries  Reduction    L       m  Lm     h min  j    j   u            min  jn   j   un i  j    m        j    m  The last result of this paper is that OMEU satisfies the weak monotonicity principle    Proposition    L  L   L  L  OM EU  L   OM EU  L    OM EU   L   L    OM EU   L    L    As a consequence dynamic programming is sound and complete for the optimization of Order of Magnitude Expected Utility  Corollary    There exists a polynomial algorithm for finding a strategy optimal w r t  the Order of Magnitude Expected Utility for any kappa decision tree      Conclusion  In this paper  we have shown that the strategy optimization in possibilistic decision trees is tractable for most of the criteria  extending the results about the qualitative utility criteria to other criteria  namely the likely dominance rule  We have also shown that the problem is intractable for the Choquet based criteria  Finally  we have extended this work to OMEU  defining a new model for sequential decision trees  extending the notion of reduction to kappa lotteries and showing that this models obey the weak monotonicity principle  These results are summarized in Table    It should be noticed that the optimization of the Table    Results about the complexity of DT  OP T   Upes Uopt P U ChN Ch L LN OMEU P P P NP hard NP hard P P P possibilistic Choquet integrals is only NP hard  the computation of the Choquet value of a possibilistic strategy is polynomial  whereas this computation can be more costly for other capacity measures  for instance computing the Choquet value of a strategy on the basis of its multi prior expected utility is itself a NP hard problem   and the corresponding optimization problem is probably beyond NP  So  it appears that the use of possibilistic decision criteria does not lead to an increase in complexity  except for Choquet integrals  This is good news and allows the extension of our work to possibilistic decision diagrams  Concerning the Choquet case  further work includes the development of a direct evaluation algorithm for possibilistic influence diagrams where possibilistic Choquet integrals are used as a decision criteria inspired by the variable elimination approach   
 Qualitative possibilistic networks  also known as min based possibilistic networks  are important tools for handling uncertain information in the possibility theory framework  Despite their importance  only the junction tree adaptation has been proposed for exact reasoning with such networks  This paper explores alternative algorithms using compilation techniques  We first propose possibilistic adaptations of standard compilation based probabilistic methods  Then  we develop a new  purely possibilistic  method based on the transformation of the initial network into a possibilistic base  A comparative study shows that this latter performs better than the possibilistic adaptations of probabilistic methods  This result is also confirmed by experimental results      INTRODUCTION  In possibility theory there are two different ways to define the counterpart of Bayesian networks  This is due to the existence of two definitions of possibilistic conditioning  product based and min based conditioning  Dubois and Prade         When we use the product form of conditioning  we get a possibilistic network close to the probabilistic one sharing the same features and having the same theoretical and practical results  However  this is not the case with min based networks  In this paper  we are interested in the inference problem in multiply connected networks  which is known as a hard problem  Cooper         More precisely  we propose three compilation methods for min based possibilistic networks  The compilation of Bayesian networks is always considered as an important area  Recently  researchers  Salem Benferhat CRIL CNRS University of Artois France        benferhat cril univ artois fr  Rolf Haenni RISIS Bern University Switzerland  CH      rolf haenni bfh ch  have been interested in various kinds of exact and approximate Bayesian networks inference algorithms using compilation techniques  Darwiche         Chavira and Darwiche         Wachter and Haenni         etc  Despite the importance of possibility theory  there is no compilation that has been proposed for possibilistic networks  This paper analyzes this issue by first adapting well known compilation based probabilistic inference approaches  namely the arithmetic circuit method  Darwiche        and the logical compilation of Bayesian Networks  Wachter and Haenni         Both of them are based on a networks encoding into a logical representation and a compilation into a target compilation language  namely  DNNF  From there  all possible queries are answered in polynomial time  The third method exploits results obtained on one hand in  Benferhat et al         that transforms a minbased possibilistic network into a possibilistic knowledge base  and on the other hand results obtained regarding compilation of possibilistic bases  Benferhat et al         in order to assure inference in polytime  This method that is purely possibilistic is flexible since it permits to exploit efficiently all the existing propositional compilers  The rest of this paper is organized as follows  Section   gives a briefly background on possibility theory  possibilistic logic  possibilistic networks and introduces some compilation concepts  Section   is dedicated to possibilistic adaptations of compilation based probabilistic inference methods  Section   presents a new inference method in possibilistic networks using compiled possibilistic knowledge bases  Experimental study is presented in Section            BASIC CONCEPTS POSSIBILITY THEORY  This subsection briefly recalls some elements of possibility theory  for more details we refer to  Dubois and Prade         Let V    X    X         XN   be a set of   variables  We denote by DXi    x        xn   the domain associated with the variable Xi   By xi we denote any instance of Xi    denotes the universe of discourse  which is the Cartesian product of all variable domains in V   Each element    is called a state of   The notion of possibility distribution denoted by  is a mapping from the universe of discourse to the unit interval         To this scale  two interpretations can be attributed  a quantitative one when values have a real sense and a qualitative one when values reflect only an order between the different states of the world  This paper focuses on the qualitative interpretation of possibility theory  Given a possibility distribution   we can define a mapping grading the possibility measure of an event    by      max      has a dual measure which is the necessity measure N             Conditioning consists in modifying our initial knowledge  encoded by a possibility distribution   by the arrival of a new certain piece of information     The qualitative interpretation of the scale        leads to the well known definition of min conditioning  Hisdal          Dubois and Prade                if                         otherwise      POSSIBILISTIC LOGIC  Possibilistic logic  Dubois et al         handles qualitative uncertainty in a logical setting  A possibilistic logic formula is a pair  p  a  where p is a propositional formula and a its uncertainty degree which estimates to what extent it is certain that p is true  The higher is the weight  the more certain is the formula  A possibilistic knowledge base  is made up of a finite set of weighted formulas  i e        pi   ai    i          n        where ai is the lower bound on N  pi    Each possibilistic knowledge base induces a unique possibility distribution such that     and   pi   ai          if     pi              max  ai      pi   otherwise where    is propositional logic entailment       POSSIBILISTIC NETWORKS  A min based possibilistic network over a set of variables V   denoted by Gmin is composed of    a graphical component that is a DAG  Directed  Acyclic Graph  where nodes represent variables and edges encode the links between the variables  The parent set of a node Xi is denoted by Ui    Ui    Ui         Uim    For any ui of Ui we have ui    ui    ui         uim   where m is the number of parents of Xi   In what follows  we use xi   ui   uij to denote  respectively  possible instances of Xi   Ui and Uij     a numerical component that quantifies different links  For every root node Xi  Ui      uncertainty is represented by the a priori possibility degree  xi   of each instance xi  DXi   such that maxxi  xi        For the rest of the nodes  Ui      uncertainty is represented by the conditional possibility degree  xi  ui   of each instances xi  DXi and ui  DUi   These conditional distributions satisfy the following normalization condition  maxxi  xi  ui        for any ui   The set of a priori and conditional possibility degrees in a min based possibilistic network induce a unique joint possibility distribution defined by the following chain rule  min  X        XN     min  i    N        Xi   Ui         COMPILATION CONCEPTS  A target compilation language is a class of formulas which is tractable for a set of transformations and queries  Compilation languages are compared in terms of their spatial efficiency via the succinctness criteria and also in terms of the set of logical queries and transformations they support in polynomial time  see  Darwiche and Marquis        for more details   Within the most effective target compilation languages  we cite the Decomposable Negation Normal Form  DNNF   Darwiche         This language is universal and presents a number of properties  determinism  smoothness  etc   that makes it of a great interest  It supports a rich set of polynomial time logical operations  To define DNNF  the starting point is Negation Normal Form  NNF  which is a set of propositional formulas where possible connectives are conjunctions  disjunctions and negations  A set of important properties may be imposed to NNF  such that    Decomposability  the conjuncts of any conjunction in NNF do not share variables    Determinism  two disjuncts of any disjunction in NNF are logically contradictory    Smoothness  the disjunct of any disjunction in NNF mentions the same variables  These properties lead to a number of interesting subsets of NNF  Within these subsets  the language DNNF  Darwiche        is one of the most effective target compilation languages that supports the decomposability  We can also mention  the d DNNF sat    isfying determinism  sd DNNF satisfying smoothness and determinism  etc  Each compilation language supports some queries and transformations in polynomial time  In what follows we are in particular interested by conditioning and forgetting transformations  Darwiche and Marquis           and  as max and min operators  respectively   A sentence in  sd DNNF is a sentence in  DNNF satisfying decomposability  determinism and smoothness      In  Darwiche         authors have focused on inference in compiled Bayesian networks  The main idea is based on representing the network using a polynomial and then retrieving answers to probabilistic queries by evaluating and differentiating the polynomial  This latter itself is exponential in size  so it has been represented efficiently using an arithmetic circuit that can be evaluated and differentiated in time and space linear in the circuit size  In what follows  we propose a direct adaptation of this method in the possibilistic setting  Given a min based possibilistic network  we first encode it using a possibilistic function fmin defined by two types of variables   POSSIBILISTIC ADAPTATIONS OF COMPILATION BASED PROBABILISTIC INFERENCE METHODS  There are several compilation methods which handle the inference problem in probabilistic graphical models  In this section  we first propose an adaptation of the arithmetic circuit method of  Darwiche         Then we will study one of its variants proposed in  Wachter and Haenni         namely the logical compilation of Bayesian Networks  DNNF has been introduced for propositional language  Recall that in qualitative possibility theory  we basically manipulate two main operators Max and Min  These operators fully make sense when we deal with qualitative plausibility ordering  Therefore  we propose to define concepts of  DNNF  resp   d DNNF   sd DNNF  as adaptations of the DNNF language  resp  d DNNF  sd DNNF   Darwiche        in the possibilistic setting  definition     Definition    A sentence in  DNNF is a rooted DAG where each leaf node is labeled with true  false or variables instances and each internal node is labeled with max or min operators and can have arbitrarily several children  Roughly speaking   DNNF is the same as the classical DNNF although its operators are max and min instead of  and   respectively  Example    Figure   depicts a sentence in  DNNF  Consider the Min node  root  in this figure  This node has two children  the first contains variables A  B while the second contains variables C  D  This node is decomposable since its two children do not share variables        INFERENCE USING POSSIBILISTIC CIRCUITS   Evidence indicators  for each variable Xi in the network   we have a variable xi for each instance xi  DXi    Network parameters  for each variable Xi and its parents Ui in the network  we have a variable xi  ui for each instance xi  DXi and ui  DUi   fmin   max x  min  xi  ui  x  xi xi  ui       where x represents instantiations of all network variables and ui  x denotes the compatibility relationship among ui and x  The possibilistic function fmin of a possibilistic network represents the possibility distribution and allows to compute possibility degrees of variables of interest  Namely  for any piece of evidence e which is an instantiation of some variables E in the network  we can instantiate fmin as it returns the possibility of e   e   Definition   and Proposition     Definition    The value of the possibilistic function fmin at evidence e  denoted by fmin  e   is the result of replacing each evidence indicator xi in fmin with   if xi is consistent with e  and with   otherwise  Proposition    Let Gmin be a possibilistic network representing the possibility distribution  and having the possibilistic function fmin   For any evidence e  we have fmin  e     e    Figure    A sentence in  DNNF   A sentence in  d DNNF is a sentence in  DNNF satisfying decomposability and determinism  viewing  Let figure   be the min based possibilistic network used throughout the paper  The possibilistic function of the network in figure   has   terms corresponding to the   instantiations of variables F  B  D  Two of these terms are as follows    is outlined by algorithm    Note that the suffix P F is added to signify that this method uses a possibilistic function  fmin   before ensuring the CNF encoding  Algorithm    Inference using  DNNF   DNNFP F    Figure    Example of Gmin    fmin   max min d    f    b    d   f   b    f    b     min  d    f    b    d   f   b    f    b          If the evidence e    d    b    then fmin  d    b    is obtained by applying the following substitutions to fmin   d       d       b       b       f    f       This leads to  e         The possibilistic function fmin is then encoded on a propositional theory  CNF  using xi and xi  ui   For each network variable Xi   the encoding contains the following clauses  xi  xj     xi  xj   i    j       Moreover  for each propositional variable xi  ui   the encoding contains the clause  xi  ui          uim  xi  ui       The CNF encoding  denoted by Kfmin recovers the min joint possibility distribution  proposition     Proposition    The CNF encoding Kfmin of a possibilistic network encodes the joint distribution of given network  Once the CNF encoding is accomplished  it is then compiled into a  DNNF  from which we extract the possibilistic circuit p  definition    that implements the encoded fmin   Definition    A possibilistic circuit p encoded by a  DNNF sentence  c is a DAG in which leaf nodes correspond to circuit inputs  internal nodes correspond to max and min operators  and the root corresponds to the circuit output  As in the probabilistic case  Darwiche         this circuit can be used for linear time inference  More precisely  computing the possibility degree of an event consists on evaluating p by setting each evidence indicator x to   if the event is consistent with x  to   otherwise and applying operators in a bottom up way  This possibility degree corresponds exactly to the one computed from the min joint possibility distribution  proposition     This method referred to  DNNFP F  Data  Gmin   instance of interest x  evidence e Result   x e  begin Compilation into  DNNF Encode Gmin into fmin using equation   EncodeCNF of Gmin into  using equations         Compile  into  c p  Possibilistic Circuit of  c Inference Applying Operators on p  x  e   Root Value  p    x e    e   Root Value  p   e  if  x  e    e  then  x e    x  e  else  x e     return  x e  end  Proposition    Let Gmin be a possibilistic network  Let min be a joint distribution obtained by chain rule  Then for any a  Da and e  DE   we have  A   a E   e    min  A   a E   e  where min  A   a E   e  is obtained from min using equation   and  A   a E   e  is obtained from algorithm    The key point to observe here is that this approach can handle possibilistic circuits of manageable size as in the probabilistic case since some possibility values may have some specific values  for instance  whether they are equal to   or    and whether some possibilities are equal  In this case  we can say that the network exhibit some local structure  By exploiting it  the produced circuits can be smaller  In fact  the normalization constraint relative to the initial network will mean that we will have several values equal to    Thus the idea is to make an advantage from such a local structure which has a particular behavior with the max operator in order to construct more compact possibilistic circuits w r t  standard ones as stated by the following proposition  Proposition    Let N bposs and N bproba be the number of clauses in the possibilistic and probabilistic cases  respectively  Then N bposs  N bproba   Note that for particular situations where probability values are   or    we have N bposs   N bproba   otherwise N bposs  N bproba   Example    To illustrate algorithm   we will consider the min based possibilistic network represented in figure    We are looking for  f   d    with f  as instance of interest and d  as evidence  First  we encode the network as a possibilistic function and encode it on CNF  This latter is then compiled into  DNNF from which a possibilistic circuit is extracted  The possibility degree  f   d    is computed using this circuit in polynomial time  For instance   f    d    is computed using p by just replacing   f    d    b    b      and applying possibilistic operators in a bottom up way as shown in figure    Hence   f   d       f    d          since  f    d               from a function f encoding the CNF  Then  we have min  xi        xj      xi        xj    i e  f recovers the min joint possibility distribution min   Comparing theoretically the probabilistic and the possibilistic case allows us to deduce the following proposition  Proposition    The possibilistic encoding of a possibilistic network given by K  equation     is more compact than the probabilistic encoding given in  Wachter and Haenni         In fact  the number of variables used in K is less than the one used in  Wachter and Haenni         In particular for parameters  our approach uses one variable per different weight  while in the probabilistic encoding one variable per parameter  For each clause in K there exists a clause of the same size in the probabilistic encoding  The converse is false   Figure    Inference using the possibilistic circuit  p          INFERENCE USING POSSIBILISTIC COMPILED REPRESENTATIONS  DNNF plays an interesting role in compiling propositional knowledge bases  It has been used to compile probabilistic networks  More precisely in  Wachter and Haenni         authors have been interested in performing a CNF logical encoding of the probability distribution induced by a bayesian network  then a compilation phase from CNF to d DNNF  In this section  we propose to adapt this encoding in the possibilistic setting by taking into consideration the local structure aspect  This allows to reduce the number of additional variables comparing to the probabilistic encoding  Let  be propositions linked to networks variables and let  be propositions linked to the possibility distribution entries  equal to     We start by looking at the possibility distribution encoding  The logical representation of a network variable Xi is defined by  Xi            ui       uim  xi  ui  xi     ui  xi  ui X  i   ui  By taking the conjunction of all logical representations of variables  we obtain the networks representation  as follows      Xi      Xi   The CNF encoding  denoted by K indeed recovers the min joint possibility distribution  proposition     Proposition    Let min be the joint possibility distribution obtained using the chain rule with the minimum operator and  be the possibility degree computed  Once the qualitative network is encoded by K   it is compiled into a compilation language that supports the transformations conditioning and forgetting and the query possibilistic computation  This language is  DNNF  proposition     Therefore  the CNF encoding is first compiled  and the resulting  DNNF is then used to compute efficiently  i e  in polynomial time a posteriori possibility degrees  proposition     This method referred to  DNNF is outlined by algo     Proposition     DNNF supports conditioning  forgetting and possibilistic computation  Algorithm    Inference using  DNNF Data  Gmin   instance of interest x  evidence e Result   x e  begin Compilation into  DNNF EncodeCNF of Gmin into  using equation    Compile  into pc Inference v   Explore  DNNF x  e  pc   v   Explore  DNNF e  pc   if v   v  then  x e   v  else  x e     return  x e  end  Proposition    Let Gmin be a possibilistic network  Let min be a joint distribution obtained by chain rule  Then for any a  Da and e  DE   we have  A   a E   e    min  A   a E   e  where min  A   a E   e  is obtained from min using equation   and  A   a E   e  is obtained from algorithm    Example    Let us illustrate algorithm    In fact   of the network of figure   is      F  B  D        f         b      f   b      d      f   b      d      f   b      d      f   b      d     such as           and   correspond respectively to               and      To compute  f   d     we should first compute  f    d    using algorithm    The first step is to check if we have at least   Algorithm    Explore  DNNF Data  a set of instances x  compiled representation pc Result   x  begin if  xi  x  xi  Ui is not a leaf node then  x     else y   xi     xi  Ui is a leaf node  Ui  x  c p y  Condition pc on y c pc  y  Forget  from p y c Applying Operators on p  y  x   Root Value of pc  y return  x  end  one  as a leaf node  In this example  we have d   f   b  and d   f   b  as leaf nodes  hence conditioning should be performed  Then  a computation step is required by applying in a bottom up way Min and Max operators on the forgotten  DNNF  Therefore   f   d       f    d               NEW POSSIBILISTIC INFERENCE ALGORITHM  In  Benferhat et al          authors have been interested in the transition of possibilistic networks into possibilistic logic bases  The starting point is that the possibilistic base associated to a possibilistic network is the result of the fusion of elementary bases  Definition   presents the transformation of a min based possibilistic network into a possibilistic knowledge base  Definition    A binary variable Xi of a possibilistic network can be expressed by a local possibilistic knowledge base as follows  Xi     xi  ui   i     i       xi  ui          The possibilistic knowledge base of the whole network is  min   X   X       Xn   In another angle  researchers in  Benferhat et al         have focused on the compilation of bases under the possibilistic logic policy in order to be able to process inference from it in a polynomial time  The combination of these methods allows us to propose a new alternative approach to possibilistic inference  This is justified by the fact that the possibilistic logic reasoning machinery can be applied to directed possibilistic networks  Benferhat et al          The idea is to encode the possibilistic knowledge base min into a classical propositional base  CNF   Let A    a         an   with a          an the different weights used in min   A set of additional propositional variables  denoted by Ai   which correspond exactly to the number of different weights  are incorporated and for each formula i   ai will correspond the propositional formula i Ai   Hence  the propositional  encoding of min   denoted by K is defined by  K    i  Ai    i   ai    min          The following proposition shows that the CNF encoding K recovers the min joint possibility distribution  Proposition    Let min be the joint possibility distribution obtained using the chain rule with the minimum based conditioning and let K be the propositional base associated with the possibilistic network given by equation     Let i be a propositional formula associated with a degree ai   Then            iff  A         An      K is consistent       ai iff  A         Ai      K is inconsistent and  A         Ai       K is consistent  The CNF encoding K is then compiled into a target compilation language in order to compute a posteriori possibility degrees in an efficient way  Here  we are interested in a particular query useful for possibilistic networks  namely what is the possibility degree of an event A   a given an evidence E   e  Therefore  we propose to adapt the algorithm given in  Benferhat et al         in order to respond to this query as shown by algorithm    Proposition    shows that the possibility degree computed using algorithm   and the one computed using the min based joint possibility distribution are equal  Note that this approach is qualified to be flexible since it takes advantage of existing propositional knowledge bases compilation methods  Benferhat et al          This method referred to DNNF PKB is outlined by algorithm    Algorithm    Inference using DNNF Data  Gmin   instance of interest x  evidence e Result   x e  begin Transformation into K Transform Gmin into min using definition   Transform min into K using equation    Inference c K  T arget K   c K  K StopCompute  false i   x e     while  K   Ai  e  and  i  k  and  StopCompute false  do K  condition  K  Ai   if K  x then StopCompute true  x e     degree i  else ii   return  x e  end  Proposition     Let Gmin be a possibilistic network  Let min be a joint distribution obtained by   chain rule  Then for any a  Da and e  DE   we have  A   a E   e    min  A   a E   e  where min  A   a E   e  is obtained from min using equation   and  A   a E   e  is obtained from Algo      Indeed  in  DNNFP F   we associate propositional variables not only to possibility degrees  parameters   but also to each value xi of Xi   While in DNNF PKB only m new variables are added  one variable per different degree    Example    To illustrate algorithm   we will consider  Let us now analyze these three approaches from experimental points of view  Our experimentation is performed on random possibilistic networks  More precisely  we have compared DNNF PKB and DNNFP F on     possibilistic networks having from    to    nodes  As mentioned that the approaches focus mainly on encoding the possibilistic network as a CNF then compile it into the appropriate language  hence  it should be interesting to compare the CNF parameters  the number of variables and clauses  and the DNNF parameters  the number of nodes and edges  for the two methods   the min based possibilistic network represented in figure    The CNF encoding is as follows   K    d   f   b   A       b   A       d   f   b   A       f   A       d   f   b   A       d   f   b   A    such as A         A         A        and A        are propositional variables followed by their weights under c brackets  Compiling K into DNNF results in  K     b   A       A   f      f    d    A   d          b     f    d    A   d         f    A      d    A   d         c The computation of  f   d    using K requires two iterations  Therefore   f   d         degree            Due to the compilation step  this algorithm runs in polynomial time  Moreover  the number of additional variables is low since it corresponds exactly to the number of priority levels existing in the base      COMPARATIVE AND EXPERIMENTAL STUDIES  The paper analyzes three compilation based methods  namely DNNF PKB   DNNF and  DNNFP F   The first dimension that differentiates the three approaches proposed in this paper is the CNF encoding  It consists of specifying the number of variables and clauses per approach  The CNF of DNNF PKB is based on encoding x where x is an instance of interest having a possibility degree different from    In  DNNF  we write implications relative to instances having   as possibility degree  We can notice that the local structure in both methods is exploited in semantically different ways  In DNNF PKB  the encoding uses the number of different weights as the number of additional variables while the  DNNF encoding uses the number of the non redundant possibility degrees different from   in the distributions  Regarding the number of clauses  both methods handle possibility degrees different from    This leads us to the following proposition        CNF PARAMETERS  First we propose to test the CNF encodings characterized by the number of variables and the number of clauses  Regarding DNNF PKB  the number of additional variables correspond to the number of weights which are different  While in  DNNFP F   variables are both those associated to the possibility degrees of each distribution and those to variables instances  The number of clauses for each method is related to the CNF encoding itself  Figure   shows the results of this experimentation  Each approach is characterized by a curve for the average number of variables and a curve for the average number of clauses  It is clear that the higher the number of nodes considered in the possibilistic network  the higher the number of variables and clauses  Figure   shows that DNNF PKB has the lower number of variables and clauses comparing to  DNNFP F   which confirms the theoretical results detailed above   Proposition     The CNF encodings of DNNF PKB and  DNNF have the same number of variables and clauses  The CNF encoding of  DNNFP F is different from the ones of DNNF PKB and  DNNF  Proposition    shows the difference between  DNNFP F and DNNFPKB in terms of number of variables and clauses  Proposition     The number of variables and clauses in  DNNFP F is more important than those in DNNF PKB   Figure    CNF parameters         DNNF PARAMETERS  Once we obtain the CNF encodings  it is important to compare the number of nodes and edges for each compiled base  Figure   represents the average size of the compiled bases for the two methods in terms of nodes and edges numbers  We remark that the number of nodes and edges depends deeply on CNF parameters  More precisely  the number of nodes and edges in DNNF PKB is considered narrow comparing to  DNNFP F   This can be explained by the lower number of variables and clauses on CNFs and the local structure which shrinks the sizes of compiled bases  Comparing DNNF PKB to  DNNFP F   the behavior of DNNF PKB is important    Pearl         Benferhat and Smaoui         Acknowledgements We thank the anonymous reviewers for many interesting comments and suggestions  Also  we wish to thank Mark Chavira for our valuable discussions on this subject  The third author would like to thank the project ANR Placid   
