    The paper deals with optimality issues in con  these labels are called separators  see Figure la    nection with updating beliefs in networks  We address two processes  triangulation and con struction of junction trees  In the first part     network   In the second part  we argue that  any exact method based on local calculations must either be less efficient than the junction tree method  or it has an optimality problem equivalent to that of triangulation      attaching a pote ntial to all separators  initially  the neutral potential consisting of ones    we give a simple algorithm for constructing an optimal junction tree from a triangulated  giving all links in the junction tree a label con sisting of the intersection of the adjacent nodes     letting the nodes communicate via the separa tors   a message from U to V with separator S  has the form that  Pu is marginalized down to S  resulting in     Psis placed on the separator and   S   S  is multiplied on v  see Figure  b    INTRODUCTION  The junction tree propagation method  Jensen et al         Lauritzen and Spiegelhalter        is designed for propagation in Markov networks    cjl  S  cjl S   cjl  S   an undirected graph with discrete variables as nodes     for each clique  U  in the graph there is a poten  tial  Pu  which is a non vanishing function from the set of configurations of  U  to the set of non  negative reals    a   The compilation part of the method is to   FIGURE     triangulate the graph  i e   add extra links such that every cycle of length greater than three has a chord      construct   a  A junction tree   b  Message passing in junction trees  It is so  that after a finite number of message passes  form a potential  Pu for each c lique  U  of the tri  angulated graph     b   a  junction tree over the cliques   A junction tree over the cliques is characterized by the  so called junction tree property  For each pair U  V of cliques with intersection S  all cliques on the path between U and  V containS   The propagation part of the method consists of  between neighbours in the junction tree  each po tential in the junction tree holds the  possibly non normalized  marginal of the joint probability distribu tion for the entire set of variables  In fact  the message passing can be organized so that it is sufficient with exactly one pass in each direction of the links in the junction tree  Therefore  in complexity considerations for propagation in junction trees  one can associate a local measure  C U  V  to  links   U  V    where  C U  V   indicates time space consumption for the two passes         Optimal Junction Trees  The compilation is not deterministic  Markov net works may have several different triangulations yield ing different sets of cliques  and a triangulated network may have several different junction trees  We therefore would like to have algorithms yielding optimal trian gulations and optimal junction trees with respect to complexity  However  the optimality problem for tri angulations isN J  complete  Arnborg et al          In the first part of the paper  we address the optimal ity problem for junction trees given the triangulated graph  and we present a simple algorithm which is quadratic in the number of cliques  In the last section  we address the triangulation pro cess and ask the question whether it may be possible to come up with a propagation method which does not contain anN J  hard optimality problem  The answer is discouraging  We show that any local calculation method must involve a hidden triangulation  and we use this to conclude that the method is either less ef ficient than the junction tree method  or it has an N J  hard optimality problem     JUNCTION TREES AND MAXIMAL SPANNING TREES  Throughout the remainder of the paper  we consider a  triangulated connected graph G with clique set e  The cliques of G are denoted b I the letters U  V  W  ll   etc  We shall not distinguish between a clique and its set of variables  So we talk of the intersection of cliques meaning the set of variables common to the cliques  Intersections are denoted by letters R S  R   etc  Definition   The junction graph for G has e as nodes  and for each pair U  V of cliques with nonempty inter section R there is a link with label R  Each link has a weight which is the number of variables in the label  Theorem   A spanning tree for the junction graph of G is a junction tree if nd only if it is a spanning tree of maximal weight   Theorem   has been proved independently by Shibata        and Jensen         Here we will give a proof much simpler than the o tiginal ones  Before giving the proof  we shall recall two algorithms for the construc tion of maximal spanning trees             cb FIGURE     Paths in T and T   Prim s algorithm constructs a sequence To   Tn  of maximal spanning trees for the subgraph deter mined byN       Algorithm    Kruskal   Choose successively a link of maximal weight not pro ducing a cycle  Kruskal s algorithm works with a forest of partial max imal weight spanning trees  Whenever a link is cho sen  two partial trees are connected into a new partial spanning tree of maximal weight  Both algorithms result in maximal weight spanning trees  and each maximal weight spanning tree can be constructed through any of the two algorithms   Proofs can be found in many textbooks on graph algorithms  e g    Goudran and Minoux        and  McHugh          Proof of Theorem    Let T be a spanning tree of maximal weight  Let it be constructed by Prim s al gorithm such that T    Tn  T is a sequence of partial maximal weight spanning trees       Assume that T is not a junction tree  Then  at some stage m  we have that Tm  can be extended to a junc tion tree T  while Tm    cannot  Let  U  V  with la belS be the link chosen at this stage  V E Tm      see Figure     Since Tm     cannot be extended to a junction tree  the link  U  V  is not a link in T  So  there is a path in T  between U and V not containing  U  V   This path must contain a link  U   V   with labelS  such that U   E T m  and V   j  Tm   see Figure     Since T   is a junction tree  we must haveS S   and sinceS was chosen through Prim s algorithm at this stage  we also have S l I           Hence  S      Algorithm    Prim      Put N  U   where U is an arbitrary node   Now  remove the link  U   V   from T  and add the link  U  V   The result is a junction tree extending Tm      contradicting the assumption that it cannot be extended to a junction tree       Choose successively a link  W  V  of maximal weight such that W E N and V  j  N  and add V toN   Next  let T be any non maximal spanning tree  We shall prove that T is not a junction tree  Again  let T    T   be a sequence of maximal trees con                     Jensen and Jensen  FIGURE    The thinning task at stage  i     in Kruskal s algorithm   structed through Prim s algorithm  Let the construc  trees of maximal weight  Note that any thinning at a  tion be so that a link from  given stage will result in the same connected compo  ble  Let  m  T is chosen whenever possi  be the first stage where this is not possible   and let   U  V  with separator S be the link actually chosen  U E Tm V  Tm   In T there is a path be tween U and V  As in the first part of the proof  we have that this path contains a link  U    V    with la belS  such that U  E Tm and V   Tm  see Figure     Since  U    V   could not be chosen  we have S I  I   S l I  and thereforeS contains variables not inS    Hence  T does not satisfy the junction tree condition         OPTIMAl JUNCTION TREES  W henever the junction graph has several spanning trees of maximal weight  there are accordingly several junction trees  Assume that there is a real valued mea  sure on junction trees yielding a priority among them  and assume that this measure can be decomposed to a local measure  C U  V   call the measure a  cost   attached to the links   We  We may also assume that  the entire measure is strictly increasing in the local measures  and that an optimal junction tree is one of minimal cost   nents  and therefore the thinning chosen has no impact on the next stage   Hence  if we in the construction  have a secondary priority  cost  say   we can perform the thinning by using Kruskal s algorithm according to cost  In this way we will end up with a maximal weight spanning tree of minimal cost  see Figure       We conclude these considerations with  Theorem    Any minimal cost juncti on tree can be constructed by successively choosing a link of max imal weight not introducing cycles  and if several links may be chosen then a link of minimal cost is selected   A proof of Theorem stages      is an induction proof over the  The induction hypothesis is that at the end  of each stage  the forest consists of partial maximal distance junction trees   Remark    An analoguous algorithm based on Prim s  algorithm will also construct minimal cost junction trees   Let us take a closer look at the construction of junction trees through Kruskal s algorithm  Let w          Wn be the different weights of  G in  decreasing order  The al  gorithm can be considered as running through n stages  Corollary   All juncti on trees over the same triangu lated graph have the same separators  also counting multiplicity    characterized by the weight of the links chosen  At the end of stage  i   all links possible of weight w   have been chosen  and a forest  T              T            Wi  of partial  Proof   Consider stage i     Figure       A cycle can be  broken by removing any link of weight Wi    If   U  V   maximal weight spanning trees has been constructed   with separatorS is removed  then all separators in the  Now  the task at stage  remaining paths between  i     can be considered in the fol  lowing way  Add all links of weight Wi    to the forest   and break the cycles by removing links of weight Wi       Any thinning will result in a forest of partial spanning  U  and  V  must contain S   This means that any separator of weight Wi    on these paths must equalS  By thinning we therefore remove the same separators       Optimal Junction Trees         For each separator  establish links to all cliques and separators containing it     For each separator  with multiplicity n   choose n    links to supersets without introducing cycles   Theorem   Any minimal cost Almond tree can be constructed by successively choosing links for sepa rators of maximal weight  and if several links may be chosen  take one of minimal complexity   A proof of Theorem   b    a     is  an induction proof along the  same line as a proof of Theorem      FIGURE      a  Contraction of the junction tree from Figure     THE NECESSITY OF TRIANGULATION   b  An Almond tree         for constructing optimal junction trees given the tri  In the former sections we gave an efficient algorithm  ALMOND TREES  angulated graph  Thereby all steps from DAG to junc  Almond and Kong         suggest another type of junc  tion tree  Compared to the junction trees in  Jensen et al            they give some reduction in computa  tional complexity   tion tree is covered by efficient algorithms yielding an optimal output except for the triangulation  Since this problem is N P complete  we cannot hope for an efficient algorithm yielding an optimal triangulation  It appears that a one step look ahead heuristic pro  Observation   If n links have the same separator  the  vides the best triangulations  An alternative propaga  communication scheme can be contracted  Figure  a    tion scheme is conditioning  Pearl           The N P  complete part of conditioning is the determination of In junction trees  each separator holds exactly one po  a cut set for the DAG  and Becker and Geiger  tential table where the marginal last communicated  have given an algorithm which guarantees a cut set  is stored   space no larger than the square of the space for an  In contracted junction trees  a separator  with n neighbours must hold at least n        potential  optimal cut set  Other schemes exist  like  e g   arc         however  as has been shown         all known methods do in fact  tables to store marginals communicated from neigh  reversal  Shachter   bours  This means that there is no saving in space   by Shachter et al   There is  however  a saving in time  since a number of  contain a hidden triangulation   marginalizations are avoided           Since belief updating in Bayesian networks is N  P hard  Observation   If a separator is a subset of another sep  arator  they can be linked  Figure   b     Cooper           there is not much hope of finding a  scheme avoiding an N  P hard step  However  Cooper s result does not yield that any scheme will contain such a step   Cooper showed that through belief updat  The type of calculations are the same for links between  ing  the satisfiability problem for propositional calcu  separators as for links between separators and cliques   lus  can  be solved  but it may still be so that a search  S   for an optimal structure for belief updating is poly  the number of supersets to which it shall be linked  and for each link  S  S    we can associate a local cost  nomially solvable  Note namely that the space of the  Due to the corollary  we know for each separator  C S  S     Also  new schemes are proposed  Zhang and Poole   Junction trees simplified through these two observa tions we call  cliques are exponential in their presentation   Almond trees   The construction of an  Almond tree may go as follows          which may seem as if they avoid the triangula  tion problem  We will in this section argue that  any  scheme for belief updating  meeting certain require ments  will contain a hidden triangulation  Then  if    From the triangulated graph  the set of cliques  the complexity ordering of the hidden triangulations  and the set of separators  including multiplicity   follows the ordering in the original scheme  we can con  This can be done through elim  dude that if the scheme has a polynomially solvable  ination in the triangulated graph  but it is not  optimality problem  then the junction tree method ei  important for our considerations   ther provides more efficient solutions or   P  is established      N  P         Jensen and Jensen  The considerations to come are somewhat specula tive and at places they need further precision  Hence  we call the results  statements  rather than theorems  However  a reader looking for alternative propagation methods can use them as guidelines preventing inves tigations of several alternatives  FIGURE     Specifications  A graph representing a general propagation task   U  A          B  is a universe consisting of a finite set of discrete variables  The joint probability P U  is a distribution over the configurations Xu  Ax    x B     A local representation of P U  consists of a set  P U          P Un    where U          lin is a covering of U  and P U    is the marginal distribution of Ui  A local representation can be visualized by a graph G with the variables as nodes and with a link between two variables if there is a Ui containing both  G is called the representing graph  The propagation task can be formulated as follows  Let P   Ui  be substituted forP Uil  ifP  U  P U  x P  Ui  P Ui  is well defined  then calculate the new marginals P  U          P  Unl    By a scene for a propagation task  we understand a universe U together with a covering U         lin such that the covering equals the cliques in the representing graphs  An instance of a propagation task is a pair  G  P   where G is an undirected graph  and P is a set of marginals of a joint distribution P U  to the cliques of G  Let U be a universe  By a local method on U  we un derstand an algorithm working only on subsets of U  More precisely  The algorithm consists of a control structure and a fixed set Pr         Pr   of proce dures such that each Pri only processes information on Vi c  U  We call Vi the scope of Pri  The repre senting graph G  for a local method is defined as the graph with U as nodes  and with links between vari ables if there is a scope containing them  Notice that the cliques of G   need not be scopes  We have defined a local method such that the control structure mainly consists of controlling message pass ing between procedures  Note that between Pr   and Pri only information on Vi n Vi is worth passing   First  we shall transform the problem to propositional calculus  Lemma   Let P U          P Uml be projections of the joint probability table P U   Let Pos U  be the table of possible configurations of U   Pos u        if P u      otherwise     if P  ud     otherwise  Define Pos U    as  Pos u        Then Pos Ui    if and only if Ui is a projection of a possible configuration     Proof  Since P U    is the marginal of P U   we have that P u        if and only if ut is the projection of at least one configuration with positive probability    The lemma shows that any scheme for belief updating has the calculus of possible configurations in proposi tional calculus as a special case  So  if we can prove Statement   for this calculus  we are done  We shall start with an example which is the corner stone of the proof  Example   Let the graph in Figure   represent a gen eral propagation task over the propositional calculus  and let Pas be the potential giving   for possible con figurations and   for impossible ones   Let PrAs  PrAc  Prsn  Prnc be procedures for solv ing the task  the index indicates the scope  see Fig ure      A general local belief updating method for a scene represented by G is a local method solving the propa gation task for each instance  G  P    We shall construct an instance which cannot be solved by the procedures  For each variable we only use the first two states  This means that all other states are impossible   We aim at the following   Initially  we have for i  j        Statement    Let G represent a scene  and let a gen eral local belief updating method be represented by the graph G   Then G  contains a triangulation of G   Pas  at  bj    Pas Ut  Cj     Pos bi  dj    Pos ci dj  l          for all i  j if and only if i if and only if i for all i  j        j j   Optimal Junction Trees       Proof of Statement    Assume that G   does not contain a triangulation of G  Then there is a cycle C in G such that the subgraph of G   consisting of the nodes in C is not triangulated  Let C  be a chordless cycle of length greater than three in that subgraph  Let A           An be the nodes of C    FIGURE     The scopes for the procedures and the communication channels  That is  A and C as well as B and D are forced into the same state  and everything else is possible  Note that the Pas relations above are projections of the Pas relation over the universe   if and only if Pos   U   bi      Pos   ai  ck     Pos bj  df      Pos ck  de         Now  assume we get the information that the config urations  a   b   and  a   b   are impossible  This is equivalent to replacing the relation Pos ai  bj  by Pos  ai  bj         if and only if  i     j   and i j       Now  the propagation task is to determine Pos   A  C   Pos    B   D   and Pos    C  D  such that these local rela tions are projections of the unique universal relation Pos  A  B  C  D   satisfying the relations Pos  A  B   Pos A  C   Pos B  D   and Pos C  D   Clearly  Pos  ai bi ck dt  l if and only if i j e  and therefore Pos  ck de  l if and only    k     k             if  The tool for achieving this result is the set PrA s   PrAc  Prso  and Prco of procedures  Since PrAB can only process information on the variables A and B  and PrAc can only process information on A and C  then the only valuable information to communicate be tween the two procedures is information on A  see Fig ure     That is  between Pr  and Prz with scopes V  and V   respectively  only information on V   n V  need to be communicated  The new relation Pos  A  B  in troduces a constraint between the state of A and the state of B  but since only information on A alone and B alone can be communicated  the constraint cannot be communicated to Prc   Note that if a cycle contains more than   variables  the construction can be extended by clamping the states of further intermediate variables   We now can construct an instantiation  which cannot be propagated correctly      Let a configuration be possible if and only if its projection to A  x    x An is possible      Perform the construction as shown in the example    By the proof of Statement    we see that it can be generalized to systems with other uncertainty calculi like  e g   Dempster Shafer belief functions or fuzzy systems  In fact  the reasoning can be applied to any calculus having propositional calculus as a special case  An axiomatization of these possible calculi is outside the scope of this paper  but the axioms in  Shenoy and Shafer        form a good starting point  Concerning complexity we still have a couple of loose ends  Although a general scheme involves a hidden tri angulation  the computational complexity needs not be of the same kind as for the junction tree scheme  In the junction tree scheme the complexity is propor tional to the number of configurations in the cliques  Therefore a general local scheme has an equivalent computational complexity if it is proportional to the number of configurations in the scopes  This is the case if each configuration has an impact on the mes sages sent in the algorithm  In this paper we shall not give sufficient conditions for this to hold  The second loose end has to do with optimality  A gen eral scheme is  e g   to work with P U  only  This cor responds to working with the complete graph over U  This scheme has a trivial optimality problem  but the junction tree method can do much better even for sub optimal triangulations  Therefore we conclude   Statement   If a general local propagation scheme has a complexity at least proportional to the num ber of configurations in the scopes  and its opti mality problem can be solved in polynomial time  then either the junction tree scheme can do better or  J    N J    Acknowledgements The work is part of the ODIN project at Aalborg Uni versity  and we thank our colleagues in the group for inspiring discussions  The work is partially funded by the Danish Research Councils through the PIFT programme         Jensen and Jensen  
  quacy of the model and the reliability of data used   After a brief introduction to causal proba  system comes up with  At least there will be kept  Therefore  no expert will blindly accept what the bilistic networks and the HUG IN approach   a critical eye on the data  and mainly one will  I  the problem of conflicting data is discussed   look for conflicts in the data or conflicts with the  A measure of conflict is defined   model   I  MUNIN  Finally it is discussed how to dis  I I I I I I I I I I  and it  is used in the medical diagnostic system tinguish between conflicting data and a rare case   In this paper we present  a  way of building such  a critical eye into a system with a CPN model  Our suggestion requires an easy way of calculating probabilities for specific configurations  We start with a brief introduction to the HUGIN approach      In section   we discuss CPN s and data conflict   Introduction  In section     a measure of conflict is defined  and  it is shown that this measure is easy to calculate It has for many years been widely recognized that  in HUGIN and that it supports a decomposition  causal probabilistic networks  CPN s   have many  of global conflict into local conflicts   Section  virtues with respect to expert systems mainly due  reports on experience with a large CPN  and in     to the transparency of the knowledge embedded  section   we discuss how to distinguish between  and their ability to unify almost all domain knowl  conflicts in data and data originating from a rare  edge relevant for an expert system  Pearl         case   However  the calculation of revised probability dis tributions after the arrival of new evidence was for a long period intractable and therefore an ob      Causal probabilistic Networks  stacle for pursuing these virtues  Theoretical de  and the HUGIN approach  velopments in the   ies have overcome this diffi culty  Kim and Pearl      Lauritzen and Spiegel  A causal probabilistic network  CPN  is con  halter       Schachter       Cooper       Shafer  structed over a  universe   consisting of a set of  With the  states  The variables  The universe is or ganized as a directed acyclic graph  The set of parents of A is denoted by pa A    To each vari  HUGIN approach efficient methods have been im  able is attached a conditional probability table for  plemented for calculation of revised probability distributions for variables in a CPN without di  P Ajpa A     Let V be a set of variables   rected cycles  Andersen et a l          Cartesian product of the state sets of the elements  the results infered from the model rely on the ade   tables are considered as functions and they are de   and Shenoy         The Lauritzen and Spiegel  halter method has been further developed to the HUGIN approach  Andersen et al        Jensen et al       a  Jensen et al      b      As always when modelling real world domains   nodes each node having a finite set of nodes are called  in  V  and is denoted by  The  Sp V    space of V  is the  The probabilitie        noted by greek letters     and   J  If A is a variable  then  A  P A pa A   maps Sp pa A U A   into the unit interval         It is convenient to consider functions which are not normalized and take arbi trary non negative values  So in the sequel   P and   J denote such functions  Evidence can by entered to a CPN in the form of findings  Usually a finding is a statement  that a certain variable is in a particular state  After evidence has been entered to the CPN one should update the probabilities for the variables in the CPN  It would be preferable to have a local method sending messages to neighbours in the net work  However  such methods do not exist when there are multiple paths in the network  The HUGIN approach which is an extension of the work of Lauritzen and Spiegelhalter          Jensen et al     a  Jensen et al     b  repre sents one way of achieving a local propagation method also for CPN s with multiple paths  This is done by constructing a so called junction tree which represents the same joint probability distri bution as the CPN  The nodes in a junction tree are sets of variables rather than single variables  Each node V has a belief table  Pv   Sp V    Ro attached to it  The pair   V   Pv  is called a belief universe  The crucial property of junction trees is that for any pair   U  V  of nodes  all nodes on the path between U and V contain U n V  A belief table is a  non normalized  assessment of joint probabilities for a node  If S C V  then an  non normalized  assessment of joint probabilities for Sp S  can be obtained from  Pv by marginal ization   Ps   E V S  Pv Evidence can be transmitted between belief uni verses through the absorption operation    U   Pu  absorbs from  V   Pv            W   Pw  by modifying  Pu with the functions L  V S  Pv         LW U  Pw  Actually  the new belief function  Pu is defined as    Pu     P u     Evw  Pv  LU V    u     w        E ww  P LU w  Pu  where the product       J is defined as        J  x     x  P x   Based on the local operation of absorption the two propagation operations CollectEvidence and Dis tributeEvidence are constructed  When CollectEv idence in Vis called  from a neighbour W  then V calls CollectEvidence in all its neighbours  except W   and when they have finished their CollectEv idence  V absorbs from them  see figure      I I I I I I    Direction of bsorption   Ca ll of COLLECT EVIDENCE  Figure    The calls and evidence passing in Col lectEvidence When DistributeEvidence is called in V from a neighbour W then V absorbs from W and calls DistributeEvidence in all its other neighbours  Having constructed a junction tree  we need not be as restrictive with findings as in the case of CPN s  Let V be a belief universe in the junction tree  A finding on V is a function Fv     Actually  the more general notion of likelihood can be  entered  Evidence is a function Ev   not pursue this in the present paper   Sp V   I I I I I I I  Sp V           So  a finding is a statement that some configu rations of Sp V  are impossible  Note that the product of two findings f   Sp V           and     Sp W           is a finding f       Sp V U W             and f    corresponds to the conjun cion f    g  Using the HUGIN approach  it is possible to en ter findings to the CPN  or the junction tree    update the probabilities for all variables  and to    with   and   J extended to the relevant space  if necessary    I        We will  I I I I I        I I I I I I I I I I I  I I I I  I I I I  Following the tradition in probabilistic reason achieve joint probability tables for all sets of vari ables which are subsets of nodes in the junction ing to take examples from California  where bur tree  The method has proved itself very efficient glary and earthquake are everyday experiences  we even for fairly large CPN s like MUNIN  see Ole have constructed the following example  sen et al        Andersen et al         When Mr  Holmes is at his office he fre The main theorem behind the method is the fol quently gets phone calls from his neigh lowing  bour Dr  Watson telling him that his burglar alarm has gone off  and Mr  Theorem   Holmes rushing home hears on the ra dio that there has been an earthquake Let T be any junction tree over the universe U  nearby  Knowing that earthquakes have and let  Pu be the joint probability table for U  a tendency to cause false alarm  he then has returned to his office leaving his  a  If CollectEvidence is evoked in any node neighbours with the pleasure of the noise V and  Pv is the resulting belief table  from the alarm  Mr  Holmes has now in then  Pv is proportional to LU  v  Pu  stalled a seismometer in his house with a  b  If further  DistributeEvidence is evoked direct line to the office  The seismometer in V  then for any node W the result has three states  ing belief table  Pw is proportional to LU W U   for no vibrations    Before we proceed with data conflict  we will state an observation proved in Jensen et al       b   but first noted by Lauritzen and Spiegelhalter        in their reply to the discussion     for small vibrations  caused by earthquakes or passing cars      for larger vibrations  caused by ma jor earthquakes or persons walking around in the house    The CPN for this alarm system is shown in figure     Theorem    One afternoon Dr  Watson calls again Let T be a junction tree with all belief tables nor and tells that the alarm has gone off  Mr  malized  and let x        y be findings with prior Holmes checks the seismometer  it is in joint probability P x         y   Enter x          y to state    T and activate CollectEvidence in any belief uni verse for V  Let  l v be the resulting belief universe From our knowledge of the CPN  we would say for V  that the two findings are in conflict  Performing   Then  Z    v  l v   P x          y   an evidence propagation does not disclose that  The posterior probabilities are given in figure    Only in the rare situations of inconsistent data  an CPN s and data conflict   evidence propagation will show that something is A CPN represents a closed world with a finite set wrong  The problem for Mr  Holmes is whether of variables and causal relations between them  he should believe that the data originate from a These causal relations are not universal  but re rare case covered by the model  or he should reject flect relations under certain constraints  Take for that  From a CPN m pdel s point of view there is no example a diagnostic system which on the basis of blood analysis monitors pregnancy  Only diseases difference between a case not covered by the model relevant for pregnant women are represented in and flawed data  So what we can hope for to pro the model  If the blood originates from a man  the vide Mr  Holmes with is a measure indicating pos constraints are not satisfied  and the case is not sible conflicts in the data given the CPN  In MUNIN  Olesen et al        an attempt to covered by the model   A similar situation appears incorporate conflict analysis in the CPN is made  if the test results are flawed  e  g  red herrings            This is done by introducing  other  states and  other  variables  In the example of Mr  Holmes  alarm system  an  other  variable covering lighten ing  flood  baseballs breaking windows etc  could be introduced to represent unknown causes for the alarm to go off  and the Burglar variable could have an  other  state covering Mr  Holmes  mis tress having forgotten the code for switching off the burglary alarm  Though this approach is claimed to be fairly successful  it raises several problems  First of all there is a modelling problem  The effect of an  other  statement is hard to model without know ing what  other  actually stands for   What should the conditional probabilities be  In fact  these Burglary   I B             Earthquake  E         probabilities were in MUNIN constructed by feed ing the network with conflicting data and thereby tuning the tables as to make  other  light up ap E  l s propriately  y N A second problem is that conflict in data is a N                        global property  and the introduction of  other  B statements in the CPN gives only a possibility of y                       evaluating evidence locally  In order to combine Seismometer the local  other  statements to a global one  the CPN has to be extended drastically  E  I A This leads to the third major problem  which N y is more of a technical kind  The introduction of N                  other  statements to the CPN can cause a dra B matic increase in the size of the junction tree  Be y                  Alarm sides  the technique with  other  states is hard to use if the variables are not discrete  Figure    Mr  Holmes  Alarm system with seisAnother approach has been suggested by mometer  Habbena          It consists of calculating a sur prise index for the set of findings  Essentially  the surprise index off  V            is the sum of the probabilities of all findings on V with probabilities no higher thanf s  Habbena suggests that a threshold between    and     should be realistic  In the seismometer E  I E B case  the surprise index for  a  s  is     However  N y the calculation of a surprise index is exponential in N         the number variables in V and must be considered B as intractable in general  y       Figure    Joint probabilities for earthquake and   The conflict measure conf burglary posterior to a    alarm   Y  and s    Seis Our approach to the problem is that correct find mometer       ings originating from a coherent case covered by the model should conform to certain expected pat terns  If x      y are the findings  we therefore  I I I I I I I I I I I I I I I I I I I        I I I I I I  I I  should expect  P x     y      P x   x     x  P y   Hence we define the conflict measure conf as   conf x   y   log  P x  X XP y  P  X     y        where log is with base     This means that a positive conf x    y  is an in dicator of a possible conflict  For the data in section   we have conf a  s          Using theorem    conf x    y  is very easy to calculate in HUGIN  The prior probabilities P x   P y  are available before the findings are entered  and P x   y  is the ratio between the prior and the posterior normalizing constant for any belief universe   I  P x  y   z  u   consists of two sets of findings  namely  x y z  and   u v   Since the product of findings is also a finding  we can say that the two findings x   y   z and u   v meet in V  The conflict in the data meeting in V is therefore composed of the conflict between x y z and u v   the conflict inside  x y z  and inside  u v   It is easy to show that  conf x  y z u v   conf x   y   z  u  z   conf x  y z    conf u v  Furthermore  as indicated at figure    P  x  y   z  and P u   v  can be calculated as ratios between prior and posterior normalizing constants  and therefore conf x y z  and conf u v  as well as conf x   y   z  u   z  are easy to calculate  In general  If evidence is propagated to any belief universe U from neighbours V    W originating from findings  v     v           w    w   respectively  then  vl  conf v    v     W    W       I I  conf v     v     w       w      conf v   v         conf  w    w   All terms are in HUGIN easy to calculate by use of Theorem    We call conf v    v    w     w   the global conflict and conf v      v     w       w   the local conflict  The calculation of conf has been implemented in HUGIN to follow the calls of CollectEvidence  The overhead to the propagation methods m terms of time and space is neglectable   P I  y z   I I t  I  I I I I  t  y  t l  t u  t  v  Figure    A junction tree with findings x  y  z  u v entered  Theorem   provides the joint probabili ties indicated at nodes V  U  W  and W   The conflict analysis can be further refined  In figure   is shown a junction tree with findings x y  z  u  v entered  If CollectEvidence is evoked in the node V  then the evidence flowing to V     Example  APB MUNIN  The conflict measure has been tested on small fictions examples and on a large subnetwork of MUNIN  namely the network for the muscle Ab ductor Pollicis Brevis  APB   The network is shown in figure    The rightmost variables in figure   are finding variables  This means that evidence is entered at the right hand side of the CPN and propagates to the left  However  as described in section    the propagation takes place in a junction tree of belief universes  In the test  CollectEvidence was called        I I I I I I I     The DAG in ductor Pollicis Brevis   Figure  MUNIN for  I  Medianus Ab  The attached numbers in  entered  see figure      I  in universe number     and the call propagates  I  dicate the belief universe to which the finding is  recursively down the junction tree  In figure   is shown the junction tree   I   Only belief universes  where evidence meet are shown   First we asked the model builder  Steen An  I  dreassen  to provide us with a complete set of nor mal findings  They were entered  and global and universal conflict values were calculated  The re sults are shown in figure a global conflict of           for  I  Surprisingly we got the entire set of find  ings and apparently the conflict can be traced to  I  belief universe no      Further  the evidence from    and    looks conflicting   Returning to Steen  Andreassen with our surprise  he recognized that  I  he had given us a wrong value for the finding qual mup amp  which was entered to belief uni verse     It should have been      J LV  rather than      pV   We entered the corrected finding and got a global conflict value        for the entire set of find  ings with local and subglobal values ranging be tween     and         Then typical findings for a patient suffering from moderate proximal myopathy were entered  As can be seen in figure    this resulted in large  Figure    The part of the MUNIN junction tree for APB where evidence meet  The numbers are labels of belief universes  Bold numbers indicate entrance of findings   I I I I         I I  negative conflict values confirming the coherence of the findings   I I I I I I I I I  Figure  I  I I I I I  Typical findings for a patient s uffer ing  Finally  we simulated hypothesizing   We en  tered a set of findings originating from a healthy patient  and we also entered the disease state  I I      from moderate proximal myopathy entered    moderate proximal myopathy   shown in figure Figure    The conflict measures from the first test example  The italiced values are local conflict val  ues and the bold figures are the global ones       The result is  The disease finding is entered to  belief universe     and it can be seen that the dis ease does not contradict a couple of normal find ings  but indeed the whole set      Conflict or rare case   It can happen that typical data from a very rare case might cause a high value of conf  In the case of Mr  Holmes  alarm system a flood  with proba       could be entered to the CPN explaining the data  see figure      For this system we get conf a  s         It is  bility  still indicating a possible conflict  The reason is that though P a  s  is possible  it is under the        rare  Mr   condition of flood   of the window   Holmes looks out  It rains cats and dogs  and he  has resolved the problem  the model gives a  P Flood    I  n ew            The problem above call s for more than a pos analysis    refined conflict  sibility for  We need a  method to point out whether a conflict  can  be ex  plained away through a rare cause    x      y  be findings with a positive conflict H be a hypothesis which could explain the findings  conf   x          y  H      Let  measure  and let  We have  con  r  x          y  H     log  P x  x       x P y  x P H  P  X      Y H       conf x       y   log  P H   P HIx     y    og  then  P Hjx       y  P H   H can    conf  x   explain away the  variables  in  conflict   t he flood example the  value is       This means that there is no need Figure      Findings for a healthy patient  and  the hypothesis  moderate proximal myopathy  en t er ed   for manually to formulate explaining hy pot hesis in terms of states of variables  More complex hy    pot hesis can also be monitored if they can be ex  pressed as findings      Conclusion        y      log  P    P  Y  X        y  x        x  has many promising properties  It is easy to cal  culate in HUGIN  it is independent of the order in  which fi nd ings are entered   it can be used for both global and loc al analysis of conflicts in data  and  it has a natural interpretation which supports the  usual mental way of inspecting data for flaws or for originating from sources outside the scope of the current investigation  Figure     Mr  Holmes  revised CPN   I I I  I I I I  The measure o f confli ct  con f   x   I  I          y   The left hand ratio can be monitored automat ic ally for all  I  I  This means that i f     I  However  still some practical and theoretical work is needed in order to understand the signifi cance of specific positive conflict values  Also  the  I I I I I I        I I I I I I I I I I I I I I I I I I I  detailed conflict analysis a it is nowconnected to Kim  J  H  and Pearl  J          A computational the structure of the junction tree rather than to model for causal and diagnostic reasoning in infer the CPN itself  This should be relaxed  ence systems  In Proceedings of the  th Interna tional Joint Conference on Artificial Intelligence       Acknowledgements            Lauritzen  S  L  and Spiegelhalter  D  J         P  We thank Steffen Lauritzen for many valuable dis Local computations with probabilities on graphi cussions on the subjects of this paper  and Steen cal structures and their applications to expert sys Andreassen for helping with the MUNIN experi tems  with discussion   J  Roy  Statis  Soc  B  ment               Olesen  K  G   Kjrerulff  U   Jensen  F   Jensen  F  V   Falck  B   Andreassen  S  and Andersen  S  K          A MUNIN network for the median nerve Andersen  S  K   Jensen  F  V  and Olesen  K  G    a case study on loops  Applied Artificial Intel         The HUGIN core  preliminary consider ligence             Special issue  Towards Causal ations on systems for fast manipulations of prob AI Models in Practice  abilities  In Proceedings of Workshop on Induc     
  When expert systems bas ed on causal pr obabilistic networks  CPNs  re ach a cer tai n size and complex ity  the  combinatori al explos ion monster  tends to be present  We propose an approximation scheme that identifies rarely occurring cases and excludes these from being processed as ordinary cases in a CPN based expert system  Depending on the topology and the probability distributions of the CPN  the numbers  representing probabilities of state combinations  in the underlying numerical rep resentation can become very small  Annihilating these numbers and utilizing the resulting sparseness through data structuring techniques often results in several orders of mag nitude of improvement in the consumption of comp uter resources  Bounds on the errors introduced into a CPN based expert system through approximations are established  Finally  re ports on empirical studies of appl yi ng the approxi mation scheme to a real world CPN are given  Keywords  Approximative reasoning  belief net work  causal probabilistic network  expert system  knowledge based system  influence diagram  junc tion tree  probability propagation  reasoning under uncertainty     Introduction  Expert systems  using causal probabilistic networks  CPNs   for knowledge representation  are reaching the state where it is feasible to handle domains mod eled by large scale networks  e g   MUNIN  Andreas sen et al         O lesen et al           When building such large networks  it is  for reasons of practicality  often necessary to introduce approximations besides those inherent in the process of modeling a domain  Two main approaches have been iwestigated  fo cusing on the development of an approximative al gorithm for propagation of information  e g    Hen rion          and focusing on approximations in the   Synonyms   belief  networks  causal networks  and  probabilistic influence diagrams   underlying network representation and then using exact inference algorithm  The objective of this paper is to p res ent  a n ap proximation scheme that takes t he latter approach  T he scheme is tailored to the Bayesian belief uni verse approach  Jensen et a      t    as used in HUGIN   Andersen et al          The met hod operates by ap proximations in the quantitative part  of t he underly ing representation  whereas the qualit at ive structure remains unchanged  Within thi framewor k   we can assess the accuracy of the appr o xim ate d probabili ties  which is not possible with heuristic methods  Application of the method ofte n results in a  sub stantial decrease in the usage of computer resources  the amount of decrease depends on domain charac teristics  such as network topology and prob ability distributions  It is known that  in general  probabilistic infer ence in CPNs is NP hard  Cooper         and ex act calculations will eventually become intractable  This fact emphasizes the importance of approxima tive methods  A domain model in the causal probabilistic net work approach consists of a graph with nodes repre senting the domain variables and the  directed  ar cs representing the causal relatious between the do main variables  Conditional probabilities are used to describe the dependency of domain variables given their immediate predecessors  parents   Different inference methods have been developed to propa gate information in such a network  If the topology is simple  singly connected   Pearl         propaga tion can be done directly in tht  CPN  otherwise  a secondary structure for topologies  including nondi rected loops  Lauritzen and Spiegelhalter        Jensen et al         Shafer and Shenoy         can be used  Alternatively  for the btter kind of topolo gies  the inference could also take place in a set of conditioned networks  Suermondt aud Cooper        or through manipulation of the uetwork with an arc reversing technique  Shachter         The method of Bayesian belief universes splits the inference task into two phases  a compilation phase and a run time phase  The proposed approximaan        tion scheme adds another phase to this task  The approximation and compression phase  The phases are thus Based on the CPN  The compil ation phase  domain model  a secondary structure is con structed a so called junction tree of belief uni verses    The approximation and compression phase   Small numbers  representing the probabilities of very rare cases  are annihilated  set to zero   thereby effectively eliminating these cases from the domain model  Through use of data struc turing techniques for sparse tables  the under lying numerical tables  the belief tables  of the junction tree are compressed   The run time phase  The actual inference takes place in the junction tree  using the modified belief tables  In Section    we review the basic belief universe concepts essential for the proposed approximation scheme  Section   describes how to perform the approximation and establishes some worst case er ror bounds on probabilities obtained from the ap proximated junction tree  Finally  Section   reports empirical results we obtained by applying the pro posed approximation scheme to a real world CPN namely  one of the networks of the MUNIN knowledge base     Belief Universes  This section reviews some of the basi c concepts of the belief universe approach  The domain represented by the CPN is divided into a set of subdomains called belief universes  A belief universe U consists of two parts  a set o f nodes  and a belief table  which contains an assess ment of the joint probabilities for the state space of U  i e   the Cartesian product of the state sets for the nodes of U   The construction of a system of belief universes  equivalent to the original CPN domain model  con sists of the following steps   Form the moral graph  For each node in the network  add links between all of its parents that are not already li nked  Drop the directions   Triangulate  the moral graph  Add links to the moral graph until a triangulated graph is ob tained   Form the system of belief universes  The node sets are the cliques  of the triangulated graph   We sha ll use U to denote both the belief universe itself and its set of nodes     A graph is triangulated if every cycle of length greater than three has a chord     A clique is a maximal set of nodes  a ll of which are pairwise linked   The initial belief tables are calculated as ap propriate products of the conditional probabil ity tables  Lauritzen and Spiegelhalter         Jensen et al            Organize the system as a junction tree  Links  between belief universes are introduced  such t bat a tree with the following property results  For each pair  U  V  of belief universes  each belief universe on the unique path between U and V contains the nodes U n V  As shown in   Jensen         a junction tree can be con structed by a maximal spanning tree algorithm  All steps except the second are deterministic  There is only one moral graph  and the set of cliques of a triangulated graph is unique  There may be several junction trees  but the differences among them are minor  the major cost of a junction tree is the repre sentation of t he belief tables for the belief universes   The second step is important  A good triangulation can save substantial space and time  Kjrerulff         Let U he a belief universe with belief table B  and let S C U  We can obtain the joint probabilities for S from B by summing up all beliefs in B for S  This operation is called marginalization  In partic ular  the belief in a single node can be obtained by marginalization of the belief table of any belief uni verse containing it  Let U be a belief universe  and let V  U  A   finding on    is a subset of the state space of V  The finding is entered into U  through annihilation of the elements in the belief table of U corresponding to state combinations not in V  A set of one or more findings is called a case  A junction tree is said to be consistent if marginal ization of two distinct belief universes U and U  with respect to some set of nodes V  contained in both U and U   yield  identical   i e   proportional  results  This property is  re established through the global propagation operation  This operation refers to a local propagation method for transmitting evidence between neighbors in a junction tree  Absorption is the local propagation method  If we have entered evidence into a belief universe V  then an adjacent belief universe U absorbs from V through the following steps     Calculate the belief table for U n V by marginal ization of the belief table of U     Calculate the belief table for the same intersec tion by marginalization of the belief table of V     Multiply the belief table of U by the ratio of the table achieved by Step   and the table achieved by Step     Typically  a finding is a statement that a node is known to be in a particular state   We shall also use the phrase  evidence is entered into U    I I I I I I I I I I I I I I I I I I I        I I I I I I I I I I I I I I I I I I I  When absorbing from several neighbors simultane ously  these steps must proceed in  parallel   imply ing use of the same version of the belief table of U in Step     Global propagation is described in terms of two operations  Col ectEvidence and Distribute Evidence  CollectEvidence is used when evidence from the entire system must be propagated to a sin gle belief universe U  U asks neighbors to Collect Evidence  when they are done  U absorbs from them  DistributeEvidence is used when evidence from a sin gle belief universe U must propagate to the entire system  U asks each neighbor to absorb from U and then DistributcEvidence to its other neighbors  A global propagation operation consists of Collect Evidence operation followed by a DistributeEvidence operation initiated from an arbitrary belief universe  CollectEvidence has an important property  As sume that we have a consistent and normalized junc tion tree  and that  we enter evidence into some of the belief universes of the junction tree  If we in voke CollectEvidence from some belief universe U  then the normalizing constant for the belief table of U  after CollectEvidence has terminated  is equal to the  prior  probability of the evidence     The Approximation Scheme  As described in the previous section  the numbers in the belief tables of the belief universes repre sent probabilities in joint probability distributions  One might expect that excluding the smallest num bers  representing rare state combinations  will lead to substantial improvements in the requirements of computer resources  In this section  we shall inves tigate some properties of such a scheme  Assuming we have a consistent junction tree  an approximation is performed in the following way     For each belief universe in the junction tree  we select some elements of its belief table and an nihilate those  the rest are left unchanged     The junction tree is made consistent again by a global propagation      Optional  The belief tables of the belief uni verses are compressed in order to take advan tage of the introduced zeros   This step will not be described here  see  Jensen and Ander sen        for details   How Do We Select the Numbers to Be Annihilated   As previously mentioned  we are interested in the small numbers  A simple way to do tl e selection is to use a threshold value to separate the numbers to be annihilated from the numbers to be kept  However  we cannot choose a global threshold value  as the size of tables and their distribution of numbers may vary substantially  So instead we shall use a local threshold value for each table   We observe that  annihilating an element of a be lief table  corresponds to entering a finding that says that the state combinations  corresponding to this element  are  impossible   or are considered unin teresting   Moreover  the sum of the annihilated el ements in a given belief table is t he probability of all the state combinations  the finding  corresponding to those elements  This probability is a measure of the  local  error  we commit   We can control this error by choosing a suitable threshold value  Suppose we want to retain   s of the probability mass of each belief table  Then  a simple method is to compute a threshold value   by repeatedly halv ing    using c  as the initial value for li  until the sum of the elements less than li is no greater than c    these elements will be annihilated  we believe that either all or no elements with the same value in a given table should be eliminated    A more costly method is to sort the elements of the table and to repeat  annihilating the smallest  number s  as long as the sum of the annihilated numbers does not ex ceed c   The global errore  the total amount of probability mass removed  is computed as t      J l  where J L is the normaliza tion constant  found during the global propagation step of the approximation algorithm  Given an arbitrary case  we can determine if it is one of the cases that have been completely excluded from consideration by detecting a zero normalization constant  The probability of such a case occurring  assuming the assessed conditional probabilities are correct  is e  For each remaining case  some of the state com binations supporting the case may have been elimi nated  The accumulated probability for those state combinations determines the error on the posterior probabilities as shown in the following     How Good Is the Approximation   Assume that we have approximated the belief universes and have propagated the approximations throughout the junction tree  We now have a con sistent junction tree  Let A denote the approximation performed  and let F denote a set of findings to be entered into the  consistent  approximated junction tree  Enter ing such a set of findings is a common operation when using the junction tree  or rather the under lying CPN  as an expert system  After F has been entered  and the junction tree has been made con sistent by propagation  we want to query the sys tem for probabilities of the form P HIF   where H is some hypothesis    However  the probabil This method is used in Hugin  Andersen et al             ln a real application  the CPN might model the re lationships between some diseases and the associated  symptoms  F then would be the set of symptoms found  H typically would be of the form  the patient has dis ease X   and  P HIF   would denote the probability that   I       ity P H F  is not available  instead  we get the probability P H F  A   that is  the probability for H given the findings F and the appr oximation A   We therefore want to find an upper bound on  jP H F  P H F  A j    P H F   P H F  A j  P H F  A P A F    P H F  A P A F  P HJF  A j  P H F  A  P A F       P H F A P A F   P A F  P H F  A    P HJF  A  I  P A F           The quantity  P A F  can be rewritten as  P F n A  P Fn A   P F n A  P F n A    P F n A   P F A P A          e        e   p  l   e     where e   P A  and JJ   P F A   These quanti ties are known  e is the appr ox imation error found at approximation time  and JJ is the normalization constant found during propagation of F  Unfortu nately  JJ is almost always small   e   so this upper bound is not a good indicator of the approximation error  In practice  however  F is almost  always of the form  I n       n fn  where fi     i  n   states that  node Xi is in state Yi    Thus  P F n A  S min  P fl n A         P fn n A   We can compute these quantities for all combina tions of nodes and states at approximation time  the space required to store these quantities is small   Although this gives us a better upper bound for the approximation error  it is  however  strictly a worst case bound  and we may have to rely on em pirical studies to determine the actual errors  In the next section  we shall investigate this issue for a real application     electromyographic findings  this model is cap abl e of diagnosing three local nerve lesions and one diffuse disorder in the median nerve in the arm  The CPN contains    nodes  the disease nodes each have be tween three and five states  and the finding nodes have from    to    states  The specification of the conditional prob ab ili t y ta bles requires      numbers  of which      pe rc en t  are assessed as zeros  however  most of these numbers have been generated by local models from a much smaller set of parameters  which has been assessed by domain experts   Andreassen et al          An explanation of the domain concepts  as well as a description of the medical performance  can be found in   Andreassen et al         Olesen et a            An Application  We shall use a network from the MUNIN knowledge base to study the effect of the proposed approxima tion scheme on a real world CPN  The domain ofMUNIN is electromyography  a tech nique for diagnosing peripheral muscle and nerve disorders  We have chosen a network describing dis orders in the median nerve    On the basis of four the patient has disease X given that he  she exhibits the symptoms F      It is our impression that this network is a  typical  network  in the sense that the benefits of approximation are neither negligible nor excessively large  Junction Trees  Based on different triangulations of the median nerve CPN  we have created four junction trees  yielding different starting points for approximation  We have used a maximum cardinalit v seatch  Tar jan and Yannakakis        and two huristic search strategies that minimize the clique cardinality  the min size heuristic  and the size of the state space of the nodes in the cliques  the min weight heuristic   respectively  see   Kjrerulff        for details  Triangulation Method Clique Size                     MaxCard    MaxCard    MinSize  lVIin   Weight  Number of Cliques  I I I I I I I I I I                                              I                         Zeros  Percent   I              Max Statespace                         Total Statespace        Table    Statistics of junction trees for the median nerve knowledge base generated from different tri angulations  Table   summarizes key parameters of junction trees  based on different triangulations  We have ob tained two maximal cardinality searches using differ   I  I I I I I        I I I I I I I I I I I I I I I I I I I  ent starting nodes  However  for obvious reasons   we consider only the second one  referred to as  max card   in the following subsections  The data in Ta ble   apply to the initial consistent  i e   after ini tialization  junction trees before any approximation or compression has been done       Effect on Resources  We shall focus on two aspects of resources      the  propagation time needed to make the junction tree consistent after a set of findings has been entered  and     the storage space needed to represent the knowledge base in a suitable compact form  see   Jen sen and Andersen        for details   The global error e  defined in Section    is used to characterize the approximation  we shall use the term total removed probability mass to refer to this value  U  Q                    Q       co a   f                  l                     J rr Q  a                             rorrl          Propagation Time  seconds   Figure    The relation between required storage space and propagation time for the median nerve knowledge base for various approximations  The line corresponds to a linear relationship between propa gation time and storage space   Min Weight Min Size Max Card Compression              Propagation Time  seconds   Figure    The effect of compression on required stor age space and propagation time for the median nerve knowledge base  The time and space measurements reported are for an implementation of HUGIN  Andersen et al         in C for a Sun   workstation  however  we are only interested in relative improvements  so the space and  in particular  time units should be regarded as ar bitrary  Figure   illustrates the effect of the initial com pression on required storage space and propagation time for three different junction trees  As expected  the gain varies according to the different ratio of ze ros in the junction trees  see Table     Figure   shows the relation between propagation time and storage space needed for the three different triangulation methods at different approximations  The total removed probability mass  e  varied be tween       and   percent  At each data point  the corresponding approximated and compressed run time system was created  and the time and space   U        Q          Unapproximated Values        Q   c    f  Q        g   a     Q     J       g  a    a    Min Weight      Min Size   o    Max Card              o                          Total Removed Probability Mass                 Figure    The space requirement as a function of the probability mass removed for different junction trees  The arrows indicate the storage requirements for unapproximated but compressed junction trees   I       cha racteristics were measured   Ve observe a linear relationship between propagation time and storage space needed  thus  we cha racterize resource require ments in term of storage space only  The resource requirements for approximatedjunc tion trees as a function of the total removed prob ability mass is the subject of Figure    Each data point in this figure corresponds to a data point in Figure    except  for points corresponding to e     p ercen t   The values corresponding to no approxi  mation  for the compressed indicated   junction trees are also  We observe that  fore less than     percent  the approximation is equally efficient for the three junc tion trees  For each junction tr ee   e        percent yields about one order of magn itu de in reduction of the required space  However  for a sufficiently large value of e  the differences between the junction trees disapp ear  Table   shows the effect  of the method applied to the different junction trees at e       percent   Triangulation  MaxCard  MinSize  Method MinWeight  Space Initial   Mby t e s  Approx   Mbytes   Reduction                                                    Figure   di sp lay s the results of entering a typical case into various approximated junction trees  The p r obability of the case is     x       The observed error in the beliefs caused by the approximation is shown as a funct ion of the total removed probability mass  e   The figure shows ob served errors in the beliefs of states representing ex act beliefs between        and         The worst case error bound  Section    for each approxi mation and case also has been computed    e ob se rve that the difference between the worst case bound and t he  worst measured absolute error is about of ma gnit ude for e          percent   Approx    seconds  Reduction                                                Table    The effect of approximation and compres sion on junction trees generated from the median ne rve CPN       Effect  on  the Quality  Whenever we commit ourselves to making an ap proximation  we want to know the risk that we will make serious errors  Unfortunately  the basis on which we calculate the theoretical worst case error bounds might be too coarse  and it is highly unlikely that the worst case situation will appear in a real ap plication  If we had some method that could warn us when the situation was questionable  we might take the risk and make approximations beyond the mag nitude imposed by a given worst case error bound  We shall use our median nerve knowledge base  and shall make a diagnosis on the basis of a set of find ings  thus showing how our theoretical estimate on upper bounds on errors compares to practical values   orders  I I I I       Q  co    o    s                   w     Q         Q   I         I           I           I       a                                           Total Removed Probability Mass      Time Initial  seconds   three  I  Exact Beliefs   Exact Beliefs    a                      Ell                                                 o          Worst case Error Bound           Figure    The errors observed in the beliefs for var ious states of a local nerve lesion given a standard case  The probability for this case is     x      Figure   shows triples of the worst case bound  filled square    maximal observed error   diamond    and average observed error   open square  for    dif ferent randomly generated cases as a function of the case specific normalizing constant  J  lcase The ap proximation used corresponds to a decrease in re source requirements by a factor of four relative to an unapproximated but compressed junction tree  Figure   shows that the observed errors on com puted beliefs for the displayed cases are much smaller than that predicted by the worst case er ror bound derived in Section    This difference shows that it is very unlikely  by picking a ran domly generated case with a given J  lcase  to get the  I I I I I I I I I I        I I I I               Ci   l                                 w  c      Q   I        I I I I I I I I I I I               For the median nerve knowledge base and the fo cus on the hypothesis of a lesion at the wrist  a de mand of      as the upper limit of error in a state  would allow us set the alert threshold as low as J Lcase        for e     X              J             J          Ji   c   I  I        Q            c  I               J  Average     Maximal    Worst Case   B                         Q        co  o   DE              o lf                              o  Normalizing Constant  Figure    For e     x       triples of worst case er ror  maximal observed error  and average observed error in the beliefs of the states of the disorder nodes used for the case in Figure   are shown for    differ ent cases  worst case configuration  In the present CPN  the ratio between the worst case bound and the max imal observed error is three orders of magnitude for J Lcase           Decreasing the normalizing con stant  J Lcase  implies increasing the error in beliefs for the specific case  as well as for the worst case er ror  W hen J Lcase approaches zero  the error in beliefs approaches one  corresponding to excluding the case from the domain model  These empirical studies show  that if we have a specific hypothesis in mind  for example the diag nosis of a local nerve lesion at the wrist  and a set of test cases which provides us with a span of J Lcase  we can get empirical values for the actual expected error in a specific case  given J Lcase Given a specific approximation e  we would have the following situations  If we insert a set of findings  and the theoretical worst case error bound are below an accepted level  we can use the approximated junc tion tree  If we insert a set of findings which already has been taken out of the domain model by  zeroing out   the violation on the model will be recognized by a zero normalizing constant  and we have to use a less approximated junction tree  If we insert a set of findings yielding an unacceptably high worst case error  we have to rely on empirical studies  such as those above  to estimate the error based on J Lcase  and on basis of this  decide whether to fall back on a less approximated junction tree or accept the risk of committing an error  This approach allow us to obtain a graceful degradation of the quality of diag noses as the limit of the approximation is reached   Conclusion  We have presented a scheme for approximation in the numerical part of a CPN based expert  system  Our approach eliminates the  small  numbers rep resenting probabilities of rare combinations of find ings  thereby preventing these findings from being trea ted as ordinary findings in the expert system  The approximation has two effects      we may gain several orders of magnitude in improvement of re source usage  and     we may lose some accuracy in the computed beliefs  However  we can estimate case specific upper bounds for the errors made on the computed beliefs  although these bounds may be too pessimistic  as the studies reported in Section   show  If the case has been completely excluded by the approximation process  we will detect it by fiudiug a zero normalizing constant during propagation  if the case is one of the common cases  we know that the computed beliefs can be trusted to a large de gree  The problematic cases are the ones that have a nonzero probability outside the  trusted range   of probabilities  remember that the probability of a case is equal to the normalization constant found during propagation   We suggest that  when a prob lematic case occur  we should reenter the case into a less approximated  maybe even a nonapproximated  junction tree  however  this solution should rarely be necessary  It would be nice to find an upper bound on the error of beliefs that is better  and still easily com putable  than is the one presented in Section    Cal culation of this bound involves the errors made on individual findings  We might be able to do better if we considered two or more findings simultaneously  however  a straightforward approach would require O sn  space  where s is the total number of states in the nodes  and n is the number of findings con sidered  There might be a clever technique to avoid con sidering all these combinations of findings and at the same time to provide a better error bound  We shall leave this topic for future research     Acknowledgements  We thank Steffen L  Lauritzen  Kristian G  Olesen  and Finn V  Jensen for valuable comments  sugges tions  and inspiring discussions on the subject of this paper  We are grateful for the inspiring environment pro vided by the Medical Computer Science Group at        Stanford University to one of us  SKA  from Au gust        through June        Computer support was partly provided by the SUMEX AIM resource  under NIH grant LM       We also thank Lyn Dupre  Stanford University  for the many improvements of the prose she cont ri bu ted to this paper  
 We present an approach to the solution of de cision problems formulated as influence dia grams   This approach involves a special tri  angulation of the underlying graph  the con struction of a junction tree with special prop  tials normalized  Ndilikilikesha  Shachter and Ndiliki likesha        Ndilikilikesha        modified the node removal  arc reversal algorithm to avoid these extra di visions  the result is an algorithm that is equivalent to Shenoys algorithm with respect to computational effi ciency   erties  and a message passing algorithm op  Our work builds primarily on the work of Shenoy  erating on the junction tree for computa         and Shachter and Peat         in addition  tion of expected utilities and optimal decision  to our previous work on propagation algorithms for  policies   the expert system shell Hugin  Andersen et al         Jensen et al               INTRODUCTION  Influence diagrams were introduced by Howard and Matheson        as a formalism to model decision     INFLUENCE DIAGRAMS  An  influence diagram is a belief network augmented  problems with uncertainty for a single decision maker   with decision variables and a utility function   The original way to evaluate such problems involved  The structure of a decision problem is determined by  unfolding the influence diagram into a decision tree and using the  average out and fold back  algorithm on that tree  Shachter        describes a way to eval  uate an influence diagram without tranforming it into a decision tree  The method operates directly on the influence diagram by means of the node removal and arc reversal operations  These operations successively transform the diagram  ending with a diagram with only one utility node that holds the utility of the op timal decision policy  the policies for the individual decisions are computed during the operation of the algorithm  when decision nodes are removed   Shenoy        describes another approach to the eval uation of influence diagrams  the influence diagram is converted to a valuation network  and the nodes are removed from this network by fusing the valuations bearing on the node  variable  to be removed  Shenoys algorithm is slightly more efficient than Shachters al gorithm in that it maintains a system of valuations   an acyclic directed graph G  The vertices of G repre sent either random variables  also known as chance or probabilistic variables  or decision variables  and the edges represent probabilistic dependencies between variables  Decision variables represent actions that are under the full control of the decision maker  hence  we do not allow decision variables to have parents in the graph  Let  UR  be the set of random variables  and let the  set of decision variables be  Uo                      Dn    with  the decisions to be made in the order of their index  Let the universe of all variables be denoted by U  UR U Uo   sets lo        We partition    In   for      UR     into a collection of disjoint  Ik is the set of variables Dk and Dk     variables  and In is the set  k    n   that will be observed  between decision  Io is the initial evidence  of variables that will never be observed  or will be observed after the last decision   This induces a partial order     on  U   whereas Shachters algorithm maintains a system of conditional probability functions  in addition to the utility functions   and some extra work  some division op erations  is required to keep the probability paten     By   observed    will be revealed   we  mean that the true state of the variable        Jensen  Jensen  and Dittmer  We associate with each random variable A a condi tional probability function A P AI PA   where  J A denotes the set of parents of A in G   The state space Xv for V  U i s defined a s the Carte sian product of the sets of possible outcomes decision alternatives for the individual variables in V  A po tential v for a set V of variables is a function from Xv to the set of real numbers  The potential  Pv can be extended to a potential  w  V  W  by simply ignoring the extra variables  w w   v v  ifv is the projection ofw on V  Given two potentials   P and tf   The product    tV and the quotient  tf  are defined in the natural way  except that     is defined to be    x   for x       is undefined    The  a priori  joint probability function  Pu is defined as A  Pu    IT  AEUR  For each instance of Uo  i e   each element of  Pu defines a joint probability function on UR   Xu      A solution to the decision problem consists of a series of decisions that maximizes some objective function  Such a function is called a utility function  Without loss of generality  we may assume that the utility func tion tfJ is a potential that may be written as a sum of  possibly  simpler potentials   The independence restriction imposed on the decision problem can be verified by checking that  in the influ ence diagram  there is no directed path from a deci sion Ok to a decision Di  i   k      DECISION MAKING  Assume we have to choose an alternative for deci sion On  i e   the last decision   We have already observed the random variables             In    and we have chosen alternatives for decisions D           n    The maximum expected utility principle  says that we should choose the alternative that maximizes the expected utility  The maximum expected utility for decision Dn is given by  Pn  max L P Inllo      In             Dn    tf   On  I   Obviously  Pn is a function of previous observations and decisions  We calculate the maximum expected utility for decision Dk  k   n  in a similar way   Pk  Df ax L P Ikllo        Ik    o          Dk   Pk   k  I   We note that Pk is well defined because of       By expansion of         we get  Pk  max L P Ikllo       Ik    D          Dk  Dk  m  Ik   max Dk l   max We need to impose a restriction on the decision prob lem  namely that a decision cannot have an impact on a variable already observed  This translates into the property  P Ikllo        Ik    D         On   P Ikllo       Ik             kl       In words  we can calculate the joint distribution for I k without knowledge of the states of Dk           Dn  i e   the future decisions        GRAPHICAL REPRESENTATION  In Figure    an example of an influence diagram is shown  Random variables are depicted as circles  and decision variables are depicted as squares  Moreover  each term of the utility function is depicted as a dia mond  and the domain of the term is indicated by its parent set  The partial order   is indicated by making I k   the parent set of D k  and we shall use the con vention that the temporal order of the decisions are read from left to right         o   L h   P Ik   Io       Ik  D         k      Pk    L max L P Ik  Ik   Io        Ik    l  Dk l  Ik l  D          k     Pk    The last step follows from      and the chain rule of probability theory  P AjB C P BIC   P A BIC   By further expansion  we get  Pk  max L max L P Ik      Inllo        Ik    Dk h Dn DnJ   t J  D   In         From this formula  we see that in order to calculate the maximum expected utility for a decision  we have to perform a series of marginalizations  alternately sum  and max marginalizations   thereby eliminating the variables  When we eliminate a variable A from a function   expressible as a product of simpler functions  we par tition the factors into two groups  the factors that involve A  and the factors that do not  call  the prod uct of  these factors   t  and A  respectively  The marginal LA is then equal to  PA   LA t   LA  Pt  There are good arguments for adhering to this principle  See  e g     Pearl           From Influence Diagrams to Junction Trees       FIGURE    An influence diagram for a decision problem with four decisions  The set of variables is partitioned into the  sets   I       b   I         e  f   Iz         I     g   and I      a  c  d  h  i  j  k  e    four local utilities  three of which are associated with single variables  D     the pair   j  k    then becomes a new factor that replaces the prod uct  cj J t  in the expression for     This also holds true for  max marginalizations  provided  cPA   does not assume  negative values   The utility function is a sum of  D   and    and one associated with  marginalizations  but  in general  we cannot inter change the order of a max  and a sum marginalization  this fact imposes some restrictions on the elimination order   The product cjJ may be represented by an undirected graph  where each maximal complete set  clique  of nodes  the nodes being variables  corresponds to a fac     INFLUENCE DIAGRAMS  tor  or a group of factors  of cjJ with that set as its do main  Marginalizing a variable  A out of   then corre  COMPILATION OF  We first form the moral graph of G  This means adding  sponds to the following operation on the graph  the set   undirected  edges between vertices with a common  A is  child  We also complete the vertex sets corresponding  of neighbors of A in the graph is completed  and  removed  It is a well known result that all variables  to the domains of the utility potentials  Finally  we  can be eliminated in this manner without adding edges  drop directions on all edges   if and only if the graph is triangulated  Rose          Next  we triangulate the moral graph in such a way  Obviously  it is desirable to eliminate all variables  that it facilitates the computation of the maximum  without adding extra edges to the graph since this  expected utility  This is equivalent to the selection of  means that we do not create new factors with a larger  a  domain than the original factors  the complexity of  verse of the elimination order must be some extension  representing and manipulating a factor is exponen  of    to a total order   tial in the number of variables comprising its domain   However  in most cases  this is not possible  we have to add some edges  and the elimination order chosen  special elimination order for the moral graph  the re  Finally  we organize the cliques of the triangulated graph in a strong junction tree   A tree of cliques  optimal elimination order for all reasonable criteria of optimality     C     C l of C  is contained in every clique on the path connecting C  and C   For two adjacent cliques  C  and C   the intersection C  n Cz is called a sepa  W hen we perform inference in a belief network  i e    least one distinguished clique R  called a strong root   will determine how many and hence also the size of the cliques   Unfortunately  it is  N Jl hard to find an  is called a junction tree if for each pair  cliques   C   n  rator  A junction tree is said to be strong if it has at   C   Cz  of adjacent cliques in C  closer to R than C   there exists an ordering of C  that respects    and with the ver tices of the separator C  n Cz preceding the vertices of C  C    This property ensures that the computation  calculation of the marginal probability of some vari  such that for each pair  able given evidence on other variables   the computa  the tree  with  tion only involves sum marginalizations  In this case  we can eliminate the variables in any order  since the order of two marginalizations of the same kind can be interchanged   However  the calculation of the max  imum expected utility involves both max  and sum   of the maximum expected utility can be done by local message passing in the junction tree  see Section            Jensen  Jensen  and Dittmer  that no two cliques have the same index  Moreover  unless index  C       the set    vE C I  X v   index  C    will be a proper subset of some other clique with a  lower index than  C   Let the collection of cliques of the triangulated graph be  C         Cm  ordered in  increasing order according  to their index  As a consequence of the above construc tion  this ordering will have the running intersection property  Beeri et  al           meaning that  k   for all  FIGURE    The moral graph for the decision problem in Figure    Edges added by the moralization process are indicated by dashed lines   k        Sl      C    n  U  Ci  C   for some  i    j   k   It is now easy to construct a strong junction tree  we start with each clique  C   the root   then we successively attach Ck to some clique C  that contains Sl    Consider the decision problem in Figure    Figure     shows the moral graph for this problem  edges have  been added between vertices with a common child  in cluding utility vertices   utility vertices have been re moved  and directions on all edges have been dropped  Note that the time precedence edges leading into de cision vertices are not part of the graph and are thus not shown  Figure  shows the strong triangulation of the graph       generated by the elimination sequence e  j  k  i  fill ins  D     and g      lt  fill in  f      a  c  fill in  b e   d  fill ins     e       f  b f  and e f       g  fill in  e     Oz           f  e      and b  This graph has the fol lowing cliques  C       i e   C s    lt k j   C         lt k   C    b c a   C    b e d c   Cs  Oz  g      i   C   f      lt   Cs  e      g   and C     b O e f d   Using the above algorithm  in Figure            FIGURE            The triangulated graph of the moral graph in Figure    Fill in edges added during triangulation are indicated by dashed lines                  we get the strong junction tree shown in Figure     for  this collection of cliques   There exists another strong      Let  CONSTRUCTION OF STRONG JUNCTION TREES   X be  a numbering of            lUI    U  such that for all  plies  X u      X v     X  U H U  u    v im   i e   a bijection  u v  E  We assume that  X is the elimi  nation order used to produce the triangulated graph  of G  vertices with higher numbers are eliminated be fore vertices with lower numbers  Let C vE C  the edge  Cs       C   by the edge  Cs       C     This tree is  computationally slightly more efficient  but  unfor tunately  it cannot be constructed by the algorithm given in this paper   In general  previous observations and decisions will be relevant when making a decision  However  sometimes only a subset of these observations and decisions are  be a clique of the triangulated graph  and let be the highest numbered vertex such that the   wE C I  X w     X v   have a common neigh bor u  j  C with  X u     X v   If such a vertex v exists  we define the index for Cas index  C   X v   other wise  we define index  C     Intuitively  the index for a clique C identifies the step in the elimination process that causes C to  disappear  from the graph  It is easy to see that the index for a clique C is well defined  and vertices        junction tree for this collection  obtained by replacing  needed to make an optimal decision  For example  for the decision problem in Figure    the variable  e  sum  marizes all relevant information available when deci sion      has to be made  although  before decision        f  is observed just  it has no relevance for that deci  sion  it does  however  have relevance for decision      This fact is detected by the compilation algorithm  the only link from    to past observations and decisions goes to  e         From Influence Diagrams to Junction Trees  FIGURE    A strong junction tree for the cliques of the graph in Figure       USING THE STRONG JUNCTION TREE  Now  letT be a strong junction tree  and let C  and C   FOR COMPUTATIONS  be adjacent cliques with separator S inT  We say that  We perform computations in the junction tree as a spe cial collect  operation from the leaves of the junction  C  absorbs from Cz if and tVc as follows   Q Jc   and tVc  change to     cPc   tree to some strong root of the tree  To each clique  C in the junction tree  we associate a  probability potential QJc and a utility potential tVc defined on  Xc   Let e be the set of cliques  We define  where  the joint potentials q  and tV for the junction tree as  tVs     M  Cz S  cPCz  tV c z    Note that this definition of absorption is  asy mmetric  We initialize the junction tree as follows  each variable  A E U R is assigned to a clique that contains A U PA  T he probability potential for  a  clique is the product of  the conditional probability functions for the variables assigned to it  For cliques with no variables assigned to them  the probability potentials are unit functions  In this way  the joint probability potential for the junc tion tree becomes equal to the joint probability func tion for the influence diagram  Similarly  each utility  in the sense that information only flows in the direc tion permitted by the partial order      It is possible to generalize this definition of absorption to a sym metric definition similar to the one given in  Jensen et  al          for the case of pure probabilistic influence  diagrams  Clearly  the complexity of an absorption operation is  O I Xc l   IXsl    Xc      Note in particular that the contribution from the division operation plays a much smaller role than in  Shenoy         since division op  function tVk is assigned to some clique that can ac commodate it  The utility potential for a clique is the  erations are performed on separators only   sum of the utility functions assigned to it  for cliques  We will need the following lemma  which we shall state  with no utility functions assigned to them  the utility  without proof   potential is a null function  We need a generalized marginalization operation that acts differently on random and decision variables  We denote the operation by   M      For random variable  A  and decision variable D  we define  M q  D  For a set  V of variables   we define     maxQ l  D  Mv q   as a series of  single variable marginalizations  in the inverse order as determined by the relation      Note that although     is only a partial order   Mv q   is well defined   Lemma   Let D be a decision variable  and let  V  a set of variables that includes all descendants of in G   of  D  Then  Mv   D  Q lu   be     considered as a function  alone  is a non negative constant   Let T be a strong junction tree with at least two cliques  let  cPT  be the joint probability potential and  tVT the joint utility potential on T  Choose a strong root R for T and some leaf l   I R   let T   l denote the strong junction tree obtained by absorbing l into  its neighbor N and removing l  denote the separator between N and l by S         Jensen  Jensen  and Dittmer  Theorem   After absorption of l into T  we have  M  Pr  tl r    PT L            Xk  is a decision variable  By induction  we get  tVT L  L S Proof  Let   iJL  IJ       Because of Lemma     P   k  l  considered as a   Pc   function of xk alone  is a non negative constant   CEe  L   and we get Since  PL does not assume negative values  we get   mxax P k  l         L S  L S     maxx   tj lk  l  maxx   j lk    J        k        We have to show that  M  PL L S      ti L   lj L       Ps       S     iJL        i      tj  k   tJ k   L           L       I  By successively absorbing leaves into a strong junction tree  we obtain probability and utility potentials on the intermediate strong junction trees that are equal to the marginals of the original potentials with respect  where  to the universes of these intermediate trees   This is  ensured by the construction of the junction tree in which variables to be marginalized out early are lo We shall prove this by induction  Let X            Xt be  some ordering of l   S that respects     Now  consider  the equation   cated farther away from the root than variables to be marginalized out later   The optimal p olicy for a decision variable can be deter  mined from the potentials on the clique that is closest  to the strong root and contains the decision variable  that clique may be the root itself   since all variables that the decision variable may depend on will also be members of that clique   where  For our example decision problem  Figure     we can determine the optimal policy for    from  the poten tials on  clique C    the root   and the optimal policies for the remaining decisions can be determined from   For k          is equivalent to the desired result   For k   e      is clearly true  for    s k  s e  we have two  cases       Xk  cliques Cs  decision      C   decision      and Cs   decision        If only the maximum expected utility is desired  it is a random variable  By induction  we get  should be noted that only storage for the  active  part of the junction tree during the collect operation needs to be reserved  this means that storage for at most two adjacent cliques and each clique that corresponds to a branch point on the currently active path from  the root to a leaf  must be reserved  Since elimination  of a group of variables can be implemented more effi  ciently than the corresponding series of single variable eliminations  it is still useful to organize the computa tions according to the structure of the strong junction tree as compared to  Shenoy   The correctness of the last step follows from the fact that   P kl  x        implies tj lkl  x         so that  our division by zero convention applies               CONCLUSION  We have described an algorithm to transform a deci sion problem formulated as an influence diagram into a   From Influence Diagrams to Junction Trees  secondary structure  a strong junction tree  that is par ticularly well suited for efficient computation of max  networks by local computations                   Computational  Statistics Quarterly   imum expected utilities and optimal decision policies  The algorithm is a refinement of the work by Shenoy        and Shachter and Peot         in particular  the construction of the strong junction tree and its use for computations has been elaborated upon   Kjcerulff  U          Triangulation of graphs algo rithms giving small total state space  Research Report R        Department of Mathematics and Computer Science  Aalborg University  Denmark   T he present work forms the basis for an efficient com puter implementation of Bayesian decision analysis in the expert system shell Hugin  Andersen et al           Lauritzen  S  L  and Spiegelhalter  D  J          Lo cal computations with probabilities on graphical structures and their application to expert systems   We have not given an algorithm to construct the elim ination sequence that generates the strong triangula tion  However  the triangulation problem is simpler than for ordinary probability propagation  since the set of admissible elimination sequences is smaller  at this stage  it appears that simple adaptations of the heuristic algorithms described by Kjcerulff        work very well  Moreover  even given a triangulation  there might exist several strong junction trees for the collec tion of diques  Besides the use of the strong junction tree for compu tation of expected utilities and optimal decision poli cies  it should be possible to exploit the junction tree for computation of probabilities for random variables that only depend on decisions that have already been made  Ideally  this should be done through a  dis tribute  operation from the root towards the leaves of the junction tree  Work regarding these problems is in progress  Acknowledgements  This work has been partially funded by the Danish research councils through the PIFT programme  
