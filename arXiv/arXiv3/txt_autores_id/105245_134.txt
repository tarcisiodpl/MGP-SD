 This paper presents an approach to the design of autonomous  real time systems operating  in uncertain environments  We address issues of problem solving and reflective control of rea  soning under uncertainty in terms of two fundamental elements     a set of decision theoretic models for selecting among alternative problem solving methods and    a general computational architecture for resource bounded problem solving  The decision theoretic models provide a set of principles for prioritizing the assignment of computational resources among multiple problem solving activities under uncertainty and with respect to various time constraints  Alternative problem solving methods are chosen based on their relative costs and benefits  where benefits are characterized in terms of the value of information provided by the output of a reasoning activity  The output may be an estimate of some uncertain quantity or a recommendation for action  The computational architecture  called Schemer     supports the interleaving of  and communication among  various problem solving subsystems that provide alternative approaches to information gathering  belief refinement  solution construction  and solution execution  We  discuss the role of decision theoretic control in an architecture such as Schemer II for scheduling problem solving elements and for critical event driven interruption of activities      Introduction  An autonomous system  operating in a complex and constantly changing environment  must for mulate and carry out plans to achieve desired behaviors or objectives  In such an environment the synthesis and use of plans will typically be severely constrained by limitations on time  infor mation  and other critical resources  In response to these dynamically changing constraints  the system must be able to judiciously manage its reasoning and other activities to make the best use of available resources  We refer to problem solving under these conditions as resource bounded problem solving  controlling and adapting actions to meet contextually determined constraints  In particular  we address the problem of selecting among a set of alternative reasoning activities  the control problem  in service of some object level problem  the primary problem   The control problem exhibits considerable uncertainty since the performance of alternative reasoning methods on the primary problem is highly uncertain  Complex tradeoff s concerning the costs of using alternative methods and directly acting in the world need to be considered   The control problem is essentially an issue of belief management  the presence of significant amounts of uncertainty in a realistic task environment forces a system to constantly face a fundamental choice between using its      I I I I I I I I I I I I I I I I I   I I I I I I I I I I I I I I I I I I I  current information to carry out its primary objectives and making efforts via reasoning activities to improve its state of information   Researchers in artificial intelligence have long been interested in the topic of problem solving control  Some investigators have focused on developing general architectures with features that support explicit reasoning about control of problem solving actions               The primary em phasis has been on mechanisms and representations by which control knowledge might be used  With few exceptions       the knowledge itself has been developed heuristically with little emphasis on developing general principles of control  In this work  we will model the control problem in terms of decision making under uncertainty as formalized in decision theory  As indicated above  control involves resource allocation under uncertainty with complex preferences and the need to reason about the cost and quality of information  Representations and tools from decision theory are a promising path for analysis of these problems from a formal basis       This work has been motivated in large part by a desire to incorporate principled control pro cedures within autonomous real time systems  In particular  we are extending Schemer II  a com putational architecture that allows embedding various problem solving elements in an autonomous system designed for operation in a complex  dynamic  environments      Although Schemer II s de sign provides a very robust computational framework for applying appropriately chosen techniques for control reasoning  this architecture does not by itself offer any such techniques for making the appropriate choices  In the latter part of the paper we indicate how the analytic techniques and results derived here are being incorporated into the architecture   Decision Theoretic Control     Our approach to selecting among alternative methods for reasoning about a particular problem is a computational version of an idea proposed by Matheson      and more recently Nickerson      and Lindley       The outputs of a problem solving method are viewed as information in a decision theoretic sense  that is  the outputs of a model are used to update the probability distribution about an event or potential action  We are concerned with two classes of action  primary actions and modeling actions  Primary actions involve the system s interface to the external world  e g  moving an item  opening a valve  or initiating communication  Modeling actions operate on the system s knowledge to produce new conclusions or recommendations  We use the term modeling to capture the set of actions regarding structuring  solving  and interpreting a model of a domain  Alternative methods may be based on different assumptions and require different amounts of data and time to run  The solutions provides may differ in their quality   J  perhaps expressed in terms of different attributes of a solution       The formulation of the control problem in these terms is illustrated in Figure    Modeling actions  m  are selected from a space of modeling alternatives M  Sequences of primary actions  d  are selected from a space of decision alternatives     The decisions are represented as square nodes in the figure  The overall utility of the control problem is a function of the primary decision  d   some uncertain state of the world  x   and the cost of using a particular method   c    The cost can be thought of as reflecting the  possibly uncertain  time  data  and processor requirements to use a particular problem solving methodology  m  The output of a model is s  It is available at the time the primary decision is made  indicated by the arrow from s to din Figure     The output of a model is uncertain  It also is probabilistically dependent on the state of the world  the information s from using method m provides information about the uncertain state of the world  In this sense  a problem solving methodology acts as a sensor for some unknown quantity  We express this measure of quality of output as the probability distribution  Pr sjx  m    where  is the background state of information  or context  where the distribution applies     Cohen     has referred to this tradeoff as balancing internal and external action      I I I I F igure    Control Problem Influence Diagram The expected utility ofthe meta level control problem is Ex c Uid m e   where          U x  d  c  Pr xls m e  Pr slm e  Pr clm e   Pr slx m e  Pr xle  r x I    m e  p     fx Pr s x m e  Pr xle   by a standard application of Bayes  rule  The optimal primary decision  d   m s  is obtained by solving  maxExc Uid  m  s e  d    The distribution over the uncertainty has been updated with the model output  The optimal model m  is obtained by solving  max Euc Uid  m  s  m e  mEM  The above formulation can be extended and operationalized in several ways  as discussed below  Resource Usage and Resource Constraints   In the previous formulation  usage of computa tional resources is captured in the cost  c  of using a particular method  Resources that are limited or that can be expended variably to modify the quality of a computational result can be expressed by conditioning the output  s  on the amount of resource available  In a multi processor system  there is a tradeoff between the amount of time available for a task  and the number of processors assigned to a computation  For example  the quality of an output may depend on time to the next interrupt  ti  and the number of processors  n  involving in running method m   Pr s x m ti  n  e   In this case n is a control decision while ti is an uncertain quantity  The form of this distribution can be used to capture behavior of methods whose outputs improve monotonically as additional time or processing power is applied  such as Monte Carlo methods   as opposed to those which require some threshold to provide any useful output  Decision Recommendations  In the previous formulation  the most natural interpretation for the output of a model is that it provides an assessment or diagnosis of some uncertain state of the world  We can modify the formulation for models and methods that provide decision recom mendations  As an example  suppose we have an autonomous vehicle that needs to navigate to some objective  The system may embody several alternative means of determining a path to the destination  It could use its logical knowledge to construct a plan while not explicitly considering uncertainty or resource usage  It could develop probability and utility models at various levels of      I I I I I I I I I I I I I I I   I I I I I I I I I I I I I I I I I I I  Figure    Control Problem Influence Diagram for Decision Recommendations detail  to be solved using exact or approximate methods  It could dispense with a  planning  stage altogether and use local obstacle avoidance and reactive planning methods to attempt to arrive at the destination      Any of these methods will produce output of the same general form  a sequence of actions to be taken  possibly conditional on observations and possibly iterated as a policy  e g  as in a reactive algorithm   We illustrate this model with Figure    Here we are assuming the existence of some  true  optimal course of action d  dependent on the state of the world  d  is the recommendation that would be obtained by maximizing Up x  d   the primary decision problem utility function ignoring the costs of reasoning  It is assessed probabilistically  reflecting the system s a priori uncertainty of the optimal action  The output of a method  as previously  provides an estimate of the uncertain optimal decision  The diagram also indicates that the output of the method will be used directly as the primary decision  and the decision model can be solved using Bayes rule and maximization of expected utility in the customary way  The burden of assessing the probability distribution Pr  s j d   m    can be eased by expressing it in terms of deviations from the optimal value  For example  let Pr s Pm the d lm   probability method m will provide an optimal result is Pm  The dispersion about the optimum can be captured in a number of ways depending on the particular method m being considered   A method is unbiased for real valued d  and s when E sjd  m e  d            Cost of an Error  A key consideration in the choice among alternative problem solving methods is the extent to which a sub optimal primary decision will reduce utility in the primary decision problem  For each world state x and alternative d we can calculate   U U x  d     U x  d   These sensitivity measures are indicative of how forgiving a domain is with respect to selection of action  Estimates of this sensitivity can be used to parameterize control strategies across domains and problems  as we would like to perform this type of reasoning without precise specification of U x d  c      We have developed an illustrative example using the control model described above for a specific numerical robot path planning problem      The robot needs to select among a feasible path method  F   a basic probabilistic model  B   and a more complex  information probabilistic model  I  which considers the possibility of collecting additional information as part of the primary decision problem  Each method is characterized with respect to its probability of providing an optimal solution under uncertainty  The results of the analysis are presented graphically in Figure    Optimal regions depend on ti  the time to an interrupt  and   the cost ofan error  W hen ti and Ce are low then the non probabilistic modeling method  F  is optimal  As these parameters increase  more complete probabilistic reasoning becomes preferred  The type of information summarized in this graph can form the basis for simple control rules  depending on contextual information  Though easy to implement and deliver  they nonetheless are developed based on defensible and clear criteria   Lindley      has used assumptions of normality to obtain a na lytic solutions in a  similar problem        I I I I I  t     I  Figure    Optimal Reasoning Policies  The Architecture     Schemer    is a computational architecture for resource bounded problem solving    It has been designed to allow for the interleaving of solution construction  solution execution  information gathering  and knowledge management activities  At a coarse level of description  Schemer II is an object based blackboard system  Various problem solving modules reside in a shared knowledge space  The invocation of these modules  or handlers  occurs in various ways and is further mediated by the operations of a top level controller  which schedules various pending activities for execution  manages communication with the external world  and handles interruption and resumption of ongoing activities  Schemer II provides some unique and important features to support flexible  reactive control of problem solving  In particular  the architecture supports a wide variety of techniques for flexible  dynamic scheduling  the ability to employ special purpose problem solving modules that can modify the system s control state  and  perhaps most importantly  true pre emptive control providing the problem solving system the ability to react promptly and re focus its attention in response to the occurrence of critical events  However  until recently  both scheduling and pre emptive control were handled with strictly domain specific techniques  In this section we use the decision analytic framework described in Section   to analyze     choices amongst alternative problem solving activities and    generation and fielding of interrupt conditions for executing plans       Scheduling diverse problem solving elements  The Schemer II architecture supports encapsulation and interleaved control of multiple  indepen dent problem solving methods  Schemer II s handlers  with their object oriented modularity  meet this requirement by providing a discipline for encapsulating each problem solving element as a distinct type of object  Each handler can encapsulate a specialzed type of problem solving skill  Handlers provide convenient data structures that support a strong distinction between the infor mation that is strictly local to a problem solving element and information that is to be shared with other elements  Handlers in Schemer II are triggered by changes in data in the system  via communication with external processes  or by direct invocation  In any of these cases  a single triggering event may cause several alternative problem solving methods to be invoked  Furthermore  at any time multiple tasks may be on the system schedule awaiting execution  The scheduling problem is selection among  See Fehling       for a detailed discussion of the architecture  Successful Schemer applications have been built for  a number of real time   process management  applications such as diagnosis or control of complex manufacturing processes and automated performance management of advanced avionics systems among others                   I I I I I I I I I I I I I   I I I I I I I I I I I I I I I I I I I  these alternatives based on computational costs  data requirements  and attributes of the solutions offered by each method  In previous implementations the scheduler has used a simple pre emptive  priority based schedul ing discipline  In this approach the carriers representing potential tasks have an initial fixed priority prescribed by the system developer as a feature of their associated handler  On each cycle of the top level controller the current priority of each task remaining on the schedule is then  aged    viz   has its priority value modified  in some simple and application dependent manner  The disadvantage with this approach is that it is essentially hardwired prior to execution time there is no general facility to adjust scheduling decisions in response to changes in environmental characteristics  As a supplement to the priority scheme currently in Schemer  we are implementing conflict detection and  resolution routines for dynamically assigning and updating task priorities  A conflict is detected if several handlers are triggered for execution simultaneously  Once a conflict is detected  the system will look for specialized control knowledge to make a selection or allocation as exemplified by tradeoffs such as in Figure    If no specialized knowledge is available or applicable  then a handler which performs decision theoretic reasoning can examine the conflict  develop a control model such as described in Section   and make a recommendation regarding which task should be undertaken  A potential problem with this approach is entailed by the computational  and other   resource requirements associated with this method of reasoning about control         The activities of scheduling are  inner loop  in Schemer II s overall computational activities  If the computation costs required to explicitly perform a full blown cost benefit analysis on each cycle are too high  they will outweigh the value of this control reasoning no matter how formally sound and general it is  Thus  it may be necessary to restrict the real time estimations performed in scheduling on each cycle in response to limitations such as time deadlines  In extreme cases  it may even be necessary to abandon such a method entirely in favor of the default prioritization scheme       Critical event driven control of reasoning  One of the most important objectives in the evolution of the Schemer II design has been to fun damentally support problem solving processes whose control is responsive to critical changes in the problem solving context  A problem solver dynamically formulating and executing solutions to problems in an uncertain environment must be able to react promptly to the asynchronous oc currence of such critical changes  In response to such changes  the problem solving system may decide that its current actions are no longer the most preferable ones  In using earlier versions of Schemer in applications that must exhibit reactive  real time performance  we found the capacity for  interrupt driven  control of pro blem solving to be of paramount importance  In Schemer II the occurrence of some critical event can initiate a response to immediately interrupt execution of the currently scheduled problem solving tasks  suspend them gracefully  and commence tasks that are more appropriate in response to the changed information about the problem solving context  This is readily accomplished by the use of special event handlers that carry out these actions in response to pre defined critical events  This aspect of Schemer II s design is a natural evolution of the mechanisms for  opportunistic control  typical of blackboard systems such as Hearsay II      The discussion in the previous sections focused entirely on the  planning  phase of a combined control and primary decision problem  A real time system both plans and executes actions  Suppose the system has solved both the control and primary planning problems  and is now executing the sequence of steps in the primary problem  which may involve a series of compute intensive low level tasks  We need to define a set of critical events that would render the current plan inappropriate or inoperable  and signal a need to replan at a higher level  Critical events are defined with respect to the modeling method used to generate a particular course of action  If the output of model is in the form of a decision recommendation  d  n  we annotate the recommendation with a set of assumptions on which the recommendation was based       I as in  d  m  The system will continually sense its knowledge base and the environment for conflicts with the set m and trigger a replanning task when this conflict occurs  The set m is a subset of the full set of assumptions  both implicit and explicit  which are embodied in a planning method  There are complex tradeoffs involved in identifying this  crit ical  subset  Clearly only those assumptions which when violated would cause a change in a recommended action should be included  One class of important assumptions relates to mutual exclusivity  If the system detects a condition that is not among a set of enumerated possibilities considered in generating a plan  the plan may be invalid  Other possible classes of critical assump tions relate to the validity of data  probabilities  or defaults used in a model  However  providing sensitivity to critical events with an interrupt structure causes an increase in system overhead and detracts from performance on other tasks  Additional analysis of this tradeoff in the context of real time reactive planning and execution is needed     Conclusion  This paper has described efforts to apply decision analysis to the control of problem solving within a computational problem solving architecture  We have addressed control of both assessment and planning methods  The formulation makes it clear that a system s ability to make well founded decisions about the control of its own problem solving activities is a problem of information man agement  and we use concepts based on value of information to perform these allocations  This research addresses a limitation of much of previous research on problem solving architec tures  Schemer II is a well tested and highly evolved computational approach to resource bounded problem solving  The architecture allows encapsulating and interruption of alternative problem solving methods so that various problem solving techniques can co exist and be scheduled for exe cution as needed  One critical limitation of previous research with Schemer was that the methods for coping with uncertainty and for reasoning about control were ad hoc and application specific  Adoption of decision theory promises to rectify this shortcoming by providing a set of well founded and rigorous principles for managing internal resources and other decisions under uncertainty  Current research efforts involve incorporation of the decision theoretic control methods de scribed in this paper into the latest implementation of Schemer H  In future work we will be characterizing various problem solving methods with respect to their quality of information  as well as analyzing time and other resource consumption issues  Additional methods for analyzing inter rupt conditions need to be developed  including development of formal justification and generation of interrupts     Acknowledgements  I I I I I I I I I I I I  We thank Eric Horvitz  Jackie Neider  and Sampath Srinivas for comments on an earlier draft of this paper   I  
  solve the problem  The methods are characterized  This paper focuses on managing the cost of de liberation before action   In many problems  the  cost and the resource consumption of the delib eration phase cannot be ignored  and the overall quality of the solution reflects the costs incurred and the resources consumed in deliberation as well as the cost and benefit of execution   A feasible  strategy that minimizes the total cost is termed  computationally optimal   a number of independent   by uncertain cost and resource consumption  and are The selection  sequentially selected and evaluated   process is performed by a strategy that determines the next method to be evaluated based on the meth ods selected so far as well as the results of previous After a sequence of methods is com  evaluations    puted  the strategy halts the process at which point the best solution found so far is executed   For a situation where  Our goal is essentially to formalize the tradeoff  uninterruptible meth  between the costs of deliberation and the benefit  ods are available to solve the problem  we develop  of immediate action by developing a family of algo  I  a pseudopolynomial time algorithm to construct  rithms to construct generate and test strategies that  generate and test computationally optimal strate  are optimal with respect to expected global cost and  Stochastic Dynamic Programming is used to  have limited resource consumption in the delibera  I  and the results address problems occurring in auto  I I  gies   solve the problem that is shown to be NP complete  tion phase  Such a feasible strategy that minimizes  the total cost is termed  matic emergency response systems  design automa  computationally optimal   The approach is characterized by explicit mod  tion  query optimization  destructive testing  and  eling of the cost and resource consumption uncer  other areas characterized by significant computa  tainties inherent in the problem solving process and  tional costs or limited deliberation resources   methods from Stochastic Dynamic Programming          We construct computationally optimal K bound  in  Introduction  voking at most K methods  and oo bound on line  This paper focuses on managing the cost of deliber  control strategies for uninterruptible  independent  ation before action  In many problems the cost and  solution methods  The problem is shown to be NP  the resource consumption of the deliberation phase  complete and the resulting strategies are adaptive to  I  cannot be ignored  and the overall quality of the so  unpredictable external changes in cost and resource  lution reflects the costs incurred and the resources  availability   I  efit of execution   I  consumed in deliberation as well as the cost and ben We consider the situation where a number of in dependent  uninterruptible methods are available to supported  by  Rockwell  International  No       Net address  einav rpal oom   under  IR D  t Supported in part by a grant from Rockwell International  Science Center  Net address  fehl ing b ayes stanford edu   I I  There  are  methods  out  Stochastic a  MK possible ways M independent  of  Dynamic  O KV  logV  space  time  where D is the  we  develop  algorithm  and running in  f   Using  Programming   pseudopolynomial time  select  to ones   consuming  O KMV  D    maximum number of values in  cost or resource consumption distributions and V is the largest number between an alternative cost  a       method that is simulated   limit on resource consumption  and K  In some situations there are many applicable so  I  We assume that these  simulations are computationally intensive and must  lution methods  Some of them may be optimal  oth  be performed sequentially  and that due to some ran  ers may be of approximate or heuristic nature  and  dom factors the repeated estimation of a method can  all may have uncertainty in deliberation and exe  produce a different estimate but every such estimate  cution costs and resource consumption  Subject to  corresponds to an executable solution  After evalu  resource availability  a number of methods could be  ating by simulation the effects of several methods   a  sequentially explored in a deliberation phase in or  least costly solution  in terms of execution  will be  der to execute the least costly solution  Problems  selected   of this type occur in automatic emergency response  The central questions addressed by this paper are   systems  design automation  query optimization  de  What methods to evaluate  W hen to stop deliber  structive testing  and other areas characterized by  ation and start acting   significant computational cost or limited delibera  adapted in case the external conditions change in  tion resources  Adapting the response of the system  the middle of its implementation   to available resources provides a new approach to real time systems   tion     The cleanup operations that must be performed entail a cost of corrective action and should be as low  The remainder of the paper is organized as fol lows  Section  How can the strategy be    presents a  as possible  Since deliberation causes delay in action  motivating example  Sec  and increased concentration of the gas due to the  formally states the problem  and in Sections  leak  the total time of deliberation must be bounded     through     a family of pseudopolynomial time al  and may be modeled as  a resource constrained   gorithms to construct generate and test strategies is  We assume that the distributions of effects are    presents a basic case  such that no method stochastically dominates an    K bound  including at most K steps  strategy  other one  no one is clearly better for all possible  with no deliberation cost and no resource consump  outcomes    gradually introduced  Section  tion  Section       K bound strategy with delibera  tion cost and resource consumption  and Section       oo bound computationally optimal strategy  no  predefined limit on the number of steps   Section discusses related work and Section       summarizes our  Our basic observation is that  because  of a time bound  it is not possible to estimate all the solutions   The problem is defined precisely in the  next section      Problem Statement  M        MM   results and presents problems for future research   Let M     that solve some specific problem instance  Motivating Example  Consider the following hypothetical situation  due to a leak of some explosive  corrosive gas into a space station s air  a state of emergency is automatically declared   There are two reasons to avoid accumu  lation of gas    a  to minimize the damage due to corrosion  and  b  to prevent critical accumulation that can cause an explosion   Since a high concen  tration of gas can cause an explosion  the response is time bound  Let us presume that a number of methods are stored in the station s main computer to deal with various contaminations  utilizing such alternative tactics as isolating contaminated areas  chemical neutralization  and dehermetization of non vital sec tors  The methods differ in their effectiveness  in the amount of damage they cause  and in other material losses  their effects are uncertain and are encoded by probability distribution functions  Given the details of a specific accident  the esti mated effect of any method can be determined by computer simulation  Simulation running times are also uncertain and depend on the inputs and the     be a finite set of methods  P  Every M  E M computes a solution instance M  P  out of the set Of of the possible so  method in  s f      lutions   Since we will consider only one problem  instance at a time the index  P  will be omitted in  the following  We assume that the methods cannot be inter rupted  The only exception is when a method ex hausts all the available resource  in which case it halts automatically without producing any solution  Let  I I I I I I  I I I I I  Cost sM   denote the distribution of cost to sM   We denote by Cost M    and Res Mi   I  Mi during the deliberation  i e   computa sM   We assume that cost and resource dis  I  execute  the distributions of cost and resource consumed by method tion of  I  tributions are given as sets of rational probabilities over the finite sets of nonnegative integer values  In general  a strategy   S   will generate and esti  mate a sequence of    methods   The methods in  this sequence  and the corresponding solutions ob  tained by evaluating them are denoted by M      and  sM   fior     Note     i                  that in general M          M   I I I I       I I I I  After analyzing a   possibly empty  sequence of the methods evaluated so far and results of these evalu  exhausted  Nevertheless  we explicitly specify feasi bility to emphasize this point   uated next  When the strategy halts  a least costly  ations  a strategy selects a new method to be eval  Since the exact sequence of methods to be evalu  known solution is executed  If we denote the halt  ated by S depends on the outcome of the previous evaluations  the deliberation cost is uncertain and  ing decision by H  strategy S can be depicted as performing at every iteration the following generate and test steps  see Figure  GenerateS    M S   sM            M S   sM          I  I I I I I I I I I  In the following we will always mean computational     raet       Method              ble  strategy  with  expected  and resources incurred when the methods are used   Cost sM   is the corresponding set of distributions  of a solution costs  f denotes the amount of resource available for deliberation  and      S is bounded by L E z  if     S L for any possible application of S  If S is bounded by L we will call it L bound   Definition  We assume that we are always given a solution  CostAlt  CostAlt also  as  cost s        min  s O      I    We define   cost sMf   Using this definition  a least costly known solution     K bound Strategies with No Cost and No Resource Con sumption in  Cost  s   the cost s   prior to starting strategy S  and by E  Cost s    its expected value  Simi   larly  let cost S       cost Ms i    and res S       s     res Msi   denote the total cost and resource condistribution of  sumption in the deliberation phase of S   the Delibera  tion Phase In this section we set cost M i    res M        for all i           M  We begin by stating independence assumptions for the probability distributions of ex  ecution cost   will be selected for execution and doing nothing is  always a possibility  Let us denote by  is a finite al  used at all   to be paid if no methods are  cost sM    CostAit  ternative cost that will be paid  if no methods are  sAlt  used at all  For notational convenience we will refer to  cost  C  The problem is defined by a   tuple  C  M  CostM  ResM  Cost sM   f  Cost Alt   where M is the set of solution methods  CostM and ResM are the distributions of computational costs  below  Generate and test deliberation strategy   that has cost  We  We want to determine whether there is a feMi  Execute the Best So Iutton  Deliberation Figure  when optimality is referred to   also consider only bounded computationally optimal strategies fitting our generate and test model        I  Let  E  Cost s      optimality   Vrest  Cost S    its expected value   Feasible strategy s is computationally optima  if for any feasible strat egy S  E Cost  S    E  Cost s        E  Cost S     otherwise  I  I  Cost S   denote  Definition        if deliberation halts  I  I       described by some random variable  E     For any i f  j  distributions   s   and Cost sM s   are mdependent   Assumption  Cost sM   Since nothing prevents a strategy from selecting and estimating the same method more than once  this  as  sumption implies that the cost distributions in any two execution instances of a method are indepen  Strategy S is feasible if for any pos sible a pplication of S  res S       r  where r denotes the amount of resource available for deliberation   dent   Note that following our earlier definition of uninter  problem  delaying the treatment of interdependent  Definition      ruptible methods  any strategy is feasible  since it  will simply halt when the deliberation resource is  Assumption     is very strong  and it clearly re  stricts the applicability of the results herein  How ever  since releasing it significantly complicates the methods is justified for two reasons  one  a simpler  algorithm can be obtained when Assumption   does       hold and two  even when the assumption does not hold  solving a simplified problem can provide a first approximation to a more complex model   is a K bound optimal strategy if zs      K  and for any K  bound feasible strategy S   Definition     s   E Cost s          E Cost s       The argument is similar to the one for k      If the cost of computed solution  cost sM    is higher than cAlt  we keep an old alternative cost  and if  the cost is lower  the alternative cost is lowered  In  both cases after estimating M   we have one method less to estimate  therefore k decreases by    Ck cAlt   k              and cA    Cl  cA t   We will now introduce the table Ck of optimal k        step strategies  By conventions of dynamic program  ck corresponds to the optimal strategy for the     ming   lastk methods  C  corresponding to an optimal  step strategy  C   to a n optimal   step strategy  and so on   is the optimal expected cost for all the feasible strategies consisting of ex actlyk methods and initiated with cAlt   Definition     Ck cAlt        Computing  K bound  Optimal  Strategy  is the optimal expected cost for all the feasible strategies consisting of exa ctly k methods  initiated with cA    and beginning with method M    Definition     Ck M   cA     We start by calculating C  M   cA    for i          M  and cAlt              CostAlt         Although our  probability distributions are discrete  the notation  drawn from the continuous case makes presenta tion simpler  and therefore will be used   T here is  of course a straightforward mapping to the discrete case   I                 CostAlt   is found by   min   l       M  Ck M  cA t        C  M  cA      cA t           C     defined recursively by     and     is the optimal expected cost for all the strate gies consisting of exa ctly k methods and initiated with cA    I  Theorem     Ck c A t   Proof  By induction on  k   C  cAlt    cAlt is the  optimal expected cost when no method can be esti  mated  Assume that ck l cAlt  is the optimal ex  pected cost for all the strategies consisting of exactly k      methods and initiated with cA   To prove the  claim for Ck cA     we notice that an optimal strat egy must select one of the methods    M        MM   to  be estimated first  Based on our assumption about optimality of Ck l cAit  and our argument earlier in this section  the expected cost for all the strate  gies that begin with some method M  and contain exactly k steps is given by      and since an optimal  strategy may select the best first method to mini  To implement the optimal K bound strategy us  ing the table Ck cA t   we must reconcile a differ ence in definitions   All  cost sM  dcost sM    I I  the minimum  If we set C  cAl t    cAlt            hold for all k E z   We also define C  M  cA lt    cA lt   expected cost    dcost sM      I  We will denote by Mk cA t  the method that attains  mize the expected cost     gives the needed optimal C Ali  I  to include  We defined K bound strategy  at most K  methods  while the entries  I  I I I I I  in Ck c A t  provide an optimal expected values for  If method Mi produces a solution with execution cost higher than cA    the new solution is ignored   strategies with exac tlyk methods  It turns out that the two are equivalent  To prove that we will need  I  T he second term represents the contribution to the  the following lemma   I  expected cost when  cost sM   is lower than cAlt   ter C  M  cAlt  is computed  we compute  Cl cAlt     min    s l         M  In a general case   k                         For anyk  Proof  Since Ck a           M  cAlt     CAli  dcost sM         Ck l cost sM   dcost sM   CAll     ck l cAlt        i  Lemma      Ck b    Cl M  cAlt               CostA     Ck M  cAlt   Af          E Z     a  b      Cl  a    min i l      M Ck Mi a   it will  suffice to prove the more specific result  for any Z  and          k  i  E  a   b      Ck M  a    Ck M   b   By  mathematical induction onk  Fork      the claim is  true by definition of C  M  a   Assume it is true for  k     we must prove that it holds fork as well  Our induction assumption and     imply that ck   a    ck   b     We will use this fact later   We must prove   I I I I I       I I  or equivalently  using      Ck l a      a dcost sM      I    foa ck I cost sM   dcost sM            Ck I b      dcost sM      I I      fo ck l  cost sM   dcost sM    or  I    Ck l a    dcost sM        dcost sM  J   I    foack I cost sM   dcost sM          Ck l b     dcost sM     I    foack I cost sM   dcost sM           ck I cost sM   dcost sM    I I    Ck l a     dcost sM          dcost sM  J            ck t  cost sM   dcost sM     I    Ck I  b     dcost sM    This is the sum of two inequalities that follow  as noted  from the induction assumption    Ck l  a    dcost sM       I I I I I I      cAll Lemma  o Ck cost sM   dcost sM       J CAli     Ck cA t         Ck  cAlt             ck t   cost sM    dcost sM    and  Now the equivalence theorem can be proved  For any k E Z  Ck t  t  is the ex pected value of an optimal k bound strategy initiated with t  t  Theorem      CAll      dcost sM      dcost sM   d  Ck M    cAit    and the result follows from the definition of C   By Theorems     and     the following Strategy     is optimal K bound strategy  Strategy      lnit  by eliminating identical terms on both sides   I I  Proof  It is enough to prove that for any value of cAlt  I     m    C  cA t      C   cA t    Then ev ery k bound strategy will contain exactly k steps  and therefore Ck cAlt  table could be used  We will prove that for any cAlt and for all k E Z  Ck    t  t     Ck cA t    Indeed  for any i          M   Step k  Compute Ck cAlt   fork               K  and c Alt               CostA it  Set c Alt   CostA It s     Alt For k      to   Estimate Mk   Mk cA t  If cost  sMk      cAlt then Set cAlt   cost sMk  s    sMk  Returns        Numerical Example  Consider the following problem  there are only two methods   M   and M   M    Mt  M     The   values of the solutions that are produced by these methods can be only       or    D       We need to compute an optimal strategy for   periods  K      and we start with an alternative solution of cost    i e   CostAlt      it will cost us   if we decide to do nothing   Distributions of cost sMk  for k       are shown on Figure    Starting with an optimal strategy for one  last  pe riod   k       we compute for c Alt      C   M       for i         C  Mt O       C  M            M        Mt  we recall that M      denotes a method for which C  M    O   is minimized   C          For c Alt      we obtain C  Mt            C  M               M       M   C                    s      I     M        s   I  M         I         Figure    Cost distributions of the solution  For cAlt       C   Mt             C  M                M        Mt  C            And so on  The resulting opti mal strategy is shown on Figure    This strategy  X    I                      M          M     M    M  l  H  Figure    Resulting optimal strategy  will start by estimating method M      M   column      and row corresponding to cAit       As sume arbitrarily that cost sM         meaning that the alternative cost was not reduced at Step    We estimate next method M     M  When  also ar bitrarily   we find that cost sM       the alternative cost is reduced to   and we continue by estimating M      M  Assume cost sM        At this point deliberation halts  and since the current alternative cost is    solution sM  found at Step   is executed   k       Computational Complexity  Input  M  methods are encoded in the input stream  Every method Mi  i           M is described by the distribution of the cost of the solution  given as a set of rational probabilities over the nonnegative in teger values  also given in the input  If the max imum number of values in cost distributions is D   and V   max   CostAlt   K   the length of the input will be O MDlogV   Space  Storing the strategy table requires space O I VlogV   Tim e  Computing the table takes time O KMVD    K bound Cost  Strategies  with  and Resource  Con  sumption in the  H       M       I M     H           M    M          M           Conjecture     Computing computationally opti mal real resource strategy with no cost and no re source consumption in deliberation phase is NP complete if D      In the next section  we prove the NP completeness of a more general problem      I  since for every entry we must compare M methods  and evaluating each requires O V  calculations  Informally  Garey and Johnson       an algorithm has a polynomial time complexity if it runs in a time polynomial in the length of its input  I  MVD is not a polynomial function of MDlogV  but it is a polynomial function of MDlogV  I   and V  An algorithm that runs in time polynomial in its input length and the largest number in the input has a pseudopolynomial time complexity  which is true in our case   Delibera  tion Phase In this section we extend the basic technique de veloped in Section   to handle cost and resource consumption in the deliberation phase  First we in troduce the cost alone  Two new assumptions are needed  For any i    j  distributions and Cost  Mf  are independent   Assumption    Cost  Ml   I I I I I I I I I I I  Assumption    I       I  For any i and j  distributions Cost Mi   and Cost  sMf  are independent  Cost in the Deliberation Phase  No Resource Consumption  Presence of the cost in deliberation phase may cause an optimal strategy to estimate fewer methods  We will appropriately change the definitions of Ck cA t   and Ck Mi  cAit    Definition s   Ck cA t  is the optimal expected to tal cost for all the strategies consisting of at most k methods and initiated with cAlt    Ck Mi  cA t  is the optimal expected total cost for all the strategies consisting of at most k methods  initiated with cA t  and beginning with method Mi  Definition      I I I I I I       I I I I I I I I I I I I I I I I I I I  The recursive formula for c   Mi   cAit  will be changed to reflect the cost of deliberation  Ck Mi CAit    c  l cAit         Ait C  dcost sM               Ck l cost sM   dcost sM     E  Cost Mi   Alf C  Note that by Assumption   only the expected value of deliberation cost appears in this formula  Finally  to provide for possibility that in some sit uations doing nothing could be the best strategy  we introduce a new artificial method to be denoted by M  It is characterized by cost Mo      and cost sMo    CostAlt  Since the deliberation cost of M  is   it can be used without restriction and since cost sMo    CostAlt it will never improve a current alternative solution  The definition of Ck cA t  will be altered to in clude M    c  cA t      min Ck Mi CAit   D l      M       c  cAit  computed recursively by     and     is the optimal expected total cost for all the strategies consisting of at most k methods with cost in deliberation phase and initiated with cAlt    Theorem      Proof is similar to that of Theorem      We must only notice that since the deliberation cost is independent of execution cost  the expected deliber ation cost is included in     and since the dummy method Mo may now be selected      must include Mo   By Theorem      if Strategy     will compute Ck cA    using      and     it will be an optimal strat egy with deliberation cost  The space and computational complexity with de liberation cost are the same as without them  as pre sented in Section     It is assumed that the interrupted method produces no solution and incurs full computational cost  In order to account for the resource consumption  we must add a resource dimension to the strategy table  Other than that  our discussion parallels the development of the previous models  As with the cost  we make an independence assumptions for re source consumption distribution functions   Res Mn  Assumption    Both  Cost  sumption  and in  Resource  the  Con  Deliberation  Phase  In this model the estimate of every method causes the consumption of some quantity of a single re source  described by the distribution Res Mi   i               M  from the total level   r  available in the beginning of the process  With one exception  we assume uninterruptability of methods  when the total resource consumption reaches r the deliberation process is interrupted and the best solution available at this point is executed   For any i and j  distributions and Res Ml  and  Res M l  and Cost   sMf     Cost Ml  are independent   Similarly to the previous case  we define       c   cAit  r   is the optimal total ex pected cost for all the strategies consisting of at most k methods  initiated with cAlt  and that can be exe cuted within resource limit r  Definition      ck Mi  CAit  r   is the optimal total expected cost for all the strategies consisting of at most k methods  initiated with cAit  that can be exe cuted within resource limit r   and begin with method Mi    Definition  We also define  Ck cAl t r     min Ck M i CAlt r         M a O   Proof          For any i  f  j  distributions and Res   Ml   are independent   Assumption  Where CI  Mi cAit r                 forcl  l cAit r res Mi  dres Mi   Ali C  dcost sM      dres Mi    r         J dres Mi Jt c  l  cost sM   r  res Mi  dcost sM    E  Cost Mi    c  cA    computed recursively by     and     is the optimal expected cost for all the strate gies consisting of at mostk methods with cost and resource consumption in deliberation phase  and ini tiated with cA     Theorem      The proof is similar to that of Theorem      We must only notice that since the resource con sumption is independent from cost      is correct  Proof     It remains to modify Strategy     to include resource management  The optimality of the Strategy     follows from the Theorem            Strategy       Compute Ck  c  t  r  fork               K  c Alt           C ostAlt  and r              f Set cAlt  CostAit  Init  Step k  r f s    sAlt  Fork  K to   Estimate Mk   Mk  cAit r  Set r   r  res Mk   If cost sM     cAit k then Set c Ait   cost sM    s   sM  Computational Complexity  The length of input is O MDlogV   where  before  D is the maximum number of values in cost or resource consumption distributions  and t V  max   CostA i   K  r   Space  Storing the strategy table requires space Input   as  O KV logV   Time  Computing the O K MV  D    because  table takes time for every entry we must com pare M methods  and evaluating each requires V  calculations  The algorithm has pseudopolynomial time complexity  Computing computationally optimal real resource strategy is NP complete problem   Theorem      Our problem can be easily solved by nondeterministic automaton by branching non deterministically every time a new method must be generated  Next  we will show that our problem re stricts to Integer Knapsack Problem  see p           i e   Integer Knapsack Problem is a special case of our problem  Set C   K  Define a method for each u E U  set cost Mi      res Mi    s u   and define the distributions of execution cost by p cost sM            v u   p cost sM               v u   Set r   B  GostAlt      Solving this real resource strat egy problem will solve Integer Knapsack Problem  Proof Outline        Strategies  without  For any instance of a problem with positive deliberation cost  If Cmin mini l      M cost Mi  an oo bound optimal strategy is bounded and equivalent to an optimal strategy for C tAl  K   bound problem  where K    r   os c   l Theorem      Returns        insisting that the strategy be bounded  otherwise it may never terminate  but we may not be given a specific bound  This section shows that in some cases   namely when all methods have positive deliberation costa problem with unspecified bound may be reduced to K bound problem by calculating the upper bound  In other cases the oo bound problems may have no bounded  optimal strategies  resource permitting  it will always be beneficial to add another method in hope to reduce the execution cost even further  Theorem     finds the bound for problems with positive deliberation cost   Prede   fined Step Limit We now consider the most general case  correspond ing to our example in Section    In real life situ ations we do not typically restrict the number of steps  or iterations to be taken by a strategy  Our concern is that the strategy be optimal while the ex act number of steps is not important  We are still  mm  Proof  Let P be an instance of a problem with positive deliberation cost  The deliberation cost of any strategy for P using more than J   steps will ex ceed the alternative cost  so such a strategy cannot be optimal  Since the number of the possible strate gies containing at most I   steps is finite  an optimal strategy exists  and has at most K  steps   The implementation of oo bound strategy is obvi ous     compute K      implement K  bound opti mal strategy     Related Work Our work emphasizes the analysis of computationa lly optimal control of deliberation before action  Several approaches were suggested to related prob lems involving the control of deliberation  Tokawa and Kim      treat a similar component selection problem in design automation domain  They suggest selecting components in random  and evaluate the resulting strategy by its rank in a list of all possible strategies  Ono and Lohman      consider the problem of query optimization  They construct a polynomial strategy for some types of queries us ing a dynamic programming formulation  but they do not allow for uncertainty  and do not consider a resource constraint  Brooks      and Agre and Chapman     suggest reactive approach to deliberation problem  and al though Brooks provides for deliberation when reac tion fails  neither Brooks   nor Agre and Chapman s work offers optimal deliberation control methods as those presented here  Kaelbling     and Rosenshein and Kaelbling     suggest avoiding deliberation by compiling in ad   I I I I I I I I I I I I I I I I I I I       I I I I I I I I I I I I I I I I I I I  vance the programs responding within the given re source limit  but they do not allow for uncertainty  and do not claim optimality with respect to all the programs meeting the limit  Horvitz     offers a decision theoretic algorithm to select a single method among the set of alternative interruptible methods  and Fehling and Breese     present a computational architecture and decision theoretic principles for real time control  In general  the reactive approaches focus on elimi nating the deliberation by sacrificing the optimality  while the decision theoretic work is traditionally ig noring the computational issues in pursued of an op timal solution  By introducing the computationally optimal strategies we reach an optimal balance be tween the deliberation and execution costs      Summary and Future Work  In this paper we have stated a problem of finding computationally optimal real resource strategies for independent  uninterraptible solution methods  and shown how to solve it for all practical purposes  The problem  which we have shown to be NP complete  appears in numerous practical applications  We de veloped an algorithm that solves it in a polynomial time if the alternative cost  resource limit  and num ber of steps have small values  The results can be readily extended to the case of multiple resources  This extension involves adding a dimension to the strategy table for each new re source  it does not require any new technical ideas and is left to the reader  Future work may address validating our NP completeness conjecture  allowing dependencies among the methods  and considering interruptible methods      Acknowledgments  We would like to thank Michael Genesereth  Matt Ginsberg  Eric Horvitz  Ross Shachter  and Dave Smith for helpful discussions that resulted in im proved presentation of this paper  Diane Cunliffe and Sue Kenney helped greatly to improve the style  We also thank anonymous referees for their sugges tions  The first author is grateful to Palo Alto Labo ratory of the Rockwell International Science Center for creating an ideal environment for this work   
 Probabilistic conceptual network is a knowl edge representation scheme designed for reasoning about concepts and categorical abstractions in utility based categorization  The scheme combines the formalisms of ab straction and inheritance hierarchies from artificial intelligence  and probabilistic net works from decision analysis  It provides a common framework for representing con ceptual knowledge  hierarchical knowledge  and uncertainty  It facilitates dynamic con struction of categorization decision models at varying levels of abstraction  The scheme is applied to an automated machining problem for reasoning about the state of the machine at varying levels of abstraction in support of actions for maintaining competitiveness of the plant   Figure    Using a pc net in utility based categorization    Introduction  A probabilistic conceptual network  pc net  is a knowledge representation scheme designed to support utility based categorization   Poh         In contrast to the traditional approaches which are logic and similarity based   Smith   Medin         utility based categorization considers the usefulness of the infor mation conveyed by the concepts  the actional con sequences  the desirability of the consequences of ac tions  the computational or cognitive resource require ment and availability  and the uncertainty about the environment   limited observations  It must conceptualizes the sit uation and decide on the most appropriate course of action  It does so by solving a categorization decision model  However  different models at different lev els of categorical abstraction can be used  Each of these models has different expected value of the recom mended action and different computational resource requirement  The agent must therefore decide on the best level of abstraction to construct the model so as to achieve the best trade off between the expected value of the recommended action and cost of computation   We have developed a decision theoretic approach for utility based categorical reasoning as shown in Figure    in contrast to previous work on abstraction in prob abilistic reasoning   Horvitz  Heckerman  Ng    Nath wani        Horvtiz   Klein        which were more narrowly focused  In our view  a resource constrained agent operating in an uncertain world is given a set of  A probabilistic representation of conceptual categories called a pc net is used to represent the agent s knowl edge about the world  A level of conceptual abstraction for a building a model is obtained by selecting a con ceptual cover from the pc net  As illustrated in Figure    a conceptual cover is obtained by selecting a set of mutually exclusive and exhaustive concepts from dif ferent levels in the pc net    Also at Dept  of Industrial   Systems Engineering  N a tiona  University of Singapore  Kent Ridge  Singapore          The notion of conceptual coverage in abstraction hier    Probabilistic Conceptual Network  We have developed an incremental algorithm whereby the reasoner iteratively specializes or generalizes the conceptual cover  A concept is specialized by breaking it up into a set of more specific subconcepts  A group of concepts may be generalized by replacing them with a single super concept  At each iteration  changes are made in order to achieve the highest expected im provement in overall utility  Poh         The proce dure applies the principles of decision theoretic control  Horvitz              Fehling   Breese        Russell   Wefald        to iteratively decide between alloca tion of additional resources to refine the current set of concepts  or to act immediately based on the cur rent action recommended by the model  This model refinement approach is a special application of a more general approach for refining general decision models  Poh   Horvitz         In this paper  we describe probabilistic conceptual net works and show how they may be used to repre sent both categorical and uncertain knowledge and to facilitate the dynamic construction of categoriza tion decision models at varying levels of abstraction  We present an example from automated machining  We also compare our scheme with similarity net works  Heckerman        and other approaches to knowledge based decision model construction     Integrating Uncertainty and Categorical Knowledge  To perform utilitY  based categorization  an intelligent actor must expres  different dimensions or perspectives of knowledge  First  she must be able to express cat egorical knowledge with some degree of modularity  Categorical knowledge expresses facts about individ ual concepts in a given domain  i e   it describes the features and properties that characterize the concepts  Second  the actor must represent categorical relations  e g  how one concept subsumes others  In particular  the actor  when problem solving  must decide which concepts to use and at which levels of abstraction in order to obtain a useful solution  In artificial intelligence  abstraction hierarchies and semantics nets  Lehmann        are graph based for malisms that have been advocated for computer rep resentation of concepts and categorical knowledge  They organize conceptual knowledge in levels of ab straction and make use of  inheritance  mechanisms whereby concepts may share features and properties with higher level ones  Since feature information need only be stored at the highest possible level of abstrac tion  maximum elegance and economy of storage is achieved  These formalisms  however  are not easily amenable to representing uncertainty in an elegant and efficient manner  In reasoning and decision making under uncertainty  archies arose in discussions with Eric Horvitz        specialized graph based formalisms like influence di agrams  Howard   Matheson        have been ad vocated for computer representation of probabilistic knowledge and decision models  These formalisms fo cus on the dependencies among the probabilistic vari ables  They encode probabilistic models as directed graphs with the nodes representing the uncertain vari ables and the directed arcs denote possible probabilis tic dependence between variables  Each node encodes a conditional probability distribution of that node s variable given each combination of values of its direct predecessors nodes  Various techniques have been de veloped over the last decade for probabilistic inference and reasoning using this representation  see for exam ple Pearl         Pc nets combine the formalisms of influence diagrams with inheritance hierarchies by representing concepts with influence diagrams and then linking these con ceptual diagrams in a hierarchy  By do so  pc nets are able to capture the best features of both formalisms and to use them effectively in support of utility based categorization     An Application  m  Automated  Machining  We will illustrate the use of pc nets in utility based categorization with a real world example of an auto mated machining problem  This is similar to an appli cation described by Agogino and Ramamurthi         Unattended or automated machining operations are important parts of any intelligent manufacturing sys tem  It requires the automation of the human op erator s efforts to monitor and make appropriate ad justments to the state of the machine  An automated machining system typically has sensors which acquire data on     dimensions of the workpiece      acous tic emission from the machining processes      cutting forces  dynamometer readings   and     electric cur rent  ammeter   etc  These data are then used to determine the state of the machine and appropriate action or actions are taken to ensure the continuous operation of the plant so as to minimize production cost  thereby maintaining competitiveness  The possi ble states of the machining process at various level of abstraction are illustrated in Figure    At the most abstract level  the state of the machin ing process is either  within variability limits  or  out of variability limits   Refining the concept  out of variability limits  are  tool failure    sensor failure  and  transient state   The latter occurs during entry or exit of the cutting tool into the workpiece  Re fining  tool failure  are  tool chatter  which is typi cally characterized by an event in which an acoustic emission signal increases dramatically in amplitude as does the frequency content of the dynamometer  If left unchecked  tool chatter can result in tool  workpiece or machine damage  Remedies for this problem include   Poh and Fehling       Probabilistic Conceptual Network                             oo    t       I       t l t l tool wear chatter breakage I  I  tf                                       I  tooi failure I I  A           fiR      t          I I                           tr          acoustic dynamo  ammeter sensor meter  I I  I      nt     tool entry         tOQl eXIt       rl  ve cal ho zontal chatter cnatter  rti  Figure    Hierarchy for states of a machine reducing the depth of cut or reducing the feed rate   Tool wear  is typically characterized by a gradual in crease in acoustic emissions  and by a gradual increase in cutting force as measured by the dynamometer  A tool that is worn out needs to be re sharpened or re placed in order to achieve the desired surface finish and dimensional tolerances   Tool breakage  is typi cally characterized by an acoustic emission exhibiting a hig amplitude peak at the moment of tool fracture  and followed by a sharp drop in signal amplitude to a level below that of normal  It is also characterized by a large rise in cutting forces  followed by a drop before finally continuing at a value above the average  Tools that are broken cannot perform any machining task and must be replaced immediately  This problem is interesting because under differing op erating conditions and situations  different levels of abstraction in monitoring and reasoning may be de sired  For example  if the tool has been changed re cently  giving it a low prior probability that it will fail soon  it may be more worthwhile to only moni tor at a more general level  i e    tool failure    sensor failure  and  transient state   rather than spent ex tra resources to differentiate the finer details  In other words  the expected value of the information derived from using more detailed concepts may not justify the required additional computational resources  On the other hand  if the tool has already been in used for a long time  then it might be worth the extra effort spent in monitoring and reasoning with more detailed concepts  like for example at the level of  tool chat ter    tool wear    tool breakage    sensor failure  and  transient state   Also if the material currently being machined is a difficult one  e g   a high carbon steel  which is known to have caused occasional tool break age  then it may also be worthwhile to monitor at a deeper level of detail  In another possible scenario  suppose the some critical sensors are out of order  then the only level of detail available might be at the most abstract level whereby only two possible states are be ing monitored  The operator would then need to be alerted to take any corrective action   Definitions  A probabilistic conceptual network  pc net  consists of a probabilistic concept hierarchy  pc hierarchy  con necting a set of probabilistic concept diagrams  pc diagrams   Each node in the pc hierarchy repre sents a concept  and the links in the hierarchy spec ify subsumption relations among the concepts thereby organizing the concepts at various level of abstrac tion or specificity  Associated with each subsumption link is a value indicating the conditional probability that a concept holds given that its immediate super concept holds  Individually  each concept within the pc hierarchy is represented by a pc diagram  We may visualize a pc net as a hierarchical organization of pc diagrams  A pc diagram for a concept is a special probabilistic influence diagram  pid    representing the knowledge about the probabilistic relations between the concept and the features that characterize it  The concept is represented as a deterministic node while the features are represented by chance nodes  As a convention  we direct arcs by default  from the concept to its feature nodes  For each feature node F in the pc diagram for concept ck  we store a probability distribution of the form k p FICk  B  F   where Bk  F  is the set of conditional predecessors  possibly empty   that excludes Ck  We shall assume that background information e is used in all the prob ability distributions  We represent Ck as a determin istic node because we do not need the distribution p Fj   Ck  Bk F    A pc diagram for a concept pro vides information for discriminating that concept from other concepts in a domain  Pc diagrams allow knowl edge to be represented locally providing modularity in the knowledge base  The value of a pc net emanates from its ability to sup port utility based categorization  As shown previously in Figure    given a pc net together  a conceptual cover can be selected at some level of abstraction to con struct a categorization decision model corresponding to that level of abstraction  We shall describe the pro cedures for model construction in Section    Finally  pc net uses an inheritance mechanism whereby a concept may share information about features from a concept higher up the hierarchy  It does so by tak ing advantage of a form of conditional independence called subconcept independence  which is not conve niently represented in ordinary influence diagram rep resentation  A feature is said to be subconcept inde pendent of a concept if knowledge about the feature   A pid is an influence diagram with only probabilistic nodes and conditioning arcs    Section     compares subconcept independence with  subset independence  in similarity networks    Probabilistic Conceptual Network  Feature  Description  AE mag  acoustic emission magnitude  AAE mag  change in acoustic emission magnitude  AE freq  acoustic emission frequency  dyn freq x  cutting force frequency in x direction  dyn freq y  cutting force frequency in y direction  AE mean  mean of the acoustic signal change in the mean of the acoustic signal  AAE mean dyn rms x  cutting force in the x direction  Adyn rms x  change in cutting force in the x direction  dyn rms y  cutting force in the y direction  Adyn rms y  change in cutting force in the y direction  AE peak  acoustic emission peak value  dyn peak x  peak cutting force in x direction  dyn peak y  peak cutting force in y direction  current  motor current  Table    Descriptions of features does not affect the agent s belief about any of that concept s subconcept  We will have more to say about subconcept independence in Section           Automated Manufacturing Example       and the most specific subsumer of a set of concepts S     C       Cn  is denoted by   C          C   or  S   p C ACj e  ci we h avep CiICi  Suppose C   p Ci       But C   Cj implies that p Ci    Cj    p Cj  There fore       In other words the subsumption probability is simply the ratio of the prior probabilities of the concepts it connects       Feature Relations and Conceptual Abstraction  Suppose we have already assessed a set of pc diagrams  we can combine them to produce a more general super concept  For example  given the pc diagrams for  tool chatter    tool wear   and  tool breakage   we can obtain the pc diagram for  tool failure   In general  given Ck  set of its most general subsumees   ck   and suppose Bk F    UciE Ck Bi F  then p F Ck  Bk F     k k l  ciE ck  p FJCj  Ck  B  F  p Ci Ck  B  F    The feature F is independent of Ck given any subcon cept Ci of Ck since once Ci is known to be true then any information about ck will not have any further effect on our belief on F  This implies that  Fi Ci  Ck  B k F     p Fi Ci  Bk F    Like wise  Cj is independent of Bk F  given Ck  Hence p F Ck  Bk F     L p F Cj Bk F  p Cj Ck   CjE Ck   Figure    The pc diagram for  tool chatter   Figure   shows the pc diagram  tool chatter   This diagram comprises a deterministic node representing  tool chatter  and a number of feature nodes whose descriptions are given Table    An arc between two feature nodes indicates that these two features may not be conditionally independent given the concept  tool chatter   For example  the arc between the node  AE mag  and the node  AE mag  indicates that information about the current magnitude of acoustic emission may provides information about the change in magnitude of acoustictemission  The direction of this arc could be reversed without any change in as sertion about possible dependency  Figure   shows a fragment of the full pc net for the automated machining showing the concepts  tool fail ure    tool chatter    tool wear    tool breakage    sensor failure   and  transient state        Probabilistic Subsumption Relations  We shall denote the fact C  is a subconcept of Cj by C   Cj  The set of the most general subsumees  i e  all the direct subconcepts  of Ck is denote by  Ck     which may be rewritten as     p F Ci  Bi F   Bk F    Bi F  p Ci Ck  CjE Ck  But the set of conditioning features Bk F    Bi F  is independent ofF given Cj  Hence p F Ck  Bk F           CjE Ck   p Ci Ck p F Ci  Bi F     Hence if Ck is a concept in the pc net and all the pc diagrams for the concepts in   ck  has been as sessed  then the pc diagram for ck may be derived from those of its subconcepts  Formally  for any fea ture F  p F Ck  Bk F    L  CjE Ck   where Bk F      p Cj Ck p F Cj  Bi F         i F   U ci E  Ck   B  Equation     allows us to build the pc net from bot tom up by propagating the probability distributions in the pc diagrams from the bottom of the hierarchy up to the root of the hierarchy  This allows us to build   Poh and Fehling                          p   I I I  I I  I I I I I  o I I I   I          I I I  I  I I I  I    I I        I I I  I  Figure    A fragment of the pc net for the automated machining problem the pc net by first constructing the pc diagrams for all the terminal or atomic concepts  and then the pc diagrams for the more general concepts may be derived from the pc diagrams below them  However  it is pos sible to simplify the pc net by identifying subconcept independence and take advantage of inheritance       Feature Inheritance for Subconcept Independent Concepts  The principle of inheritance in pc net is based on a special type of independence that can hold among con cepts and features  Formally  we say that a feature F is subconce pt independent of a concept C  given B  if and only if     for all feature values f ofF and for all subconcepts C  of Ck  Intuitively  information about a feature that is subconcept independent of a concept does not affect the agent s belief about any of that concept s subcon cepts  An equivalent criterion for subconcept indepen dence is obtained using using Bayes  rule   The last equation applies that for any pair of sub concepts C  and Cj of Cc  i e   p FjC     p FICJ  Conversely  if the last equation holds then using equation      p FIC     Lj p CJICk p FICJ  p FIC   Lj p CjiCk  Lj p CjiCk p FIC    p FjC    Hence an equivalent criterion for subconcept independence is   We shall denote by F   lCkjB  the fact that F is sub concept independent of Ck given B  In cases where the background knowledge is understood  the B may be omitted  An interesting property about   l is that once it has been established for a concept  it recur sively applies to all of its subconcepts  Poh         That is   The justification for the application of inheritance for subconcept independent concepts for a feature is due to equations     and      Since the probability dis tributions for the feature are identical  we need only store them at the highest possible position  To illustrate the idea of inheritance  consider the frag ment of the pc net for  transient state    tool exit  and  tool entry  shown in Figure    The feature  rms current  is subconcept independent of  tran sient state   We do not need to explicitly store the probability distributions for  rms current  in the pc diagrams for  tool entry  and  tool exit   That is  we may  omit  these probability distributions  and hence the corresponding feature nodes  in their respective pc diagrams  When needed  the probability values are filled in by inheriting them from  transient state     Probabilistic Conceptual Network              Model Construction Constructing Categorization Decision Models  Figure    The categorization decision model  Figure    The categorization prob  influence diagram We shall illustrate how a categorization decision model may be constructed from the pc net for the automated machining problem  In this application  the prefer ence model may be expressed in the form v Ak  C   where Ak is an action that may be taken  like for ex ample   reducing cutting speed    reducing depth of cut   etc  C  is any state of the machining operation we have described earlier  v Ak  C   gives the utility of the outcome by taking action Ak when the state of the machining operation is C   Suppose the sensors report information on  AE mag    AE rms    dyn rms x    dyn rms y   and  rms current   and  our utility based categorical rea soner described earlier  determines that the most ap propriate level of abstraction corresponds to the set of concepts comprising  tool chatter    tool wear    tool breakage    sensor failure  and  transient state   We can combine the respective pc diagrams for these five concepts to construct a categorization probabilistic in fluence diagram as shown in Figure    The graphical structure of the combined categorization influence di agram is obtained by performing graphical union of the individual pc diagrams while treating each central concept node as being the same node in each of the individual pc diagrams  Notice that the concept node in the constructed diagram is now a probabilistic vari able  C  ranging over the five concepts used in its con struction  The conditional probabilities for each of the feature nodes in the constructed diagram is obtain by copying over their respective original values in the in dividual pc diagrams  That is  for any feature F  p FIC   C  B  F     p F IC  B  F       where Bg  F  is the set conditional predecessors of F excluding C  in the constructed diagram  The next step in the construction procedure is to com plete the diagram by turning it into a categorization decision model as shown in Figure    This is done by first  adding the decision and value node to reflect  the preference model described earlier  Next  infor mational arcs from the observed feature nodes to the decision node are added  The completed categoriza tion influence diagram can now be solved using exist ing methods  Shachter              Validity of the Constructions  An important characteristic of our decision model con struction procedure is that the final model so con structed must reflect as accurately as possible the state of information originally asserted by the knowledge base and preference model  Our knowledge base con tains assertions about concepts  their properties  and the probabilistic relationships among them  Validity of a probabilistic model construction depends on the soundness of the construction procedure  Heckerman        suggests that soundness should be character ized by the preservation of the joint distribution of the variables involved across the construction  For pc net  it can be shown that if the pc diagrams in a given con ceptual cover are mutually consistent  then the con struction is indeed sound  Poh                Related Work Probabilistic Similarity Networks  Probabilistic similarity network  Heckerman        is a knowledge engineering tool for building probabilistic influence diagrams  We shall briefly describe the sim ilarities and differences between pc net and similarity network here  A more comprehensive comparison is available in  Poh         Both pc net and similarity networks are capable of building the same type of influ ence diagrams  but pc net is able to do so at varying levels of abstraction  whereas similarity network can only do so at one level  Another major difference is that pc net is capable of representing categorical ab straction relations whereas similarity networks can t  Another difference is that the probabilities in a pc net are assessed before categorical reasoning and model        Poh and Fehling  construction take place whereas in similarity networks  all the knowledge maps are initially unassessed and are carried out only after the global knowledge map has been built  Both pc net and similarity network use some sort of local influence diagrams for concept representation  However  a local knowledge map in similarity network is built based on a pair of concepts  There are also differences between a pc diagram and a hypothesis specific knowledge map  hs map  in similarity net works  First  the concept node is included in the pc diagram  whereas  it is not part of the hs map  Second  a pc diagram is always a connected graph whereas a hs map may not be  Finally  a pc diagram has its probabilities initially assessed whereas  a hs map is not  The notion of subconcept independence in a pc net is analogous to subset independence used in conjunc tion with partitions in similarity networks  Similarity networks use partitions to speed up assessment while pc net saves assessments and storage by using inheri tance mechanisms based on subconcept independence  In pc net terms  a partition for a feature in similarity network can be viewed as an an abstracted concept subsuming all the concepts in the partition  Further more  that feature is subconcept independent of the abstracted concepts  Assessing the probability distri bution for the feature given the abstracted concept and applying inheritance is equivalent to assessing the probabilities within the partition       Knowledge Based Model Construction Methods  Several approaches have been proposed for construc tion or building of influence diagrams  There ap proaches may be classified under two highly contrast ing methodologies  The first  known as the synthetic approach   Horvitz        starts with the empty influ ence diagram  nodes and arcs are added to the model through some methods of inference based on simple rules or relationships  These inferences are usually driven by assertions about the world  goals  or utility  Holtzman        Breese        Goldman   Charniak        Wellman         These approaches however  usually do not have principled control over the degree of abstraction or details in the model that they are building other than using some heuristics  The second  known as the reduction approach   Horvitz        seeks to custom tailor comprehensive  intractable decision problems to specific challenges at run time through a pruning procedure that removes irrelevant distinctions and dependencies  Heckerman   Horvitz         The decision model construction approach based on probabilistic conceptual networks developed in our re search does not commit to either of these two contrast ing approaches  but instead  employs mixed strategies  The approach can be seen as synthetic to some ex tent in that it builds an influence diagram dynami   cally at runtime  However  unlike the pure synthetic approaches  the building blocks used by this approach are not individual nodes and arcs  but rather modules of localized influence diagrams  On the other hand  the approach can be seen to be reducible in that mod ules of local influence diagram have been pre assessed  However  instead of pre assessing a comprehensive in fluence diagram  pc net does not commit to one large influence diagram  but instead  is a comprehensive net works of related local probabilistic influence diagrams  The approach here allows for reasoning about the re lationship among these local influence diagrams  and combines only those that are relevant or are required while discarding those not required in the decision model it is building  The advantage of our approach over that of the com prehensive model reduction approach  is that assess ing smaller and more focused local pc diagrams is usu ally easier and more manageable as compared with at tempting to assess a huge comprehensive influence di agram  This local to global approach to constructing large probabilistic influence diagrams has been demon strated with similarity networks  The advantage of this approach over that of the com plete synthetic approach is that the construction pro cedure is controlled using well founded principles of decision theory  We use a principled approach to rea son about the values of constructing different parts of the model  The model being built can be custom tailored to the optimal level of abstraction and avoid any unnecessary details  This is very important when we consider computational or resource constraints     Conclusion  Previous work on integrating uncertainty   and cate gorical knowledge representation has been done with a broad range of emphases and purposes  Saffiotti        proposed a general framework for integrating categorical and uncertainty knowledge  In particu lar  Shastri        proposed a semantic network like representation language for evidential reasoning using the principle of maximum entropy  Similarly  Lin and Goebel        proposed a graphical scheme integrat ing probabilistic  causal and taxonomic knowledge for abductive diagnostic reasoning  This latter formalism has two types of links  namely  is a  and  causal   In classifier based reasoning  term subsumption lan guages are being extended to accommodate plausible inferences  Yen   Bonisson         More recently  Leong        proposed a network formalism using var ious kinds of links including  a kind of   temporal precedence  qualitative probabilistic influence  Well man        and property relations    Context      Many of these formalisms have desirable features that we need  but none has all  Finally  by combining the formalisms of influence dia grams and abstraction hierarchies  pc nets effectively   Probabilistic Conceptual Network  represent both categorical knowledge relations and uncertainty in a modular and compact way  It can also support dynamic construction of a specific class of decision model at varying levels of abstraction  We have also demonstrated the applicability of pc net to real world applications in automated machining  Acknowledgements  We wish to thank Ross Shachter  Eric Horvitz and the anonymous referees for their helpful comments and suggestions on the content of this paper  Reference  Agogino  A  M     Ramamurthi  K          Real time influence diagrams for monitoring and controling mechanical systems  In Oliver  R  M     Smith  J  Q   Eds    Influence Diagrams  Belief Nets and Decision Analysis  pp           John Wiley  Knowledge Representation and Inference in Intelligent Decision Systems  Ph D   Breese  J  S           thesis  Department of EES  Stanford University  Fehling  M  R     Breese  J  S          A compu tational model for decision theoretic control of problem solving under uncertainty  Technical Memo           Rockwell International Science Center  Palo Alto Laboratory  Palo Alto  CA  Goldman  R  P     Charniak  E          Dynamic con struction of belief networks  In Proceedings of the  th Conference on Uncertainty in Artificial In telligence  pp          Beckerman  D  E          works  MIT Press   Probabilistic Similarity Net  Beckerman  D  E     Horvitz  E  J          Problem formulation as the reduction of a decision model  In Bonissone  P  P   Henrion  M   Kana   L  N     Lemmer  J  F   Eds    Uncertainty in Artificial Intelligence    pp           Elsevier Science  Holtzman  S          Addison Wesley   Intelligent Decision Systems   Horvitz  E  J          Reasoning about beliefs and ac tions under computational resource constraints  In Proceedings of th  Third Workshop on Uncer tainty in Artificial Intelligence  pp           Computation and action under bounded resources  Ph D  thesis  Depts of Com  Horvitz  E  J           puter Science and Medicine  Stanford University  Horvitz  E  J          Problem formulation and deci sions under scarce resources  In Working Notes of the AAAI Workshop on Knowledge Based Con struction of Decision Models   Horvitz  E  J   Beckerman  D  E   Ng  K  C     Nath wani  B  N          Heuristic abstraction in the decision theoretic pathfinder system  Report KSL        Stanford University        Horvtiz  E  J     Klein  A  C          Utility based ab straction for categorization  Technical Memoran dum     Rockwell International Science Center  Palo Alto Laboratory  Howard  R  A     Matheson  J  E          Influence diagrams  In Howard  R  A     Matheson  J  E   Eds    Readings on the principles and applica tions of decision analysis  Vol     pp                 SDG  Menlo Park  California  Lehmann  F   Ed            Semantic Networks in Ar tificial Intelligence  Pergamon Press  Leong  T  Y          Representing context sensitive knowledge in a network formalism  A prelimary report  In Proceedings of the Eighth Confer ence on Uncertainty in Artificial Intelligence  pp           Lin  D     Goebel  R          Integrating probabilistic  taxonomic and causal knowledge in abductive di agnosis  In Proceedings of the  th Conference on Uncertainty in Artificial Intelligence  pp         Pearl  J          Probablistic Reasoning in Intelligent Systems  Networks of Plausible Inference  Mor gan Kaufmann Publishers  San Mateo  CA  Poh  K  L          Utility based categorization  PhD dissertation draft  Department of Engineering Economic Systems  Stanford University  Poh  K  L     Horvitz  E  J          Reasoning about the value of decision model refinement  methods and applications  This volume  Russell  S     Wefald  E          Principles of metar easoning  Artificial Intelligence               Saffiotti  A          A hybrid framework for represent ing uncertain knowledge  In AAAI     Proceed ings of the Eight National Conference on Artifi cial Intelligence  pp            Shachter  R  D          Evaluating influence diagrams  Operations Research                  Shastri  L          Evidential reasoning in semantic networks  A formal theory and its parallel im plementation  Ph D  thesis  Department of Com  puter Science  University of Rochester  Smith  E  E     Medin  D  L          Categories and Concepts  Harvard University Press  Wellman  M  P          Formulation of tradeoffs in planning under uncertainty  Ph D  thesis  Dept of EECS  MIT   Yen  J      Bonisson  P  P          Extending term sub sumption systems for uncertainty management  In Proceedings of the  th Conference on Uncer tainty in Artificial Intelligence  pp              
  information and the uncertainties introduced by the potential actions of other agents   When agents devise plans for execution in the real world  they face two important forms of uncertainty  they can never have complete knowledge about the state of the world  and they do not have complete control  as the effects of their actions are uncertain  While most classical planning methods avoid explicit uncertainty reasoning  we believe that uncertainty should be explicitly represented and reasoned about  We develop a probabilistic representation for states and actions  based on belief networks  We define conditional belief nets  CBNs  to capture the probabilistic dependency of the effects of an action upon the state of the world  We also use a CBN to represent the intrinsic relationships among entities in the environment  which persist from state to state  We present a simple projection algorithm to construct the belief network of the state succeeding an action  using the environment CBN model to infer indirect effects  We discuss how the qualitative aspects of belief networks and CBNs make them appropriate for the various stages of the problem solving process  from model construction to the design of planning algorithms      INTRODUCTION  Real world planning poses special challenges which early planning systems did not fully confront  Typically  the domain models upon which real world planners rely reflect incomplete and inaccurate understanding of the domain s ontology  the objects and events used to describe domain states  and its dynamics  the underlying principles that define object event relationships in the domain  Due to such inherent limitations of scope and accuracy  real world planners must cope with substantive uncertainty as they reason about actions and formulate plans  These planners must deal adequately with uncertainty about past  present  and future states of the world including uncertainty about the occurrence of particular events in the domain  These challenges are exacerbated by the reliance on imperfect sensor  Early planning systems  e g   S RIPS  Fikes and Nilsson        and NOAH  Sacerdoti        presumed availability of a complete  accurate domain representation and  consequently  produced plans that would readily fail as a result of inadequacies in the domain model  As planning researchers began to address the challenges of uncertainty several approaches emerged  including replanning  Wilkins         interleaved planning and execution  McDermott        Georgeff and Lansky         reactive planning  Brooks        Kae bling        Schoppers         and conditional planning  Warren        Peot and Smith         These approaches reduce the negative impact of uncertainty on the quality of plans  but none represents and reasons about uncertainty explicitly  So far  several attempts have been made to integrate uncertainty representation and reasoning techniques into planning  Markov chains are used by Christiansen and Goldberg         and by Dean et al         to depict a sequence of possible actions  Kanazawa and Dean        use influence diagrams similarly to Markov chains  without exploiting their structure  Several efforts focus on the design of specialized projection algorithms  e g   Dean and Kanazawa        Hanks        Drummond and Bresina         Recently  some probabilistic and decision theoretic systems have been implemented  Kushmerick et al        Goldman and Boddy        Haddawy and Suwandi         Most of these approaches represent uncertainty probabilistically  However  Wellman      a  uses qualitative probabilistic networks  while Chrisman        rejects Bayesian probability in favor of Belief Functions  Some of these probabilistic approaches contrast strongly with the more classical AI approaches  While it is agreed that transition matrices provide a complete representation for actions  effects and readily support probabilistic temporal projection  this representation poses extreme challenges  On the practical side  a daunting amount of assessment may be needed to construct a complete Markov transition matrix  and inference with matrices cannot easily support queries about specific properties of states  Perhaps more importantly  it remains unclear how         A Structured  Probabilistic Representation of Action  if at all  matrices can be incorporated into anything like conventional planning techniques  In contrast  our approach to planning under uncertainty aims to incorporate a suitable treatment of uncertainty within a more conventional overall planning process  As a first step in this research we have focused on the representation of actions as operators that probabilistically  transform states by specifying probabilistic relationships among their descriptive elements  framework on belief networks  Pearl   We build our        and a variant  thereof to represent conditional probability distributions  Contrary to the probabilistic planners mentioned above  we do not make the  STRIPS assumption that anything that  is not explicitly part of the action s model remains unchanged  In this respect  our work may be compared to  recent research on action representation in belief networks  Goldszmidt and Darwiche         Pearl          We  propose a simple projection algorithm that uses graphic  operations to construct the probabilistic model that represents action  the direct and indirect effects of an action  Our  representation  combines  qualitative  and  quantitative description in order to support reasoning under uncertainty in the context of more conventional qualitative methods for reasoning about action      simply states  by belief networks  Pearl         which  depict the factorization of a joint probability distribution in a graphical manner   P D  be a joint probability distribution D  Let G be a directed acyclic graph  D  R   where D is a set of nodes that correspond to the distinctions   and R is a set of directed arcs  Let  dJo    dn  be a node ordering consistent with G  i e   if  Definition     Let  over a set of distinctions   d d E R then i   j  Let  t d  be the set of parents of node  dinG   t d    ceDI  c  d ER    Then  we say that G is a b elief network for P if for every node d ED  P d  I dl      d     P d  l t d     and no arc can be removed from G without violating this factorization  W often attach the conditional probability distribution P d   t d     to the node d  and view the network as representing P     f  Definition     A state  ofthe world W is a specification of  the values of all the distinctions of interest at a snapshot  Pw D  is state model if it reflects the uncertain beliefs of an agent about W  We often use the corresponding belief network as a model for W  of the real world  A joint probability distribution  a  The belief network in figure   shows that the robot has some prior information about possible size and location of the object  and believes that object weight is related to  MODELING WORLD STATES  size    I e   information about one of these features  The following example will motivate our presentation of  provides information about the other    this research  a robot is secretly attempting to fetch an  these features are independent of  provide no information  However  both  object from a room in the WhiteWaterGate office  about  the object s location   building  The robot must avoid detection  It has a partial  independent sensor sources light  sound  and motion   description of the object  including its location  size and  The robot believes that the value of each of these is  weight  Upon locating the object  the robot is now reasoning about picking it up  but since it must  chance of being discovered by a guard is believed to be  accomplish the task wiUJ out being detected  it also must  related to the alarm activation   assess the possibility of activating an alarm   The alarm has three  probabilistically related to the alarm activation  Also  the  Thus  the  appropriateness of the pickup action depends upon the   obi   v  robot s model of the state of the world when the action is attempted  and its model of how the action  if undertaken  might affect critical distinctions  in that state  Since the robot is uncertain about most aspects of the environment  and  the  exact  effects  probabilistic representation is called for   of actions   a  One possible  approach would be to model the robot s situation as a probability distribution over all the possible states  with a conditional probability distribution for the states that may result from executing the action   An action is  thus   represented by a state transition probability matrix  However  this representation technique hides important qualitative information about relationships in the domain that may be important to planning  A representation that  Figure  provides explicit information about independence and conditional independence among distinctions in the model can make descriptions more compact and expressive while helping to improve efficiency of inference algorithms   We  therefore  represent world states  or    A distinction is a predicate or a random variable describing some  property of the task domain      A World State  Several aspects of belief networks deserve mention  Fust   the most important qualitative information conveyed by belief networks lies in the arcs that are missing  i e   in the   For this discussion  we need no distinguish between a node in the graph and  the model distinction it represents         Davidson and Fehling  independen ce assertions  In figure    one can readily see the independence of object location from all other  distinctions and the independence among the alarm  and   sensors  This can be seen without examining quantitative information about the joint distribution through the graphical criterion of Second  arcs do  d separation  Geiger et al          not necessarily imply causality  Some  arcs may be reversed without affecting the rest of the network  e g   between object size and weight   In fact   any arc can be reversed  with possible modifications to the rest of the network  Shachter         Third  a node may be a deterministic function of its predecessors  e g   the alarm is activated if  and only if at least one sensor is on   but generally  a node remains probabilistic even if predecessor values are known  e g   the robot may not be discovered even if the alarm is activated      eff A  is independent of P qual A  given qual A  and the fact that A was performed S ejj A  and P qual A  are independent of A given qual A  and eff A    The last requirement says that given qual A  and eff A   knowledge that A was performed does not convey any  additional information about any distinction in the model   Note that even if we have the full transition matrix  or the conditional probability distribution  that  A  we cannot derive qual A  and eff A  directly  as our ability to distinguish the execution of action A depends on the other possible actions that could have been performed  Thus  qual A  and eff A  corresponds to action  need to be specified by the domain expert  Once they are specified     REPRESENTING ACTIONS  P eff A  I qual A   can be considered as the  compact model of the action   World state models describe relationships within a specific state  We now model actions taking the standard  view of actions as transitions between consecutive states  Thus  given the state of the world preceding the action  an action model defines probabilistic constraints on the state succeeding the action  In other words  an action could be described by a conditional probability distribution for the state succeeding the action given t  e state preceding the action  We do not wish  however  to require that every action be specified by a full probability matrix  for  reasons stated above  We seek a compact representation that states only the intrinsic properties of an action  Before presenting the formal definition  consider the action of our robot picking up the object  The robot is uncertain whether the object will end up in its g rasp  Thus  one probabilistic effect of the action is object location the object may remain in t  e same location  if it is too heavy to lift  say   the object may fall to the floor  if its size makes it awkward to carry to the loading bay   or   hopefully  the object s new location may indeed be tile robot s bay  Another uncertain effect is the activation of the alarm by triggering one of the sensors   eff A   are defined to be the minimal sets of  distinctions such that   Thus  some  distinctions in the model qualify the effects of the action   Definition and  P E I Q  be a conditional probability P is a nwdel for action A if Q qual A      Let  distribution  Then  E eff A    As actions are defined in terms of conditional probability distributions  and in light of our emphasis on qualitative representation  we now define a variant of a belief network a  conditional belief net  CBN  to graphically  display a conditional distribution   Let P E I Q  be a conditional probability E given Q  where Q and E are disjoint sets of distinctions   Let B be a directed acyclic graph  Q  E R   where QuE is a set of nodes and Rb  Qu  xE is a set of directed arcs  Let  Q  e      en  be a node ordering consistent with B and let  t e  be the set of parents of node e in B  We say that B is a conditional belief network   CBN  for P E I Q  if for every node e EE  P e  I Q eJ      e       P e    t e     and no arc can be removed from B without violating this factorization   Definition     distribution of     Note that the order of the nodes in Q is irrelevant as there are no arcs going into nodes in  Q  For these nodes  only  their list of possible values needs to be specified  Since a  set of the directly affected distinctions in tile succeeding  R  does not specify a probability distribution Q  we often term Q as the set of free distinctions of the CBN  while tile set E is the set of bou n d distinctions  as they are constrained by a  the definition below  In the sequel we omit the model  A model of tile pickup action is given in figure    The  while other distinctions are affected by the action  So  for  M of action A  we denote the set of qualifying distinctions in the state preceding A by qualM A   and the  any model  state by effu A   The notion of direct effects is captured by designation M unless we discuss different models for tile same action   for the nodes in  probability distribution   nodes surrounded by a rounded rectangle represent tile affected distinctions in tile succeeding state   The following definition for qual A  and ef  f A  express our intent that these sets are tile minimal ones required for an adequate representation of  CBN  Q  E   A  The requirements we  impose on these sets are in line with Wellman s characterization of probabilistic actions              Let P and S be the sets of distinctions tllat correspond to the states that precede and succeed an  A special  node marks the action s name  with an outgoing arc into the effects  Although this extra node is redundant  it will prove useful in representing the combined effects of simultaneous actions and for the construction of decision models for sequences of actions   Definition  action  respectively   Then  for every action  A  qual A QJ   Moreover   qual A  and eff A  render A independent of any distinction  in the past or in the future    A Structured  Probabilistic Re presentation of Action  How should we interpret figure    affected by the action   Object location is  Its value in the succeeding state  designated as  the Environment Model        While these  relations are not changed by any action the agent may  depends  probabilistically  on its location before the  take  they may change in particular states due to  action and on the object s size and weight  The model  observ ations  Thus  if the agent hears the alarm in a  relates the status of the sound sensor after the action to its status before the action  if it was on  it will probably  status of its sensors in that state   remain on   and to the object location after the action  since if it falls to the floor  it makes noise   Note that the alarm activation is not specified as a possible effect of the action   It was not judged to be a direct ef fect of the  action   certain state  it is no longer probabilistically related to the    Let  D be the set of distinctions in terms of Let  F H  be a partition of D  D FuH  FnH   such that the set of probabilistic relationships P H I F  is believed to hold in every state  The cond itional distribu tion P  H I F   and its corresponding CBN  are called the Environment Model   Definition  which states are described   The set of the free distinctions  F is not constrained by the E  Environment Model  The bound distinctions in the set  are constrained to the same distribution in every state  unless observations are available   Figure   displays the Environment Model for the robot s example  The free distinctions  for which no probabilistic information is specified  are the object location and the three sensors   The distribution of all other distinctions   the bound distinctions in the rounded rectangle  is believed to be the same in all states   qual A   eff A   Figure    An Action Model     THE ENVIRONMENT MODEL  A belief network represents the relationships between distinctions within a particular state  Effective reasoning about action requires that we understand and represent state  These relationships are inherent in the environment  Figure  or the system we model  and we can use them to achieve goals   e g   to induce rain we can seed clouds   and to  avoid undesirable side effects  e g   if we make noise  we  bound  free  contingent relationships that extend beyond any specific     The Environment Model  The Environment Model can be transformed into a world state model by adding a probability distribution for the  might trigger the sound sensor    nodes in  The knowledge that characterizes invariant relationships in an uncertain system or environment is best described  network  from which we can derive the marginal  F   This transforms the CBN into a belief  probability of every distinction of interest  We can draw  and a set of  by conditional probability distributions  in much the same  an analogy between the Environment Model  way that dynamic systems are described by differential equations   These conditional relations are contingent  free distinctions correspond to the boundary conditions of  differential equations that defines a physical system  The  upon inputs whose distribution may not be known at modeling time  For example  we do not know the status of the sound sensor in general  but we may know the  the system  whose specification permits one to calculate  conditional probability of alarm status given sensors      status  and this conditional relation holds for every possible state of the world  We collect all the relationships that are expected to hold in every state into a conditional probability distribution   the entire behavior of the system   STATE PROJECTION  Temporal projection is about inferring the state of the world after an action is taken  We now present a projection  algorithm  representations   exploiting  our  CBN  based        Davidson and Fehling  The state that succeeds an action depends  in general  on the preceding state and on the action s model  algorithm below  constructs  The  a belief network that  combines bo th the preceding and the succeeding states  and the relations between them   The model of the  succeeding state can then be extracted from the combined network   the preceding state as depicted by figure    and the action model in figure    The nodes in E  the direct effects  object location  sound sensor and motion sensor  are added to the network of the preceding state  with their incoming arcs  These nodes are distinguished by the rounded rectangle  while all the succeeding state nodes  are annotated by s under their label  In the next step  the nodes in  Algorithm Project State lnJ uU  A belief network G p over D representing the preceding state and a CBN B over QuE that represents an action A Qmwtl  A belief network Gp s over DuE representing the  K  the indirect effects  alarm  guard  are added  to the succeeding state   with  their incoming arcs  originating from succeeding state nodes  if possible   For  example  the alarm node has two incoming arcs from new  nodes  but the arc from the light sensor node comes from the preceding state   relations between the preceding and the succeeding states  and a belief network  G s over D representing the  succeeding state     Initialize Gps to the network Gp of the preceding state   Gps by the CBN B in the following way  B  with the nodes with the same label in Gps       Augment A  B   Coincide the free nodes Q  in Add the bound nodes E to nodes   Gps as succeeding state  These nodes inherit their probabilistic  information  their incoming arcs  from B  C   Let  F be the distinctions in Gp that correspond to E   i e   the distinctions in the preceding state that are affected by the action    Let K be the set of descendents of  F in Gp   K u des    feF     F  where  de s j  are nodes to which there exists a directed path in Gp fromf  The nodes inK are duplicated  o that a new opy of these nodes is added to Gps m the succeedmg state  The new nodes carry their  probabilistic information  their incoming arcs  from the preceding state in  G ps   Whenever  possible  these arcs originate from a new copy of a node  i e   from the succeeding state      Gs can constructed from G p s  by computationally  removing the setFuK of nodes from the preceding state of  Gps   The resulting belief network Gs represents the  Figure  succeeding state   A node is computationally removed  step algorithm   Shachter   following  the  procedure    in the  described  in         The procedure essentially averages out  a node  so that the distribution of its children is properly     State Projection  Note that the nodes in D F K are not affected by the action and are not copied into the succeeding state  We could  of course  copy them as deterministic identity functions of their value in the preceding node   updated  For most purposes  it is advised not to perform step    and use the combined network Gps for inference   We can project the succeeding state from the combined  other words  if the purpose of projection is to construct a  in the preceding state  The node removal algorithm  Shachter        assures that the probability distribution  so as not to lose relevance information across states  In  probabilistic model that corresponds to a sequence of    should not be performed   In this case  step   C requires that new arcs originate from the most recent actions  step  copy of a node   If  however  the purpose of projection is to calculate the marginal probabilities for the distinctions in the succeeding state  step    is necessary   F iure   depicts the combined network for the pickup actiOn of our robot example  The input to the algorithm is  network by computationally removing all the nodes  FuK  of the remaining nodes is consistent with the agent s  beliefs  Figure   depicts the succeeding state network Gs  We can now ignore  the annotation by  s  since the network  includes exactly all the distinctions in D of the succeeding state         A Structured  Probabilistic Representation of Action  these are the relations that persist from state to state  unlike the other relations in a state which are purely ad hoc  We modify slightly the projection algorithm from the previous section to rely on the Environment Model to derive the indirect effects of an action  instead of on the network of the preceding state   The modified algorithm accepts as input the Environment Model V too  and it differs only in the method of identifying and deducing the indirect effects  Algorithm Project State  modified     nl m add the Environment Model Vto the original inputs Performsteps l   B as in the original algorithm  Figure    The Projected State     PROJECTING STATES CORRECTLY  Note that the network in figure   t  he succeeding state  has a different structure from the one in figure    the preceding state   In particular  object size became probabilistically relevant to object location and motion sensor and similarly information about the sound sensor is relevant to object location  Thus the action introduced in formational relationships between entities in the domain  There is a potential problem with our very flexible approach  S uppose next  our robot performs an action that directly affectsthe size ofthe object e    g  cutting it into half   Our projection algorithm would infer an indirect effect on both the object location and the motion sensor  Similarly the robot may now have a silent way to move the object so a subsequent change in object location need not necessarily have the status of the soundsensor as an indirect effect  The main point here is that these informational relations that are introduced by the action do not necessarily persist from one state to another  fI a subsequent action affects a distinction dthat is associated with another distinction e  the new value ds in the succeeding state need not be related  toe ores   In general the algorithm as outlined above is sensitive to the direction of the arcs in h t e network of the preceding state  Since every arc can be reversed employing the graphical equivalent ofBayes  rule S   hachter        our projection algorithm may yield different results given different graphical representations of the preceding state  These difficulties should not come as asurprise  As Pearl       notes   While a   probability distribution  tells us everything about responding to new observations it tells us close to nothing about responding to external actions   p        Thus the model of the preceding statecannot be sufficient  Additional assumptions must be made  To resolve the problem we tumback to the Environment Model  Recall that the Environment Model representsthe probabilistic relations that are believed to hold in every world state  These are the only relations that we must guarantee to hold in the succeeding state  n I other words     C   Let F bethe distinctions in Vthat correspond to E i   e  the distinctions in the Environment Modelthat are directly affected by the action   Let Kbe the set of descendents of  Fin  u des J   F   eF  V  K   where des j  are nodes to which there exists a directed path in V from f  The nodes in K are duplicated  so that a new copy of these nodes is added to Gpsin the succeeding state  The new nodes carry h t eir probabilistic information  their incoming arcs  from the V  These arcs originate from the most recent copy of a node  As before  nodes can be removed to derive a network that represent the succeeding state solely   belief  For the robot s example above the combined network for the pickup action would be the same with the modified algorithm  with the Environment Model in figure  as an additional input  as it was with the original algorithm  That is  the modified algorithm projects the same succeeding state as in figure    However if a subsequent action changes the location of the object independent of the sensors  the modified algorithm would not infer the sound sensor  and the rest of the alarm system  as indirect effects  They would retain their values from the preceding state  Without imposing any restriction on action models  a potential conflict might arise between the direct effectsof actions and relations in the Environment Model  fI a bound distinction ein Vis a direct effect of an action A  i e  if  eeefj A   then itis not clear whether eshould  be  defined in the succeeding state as in the action model or as in the Environment Model  a s we assumed that eis bound to the distribution in Vin all states   We gave absolute priority to the action model in the projection algorithm but this is an arbitrary decision  As we discuss in section   we believe thatsuch a conflict is a result of poor modeling and we therefore introduce the following restriction on action models      A model M for action A is said to be compatible with the Environment Model Vif the direct  Definition  effects  e f M A  arerestricted to the free distinctions of  V         Davidson and Fehling  From now on  we assume that all action models are compatible with the Environment Model   It is not  difficult to verify to that with this restriction on actions  the modified projection algorithm preserves consistency of state models with the Environment Model   Definition    A state model W is consistent with the Environment Model V if for every bound distinction h in V  Pv h I Trv h   Pw h l  rv h    where  rv h  is the set of parents of h in V     Proposition     If the model of the preceding state is  consistent with the Environment Model V  and the action  set included non direct effects as part of the action model  i e   if a modeler fails to distinguish the genuine direct effects from those that result from relationships in the environment  Compatible models can never be equivalent  every preceding state  as any free distinction not in ef f M A  persists when M is used for projection  for  The compatibility restriction is useful beyond avoiding conflicts between action models and the Environment Model  and promoting uniqueness of effects   following way  if a need arises to model a bound distinction  h as an effect  the Environment Model V is not h  For  model is compatible with V  then the model of the  complete  since it ignores a possible way to affect  succeeding state  as derived by the modified projection  example  if V specifies  algorithm  is consistent with V too    a way to affect  Note that the original projection algorithm satisfies this proposition as well  This is to say that proper projection cannot be judged only by the consistency of the resulting state with the relations in the Environment Model  Rather  it is the appropriate handling of the distribution of the free distinctions that makes the difference   correctness of the projection algorithm  We can only  verify that the projection procedure is consistent with the assumptions we make  proposition  grass  Pv grass I rain   and we identify   e g   by turning the sprinkler on    we conclude the V is incomplete as it neglects the  s p r   n k   e r on grass  Pv grass I raln sprlnkler    influence of specify  Instead  V  should  In general  the sets qualA  are not unique  For example   h  then any M with hEqualM A  has an equivalent model M  with Trv h   h EqualM A   If  however  all distributions are strictly positive  the intersection property  Pearl        p      can be used to define a minimal unique qualifiers set qual A    if V contains a deterministic bound distinction model  Note that we are unable to assert an objective criterion for the  It also  facilitates modeling  knowledge acquisition  in the      argue for the  reasonability of these assumptions and test them   Our primary assumption is that there are probabilistic relations between entities in the real world that are  expected to hold in every state  unless modified by an observation of one of the relevant entities   Moreover  we assume that all other probabilistic relations are just informational relationships that hold only for specific entities at the specific time when they are asserted      SUMMARY AND DISCUSSION  We have presented a scheme for modeling the states of the world and the effects of actions in a probabilistic  fashion  We use belief networks to represent world states  and  conditional belief nets to represent actions and  environmental contingencies  Our representation scheme enjoys the advantages of qualitative modeling and the  The persistent relationships in the Environment Model are  precision of quantitative models   The representation          supports efficient projection and prepares for intelligent  have a causal meaning  This strong assumption is made  of states  The framework is flexible  and can be extended  reminiscent  of course  of causal networks  Pearl   These are belief networks in which all arcs are asswned to by  Pearl         and  Goldszmidt and Darwiche        to  permit reasoning about action and change within the framework of belief networks  Indeed  as Druzdzel and Simon         note   The effect of a structural change in a  system cannot be induced from a model that does not  contain causal information   p      We delay to a forthcoming paper the discussion of the causal interpretation of our Environment Model  as well as a comparison to the contemporary works mentioned above and that of Heckerman and Shachter              PROPERTIES OF ACTION MODELS  We now briefly discuss the restriction we imposed on actions to affect only free distinctions in the Environment Model   and the uniqueness properties that result   Without the compatibility restriction  an action have models with different effects sets  A could  effM A  that would  be projection wise equivalent  they would result in the same succeeding state  This would happen if some effects  planning by emphasizing the properties and the structure in several ways  Davidson  Our  work is          influenced  by  the  classical  action  representation schemes such as STRIPS  Fikes and Nilsson        and the situation calculus  McCarthy and Hayes         Like STRIPS  our action models depict the  relationships among preconditions and effects  though we  relate them probabilistically   STRIPS suffers from the  need to explicitly specify the truth value of all formulas  that could possibly be affected by an operator  Attempts  to eliminate the problem  Wilkins        allow a set of basic formulas to appear in add delete lists  from which all other formulas are calculated   Our approach is similar   action models may affect only the free distinctions in the  environment  while all other distinctions are conditioned upon the free ones  and cannot be affected directly   Any scheme similar to the situation calculus suffers from the frame problem   Our solution to the extended  prediction problem is similar to STRIPS   we assume persistence of whatever is not affected  but we handle   A Structured  Probabilistic Representation of Action       indirect effects  Moreover  our framework addresses the qualification problem by acknowledging that a model can never exhaust the qualifying distinctions in the real world   Goldman  R  P   and M S  Boddy       Epsilon safe planning  In Proc  lOth Conf Uncertainty in AI  Seattle  WA   and therefore  all effects are probabilistic   Goldszmidt  M   and A  Darwiche       Action networks  A framework for reasoning about actions and change under uncertainty  In Proc  lOth Conf Uncertainty in  Our work on this scheme continues  We believe that the framework will prove appropriate for decision theoretic planning  whereby maximum expected value is the criterion for the optimality of plans  We are now at work to introduce levels of abstraction into this representation scheme  and to devise a hierarchical planning algorithm for this approach  Acknowledgments  We wish to thank Ross Shachter and Eric Johnson for useful discussions  Bill Poland for reviewing an earlier draft  and the anonymous referees for their comments  The remaining errors are solely ours  of course  Work reported here was supported by funds from grant no  N                from the Office of Naval Research   
 This paper describes some results of research on associate systems  knowledge based systems that flexibly and adaptively support their human users in carrying out complex  time dependent problem solving tasks under uncertainty  Based on principles derived from decision theo ry and decision analysis  a problem solving approach is presented which can overcome many of the limitations of traditional expert systems  This approach implements an explicit model of the human user s problem solving capabilities as an integral element in the overall problem solving architecture  This integrated model  represented as an influence diagram  is the basis for achieving adaptive task sharing behavior between the associate system and the human user  This associate system model has been applied toward ongoing research on a Mars Rover Manager s Associate  MRMA   MRMA s role would be to manage a small fleet of robotic rovers on the Martian surface  The paper describes results for a specific scenario where MRMA examines the benefits and costs of consulting human experts on Earth to assist a Mars rover with a complex resource management decision      Introduction  This paper describes some results of research on associate systems  knowledge based systems that manage their own task performance to flexibly and adaptively support their human users in carrying out complex  time dependent problem solving tasks under uncertainty  Our efforts to develop such systems focus on the development of problem solving methods based on well founded principles of time bounded rationality  Fehling   Breese        Horvitz        Russell   Wefald         The principles which underlie the approach we shall describe are derived from decision theory and decision analysis  Raiffa        Howard   Matheson         We believe that this principled approach to problem solving can overcome many of the limitations of traditional expert system  approaches  particularly in applications where the system must flexibly and cooperatively share task performance with human users  Conventional expert system approaches suffer from some critical shortcomings in providing adaptive and cooperative support to their users  For the most part  conventional knowledge systems  especially so called rule based systems  support their users with problem solving expertise that is encoded in the form of fixed problem representations and solution methods  The support provided by such systems breaks down in situations that are not sufficiently represented  or when the solution methods do not match the style or perspective of the user  In addition  knowledge systems are designed with a fixed commitment to the role played   i e   the tasks performed by the expert system  there is no ability to cooperatively adapt the actions of the support system to the situation specific needs of its user  Furthermore  conventional systems suffer from an inability to adapt to the concerns of a user to the extent that these concerns diverge from those of the expert whose knowledge is encapsulated  The source of these shortcomings in conventional knowledge systems is the failure to recognize the context sensitive needs and objectives of the human user  The user may require any range of support  from an analytical tool to a domain tutor  but it is the user s preferences which should drive the system s actions in providing that support  We refer to this type of system as an associate  one which acts flexibly  adaptively  and cooperatively in support of human problem solving in performing complex  time dependent tasks under uncertainty  Our focus in this paper is on the management of task sharing between the human user and an associate system  We will illustrate how a decision analytic framework for problem solving in an associate system provides the mechanism for adaptive task sharing under uncertainty  Preliminary results are presented for an associate system application dealing with the management of robotic planetary exploration rovers    Decision Methods for Adaptive Task Sharing in Associate Systems     Associate Systems  Associate systems bridge the gap between systems that perfonn tasks  on line   in real time  and with complete autonomy in initiating and completing tasks  and typical advisory systems that operate  off line  in giving advice to humans who must initiate and complete all primary task activities  Advances in associate system architectures were recently addressed at a DARPA sponsored conference  Lehner P          Two notable associate system programs discussed at the conference are    rhe U S  Air Force s Pilot s Associate  PA   and the U S  Navy s Submarine Operation Automation System  SOAS    Uncertainties and situational dependancies of both benefits and costs must be modeled  The outcome of task performance and  the cost of taking those actions  inc uding the cost  if any  of making the consultation  all effect the final outcome achieved by the cooperative human associate problem solving system  The estimated state of th is total system i s used to determine the comparative utility of the various strategies for task sharing  The primary model  rhen  for an associate system is an integrated dual decision problem  whether or not to consult the human user prior to taking action  and what action to take  We represent this model in an influence diagram  Howard   Matheson         as shown in Figure      As in any cooperative relationship  both rhe associate system and the human user make use of their perceptions of each other s relative strengths and weaknesses  While humans are good at making judgements from synthesising large amounts of information  they have a limited capacity and efficiency for consistently applying principles for correct problem solving  Computation systems  including intelligent systems  are good at following such normative principles  but their capacity for judgement is limited to rheir internal knowledge representations and inference capabilities  Associate systems exploit these relative strengths by cooperatively focusing on performance of subtasks involving minimal judgement  In addition  associate systems exhibit context sensitive  mixed initiative behavior by adapting the range of subtasks they perfonn to meet the demands of the current  Figure    Generic Associate System Influence Diagram  problem solving context  For example  an associate system may weighr the costs  e g  time  versus the benefits  e g  validity  of consulting the human user for  Round nodes in the influence diagram represent state  his her judgement before taking action autonomously  Alternatives to consult the user or not are evaluated according to a utility function which expresses the user s preferences over multiple  possibly competing  task objectives  Since the decision is made under uncertainty  maximum expected utility is the criterion for selecting a decision alternative  This utility maximizing approach provides the mechanism for evaluating the costs and benefits of consulting the human user  As the preceding example suggests  the key to an associate system s mixed initiative behavior is the adequacy of the consultation decision  This decision must reflect rhe potential benefirs of attaining the human user s judgement before complering and executing a plan for some speci fic course of one or more actions  Consultation might improve the state of knowledge of the associate to support planning and execution  increasing the expected utility of the problem solving actions that are likely to be undertaken  The decision musr also reflecr rhe costs of making rhe consultation with the human user  These costs should re flec t not only resource or performance costs from the associate s point of view  but also the costs incurred by the human user as well   variables whose value is uncertain  Two circle nodes represent deterministic functions whose output is purely a function of the inputs with no additional uncertainty  Square nodes represent decision variables  and octagons represent the utility function wh i ch expresses the preferences of the human user  Arrows between uncertain nodes represent probabilistic dependencies between the two variables  Arrows pointing to decision nodes indicate tha t the state of the node at the tail of the arrow is known when the decision is made  While a node in an influence diagram is intended to represent a single state variable  each node in Figure   may be seen as a  super node  representing a vector of many state variables  The World node in Figure   represents the uncertain state of the task environment with which the human associate system is interacting  The associate is capable of making imperfect observations of the world     ssocObs  which it can then use to determine the Situatbn with which it is dealing  Those observations are known at the time that it makes the decision whe ther or not to Consult the human user  Depending on rhe implementation  the human may also be capable of making direct  but imperfect  observations of the world  HumanObs   as well as having access to the observations made by the associate              Paterson and Fehling  If consulted  the human observations are also used to determine the situation prior to making a decision on what Action to take  The Situ ation is modeled as a deterministic node  since it represents a deterministic procedure by which the associate will synthesise both the associate and human observations of the world  Both the action itself and the state of the world influence the Outcome of the action  as well as the costs incurred by  taking that action  ActCost   If the human user is consulted there will be some consultation costs  ConsCost  which could also be influenced by the state of the world  The Value of the consult decision together with the action decision is a function of the outcome of the action and total costs incurred during consultation with the human user and the course of action carried out  The consultation model discussed above is made up of the  H u m a n   b s and C ons Cost nodes  It is the Hum anObs node which captures the consulting benefits  or judgement capabilities of the human user  Characterizing the possible states and corresponding conditional probabilities for this node is a significant knowledge acquisition task which should not be underestimated      The Mars Rover Manager s Associate  MRMA  system  We have designed and implemented a system that demonstrates management of mixed initiative behavior in a Mars Rover Manager s Associate  MRMA   Intended as  part of an unmanned robotic exploratory mission to Mars  MRMA s role would be to manage a small fleet of semi  autonomous rovers on the Martian surface  MRMA itself would be located on a Mars orbiting communications satellite serving as the link between the rovers and the human Rover Manager  RM  at mission control on Earth  The management of  Mars rovers is an excellent  application for a decision making associate system such as MRMA  Uncertainties will have serious impact on virtually every aspect of the mission  environment  communications  navigation  rover performance  etc  Important tradeoffs will have to be made between rover safety  i e  rover mission lifetime  and the potential gain of scientific knowledge  While the rovers themselves could be designed to exhibit associate behavior  there are several advantages to having a centralized intelligent management system  Environmental knowledge bases would be maintained with MRMA so that each rover could learn from the experiences of others in the fleet  Integrated planning solutions for cooperating rovers could also be formulated by MRMA  While strategic and tactical planning would  be executed by MRMA  only lower level operational planning would be required of the rovers themselves  By offloading these functions from the rovers  they would be smaller and less expensive  with more of them for a given mass budget for Earth to Mars transport  Thus  an  associate management system would complement the use of small  i ntelli gent  insect  robots  such as those developed by Rodney Brooks at MIT l Resource management will be a dominant theme in managing the rover fleet  Various consumables will be  carried on board to carry out scientific experiments  Sample collection mechanisms as well as the propulsion system will exhibit significant wear and tear over the mission lifetime  While the rovers will not have to manage battery energy as a resource  they will have to manage time  Current designs for the rovers make use of radioisotope thermal generators or RTGs as their power supplies  Once power generation is initiated in the RTGs they cannot be powered down during periods of inactivity  the power would be lost  radiated as heat  Therefore  it is critical that inactivity periods for the rovers are minimized to make use of their limited mission lifetime    to   years for the RTGs   Due to the long time delay for Mars Earth communications     to    minutes round trip  varying with a period of about   years   there is a h igh cost associated with consulting mission control for human  judgement  This cost is even higher  and more uncertain  when the time for human analysis of the returned data is considered   This time delay constitutes the cost component of the mission control consultation model  Capturing accurate expectations of human judgement capabilities for the consultation model will require characterizing the performance of mission control personnel in interpreting  rover sensor data  One obvious example of this is visual scene interpretation  Although the rover will posess  image processing and recognition software  the performance of current technology in this area is limited  Knowledge acquisition tests with the human rover  managers would be performed to assemble conditional probabilities for properly identifying various classes of surface features  Similar performance characterizations would be made of the rover hardware software as well  Both rover and human performance knowledge bases would be updated during the course of the mission as both gain experience  We now present an example where MRMA must decide whether or not to consult the human rover manager before planning a deviation from a rover s nominal path  The scenario is illustrated in Figure       MRMA is  in fact  part of an overall demonstration Work on a case  that includes these components  based is  planning  system and  the actual  being performed by ISX Corporation   robotic  devices   Decision Methods for Adaptive Task Sharing in Associate Systems   FieldDepth and FieldWidth   the path Deviation  and the range from the rover s present location to the destination site  SiteRange   The FieldRocks can be interpreted by both the associate and the rover manager  AssocVideo and User Video   to derive an estimate of the RockSize  The rover s rate through the field  FieldRate  is a function of the FieldRocks a n d Traction  while the rate over the plain  PiainRate  is assumed to be known  The dimensions  Figure    Rover Path Deviation Scenario Along its nominal path  the rover has encountered an obstacle field whose surface characteristics differ from the clear plain over which it had been traveling  Due to limited resolution in mapping the Martian surface by satellite  the depth and width of the field are uncertain  Prior estimates from satellite maps indicate the field is strewn with rocks of uncertain size  Depending on the size of the rocks  the rover may be able to roll or step over them with little or no change in speed  or it may have to reduce its speed significantly to move around them  To minimize the time required for the rover to reach its next destination site  MRMA must decide how far the rover should deviate around the field  While MRMA must use prior estimates on the fields dimensions from the satellite maps  it can task the rover to process a far field visual scene of the obstacle field  since the rover is currently at the edge   The processed image provides an improved estimate of rock size  However  MRMA also has the option of transmitting the visual scene to the human rover managers at mission control for them to interpret  Figure   shows how we have instantiated the generic associate system influence diagram  Figure    for this scenario   location of M a rs in its orbit relative to the Earth  MarsLoc  is relevant to the consultation delay  ConsDelay  with the rover manager  In this example  the utility function is one dimensional  being concerned only with the TotaiTime required for the rover to get to the destination site  It is obvious from our description that a significant level of knowledge representation is required to assess and implement the associate system decision model  The conditional probability distributions for the uncertain nodes capture prior know edge about the environment  e g  FieldRocks   knowledge of sensor accuracies  e g  FieldDepth  FieldWidth   and performance knowledge of the associate and human user  e g  AssocVideo  Tracti o n  U s er V i de o  C ons D elay   Other performance knowledge is captured in the deterministic node functions  e g  FieldRate  PlainRate   While many efficient algorithms exist for solving influence diagrams  Olmsted        Shachter          various types of analyses can be performed on an influence diagram prior to actual solution  Deterministic sensitivity analysis and value of information calculations are of particular use to associate systems  Howard  Matheson        Deterministic sensitivity analysis is used to evaluate the sensitivity of the value node s utility function  to the various sources of uncertainty in the influence diagram  For each combination of decision alternatives  the utility range is determined for each variable by fixing the remaining variables at their base case values  Ranking each variable in its contribution to total variance  the utility ranges for each variable can be plotted in a  tornado diagram   Figure   shows one such tornado diagram for the influence diagram in Figure        U     i i  I  I   Figure    Associate System Influence Diagram for Path Deviation Scenario The deviated path is broken into two segments  that which lies in the plain  and that which lies in the field  The distances of both segments  Piain D i st and FieldDi st  are functions of the uncertain field  liD lU                     I        f   Fio th I           c c              rioWI           tttortto   Iorio fw   Totorr  lan   a  Diatr         tt        t   H         I   ioW dth I    I  r     I  I I   i l           t  Figure    Tornado Diagram for Path Deviation Scenario          t   Paterson and Fehling  The associate then has the capability to fix uncertain variables at their base case values if they fall below a predetermined cumulative variance threshold  e g        Since fixing uncertain variables reduces the combinatorial complexity of the problem  this analysis aids the associate in achieving time bounded rationality  If the human user is consulted for advice  or if the user is reviewing actions that the associate has taken autonomously  the tornado diagram is a useful representation for the user to gain insight onto the problem itself  and the problem solving approach of the associate  For the analysis shown in Figure    the FieldRocks node was shown to be the most sensitive of all the uncertainties in the model  This is fortunate  since the AssocVideo and UserVideo nodes provide  imperfect  information on the state of FieldRocks prior to making the Deviation decision  Figure   also shows a high sensitivity to FieldWidth   Value of information calculations could be performed to determine the cost  in time  that the associate user would be willing to pay for perfect information on this variable  in terms of the influence diagram  the increase in utility from adding an  Specifically  we have developed the model of the consultation decision which the associate uses to infer the utility of deferring its own action in order to consult the human user  Our work has also expanded the notion that intelligent associate systems should employ decision theoretic computations to guide problem solving by using such techniques to determine appropriate context specific tactics for person machine  cooperative task sharing  This research has shown that the methods of rational decision making are central to associate system design  While these decision methods constitute a normative model of problem solving  we believe the concept and implementation of the consultation model for associates seeking support from humans is very similar to the process humans use when contemplating the use of software tools in time or resource constrained situations  Finally  our work with MRMA has led to the design and application of new software tools and architectures for implementing decision theoretic principles in associate systems      Implications and Future Work  information arrow from FieldWidth to Deviation   For this particular scenario  the associate might expand  theoretic  We have solved the decision model in Figure   using a number of numerical assessments  The optimal policies which MRMA developed for the C o nsult and Devi atio n decisions show examples of both  development of intelligent system technology  enabling cooperative person machine interaction  Decision theoretic methods are critically needed to provide a principled basis for reasoning and acting under uncertainty  Moreover  these decision principles focus system design and operation on serving a user s preferences rather than meeting a fixed set of goals that may or may not arise out of these preferences depending upon context  We are continuing to explore these issues with further  autonomous and consulting behavior  according to its  development of MRMA and with associate systems for  prior beliefs about its environment  MRMA s own performance at interpreting its environment  as well as the performance of the human user   other problem solving applications such as intelligent management of complex  distributed production processes  and in the development of an insuuctable robot   MRMA is currently implemented both in HyperCard on a Macintosh II  and using CLOS in Macintosh Common Lisp  MCL   While the HyperCard implementation uses conventional discrete probability distributions and discrete decision alternatives  the MCL implementation uses a linear quadratic Gaussian model with multivariate normal distributions  Shachter   Kenley          We are exploring new knowledge representation techniques that are better suited for use in an associate system s decision making and action control processes  These knowledge representation techniques support uniform representation of uncertain causal  taxonomic  and temporal relations among events  objects  and process concepts  We are also developing methods for dynamic model construction  Fehling   Johnson        that allow  the influence diagram shown in Figure   to include a third decision node to examine the alternative of waiting for the next mapping satellite pass for an improved estimate on the distribution of FiefdWidth      Analysis and Review  Our research with MRMA is helping us to formulate and implement problem solving capabilities required in associate systems and to demonstrate their value in performing complex time bounded tasks under uncertainty  While other research efforts have shown the effectiveness of decision theoretic approaches for adaptive  automated problem solving under uncertainty  Fehling   Breese        Horvitz        Russell   Wefald         our efforts on MRMA have clarifiied several issues in the management of task  sharing in associate systems   Work on associate systems extends the use of decision methods  to  an  important point  in  the  an associate system to automate construction of an influence diagram of the form built by hand in MRMA  This work builds upon earlier research on automated decision modeling  Holtzman          
