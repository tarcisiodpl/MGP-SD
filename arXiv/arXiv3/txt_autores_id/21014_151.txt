 We consider the problem of diagnosing faults in a system represented by a Bayesian network  where diagnosis corresponds to recovering the most likely state of unobserved nodes given the outcomes of tests  observed nodes   Finding an optimal subset of tests in this setting is intractable in general  We show that it is difficult even to compute the next most informative test using greedy test selection  as it involves several entropy terms whose exact computation is intractable  We propose an approximate approach that utilizes the loopy belief propagation infrastructure to simultaneously compute approximations of marginal and conditional entropies on multiple subsets of nodes  We apply our method to fault diagnosis in computer networks  and show the algorithm to be very effective on realistic Internet like topologies  We also provide theoretical justification for the greedy test selection approach  along with some performance guarantees     Introduction The problem of fault diagnosis appears in many places under various guises  Examples include medical diagnosis  computer system troubleshooting  decoding messages sent through a noisy channel  etc  In recent years  diagnosis has often been formulated as an inference problem on a Bayesian network  with the goal of assigning most likely states to unobserved nodes based on outcome of test nodes  An important issue in diagnosis is the trade off between the cost of performing tests and the achieved accuracy of diagnosis  It is often too expensive or even impossible to perform all tests  In this paper  we concentrate on the problem of active diagnosis  in which tests are selected sequentially to minimize the cost of testing  We use entropy as  Alina Beygelzimer IBM T J  Watson Research Center    Skyline Drive Hawthorne  NY       beygel us ibm com  the cost function and select a set of tests providing maximum information  or minimum conditional entropy  about the unknown variables  However  exact computation of conditional entropies in a general Bayesian network can be intractable  While much existing research has addressed the problem of efficient and accurate probabilistic inference  other probabilistic quantities  such as conditional entropy and information gain  have not received nearly as much attention  There is a vast amount of literature on value of information and mostinformative test selection                 but none of the previous work appears to focus on the computational complexity of most informative test selection in a general Bayesian network setting  We propose an approximation algorithm for computing marginal conditional entropy  The algorithm is based on loopy belief propagation  a successful approximate inference method  We illustrate the algorithm at work in the setting of fault diagnosis for distributed computer networks  and demonstrate promising empirical results  We also apply existing theoretical results on the optimality of certain greedy algorithms to our test selection problem  and analyze the effect of approximation error on the expected cost of active diagnosis  Our method is general enough to apply to other applications of Bayesian networks that require the computation of information gain and conditional entropies of subsets of nodes  In our application  it can efficiently compute the information gain for all candidate tests simultaneously  The paper is structured as follows  Section   introduces necessary background and definitions  In section    we describe the general problem of active diagnosis and the computational complexity issue thereof  We propose a solution to this problem in section    Section   discusses an application of our approach in the context of distributed computer system diagnosis  while section   presents empirical results  We survey related work in section    and conclude in section        Background and Definitions  process could diverge  convergence is guaranteed only for polytrees   Let X    X    X            XN   denote a set of N discrete random variables and x a possible realization of X  A Bayesian network is a directed acyclic graph  DAG  G with nodes corresponding to X     X            XN and edges representing direct dependencies       The dependencies are quantified by associating each node X i with a local conditional probability distribution P  xi   pai    where pai is an assignment to the parents of X i  nodes pointing to X i in the Bayesian network   The set of nodes  x i   pai   is called a family  The joint probability distribution function  PDF  over X is given as product  Let a denote a factor node and i one of its variable nodes  Let N  a  represent the neighbors of a  i e   the set of variable nodes connected to that factor  Let N  i  denote the neighbors of i  i e   the set of factor nodes to which variable node i belongs  The BP message from node i to factor a is defined as  see  e g           mci  xi        nia  xi       P  x     N    P  xi   pai          i    We use E  X to denote a possibly empty set of evidence nodes for which observation is available  For ease of presentation  we will also use the terminology of factor graphs      which unifies directed and undirected graphical representations of joint PDFs  A factor graph is an undirected bipartite graph that contains factor nodes  usually shown as squares  and variable nodes  shown as circles    See Fig    for an example   There is an edge between a variable node and a factor node if and only if the variable participates in the potential function of the corresponding factor  The joint distribution is assumed to be written in a factored form P  x         fa  xa    Z a       where Z is a normalization constant called the partition function  and the index a ranges over all factors f a  xa    defined on the corresponding subsets X a of X  The computation complexity of many probabilistic inference problems can be related to graphical properties  Exact inference algorithms require time and space exponential in the treewidth      of the graph  which is defined to be the size of the largest clique induced by inference  and can be as large as the size of the graph  Many common probabilistic inference problems are NP complete      This includes our problem of probabilistic diagnosis  which can be formulated as a Maximum A Posteriori  MAP  probability problem  given a set of observations  find the most likely states of unobserved variables  Although probabilistic inference can be intractable in general  there exists a simple linear time approximate inference algorithm known as belief propagation  BP         BP is provably correct on polytrees  i e  Bayesian networks with no undirected cycles   and can be used as an approximation on general networks  In belief propagation  probabilistic messages are iterated between the nodes  The  cN  i  a  and the message from factor a to node i is defined as     fa  xa   nja  xj    mai  xi      xa  xi       jN  a  i  Based on these messages  we can compute the beliefs for each node and the probability potential for each factor    mai  xi        bi  xi    aN  i   ba  xa    fa  xa       nia  xi          iN  a   Observations are incorporated into the process via functions as local potentials for the evidence nodes  In that case  bi  xi   becomes the approximation of the posterior probability P  x i   e      The Active Test Selection Problem In many diagnosis problems  the user has an opportunity to actively select tests in order to improve the accuracy of diagnosis  For example  in medical diagnosis  doctors face the experiment design problem of choosing which medical tests to perform next  Let S    S    S            SN   denote a set of unobserved random variables we wish to diagnose  and let T    T    T            TM   denote the available set of tests  Our objective is to maximize diagnostic quality while minimizing the cost of testing  The diagnostic quality of a subset of tests T can be measured by the amount of uncertainty about S that remains after observing T    From the information theoretic perspective  a natural measurement of uncertainty is the conditional entropy H S   T     Clearly  H S   T   H S   T   for all T  T  Thus the problem is to find T   T which minimizes both H S   T   and the cost of testing  When all tests have equal cost  this is equivalent to minimizing the number of tests  This problem is known to be NP hard       A simple greedy approximation is to choose the next test to be T    arg minT H S   T  T     where T  is the currently selected   test set  The expected number of tests produced by the greedy strategy is known to be within a O log N   factor from optimal  see Appendix   The same result holds for approximations  within a constant multiplicative factor  to the greedy approach  Furthermore  our empirical results show that the approach works well in practice  We make a distinction between off line test selection and online test selection  In online selection  previous test outcomes are available when selecting the next test  Off line test selection attempts to plan a suite of tests before any observations have been made  We will focus on the online approach  sometimes called active diagnosis  which is typically much more efficient in practice than its off line counterpart       Active Test Selection Problem  Given the observed outcome t  of previously selected sequence of tests T     select the next test to be arg minT H S   T  t     In a Bayesian network  the joint entropy H X  can be decomposed into sum of entropies over the families and thus can be easily computed using the input potential functions  Conditional marginal entropies  on the other hand  do not generally have this property  Under certain independence conditions they decompose into functions over the families  But computing those functions will require inference   See Appendix for proofs   Lemma    Given a Bayesian network representing a joint PDF P  X   the joint entropy H X  can be decomposed into the sum of entropies over the families  H X     N i   H Xi   Pai    Lemma    Given a Bayesian network representing a joint PDF P  S  T   where i   paTi  S  i e  tests Ti and Tj are independent given a subset of S   the observation t   of previously selected test set  and a candidate test T   the conditional marginal entropy H S   T  t     can be written as   H S   T  t       P  spaT   t   t    log P  t   spaT   t spaT        P  t   t    log P  t   t      const       t  where const is a constant expression     BP for Entropy Approximation Let us consider the problem of computing the conditional marginal entropy   P  xa   e  log P  xa   e       H Xa   e     xa     where P  xa   e    x xa P  x   e   x xa representing variable nodes not in x a   The trick is to replace the marginal posterior P  xa   e  with its factorized BP approximation  and make use of the BP message passing mechanism to perform the summation over x a   We call this process Belief Propagation for Entropy Approximation  BPEA   Pick any node X   from Xa and designate it as the root node  We modify the final message passed to X   as follows    m a   x            ba  xa   log ba  xa    xa  x   Here  ba  xa   is the unnormalized belief of X a  i e     ba  xa     ba  xa    where    xa ba  xa     Plugging in ba  xa   in place of P  x a   e  in Eqn     we see that it only remains to sum over the root node X   and normalize properly    h Xa   e     m a   x          x   h Xa   e       h Xa   e    log           It follows immediately that BPEA is exact whenever BP is exact  The normalization constant  is already computed during normal BP iterations  The computation of ba     m ai   and h   can all be piggy backed onto the same BP infrastructure  and therefore does not impact its overall complexity  Furthermore  due to the local and parallel message update procedure in BP  we can compute the marginal posterior entropies of multiple families in one single sweep  This is an important advantage for the active probing setup   Minimizing conditional entropy is a particular instance of value of information  VOI  analysis      where tests are selected to minimize the expected value of a certain cost function c s  t  t     The result of Lemma   can be generalized to this case if the cost function is decomposable over the families  See Lemma   in the Appendix for details   It is also easy to show that the approach is extendible beyond the entropy computation  to an arbitrary cost function decomposable over families  see Lemma   in the Appendix   The cost function replaces the negative logarithm in Eqns      and       Since observations of test outcome correlate the parent nodes  the exact computation of all the posterior probabilities in Eqn      is intractable  We can certainly use an existing approximation method to compute P  s paT   t   t    and P  t   t     But a more efficient approach is possible if we exploit the belief propagation infrastructure     Application  Fault Diagnosis in Computer Networks Suppose we wish to monitor a system of networked computers  Let S represent the binary state of N network elements  Si     indicates that the element is in normal   is the cross entropy between the posterior probability of T and its parents  and the conditional probability of T given its parents  The second term in Eqn      is simply the negative conditional entropy H T   t        S   S   S   T   T     SM    TN  Figure    Factor graph of the fault diagnostic Bayes net  operation mode  and S i     indicates that the element is faulty  We can take S i to be any system component whose state can be measured using a suite of tests  If the system is large  it is often impossible to test each individual component directly  A common solution is to test a subset of components with a single test probe  If all the test components are okay  the test would return a    Otherwise the test would return    but it does not reveal which components are faulty   We deal with the two entropy terms separately  For H T   t     we may use approximation methods such as BP or GBP to calculate the belief b t   t     which can then be used to directly compute H T   t       Note that the summation over values of T is simple since T is binary valued   To calculate A T  SpaT   t     we use the entropy approximation method BPEA  as described in Section    Because BP message updates are done locally  we can compute A T  SpaT   t    for all unobserved T nodes during a single application of BP  Thus  picking the next probe requires only one run of the BPEA approximation algorithm  For each candidate probe  we designate the probe node T itself as the root node  The unnormalized belief has the form   bt  t  spaT      P  t   spaT   njt  sj         jpaT  We assume there are machines designated as probe stations  which are instrumented to send out probes to test the response of the network elements represented by S  Let T denote the available set of probes  A probe can be as simple as a ping request  which detects network availability  A more sophisticated probe might be an e mail message or a webpage access request  In the absence of noise a probe is a disjunctive test  it fails if an only if there is at least one failed node on its path  More generally  it is a noisyOR test       The joint PDF of all tests and network nodes forms the well known QMR DT model        This is used to calculate the modified message m  at  t   cf  Eqn        However  since A T  S paT   t    is a cross entropy term  we do not take the log of b  but rather take the logarithm of the known probabilities P  t   s paT    This simplifies the normalization step described in Eqn       to A T  SpaT   t      A T  SpaT   t      where      t spa  T   bt  t  spaT     P  sj      j  sj     j    sj       s P  ti       spai     i  ijj    We conduct experiments on network topologies built by the INET generator       which simulates an Internet like topology at the Autonomous Systems level  Our dataset includes a set of networks of     nodes  where the number of probe stations varies from   to      P  s  t       i             jpai  P  ti   spai       P  sj           j  Here  j    P  sj      is the prior fault probability   ij is the so called inhibition probability  and    i    is the leak probability of an omitted faulty element  The inhibition probability is a measurement of the amount of noise in the network  Fig    shows a factor graph representation of our model  As discussed in Section    we adopt the active probing framework for fault diagnosis  sequentially selecting probes to minimize the conditional entropy  Our previous work      makes the single fault assumption  which effectively reduces S to one random variable with N    possible states  In general  however  multiple faults could exist in the system simultaneously  which requires the more complicated conditional entropy given in Eqn        Let A T  SpaT   t    denote the first term in Eqn       This    Empirical Results  The connections between probe nodes and network nodes are generated with two goals in mind  detection and diagnosis  A detection probe set needs to cover all network components  so that at least one probe has a positive probability of returning   when a component fails  A diagnosis probe set needs to further distinguish between faulty components  Optimal probe set design is NP hard for either detection or diagnosis  For the datasets used here  we first use a greedy approach to obtain a probe set that covers all network components  then augment this set with additional probes in order to guarantee single fault diagnosis  Interested readers may find detailed discussions of probe set design for diagnostic Bayesian networks in           In our experiments  we measure the effects of prior fault probability  and inhibition probability  on approximation and diagnostic quality  We compare the approximate entropy values and the quality of the selected probe set                                                                                                     inhibition prob                                                                            inhibition prob  c  Test set entropy                                        inhibition prob  d  Test set size                                                   inhibition prob  Figure    Approximation errors and diagnostic quality for an augmented detection network  Each curve represents a different prior fault probability  against the ground truth  which is obtained via the junction tree exact inference algorithm  In subsection      we also summarize how the type of network may effect computational efficiency  Since all measurements depend on the particular set of probe outcomes  we repeat all experiments on    different samples of the Bayes net  We use the diagnostic quality of the probe set to determine when to stop the probe selection process  when the reduction in entropy for the past   iterations is no more than          the selection process is deemed to converge  Otherwise we continue until all probes have been picked      Approximation accuracy First  we look at approximation accuracy  Recall that at each time step of the active probing process  we obtain a vector of approximate entropy values  one for each candidate probe T   We average the relative error between the approximate values and the exact values for all candidate probes  and further average over all time steps and samples  Let M denote the total number of probes  n the number of selected probes  h ij the approximate value for probe j at the ith time step of probe selection  and H ij the corresponding exact value  We compute R h  H                     diag                  Network type                 diag                                          seconds saved     Figure    Efficiency of approximate method   a  Average number of BP iterations saved by re using messages   b  CDF of speed up  in CPU seconds  compared to exact method                              b       cumulative distribution           reduction in bit entropy  ave relative abs error        size of final probe set  ave relative abs error         a    b  Second term approx errors                            iters saved per node   a  First term approx errors           n  Mi          hij  Hij     n i   M  i j    Hij          We conduct this experiment on the detection network with    probe stations  augmented with single node probes  Fig    a b  contains plots of the average  the minimum  and the maximum approximation errors  taken over    samples of probe outcomes  Relative error values are shown separately for the first term  A T  S paT   t     and the second term  H T   t     For both terms  the approximation errors  are generally lower at lower  values  The average errors do not exceed     with the only exception being the BP error for term two at        and       which reaches up to      BP approximaton errors of the second term seem to be generally higher than BPEA approximations of the first term  At the maximum  the approximation error never exceeds     for term one  and     for term two  BP errors for term two does not seem to contain any linear trends with respect to   However  BPEAs approximation quality of term one does seem to become slightly worse at higher levels of the inhibition probability      Diagnostic quality The quality of diagnosis is taken to be the reduction in conditional bit entropy of the hidden states  If t   represents the observed outcomes of the final set  of selected probes    we measure H S   H S   t      s P  s  log  P  s          P  s   t   log P  s   t      s Fig    c  compares the diagnostic quality of approximate and exact algorithms on the augmented detection network with    probe stations  Overall  the reduction in bit entropy is larger for higher values of   This is due to the fact that H S  is higher when  is larger  The quality of the exact algorithm is almost identical to that of the approximate algorithm  The two are virtually indistinguishable  except at        and         There is an outlier at this combination  For one of the samples  the value of the entropy H S   t    plateaued unusually early during the active probing process  fooling the algorithm into believing that it had converged  even though the amount of reduction in entropy is still very small  Fig    d  shows that the process terminated after selecting only a small set of tests  This outlier is an artifact of our convergence criterion  not of the approximate algorithm itself  Fig    d  looks at the size of the final selected probe set when active probing converges  Here again  the two algorithms have almost identical behavior  The value of  does not have much impact on the number of selected tests  except when       i e   no noise in the tests   in which case   fewer tests are needed for diagnosis at lower levels of   These results demonstrate that  while the approximated entropy values may deviate from the truth  the diagnostic quality of the approximate method is virtually identical to that obtained using the exact method  Combined with its speed advantages as described in the next section  these results make a strong case for why the approximate method is preferable over the exact one      Implementation and speed We use the junction tree inference engine in Kevin Murphys Bayes Net Toolbox      for Matlab to obtain exact singleton posterior probabilities  The approximate method is implemented on top of the belief propagation C   mex code developed by Yair Weiss and Talya Meltzer  Additionally  we speed up the approximate active probing process by re using BP messages at the start of each round of test selection  thereby maintaining BPs state from the end of the selection round  We find that BP converges in substantially fewer iterations this way  Fig    a  plots the average  maximum  and minimum number of BP iterations that we save by re using BP messages  The results are aggregated over   samples of the Bayes net  The x axis denotes the type of network used  The label diag represents the diagnosis network with   probe station  and the rest are detection networks with various numbers of probe stations  In the detection network with    probe stations  we save up to     iterations per test node at the maximum  On average  re using messages shortens the BP convergence time by       iterations per test  If active probing selected     tests  say  then re using messages would require      to      fewer iterations of belief propagation  Fig    b  is a plot of the empirical cumulative distribution of the speed up using the approximate method  For all of the detection networks  the approximate method is at least   CPU second faster than the exact method for     of the test nodes  The speed up is even higher for the diagnostic network  where for     of all test nodes the approximate method saves at least   CPU seconds per node  This amounts to substantial savings over the entire active probing process  Also keep in mind that  for networks with large tree width  the exact method is not even computationally feasible  Hence  approximation may be the only realistic option     Related Work The problem of most informative test selection was previously addressed in various areas including diagnosis  decision analysis  and feature selection in machine learning  Given a cost function  a common decisiontheoretic approach is to compute the expected value of   information      of a candidate test  i e   the expected cost of making a decision after observing the test outcome  When entropy is used as the cost function  the approach is called most informative test selection  In particular  mostinformative test selection was considered in the context of model based diagnosis     and probabilistic diagnosis       Previous research        on VOI analysis has made various simplifying assumptions such as binary hypothesis and direct observations  An interesting but tangential approach was taken in      which proposes to select a set of tests based on a law of large numbers approximation of the VOI  Up to now  however  no one seems to have addressed the efficiency of computing single test information gain in a generic Bayesian network  Most informative test selection is quite similar to the optimal coding problem      Namely  the hidden state vector S is the input message  and the test outcomes T the output message from some noisy channel  The goal of mostinformative test selection is to minimize the number of bits sent through the channel while still accurately decoding the input message  There is  however  an important difference between the two  In the coding domain  one may separate source coding from channel coding  Fault diagnosis  on the other hand  has to deal with a combination of the two  represented by the conditional probability P  T i   Spai    We may have no control over the source coding function  but we can still aim to select the smallest  most informative subset of tests  In the context of probing  optimal test selection is very similar to the group testing problem      Given a set of Boolean variables  the objective of group testing is to find all failed objects by using a sequence of disjunctive tests  Particularly  sequential test selection is known as adaptive group testing       There is also a direct connection between adaptive group testing and Golomb codes        Note that group testing assumes no constraints on the tests  i e   any subset of objects can be tested together   while in Bayesian networks the tests can be only selected from a fixed set  Even in a less restrictive case of probe selection  we are still constrained by the network topology  Theoretical analysis of constrained group testing is difficult     Conclusions We propose an entropy approximation method based on loopy belief propagation  and examine its behavior on the application of active probing for fault diagnosis in a networked computer system  The level of approximation error varies slightly with the level of noise  But even so  the diagnosis quality is practically identical to that of the exact method  Furthermore  the approximate method can handle larger networks than the exact method  and is almost always faster on the smaller ones  This highlights a promising direction for active probing and fault diagnosis  as well   as for entropy approximation on Bayesian networks in general   
  Keywords  In evaluating prediction markets  and other crowd prediction mechanisms   investigators have repeatedly observed a socalled wisdom of crowds effect  which can be roughly summarized as follows  the average of participants performs much better than the average participant  The market price an average or at least aggregate of traders beliefsoffers a better estimate than most any individual traders opinion  In this paper  we ask a stronger question  how does the market price compare to the best traders belief  not just the average trader  We measure the markets worst case log regret  a notion common in machine learning theory  To arrive at a meaningful answer  we need to assume something about how traders behave  We suppose that every trader optimizes according to the Kelly criteria  a strategy that provably maximizes the compound growth of wealth over an  infinite  sequence of market interactions  We show several consequences  First  the market prediction is a wealthweighted average of the individual participants beliefs  Second  the market learns at the optimal rate  the market price reacts exactly as if updating according to Bayes Law  and the market prediction has low worst case log regret to the best individual participant  We simulate a sequence of markets where an underlying true probability exists  showing that the market converges to the true objective frequency as if updating a Beta distribution  as the theory predicts  If agents adopt a fractional Kelly criteria  a common practical variant  we show that agents behave like full Kelly agents with beliefs weighted between their own and the markets  and that the market price converges to a time discounted frequency  Our analysis provides a new justification for fractional Kelly betting  a strategy widely used in practice for ad hoc reasons  Finally  we propose a method for an agent to learn her own optimal Kelly fraction   Auction and mechanism design  electronic markets  economically motivated agents  multiagent learning  Categories and Subject Descriptors I       Artificial Intelligence   Distributed Artificial IntelligenceIntelligent agents  Multiagent systems  General Terms Economics  Short Version Appears in  Proceedings of the   th International Conference on Autonomous Agents and Multiagent Systems  AAMAS        Conitzer  Winikoff  Padgham  and van der Hoek  eds    June            Valencia  Spain       INTRODUCTION  Consider a gamble on a binary event  say  that Obama will win the      US Presidential election  where every x dollars risked earns xb dollars in net profit if the gamble pays off  How many dollars x of your wealth should you risk if you believe the probability is p  The gamble is favorable if bp  p       in which case betting your entire wealth w will maximize your expected profit  However  thats extraordinarily risky  a single stroke of bad luck loses everything  Over the course of many such gambles  the probability of bankruptcy approaches    On the other hand  betting a small fixed amount avoids bankruptcy but cannot take advantage of compounding growth  The Kelly criteria prescribes choosing x to maximize the expected compounding growth rate of wealth  or equivalently to maximize the expected logarithm of wealth  Kelly betting is asymptotically optimal  meaning that in the limit over many gambles  a Kelly bettor will grow wealthier than an otherwise identical non Kelly bettor with probability                      Assume all agents in a market optimize according to the Kelly principle  where b is selected to clear the market  We consider the implications for the market as a whole and properties of the market odds b or  equivalently  the market probability pm          b   We show that the market prediction pm is a wealth weighted average of the agents predictions pi   Over time  the market itselfby reallocating wealth among participantsadapts at the optimal rate with bounded log regret to the best individual agent  When a true objective probability exists  the market converges to it as if properly updating a Beta distribution according to Bayes rule  These results illustrate that there is no price of anarchy associated with well run prediction markets  We also consider fractional Kelly betting  a lower risk variant of Kelly betting that is popular in practice but has less theoretical grounding  We provide a new justification for fractional Kelly based on agents confidence  In this case  the market prediction is a confidence and wealth weighted average that empirically converges to a time discounted version of objective frequency  Finally  we propose a method for agents to learn their optimal fraction over time       KELLY BETTING   When offered b to   odds on an event with probability p  the Kelly optimal amount to bet is f  w  where bp      p  b is the optimal fixed fraction of total wealth w to commit to the gamble  If f  is negative  Kelly says to avoid betting  expected profit is negative  If f  is positive  you have an information edge  Kelly says to invest a fraction of your wealth proportional to how advantageous the bet is  In addition to maximizing the growth rate of wealth  Kelly betting maximizes the geometric mean of wealth and asymptotically minimizes the mean time to reach a given aspiration level of wealth       Suppose fair odds of   b are simultaneously offered on the opposite outcome  e g   Obama will not win the election   If bp      p       then betting on this opposite outcome is favorable  substituting   b for b and    p for p  the optimal fraction of wealth to bet becomes    p  bp  An equivalent way to think of a gamble with odds b is as a prediction market with price pm          b   The volume of bet is specified by choosing a quantity q of shares  where each share is worth    if the outcome occurs and nothing otherwise  The price represents the cost of one share  the amount needed to pay for a chance to win back     In this interpretation  the Kelly formula becomes f    f    p  pm      pm  The optimal action for the agent is to trade q    f  w pm shares  where q      is a buy order and q      is a sell order  or a bet against the outcome  Note that q  is the optimum of expected log utility p ln     pm  q   w        p  ln pm q   w    odds reached when all agents are optimizing  and supply and demand are precisely balanced  Recall that the markets probability implied by Pthe odds of b is pm          b   We will show that pm is i wi pi         Payout balance  The first approach well use is payout balance  the amount of money at risk must be the same as the amount paid out  Theorem     Market Pricing  For all normalized agent wealths wi and agent beliefs pi   X pi wi pm   i  Proof  To see this  recall that fi    pi  pm       pm   for pi   pm   For pi   pm   Kelly betting prescribes taking the other side of the bet  with fraction     pi        pm   pm  pi            pm   pm So the market equilibrium occurs at the point pm where the payout is equal to the payin  If the event occurs  the payin is X pi  pm X pi  pm   wi   wi        b     pm pm i p  p    pm i p  p Thus we want X   pm i p  p i     pm pm  X pi  pm pi  pm wi   wi      pm    pm i pi  pm X pm  pi wi   pm i p  p  i pi  pm  X  pi w i    i  X  pm wi    i  Using  P       Log utility maximization  wi      we get the theorem   An alternate derivation of the market prediction utilizes the fact that Kelly betting is equivalent to maximizing expected log utility  Let q   x b      be the gross profit of an agent who risks x dollars  or in prediction market language the number of shares purchased  Then expected log utility is E U  q     p ln     pm  q   w        p  ln pm q   w   The optimal q that maximizes E U  q   is q pm      w p  pm    pm    pm       Proposition    In a market of agents each with log utility and initial wealth w  the competitive equilibrium price is X pm   wi pi      MARKET PREDICTION  In order to define the prediction markets performance  we must define its prediction b  or the equilibrium payoff  or  m  X pm  pi pi  pm wi   wi   or    pm pm i pi  pm i pi  pm X X  pi  pm  wi    pm  pi  wi   or  i pi  pm  i  m  X  MARKET MODEL  Suppose that we have a prediction market  P where participant i has a starting wealth wi with i wi      Each participant i uses Kelly betting to determine the fraction fi of their wealth bet  depending on their predicted probability pi   We model the market as an auctioneer matching supply and demand  taking no profit and absorbing no loss  We adopt a competitive equilibrium concept  meaning that agents are price takers  or do not consider their own effect on prices if any  Agents optimize according to the current price and do not reason further about what the price might reveal about the other agents information  An exception of sorts is the fractional Kelly setting  where agents do consider the market price as information and weigh it along with their own  A market is in competitive at price pm if all P equilibrium  agents are optimizing and q      or every buy order i i and sell order are matched  We discuss next what the value of pm is       m  i  i  This is not a coincidence  Kelly betting is identical to maximizing expected log utility       m  i  i  where we assume absolute wealth   P  i wi      or w is normalized wealth not   P Proof  These prices satisfy i qi      the condition for competitive equilibrium  supply equals demand   by substitution    This result can be seen as a simplified derivation of that by Rubinstein              and is also discussed by Pennock and Wellman          and Wolfers and Zitzewitz            as L       Wealth redistributed according to Bayes Law  In an individual round  if an agents belief is pi   pm   i pm wi and have a total wealth afterward then they bet p p m dependent on y according to   I yt      log  t          I yt      log   pt    pt  Similarly  we measure the quality of market participant making prediction pit as Li   LEARNING PREDICTION MARKETS  Individual participants may have varying prediction qualities and individual markets may have varying odds of payoff  What happens to the wealth distribution and hence the quality of the market prediction over time  We show next that the market learns optimally for two well understood senses of optimal   T X  T X  I yt      log  t          I yt      log   pit    pit  So after T rounds  the total wealth of player i is  y     yt T   Y pit t    pit wi   pt    pt t   where wi is the starting wealth  We next prove a well known theorem for learning in the present context  see for example       Theorem    For all sequences of participant predictions pit and all sequences of revealed outcomes yt   L  min Li   ln i     If  y       If  y           pi  pm pi   wi   wi   wi pm    pm pm pi  pm    pi     wi   wi   wi    pm    pm  Similarly if pi   pm   we get  If  y       If  y       pm  pi pi wi   wi   wi pm pm     pm  pi    pi   wi   wi   wi      pm pm    pm         This theorem is extraordinarily general  as it applies to all market participants and all outcome sequences  even when these are chosen adversarially  It states that even in this worst case situation  the market performs only ln   wi worse than the best market participant i  P Proof  Initially  we have that i wi      After T rounds  the total wealth of any participant i is given by  y     yt T   Y pit t    pit wi   wi eLLi     p    p t t t   where the last inequality follows from wealth being conserved  Thus ln wi   L  Li     yielding  which is identical  If we treat the prior probability that agent i is correct as wi   Bayes law states that the posterior probability of choosing agent i is P  i   y         P  y       i P  i  p i wi pi w i       P P  y      pm i pi wi  which is precisely the wealth computed above for the y     outcome  The same holds when y      and so Kelly bettors redistribute wealth according to Bayes law        Market Sequences  It is well known that Bayes law is the correct approach for integrating evidence into a belief distribution  which shows that Kelly betting agents optimally summarize all past information if the true behavior of the world was drawn from the prior distribution of wealth  Often these assumptions are too strongthe world does not behave according to the prior on wealth  and it may act in a manner completely different from any one single expert  In that case  a standard analysis from learning theory shows that the market has low regret  performing almost as well as the best market participant  For any particular sequence of markets we have a sequence pt of market predictions and yt         of market outcomes  We measure the accuracy of a market according to log loss      wi  L  Li   ln          wi  FRACTIONAL KELLY BETTING  Fractional Kelly betting says to invest a smaller fraction f  of wealth for       Fractional Kelly is usually justified on an ad hoc basis as either     a risk reduction strategy  since practitioners often view full Kelly as too volatile  or     a way to protect against an inaccurate belief p  or both       Here we derive an alternate interpretation of fractional Kelly  In prediction market terms  the fractional Kelly formula is p  pm       pm With some algebra  fractional Kelly can be rewritten as p   pm    pm where p    p        pm         In other words   fractional Kelly is precisely equivalent to full Kelly with revised belief p    pm   or a weighted average of the agents original belief and the markets belief  In   this light  fractional Kelly is a form of confidence weighting where the agent mixes between remaining steadfast with its own belief        and acceding to the crowd and taking the market price as the true probability         The weighted average form has a Bayesian justification if the agent has a Beta prior over p and has seen t independent Bernoulli trials to arrive at its current belief  If the agent envisions that the market has seen t  trials  then she will update her belief to p        pm   where    t  t   t                 The agents posterior probability given the price is a weighted average of its prior and the price  where the weighting term captures her perception of her own confidence  expressed in terms of the independent observation count seen as compared to the market            MARKET PREDICTION WITH FRACTIONAL     KELLY  When agents play fractional Kelly  the competitive equilibrium price naturally changes  The resulting market price is easily compute  as for fully Kelly agents  Theorem     Fractional Kelly Market Pricing  For all agent beliefs pi   normalized wealths wi and fractions i P i wi pi       pm   Pi l l wl Prices retain the form of a weighted average  but with weights proportional to the product of wealth and self assessed confidence  Proof  The proof is a straightforward corollary of Theorem    In particular  we note that a  fractional Kelly agent of wealth w bets precisely as a full Kelly agent of wealth w  Consequently  we can apply theorem   with wi    Piwiiwi i and p i   pi unchanged       MARKET DYNAMICS WITH STATIONARY OBJECTIVE FREQUENCY  The worst case bounds above hold even if event outcomes are chosen by a malicious adversary  In this section  we examine how the market performs when the objective frequency of outcomes is unknown though stationary  The market consists of a single bet repeated over the course of T periods  Unbeknown to the agents  each event unfolds as an independent Bernoulli trial with probability of success   At the beginning of time period t  the realization of event Et is unknown and agents trade until equilibrium  Then the outcome is revealed  and the agents holdings pay off accordingly  As time period t     begins  the outcome of Et   is uncertain  Agents bet on the t     period event until equilibrium  the outcome is revealed  payoffs are collected  and the process repeats  In an economy of Kelly bettors  the equilibrium price is a wealth weighted average      Thus  as an agent accrues relatively more earnings than the others  its influence on price increases  In the next two subsections  we examine how this adaptive process unfolds  first  with full Kelly agents and second  with fractional Kelly agents  In the former case  prices react exactly as if the market were a single agent updating a Beta distribution according to Bayes rule                    a                                                    b                                                       Figure     a  Price  black line  versus the observed frequency  gray line  of the event over     time periods  The market consists of     full Kelly agents with initial wealth wi           b  Wealth after    time periods versus belief for     Kelly agents  The event has occurred in    of the    trials  The solid line is the posterior Beta distribution consistent with observing    successes in    independent Bernoulli trials         Market dynamics with full Kelly agents  Figure   a plots the price over     time periods  in a market composed of     Kelly agents with initial wealth wi          and pi generated randomly and uniformly on         In this simulation the true probability of success  is      For comparison  the figure also shows the observed frequency  or the number of times that E has occurred divided by the number of periods  The market price tracks the observed frequency extremely closely  Note that price changes are due entirely to a transfer of wealth from inaccurate agents to accurate agents  who then wield more power in the market  individual beliefs remain fixed  Figure   b illustrates the nature of this wealth transfer  The graph provides a snapshot of agents wealth versus their belief pi after period     In this run  E has occurred in    out of the    trials  The maximum in wealth is near       or      The solid line in the figure is a Beta distribution with parameters        and        This distribution is precisely the posterior probability of success that results from the observation of    successes out of    independent Bernoulli trials  when the prior probability of success is uniform on        The fit is essentially perfect  and can be proved in the limit since the Beta distribution is conjugate to the Binomial distribution under Bayes Law  Although individual agents are not adaptive  the markets composite agent computes a proper Bayesian update  Specifically  wealth is reallocated proportionally to a Beta distribution corresponding to the observed number of successes and trials  and price is approximately the expected value of this Beta distribution   Moreover  this correspondence holds regardless of the number of successes or failures  or the temporal order of their occurrence  A kind of collective Bayesianity emerges from the interactions of the group  We also find empirically that  even if not all agents are Kelly bettors  among those that are  wealth is still redistributed according to Bayes rule                             where  E t  is the indicator function for the event at period t  and  is the discount factor  Note that      recovers the standard observed frequency    As t grows  this expected value rapidly approaches the observed frequency plotted in Figure                                                     Market dynamics with fractional Kelly agents  In this section  we consider fractional Kelly agents who  as we saw in Section    behave like full Kelly agents with belief p        pm   Figure   a graphs the dynamics of price in an economy of     such agents  along with the observed frequency  Over time  the price remains significantly more volatile than the frequency  which converges toward         Below  we characterize the transfer of wealth that precipitates this added volatility  for now concentrate on the price signal itself  Inspecting Figure   a  price changes still exhibit a marked dependence on event outcomes  though at any given period the effect of recent history appears magnified  and the past discounted  as compared with the observed frequency  Working from this intuition  we attempt to fit the data to an appropriately modified measure of frequency  Define the discounted frequency at period n as Pn nt      t    P E t  nt       dn   Pn nt   E t      n   E t    t    t          a    b                                  Figure     a  Price  black line  versus observed frequency  gray line  over     time periods for     agents with Kelly fraction         As the frequency converges to         the price remains volatile   b  Price  black line  versus discounted frequency  gray line   with discount factor          for the same experiment as  a     For example  if you allocate an initial weight of     to your predictions and     to the markets prediction  then the regret guarantee of section     implies that at most half of all wealth is lost                                                                 Figure     a  Wealth wi versus belief pi at period     of the same experiment as Figure   with     agents with Kelly fraction         The observed frequency is        and the solid line is Beta                  The wealth distribution is significantly more evenly dispersed than the corresponding Beta distribution   Figure   b illustrates a very close correlation between discounted frequency  with          hand tuned   and the same price curve of Figure   a  While standard frequency provides a provably good model of price dynamics in an economy of full Kelly agents  discounted frequency     appears a better model for fractional Kelly agents  To explain the close fit to discounted frequency  one might expect that wealth remains dispersedas if the markets composite agent witnesses fewer trials than actually occur  Thats true to an extent  Figure   shows the distribution of wealth after    successes have occurred in     trials  Wealth is significantly more evenly distributed than a Beta distribution with parameters      and       also shown  However  the stretched distribution cant be modeled precisely as another  less informed Beta distribution       LEARNING THE KELLY FRACTION  In theory  a rational agent playing against rational opponents should set their Kelly fraction to       since  in a rational expectations equilibrium      the market price is by definition at least as informative as any agents belief  This is the crux of the no trade theorems      Despite the theory      people do agree to disagree in practice and  simply put  trade happens  Still  placing substantial weight on the market price is often prudent  For example  in an online prediction contest called ProbabilitySports        of participants were outperformed by the unweighted average predictor  a typical result   In this light  fractional Kelly can be seen as an experts algorithm     with two experts  yourself and the market  We propose dynamically updating  according to standard experts algorithm logic  When youre right  you increase  appropriately  when youre wrong  you decrease   This gives a long term procedure for updating  that guarantees   You wont do too much worse than the market  which by definition earns     You wont do too much worse than Kelly betting using your original prior p    http   www overcomingbias com         how and when to html  DISCUSSION  Weve shown something intuitively appealing here  selfinterested agents with log wealth utility create markets which learn to have small regret according to log loss  There are two distinct logs in this statement  and its appealing to consider what happens when we vary these  When agents have some utility other than log wealth utility  can we alter the structure of a market so that the market dynamics make the market price have low log loss regret  And similarly if we care about some other losssuch as squared loss      loss  or a quantile loss  can we craft a marketplace such that log wealth utility agents achieve small regret with respect to these other losses  What happens in a market without Kelly bettors  This cant be described in general  although a couple special cases are relevant  When all agents have constant absolute risk aversion  the market computes a weighted geometric average of beliefs               When one of the bettors acts according to Kelly and the others in some more irrational fashion  In this case  the basic Kelly guarantee implies that the Kelly bettor will come to dominate non Kelly bettors with equivalent or worse log loss  If non Kelly agents have a better log loss  the behavior can vary  possibly imposing greater regret on the marketplace if the Kelly bettor accrues the wealth despite a worse prediction record  For this reason  it may be desirable to make Kelly betting an explicit option in prediction markets        
