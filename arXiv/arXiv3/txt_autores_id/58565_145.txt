ions  Alejandro Isaza and Csaba Szepesvari and Vadim Bulitko and Russell Greiner Department of Computing Science  University of Alberta Edmonton  Alberta  T G  E   CANADA  isaza szepesva bulitko greiner  cs ualberta ca  Abstract In this paper  we consider planning in stochastic shortest path  SSP  problems  a subclass of Markov Decision Problems  MDP   We focus on medium size problems whose state space can be fully enumerated  This problem has numerous important applications  such as navigation and planning under uncertainty  We propose a new approach for constructing a multi level hierarchy of progressively simpler abstractions of the original problem  Once computed  the hierarchy can be used to speed up planning by first finding a policy for the most abstract level and then recursively refining it into a solution to the original problem  This approach is fully automated and delivers a speed up of two orders of magnitude over a state of the art MDP solver on sample problems while returning near optimal solutions  We also prove theoretical bounds on the loss of solution optimality resulting from the use of abstractions      Introduction and Motivation  We focus on planning in stochastic shortest path problems  the problem of reaching some goal state under uncertainty  when planning time is critical  a situation that arises  for instance  in path planning for agents in commercial video games  where map congestions are modeled as uncertainty of transitions  Another example is path planning for multi link robotic manipulators  where the uncertainty comes from unmodeled dynamics as well as sensor and actuator noise  More specifically  we consider the problem of finding optimal policies in a sequence of stochastic shortest path problems  Bertsekas   Tsitsiklis         where the problems share the same dynamics and transition costs  and differ only in the location of the goal state  When the state space underlying the problems is sufficiently large  exact planning methods are unable to deliver a solution within the required time  forcing the user to resort to approximate methods in order to scale to large domains  Exploiting the fact that multiple planning  problems share the same dynamics and transition costs  we build an abstracted representation of the shared structure where planning is faster  then map the individual planning problem into the abstract space and derive a solution there  The solution is then refined back into the original space  In a related problem of path planning under real time constraints in deterministic environments  e g   Sturtevant         a particularly successful approach is implemented in the PR LRTS algorithm  Bulitko  Sturtevant  Lu    Yau         which builds an abstract state space by partitioning the set of states into cliques  i e   each state within each cluster is connected to each other state in that cluster with a single action   Each such cluster becomes a single abstract state  Two abstract states are connected by an abstract transition if there is a pair of non abstract states  one from each abstract state  connected by a single action  The resulting abstract space is smaller and simpler  yet captures some of the structure of the original search problem  Thus  an abstract solution can be used to guide and constrain the search in the original problem  yielding a significant speed up  Further speed ups can be obtained by building abstractions on top of abstractions  which creates a hierarchy of progressively smaller abstract search spaces  PR LRTS can then be tuned to meet strict real time constraints while minimizing solution suboptimality  Note that state cliques produced by PR LRTS make good abstract states because landing anywhere in such a cluster puts the agent a single action away from any other state in the clique  This also means that the costs of the resulting actions are similar  and that the cost of a single action is negligible compared with the cost of a typical path  Finally  any  optimal  path in the original problem can be closely approximated at the abstract level  as an agent following an  optimal  path has to traverse from cluster to cluster  Since all neighboring clusters are connected in the abstract problem  it is always possible to find a path in the abstract problem that is close to the original path  Given the attractive properties or PR LRTS  it is natural to ask whether the ideas underlying it can be extended to stochastic shortest path problems  with arbitrary cost structures  In a stochastic problem  the result of planning is a closed loop policy that assigns actions to states  A successful ab    straction must be suitable for approximating the execution trace of an optimal policy  Imagine that clustering has been done in some way  The idea is again to have abstract actions that connect neighboring clusters cheaply  that is  the system should not produce expensive connections  Intuitively  we want to connect one cluster to another if  from any state of the first cluster  we can reliably get to some state of the second cluster at roughly a fixed cost  the same for any state in the first cluster   This way  simulating a policy of the original problem becomes possible at a small additional cost  the meaning of simulation will become clear later   This means that a connection between clusters is implemented by a policy with a specific set of initial states that brings the agent from any state of the source cluster to some state of the target cluster  We will use options  Sutton  Precup    Singh        for such policies  and choose clusters to allow such policies for any two neighboring clusters  Thus  it is natural to look for clusters of states that allow one to reliably simulate any trajectory from any of the states to any other state  Finally  we need an extra mechanism  the goal approach  that deals with the challenge of reaching the base level goal itself from states that are close to the goal  Thus  our planner first plans in the abstract space to reach the goal cluster  After arriving at some state of the goal approach region  the planner then uses the goal approach policy that  with high probability  moves the agent to the goal state itself  These ideas form the core of our algorithm   The MDP is undiscounted if       An action a  xX A x  is called admissible in state x if a  A x   Definition   A  generic  policy is a mapping that assigns to each history  x    a    c            xt    at    ct    xt   an action admissible in the most recent state xt   In general  a mapping that maps possible histories to some set is called a history dependent mapping  Under mild conditions  it suffices to consider only stationary  deterministic policies  Bertsekas   Tsitsiklis         on which we will focus  Definition   A stationary and deterministic policy  is a mapping of states to actions such that  x   A x  holds for any state x  X  In what follows  we will use policy to mean stationary and deterministic policies  unless otherwise mentioned  The expected cost of policyP when the system starts  in state x  is v  x      E   t    t c Xt    Xt    Xt      where Xt is a Markov chain with P  Xt     y Xt   x    p y x   x    The function v is called the value function underlying policy   One solves an MDP by finding a policy that minimizes the cost from every state  simultaneously  In this paper we deal only with stochastic shortest path problems  a subclass of MDPs  In these MDPs the problem is to get to a goal state with the least cost   The three major contributions of the paper are   i  a novel theoretical analysis of option based abstractions   ii  an effective algorithm for constructing high quality option based abstractions  and  iii  experimental results demonstrating that our algorithm performs effectively over a range of problems of varying size and difficulty   Definition   A finite stochastic shortest path  SSP  problem is a finite undiscounted MDP that has a special state  called the goal state g  such that a  A g   we have p g g  a      and c g  a  g      and the immediate costs for all the other transitions are positive   Section   formally describes our problem  and provides the theoretical underpinning of our approach  Section   then presents our algorithm for automatically building options based abstractions  and Section    our planning algorithm that uses these abstractions  Section   empirically evaluates this approach  in terms of both efficiency and effectiveness  suboptimality   Finally  Section   summarizes related work   Consider a finite SSP  X  A  p  c   Let  be a stationary policy  We say that this policy is proper if it reaches the goal state g with probability one  regardless of the initial state  Let T   RX  RX be the policys evaluation operator  X  T v  x    p y x   x    c x   x   y    v y     yX     Problem Formulation and Theory  This section formally defines stochastic shortest path problems and the abstractions that we will consider  It also presents a theoretical result that characterizes the relationship between the performance of abstract policies and policies of the original problem  Definition   A Markov Decision Process  MDP  is defined by a finite state space X               n   a finite set of actions A x  for each state x  X  transition probabilities p y x  a          that correspond to the probability that the next state is y when action a is applied in state x  immediate cost c x  a  y   R for all x  y  X and all a  A x  and a discount factor            Bertsekas and Tsitsiklis        prove that T is a contraction with respect to a weighted maximum norm  kkw    with some positive weights  w  RX     where kvkw    maxx  v x   w x   In particular  w x  can be chosen to be the expected number of steps until  reaches the goal state when started from x  The contraction coefficient of T      satisfies            maxxX w x   Thus           is the maximum of the expected number of steps to reach the goal state  or in other words  the maximum expected time policy  spends in the MDP  cf  Prop     in Bertsekas   Tsitsiklis         We adopt the notion of options from Sutton et al          Definition   An option is a triple    I     where I  X is the set of initial states   is a  generic  policy that is   defined for histories that start with a state in I and  is a history dependent mapping with range         called the terminating condition  We say that the terminating condition fires when  ht        Let T     denote the random time when the terminating condition fires for the first time while following    Note that T     is not allowed   We assume that P  T           independent of the initial state when the policy  is started  i e   the option terminates in finite time with probability one   As suggested in the introduction  an abstraction is a way to group states and the abstract actions correspond to options  Definition   We say that the MDP  X   A  p  c  is an option based abstraction of  X  A  p  c   if there exists a mapping  S   X   X specifying the states S x   X that correspond to an abstract state x  X   a set  of options abstracting the actions of the MDP and a mapping    xX A x    such that for any a  A x   if  a     I      then S x   I   Henceforth we will use abstraction instead of optionbased abstraction and will call  X   A  p  c  the abstract MDP  X the set of abstract states  A the set of abstract actions  etc  Notationally  we call  X  A  p  c  the ground level MDP  and we will identify quantities related to the abstract MDP by using a tilde        For simplicity  we will identify the abstract actions with their corresponding options  In particular  we will call a both an abstract action and an option  depending on the context  In the following  we will assume that  S x    x  X   is a partition of X  we can then let x   X  X denote the  unique  abstract state that includes x  x x   X such that x  S x x    and say that  X   S  is an aggregation of the states in X  We also define S x    S x x   as the set of states in X that are in the same partition with x  The restriction on  in the above definition ensures that the execution of any policy  in the abstract MDP is well defined and proceeds as follows  Initially  there is no active option  In general  whenever there is no active option  we look up the abstract state x   x x  based on the current state x and activate the option   x    When there is an active option  the option remains active until the corresponding terminating condition fires  When an option is active  the options policy selects the actions in the ground level MDP  This way a policy  in the abstract MDP induces a policy in the ground level MDP  Our goal now is to characterize what makes an abstraction accurate  The following theoretical analysis is novel as it considers abstractions where the action set is changed  In particular  the action set can potentially be reduced and the abstract actions can be options  To our knowledge  such options based abstractions have not been analyzed previously  the closest results are probably Theorem   of Kim and Dean        and Theorem   of Dean  Givan  and Leach         The proof is rather technical and is given   X     denotes the power set of X  the set of all subsets of X   in the extended version of our paper  Isaza  Szepesvari  Bulitko    Greiner         Consider a proper policy  of the ground level MDP  We want abstractions such that one can always find a policy in the abstract MDP  X   A  p  c  that approximates  well  no matter how  was chosen  Clearly  this depends on how the action set A and the corresponding transitions and costs are defined in the abstract MDP  Quantifying this requires a few definitions  Let p  x  y  be the probability of landing in some state of S y  when following policy  until it leaves the states of S x   when the initial state is selected at random from the states of S x  based on the distribution S x    Let c  x  denote the corresponding expected immediate cost  Now pick a proper policy  of the abstract MDP  Let w be the weight vector that makes T a contraction in the abstract MDP  P Further  define p  x  y    p y x   x   and c  x    yX p  x  y c  x  y  and the mixed l   l norm kkw      kp   p  kw      max xX  X  yX   p   x  y   p   x  y    w y    w x   Let     kc  c kw    cmax kp  p kw            where cmax is the maximum of the immediate costs in the ground level MDP  Hence    measures how well the costs and the transition probabilities induced by  after state aggregation match those of   Introduce c x    as the expected total cost incurred  conditioned on that policy  starting in state x and stopping when it exits S x   Further  introduce p y x    as the probability that  given that policy  is started in state x  when it exits S x  it enters S y   y    x x    Now fix an abstract state x  X   If the costs  c x    xS x  and probabilities  p y x    xS x    y    x  have a small range then we can model closely the behavior of  locally at S x  by introducing an option with initial states in S x  which mimics the expected behavior of  as it leaves S x   assuming  say  that the initial state in S x  is selected at random according to the distribution S x    If we do so for all abstract states x  X then we can make sure that min   is small  If the above range conditions hold for all policies  of the ground level MDP and all abstract states x  X then by introducing a sufficiently large number of abstract actions it is possible to keep max min   small  Further  notice that max p y x    is zero unless there exists a transition from some state of S x  to some state of S y   in which case we say that S x  is connected to S y   Hence  no abstract action is needed between x and y  unless S x  is connected in the ground level MDP to S y   Define TP   B X   B X    T v  x     c  x    p Since  is proper in the y   x  y v y   ground level MDP  it is not difficult to show that T is a contraction with respect to an appropriately defined weighted supremum norm  The next result gives a bound on the difference of value functions of  and  in terms of       Theorem   Let  be a proper policy in the ground level MDP and let  be a proper policy in the abstract MDP  Let w  resp   w   be the weight vector that makes T  resp   T   a contraction and let the corresponding contraction factor be   resp       Let v be the value function of  and v be the value function of   Then kv  Ev kw    kAv  v kw                    where the operator E extends functions defined over X to functions defined over X in a piecewise constant manner  E   B X    B X    Ev  x    v x x    and A   B X   B X  is the aggregation operator defined by X  AV   x    S x   z V  z   zS x   and    maxxX w  x x   w  x   The factor  measures how many more steps are needed to reach the goal if the execution of policy  is modified such that  whenever the policy enters a new cluster x  the state gets perturbed  by choosing a random state according to S x    The theorem provides a bound on the difference between the value function of a ground level policy  and the value function of an abstract policy when its value function is extended to the ground level states  The bound has two terms  The first bounds the loss due to state abstraction  while the second bounds the loss due to action abstraction  When a similar range condition holds for the abstract actions  too  then it is possible to bound the difference between the value function of the policy induced in the ground level MDP by  and Ev   yielding a difference on the value functions of  and the policy induced by   Isaza et al         provides further details  If we apply this result to an optimal policy   of the ground level MDP  we immediately get a bound on the quality of the abstraction  We may conclude then that the quality of abstraction is determined by the following factors   i  whether states with different optimal values are aggregated   ii  whether the random perturbation described in the previous paragraph can increase the number of steps to the goal substantially  and  iii  whether the immediate costs c and transition probabilities p can be matched in the abstract MDP  Since we want to build abstractions that work independently of where the goal is placed  the knowledge of the optimal policy with respect to a particular goal cannot be exploited when constructing the abstractions  In order to prevent large errors due to  i  and  ii   we restrict aggregation such that only a few states are grouped together  This makes the job of creating an aggregation easier  Fortunately  we can achieve higher compression by adding additional layers of abstractions  We can address  iii  by creating a sufficiently large number of abstract actions  Here  we use the simplifying assumption that we only create abstract actions that bring the agent from some cluster of states to some neighboring cluster  These can  serve as a basis for matching any complex next state distribution over the clusters by choosing an appropriate stochastic policy in the abstract MDP  We also want to ensure that the initial state within a cluster has a small influence on the probability of transitioning to some neighboring cluster and the associated costs  We use two constants   and   to bound the amount of variation with respect to initial states  note this allows us to control the difference between the value function of a policy induced in the ground level MDP by some abstract policy  and the extension of the value function of  defined in the abstract MDP to the ground level states  Ev   This is necessary to ensure that a good policy in the abstract MDP produces a good policy in the ground level MDP  ultimately assuring that the optimal policy of the abstract MDP will give rise to a close to optimal policy in the ground level MDP  The resulting procedure is described in the next section      Abstracting an SSP  This section describes our algorithm BuildAbstraction for automatically building options based abstractions  These abstractions are goal independent and thus apply to a series of SSPs that share the state space and transition dynamics  The process consists of four main steps  Figure         Cluster proposes candidates for abstract states      GenerateLinkCandidates proposes candidates for abstract actions  or links       Repair validates and  if necessary  repairs the links in order to satisfy the so called      connectivity property  the formal definition is given later  and Prune discards excessive links  Once an abstraction is built  we use a special purpose planning procedure  described in Section    to solve specific SSPs  The rest of this section describes the four steps of our BuildAbstraction algorithm in detail  Step    Cluster  A straightforward cluster er will cluster a state with some of its immediate neighbors  Unfortunately  this approach may group states with diverging trajectories  the trajectories from one state can differ from those of the other state   By looking for the peers of a state  predecessors of its successors  line    Figure    we hope to find a peer whose trajectories are similar to the trajectories of the first state  Note that the clustering routine creates minimal clusters  This is advantageous as it means the subsequent steps  which connect clusters  is more likely to succeed  Unfortunately  it also means relatively low reduction in the number of states  Several layers of abstractions can help increase this reduction  Step    Generate Link Candidates  After forming the initial clusters  i e   the initial abstract states   BuildAbstraction generates candidates for abstract actions  One approach is simply to propose abstract actions for all pairs of abstract states  in the hope that only important ones will remain after pruning  We use a less expensive strategy and propose abstract action candidates only for nearby clusters  line     For each such pair we add two candidate links  one in the forward and another in the backward direction  this heuristic quickly generates reasonable link candidates  We typically use k      Our experiments confirm this is   BuildAbstraction k  p  M      M  ground level MDP Cluster   for each unmarked ground state x do   Find P  x   all the predecessors of successors of x   Find y  P  x  that has the most successors in common with x   Add x to X with S x     x  y    Mark states  x  y    end for GenerateLinkCandidates   repairQ     for every x  y  X  where any state in S y  is within k ground transitions of some state in S x  do   repairQ  repairQ    x  y    y  x      end for Repair    while repairQ     do     x  y   pop an element from repairQ    set up an SSP  S  with domain R  X where S x S y   R with states in S y  as goals    attempt to find an optimal policy S in S with IPS    if no policy found then    continue    else if S does not meet the      conditions then    split the cluster adding both parts to repairQ    else    add a to A x  with  a     S x   S   IS y         set c x  a  to be the expected cost of executing a from a random state of x    set p y x  a       p y   x  a      for y     y     end if    end while Prune    for each state x do    find A  x     a            am    all abstract actions that connect clusters that are neighbors in M    order A x    A  x  to create  am             an   such that c x  ai    c x  ai      i   m              n       let A x     a            ap      end for    return  X  A  p  c    Figure    The abstraction algorithm  sufficient  increasing k results in slightly better quality  but slower running times when solving the planning problems  Step    Repair  For each candidate abstract action connecting abstract states x and y  we first need to derive an option that  starting in any state in cluster x leads the agent to some state in cluster y with a minimum total expected cost  We derive this option by setting up a shortest path problem S  whose domain includes S x  and S y   We set the domain of S to be sufficiently large that a policy within this domain can reliably take the agent from any state of S x  to some state of S y   BuildAbstraction builds this domain by performing a breadth first search from S y   proceeding backwards along the transitions  stopping at depth D   m  where D is the search depth from S y  and m is the margin to leave after all states of S x  were added to the domain  If there is any state of S x  that was not included at depth D  the Repair routine reports no solution  The transitions  actions and costs of S are inherited from the MDP M   We also add a new terminating state  which is the destination   Here IS is the characteristic function of S  IS  x      iff x  S and IS  x      otherwise   of transitions leaving the region  i e   those transitions are redirected to this new terminal  with a transition cost that exceeds the maximum of the total expected costs of the ground level MDP  The high cost discourages the solutions to enter the extra terminating state  The optimal solution to S is obtained by using the Improved Prioritized Sweeping  IPS  algorithm of McMahan and Gordon          line      We selected this algorithm based on its excellent performance and known optimality properties  IPS reduces to Dijkstras method in deterministic problems   The resulting policy  is checked against      connectivity  defined as follows  we first compute the expected total cost of reaching some states in S y  for all states of S x   let the resulting costs be c x     Similarly  we compute the probabilities p S y  x    for every x  S x   Then we check if maxx x S x   c x     c x        and maxx x S x   p S y  x     p S y  x        both hold  If these constraints are met  a new abstract action is created and is added to the set of admissible actions at x and the policy is stored as the option corresponding to this new abstract action  lines        Otherwise  the cluster is split  since every cluster has two states  this is trivial  and the appropriate link candidates are added to the repair queue so that no link between potentially connected clusters is missed  Step    Prune  After step    we have an abstract SSP whose abstract states are      connected  However  our abstract action generation mechanism may produce too many actions  which may slow down the planning algorithm  see Section     We address this problem using a pruning step that leaves only the critical and cheapest abstract actions  An action is critical if it connects clusters that are connected at the ground level with a single transition  these actions are important to keep the structure of the ground level MDP  We also keep the cheapest abstract actions as they are likely to help achieve high quality solutions  The pruning parameter  p  specifies the total number of actions to keep   If p is smaller or equal than the number of ground actions  then only the critical actions are kept   BuildAbstraction runs in time linear in the size of the input MDP  as every step is restricted to some fixed size neighborhood of some state  i e   every step is local   Further  employing a suitable data structure  the memory requirements can also be kept linear in the size of the input  These properties are important when scaling up to realistic  real world problem sizes      Planning with an Abstraction  After building an abstraction  we can use it to solve particular SSP problems  When we specify a new goal  our abstraction planner  AbsPlanner  then creates a goal approach region in the abstract MDP that includes the goal and is large enough to include all states of the cluster containing the goal  AbsPlanner builds this region by starting with the ground goal and adding states and transitions in a breadth first fashion to a certain depth  proceeding backwards along the transitions  stopping only after adding all states of the goal cluster  After building the region  AbsPlanner produces an SSP  The domain of this   SSP includes the states found in the breadth first search  and also a new terminal state that becomes the destination of transitions leaving the region  i e   those transitions are redirected to this new terminal  with a high transition cost  All other costs and transitions of this SSP are inherited from the ground level MDP  AbsPlanner uses IPS to solve the local MDP  and saves the resulting goal approach policy  It then solves the abstract MDP  where the goal cluster is set as the goal  When executing the resulting policy   AbsPlanner proceeds normally until reaching a state of the goal approach region  it then switches to the goal approach policy  which it follows until reaching the goal or leaving the region  When this latter event happens and the state is x  execution switches to the option  x x    When using multiple levels of abstraction  AbsPlanners execution follows a recursive  hierarchical strategy  Note that the size of the goal approach region is independent of the size of the MDP  Thus  the planning time will depend on the size of the top level abstract MDP  For an MDP of size n  by using log n levels of hierarchy  in theory it is then possible to achieve planning times that scale with O log n   However  depending on the problem  it might be hard to guarantee high quality solutions when using many levels of abstraction  Furthermore  in practice  over the problems used in our tests   the computation time is dominated by the time needed to set up and solve the goal approach SSPs  which is required for even one layer of abstraction  This is partly because our abstractions result in deterministic shortest path problems  whose solutions can be found significantly faster than those of stochastic problems      Empirical Evaluation  This section summarizes our empirical evaluation of this approach  in terms of the quality  suboptimality  of the solutions and the solution times  Here we report the tradeoffs of using different levels of abstraction as well as the dependence on the stochasticity of the transitions   Note that stochasticity makes it difficult to build abstractions   We also tested the performance of the algorithm on more practical problems  In addition to the results presented here  we conducted extensive experiments  studying the trade off between solution quality and solution time as a function of the various parameters of our algorithm  e g   the values of p  k  or the number of abstraction levels   the scaling behavior of our algorithm in terms of its resource usage  the quality of solutions and the solution time  These results  appearing in  Isaza et al          confirm that the algorithm is robust to the choices of its parameters and scales as expected by increasing problem sizes  We run experiments over three domains  noisy gridworlds  a river and congested game maps  The gridworlds are empty and have four actions  up  down  left  and right  each with cost    The probability that an action leaded to the expected position  e g   the action up moves the agent up one cell  is      while the probability of reaching any of the other three adjacent cells is      The river is similar to the gridworld  its dimensions are w  h  but there is a current flowing from left to right  and a fork corresponding to a line connecting the points  w    h    and  w  h      The flow is represented by modifying both the cost structure and the transition probabilities of the actions  action forward costs    backward costs    diagonally up and forward and diagonally down and forward each cost    These actions are also stochastic  For the backward action  the probabilities are     for going back and     for each of the other actions  For the other three actions  the anticipated move occurs with probability     and the other moves except backwards occur each with probability      and backwards has probability    We include the river domain to determine whether our system can deal with non uniform structures and because the fork complicates the task of creating abstractions  We empirically found the time to build abstractions for the n state gridworld was close to n     seconds  and around n    for an n state river domain  The build time for the maps  using k      was between    and     seconds   The congested game maps are again similar to gridworlds  but with obstacles and with transitions probabilities that depend on the congestion  The obstacle layout comes from commercial game maps  and the stochastic dynamics simulate what happens if multiple units traverse the same map  in narrow passages  the units to become congested  which means an agent trying to traverse such a passage is likely to be blocked  We model this by modifying each action by including a probability that the action will fail and cause the agent to stay at the same position  This failure probability depends on the position on the game map  calculated by simulating many units randomly traversing the game maps and measuring the average occupation of the individual cells  then turning the occupation numbers into probabilities  The optimal policy of an agent in a congested game map will then try to avoid narrow passages  since the higher probability of traffic congestion in such regions means an agent takes much longer to get through those regions  The baseline performance measures are obtained by running the state of the art SSP solver algorithm IPS  For each study  we generate the abstraction and then use it to solve       problems  whose start and goal locations are selected uniformly at random  For each problem we measure the solution time in seconds and the total solution cost for both IPS and our method  then compute the geometric average of the individual suboptimalities and the individual solution time ratios       Abstraction level trade offs  We used a          gridworld to analyze the trade offs of different abstraction levels  with several different parameter configurations  We say a configuration is dominant if it was a Pareto optimal  i e   if no other configuration is better in both time and suboptimality  Figure   presents properties of the dominant configurations   See  Isaza et al         for more details  including relevant pictures    We ran all experiments on a  GHz AMD Opteron tm  Processor with  GB of RAM running Linux with kernel                                                                                                                                                Solution time ratio  Figure    Subobtimality versus the solution time ratio as compared to IPS for different parameter configurations  The dominant configurations are shown for different levels of abstraction  for various abstraction levels  We see that using a smaller number of abstractions required more time but produced better solutions  i e   lower suboptimality   and higher levels of abstractions required less solution time but produced inferior solutions  i e   increased suboptimality   Note that there are dominant configurations for every level of abstraction  from   to    We obtain a level   abstraction by converting the given ground level SSP to deterministic shortest path problem with the same states   Recall that our abstraction process abstracts the state space and produces a deterministic SSP  here we just used the original state space   Figure   shows that this transformation provides solutions whose quality is slightly inferior to the original problem  but it finds this solution significantly faster  e g   in       to        of the time   We also see that these level   solutions are superior to those based on higher abstraction levels  but one can obtain these level i solutions in yet less time                 Suboptimality  level   level   level   level   level   level    Suboptimality vs  speed up on a   x   gridworld             Figure   plots the suboptimality and the speed up of finding a solution using our method  as compared to IPS  for different values of P   We see that our method loses optimality as the dynamics becomes noisier  i e   when P gets smaller   This is because our abstract actions  trying to move the agent from one abstract state to the next will fail with higher probability for noisier dynamics  Note        that the advantage of our method  in terms of planning time  becomes larger with increased stochasticity  This is because our abstractions are deterministic and planning in a deterministic system is much faster than planning with a stochastic system  Figure    plotting the absolute values of cost and time for both our method and IPS  provides another insight  It shows that for increasing stochasticity both methods are slowed down  but our method can cope better with this situation  This figure also confirms that this leads to a loss in solution quality  For our method the typical parameters produce a suboptimality of around     for the river  and around      for the gridworld domain  The speed up for the gridworld is around     while for the river it is around       Sensitivity to Stochasticity of the Dynamics  As the environment becomes noisier  it becomes more difficult to construct a high quality abstraction  This section quantifies how the solution quality and construction time relate to noise in the dynamics  In general  we consider an action successful if the agent moves to the appropriate direction  our gridworld model set the success probability to P        leaving a probability of     P     to moving in each of the other three directions  Here  we vary the value of P   All of these experiments use a        gridworld with k     and p      which means we keep only the critical actions  see Section                Solution time ratio  Figure    Subobtimality versus the solution time ratio as compared to IPS for different values of P    Cost  Suboptimality  Suboptimality vs  Speed up on a    x    gridworld                                                        Cost vs  solution time trade off in a   x   gridworld          IPS     Abstraction                                                                                                                Solution time  s   Figure    Cost versus solution time for IPS and abstraction at different values of P        Congested Game Maps  To test the performance of our approach in a more practical application  we used maps modeled after game environments from commercial video games  We first created simplified gridworlds that resemble some levels from a   Figure    A congested game map  Darker redder color refers to high congestion  Dark blue regions are impassable obstacles  popular role playing and real time strategy game  We then converted the gridworlds into congested maps as described earlier  This produced maps with state space sizes of       BG          BG          BG           WC   and       WC    Figure   provides one such map  where each states color indicates the associated congestion  warmer redder colors indicates high congestion  i e   low probability of success P   while colder bluer colors indicates low congestion  i e   high value of P    Very dark blue indicates impassable obstacles  We see that many of the states in cluttered regions are highly congested and should therefore be avoided  Figure   shows the solution time and the solution suboptimalities for both our method and IPS  for two maps from WarCraft  Blizzard Entertainment        and three maps from Baldurs Gate  BioWare Corp          including Figure    using only a single layer of abstraction  We see that our approach is indeed successful in speeding up the planning process  while keeping the quality of the resulting solutions high      Related Work  Due to space constraints we review only the most relevant work  references to other related works can be found in the extensive bibliography lists of the cited works  Dean et al         introduced the notion of  homogeneous partitions and analyzed its properties  but without giving explicit loss bounds  Kim and Dean        developed some loss bounds  Their Theorem   can be strengthened with our proof method to kv   vP k  kT vP  vP k         using our notation   basically dropping the first term in their bound  Here v  is the optimal value function in the original MDP  vP is the optimal value function of the aggregated MDP extended back to the original state space in a piecewise constant manner and T is the Bellman optimality operator in the original MDP  This bound is problematic as it does not show how the quality of  partitions influences the loss  Our bound improves on this bound in this respect  and also by extending it to the case when the abstract actions correspond to options  While Asadi and Huber        also considered such optionsbased abstractions  they assume that the abstract actions  options  are given externally  possibly by specifying goal states for each of them  and they do not develop bounds  In a number of subsequent papers  the authors refined their methods  In particular  they became increasingly focussed on learning problems  For example  in the recent follow up work  Asadi and Huber        provide a method to learn an abstract hierarchical representation that uses state aggregation and options  Since they are interested in skill transfer through a series of related problems that can differ in their cost structure  they introduce a heuristic to discover subgoals based on bottleneck states  They learn options for achieving the discovered subgoals and introduce a partitioning that respects the learned options  in the clusters typically there are many states   The success of the approach relies critically on the existence of meaningful bottleneck states  This leads to a granularity issue  identifying the bottleneck states requires computing a statistic for each state visited  meaning bottlenecks will not be pronounced if resolution is increased in narrow pathways  Nevertheless  the approach has been successfully tested in a non trivial domain of        states  Hauskrecht  Meuleau  Kaelbling  Dean  and Boutilier        introduce a method that also uses options  but the abstract states correspond to boundary states of regions  The regions are assumed to be given a priori  The idea is similar to using bottleneck states  In contrast to that work  we do not assume any prior knowledge  but construct the abstractions completely autonomously  Further  we deal with undiscounted SSPs  while Hauskrecht et al         dealt with discounted MDPs  but this difference is probably not crucial       Discussion and Future Directions  In the approach presented  options serve as closed loop abstract actions  Another way to use an abstract solution would be to use the abstract value function to guide local search initiated from the current state  These ideas has proven successful in pattern database research where the cost of an optimal solution of an abstract problem is used as a powerful heuristic for the original problem  Such a procedure has the potential to improve solution quality  while keeping low the cost of the planning steps interleaved with execution  Another idea is to use the abstraction to select the amount of such local search  i e   the depth of the rollouts   these ideas has proven successful in deterministic environments  Bulitko  Bjornsson  Lustrek  Schaeffer    Sigmundarson        Bulitko  Lustrek  Schaeffer  Bjornsson    Sigmundarson         Presently  our abstractions are deterministic  This suggests two avenues for future work  First  applying advanced heuristic search methods to such abstractions may lead to performance gains  Second  in highly stochastic domains  the abstractions determinism may lead to a poor quality of solution  as the cost of ensuring arrival at an abstract   Solution time for different game maps  Solution suboptimality for different game maps       IPS Abstraction       Suboptimality  Solution time  s                                       WC    WC    BG    BG    BG    WC    Map  WC    BG    BG    BG    Map  Figure    Solution times  left  and suboptimalities  right  for several game maps  state with certainty  or very high probability  can lead to very conservative and costly paths  Thus  it would be of interest to investigate stochastic abstractions  One idea is to modify the way abstract actions are defined  When planning to connect to abstract states after a solution of the local SSP is found  with a little extra work we can compute the probabilities of reaching various neighboring abstract states under the policy found when the policy leaves the region of interest  Yet another avenue for future work would be to move from a state based problem formulation to a feature based one  assuming that the features describe the states  The challenge is to design an algorithm that can construct an abstraction without enumerating all the states  as ours currently does  Although this paper has not attempted to address this problem  we believe that the approach proposed here  i e   incremental clustering and defining options by solving local planning problems  is applicable  Finally  although the present paper dealt only with undiscounted  stochastic shortest path problems  the approach can be extended to work for discounted problems  This holds because a discounted problem can always be viewed as an undiscounted stochastic shortest path problem where every time step a transition is made to some terminal state with probability      where          is the discount factor      Conclusions  This paper has explored ways to speed up planning in SSP problems via goal independent state and action abstraction  We strengthen existing theoretical results  then provide an algorithm for building abstraction hierarchies automatically  Finally  we empirically demonstrate the advantages of this approach by showing that it works effectively on SSPs of varying size and difficulty   Acknowledgements We gratefully acknowledge the insightful comments by the reviewers  This research was funded in part by the National Science and Engineering Research Council  NSERC   iCore and the Alberta Ingenuity Fund   
 A Bayesian belief network models a joint distribution with an directed acyclic graph representing dependencies among variables and network parameters characterizing conditional distributions  The parameters are viewed as random variables to quantify uncertainty about their values  Belief nets are used to compute responses to queries  i e   conditional probabilities of interest  A query is a function of the parameters  hence a random variable  Van Allen et al               showed how to quantify uncertainty about a query via a delta method approximation of its variance  We develop more accurate approximations for both query mean and variance  The key idea is to extend the query mean approximation to a doubled network involving two independent replicates  Our method assumes complete data and can be applied to discrete  continuous  and hybrid networks  provided discrete variables have only discrete parents   We analyze several improvements  and provide empirical studies to demonstrate their effectiveness      INTRODUCTION  Consider a simple example  Suppose A represents presence absence of a medical condition while B and Y are test results  Variables B and Y are conditionally independent given A  with A and B binary and Y continuous  The conditional independence assumption is represented by the directed acyclic graph structure in Figure   a   Let a   P  A   a   b a   P  B   b   A   a   and let p y   a   a   be the conditional density of Y given A   a  assumed normal with mean a and variance a    We want to estimate the probability that condition A is present given  specified results from the two tests B and Y   Let  represent all of the parameters  If  were known  we would use the formula  a b a p y   a   a     a  a  b a  p y   a    a     q     qa b y      P       In the Bayesian paradigm  uncertainty about  is quantified by modeling parameters as random variables  It follows that query probabilities such as     are also random  A query response is usually estimated by approximating its posterior mean  This approximation is similar to expression      but with a and b a replaced by their posterior means and with the normal densities replaced by Students t densities  One may want more than just a point estimate  Van Allen et al               showed  for discrete networks  how one can approximate the variance and posterior distribution of a query  Their variance derivation employs the delta method  i e   a first order Taylor series expansion of the function q   about the posterior mean of   They provide asymptotic theory and empirical experiments supporting this approach  They also showed how these approximations can be used to construct a Bayesian credible interval  error bars  for q    Guo and Greiner        applied this delta method approximation as part of a mean squared error  i e   squared bias   variance  measure designed to estimate the quality of different belief net structures when seeking a best classifier  Lee et al         provide a technique for combining independent belief net classifiers that involves weighting their respective mean probability values by their inverse variances  and they show that this works well in practice  We propose new approximations for the mean and variance based on a simple trick  Suppose  A    B    Y    and  A    B    Y    are replicates of the network variables  conditionally independent given   We represent the paired replicates as nodes in a doubled network with the same structure  see Figure    The squared query q    can be expressed as a query in this doubled net    UAI       b   a  b   a   b   a  b   a   HOOPER ET AL     a  a  A                                            b  a b  a    b   a  b   a   a    a     Y B       a    a       b   a  b   a  b   a  b   a        a  a   b   a  b   a  b   a  b   a  b   a  b   a  b   a  b   a   b   a  b   a  b   a  b   a  b   a  b   a  b   a  b   a   a  a   b   a  b   a  b   a  b   a  b   a  b   a  b   a  b   a   a  a   a  a       A    A                             a    a     a    a                a    a     a    a     Y    Y  B    B   a          a                   a         a           a a a a  Figure     a  A simple Bayesian network   b  The corresponding doubled network  Figure    A simple Bayesian net   work  P  A    A    a   B    B    b  Y    Y    y      The method used to approximate the mean of q   can be extended to the doubled network to approximate the mean of q    and hence to approximate the variance  Unlike the delta method  our approach does not rely on approximate local linearity of q    It does involve the addition of two incomplete observations to the data set when calculating the posterior mean of q      In some situations  this addition results in under estimation of the desired variance  This deficiency is largely eliminated by a simple adjustment  A similar adjustment substantially improves the usual query mean approximation  Section   reviews pertinent models and methods for belief networks  The network doubling technique is described in Section   for discrete  continuous  and hybrid networks  Proposed adjustments and numerical results are presented in Sections   and   for discrete networks  Corresponding work for continuous and hybrid networks is ongoing  Computational issues are discussed in Section    Contributions and plans for further work are summarized in Section            BACKGROUND NETWORK VARIABLES  We assume network structure is known  Let B denote a discrete network variable taking values b  DomB   Let Y denote a continuous network variable taking values y on the real line  Vectors of variables are denoted by boldface  A for discrete and X for continuous  Let  be a random vector comprising all unknown network parameters  i e    determines all conditional distributions of variables given their parents  We assume that discrete variables have only discrete parents  Suppose pa B    A  i e   the parents of B are the variables comprising the vector A  The conditional probability that B   b given A   a is denoted b a   B b A a   P  B   b   A   a         Variables associated with values will be clear from context  We employ similar abbreviations for other parameters and hyperparameters  The b a parameters are often presented in conditional probability tables  CPtables  with rows indexed by a and columns by b  e g   see Figure    Note that we use superscripts b    b  to list the distinct values in DomB   We use subscripts b    b  to denote arbitrary values in DomB   often related to replicated variables B    B    Continuous variables can have both discrete and continuous parents  Suppose pa Y     hA  Xi with X   hX            Xd i  The conditional distribution of Y is    Y   A   a  X   x     N     xT   a   a        i e   normally distributed  conditional mean related to x by a linear regression model with coefficients depending on a  Here xT is the transpose of the ddimensional column vector x while  a is an  d     dimensional column vector of regression coefficients  the first entry is the constant term        PRIOR AND POSTERIOR  The network parameters represented by  consist of CPtable parameters b a   regression coefficient vectors  a   and variances a    We assume the prior distribution for  has the following form  e g   see Gelman et al           CPtable rows follow Dirichlet distributions  B a    hb a   b  DomB i  Dir B a    where B a    hb a   b  DomB i    The regression coefficients and variance together have a normal  inverse chi square  distribution      a   a     Nd   a   a   a a      a     a  a     a    I e   dropping subscripts for a moment   conditioned on    is multivariate normal with mean        HOOPER ET AL  vector  and covariance matrix          and        has a   distribution with       not necessarily an integer   Note that        has mean   and variance       Parameters are assumed to be statistically independent except where joint distributions are specified above  In particular  we assume global independence  the parameters determining the conditional distribution of one variable given its parents are independent of all other parameters  The prior is conjugate  given a data set D consisting of n independent replicates of complete tuples of network variables  the prior hyperparameter values are updated as follows  Let nab and na be the number of tuples in D with  A  B     a  b  and A   a  respectively  Let  xi   yi   be the observations of  X  Y   for the na tuples with A   a  Let X a be the na   d      matrix with rows     xTi    Let y a be the column vector with entries yi   In the five equations below  the prior hyperparameter values appear on the right hand side and are identified with tildes  e g      b a   b a   nab a   a   na a a   a a   X Ta X a a a a   a a a   X Ta y a i h       a a   Ta a a   a a    Ta a a   y Ta y a P P The values a b b a and a a are called the effective sample sizes for variables B and Y   respectively  Our adjustments developed in Section   are motivated by large m asymptotics  where m is proportional to the effective sample size for each of the variables  i e     b a   mb a and a   ma    with  b a   a    a   a   a    fixed        Large m asymptotics are similar to but not the same as large n asymptotics  As the sample size n increases  the posterior mean E b a   D    b a   a varies and converges to some value   Here and elsewhere  the dot P subscript indicates summation   a   b b a    Under assumption      the posterior mean remains fixed as m varies       APPROXIMATING A QUERY MEAN  Consider a query involving outcomes of hypothesis variables H given values for evidence variables E  It is convenient to represent the query in terms of a function w H   E g   suppose H   A  E    B  Y    e    b  y   and q      P  A   a   B   b  Y   y      E w A    B   b  Y   y       UAI       where w A      for A   a and w A      otherwise  For discrete networks  query responses q   are usually estimated by q    where     E    D  is the posterior mean of the parameter vector  This plugin estimate usually differs slightly from the posterior query mean E q     D   Cooper and Herskovits        expression     showed that the plug in estimate equals E q     D  e   i e   the posterior query mean given an augmented data set consisting of D and an additional partial observation of the evidence variables E   e  Cooper and Herskovits        derived a formula for E q     D  e  that is valid for discrete  continuous  and hybrid networks  This formula provides a useful approximation of the less tractable E q    D   The plug in estimate is a special case of this formula for discrete networks  The formula is important for our network doubling technique  so is reviewed here  In the integral expression below  Z represents all variables not included in  H  E   dh and dz refer to product measures allowing both integration for continuous variables  Lebesgue measure  and summation for discrete variables  counting measure   Some manipulation yields E q     D  e    E w H    E   e  D    E   E w H    E   e      D       RR R w h  p h  e  z    p    D ddhdz RRR     p h  e  z    p    D ddhdz Now p h  e  z     factors as a product of conditional probabilities and densities  one for each variable in the network  Due to global independence  the inteR gral p h  e  z    p    D d factors into a product of integrals  one for each variable  The result is a product of probabilities and densities described in Section     below  It follows that E q    D  e  can be calculated in essentially the same manner as the function q    but with two modifications   For discrete variables  parameters b a are replaced by their posterior means  If all network variables are discrete  then we have the plug in estimate  E q     D  e    q E    D           For continuous variables  the normal densities are replaced by the St            densities described below  Note that this is not the same as replacing  and    parameters with their posterior means       PREDICTIVE DISTRIBUTIONS  The predictive distribution of the network variables is obtained by integrating out their joint conditional dis    UAI       HOOPER ET AL   tribution given  with respect to the posterior distribution of   Global independence allows this integration to be carried out separately for each conditional distribution of a variable given its parents  The predictive distribution for a discrete variable B is b a    P  B   b   A   a  D    E b a   D     b a    a  The predictive distribution for a continuous variable is a location scale version of the Students t distribution with  degrees of freedom  We need the multivariate form of this distribution in Section    so we define it here  Suppose T      U      Z     where Z and U are independent  Z  Np       U          and  is a nonsingular covariance matrix  It follows that T has the following density function  Johnson and Kotz        page          p               p                 p             t   T    t     We refer to this as the Stp        distribution  For p      we write St             Note that St           is Students t distribution  We claim that  Y   A   a  X   x  D   St            with    a          xT  a   and        a      xT   a a        xT  T           To see this  let us suppress subscripts for a moment  Let Z   N        be independent  of       Put Z               Nm            We then have  Y   a  x  D       xT     Z                 xT  Z     Z        NETWORK DOUBLING  In Section     we noted that E q     D  is usually approximated by the more tractable E q     D  e   Here we propose approximating Var q     D  by Var q     D  e  e   i e   the posterior variance given D and additional replicates E   and E   of the vector of evidence variables  both having the same value e  We develop a formula for this latter variance by imagining a doubled network  see Figure   b   These mean and variance approximations can be improved by adjustments described in Section    Consider two replicated tuples of network variables  conditionally independent and identically distributed given   Use these to replace each variable in the       original network by a pair of variables  e g   B is replaced by B      B    B    with possible values b    b    b     DomB    DomB  DomB   If pa B    A  then pa B      A     A    A     Conditional distributions of doubled variables given parents are obtained by multiplying probabilities or densities for single variables  For discrete variables  we have P  B    b   A   a       b   a  b   a    E g   if A   A  DomA    a    a     and DomB    b    b     then the CPtable for B  is the      array shown in Figure   b   More generally  if a CPtable in the original network involves dr  dc parameters  then corresponding table in the doubled network has d r  d c entries  Note that CPtable rows in the doubled network are not independent  local independence does not hold  and do not have Dirichlet distributions  Fortunately  these properties are not needed for the factorization described following      For continuous variables  the conditional density of Y     Y    Y    given  A   a   X    x     is the product of the densities for two normal distributions of the form     with subscript i        on a and x  Put H     H     H      w  H      w H    w H      E     E     E      and e    e  e   Some manipulation using conditional independence yields q      E w  H      E    e       q     E w H      E    e       We thus have Var q     D  e  e            E q     D  e  e    E q     D  e  e     E w  H      e   D    E w H      e   D      The doubled network satisfies global independence assumptions  so we can follow the approach of Section     to evaluate the two expected values in      To accomplish this task  we need bivariate predictive distributions for the doubled network  For discrete variables  the calculation follows from the means and covariances of a Dirichlet distribution  Let b  b  be the Kronecker delta function  We have b  a     P  B    b   A   a   D    E b   a  b   a    D     b   a  b   a    a  a   b   a   b  b   b   a       a       If all network variables are discrete  then we have an identity corresponding to      Let  be the vector        HOOPER ET AL   of all CPtable entries in the doubled network  e g   b   a  b   a  appears in row a and column b for the CPtable of B    We then have E q        D  e  e    q   E    D         with the entries in E    D  given by the b  a values above  The two expected values in the variance approximation     are calculated by applying     twice  with q        q    and with q        q    For continuous variables  we need the density for   Y    Y      a    a    x    x    D   There are two cases to consider   If a     a    then the parameters   a    a      and   a    a      are mutually independent  Consequently  the joint distribution factors as a product of two St            densities  see expression       If a    a      a  say   then the joint distribution is St         with    a      X   a   and o n    a  X    a a    X T    I     where X   is the         d  matrix whose rows are each     xTi   and I   is the      identity matrix  The derivation is similar to that following      Note that   a   a    is the same for both Y  and Y  in this case      UAI       Table    Summary of approximations for q and qq   Means q    E q     D  e  q    E q     D  e  e  q    q    q   q    q    q   qr  r   verify that the distribution of m Q  q   R  r   converges to bivariate normal by modifying the proof of Theorem   in Van Allen et al          Asymptotic normality implies that   qqrr   qr  qq rr    at rate m     T  v    g Cg    E R  r   Q    Q  q    We use approximations for higher moments motivated by large m asymptotics  i e   a sequence of posterior distributions of the form     with m    One may   qr qq      q     q     q     qq        Switching the roles of Q and R gives qrr        For conciseness we suppress D in our expressions  i e   we implicitly assume that expectations are conditioned on D  Put Q   q     P  H   h   E   e    and R   P  E   e      Note that R is an unconditional query  with hypothesis E   e and no evidence variables  Let q   r   qq   rr   and qr denote the means  variances  and covariance for  Q  R   We extend this notation to higher moments  e g   qqr   E  Q  q     R  r      qr qq  and hence qqr  qqq qr  qq   Now qqq     for normal distributions  however  Van Allen et al         argue that query distributions are usually better approximated by beta distributions  Substituting the third moment of a beta distribution for qqq   we obtain qqr   where g is the gradient vector of q   and C is the covariance matrix of   both evaluated at E    D   The second variance approximation v  is the doubling method introduced in Section    The simple adjustments  q    v    and more complex adjustments  q    v    are developed in this section         while qrr and qqr converge to zero at rate m    We considered approximating qqr and qrr by zero but found that more accurate approximations give better results  Asymptotic bivariate normality suggests  ADJUSTMENTS  We now narrow our focus to discrete networks and consider the four mean and variance approximations in Table    The delta method approximation is  Variances v    delta method     v    Var q     D  e  e  v    expression      v    expression        qr rr      r     r     r     rr        Before proceeding  we observe that r and rr can be calculated exactly because R can be expressed as a sum of products of independent terms  For queries with this property  all approximations  except v    are exact  i e   additional observations of evidence variables have no effect on the posterior mean or variance  E g   given a discrete network with structure P E  B  H  we have q     b h b b e   Since parameters in each product are independent  it follows that q    q    q and v    qq   We begin with adjustments to improve q    Bayes rule and some manipulation yields q      q      E QR  qr   q        E R  r E QR     r qr   qrr   q       E R    r   rr   We approximate qqrr using       qqr by       qr by       q by q    and replace qq by v    Rearranging terms yields the identity  v        r   rr   v     q   q         qr         r   rr    r qr      q     q      q      v     Notice that v  appears in the denominator of       We initially set this value to v    then iteratively solve for v    The values converge in a few iterations  We observe that replacing rr by zero has negligible effect on      as m    By also replacing q  by q  and qr  r by q   q    we obtain a simpler identity  v     v      q   q                  q   q        q     q      q      v     We again initialize by v    then iteratively solve for v    The approximations q  and v  may be preferred to q  and v  since r and rr are not required  Rates of convergence are summarized in Proposition   below  The proof of this result follows easily from Van Allen et al         and the development above  Proposition    Assume a discrete network satisfying     and let m    The query mean q remains constant while the variance qq approaches zero at rate m    The mean approximations have errors qj  q approaching zero at rate m  for j     and    and at the faster rate m    for j     and    All four variance approximations have relative errors  vj qq   qq approaching zero at rate m                Scaled Error q   q   q   q                   Scaled Error       Scaled Error  q    b  Diamond   m             a  NB   m              r qq    r qqr   qqrr E  Q  q    R             E R     r   rr       q   In trying to improve v    we began with the idea of replacing q  with q    This suggests an approximation v     q   q       which does help to reduce the under estimation problem  however  a greater improvement is obtained by further analysis of              The formula for q  in Table   follows from       Now recall that  under condition      r remains fixed while rr    as m    It follows that setting rr     in      will have negligible effect for large m  We thus obtain qr   q   q   r   leading to the simpler q  approximation   E  Q  q      e  e    v     q   q                               q   q   r   r   rr   r     r     rr        r     r     r      r  rr  rr  Scaled Error  If r      then set qr      Otherwise  substituting      for qrr and solving yields qr              HOOPER ET AL         UAI       q   q   q    c  NB   m        q   q   q    d  Diamond   m        Figure    Boxplots of scaled errors m qj  q    for j             m             and network structures NB and Diamond  Each boxplot shows variation in errors for a set of distinct queries              for NB and     for Diamond  Errors for q  and q  are nearly identical  Errors for q  are often much larger  Results for q  are not plotted since q   q     q   q         NUMERICAL RESULTS  We evaluated accuracy of approximations qj and vj using highly accurate empirical estimates of q and qq   These estimates q  and v  were obtained by simulating k       replicates of  from the posterior distribution  evaluating q   for each replicate  then calculating the sample mean and sample variance  Computational costs preclude using empirical variance estipaper R figures mates Users peterhooper Documents Research Doubling in practice  When m is large  asymptotic normality of q   implies that the distribution of v   qq is approximately    k  k with variance   k p Consequently v   qq varies over the interval        k for roughly     of samples  Since our variance approximations have relative errors of order m    it follows that k should be of order at least m  for v  to have substantially smaller relative error  When comparing approximate relative errors  vj  v    v  with k         variation in v  has a noticeable effect for m        see Figure   f   Our examples differ with respect to network structure  posterior distribution  and query  All variables are binary  All posterior distributions satisfy BDe constraints  e g   see Hooper        so all variables have the same effective sample size m  Hyperparameters are thus determined by m and the poste         HOOPER ET AL     E   all children of H  e varies over all combinations     for NB       for NB               Diamond network with   variables         all     distinct queries with one hypothesis variable           Scaled Relative Error                Scaled Relative Error           v   v   v   v   v   v   v                Scaled Relative Error                    Scaled Relative Error  v    b  Diamond   m           a  NB   m       v   v   v   v   v   v   v   v    d  Diamond   m        COMPUTATIONAL ISSUES                 Scaled Relative Error             Approximations for means are compared in Figure   and for variances in Figure    The errors and relative errors are multiplied by m in these figures to facilitate comparisons across a range of effective sample sizes  Boxplots for m            and     are shown  Plots for other values of m are similar  By Proposition    relative errors  vj  qq   qq should approach zero at rates cj  m  where cj depends implicitly on the network  E    D   and the query  This theory is supported by Figure   and additional plots  not shown  comparing the four methods for individual queries  Our results suggest that c   c  while c  and c  tend to be further from zero  Relative errors can be interpreted in terms of variances or standard deviations  If  vj  qq   qq   cj  m  then we have p r vj cj cj cj vj     and            qq m qq m  m          Scaled Relative Error           c  NB   m             UAI       v   v   v    e  NB   m        v   v   v   v   v    f  Diamond   m        Figure    Boxplots of relative errors m vj  v    v  for j                m                  and network structures NB and Diamond  Each boxplot shows variation among values for a set of distinct queries     for NB and     for Diamond  We observe that  relative errors tend to be larger for NB compared with Diamond  v  and v  tend to over estimate qq for NB and are more accurate than v    the three methods v    v   and v  have similar accuracy for Diamond  v  is less accurate than the other methods  The four methods appear to have paper R figures similar accuracy in  f   but these plots are mislead Users peterhooper Documents Research Doubling ing  Many of the Diamond queries have the property described following       where v    v    v    qq   We would therefore expect the Diamond results for m       to be similar to those for m        It appears that the variation among relative errors for m       is due in large part to variation in v    rior means E    D   Our examples are from three small networks  each with one vector E    D  and m                            Two nave Bayes networks  NB   and NB   with   and   features plus the root variable   H   root   Inference in Bayesian networks is in general an NPcomplete problem  Cooper         For instance  the complexity of the Variable Elimination  VE  Algorithm is O dr    where d is an upper bound on the number of values that a variable can take and r is an upper bound on the size of a factor generated by the VE Algorithm  Koller and Friedman         Network doubling uses essentially the same technique to calculate a variance as that used to evaluate a query  resulting in corresponding computational complexity  The doubled CPtables are larger  squared number of rows and columns   so the computational complexity of VE is increased to O d r    The delta method retains O dr   complexity  Van Allen et al          so is typically faster in large networks  see Table   below  In some cases  we can exploit the structure of the network or query to achieve a polynomial time inference algorithm  For poly tree Bayesian networks  i e  networks with at most one undirected path between any pair of nodes   there exist inference algorithms with linear time complexity  Reduced complexity is also available when the query can be expressed in terms of probabilities of hypothesis and evidence nodes conditioned on their Markov blanket  i e   the parents  the children and the parents of the children  Once again  we have a polynomial time inference algorithm  These techniques translate directly to efficient algorithms for computing all of the variance approximations in Table      UAI       HOOPER ET AL   Table    Timing results in seconds  Network NB   Diamond Alarm    Queries                      Delta                       Doubling                            Acknowledgements We are grateful for helpful comments from the anonymous reviewers  We acknowledge support provided by NSERC  iCORE  and the Alberta Ingenuity Centre for Machine Learning  
 A Bayesian net  BN  is more than a succinct  way to encode a probabilistic distribution  it also corresponds to a function used to answer queries  A BN can therefore be evaluated by the accuracy of the answers it returns  Many algorithms for learning BNs  however  attempt to optimize another criterion  usu ally likelihood  possibly augmented with a regularizing term    which is independent of the distribution of queries that are posed  This paper takes the  performance criteria  seriously  and considers the challenge of com puting the BN whose performance   read  accuracy over the distribution of queries    is optimal  We show that many aspects of this learning task are more difficult than the corresponding subtasks in the standard model  INTRODUCTION     Many tasks require answering questions  this model applies  for example  to both expert systems that iden tify the underlying fault from a given set of symp toms  and control systems that propose actions on the basis of sensor readings  When there is not enough information to answer a question with certainty  the answering system might instead return a probabil ity value as its answer  Many systems that answer such probabilistic queries represent the world using a  Bayesian net   BN   which succinctly encodes a dis tribution over a set of variables  Often the underlying distribution  which should be used to map questions to appropriate responses  is not known a priori  In such cases  if we have access to training examples  we can try to learn the model  There are currently many algorithms for learning BNs  Hec    Bun      Each such learning algorithm tries to determine which BN is optimal  usually based   Also  NEC Research Institute  Princeton  NJ  Dale Schuurmans  Inst  for Research in Cognitive Science University of Pennsylvania Philadelphia  PA            daes linc cis upenn edu  on some measure such as log likelihood  possibly aug mented with a  regularizing  term  leading to mea sures like MDL  LB     and Bayesian Information Cri terion  BIC   Sch       However  these typical mea sures are independent of the queries that will be posed  To understand the significance of this  note that we may only care about certain queries  e g   the prob ability of certain specific diseases given a set of ob served symptoms   and a BN with the best  say  log likelihood given the sample may not be the one which produces the appropriate answers for the queries we care about  This paper therefore argues that BN learning algorithms should consider the distribution of queries  as well as the underlying distribution of events  a nd should therefore seek the BN with the best performance over the query distribution  rather than the one that appears closest to the underlying event distribution   To make this point more concrete  suppose we knew that all queries will be of the form p  H I J  B  for some assignments to these variables  e g    Hepatitis  given the possible symptoms Jaundice false and Blood test  true   Given a set of examples  our learner has to de cide which BN  perhaps from some specified restricted set  is best  Now imagine we had two candidates BNs from this set  B   which performs optimally on the queries p  H I J  B   but does horribly on other queries  e g   incorrectly claims that J and E are conditionally independent  has the completely wrong values for the conditional probability of H to the treatment T   Take aspirin     and so on   versus B   which is slightly off on the p  H I J  B  queries  but perfect on all other queries  Here  most measures would prefer B  over B   as they would penalize B  for its errors on the queries that will never occur  Of course  if we re ally do only care about p  H I J  B    this B  over B  preference is wrong  This assumes we have the correct distributions  of both the real world events  e g   quantities like p  H      J       B                and the queries that will be posed  e g       of the queries will be of the form  What is p H h J   j  B  b         will be  What is p  H   hI sl   VI  s    V   s    V           Learning Bayesian Nets that Perfonn Well  etc    Another more subtle problem with the maximal likelihood based measures arises when these distribu tions are not given expl icit ly  but must instead be es timated from examples  Here  we would  of course  like to use the given examples to obtain good esti mates of the conditional probabilities P HjJ  B   In the general maximal likelihood framework  however  the examples would be used to fit all of the param eters within the entire BN  so we could conceivably  waste  some examples or computational effort learn ing the value of irrel evant parameters  In general  it seems better to focus the learner s resources on the relevant queries  but see Section     Our general challenge is to acquire a BN whose per formance is optimal  with respect to the distribution of queries  and the underlying distribution of events  Section   first lays out the framework by providing the relevant definitions  Section   then addresses sev eral issues related to learning a BN whose accuracy  by this measure  is optimal  presenting the computa tional  sample complexities of first evaluating the qual ity of a given BN and then of finding the best BN of a given structure  It then provides methods for hill climbing to a locally optimal BN  We will see that these tasks are computationally difficult for general classes of queries  Section   also presents a particular class of queries for which these tasks are easy  Sec tion   then reflects on the general issue of how to best use knowledge of the query distribution to improve the efficiency of learni ng a good BN under our model  Here we show situations where this information may lead to ways of learning a BN  of a given structure  th at are more sample efficient than the standard ap proach  We first close this section by discussing how our results compare with others   Related Results  The framework closest to ours is  Friedman and Goldszmidt  FG     as they also con sider finding th e BN that is best for some distribution of queries  and also explain why the BN with  say  maximal log likelihood may not be the one with op timal performance on a specific task  In particular  they note that evaluating a Bayesian net B  given a set of training data D     ci  ai          a      under the log likelihood measure  amounts to using the formula LL B D     where B  x  is the probability that B assigns to the event X If all of the queries  however  ask for the value of c given values of  a        an     then only the first summation matters  This means that systems that use LL BID  to rank BNs could do poorly if the contributions of second summation dominate those of the first  The  FG    paper  however  considers only building BNs for classification  i e   where every query is of the specific form p  C   c I A   a          An  an   where C is the only  consequent  variable  and  Ai        is the set of all other variables  their formulation also implicitly assumes that all possible query instances  of complete tuples  will occur  and all are equally likely  By contrast  we do not constrain the set of queries to be of this single form  nor do we insist that all queries occur equally often  nor that all variables be involved in each query  Note in particular that we allow the query s antecedents to not include the Markov blan ket of the consequent  we will see that this restriction considerably simplifies the underlying computation  Each of the queries we consider is of the form  p  X  xI Y   y        where X  Y are subsets of the vari ables  and x  y are respective  ground  assignments to these variables  As such  they resemble the stan dard class of  statistical queries   discussed by Kearns and others  Kea    in the context of noise tolerant learners   In that model  however  the learner is pos ing such queries to gather information about the un derlying distribution  and the learner s score depends its accuracy with respect to some other specific set of queries  here the same p  C   c I At   a           An  an   expression mentioned ab ove    In our model  by con trast  the learner is observing which such queries are posed by the  environment    as it will be evaluated based on its accuracy with respect to these queries   Other researchers  including  FY    Hi if     also com pute the sample complexity for learnin g good BNs  They  however  deal with likelihood based measures  which  as we shall see  have some fundamental differ ences from our query answering b ased model  hence  our results are incomparable     FRAMEWORK  As a quick synopsis  a Bayesian net is a directed acyclic graph  V  E   whose nodes represent variables  and whose arcs represent dependencies  Each node also includes a conditional probability table that spec ifies how the node s values depends  stochastically  on the values of its parents   Readers unfamiliar with these ideas are referred to  Pea      In general  we assume there is a stationary un derlying distribution P over the N variables V    Vt         VN     I e   p Vt   V t        VN   VN      and L        vN p  Vt   Vt          VN   VN        For example  perhaps vl is the  disease  random variable  whose value ranges over  healthy  cancer  flu         V  is  gender  E  male  female   V  is  body temperature  E              etc  We will refer to this as the  underly ing distribution  or the  distribution over events   A statistical query is a term of the form  p  X  x I Y   y        where S  T C V are  possibly empty  subsets of V  and x  resp   y  is a legal assignment to the elements of X  resp  Y   We let SQ be the set of all    course  other groups have long been interested in this idea  cf   the work in finding statistical answers from database queries         Greiner  Grove  and Schuunnans  possible legal statistical queries  and assume there is a  stationary  distribution over SQ  written sq  X  x  Y y   where sq X x  Y y  is the probability that the query  What is the value of p  X   xI Y   y     will be asked  We of course allow Y       here we are requesting the prior value of X  independent of any conditioning  We also write sq  x  y  to refer to the probability of the query  p  X  x I Y   y        where the variable sets X and Y can be inferred from the context  While all of our results are based on such  ground  statistical queries  we could also define sq  X  Y  to refer to the probability that some query of the gen eral form  p  X   xI Y   y       will be asked  for some assignments x  y  we could assume that all assignments to these unspecified variables are equally likely as queries  Finally  to simplify our notation  we will often use a single variable  say q  to represent the entire  X x  Y y  situation  and so will write sq  q  to refer to sq  X x  Y  y   As a simple example  the claim sq  C   A       An     states that our BN will only be used to find clas sifications C given the values of all of the variables  Ai   Notice this is not asserting that p  C   c I A    a         An   an       for any set of assignments  c  ai    If all variables are binary  this corresponds to the claim that sq  C   c  A    a           An   an       n l for each assignment  Alternatively  we can use sq  C  A   A   A          sq  C  A   A         and sq  D   C      A     A           and sq  D  C      A       A            to state that     of the queries involve seeking the conditional probability of C given the observed values of the   attributes  A  A   A        involve seeking the probability of C given only the   attributes  A    A         seek the probability of  the different  consequent   D given that C    A    and some observed value of A   and the remaining     seek the probability of D given that C      A      and some observed value of A    correlated  or at least  not in any simple way  with the value of the conditional probabilityp  X xI Y   y   The fact that the underlying p     is stationary sim ply means that the query sq         has a determi nate answer given by the true conditional probability p  X  xI Y   y  E         In general  we call each tuple  X x  Y  y  p X x I Y y   a  labeled sta tistical query    Now fix a network  over V  B  and let B xI y    B  X   xI Y   y  be the real value  probability  that B returns for this assignment  Given distribu tion sq      over SQ  the  score  of B is   errsq p   B      L sq x y  B xly  p xly    x y       where the sum is over all assignments x  y to all sub sets X  Y of variables   We will often write this simply err  B  when the distributions sq and pare clear from the context   Note this depends on both the underly ing distribution p    over V  and the sq     distribution over queries SQ                   If each of the N variables has domain         then the SQ distribution has    N  parameters  because each variable Vi E V can play one of the following   roles in a query         vv        vv  r            vv    c                Notice that we assume that sq       can be  in general  completely unrelated top  I   because the probabil ity of being asked about sq  X  x   Y   y   need not be   sq X x  Y y   is  legal   ifp Y y         Note also that we use CAPITAL letters to represent single variables  lowercase letters for that values that the vari  ables might assume  and the boldface font when dealing  with sets of variables or values   effJ B         L  IQI  X  Y  p EQ   B xly   p    be the  empirical score  of the Bayesian net  For comparison  we will later use KL  B   to refer to the Kullback Liebler di Ld p  d  log vergence between the correct distribution p     and the distribution represented by the Bayesian net B    Given a set D of event tuples  we can approximate fn   L dED log   this score using KLD  B  Note     that small KL divergence corresponds to the large  log likelihood  and     that neither KL  B  nor  D KL  B  depend on sq                 Finally  let SQ  C SQ be the class of queries whose  consequent  is single literal X    V   and whose  antecedents  Y are a superset of V s Markov blanket  with respect to the BN B  we will call these  Markov blanket queries       We avoid degeneracies by assuming Y n X         A query  Given a set of labeled statistical queries Q   xi  Yii Pi  i we let  LEARNING ACCURATE BAYES IAN NETS  Our overall goal is to learn the Bayesian Net with the optimal performance  given examples of both the un derlying distribution  and of the queries that will be posed  i e   instances of  VI   VI        VN   VN  tuples and instances of SQ  possibly labeled     Any Bayesian net B  that encodes the underlying distribution p      will in fact produce the optimal performance  i e   err  B   will be optimal   However  the converse is not true  there could be nets  Observation     Learning Bayesian Nets that Perfonn Well       whose performance is perfect on the queries that inter est us  i e   err  B        but which are otherwise very different from the underlying distribution   I  in the general SQ case  or to estimate KLD  B  from incomplete tuples D  CH    RBKK     as here the Bayesian net computations are inherently intractabl e  We will see these parallels again below   From this observation we see that  if we have a learn ing algorithm that produces better and better approxi mations t o p    as it sees more training examples  then in the limit the sq    distribution becomes irrelevant   Another challenge is computing the sample complexity of gathering the information required to compute the score for a network  It is easy to collect a sufficient number of examples if we are considering learning from labeled statistical queries  Here  a simple application of Hoeffding s Inequality  Hoe    shows     Given a small set of examples  however  the sq     dis tribution can play an important role in determining which BN is optimal  This section considers both the computational and sample complexity of this under lying task  Subsection     first considers the simple task of evaluating a given network  as this informa tion is often essential to learning a good BN  Subsec tion     then analyses the task of filling in the optimal CP tables for a given graphical structure  and Subsec tion     discusses a hill climbing algorithm for filling these tables  to produce a BN whose accuracy is locally optimal           Theorem  Let     B       L     MLSQ  q p ESLsQ   B  q    p    be the empirical score of the Bayesian net B  based on set SLSQ of  a  MLSQ      MLsQ f       o      D  It is easy to compute the estimate KL   B  of KL  B     based on examples of complete tuples D drawn from the p    distribution  In contrast  it is hard to com pute the estimate   B  of err  B  from general statistical queries   in fact  it is not even easy to approximate this estimate        ln  J       labeled statistical queries  drawn randomly from the sq    distribution and labeled by p      Then  with probability at least      eLsQ  B  will be within    of err  B   i e   P   errS LsQ  B   err  B  I   t     o  where this distribution is over all sets of MLsQ e   J  I randomly drawn statistical queries    COMPUTING err B              Rot    DL     It is  P hard  to compute er Q   B  over a set of general queries Q C SQ  It is NP hard to even estimate this quantity to within an additive factor of      I  Theorem  The reason is that evaluating the score for an arbi trary Bayesian network requires evaluating the poste rior probabilities of events in Q  which is known to be difficult in general  In fact  this is hard even if we know the distribution p    and consider only a single  known  form for the query    Note  however  that this computation is much easier in the SQB case  because there is an trivial way to evaluate a Bayesian net on any Markov blanket query  Pea     and hence to compute the score  There is an obvious parallel between estimating  en O   B  when dealing with SQB queries Q   and estimating KL D    B  from complete tuples D   Hec      both tasks are quite straightforward  basically because their respective Bayesian net computations are simple  Similarly  it can be challenging to compute errQ   B     A more challenging question is  What if we only get unlabeled queries  together with examples of the un derlying distribution  Fortunately  we again need only a polynomial number of  unlabeled  query examples  Unfortunately  we need more information before we can bound on the number of event examples required  To see this  imagine sq    puts all of the weight on a single query  i e   sq  X       Y            Hence  a BN s accuracy depends completely on its perfor mance on this query  which in turn depends critically on the true conditional probability p  X      Y         The only event examples relevant to estimating this quantity are those with Y      of course  these ex amples only occur with probability p  Y        Un fortunately  this probability can be arbitrarily small  Further  even if p  Y                the true value of p X   II Y      can still be large  e g   if X is equal to Y  then p  X   II Y         even if p  Y      l  n   Hence  we cannot simply ignore such queries  as sq  X  x  Y y  can be high   nor can we assume the resulting value will be near     as p  X x I Y  y  can be high              We can still estimate the score of a BN  in the following on line fashion  Theorem of  to a satisfiability problem  and thus  P hard problems are at least as difficult  as  problems in NP   First  let SsQ  MsQ E      Roughly speaking   P is the class of problems corre  sponding to counting the number of satisfiable assignments             sq  Xi            E  ln  Yi     i be  a  set     J  Proofs for all new theorems  lemmas and corollaries  appear in   GGS            Greiner  Grove  and Schuurmans  unlabeled statistical queries drawn randomly from the sq      distributzon  Next  let Sn be the set of  com plete  examples sequentially drawn from the underlying distribution p     until it includes at least         f u Mn          In   MsQ f   cl  instances that match each Yi value  notice Sn may require many more than Mb examples   The  legal query  requirement p  Yi      insures that this col lection process will terminate  with probability     Fi nally  letp So  x   y    be the empirically observed es timate of p  Xi I Yi     based on this Sn set  Then  with probability at least         e f l sq Sn B            L    B  xly   p Sv  xly   SsQ   x y E sq S  f  of err  B   err B   f       J   will be within  i e    r  P   erP    Sn  B     I  We can  moreover  get an a priori bound on the total number of event examples if we can bound the proba bility of the query s conditioning events  That is   Corollary   If we know that all queries encountered  sq  x  y    satisfy p  y         for some         then we need only gather MD   o     max      M   ln           ln     sg     complete event examples  along with  MsQ f                    ln  J       COMPUTING OPTIMAL CP tables FOR A GIVEN NETWORK STRUCTURE  The structure of a Bayesian net  in essence  specifies which variables are directly related to which others  As people often know this  causal  information  at least approximately   many EN learners actually be gin with a given structure  and are expected to use training examples to  complete  the BN  by filling in the  strength  of these connections   i e   to learn the CP table entrie s  To further motivate this task of   fitting  good CP tables to a given BN structure  note that it is often the key sub routine of the more general EN learning systems  which must also search through the space of structures  This subsection addresses both the computational  and sample  complexity of finding this best  or near best  CP table  Subsection     next suggests a more practical  heuristic approach  Stated more precisely  the structure of a specific is a directed acyclic graph  V  E  with nodes V and edges E C V x V  There are  of course   uncountably  many BNs with this structure  corre sponding to all ways of filling in the CP tables  Let LW V  E  denote all such BNs   B ayesi an net  We now address the task of finding a BN B E whose score is  with high probability   near  minimal among this class   i e   find B such that  LW V  E   err  B      E     min  B  El  II V E   err  B    with probability at least    J  for small t   J      As in Subsection      our learner has access to either labeled statistical queries drawn from the query distribution sq    over SQ  or unlabeled queries from sq      to gether with event examples drawn from p          example queries  to obtain an E close estimate  with probability at least     J  I Of course  as   can be arbitrarily small  e g   o  l  n  or worse   this Mn bound can be arbitrarily large  in terms of the size of the Bayesian net  Note also that the Friedman and Yakhini  FY    bound similarly depends on  skewness  of the distribution  which they define as the smallest non zero probability of an event  over all atomic events   Two final comments      Recall that these bounds de scribe only how many examples are required  not how much work is required  given this information  Unfor tunately  using these examples to compute the score of a BN requires solving a  P hard problem  see The orem        The sample complexity results hold for estimating the accuracy of any system for represent ing arbitrary distributions  not just BNs     Hoffgen  Hof    was able to avoid this dependency  in certain  log loss  contexts  by  tilting  the empirical dis tribution to avoid   probability atomic events  That trick does not apply to our query based error measure   Unfortunately this task   like most other other in teresting questions in the area   appears computa tionally difficult in the worst case  In fact  we prove below the stronger result that finding the  truly  opti mal Bayesian net is not just NP hard  but is actually non approximatable     Assuming P   j   NP  no polynomial time algorithm  using only labeled queries  can com pute the CP tables for a given Bayesian net structure whose error score is within a sufficiently small addi tive constant of optimal  That is  given any structure  V  E  and a set of labeled statistical queries Q  let B v E  Q E BIV V E  have the minimal error over Q   Theorem  i e    VB   E    N V E   e    Q B V E  Q       B     Then  assuming P  f  NP  there is some       such that no polynomial time algorithm can always find a solution within   of optimal  i e   no poly time algorithm can always return a B  v E  Q such that  er rQ B  E  Q    B V E  Q             I  In contrast  notice that the analogous task is trivial in   Learning Bayesian Nets that Perform Well the log likelihood framework  Given complete train ing examples  and some beni gn assumptions   the CP table that produces the optimal maximal likelihood BN corresponds simply to the observed frequency es timates  Hec     However  the news is not all bad in our case  Although the problem may be computationally hard  the sample complexity can be p oly nom ial   That is  under certain conditions  see below   if we draw a polynomial num ber of labeled queries  and  somehow   find the BN B t ha t gives minimal error for tho se queries  then with hi gh probability B will be within t of optimal over the ful l distribution sq        We conjecture that the sample complexity result is true in general  However  our results below uses the following annoying  but extremely benign  technical restriction  Let T  y I sq  x  y       be th e set of all conditioning events that might appe ar in queries  often Twill simply be the set of all events   For any    c        define  J NTl   N  V  E      N  BE   N V E  IVy E T B y    l      to be the subset of BNs that assign  to each condi ti on in g event  a probability that is bounded below by N the doubly exponcnttally small number l  c    Recall th at N   IV   the number of variables   We now restrict our attention to these Bayesian nets      Theorem   Consider any Bayesian net structure  V  E   requiring the specification of K CP table entries CPT   q lrdh l  K  Let B  E I  Af    cN  V  E  be the BN that has minimum em   pirical score with respect to a sample of  MsQ t o       b   log     Klog      NKlog   c logE    labeled statistical queries from sq     Then  with prob ability at least     J  B  will be no more than t worse   than Bopt  where Bopt is the BN with optimal score among   NTl   N  V  E  with respect to the full dis tribv tion sq       I   This theorem is nontrivial to prove  and in particular is not an immediate corollary to Theorem    That earlier result shows how to estimate the score for a  Conceivably    although we  conjecture  otherwise    there could be some sets of queries and some graphs  V  E   such that the best performance is obtained with extremely  small CP table entries  e g   of order  o l             But note  that numbers this small can require doubly exponential precision just to write down  so such BNs would perhaps be  impractical anywayr   Our result assumes that  even if such  BNs do allow improved performance  we are not interested in them        single fixed BN  allow in g   p robabilit y of error  But since B  is chosen after the fact  i e   to be opt imal on the training set  we cannot have the same confidence  that we have estimated its score correctly  Instead  we must use sufficiently many examples so that the simultaneously estimated scores for all  uncountably many  B  E BN T   l  eN  V  E  are all within E of the true values  with collective probability of at most J that there is any error  Only then can we be confident about B  s accuracy   See pro of in  GGS        As i n Sect ion      we can also consider the slightly more complex task of lea rn in g the CP table entries f ro m unlabeled st ati sti cal queries sq  X   x  Y   y     augmented with examples of the underlying distribu tion p      However  as above  this is a straightfor ward extension of th e  learning from labeled s tatist i cal query  case  one firs t draws a slightly larger sam ple of unlabeled statistical queries  and then uses a sufficient sample of domain tuples to accurately esti mate the lab el s for each of these queries  h enc e sim ulating the effect of drawin g fewer   but still suffi ciently many   labeled statistical queries   Here we encounter the s am e caveats that each of the unlabeled statistical queries sq  X  x   Y  y  must involve con ditioning events Y   y that occur with some nontrivial probability p  Y y       for otherwise one could not put an no ntri vial upper bound on the number of tu ples needed to learn a good setting of the CP table entries   A detailed statement and proof of this r e sult is a straightforward exte nsio n of Theorem    so we omit the details here   See  GGS           The point is that  from a sample complexity per sp ec  tive  it is fe asibl e to learn near optimal settings for the CP table entries in a fixed Bayesian network structure under our mod el  The only difficult part is that actu ally computing these optimal entries from  a polyno mial number of  training samples is hard in g ener al  cf   Theo rem    In fact  we will see  in Section    that it is not correct to simply fill each CP table entry with the frequency es timat es       HILL CLIMBING  It should not be surprising that finding the optimal CP tables was computationally hard  as this problem has a lot in common with the challenge of l e arn in g the KL       bes t network  given partially specified tuples  a task for which people often use iterative steepest ascent climbing methods  RBKK     We now briefly consider the analogous approach in our setting   Given a single labeled statisti cal query   x  y  p  xI y      consider how to change the value of the CP table entry  qlr   whose current value is eqlr  We use th e follow in g lem ma     Let B be a Bayesian net whose CP table includes the value eQ qiR r   eqjr E        as the value for the conditional probability of Q   q given R   r  Let sq  X   Y  be a statistical query  to which  Lemma   Greiner  Grove  and Schuurrnans       B assigns the probability B  X I Y   Then the deriva  tive of B  X I Y   wrt the value  eq r   is  d err X  Y    B  d eqlr   B X Y  p  B X Y     B X Y       eqlr  dB X  Y  deqlr      B XfY   B q  r  X  Y  B q rjY   eqlr As       produced the score B X I Y  here  the error for this single query is ffi X Y   B   B  X   Y    p      To compute the gradient of this error value  as a func tion of this single CP table entry  using Equation      B     am XY      B  d eqlr  thus  letting  C          B XjY   p   dB XfY  d eqlr    B   X I Y   p   we get   dB  XjY  deqlr           c     B q r  XJY   B XJY B q r  Y   eqlr c   B X J Y   B  q r I X  Y  B q r I Y        eqlr  We can t en   lse his derivatie t update the eq r   value  by htll chmbmg m the d rect  n of the gradi ent  i e   gradient ascent    Of course  Equation   pro vides only that component of the gradient derived from a single query  the overall gradient for eq r will in    volve summing these values of all queries  or perhaps all queries in some sample   Furthermore  we must constrain the gradient ascent to only move such that eq   r remains as    i e   the sum of probabilities of  L   all possible values for Q  given a particular valuation for Q s parents  must sum to     However  the tech niques involved are straightforward and well known  so we omit further analysis here   Notice immediately from Equation   that we will no t update eqlr  at least  not because of the query  sq  X  Y   if the difference B  X I Y   p is    i e   if B  X I Y   is correct  or if B q  r I X  Y    B  q  r I Y  is    i e   if Y  d separates  X and q  r   both of which makes intuitive sense   Unfortunately  we see that evaluating the gradient re quires computing conditional probabilities in a BN  This is analogous to to th e known result in the tra ditional model  RBKK     It thus follows that it can be  P hard to evaluate this gradient in general  see Theorem     However  in special cases  i e   BNs for which inference is tractable   efficient computation is possible  One demonstration of this is the class of  Markov bl anket queries  SQB  recall the definition at the end of Section     Carrying out the gradient computation is easy i this case  Here when updatin the  qlr  entry  Y e can  gnore queries sq  X  Y  if  qJr  is outside of  ts Markov blanket  We therefore need only consider the queries sq  X  Y  where  Q  U R C XU Y and moreover  when Q q is consistent with X s assign ment  for these queries  the gradient is    which follows from Equation   using B  q  r I X  Y        q  r is consistent with X s claim  recall we ignore sq X  Y  otherwise   and observing that B q rj Y  reduces to B  X I Y   as the part of   Q  U R already in Y is irrelevant  Notice Equation   is simple to com pute  as it involves no non trivial Bayesian net com putation  see the simple algorithms in  Pea  J    as     HOW CAN THE QUERY DISTRIBUTION HELP   Our intuition throughout this paper is that having ac cess to the distribution of queries should allow us to learn better and more efficiently than if we only get to see domain tuples alone  Is this really true  Note that the simplest and most standard approach to learning CP table entries is simply filling in each CP table entry with the observed frequency estimates  OFE  obtained from p     Note that this ignores any information about the query distribution  Unfor tunately  OFE is not necessarily a good idea in our model  even if we have an arbitrary number of ex amples  This follows immediately from Theorem    If the standard OFE algorithm was always success ful  then we would have a trivial polynomial time al gorithm for computing a near optimal CP table for a fixed Bayesian net structure   which cannot be  un less P    Yes  Observation   does claim that the optimal BN is a faithful model of the event distribu tion  meaning in particular that the value of each CP table entry  qlr  can be filled with the true probability p q I r    However  this claim is not true in general in the current context  where we are seeking the best CP table entries for a given network structure  as this network structure might not correspond to the true conditional independence structure of the underlying distribution p       NP      In the case where the BN structure does not corre spond to the true conditional independence structure of the underlying p      ignoring the query distribution and using straight OFE can lead to arbitrarily bad   results   Example      Suppose the EN structure is simply A  t X  t C  and the only labeled queries are  C  A       and  C  A         I e   A   C with proba bility    and we are only interested in querying C given A or A   Suppose further that the intervening X is completely independent of A and C  i e   p  X I A  p  X  A  p  C I X  p  C IX        Note that this BN structure is seriously wrong                     Learning Bay esian Nets that Perfonn Well  In this situation  the EN that most faithfully follows  the event distribution  Bp  would have CP table en e x    t   ec x   e q x      with a per tries e x i A  s core of err  Bp            Recall that ex l A s the CP table entry that specifies the probability of X given that A holds  etc   Now consider Bsq   whose ent ies are exiA   eCix     and e x   Ji   eqx             formance    make X   A and C         X   While Bsq clearly has the X  dependencies completely wrong  its score is        e      perfect  i e    err   Bsq             I  Thus  filling CP table entries with observed frequency estimates   or using any other technique that con verges to Bp   leads to a bad solution in this case  no matter how many training examples are used  On the other hand  consider a learning procedure that  knowing the query distribution   ignores the X vari able completely and directly estimates the conditional probabilities p  A I C   and p  A     C   before filling in the CP table entries  i  e   which is isomorphic to B       This would eventually learn a perfect classifier  Of course  such a procedure might have to be based on the  impractical  learning techniques developed in Theo rem    or p erhaps  more realistically  use the heuristic hill climbing strategies presented in Section      What about the case when the proposed network structure is correct  Here we know that the standard OFE approach eventually does converge to an optimal CP table setting for any query distribution   Observa tion       So  unlike the case of an incorrect structure  there is no reason in the large sample size limit to con sider the query distribution  But what about the more realistic situation  where the sample is finite  The question then is  Given that the known structure is correct  can we exploit knowing the true query distribution  There is one simple sense in which the answer can certainly be yes  It is clearly safe to to restrict our attention to those nodes of the BN that are not d separated from every query variable by the condition ing variables that appear in the queries  That is  if a B N B contains the edge U  V  and the query  The same issue is relevant to understanding the re striction in Theorem   to BNT   l  cN  V  E    One might  consider removing this restriction by assuming that all con ditioning events y E T have significant probability accord ing to p       i e    they are not too unlikely  a la Corol lary       But Theorem   does not make this assumption  for an important reason  Note that  if we are not directly interested in queries about p  y     then the BN we use to answer queries is not constrained to agree with p  y     In particular  if it helps to get better answers on the queries that do occur  the optimal BN Bopt could  conceivably   set  Bopt  y  to be extremely small  knowing that p  y   is p erhaps large is j ust irrelevan t   Our theorem  which in sead assumes that the former quantity is not too small  simply would not be helped by  what might seem to be more natural  restrictions on p  y      Figure     Bayesian network structure for Example       Naive Bayes      distribution sq  X   x   Y   y  i s such that  for ev ery query  p  X   x I Y   y          both U and V are d separated from X by Y  then we know that the CP table entry e v l u cannot affect B s answer to the query  B  X I Y    Thus  it seems clear that we do not need to bother estimating evJu here  Now suppose we have a learning algorithm that uses a computed sample size bound  which grows with the number of parameters to be estimated  in order to provide certain perfor mance guarantees  Here  our knowledge of the query distribution will reduce the effective size of the BN  which will allow us to stop learning after fewer sam ples  Thus  using the query distribution can give an advantage here  although only in a rather weak sense  the basic learning technique might still amount to fill ing in the CP table entries with frequency estimates obtained from the underlying distribution p      the only win is that we will know that it is safe to stop earlier because a small fragment of the network is rel evant    Can one do better than simply filling in CP table entries with frequency estimates  given that the BN structure is correct  As we now show  this question does not seem to have a simple answer  Motivated by Example      one might ignore the EN structure in general  and just directly estimate the con ditional probabilities for the queries of interest  Note that this is guaranteed to converge to an optimal solu tion  eventually  even if the BN structure is incorrect  However  it can be needlessly inefficient in some cases  especially if the postulated BN structure is known to be correct  This is because the BN structure can pro vide valuable knowledge about the distribution        Consider the standard  Naive Bayes   model with n     binary attributes C  A            An such that the Ai are conditionally independent given C   Example  see Figure      Suppose the single query of interest is        If      A               An       we attempt to learn this probability directly  we must wait for the  possibly very rare  event that A    A          An      it is easy to construct situations where this will require an exponential  expected  number of examples  However  if we use the EN structure  we can compute the required probability as soon as we have learned the     probabilities p C      and    p  C       I A       n        Greiner  Grove  and Schuunnans    CONCLUSIONS  Remaining Challenges  There are of course several other obvious open questions   Figure    Bayesian network structure for Example        Reverse Naive Bayes       p A    O I C   O     p A    O I C       for all i   If p C      is near       these probabilities will all be learned accurately after relatively few samples   I  This example might suggest that we should always try to learn the B N as accurately as possible  and ignore the query distribution  e g   just use OFE     However  there are other examples in which this approach would hurt us   First  the analyses above assume that we had the EN structure  and simply had to fill in the values of the CP tables  In general  of course  we may have to use the examples to learn that structure as well  The obvi ous approach is to hill climb in the discrete  but combi natorial space of BN structures  perhaps using a sys tem like PALO  Gre      after augmenting it to climb from one structure S  to a  neighboring  structure Si b if Si b filled with some CP table entries  appears better than S  with  near  optimal CP table values  over a distribution of queries  Notice we can often save computation by observing that  for any query q  B  and B  will give the same error scores B    q     B    q   if the only differences between B  and B  are outside of q s Markov blanket  The second challenge is how best to accommodate both types of examples  queries  possibly labeled    and do main tuples  As discussed above  sq    examples are irrelevant given complete knowledge of p     Obser vation     Similarly  given complete knowledge of the query distribution  we only need p     information to provide the labels for the queries    Example        Consider the  reverse   EN structure from Example        where the arrows are now directed A   t C instead of C  t Ai  Figure     and assume we are only interested in queries of the form   P  C I           Here the strategy that estimates p  C   c   di rectly  hence  ignoring the given EN structure  domi nates the standard approach of estimating the CP table entries  To see this  note that for any reasonable train ing sample size N    n   the frequency estimates for most of the  n CP table entries eel a           an will be un defined  Even using Laplace adjustments to compen sate for this  the accuracy of the resulting EN estimate B  C cl       will be poor unless p  C   c   happens to be near       So  for example  if the true distribu tion p     is such that C   A     parity A         A n     and p  A               then p  C       will be equal to       But here the EN estimator  using Laplace ad justments  will give a value of B  C   I I                  for any training sample size N      n   whereas the direct strategy will quickly converge to an accurate estimate P C                    Note that the standard maximum likelihood EN estimator will not even give a defined value for E  C   I I       in this case  since most of the possible a             a n patterns will remain unobserved                 In general  the question What should we actually do if the BN structure is known  or assumed  to be correct  and we are training on a  possibly small  sample of complete instances  remains open  and is an interesting direction for future work asking  in essence  should we trust the given EN structure  or the given query distribution  The previous two examples suggest that the answer is not a trivial one    Of course  these extreme conditions are seldom met  in general  we only have partial information of either distribution  Further  Example       illustrates that these two corpora of information may lead to differ ent BNs  We therefore need some measured way of combining both types of information  to produce a B N that i s both appropriate for the queries that have been seen  and for other queries that have not even if this means degrading the performance on the observed queries   That is  the learner should not  overfit  the learned BN to just the example queries it has seen  it should be able to  extend  the BN based on the event distribution     Contributions   As noted repeatedly in Machine Learning and elsewhere  the goal of a learning algo rithm should be to produce a  performance element  that will work well on its eventual performance task  SMCB    KR      This paper considers the task of learning an effective Bayesian net within this frame work  and argues that the goal of a EN learner should be to produce a BN whose error  over the distribution of queries  is minimal   Our results show that many parts of this task are  un fortunately  often harder than the corresponding tasks when producing a BN that is optimal in more familiar contexts  e g    maximizing likelihood over the sampled event data   see in particular our hardness results for evaluating a BN by our criterion  Theorem       for fill ing in a EN structure s CP table  Theorem       and for the steps used by the obvious hill climbing algorithm trying to instantiate these tables   Note  however  that   Learning Bayesian Nets that Perform Well Learning  Algorithm   Structure is  OFE  Correct Incorrect  QDt  Correct Incorrect    OFE     Computational Efficiency  Correct convergence  in the limit   Small sample   easy   Yes  Obs    No  Ex           QD  Ex        Yes       FE  Ex           N P hard to approx   Th           Yest  Observed Frequency Estimates  or any other algorithm that tries to match the event distribution     QD uses the CP table that i s  best  for given query distribution  using samples from the distribtion to  label queries   QD will produce the BN that has minimum error  for this structure   Our examples illustrate cases in which one  algorithm   OFE  QD  is more sample efficient than the other      Table    Issues when Learning from Distributional Samples our approach is robustly guaranteed to converge to a BN with optimal performance  while those alterna tive techniques are not   Fortunately  we have found that the sample requirements are not problematic for our tasks  see Theorems         and Corollary     given various obvious combination o f example types  we also identify a significant subclass of queries  SQs  in which some of these tasks are computationally easy  We have also compared and contrasted our proposed approach to filling in the CP table entries with the standard  observed frequency estimate  method  and found that there are many subtle issues in deciding which of these  algorithms  works best  especially in the small sample situation  These results are summa rized in Table     We p lan further analysis  both theo retical and empirical  towards determining when this more standard measure  now seen to be computation ally simpler  is in fact an appropriate approximation to our performance based criteria  
  These values  referred to as query responses  clearly de pend on the training sample used to instantiate the param  A Bayesian Belief Network  BN  is a model of  eter values   i e   different training samples will produce  a joint distribution over a finite set of variables   different parameters and hence different responses   with a DAG structure to represent the immedi  This paper investigates how sampling variability in the  ate dependencies between the variables  and a set of parameters  aka CPTables  to represent the  training data is related to uncertainty about a query re  local conditional probabilities of a node  given  sponse  We follow the Bayesian paradigm  where uncer  each assignment to its parents  In many situa  tainty is quantified in terms of random variation  and we  tions  the parameters are themselves treated as  present a technique for computing Bayesian credible in  random variables  reflecting the uncertainty re  tervals  aka  error bars   for query responses  Our algo  maining after drawing on knowledge of domain  rithm takes as inputs a belief net structure  which we as  experts and or observing data generated by the  sume is correct  i e   an accurate   map of true distribu  network  A distribution over the CPtable param  tion  Pea      a data sample generated from the true belief  eters induces a distribution for the response the  net distribution  and a specific query of the form   What is  BN will return to any  W hat is  Q    Pr  HIE      Pr  H     hIE    e       After determining the  This paper investigates the distribution  conditional  posterior  distribution of the belief net param  of this response  shows that it is asymptotically  eters given the sample  the algorithm produces an estimate  query    posterior mean value  of Q  e g   estimate Q to be  asymptotic variance  We show that this compu  To quantify uncertainty about this estimate  the algorithm  tation has the same complexity as simply com  computes an approximate posterior variance for Q and uses  puting the  this variance to construct error bars  a Bayesian credible in   mean value of the  response  i e    O n exp w    ables and  w  where  n  terval  for Q  e g   assert that Q is in the interval  is the number of vari  is the effective tree width   with     probability   We  also provide empirical evidence showing that the            There are several obvious applications for these error bars   error bars computed from our estimates are fairly  First  error bars can help a user make decisions  especially  accurate in practice  over a wide range of belief  in safety critical situations   e g   take action if we are  net structures and queries        sure that Q    Pr  H     hIE    e     is on one  side of a decision boundary  Second  error bars can     Introduction  can make appropriate guarantees about the answers to cer  model of a joint probability distribution  are used in an ever increasing range of applications  Hec     nets  are  typically  built by  Be  first finding an ap  propriate structure  either by interviewing an expert  or by  selecting  a  good model  from training  data    then using a training sample to fill in the parame ters  sug  gest that more training data is needed before the system  Bayesian belief nets  BNs   which provide a succinct  lief        normal  and derives expressions for its mean and   Hec     T he resulting belief net is then used to an  swer questions  e g   compute the conditional probability  tain queries  This information is especially valuable when additional training data  while available  is costly  and its acquisition needs to be justified  Similarly  the user might decide that more evidence is needed about a specific in stance  before he can render a meaningful decision   Fi  nally  if an expert is available and able to provide  correct answers  to some specific questions  error bars can be used to validate the given belief net structure  E g   if the expert claims that Q         but our algorithm asserts that Q is in   UAJ       VAN ALLEN ET AL      a I                                       G l  x   x   Figure      o       Simple Example  Diamond Graph  the interval            with       probability  then we may question whether the structure provided is correct  as suming we believe the expert   By contrast  we might not question this structure if our algorithm instead asserted that Q is in the interval            with       probability  Section   provides background results and notation con cerning belief nets and Dirichlet distributions for belief net parameters  Section   presents the theoretical results under lying our error bars  a derivation of an approximate poste rior variance for a query probability Q  and a proof that the posterior distribution of Q is asymptotically normal  Com putational issues related to calculation of the variance are briefly discussed  Section   presents the results of an em pirical study using Monte Carlo simulations to validate our error bar methodology over a wide range of belief net struc tures and queries  Section   briefly surveys related work  placing our results in context            Belief nets and Dirichlet distributions  We encode the joint distribution of a vector of discrete ran dom variables X    Xv vEV as a belief net  aka Bayesian network  probability net   A belief net  V  A     is a directed acyclic graph whose nodes V index the random variables and whose arcs A represent dependencies  Let Pa v  C V be the immediate parents of node v  and let Fv    Xw wEPa v  be the corresponding vector of parent variables  In a belief net  a variable Xv is independent of its nondescendents  given Fv  The elements of the vector   are the CPtable entries  Let Xv and Fv   TiwEPa v Xw be the domains of Xv and Fv We assume that the domains are finite  The CPtable for Xv contains IXvl X IFvl entries  v xJf Figure   provides a simple example of a belief network with specific CPtable entries  Here X  has no parents  so we write F       We have F        Xt   Fa   Xt   F      X   Xa   and for each value a  b  c  d  we have    al    Pr  xl   a IE    e  bJa   Pr  x    b I Xt   a  E     and e  djb c   Pr   x    d I x    b  X a   c  e      Hence  using Figure    we have                Note that the values in each row add up to    In general  the variables need not be binary  but can have larger  finite  domains  The CPtable entries are estimated using training data and  possibly  expert opinion  The latter information is incor porated using the Bayesian paradigm  where   is mod eled as a random variable and expert opinion is expressed through an a priori distribution for    We adopt indepen dent Dirichlet priors  for the various CPtable rows  Specit cally  let  vl      v zl  xEX  denote the CPtable row for Fv   f  e g   e J                                 denotes the entries for the X  variable associated with the parental assignment X      and X       We assume that  be fore observing the training data  the evil are independent  Dir  a        x E Xv   random vectors  where a            An absence of expert opinion is often expressed by setting a  xlf     for all  v x  f   e g     J   o    Dir  I       which yields a uniform  flat  prior  Stronger opinion is expressed through larger values of a  v x     Expressions for the mean and variance of a Dirichlet distribution are given below  Now suppose that the training data consist of m indepen dent replicates of vectors X  generated using the given structure and a fixed set of CPtable entries e  Let mv xlf denote the number of cases in the training set with  Xv  Fv     x  f   Under the posterior distribution  the conditional distribution given the training data   the E  vlf are independent Vir  O v zl  x E Xv  random vectors  with O v xlf   a  xlf   m v xlf  BFH     This posterior distri bution underlies our derivation of Bayesian credible inter vals  Several properties of the Dirichlet distribution will be needed  Setting O v  J    l  xEXv O v xJ f the posterior means and  co variances for CPtable entries are  BFH         E G v xJf      Cov  v zJ   v yJ       f lv xlf  O v zl              O v  J  llv xjt c xy  llv yJf      O v  J       Readers unfamiliar with these assumptions  or with Dirichlet  distributions  are referred to  Hec     Note that a Dirichlet distri bution over a binary variable is a Beta distribution    VAN ALLEN ET AL          if x    y and c  y     otherwise  The ran Elvlf are asymptotically normal  in the limit as min  av xl    t oo  Aki     More precisely  the nor malized variables    av   f  v x J     Lv xJJ  converge in  where  c xy    dom vectors  distribution to jointly normal random variables with mean zero and covariances  J tv xJJ o y  J tv yJJ    This asymp  totic framework is applicable as the amount of training data increases   v xJJ   m   t oo  provided all of the CPtable entries  are positive  This condition occurs with probability  one under a Dirichlet prior      Bayesian Credible Intervals for Query Re sponses  It is well known that the CPtable entries determine the  joint distribution of X   Pr  Xv   Xv  v  E  vIe      I vEV ev x  II   where   vlvEV is determined by  xv   vEV   see  Pea     Users are typically interested in one or more  specific  queries  asked of this joint distribution  where a query is expressed as a conditional probability of the form Q     q B      Pr H hiE e e          UAI      partial derivatives  Let Pv  h  x fIe  denote the probabil  ity  Pr  H  h  Xv   x  Fv  fIE  e  e and let pv  x   f     f       le  Pv h f le  pv f le   andp h le  be  defined in a similar manner  Note that the subscript  v  is  Xv or F u is involved  and all probabilities are evaluated at e     Let q    zl denote the partial derivative  q B   Bv zlf evaluated at      IL We will use the following identity  derived by needed to identify the node when      GGS    DarOO      qv zlf  Pv h x f le    p h le pv x f le  J tv zlf       We now derive an expression for  i       S   and demonstrate  asymptotic validity of the credible interval  Equation      given a sufficiently large training sample     We assume that   is a random vector with posterior Dirichlet distribution described in Section    and approximate the variance of Q q    by  Theorem     where H and E are subvectors of X  and h and e are legal  assignments to these subvectors  Note also the dependency one  In our Bayesian context  Q is a random variable with a  the oretically  known distribution determined by the posterior  ij  the posterior mean J LQ    E  Q    the iden tity  CH        E  q     Set It    defined  E E    where the components  by Equation  J tv zJ   of     are      W hile a point estimate    Q     q t   can be useful  one  often requires some information concerning the potential error in the estimate   In the Bayesian context  this can  be achieved by plotting the posterior distribution of Q  Alternatively  one may construct a           r     cally not analytically tractable  but simple approximations We  ill show that the distribution of Q is  w  approximately normal  and derive an approximation i Q for  the standard deviation of Q  We then propose the following interval as an approximate        J LQ       r    credible interval   zo   ifQ   where zo      I              is the upper standard normal distribution        J    value of the  Our derivation is based on a first order Taylor expansion of  q E    about  q J     Some notation is needed to express the     Bvf    av  Jf                Pv h x  Je  p hle pv x f e P   J t v  zlf  Consider an asymptotic framework where the poste rior means J tv xlf are fixed  positive values  and min   nv zl   T hen the random variable    oo   Q  J LQ   i Q converges in distribution to the standard nonnal distribution  Proof  Our proof uses the Delta method  sider the Taylor expansion  credi  ble interval for Q  i e   an interval  L  U  defined so that Pr  L      Q      U       o  Exact calculations are typi  are available   L  T his value can be calcu  q  E E       vEV  E Fv  where  distribution of e  For a point estimate of Q  one may use  lated using  L L  Avt     q        q fJ     D      BFH     Con  R   where  D  L L L q l l   E v zlf    Jv z f     vEV  E Fv zEXv       and the remainder term R can be expressed in terms of the matrix of second derivatives of q  e  evaluated at a pointe between Band J t  Since the variances for E u zJ  in EqUCJ tion   are of order   av zlf   t    and since the second derivatives remain bounded in a neighbourhood of f i  the remainder R is asymptotically negligible compared with D    b  We define to be the variance of D  Equation     As the CPtable rows El vlf are statistically independent  but   UAI      VAN ALLEN ET AL   e ntries within a row are correlated  the variance of be expressed as  D  can       Table    Gold Standard for Validity Estimates d  After substituting Equation   for the covariances and sim plifying  we obtain Equation   with  L  q xlt   Lx vlf   Avf  A substitution of Equation   then yields the equivalent ex pressions or Avt and Bvt within Equation     Dfuq                   Mean                        Std Dev                        q xlf in time O n w    see  DarOO   Given these deriva tives  the summations in Equation   can be performed with one additional pass over the values  of time    n    The extended paper  VGHOl  describes an algorithm for computing UQ  The main challenge  computing all of the derivatives q xlf  is accomplished by  back propagat ing  intermediate  results obtained by the Bucket Elimina tion  Dec    algorithm   We observe that is a random variable with mean   and variance    It remains to show that D   ijQ is asymp totically normal  This result follows from the asymptotic multivariate normality of the components of    after suit able standardization  see Section     and the fact that D   is a linear function ofEl    VGHOl  also provides additional comments on the proper interpretation and application of this theorem   There are exceptional situations where the posterior distribution of q    is analytically tractable and exact credible intervals are available  In the degener ate situation where the network structure has arcs connect ing all pairs of nodes  and hence imposes no assumptions about conditional independence   the assumption of inde pendent Dirichlet distributions for CPtable rows is equiva lent to an assumption of a single Dirichlet distribution over unconditional probabilities Pr  Xv   Xv  v E V   It is then straightforward to derive the distribution of the query probability using properties of the Dirichlet distribution  see  Mus      Note that this exact approach is not cor rect in general i e   it does not hold for networks with non trivial structure            Empirical Study  Theorem   proves that the interval   LQ  z   uq is asymp totically valid  More precisely  let  Degenerate Case      The computational problem of computing J LQ   q p   is known to be NP hard  Coo     when all variables Xv are binary  the most effective ex act algorithms require time O n w   where n   lVI is the number of nodes and w is the induced tree width of the graph  Dec    LS     The variance uq can also be com puted in time O n w   This result follows from the exis tence of algorithms that can compute all of the derivatives Computational Issues   Assuming a uniform prior and a sample of size m  we can compute the posterior variance of Pr  HIE  as P HIE  x   F HIE      m x P E       where F x  is the expected value of x  wrt the given belief net   This follows from a dimensionality argument  in a non trivial structure  the  n dimensional vector of unconditional probabili ties is constrained to lie in a lower dimensional submanifold of t e  n    dimensional simplex  This cannot be represented by a smgle Dirichlet distribution because  wpl  the constraints would not be satisfied       be the probability that the query response Q falls outside of the credible interval  based on our UQ estimate of standard deviation  Equation    The values   o and    are the nominal and actual coverage probabilities for the credible interval  The value is a function of o  the graph  V  A   the query q  and the posterior distribution of    The pos terior distribution depends on the prior distribution and the training sample  Thus typically varies from one applica tion to the next  While Theorem   implies that  o when the training sample is sufficiently large  it does not tell us whether this approximation is valid in practice  particularly for small samples  In general  the validity of the approxi mation depends on all of the factors determining   We carried out a number of experiments to assess how these factors affect validity        Given a fixed set of factors  we estimate the correspond ing by a simple Monte Carlo strategy  Using the  fixed  posterior distribution of    calculate ILQ and uq  Simulate r replicates ei from the posterior distribution  calculate Qi   q      then let    be the proportion of the  Qi  with IQ    LQI   Zof UQ  In our experiments  each  was based on r     replicates        To quantify the validity of the approximation employ average absolute differences  validity estimate     average I    Jl     o  we       The absolute differences are averaged as we vary one or more of the the factors determining   The validity es timates are presented as percentages in our tables  When   VAN ALLEN ET AL        Diamood Gqaph Qu riat wit   lilO  E rorBa   Ee  r        m  UAI            Analyiic  r    QyeryII OnM   Mon le Carlo        D             lo    i                      QO      Figure     Results for the Diamond Graph  We studied the following inferential patterns in the dia mond graph  Figure I   Pr Xl       IE    Q    Pr X       IX        IX X   Qi           el ll         E           E    Q      Pr Xt  Q  Qs     IIX       E   Pr X X    IX     E   Pr X   Q                    Standard Normal Ouanmea             B  QQ plot showing relation to Normal J E                        The resulting validity es timates are listed in Table    Each cell in the table is an average of    values   Figure   A  shows the error bars returned by our approx imation  and also the Monte Carlo system  on a random network posterior  for the error bars for     credible inter vals  We see the two methods give similar answers  Figure   B  uses a quantile quantile  QQ  plot to address the validity of the normality assumption  independently of the linear approximation  Each  line  in this figure corre sponds to z scores of the     query responses generated by our Monte Carlo simulation  plotted against standard normal quantiles  This figure shows six such lines  each corresponding to a single query in   Q          Q    given a sample of size m     A straight line would correspond to data produced by a  perfect  normal distribution  we see each dataset is close   Of course  this is only suggestive  the real proof comes first from Theorem    and then from the data  e g   Table    which demonstrates that our approach  which assumes normality  produces reasonable results                La e  lla e    o       e      e  qt e   IO  La e  tla e  t a e    o                       Lb c e  t b c e  bll es c   e   IO L   b c e  llb c e  bla e  cla e    o     Pr X           A  Examples of Error Bars   viewing these values  it is helpful to have a gold standard for comparison  Consider the validity estimate          for a single    l  The minimum expected value is obtained when    l    S  i e   when       has the Binomial lOO  S  distribu tion  Table   presents means and standard deviations under these ideal circumstances  Now suppose a validity estimate is obtained by averaging k independent terms  Its standard deviation is typically greater than the value Std Dev   v k suggested by Table   because there is usually variation in the underlying  values              IXt        E       L o c    tlb c    olt    cll  The six queries cover a range of different inferential pat terns  The first is basically a  sanity check   as it is a triv ial inference  the fourth is also straightforward  although it does involve a multiplication  The sixth is slightly more complex  but it is still only a summation of a set of prod ucts  The remaining queries involve divisions of increas ingly complicated expressions  For each m E                    we carried out    trials of the form      generate E  from a uniform Dirichlet prior distribution      generate a training sample of size m based on E  and use the result to obtain a posterior dis tribution      generate     Monte Carlo replicates from the posterior distribution and use these to obtain an esti mate    for each pair  Q  J   for Q E  QI        Q   and       Results for Alarm Network  The Alarm network  BSCC    is a benchmark network based on a medical diagnosis domain  commonly used in belief network studies  The network variables are all dis crete  but many range over   or more values  The network includes a CPtable for each node  i e   a particular   is spec ified  Table   summarizes the results for experiments on the Alarm network  where we varied both J and m  For each m  we generated a single random sample of size m from    and used this to determine a posterior distribution  as suming a uniform prior   Validity estimates were obtained by averaging over randomly chosen queries  The queries Pr H  hIE  e     were chosen by determining an as signment H   h to one randomly chosen query variable  and assignments E   e to five randomly chosen evidence variables   Here  we used  HC    to determine which vari         VAN ALLEN ET AL   UAI      Table    Results for Random Networks  E  H          Table    Results for Diamond Graph m  Ql  Q                                                                                                                                                                                                                                                                                                                                                                                                                                                          Q   Q   Q   Q                                                                                                                                                                                                                       fJ                                                                                                                                   abies could be query as opposed to evidence variables   Some or all of the evidence variables might have had no effect on the query variable  others might have had a pro found effect  Each cell in Table   represents an average from     queries on a single posterior distribution        Results for Random Networks  Although random networks tend not to reflect typical  or natural  domains  they complement more focussed studies by exposing methods to a wide range of inputs and help to support claims of generality  We carried out experiments on networks with    binary variables and    links  gener ating gold models from a uniform prior distribution on e  and generating random queries of various types  Here we used sample size m        throughout  and varied the type of query  Table   displays the results of our experiments  Each query was of the form Pr H  hIE  e      with varying dimensionalities forE and H  Let  E and  H denote the number of variables comprising E and H  re spectively  Each cell of Table   is based on     trials  I   queries on    networks  with both structure and posterior generated randomly                                                                                                                                                                                                                                                                                                                                                                                                                           S                                     Table    Results for Alarm Network m                                                                                                                                                                         Discussion  Our hypothesis was that our Bayesian error bars algorithm would be accurate for essentially all cases  We tried to falsify our hypothesis by varying the following experimental factors    Network structure  V  A     Credibility level      Query type  Diamond network  Alarm     Number of evidence variables  Random networks     Number of query variables  Random networks      c   In no case did we observe a result where averagelto    exceeded      In most cases  the validity estimate was less than      As noted in Table    even if our error bars were exact  we would still get positive validity estimates due to the variance in to about   We therefore believe that these results comfortably bound the expected error of our method under the experimental conditions   None of the factors that we manipulated had a profound effect  T he strongest ef fect  observed in Table    was that increasing the number of variables assigned in a query tended to increase the er ror I     see also  Kle     One possible explanation is that  as  E and  H increase  the query function q tends to become more complex  and the local linear approxima tion of q becomes less reliable  Another possibility is that        VAN ALLEN ET AL        the query probability  Q  tends to become very small  mak  UAI      bution over CPtables  but for different purposes  For exam  ing the normal approximation less accurate  Further exper  ple  Cooper and Herskovits  CH    use it to compute the  iments could address this issue   expected response to a query  by contrast  we also approx  We found these results very encouraging   Our method  appears to give reasonable error bars for a wide range of queries and network types   This makes the technique a  promising addition to the array of data analysis tools re lated to belief networks  especially as the algorithm is rea sonably efficient   only  roughly doubling the computation time per inference  W hile there may be pathological cases  imate the posterior variance in that response  Similarly  while many BN learning algorithms compute the posterior distribution over CPtables  Hec     most of these systems seek a single set of CPtable entries that maximize the like lihood  which again is different from our task   e g    their  task is not relative to a specific query  but see  GGS      Many other projects consider sensitivity analyses  provid  where our method will not give reasonable results   per  ing mechanisms for propagating ranges of CPtable values  haps because the local linear approximation and the asymp  to produce a range in the response  cf    BKRK    Las     totic normality are far off the truth   we  did not find such  CNKE    DarOO   W hile these papers assume the user is explicitly specifying the range of a local CPtable value  our  cases in our experiments   work considers the source of these variances based on a Other Experiments   We also ran a number of other ex  periments  One set computed the average  A      data sample  This also means our system must propagate  scores  all of the  ranges   most other analyses consider only prop  in each situation  to determine if there was any systematic  agating a single range  The  DarOO  system is an excep     bias   Note this score differs from Equation   by not tak  tion  as it can simultaneously produce all of the derivatives   ing absolute values   We found that our bounds were typi  However  Darwiche does not consider our error bar appli  cally a bit too wide for most queries  i e   we often found the        a interval included slightly more than          of the  cases  We are currently investigating this  to see if there are straight forward refinements we can incorporate   cation  and so does not include the additional optimizations we could incorporate  Excluding the  DarOO  result  none of the other projects provides an efficient way to compute that information   We also computed error bars based on the  incorrect    Also  some of those other papers focus on properties of   complete structure  assumption  which implies the re  this derivative   e g   when it is  sponse will have a simple Dirichlet distribution  see Foot  able entry   note  ately from our expression  Equation     Finally  our anal     We found that  as anticipated  the approach de  scribed in this paper  using Equation    consistently out     for some specific CPt  Note that this information falls out immedi  ysis holds for arbitrary structures  by constrast some other  performed that case  in that our approach was consistently  results  e g    CNKE     deal only with singly connected  closer to the Monte Carlo estimates   networks  trees     VGHOl  discusses these results in detail   It also inves  Lastly  our analysis also connects to work on abstractions   tigates techniques for dealing with extreme values  where  which also involves determining how influential a CPtable  the normal distribution may be sub optimal   entry is  with respect to a query  towards deciding whether     typically computational efficiency in computing that re  to include a specific node or arc  GDSOl   Their goal is  Related Work  sponse  By contrast  our focus is in computing the error Our results provide a way to compute the variance of  bars around the response  independent of the time required  a BN s response to a query   to determine that result   which depends on the  posterior distribution over the space of CPtable entries  based on a data sample  method   BFH      This is done using the  Delta  first determine the variance of each  CPtable row  then propagate this variance using a sensi tivity analysis   i e   the partial derivatives   see Equation     Kleiter  Kle    performs a similar computation  parts of his analysis are more general  in that he considers incomplete      discuss how to deal structures      show how to deal  data  However  he does not  with  general graphical  with  the correlations encountered with general Dirichlet distri butions  nor       provide an efficient way to compute this  information  Moreover  our empirical data provide addi tional evidence that the approximations inherent in this ap proach are appropriate  even for small sample sizes  Several other researchers also consider the posterior distri      Conclusion  Further Extensions   Our current system has been im  plemented  and works very effectively  There are several obvious ways to extend it   One set of extensions corre  spond to discharging assumptions underlying Theorem      computing error bars when the data was used to learn the structure  as well as the parameters  dealing with param eters that are drawn from a distribution other than inde pendent Dirichlets  perhaps even variables that have con tinuous domains  dealing with a training sample whose instances are  not completely specified   Our work deals  with fully parameterized CP tables  It would be interesting to investigate techniques capable of dealing with CPtables   UAI      VAN ALLEN ET AL   represented as  say  decision tree functions  BFGK     etc  Contributions  Many real world systems work by rea soning probabilistically  based on a given belief net modeL When knowledge concerning model parameters is condi tioned on a random training sample  it is useful to view the parameters as random variables  this characterizes our uncertainty concerning the responses generated to specific queries in terms of random variation  Bayesian error bars provide a useful summary of our current knowledge about questions of interest  and so provide valuable guidance for decision making or learning   This paper addresses the challenge of computing the error bars around a belief net s response to a query  from a Bayesian perspective  We first motivated and formally de fined this task  finding the         o   credible interval for a query response with respect to its posterior distribu tion  conditioned on a training sample  We then investi gated an application of the  Delta method  to derive these intervals  This required determining both the covariance matrix interrelating all of the parameters  and the derivative of the query response with respect to each parameter  We produced an effective system that computes these quanti ties  and then combines them to produce the error bars  The fact that our approximation is guaranteed to be cor rect in the limit does not mean it will work well in practice  We therefore empirically investigated these claims  by test ing our system across a variety of different belief nets and queries  and over a range of sample sizes and credibility levels  We found that the method works well throughout   Acknowledgements We are grateful for the many comments and suggestions we received from Adnan Darwiche and the anonymous review ers  and for the fairness of the UAI     programme chairs  All authors greatfutly acknowledge the generous support provided by NSERC  iCORE and Siemens Corporate Re search  Most of this work was done while the first author was a student at the University of Alberta  
 Belief Propagation  BP  is one of the most popular methods for inference in probabilistic graphical models  BP is guaranteed to return the correct answer for tree structures  but can be incorrect or non convergent for loopy graphical models  Recently  several new approximate inference algorithms based on cavity distribution have been proposed  These methods can account for the effect of loops by incorporating the dependency between BP messages  Alternatively  regionbased approximations  that lead to methods such as Generalized Belief Propagation  improve upon BP by considering interactions within small clusters of variables  thus taking small loops within these clusters into account  This paper introduces an approach  Generalized Loop Correction  GLC   that benefits from both of these types of loop correction  We show how GLC relates to these two families of inference methods  then provide empirical evidence that GLC works effectively in general  and can be significantly more accurate than both correction schemes      Introduction Many real world applications require probabilistic inference from some known probabilistic model  Koller   Friedman         This paper will use probabilistic graphical models  focusing on factor graphs  Kschischang et al          that can represent both Markov Networks and Bayesian Networks  The basic challenge of such inference is marginalization  or maxmarginalization  over a large number of variables  For discrete variables  computing the exact solutions is Appearing in Proceedings of the    th International Conference on Machine Learning  Edinburgh  Scotland  UK        Copyright      by the author s  owner s    NP hard  typically involving a computation that is exponential in the number of variables  When the conditional dependencies of the variables form a tree structure  i e   no loops   this exact inference is tractable  and can be done by a message passing procedure  Belief Propagation  BP   Pearl         The Loopy Belief Propagation  LBP  system applies BP repeatedly to graph structures that are not trees  called loopy graphs   however  this provides only an approximately correct solution  when it converges   LBP is related to the Bethe approximation to free energy  Heskes         which is the basis for minimization of more sophisticated energy approximations and provably convergent methods  Yedidia et al         Heskes        Yuille         A representative class of energy approximations is the region graph methods  Yedidia et al          which deal with a set of connected variables  called regions   these methods subsume both the Cluster Variation Method  CVM   Pelizzola        Kikuchi        and the Junction Graph Method  Aji   McEliece         Such region based methods deal with the short loops of the graph by incorporating them into overlapping regions  see Figure   a    and perform exact inference over each region  Note a valid region based methods is exact if its region graph has no loops  A different class of algorithms  loop correction methods  tackles the problem of inference in loopy graphical models by considering the cavity distribution of variables  A cavity distribution is defined as the marginal distribution on Markov blanket of a single  or a cluster of  variable s   after removing all factors that depend on those initial variables  Figure   b  illustrates cavity distribution  and also shows that the cavity variables can interact  The key observation in these methods is that  by removing a variable xi in a graphical model  we break all the loops that involve the variable xi   resulting in a simplified problem of finding   A Generalized Loop Correction Method  o  j     w        v  i  L  I  T  K    Y u  W  j     w  t Z  J  v  L  K    Y u  j w  t Z  J  v  m    k    s  W  L  I  T    i     S m    k    s  W  i I  T       o     S    m    k    s  o        S      J  K    Y u  t Z         Figure    Part of a factor graph  where circles are variables  circle labeled i corresponding to variable xi   and squares  with CAPITAL letters  represent factors  Note variables  xi   xk   xs   form a loop  as do  xk   xu   xt    etc   a  An example of absorbing short loops into overlapping regions  Here  a region includes factors around each hexagon and all its variables  Factor I and the variables xi   xj   xk appear in the three regions r    r    r     Figure just shows index  for region r    Region based methods provide a way to perform inference on overlapping regions   In general  regions do not have to involve exactly   variables and   factors    b  Cavity variables for xs are  xw   xj   xk   xu   xv    shown using dotted circles  We define the cavity distribution for xs by removing all the factors around this variable  and marginalizing the remaining factor graph on dotted circles  Even after removing factors  T  Y  W    the variables xv   xw   and xj   xk   xu still have higher order interactions caused by remaining factors  due to loops in the factor graph   c  Cavity region r     j  s  k  includes variables shown in pale circles  Variables in dotted circles are the perimeter r    Removing the pale factors and marginalizing the rest of network on r    gives the cavity distribution for r     the cavity distribution  The marginals around xi can then be recovered by considering the cavity distribution and its interaction with xi   This is the basis for the loop correction schemes by Montanari   Rizzos        on pairwise dependencies over binary variables  and also Mooij   Kappens        extension to general factor graphs  called Loop Corrected Belief Propagation  LCBP   This paper defines a new algorithm for probabilistic inference  called Generalized Loop Correction  GLC   that uses a more general form of cavity distribution  defined over regions  and also a novel message passing scheme between these regions that uses cavity distributions to correct the types of loops that result from exact inference over each region  GLCs combination of loop corrections is well motivated  as regionbased methods can deal effectively with short loops in the graph  and the approximate cavity distribution is known to produce superior results when dealing with long influencial loops  Mooij   Kappen         In its simplest form  GLC produces update equations similar to LCBPs  indeed  under a mild assumption  GLC reduces to LCBP for pairwise factors  In its general form  when not provided with information on cavity variable interactions  GLC produces results similar to region based methods  We theoretically establish the relation between GLC and region based approxi   mations  for a limited setting  Section   explains the notation  factor graph representation and preliminaries for GLC  Section   introduces a simple version of GLC that works with regions that partition the set of variables  followed by its extension to the more general algorithm  Section   presents empirical results  comparing our GLC against other approaches      Framework      Notation Let X    X    X            XN   be a set of N discretevalued random variables  where Xi  Xi   Suppose their joint probability distribution factorizes into a product of non negative functions    Y P  X   x     I  xI   Z IF  where each I                 N   is a subset of the variable indices  and xI    xi   i  I  is the set of values Q in x indexed by the subset I  Each factor I   iI Xi        is a non negative function  and F is the collection of indexing subsets I for all the factors I   Below we will use the term factor interchangeably with the function I and subset I  and the term variable interchangeably for the value xi and index i  Here Z is the partition function    A Generalized Loop Correction Method  This model can be conveniently represented as a bipartite graph  called the factor graph  Kschischang et al          which includes two sets of nodes  variable nodes xi   and factor nodes I   A variable node xi is connected to a factor node I if and only if i  I  We use the notation N  i  to denote the neighbors of variable xi in the factor graph  i e   the set of factors defined by N  i      I  F   i  I   To illustrate  using Figure   a   N  j     I  T  S  and T    j  s  w   Q We use the shorthand A  x     IA  xI   to denote the product of factors in a set of factors A  For marginalizing all possible values of x except the ith variable  notation  X we define theX f  x     f  x   x i  xj Xj  j  i  Similarly for a set of variables r  we use the notation P to denote marginalization of all variables apart x r from those in r   r  is defined over by r  as  X Y X the variables indexed F  N  r   x    I  xI   P  r  x r    x   r  x   r  I N    r   Here the summation is over all variables but the ones indexed by r  In Figure   c   this is the distribution obtained by removing factors N  r       I  T  Y  K  S  W   from the factor gaph and marginalizing the rest over dotted circles  r    The core idea to our approach is that each cavity region r can produce reliable probability distribution over r  given an accurate cavity distribution estimate over the surrounding variables r  Given the exact cavity distribution P  r over r  we can recover the exact joint distribution Pr over r by  Y Pr  xr    P  r  x r  N  r   x    P  r  x r   I  xI     IN  r        Generalized Cavity Distribution The notion of cavity distribution is borrowed from socalled cavity methods from statistical physics  Mezard   Montanari         and has been used in analysis and optimization of important combinatorial problems  Mezard et al         Braunstein et al          The basic idea is to make a cavity by removing a variable xi along with all the factors around it  from the factor graph  Figure   b    We will use a more general notion of regional cavity  around a region  Definition A cavity region is a subset of variables r              N   that are connected by a set of factors  i e   the set of variable nodes r and the associated factors N  r      N  i    i  r  forms a connected component on the factor graph  For example in Figure   a   the variables indexed by r     j  k  s  define a cavity region with factors N  r       I  T  Y  S  W  K  Remark A cavity region is different from common notion of region in region graph methods  in that a cavity region includes all factors in N  r   and nothing more   while common regions allow a factor I to be a part of a region only if I  r  The notation r     i  I   I  N  r   denotes the cavity region r with its surrounding variables  and r    r   r denotes just the perimeter of the cavity region r  In Figure   c   the dotted circles show the indices r     o  i  m  t  u  v  w  and their union with the pale circles defines r    Definition The Cavity Distribution  for cavity region  In practice  we can only obtain estimates P  r  x r   of the true cavity distribution P  r  x r    However  suppose we have multiple cavity regions r    r            rM that collectively cover all the variables  x            xN    If rp intersects with rq   we can improve the estimate of P  rp  x rp   by enforcing marginal consistency of Prp  xrp   with Prq  xrq   over the variables in their intersection  This suggests an iterative correction scheme that is very similar to message passing  In Figure   a   let each hexagon  over variables and factors  define a cavity region  here r            r    Note r  can provide good estimates over  j  s  k   given good approximation to cavity distribution over  o  i  m  t  u  v  w   This in turn can be improved by neighboring regions  e g   r  gives a good approximation over  i  o   and r  over  i  m   Starting from an  r initial cavity distribution P     for each cavity region                    We perform this improvement for all cavity regions  in iterations until convergence   r  When we start with a uniform cavity distribution P  p for all regions  the results are very similar to those of CVM  The accuracy of this approximation depends on  r the accuracy of the initial P  p   Following Mooij         we use variable clamping to estimate higher order interactions in r  Here  we estimate the partition function Zx r after removing factors in N  r  and fixing x r to each possible assignment  Doing this calculation  we have P  r  x r    Zx r   In our experiments  we use the approximation to the partition function provided using LBP  However there are some alternatives to clamping  conditioning scheme Rizzo et al         makes it possible to use   A Generalized Loop Correction Method  any method capable of marginalization for estimation of cavity distribution  clamping requires estimation of partition function   It is also possible to use techniques in answering joint queries for this purpose  Koller   Friedman          Using clamping for this purpose also means that  if the resulting network  after clamping  has no loops  then Pr  xr   is exact  hence GLC produces exact results if for every cluster r  removing r results in a tree   sistency condition  X X Prp xrp N rp N rq   x    Prq xrq N rp N rq   x     x  rp q  x  rp q       which we can use to derive update equations for mqp   Starting X from the LHS of Eqn       Prp  xrp  N  rp  N  rq    x      rp q Xx   r P  p  x  rp  N  rp   N  rq    x        Simple Case  Partitioning Cavity Regions To introduce our approach  first consider a simpler case where the cavity regions r            rM form a  disjoint and exhaustive  partition of the variables             N    Let rp q      rp    rq denote the intersection of the perimeter rp of rp with another cavity region rq    Note rp q    rq p    As r            rM is a partition  each perimeter rp is a disjoint union of rp q for q           M  some of which might be empty if rp and rq are not neighbors   Let N b p  denote the set of regions q with rp q      We now consider how to improve the cavity distribution estimate over rp through update messages sent to each of the rp q   In Figure   a   the regions r    r    r    r    r     r   form a partitioning  Here  r  with  m  k  s  w   r    receives updates over r       m  from r  and updates over r       k  from r    This last update P P ensures x  k  Pr   xr      x  k  Pr   xr     Towards enforcing this equality  we introduce a message m    x r      into distribution over r    Here  the distribution over rp becomes  Prp  xrp     rp  P    x  rp  N  rp    xrp    Y  mqp  x  rp q          qN b p   where Prp denotes our estimate of the true distribution Prp   The messages mqp can be recovered by considering marginalization constraints  When rp and rq are neighbors  their distributions Prp  xrp   and Prq  xrq   should satisfy X  X  Prp  xrp      x rp rq  Prq  xrq     x rp rq  As   mqp  x  rp q   X   r  P  p x  rp N rp  N rq   x   Y  rp q     mq  p  x  rp q        x  rp q  q N b p  q     q  Setting this proportional to the RHS of Eqn      we have the update equation mnew qp  x  rp q    Prq  xrq  N  rp  N  rq    x    P   x  rp q  P   rp  P   x  rp q  P    x  Prq  xrq  N  rp  N  rq    x    x  rp q  P  Q  mqp  x rp q    rp  N  rp   N  rq    x  q   N b p  q     q  Prp  xrp  N  rp  N  rq    x    mqp  x  rp q         x  rp q  The last line follows from multiplying the numerator and denominator by the current version of the message mqp   At convergence  when mqp equals mnew qp   the consistency constraints are satisfied  By repeating this update in any order  after convergence  the Pr  xr  s represent approximate marginals over each region  The following theorem stablishes the relation between GLC and CVM in a limited setting  Theorem   If the cavity regions partition the variables and all the factors involve no more than   variables  then any GBP fixed point of a particular CVM construction  details in Appendix A  is also a fixed point for GLC  starting from uniform cavity distribu r tions P        Proof in Appendix A   Corollary   If the factors have size two and there are no loops of size   in the factor graph  for single variable partitioning with uniform cavity distribution  any fixed points of LBP can be mapped to fixed points of GLC   x rp rq  We can divide both sides by the factor product N  rp  N  rq    x   as the domain of the factors in N  rp    N  rq   is completely contained in rp  rq and independent of the summation  Hence we have X  mq  p  x  q   N b p   x  rp q     Generalized Loop Correction  Y  Prp xrp  N rp N rq   x      X x rp rq  Prq xrq  N rp N rq   x   rp q  rp  rq   this implies the weaker con   Proof If there are no loops of size   then no two factors have identical domain  Thus the factors are all maximal and GBP applied to CVM with maximal factor domains  is the same as LBP  On the other hand  refering to CVM construction of Appendix A  under the given condition  GLC with single variable partitioning shares the fixed points of GBP applied to CVM   A Generalized Loop Correction Method  with maximal factors  Therefore GLC shares the fixed points of LBP     o  i     i   m   Theorem   If all factors have size two and no two factors have the same domain  GLC is identical to LCBP under single variable partitioning  Proof Follows from comparison of two update equations  i e   Eqn     and Eqn     in  Mooij   Kappen        under the assumptions of the theorem       General Cavity Regions When cavity regions do not partition the set of variables  the updates are more involved  As the perimeter rp is no longer partitioned  the rp q s are no longer disjoint  For example in Figure    for r  we have r       o  i   r       i  m   r       t  u   r       v  w  and also r       i   r       m   r       m  t   r       t   etc  This means xi appears in messages m     m   and m     Directly adopting the correction formula for Pr in Eqn     as a product of messsages over rp q could double count variables  To avoid this problem  we adopt a strategy similar to CVM to discount extra contributions from overlapping variables in rp   For each cavity region rp   we form a rp  region graph  Figure    with the incoming messages forming the distributions over top regions  For computational reasons  we only consider maximal rp q domains   here  this means dropping m   as r     r    and so on  Our region graph construction is similar to CVM  Pelizzola         i e   we construct new sub regions as the intersection of rp q s  and we repeat this recursively until no new region can be added  We then connect each sub region to its immediate parent  Figure   shows the r   region graph for the example of Figure   a   If the cavity regions are a partition  the rp  region graph includes only the top regions  Below we use Rp to denote the rp  region graph for rp   RO p to denote its top  outer  regions  and brp  x   to denote the belief over region  in rp  region graph  For top regions  the initial belief is equal to the basic messages obtained using Eqn      Next we assign counting numbers to regions  in a way similar to CVM  top regions are assigned cn  rp q        and each sub region  is assigned using    This does not noticably affect the accuracy in our experiments  When using uniform cavity distributions  the results are identical    o     m  t     t  u    m     v  w    t   Figure    The r   region graph consisting of all the messages to r    The variables in each region and its counting number are shown  The upward and downward messages are passed along the edges in this r   region graph   the Mobius formula  X cn            A    cn      where A   is the set of ancestors of   We can now define the belief over cavity regions rp as   rp  Prp  xrp    P   rp  N  rp    xrp     x  Y  brp  x  cn         Rp  This avoids any double counting of variables  and reduces to Eqn     in the case of partitioning cavity regions  To apply Eqn     effectively  we need to enforce marginal consistency of the intersection regions with their parents  which can be accomplished via message passing in a downward pass  Each region   sends to each of its child   its marginal over the childs variables  X     x      brp  x    x    Then set the belief over each child region to be the geometric average Y of the incoming messages    brp  x          x    pr       pr    The downward pass updates the child regions in Rp   RO p   We update the beliefs at the top regions using a modified version of Eqn      brp  x rp q    P  Prq xrq N rq N rp  xrq    x  rp q  P  Prp xrp N rp N rq  xrp    f bef rp  x  rp q   cn            x  rp q  rp q   for all top regions f Here bef rp  x rp q   f bef rp  x  rp q    rp q    RO p   is the effective old message over     X x  rp q  Y  Rp  brp  x    That is  in the update equation  we need the calculation of the new message to assume this value as the old message from q to p  This marginalization is important because it allows the belief at the top region   A Generalized Loop Correction Method  brp  x rp q   to be influenced by the beliefs brp  x   of the sub regions after a downward pass  It enforces marginal consistency between the top regions  and at f convergence we have bef rp  x rp q     brp  x rp q    Notice also Eqn     is equivalent to the old update Eqn     in the partitioning case  To calculate this marginalization more efficiently  GLC uses an upward pass in the rp  region graph  Starting from the parents of the lowest regions  we def fine bef rp  x   as  f bef rp  x       brp  x     Y ch      f bef r  x      x    Returning to the example  the previous text provides a method to update Pr   xr     GLC performs this for the remaining regions as well  and then iterates the entire process until convergence  i e   until the change in all distributions is less than a threshold      Experiments This section compares different variations of our method against LBP as well as CVM  LCBP and TreeEP  Minka   Qi        methods  each of which performs some kind of loop correction  For CVM  we use the double loop algorithm of  Heskes         which is slower than GBP but has better convergence properties  All methods are applied without any damping  We stop each method after a maximum of  E  iterations or if the change in the probability distribution  or messages  is less than  E    We report the time in seconds and the error for each method as the averagePof absolute error in single variable marginals  i e   xi  v  P  xi   v P  xi   v    For each setting  we report the average results over    random instances of the problem  We experimented with grids    regular random graphs  and the ALARM network as typical benchmark problems   Both LCBP and GLC can be used with a uniform initial cavity or with an initial cavity distribution estimated via clamping cavity variables  In the experiments  full and uniform refer to the kind of cavity distribution used  We use GLC to denote the partitioning case  and GLC  when overlapping clusters of some form are used  For example  GLC  Loop   full  refers to a setting with full cavity that contains all overlapping loop clusters of length up to    If a factor does not appear in any loops  it forms its own cluster  The same form of clusters are used for CVM    The evaluations are based on implementation in libdai inference toolbox  Mooij          Figure    Time vs error for   regular Ising models with local field and interactions sampled from a standard normal  Each method in the graph has    points  each representing an Ising model of different size     to     variables         Grids We experimented with periodic Ising grids in which xi          is a binary variable and the probability distribution of a setting when xi and xj are connected inPthe graph is given by P  x   P exp  i i xi      i jI Ji j xi xj   where Ji j controls variable interactions and i defines a single node potential  a k a  a local field  In general  smaller local fields and larger variable interactions result in more difficult problems  We sampled local fields independently from N        and interactions from N           Figure   left  summarize the results for  x  grids for different values of   We also experimented with periodic grids of different sizes  generated by sampling all factor entries independently from N         Figure   middle  compares the computation time and error of different methods for grids of sizes that range from  x  to   x         Regular Graphs We generated two sets of experiments with random   regular graphs  all nodes have degree    over    variables  Here we used Ising model when both local fields and couplings are independently sampled from N           Figure   right  show the time and error for different values of   Figure   shows time versus error for graph size between    to     nodes for       For larger s  few instances did not converge within allocated number of iterations  The results are for cases in which all methods converged    A Generalized Loop Correction Method  Figure    Average Run time and accuracy for   Left   x  spinglass grids for different values of   Variable interactions are sampled from N           local fields are sampled from N          Middle  various grid sizes    x             x     Factors are sampled from N          Right    regular Ising models with local field and interactions sampled from N            Table    Performance of varoius methods on Alarm Method Time s  Avg  Error LBP     E       E   TreeEP     E       E   CVM  Loop       E       E   CVM  Loop       E       E   CVM  Loop       E       E   CVM  Loop       E       E   LCBP  Full      E       E   GLC   Factor  Uniform      E       E   GLC   Loop   Uniform      E       E   GLC   Loop   Uniform      E       E   GLC   Factor  Full      E       E   GLC   Loop   Full      E       E   GLC   Loop   Full      E       E         Alarm Network  lacking in general single loop GBP implementations  GLCs time complexity  when using full cavity  and using LBP to estimate the cavity distribution  is O  M N  X  u   M  X  v     where  is the number of iterations of GLC   is the maximum number of iterations for LBP  M is the number of clusters  N is the number of variables  u   maxp   rp   and v   maxp    rp    Here the first term is the cost of estimating the cavity distributions and the second is the cost of exact inference on clusters  This makes GLC especially useful when regional Markov blankets are not too large      Conclusions  Alarm is a Bayesian network with    variables and    factors  Variables are discrete  but not all are binary  and most factors have more than two variables  Table    compares the accuracy versus run time of different methods  GLC with factor domains as regions  i e   rp   I for I  F  and all loopy clusters produces exact results up to the convergence threshold   We introduced GLC  an inference method that provide accurate inference by utilizing the loop correction schemes of both region based and recent cavitybased methods  Experimental results on benchmarks support the claim that  for difficult problems  these schemes are complementary and our GLC can successfully exploit both  We also believe that our scheme motivates possible variations that can also deal with graphical models with large Markov blankets        Discussions     Acknowledgements  These results show that GLC consistently provides more accurate results than both CVM and LCBP  although often at the cost of more computation time  They also suggest that one may not achieve this tradeoff between time and accuracy simply by including larger loops in CVM regions  When used with uniform cavity  the performance of GLC  specifically GLC   is similar to CVM  and GLC appears stable  which is  We thank the anonymous reviewers for their excellent detailed comments  This research was partly funded by NSERC  Alberta Innovates  Technology Futures  AICML  and Alberta Advanced Education and Technology   
 A new approach to maximum likelihood learning of discrete graphical models and RBM in particular is introduced  Our method  Perturb and Descend  PD  is inspired by two ideas  I  perturb and MAP method for sampling  II  learning by Contrastive Divergence minimization  In contrast to perturb and MAP  PD leverages training data to learn the models that do not allow efficient MAP estimation  During the learning  to produce a sample from the current model  we start from a training data and descend in the energy landscape of the perturbed model  for a fixed number of steps  or until a local optima is reached  For RBM  this involves linear calculations and thresholding which can be very fast  Furthermore we show that the amount of perturbation is closely related to the temperature parameter and it can regularize the model by producing robust features resulting in sparse hidden layer activation     Introduction The common procedure in learning a Probabilistic Graphical Model  PGM  is to maximize the likelihood of observed data  by updating the model parameters along the gradient of the likelihood  This gradient step requires inference on the current model  which may be performed using deterministic or a Markov Chain Monte Carlo  MCMC  procedure      Intuitively  the gradient step attempts to update the parameters to increase the unnormalized probability of the observation  while decreasing the sum of unnormalized probabilities over all states i e   the partition function  The first part of the update is known as positive phase and the second part is referred to as the negative phase  An efficient alternative is Contrastive Divergence  CD      training  in which the negative phase only decreases the probability of the configurations that are in the vicinity of training data  In practice these neighboring states are sampled by taking few steps on Markov chains that are initialized by training data  Recently Perturbation methods combined with efficient Maximum A Posteriori  MAP  solvers were used to efficiently sample PGMs            Here a basic idea from extreme value theory is used  which states that the MAP assignments for particular perturbations of any Gibbs distribution can replace unbiased samples from the unperturbed model      In practice  however  models are not perturbed in the ideal form and approximations are used      Hazan et al  show that lower order approximations provide an upper bound on the partition function      This suggest that perturb and MAP sampling procedure can be used in the negative phase to maximize a lower bound on the log likelihood of the data  However  this is feasible only if efficient MAP estimation is possible  e g   PGMs with submodular potentials       and even so  repeated MAP estimation at each step of learning could be prohibitively expensive  Here we propose a new approach closely related to CD and perturb and MAP to sample the PGM in the negative phase of learning  The basic idea is to perturb the model and starting at training     data  find lower perturbed energy configurations  Then use these configurations as fantasy particles in the negative phase of learning  Although this scheme may be used for arbitrary discrete PGMs with and without hidden variables  here we consider its application to the task of training Restricted Boltzmann Machine  RBM          Background     Restricted Boltzmann Machine RBM is a bipartite Markov Random Field  where the variables x    v  h  are partitioned into visible v    v            vn   and hidden h    h            hm   units  Because of its representation power        and relative ease of training       RBM is increasing used in various applications  For example as generative model for movie ratings       speech      and topic modeling       Most importantly it is used in construction of deep neural architectures           RBM models the joint distribution over hidden and visible units by P h  v        E h v   e Z    P where Z     h v eE h v   is the normalization constant  a k a  partition function  and E is the energy function  Due to its bipartite form  conditioned on the visible  hidden  variables the hidden  visible  variables in an RBM are independent of each other  Y Y P h v      P hj  v    and P v h      P vi  h         jm   in  Here we consider the energy function of binary RBM  where hj   vi                 X X X T T T E v  h       vi Wi j hj   ai vi   bj hj    v Wh   a v   b h  in   in  jm   jm  The model parameter     W  a  b   consists of the matrix of n  m real valued pairwise interactions W  and local fields  a k a  bias terms  a and b  The marginal over visible units is   X P v     P v  h   Z   h  Given a data set D    v              v N      maximum likelihood learning of the model seeks the maximum of the averaged log likelihood    X l     log P v k          N  k  v D   Y   X  k    X     exp      vi Wi j    log Z      N  k  v  D  jm   in  Simple calculations gives us the derivative of this objective wrt   h i   X  k  l   Wi j   EP hj  v k     vi hj  EP vi  hj      vi hj   N  k  v    l   ai   N l   bj      N  D  X  vi  X  EP hj  v k       hj    EP hj      hj     k    EP vi      vi    v k  D  v k  D      where the first and the second terms in each line correspond to positive and negative phase respectively  It is easy to calculate P hj  v k       required in the positive phase  The negative phase  however  requires unconditioned samples from the current model  which may require long mixing of the Markov chain  Note that the same form of update appears when learning any Markov Random Field  regardless of the form of graph and presence of hidden variables  In general the gradient update has the following form I l     ED    I  xI      E   I  xI           where I  xI   is the sufficient statistics corresponding to parameter I   For example the sufficient statistics for variable interactions Wi j in an RBM is i j  vi   hj     vi hj   Note that  in calculating the expectation of the first term appears only if hidden variables are present      Contrastive Divergence Training In estimating the second term in the update of eq     we can sample the model with the training data in mind  To this end  CD samples the model by initializing the Markov chain to data points and running it for K steps  This is repeated each time we calculate the gradient  At the limit of K    this gives unbiased samples from the current model  however using only few steps  CD performs very well in practice      For RBM this Markov chain is simply a block Gibbs sampler with visible and hidden units are sampled alternatively using eq     It is also possible to initialize the chain to the training data at the beginning of learning and during each calculation of gradient run the chain from its previous state  This is known as persistent CD      or stochastic maximum likelihood           Sampling by Perturb and MAP Assuming that it is possible to efficiently obtain the MAP assignment in an MRF  it is possible to use perturbation methods to produce unbiased samples  These samples then may be used in the negative phase of learning  e Let E x    E x   o x  denote the perturbed energy function  where the perturbation for each x is a sample from standard Gumbel distribution o x        exp   exp     Also let e e denote the perturbed distribution  Then the MAP assignment arg max P x  e P x   exp E  is x an unbiased sample from P x   This means we can sample P x  by repeatedly perturbing it and finding the MAP assignment  To obtain samples from a Gumbel distribution we transform samples from uniform distribution u  U       by o  log  log u    The following lemma clarifies the connection between Gibbs distribution and the MAP assignment in the perturbed model  e Lemma          Let  E x  xX and E x   R  Define the perturbed values as E x    E x   o x   when o x      x  X are IID samples from standard Gumbel distribution  Then exp E b x     exp E y   yX  e b    P P r argxX max E x    x       Since the domain X   of joint assignments grows exponentially with the number of variables  we can not find thePMAP assignment efficiently  As an approximation we may use fully decomposed noise o x    i o xi        This corresponds to adding a Gumbel noise to each assignment of unary potentials  In the case of RBMs parametrization  this corresponds to adding the difference of two random samples from a standard Gumbel distribution  which is basically a sample from a logistic distribution  to biases  e g   e ai   ai   o vi       o vi        Alternatively a second order approximation may perturb a combination of binary and unary potentials such that each variable is included once  Section            Perturb and Descend Learning Feasibility of sampling using perturb and MAP depends on availability of efficient optimization procedures  However MAP estimation is in general NP hard      and only a limited class of MRFs allow efficient energy minimization      We propose an alternative to perturb and MAP that is suitable when inference is employed within the context of learning  Since first and second order perturbations in perturb and MAP  upper bound the partition function      likelihood optimization using this method is desirable  e g          On the other hand since the model is trained on a data set  we may leverage the training data in sampling the model  Similar to CD at each step of the gradient we start from training data  In order to produce fantasy particles of the negative phase we perturb the current model and take several steps towards lower energy configurations  We may take enough steps to reach a local optima or stop midway  f e e denote the perturbed model  For RBM  each step of this block coordinate descend Let e    W  a  b  takes the following form f    v  e a   Wh      k   e W fT v     h  b       where starting from v   v  D  h and v are repeatedly updated for K steps or until the update above has no effect  i e   a local optima is reached   The final configuration is then used as the fantasy particle in the negative phase of learning      Amount of Perturbations To see the effect of the amount of perturbations we simply multiplied the noise o by a constant   i e        means we perturbed the model with larger noise values  Going back to Lemma   we see that any multiplication of noise can be compensated by a change of temperature of the energy e function  i e   for    T    the argx max E x    argx max T  E x   o x  remains the same  However here we are only changing the noise without changing the energy  Here we provide some intuition about the potential effect of increasing perturbations  Experimental results seem to confirm this view  For       in the negative phase of learning  we are lowering the probability of configurations that are at a larger distance from the training data  compared to training with       This can make the model more robust as it puts more effort into removing false valleys that are distant from the training data  while less effort is made to remove  false  valleys that are closer to the training data      Second Order Perturbations for RBM As discussed in Section     a first order perturbation of   only injects noise to local potentials  e ai   ai   o vi       o vi      and ebi   bj   o hi       o hi       In a second order perturbation we may perturb a subset of non overlapping pairwise potentials as well as unary potentials over the remaining variables  In doing so it is desirable to select the pairwise potentials with higher influence  i e   larger  Wi j   values  With n visible and m hidden variables  we can use Hungarian maximum bipartite matching algorithm to find min m  n  most influential interactions       Once influential interactions are selected  we need to perturb the corresponding      factors with Gumbel noise as well as the bias terms for all the variables that are not covered  A simple calculation shows that perturbation of the      potentials in RBM corresponds to perturbing Wi j as well as ai and bj as follows f i j   Wi j   o        o        o         o       W  e ai   ai  o         o       ebj   bj  o         o       o        o        o        o           where o y  z  is basically the injected noise to the pairwise potential assignment for vi   y and hj   z      
