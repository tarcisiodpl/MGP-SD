 Message passing algorithms have emerged as powerful techniques for approximate inference in graphical models  When these algorithms converge  they can be shown to find local  or sometimes even global  optima of variational formulations to the inference problem  But many of the most popular algorithms are not guaranteed to converge  This has lead to recent interest in convergent message passing algorithms  In this paper  we present a unified view of convergent message passing algorithms  We present a simple derivation of an abstract algorithm  tree consistency bound optimization  TCBO  that is provably convergent in both its sum and max product forms  We then show that many of the existing convergent algorithms are instances of our TCBO algorithm  and obtain novel convergent algorithms for free by exchanging maximizations and summations in existing algorithms  In particular  we show that Wainwrights non convergent sum product algorithm for tree based variational bounds  is actually convergent with the right update order for the case where trees are monotonic chains      Introduction  Probabilistic inference in graphical models is a key component in learning and using these models in practice  The two key inference problems are calculating the marginals of a model and calculating its most likely assignment  sometimes referred to as the MAP problem   One approach to these generally intractable problems is to use a variational formulation  where approximate  inference is cast as an optimization problem  For the marginals case this usually corresponds to minimization of a free energy functional  and for the MAP problem it corresponds to solving a linear programming  LP  relaxation       A key challenge in both the MAP and marginals case is to devise simple and scalable algorithms for solving the variational optimization problem  In recent years numerous algorithms have been introduced for both tasks  These algorithms typically have a message passing like structure  Perhaps the most widely used message passing algorithms are belief propagation and its generalizations                 These algorithms typically have two variants  sum product which is used to approximate the marginals  and max product which is used to approximate the MAP  Fixed points of these algorithms can be shown to be local  or sometimes even global  optima of the corresponding variational formulation  Yet despite the spectacular empirical success of these algorithms in real world applications  they are not guaranteed to converge  and variants of dampening are often used to improve their convergence              There has therefore been much recent work on convergent message passing algorithms                These algorithms are often very similar in structure to the nonconvergent algorithms and often include local maxproduct or sum product operations  However  for each of these specific algorithms it has been possible to prove that the value of the variational problem  or its dual  improves at each iteration  Perhaps the most intriguing example of this is Kolmogorovs TRW S algorithm     which is simply Wainwrights tree reweighted max product algorithm      with a different update schedule  Here we introduce a unifying framework which encompasses both marginals and MAP approximations  by exploiting the mathematical similarities between these approximations  Specifically  we provide an up         MELTZER ET AL   per bound on the optimum of the variational approximations  and give sufficient conditions that algorithms need to satisfy in order to decrease this bound in a monotone fashion  Any algorithm which satisfies these conditions is guaranteed to decrease the upper bound at every iteration  This property in turn guarantees that such algorithms converge to a global optimum of the variational problem in the marginals case and to a local optimum in the MAP LP approximation case  Our framework involves updating a subset of regions which form a tree in the region graph  A related approach was recently suggested by Sontag et al      in the context of solving the MAP approximation  Their work gives an explicit algorithm for optimizing all edges corresponding to a tree in the original graph  such that an upper bound on the LP optimum is decreased at every iteration  Our formalism does not give an explicit update but rather conditions that guarantee an update to decrease the objective  However  we show that these conditions are satisfied by several known algorithms  Furthermore  since the condition is similar in the marginals and MAP case  specifically a condition of sum and max consistency respectively  it is easy to obtain algorithms for both these cases simultaneously  and to use results in one problem for obtaining algorithms for the other  For instance  we consider the tree reweighted  TRW  free energy minimization problem       Recently two works have provided convergent algorithms for this problem         but these were more involved than standard message passing algorithms  Here we show the surprising result that in fact the original algorithm provided for TRW by Wainwright et al  is convergent  if run with an appropriate schedule of message updates      Bounds for MAP and Log Partition  We consider a graphical model where the joint probability over variables p x  factors Q into a product over clique potentials p x    Z     x   or equivalently  the energy function is a sum over clique enP   ergies p x      x     We also denote exp    Z P  x       x    The problem of calculating marginals and approximation of the partition function Z can be recast as the following maximization problem of the function F  q   the negative of the free energy   log Z   max F  q    max  h x iq   H q   q  q       where q is the set of probability distributions over x  h x iq is the average energy with respect to q and H q  is the entropy function  The maximizing argu   UAI       ment is then the distribution p x   This maximization is in general intractable  so approximate free energies are often used  A class of approximate free energies  discussed in       is based on the concept of a region graph G whose nodes  are regions of the original graph  and whose edges represent subregion relationships  i e  an edge between  in  exists only if      The approximation replaces the joint entropy H q  with a linear combination of local region entropies H  q   where each local entropy is weighted by a double counting number c   HG c  q     X  c H  q             where the subscript G  c indicates the dependence of the approximation on the region graph G and the counting numbers c   With this approximation of H q  the free energy now only depends on local distributions  since the average energyPis a simple function of the q   namely h x iq    h  x  iq   To optimize only over local distributions q   we need to consider only distributions such that there exists a q x  that has these as marginals  This set  called the marginal polytope       cannot be expressed in a compact form  and is typically approximated  One popular approximation is the local polytope of the region graph L G  defined as the set of local distributions that agree on the marginals for any two regions in the region graph that are subsets of each other   P         x q  x     q  x   x  x L G    q    P   x q  x       Take together  this results in the following standard variational approximation       X max F  q    max h  x  iq   HG c  q      qL G   qL G     Similarly the MAP problem is approximated via X max F  q    max h  x  iq qL G   qL G          To obtain a unified formalism for MAP and marginals  we use a temperature parameter T where T     for marginals and T     for MAP and the optimization is  X max F  q    max h  x  iq   T HG c  q      qL G   qL G       Note that this is the local polytope of the region graph not the local polytope of the original graph   UAI           MELTZER ET AL   Positive Counting Numbers  The entropy approximation HG c  q  in Eq    is generally not a concave function of the local distributions q  Thus maximization of F  q  may result in local optima  To avoid this undesirable property  several works  e g        have focused on entropies which are obtained by considering only concave HG c  q  functions  We focus on approximations where all the double counting numbers are non negative  This is a strong restriction but since we are working with a region graph formulation  many approximate free energies which have negative double counting numbers can be transformed into ones with positive double counting numbers on a region graph  Perhaps the most important example are tree reweighted free energies inPwhich the entropy is approximated as HT RBP  q      H  q  with  a probability distribution over trees in the graph and H  q  is the entropy of the distribution on  with marginals given by q  more precisely  the projection of q on the tree     If we consider a region graph with trees and their intersection  Fig     the double counting numbers are non negative  ButP HT RBP can P also be rewritten H    H   T RBP ij ij ij i ci Hi with P ci      j ij and ij is the edge appearance probability of the edge ij under the distribution   In this case  the double counting number for the singletons ci may be negative  However  we will show that it is sometimes advantageous to work in the representation that uses a non negative mixture of trees  since nonnegativity of the counting numbers allows a simpler derivation of algorithms       Optimization and Reparameterization  The vast majority of methods for solving the variational approximation are based on two classes of constraints that local optima should satisfy  It is easy to show using Lagrange multipliers  that local optima of F should satisfy two types of constraints                     Reparametrization Q  or admissibility  or e constraints   P  x    q  x  c   for every x    sum consistency  or m constraints   P x  x q  x     q  x   for all    and x    By enforcing each of these constraints iteratively one obtains many of the popular sum product algorithms  Replacing the sum consistency constraint with maxconsistency gives many of the popular max product algorithms  A simple example is ordinary BP  which maintains admissiblity at each iteration and a message from i to j enforces consistency between bij and bj         In general  simply iteratively enforcing constraints is not guaranteed to give convergent algorithms  However  as we show in this paper  by iterating through the constraints in a particular order  we obtain monotonically convergent algorithms       Bound minimization and reparameterizations  We begin by providing an upper bound on the logpartition function whose minimization is equivalent to the maximization in Eq     We consider marginals b of the exponential form  b  x               exp   x   c Z       and require that these marginals will be admissible  maintain the e constraints   We obtain admissibility by requiring that the variables  will satisfy the following for each x  X X   x       x           The algorithms we propose will optimize over the variables  while keeping the constraint in Eq    satisfied at all times  Moreover  they will monotonically decrease an upper bound on the optimum of Eq     In the following two lemmas we provide this bound for the sum and max cases  Lemma   The approximation to the log partition function is bounded above by  X boundsum          c ln Z   for any reparameterization   i e   any  satisfying Eq      Minimizing boundsum    over the set of reparameterizations  would give the approximated log partition function  min boundsum      max F  q    qL G        This is the optimum of Eq    with T      Proof  Kolmogorov     showed that if  is a reparameterization  i e  keeping the constraint in Eq      it also holds that hiq   hiq for any q  L G   Using this property  we can see that the log partition function is constant under reparameterization  F  q      F  q    for any q  L G   and in particular the maximum value        MELTZER ET AL   will remain the same  Now  using the new variables  we have a trivial bound on the log partition    X  h iq   c H  q   max F  q      max qL G   qL G     X   Algorithm   The tree consistency bound optimization  TCBO  algorithm Iterate over sub graphs T of the region graph that have a tree structure        Choose a tree T      max h iq   c H  q   q     Update the values of t   for all   T such that   Since the counting numbers c are non negative  the marginals defined in Eq    maximize each local functional F  q      c     h iq   c H  q    and the optimal value is c ln Z   Thus  max F  q      qL G   X  c ln Z   re parameterization is maintained  X X t    x      x    t  x    tree consistency is enforced  Define the beliefs          t   bt     x         or optimize the bound to the MAP by enforcing max consistency   qL G   t   t   t   max bt     x        b  x      x   x  Minimizing boundmax    over the set of reparameterizations  would give the optimal value for the regiongraph LP relaxation of the MAP  X min boundmax      max      h  x  iq   This is the optimum of Eq    with T      Proof  The bound follows directly P from the admissiblity constraint so that maxx    x    P  maxx   x    The fact that the tightest bound coincides with the LP relaxation was proven in       We note that the above two lemmas may also be viewed as an outcome of convex duality  In other words  the original variational maximization problem and the equivalent bound minimization problem are convex duals of each other  In the following sections we provide a framework for deriving minimization algorithms for the above two bounds   Zt        exp t    x   c  x   Lemma   The value of the MAP is bounded above by  X boundmax           max   x   for any reparameterization   i e   any  satisfying Eq          For each   T    T     and x   optimize the bound to the log partition function by enforcing sum consistency  X t   t   t   bt     x        b  x       A similar result may be obtained for the MAP case  this result or variants of it appeared in previous works  e g                    T  T  The bound is tight if there exists a reparameterization  such that the marginals b  x      are sumconsistent  i e  b  L G    The existence of such a re parameterization is guaranteed if the maximum of the approximated negative free energy F  q    does not happen at an extreme point          UAI          Bound optimization and consistency  We propose the tree consistency bound optimization  TCBO  algorithm as a general framework for minimizing the bounds in Sec      for the approximated log partition and for the MAP  within a region graph with positive counting numbers c   The idea is to perform updates on trees that are subgraphs of the region graph  The  corresponding to each such tree will be updated simultaneously in a way that will achieve a monotone decrease in the bound  The method we propose  as described in Algorithm   keeps the beliefs admissible with the positive counting numbers c  or equivalently  always maintains  x  that reparameterize the original energy  x    The corresponding  thus satisfy the conditions of the bound in Sec       Furthermore  at each iteration  max or sum consistency of the beliefs is enforced for the subtree T   As mentioned earlier  maintaining consistency on subsets does not generally result in convergent algorithms  However  as the following lemmas show  in our case enforcing consistency is equivalent to block coordinate   UAI       MELTZER ET AL        descent on the bound  Lemma   The sum consistency lemma  Consider the bound minimization problem for the logpartition function with positive counting numbers  Lemma     defined on a subset of regions and intersections T   The part of the bound which is influenced by the beliefs of the subset is  X P BT  T     c ln Z T  The problem is to find     for all   T that minimize P BT  T   subject to  being reparameterizations of the energy      If for some  the be    reparameterization  Figure    A simple  x  grid  with pair regions  Proof  The part of the bound which is dependent on T is bounded below  P BT  T    max T  xT   xT  where  liefs b x       exp   c are sum consistent  then it minimizes the bound   Proof  The part of the bound which is dependent on T the is bounded below  X P BT  T     max F  q      c   T    q  max  qT L G   X  F  q      c    T  Now  if we find variables  for all   T such that they provide global re parameterization  x     x   so we can have a bound   and the marginals b  x       exp   x   c   which maximize each term F  q      c   separately are also sum consistent  bT  L G    then P BT  T   will achieve its optimal value  and thus we perform block coordinate descent on the bound  Note that for optimizing the bound to the logpartition  the subset T does not have to form a tree  and the sum consistency of the beliefs is enough  Yet  it may be easier in practice to enforce sum consistency on trees  Lemma   The max consistency lemma  Consider the bound minimization problem for MAP with positive counting numbers  Lemma     defined on a subset of regions and intersections that form a tree T   The part of the bound which is influenced by the beliefs of the tree is  X P BT  T     max   x   T  x  The problem is to find     for all   T that minimize P BT  T   subject to  being reparameterizations of the energy      If for some  the be    reparameterization liefs b x       exp   c are max consistent  then it minimizes the bound     X   x   T  xT     T  so if we can find an assignment xT whose cost T  xT   equals P BT  T    that means we have the tightest bound  Now  if for some T the be    reparameterization  liefs b  x       exp   c are max marginalizable then we can always find an assignment xT that sits on the maxima of  because the subgraph is a tree  so there cannot be any frustrations   Hence  we obtain T  xT     P BT  T    and the bound achieves its optimal value for the coordinates in T   The above two lemmas show that the TCBO algorithm monotonically decreases the bound after each update  In the log partition case  the bound is strictly convex and thus this strategy finds the global minimum of the bound which is the global maximum of Eq     In the MAP case  the function is not strictly convex and the algorithm may converge to values that are not its global optimum  This phenomenon is shared by most dual descent algorithms  e g                TCBO is a general scheme and can be implemented for different choices of tree sub graphs  In the next section we illustrate some possible choices and their relation to known algorithms      Existing bound minimizing algorithms  We identify some existing convergent algorithms as instances of TCBO  Heskes algorithm     for approximating the marginals  and MPLP     TRW S      maxsum diffusion  MSD       for approximating MAP  Figures     show the reparametrization  region graph and the tree sub graph updated at each iteration of these algorithms  for the simple example of a  x  grid shown in Fig     Note that all algorithms use a reparameterization with positive double counting numbers  Furthermore  they update only a subtree at        MELTZER ET AL   Figure    Illustration of the max sum diffusion  MSD  algorithm as an instance of the TCBO formalism  MSD operates on a region graph containing pairs and singletons  here corresponding to a  x  grid   The subgraph T corresponding to the TCBO update is shown in the blue dashed line   UAI       Figure    Heskes sum product algorithm may be viewed as a TCBO algorithm updating the subtree shown in the blue dashed line  a star graph centered on a singleton node   Algorithm   Heskes sum product algorithm Iterate over intersection regions    Algorithm   The max sum diffusion  MSD  algorithm Iterate over edges between regions                set the message from  to       Set the message from  to    t   m  x       t m  x    t   m  x    v u u maxx  bt  x   t bt  x       t x  b  x   mt  x    P     Update the belief of the intersection region  t    b     Update the beliefs    x     c  c Y  t    m  x     t    b   x      t    m  x     Y  t  m   x        t   b  x        x   Q t mt        m   x     x           set the messages to the parent regions and their beliefs  t    m  x       t   b  x      bt    x    mt     x     c    t     x    m  x    Y  t    m    x          a time  What remains to be shown is that each iteration achieves consistency among the beliefs  in other words  it satisfies the conditions of TCBO framework and thus monotonically decreases the corresponding upper bound   Heskes algorithm can be shown to be an instance of TCBO using direct substitution  The update rules are shown in algorithm    MPLP  algorithm    does not appear at first sight to use the region graph illustrated in Fig     but rather works with edges and singletons  However  as we show in the appendix  there is a way to transform the messages used in the max product version of Heskess algorithm into messages of MPLP using the MPLP region graph  The max consistency achieved by MSD  algorithm    can again be shown directly  It is also possible to use tree graphs  or forests  as regions  and various existing methods indeed use this approach  We may consider a TCBO algorithm which iterates through all edges and nodes  and for each edge or node enforces consistency between it and all trees that contain it  This is illustrated in Fig     A naive  implementation of such a scheme is costly  as it requires multiple tree updates for every edge  However  Kolmogorov     showed that there exists an efficient implementation  which he called TRW S  of such a scheme in the MAP case  This implementation may only be applied if the trees are monotonic chains  defined as follows  given an ordering of the nodes in a graph  a set of chains is monotonic if the order of nodes in the chain respects the given ordering  This structure allows one to reuse messages in a way that simultaneously implements operations on multiple trees  The scheduling of messages is important for guaranteeing convergence in this case  It turns out that one needs to scan nodes along the pre specified order  first forward and then backward  In the marginals case  the TRW algorithm of Wainwright      corresponds to optimizing over tree regions but is not provably convergent  In the next section we show how to derive a convergent algorithm for this case using our formalism    UAI       MELTZER ET AL        Figure    MPLP for pairs and singletons is equivalent to Heskes algorithm with stars and pairs  Algorithm   The max product linear programming  MPLP  algorithm Iterate over pairs of neighbouring nodes   ij       Set the message from i to   ij    t    miij  xi      t  Y  miki  xi    kN  i  j  and equivalently from j to   ij      Update the pairwise beliefs of   ij    t    bij  xi   xj     q t   ij  xi   xj    mt   iij  xi    mjij  xj       Set the messages from   ij   to i  and equivalently from   ij   to j   v   u u max ij  xi   xj    mt   xj u jij  xj   t   miji  xi    t mt   iij  xi      Set the beliefs of i  and same for j   t    bi  t     xi    miji  xi     Y  t  miki  xi    kN  i  j     Figure    A region graph with chains  their pairwise and singleton components  Such graphs are used by the TRW S algorithms  In the above example there are two chains  which are also monotonic chains since they agree with the node ordering               TRW S may be viewed as a TCBO algorithm on the subgraph shown in the blue dashed line  and an additional subgraph corresponding to a pairwise component and all the chains that contain it   since it is an instance of a TCBO algorithm for the sum case  Furthermore  this TRW S variant differs from the algorithm in      only in the scheduling of messages  An additional algorithm that can be easily shown to be convergent is two way GBP      with all double counting numbers c      both in the sum and in the max versions  At each iteration  two way GBP updates only the beliefs of a region and one of its subregions  which is trivially a tree  The fact that it maintains reparameterization and enforces consistency can be shown directly  In fact  it can be shown that two way GBP with c     is identical to MSD   New bound minimizing algorithms    By replacing the max with a sum  or vice versa  in the algorithms discussed in the previous section  we obtain algorithms that enforce a different type of consistency  and keep the same reparameterization and region graph as shown in the figures  Thus  the maxproduct version of Heskes algorithm and the sumproduct versions of TRW S  MPLP and MSD are convergent with respect to the relevant bound  The TRW S sum product case is especially interesting  In this case the relevant bound becomes the treereweighted log partition function bound introduced in       The message passing algorithm suggested in      does not generally converge  In contrast  the TRWS sum product algorithm is guaranteed to converge   Experiments  We present two experiments to illustrate the convergence of our sum and max algorithms  All algorithms were applied to an instance of a   x   spin glass with pairwise terms drawn randomly from        and field from         In each case we tested the new TCBO algorithms  For estimating the log partition  we ran TRW and considered a uniform distribution over   spanning forests in the graph  all horizontal and all vertical chains  These chains are monotone with respect to the node ordering                   We ran TRW S by following the nodes order first forward and then backward  updating each time only the messages in the direction of        MELTZER ET AL   UAI       Algorithm   The sequential tree reweighted BP  TRW        S  algorithm    ij  mij  xj    max i  xi  ij xi   xi   xj    Q  ik kN  i  j mki  xi     mjiij  xi       After each iteration over all edges  update all singleton and pairwise beliefs  bi  xi      i  xi    Y       ik  x   mki i  kN  i  j   mjiij  xi    Q    jk kN  j  i mkj  xj                                   Iterations                 mijij  xj    the scan  Fig    shows a comparison of this schedule to TRW where the node ordering is followed in a forward manner  and all outgoing messages are updated from each node  Both schedules keep a re parameterization and provide a bound to the log partition  yet only TRW S monotonically decreases it at each iteration  For the MAP case  we ran the max product version of Heskes algorithm using a region graph of pairs  with double counting numbers    and singletons  with double counting numbers     We also ran MPLP and MSD on the same problem  Fig    shows the bounds obtained after each iteration  As can be seen  all three algorithms monotonically converged to the same value      sumTRWS sumTRBP               i  xi  j  xj  ij ij  xi   xj    Q         ij mji  xi    jN  i   bij  xi   xj    Bound to LogPartition          Iterate over edges i  j in a certain updating order  and set the message from i to j   Discussion  Despite the empirical success of max product and sumproduct algorithms in applications  the original algorithms are not guaranteed to converge  Much research in recent years has therefore been devoted to devising convergent algorithms  Typically these recent algorithms are either max product or sum product and their proof of convergence is specific to the algorithm  Here we have presented a unified framework for convergent message passing algorithms and showed the importance of enforcing consistency in both sum product and max product algorithms  Not only does this analogy allow us to give a unified derivation for existing algorithms  it also gives an easy way to derive novel algorithms from existing ones by exchanging maximizations and summations  Although many convergent algorithms are instances of our framework  it is worth pointing out two convergent algorithms that are not  The first is Hazan and Shashuas recent algorithm        which works for provably convex double counting numbers  not necessarily  Figure    The bound on the log partition in a   x   spin glass  obtained by sum product TRW and TRW S with edge probability appearances of      Note that the two algorithms differ only in the order of updates they perform  TRW S follows the node ordering                  that agrees with the monotonic chains  first forward and then backward  In the TRW implementation we followed the same nodes order in a forward manner   positive as we are assuming   The second is ordinary BP on a single cycle  which can be shown to be convergent in both its sum and max product forms  We emphasize that even negative counting numbers can be handled by us in some cases  by using larger regions  All the algorithms we discussed here in fact only updated star graphs in the region graph  Our conditions for monotonicity apply to general tree updates  However  it seems less straightforward to obtain general  non star  tree updates that achieve  max or sum  consistency and reparameterization simultaneously  Interestingly  the tree based updates in     do monotonically decrease an upper bound but seem not to satisfy maxconsistency  Thus  it remains an interesting challenge to find general tree updates that satisfy the consistency constraints  as these could be easily used interchangeably for MAP and marginals  Perhaps the most intriguing result of our analysis is the importance of update schedule for obtaining convergence  a non convergent algorithm becomes convergent when the right update schedule is used  It will be interesting to see whether convergent update schedules can be derived for an even larger class of message passing algorithms    UAI       MELTZER ET AL   clusters and hyper stars respectively  in which the centers are the intersections of the clusters            
 Linear Programming  LP  relaxations have become powerful tools for finding the most probable  MAP  configuration in graphical models  These relaxations can be solved efficiently using message passing algorithms such as belief propagation and  when the relaxation is tight  provably find the MAP configuration  The standard LP relaxation is not tight enough in many real world problems  however  and this has lead to the use of higher order cluster based LP relaxations  The computational cost increases exponentially with the size of the clusters and limits the number and type of clusters we can use  We propose to solve the cluster selection problem monotonically in the dual LP  iteratively selecting clusters with guaranteed improvement  and quickly re solving with the added clusters by reusing the existing solution  Our dual message passing algorithm finds the MAP configuration in protein sidechain placement  protein design  and stereo problems  in cases where the standard LP relaxation fails      Introduction  The task of finding the maximum aposteriori assignment  or MAP  in a graphical model comes up in a wide range of applications  For an arbitrary graph  this problem is known to be NP hard      and various approximation algorithms have been proposed  Linear Programming  LP  relaxations are commonly used to solve combinatorial optimization problems in computer science  and have a long history of being used to approximate the MAP problem in general graphical models  e g   see       LP relaxations have an advantage over other approximate inference schemes in  Tommi Jaakkola CSAIL  MIT Cambridge  MA  Yair Weiss Hebrew University Jerusalem  Israel  that they come with an optimality guarantee  if the solution to the linear program is integral  then it is guaranteed to give the global optimum of the MAP problem  An additional attractive quality of LP relaxations is that they can be solved efficiently using messagepassing algorithms such as belief propagation and its generalizations              In particular  by using message passing algorithms  we can now use LP relaxations for large scale problems where standard  offthe shelf LP solvers could not be used       Despite the success of LP relaxations  there are many real world problems for which the basic LP relaxation is of limited utility in solving the MAP problem  For example  in a database of    protein design problems studied in       the standard LP relaxation allowed finding the MAP in only   cases  One way to obtain tighter relaxations is to use clusterbased LP relaxations  where local consistency is enforced between cluster marginals  As the size of the clusters grow  this leads to tighter and tighter relaxations  Furthermore  message passing algorithms can still be used to solve these cluster based relaxations  with messages now being sent between clusters and not individual nodes  Unfortunately  the computational cost increases exponentially with the size of the clusters  and for many real world problems this severely limits the number of large clusters that can be feasibly incorporated into the approximation  For example  in the protein design database studied in       each node has around     states  so even a cluster of only   variables would have     states  Clearly we cannot use too many such clusters in our approximation  In this paper we propose a cluster pursuit method where clusters are incrementally added to the relaxation  and where we only add clusters that are guaranteed to improve the approximation  Similar to the work of      who worked on region pursuit for sumproduct generalized belief propagation       we show   how to use the messages from a given cluster based approximation to decide which cluster to add next  In addition  by working with a message passing algorithm based on dual coordinate descent  we monotonically decrease an upper bound on the MAP value      MAP and its LP Relaxation  We consider functions over n discrete variables x    x            xn   defined as follows  Given a graph G    V  E  with n vertices  and potentials ij  xi   xj   for all edges ij  E  define the function f  x       X  ij  xi   xj      ijE  X  i  xi           iV  Our goal is to find the MAP assignment  xM   that maximizes the function f  x     The MAP problem can be formulated as a linear program as follows  Let  be a vector of marginal probabilities that includes  ij  xi   xj   ijE over variables corresponding to edges and  i  xi   iV associated with the nodes  The set of  that arise from some joint distribution is known as the marginal polytope         M G        p x  s t   p xi   xj     ij  xi   xj   p xi     i  xi         The MAP problem can then be shown to be equivalent to the following LP  max f  x      max      x       M G   refer to the P marginal of c  xc   for the edge  i  j   i e  c  xi   xj     xc i j c  xc    Define MC  G  as     ij  xi   xj     i  xi    P c  xi   xj     ij  xi   xj   c   i  j   c  xc c  xc       P          xj  It is easy to see that MC  G  is an outer bound on M G   namely MC  G   M G   As we add more clusters to C the relaxation of the marginal polytope becomes tighter  Note that similar constraints should be imposed on the cluster marginals  i e   they themselves should arise as marginals from some joint distribution  To exactly represent the marginal polytope  such a hierarchy of auxiliary clusters would require clusters of size equal to the treewidth of the graph  For the purposes of this paper  we will not generate such a hierarchy but instead use the clusters to constrain only the associated edge marginals       Choosing Clusters in the LP Relaxation  Adding a cluster to the relaxation MC  G  requires computations that scale with the number of possible cluster states  The choice of clusters should therefore be guided by both how much we are able to constrain the marginal polytope  as well as the computational cost of handling larger clusters  We will consider a specific scenario where the clusters are selected from a pre defined set of possible clusters C  such as triplet clusters  However  we will ideally not want to use all of the clusters in C    but instead add them gradually based on some ranking criterion   P P where      ijE xi  xj ij  xi   xj  ij  xi   xj     P P   x    x    There always exists a maximizi i i i i xi ing  that is integral  a vertex of the marginal polytope  and which corresponds to xM   Although the number of variables in this LP is only O  E   V     the difficulty comes from an exponential number of linear inequalities typically required to describe the marginal polytope M G    The best ranking of clusters is problem dependent  In other words  we would like to choose the subset of clusters which will give us the best possible approximation to a particular MAP problem  We seek to iteratively improve the approximation  using our current beliefs to guide which clusters to add  The advantage of iteratively selecting the clusters is that we add them only up to the point that the relaxed LP has an integral solution   The idea in LP relaxations is to relax the difficult global constraint that the marginals in  arise from some common joint distribution  Instead  we enforce this only over some subsets of variables that we refer to as clusters  More precisely  we introduce auxiliary distributions over clusters of variables and constrain the edge distributions ij  xi   xj   associated with each cluster to arise as marginals from the cluster distribution   Let C be a set of clusters such that each c  C is a subset of             n   and let c  xc   be any distribution over the variables in c  We also use c  xi   xj   to  Recently  Sontag and Jaakkola      suggested an approach for incrementally adding constraints to the marginal polytope using a cutting plane algorithm  A similar approach may in principle be applied to adding clusters to the primal problem  One shortcoming of this approach is that it requires solving the primal LP after every cluster added  and even solving the primal LP once is infeasible for large problems involving hundreds of variables and large state spaces      Each edge may participate in multiple clusters   In the next section we present a method that incrementally adds clusters  but which works exclusively within the dual LP  The key idea is that the dual LP   provides an upper bound on the MAP value  and we seek to choose clusters to most effectively minimize this bound  Note that an analogous bound minimization strategy is problematic in the primal where we would have to assess how much less the maximum is due to including additional constraints  In other words  obtaining a certificate for improvement is difficult in the primal  Moreover  unlike the dual  the primal algorithm might not give an upper bound on the MAP prior to convergence  Finally  we can warm start our optimization scheme after each cluster addition in order to avoid re solving the dual LP  We do this by reusing the dual variables calculated in the previous iterations which did not have the new clusters      Dual LP Relaxation  The obstacles to working in the primal LP lead us to consider the dual of the LP relaxation  Different formulations of the primal LP have lead to different dual LPs  each with efficient message passing algorithms for solving them                 In this paper we focus on a particular dual formulation by Globerson and Jaakkola     which has the advantage that the message passing algorithm corresponds to performing coordinate descent in the dual LP  Our dual algorithm will address many of the problems that were inherent in the primal approaches  giving us   we show in our experiments that MAP assignments can be found for nearly all of the problems we consider  We next describe the generalized MPLP algorithm for the special case of clusters comprised of three nodes  Although the algorithm applies to general clusters  we focus on triplets for simplicity  and because these are the clusters used in the current paper  MPLP passes the following types of messages   Edge to Node  For every edge e  E  e denotes two indices in V   and every node i  e  we have a message ei  xi     Edge to Edge  For every edge e  E  we have a message ee  xe    where xe is shorthand for xi   xj   and i and j are the nodes in the edge    Triplet to Edge  For every triplet cluster c  C  and every edge e  c  we have a message ce  xe    The updates for these messages are given in Figure    To guarantee that the dual objective decreases  all messages from a given edge must be sent simultaneously  as well as all messages from a triplet to its three edges  The dual objective that is decreased in every iteration is given by   X X g     max i  xi     kii  xi   iV     Simple warm start of tighter relaxation     An efficient algorithm that scales to very large problems       The Generalized MPLP Algorithm  The generalized Max Product LP  MPLP  messagepassing algorithm  introduced in      decreases the dual objective of the cluster based LP relaxation at every iteration  This monotone property makes it ideal for adding clusters since we can initialize the new messages such that the dual value is monotonically decreased  Another key advantage of working in the dual is that the dual objective gives us a certificate of optimality  Namely  if we find an assignment x such that f  x    is equal to the dual objective  we are guaranteed that x is the MAP assignment  since the dual objective upper bounds the MAP value   Indeed  using this property  kN  i            Monotonically decreasing upper bound on MAP     Choosing clusters which give a guaranteed bound improvement   xi     X eE  max ee  xe     xe  X  ce  xe    c ec  It should be noted  however  that not all  are dual feasible  Rather   needs to result from a reparameterization of the underlying potentials  see       However  it turns out that after updating all the MPLP messages once  all subsequent  will be dual feasible  regardless of how  is initialized   By LP duality  there exists a value of  such that g   is equal to the optimum of the corresponding primal LP  Although the MPLP updates decrease the objective at every iteration  they may converge to a  that is not dual optimal  as discussed in      However  as we will show in the experiments  our procedure often finds the exact MAP solution  and therefore also achieves the primal optimum in these cases       Choosing Clusters in the Dual LP Relaxation  In this section we provide a very simple procedure that allows adding clusters to MPLP  while satisfying the    In our experiments  we initialize all messages to zero     Edge to Node  For every edge ij  E and node i  or j  in the edge  iji  xi         hX i     j i  xi     i  xi     max cij  xi   xj     i  x       x   x       x   j ij i j j j j     xj c ijc  j where j i  xi   is the sum of edge to node messages into i that are not from edge ij  namely  i  xi     P kN  i  j iki  xi      Edge to Edge  For every edge ij  E  ijij  xi   xj     i  h   X j  x       x       x   x       x       x   cij  xi   xj     i j i ij i j i i j j i   c ijc   j   Triplet to Edge  For every triplet c  C and every edge e  c  ce  xe           h X   X    ee  xe     c  e  xe     max e  e   xe          xc e     e c e  c     c e  c   X   i c  e   xe     c      c e   c   Figure    The generalized MPLP updates for an LP relaxation with three node clusters  algorithmic properties in the beginning of Section    Assume we have a set of triplet clusters C and now wish to add a new triplet  Denote the messages before adding the new triplet by t   Two questions naturally arise  The first is  assuming we decide to add a given triplet  how do we set t   such that the dual objective retains its previous value g t    The second question is how to choose the new triplet to add  The initialization problem is straightforward  Simply set t   to equal t for all messages from triplets and edges in the previous run  and set t   for the messages from the new triplet to its edges to zero   This clearly results in g t       g t    In order to choose a good triplet  one strategy would be to add different triplets and run MPLP until convergence to find the one that decreases the objective the most  However  this may be computationally costly and  as we show in the experiments  is not necessary  Instead  the criterion we use is to consider the decrease in value that results from just sending messages from the triplet c to its edges  while keeping all other messages fixed   The decrease in g   resulting from such an update has a simple form  as we show next  Assume we are considering adding a triplet c  For every edge e  c  define be  xe   to be X be  xe     ee  xe     c  e  xe         c   ec     It is straightforward to show that t   is dual feasible   where the summation over clusters c  does not include c  those messages are initially zero   The decrease in g   corresponding to updating only messages from c to the edges e  c can be shown to be   d c     X ec  max be  xe    max xe  xc    X  be  xe            ec  The above corresponds to the difference between independently maximizing each edge and jointly maximizing over the three edges  Thus d c  is a lower bound on the improvement in the dual objective if we were to add triplet c  Our algorithm will therefore add the triplet c that maximizes d c        The Dual Algorithm  We now present the complete algorithm for adding clusters and optimizing over them  Let C  be the predefined set of triplet clusters that we will consider adding to our relaxation  and let CL be the initial relaxation consisting of only edge clusters  pairwise local consistency      Run MPLP until convergence using the CL clusters     Find an integral solution x by locally maximizing the P single node beliefs bi  xi    where bi  xi     i  xi     kN  i  kii  xi    Ties are broken arbitrarily     If the dual objective g t   is sufficiently close to the primal objective f  x     terminate  since x is approximately the MAP        Add the cluster c  C  with the largest guaranteed bound improvement  d c   to the relaxation     Construct warm start messages t   from t      Run MPLP for N iterations  and return to    Note that we obtain  at least  the promised bound improvement d c  within the first iteration of step    By allowing MPLP to run for N iterations  the effect of adding the cluster will be propagated throughout the model  obtaining an additional decrease in the bound  Since the MPLP updates correspond to coordinatedescent in the dual LP  every step of the algorithm decreases the upper bound on the MAP  The monotonicity property holds even if MPLP does not converge in step    giving us the flexibility to choose the number of iterations N   In Section   we show results corresponding to two different choices of N   In the case where we run MPLP to convergence before choosing the next cluster  we can show that the greedy bound minimization corresponds to a cutting plane algorithm  as stated below  Theorem    Given a dual optimal solution  if we find a cluster for which we can guarantee a bound decrease  all primal optimal solutions were inconsistent with respect to this cluster  Proof  By duality both the dual optimum and the primal optimum will decrease  Suppose for contradiction that in the previous iteration there was a primal feasible point that was cluster consistent and achieved the LP optimum  Since we are maximizing the LP  after adding the cluster consistency constraint  this point is still feasible and the optimal value of the primal LP will not change  giving our contradiction  This theorem does not tell us how much the given cluster consistency constraint was violated  and the distinction remains that a typical cutting plane algorithm would attempt to find the constraint which is most violated      Related Work  Since MPLP is closely related to the max product generalized belief propagation  GBP  algorithm  our work can be thought of as a region pursuit method for GBP  This is closely related to the work of Welling      who suggested a region pursuit method for sum product GBP  Similar to our work  he suggested greedily adding from a candidate set of possible clusters  At each iteration  the cluster that results in the largest change in the GBP free energy is added  He showed excellent results for  D grids  but on fully connected graphs the performance actually started deteriorating  with additional clusters  In       a heuristic related to maxent normality      was used as a stopping criterion for region pursuit to avoid this behavior  In our work  in contrast  since we are working with the dual function of the LP  we can guarantee monotonic improvement throughout the running of the algorithm  Our work is also similar to Wellings in that we focus on criteria for determining the utility of adding a cluster  not on finding these clusters efficiently  We found in our experiments that a simple enumeration over small clusters proved extremely effective  For problems where triplet clusters alone would not suffice to find the MAP  we could triangulate the graph and consider larger clusters  This approach is reminiscent of the bounded join graphs described in      There is a large body of recent work describing the relationship between message passing algorithms such as belief propagation  and LP relaxations              Although we have focused here on using one particular message passing algorithm  MPLP  we emphasize that similar region pursuit algorithms can be derived for other message passing algorithms as well  In particular  for all the convex max product BP algorithms described in       it is easy to design region pursuit methods  The main advantage of using MPLP is its guaranteed decrease of the dual value at each iteration  a guarantee that does not exist for general convex BP algorithms  Region pursuit algorithms are also conceptually related to the question of message scheduling in BP  as in the work of Elidan et al       One way to think of region pursuit is to consider a graph where all the clusters are present all the time  but send and receive non informative messages  The question of which cluster to add to an approximation  is thus analogous to the question of which message to update next      Experiments  Due to the scalable nature of our message passing algorithm  we can apply it to cases where standard LP solvers cannot be applied to the primal LP  see also        Here we report applications to problems in computational biology and machine vision   We use the algorithm from Section     for all of our experiments  We first run MPLP with edge clusters until convergence or for at most      iterations  whichever comes first  All of our experiments  except those intended to show the difference between schedules  use N      for the number of MPLP iterations run after adding a cluster  While running MPLP we use the messages to decode an integral solution  and compare    Graphical models for these are given in                        Objective                               MPLP for    iterations MPLP until convergence MAP                                        MPLP iterations        Figure    Comparison of different schedules for adding clusters to relaxation on a side chain prediction problem   the dual objective to the value of the integral solution  If these are equal  we have found the MAP solution   Otherwise  we keep adding triplets  Our results will show that we often find the MAP solution to these hard problems by using only a small number of triplet clusters  This indicates both that triplets are sufficient for characterizing M G  near the MAP solution of these problems  and that our algorithm can efficiently find the informative triplets       Side Chain Prediction  The side chain prediction problem involves finding the three dimensional configuration of rotamers given the backbone structure of a protein       This problem can be posed as finding the MAP configuration of a pairwise model  and in      the TRBP algorithm      was used to find the MAP solution for most of the models studied  However  for    of the models  TRBP could not find the MAP solution  In earlier work      we used a cutting plane algorithm to solve these side chain problems and found the MAP solution for all    models  Here  we applied our dual algorithm to the same    models and found that it also results in the MAP solution for all of them  up to a     integrality gap   This required adding between   and    triplets per model  The running time was between   minute and   hour to solve each problem  with over half solved in under   minutes  On average we added only   triplets  median was       another indication of the relative ease with which these techniques can solve the side chain prediction problem    In practice  we terminate when the dual objective is within     of the decoded assignment  so these are approximate MAP solutions  Note that the objective values are significantly larger than this threshold   We also used these models to study different update schedules  One schedule  which gave the results in the previous paragraph  was to first run a pairwise model for      iterations  and then alternate between adding triplets and running MPLP for    more iterations  In the second schedule  we run MPLP to convergence after adding each triplet  Figure   shows the two schedules for the side chain protein  gsk  one of the side chain proteins which took us the longest to solve     minutes   Running MPLP to convergence results in a much larger number of overall MPLP iterations compared to using only    iterations  This highlights one of the advantages of our method  adding a new cluster does not require solving the earlier problem to convergence       Protein Design  The protein design problem is the inverse of the protein folding problem  Given a particular  D shape  we wish to find a sequence of amino acids that will be as stable as possible in that  D shape  Typically this is done by finding a set of amino acids and rotamer configurations that minimizes an approximate energy  While the problem is quite different from side chain prediction  it can be solved using the same graph structure  as shown in       The only difference is that now the nodes do not just denote rotamers  but also the identity of the amino acid at that location  Thus  the state space here is significantly larger than in the sidechain prediction problem  up to     states per variable for most variables   In contrast to the side chain prediction problems  which are often easily solved by general purpose integer linear programming packages such as CPLEXs branch and cut algorithm      the sheer size of the protein design problems immediately limits the techniques by which we can attempt to solve them  Algorithms such as our earlier cutting plane algorithm      or CPLEXs branch and cut algorithm require solving the primal LP relaxation at least once  but solving the primal LP on all but the smallest of the design problems is intractable       Branch and bound schemes have been recently used in conjunction with a message passing algorithm     and applied to similar protein design problems  although not the ones we solve here  We applied our method to the    protein design problems described in       adding   triplets at a time to the relaxation  The key striking result of these experiments is that our method found the exact MAP configuration for all but one of the proteins   up to a precision of     in the integrality gap   This is es   We could not solve  fpo  the largest protein    pecially impressive since  as reported in       only   of these problems were solvable using TRBP  and the primal problem was too big for commercial LP solvers such as CPLEX  For the problem where we did not find the MAP  we did not reach a point where all the triplets in the graph were included  since we ran out of memory beforehand  Among the problems that were solved exactly  the mean running time was     hours with a maximum of    days and a minimum of a few minutes  We note again that most of these problems could not be solved using LP solvers  and when LP solvers could be used  they were typically at least    times slower than message passing algorithms similar to ours  see      for detailed timing comparisons   Note that the main computational burden in the algorithm is processing triplet messages  Since each variable has roughly     states  passing a triplet message requires     operations  Thus the number of triplets added is the key algorithmic complexity issue  For the models that were solved exactly  the median number of triplets added was      min     max        As mentioned earlier  for the unsolved model this number grew until the machines memory was exhausted  We believe however  that by optimizing our code for speed and memory we will be able to accommodate a larger number of triplets  and possibly solve the remaining model as well  Our current code is written mostly in Matlab  so significant optimization may be possible       Stereo Vision  Given a stereo pair of images  the stereo problem is to find the disparity of each pixel in a reference image  This disparity can be straightforwardly translated into depth from the camera  The best algorithms currently known for the stereo problem are those that minimize a global energy function       which is equivalent to finding a MAP configuration in a pairwise model  For our experiments we use the pairwise model described in       and apply our procedure to the Tsukuba sequence from the standard Middlebury stereo benchmark set       reduced in size to contain    x    pixels  Since there are no connected triplets in the grid graph  we use our method with square clusters  We calculate the bound decrease using square clusters  but rather than add them directly  we triangulate the cycle and add two triplet clusters  This results in an equivalent relaxation  but has the consequence that we may have to wait until MPLP convergence to achieve the guaranteed bound improvement  In the first experiment  we varied the parameters of the            x                        Objective Integer solution                                                                         MPLP iterations  Figure    Dual objective and value of decoded integer solution for one of the reduced Tsukuba stereo models  as a function of MPLP iterations  It can be seen that both curves converge to the same value  indicating that the MAP solution was found   energy function to create several different instances  We tried to find the MAP using TRBP  resolving ties using the methods proposed in      In   out of    cases those methods failed  Using our algorithm  we managed to find the MAP for all   cases   Figure   shows the dual objective and the decoded integer solution after each MPLP iteration  for one set of parameters  In the results above  we added    squares at a time to the relaxation  We next contrasted it with two strategies  one where we pick    random squares  not using our bound improvement criterion  and one where we pick the single best square according to the bound criterion  Figure   shows the resulting bound per iteration for one of the models  It can be seen that the random method is much slower than the bound criterion based one  and that adding    squares at a time is better than just one  We ended up adding      squares when adding    at a time  and    squares when adding just one  Overall  adding    squares at a time turned out to be faster  We also tried running MPLP with all of the square clusters  Although fewer MPLP iterations were needed  the cost of using all squares resulted in an overall running time of about four times longer      For one of these models  a few single node beliefs at convergence were tied  and we used the junction tree algorithm to decode the tied nodes  see         
 Inference problems in graphical models are often approximated by casting them as constrained optimization problems  Message passing algorithms  such as belief propagation  have previously been suggested as methods for solving these optimization problems  However  there are few convergence guarantees for such algorithms  and the algorithms are therefore not guaranteed to solve the corresponding optimization problem  Here we present an oriented tree decomposition algorithm that is guaranteed to converge to the global optimum of the Tree Reweighted  TRW  variational problem  Our algorithm performs local updates in the convex dual of the TRW problem  an unconstrained generalized geometric program  Primal updates  also local  correspond to oriented reparametrization operations that leave the distribution intact      Introduction  The problem of probabilistic inference in graphical models refers to the task of calculating marginal distributions or the most likely assignment variables  Both these problems are generally NP hard  requiring approximate methods  Many approximate inference methods  including message passing algorithms  can be viewed as trying to solve a variational formulation of the inference problem  The idea in variational approaches is to cast approximate inference as a constrained minimization of a free energy function  see      for a recent review   Two key questions arise in this context  The first is how to choose the free energy  and the second is how to design efficient algorithms that minimize it  When the Bethe free energy is used  it has been shown      that  Tommi Jaakkola CSAIL Massachusetts Institute of Technology Cambridge  MA        fixed points of the belief propagation  BP  algorithm correspond to local minima of the free energy  However  BP is not generally guaranteed to converge to a fixed point  Although there do exist algorithms that are guaranteed to converge to a local minimum of the Bethe free energy           its global minimization is still a hard non convex problem for which no efficient algorithms are known  The difficulties with the Bethe free energy derive from its non convexity and corresponding local minima problem  To avoid this difficulty  several authors have recently studied convex free energies             The associated convex optimization problems can in principle be solved using generic convex optimization procedures     with guarantees of finding the global optimum in polynomial time  Although this presents a significant improvement over the non convex case  the generic optimization route may be very costly in large practical problems  For example  when using a generic convex solver  every update of the variables has complexity O n   where n is the number of variables  In contrast  the optimization using message passing algorithms can be reduced to local updates with O    operations  Interestingly  even in the convex setting  the convergence of these message passing algorithms is typically not guaranteed  and damping heuristics are required to ensure convergence in practice       A prominent exception is     where the author provides a provably convergent message passing algorithm for free energies where the entropy term is a non negative combination of joint entropies  Here we provide a provably convergent message passing algorithm for a specific variational setup  namely the Tree Reweighted  TRW  optimization problem of Wainwright et al        The algorithm we propose is guaranteed to converge to the global optimum of the free energy  and does not require additional parameters such as the damping ratio  A key step in obtaining the updates is deriving the convex dual of TRW  which we show to be an unconstrained instance of a        GLOBERSON   JAAKKOLA generalized geometric program  GP       We derive a message passing algorithm  which we call TRW Geometric Programming  TRW GP   that yields monotone improvement of the dual GP  We demonstrate the utility of our TRW GP algorithm by providing an example where the TRW message passing algorithm in      does not converge  but TRW GP does      where H Xi   is the entropy of i  xi   and I Xi   Xj   is the mutual information calculated from ij  xi   xj    Note that this expression is independent of the direction of the edges in the tree  We will make use of the directed edges in the next section  Define the following variational free energy function F         The Tree Reweighting Formulation  We consider pairwise Markov random fields  MRF  over a set of variables x   x            xn   Given a graph G with n vertices V and a set of edges E  an MRF is a distribution over x defined by p x         PijE ij  xi  xj   PiV e Z    i  xi    Our focus here is on approximating singleton marginals of p x     namely p xi      This problem is closely related to that of evaluating the partition function Z    We focus on the TRW variational problem which yields an upper bound on Z   as well as a set of approximate marginals obtained from the minimizing solution  We begin by briefly reviewing the TRW formalism  Consider a set of k spanning trees on G denoted by T             Tk   P and a distribution i over these trees where i    and i      To avoid overloading notation in subsequent analysis  we assume here that the trees are directed  so that the same tree structure may appear multiple times with different edge orientations  This differs from the presentation in      though the distinction is immaterial in the remainder of this section  We also introduce the notion of pseudomarginals defined as the singleton and pairwise marginals i  xi    ij  xi   xj   associated with the edges and nodes of G  We use  to denote the set of all these marginals and C G  the set of s that are pairwise consistent P P ij  xi   xj     i  xi     ij  xi   xj     j  xj   xj xi P i  xi         ij  xi   xj        xi  For a given tree T and   C G   define the entropy H   T   to be the entropy of an MRF on the tree T with marginals given by   Note that only a subset of the pairwise distributions in  will be used for each tree  namely ij  xi   xj   such that ij is an edge in T   The tree entropy may be written in closed form as  cf        X X H   T     H Xi    I Xi   Xj       ijT  k X  i H   Ti           i    In      it is shown that minimizing F        results in an upper bound on the log partition function log Z     min F          C G        where ij  xi   xj   and i  xi   are parameters   denotes all the parameters  and Z   is the partition function   i  F                    The minimization also results in an optimal  minimizing    which is used to approximate the marginals of p x     Empirical results in      show that TRW usually performs as well as  and often better than the standard Bethe free energy approximations  especially in regimes where BP fails to converge      Conditional Entropies and Directed Edge Probabilities  Our goal is to use convex duality to obtain the dual problem of Eq       To achieve this  we first seek a representation of F        that is a convex function of  for all values of   and not just within the consistent set   C G   For example  the entropy term in Eq      is concave only for   C G  but not for a general   We therefore seek an alternative expression for the tree entropy  Let r T   be the root node of T  recall that the trees are directed   We write the entropy associated with the tree as X H   T     H Xr T       H Xi  Xj       jiT  where j  i  T implies that there is a directed edge from vertex j to vertex i in the directed tree T   The conditional entropy H Xi  Xj   is assumed to be calculated only on the basis of the joint marginal ij  xi   xj    and does not involve i  xi    The entropy H Xr T     is calculated via the singleton marginal r T    xr T      The expressions in Eq      and Eq      will agree whenever   C G   However  they will yield different results when     C G   The advantage of Eq      is that H   T   is now a concave function of the set of marginals   The concavity follows immediately from the concavity of H Xi   as a function of i  xi   and the concavity of the conditional entropy H Xi  Xj   as a function of ij  xi   xj          GLOBERSON   JAAKKOLA The function F        involves a summation over a potentially large number of tree entropies  To express this compactly while maintaining directionality  we define i j as the probability that the directed edge j  i is present in a tree drawn according to the distribution  over trees  Similarly  we define i as the probability that node i appears as a root  We note that it is possible to find such edge probabilities for distributions  e g  uniform  over the set of all spanning trees by employing a variant of the matrix tree theorem for directed trees  see      p      and        The function F        can now be written as      X  iV  i H Xi     X  ijE  i j H Xi  Xj    now on  and refer to the consistency constraints by   C G   The TRW primal problem is then P T RW    min F                The TRW Convex Dual         C G   The convex dual of P T RW is derived in App  A  and is in fact a convex unconstrained minimization problem  In what follows we describe this dual  The dual variables will be denoted by ij  xi   xj   for ij  E  and are not constrained   The dual objective is given by X X      x  P kN  i  k i  xi     FD          i log e i i i xi  i  where the edge set E contains edges in both directions  In other words  if ij  E then ji is also in E  The new function F        is convex in  without assuming consistency of the marginals           where j i  xi     is a function of the  variables  j i  xi       j i log  X  e     ij  xi  xj   j i ij  xi  xj    j i  xj  and j i is defined as     ji  E j i     ij  E   The dual TRW optimization problem is then  The TRW primal problem is given by min F           C G   DT RW        Since the function F        is now convex for all  and the set of constraints is linear  this optimization problem is convex and thus has an equivalent convex dual       However  it is not immediately clear how to derive this dual in closed form  The main difficulty is that two terms in the objective F        depend on ij  xi   xj    namely H Xi  Xj   and H Xj  Xi    To get around this problem we introduce additional variables to the primal problem  Specifically  we replace ij  xi   xj   by two copies which we denote by i j  xi   xj   and j i  xi   xj    and require that these two copies are identical  The entropy H Xi  Xj   is then evaluated via the variables i j  xi   xj    We shall also find it convenient to replace the consistency constraints in C G  by the following equivalent directed consistency constraints i j  xi   xj     j i  xi   xj   P P j i  xi   xj     i  xi     i j  xi   xj     j  xj   xj xi P i  xi         i j  xi   xj        j i  xi   xj        xi  For simplicity we will continue to denote the new extended variable set by   as we will be using it from   Strict duality follows from Slaters conditions  which are satisfied in this case   min FD                 We re emphasize the fact the DTRW is an unconstrained minimization of a function of   The variables j i  xi     are introduced merely for the purpose of notational convenience  The mapping between dual and primal variables can be shown to be    i  xi    ei  i  xi   j i  xj  xi    e  P  kN  i   k i  xi         ij  xi  xj   j i ij  xi  xj    j i           This relation maps the optimal  to the optimal   but we shall also use it for non optimal values  The dual objective FD        is a convex function  see App  B  and therefore has no local minima      Dual Gradient and Optimum  The DTRW problem presented above is unconstrained and can thus be solved using a variety of gradient based algorithms  such as conjugate gradient or BFGS       The gradient of FD        w r t   is FD          i j  xi  xj  j  xj    j i  xj  xi  i  xi   ij  xi   xj   where the distributions are given by the dual to primal mapping in Eq        The gradient is thus a measure   Note that  variables are not directed  i e   there is one variable ij per edge         GLOBERSON   JAAKKOLA of the discrepancy between two ways of calculating the joint pairwise marginal  based on the two different orientations of the edge ij  To characterize the optimum of DTRW we set the gradient to zero  yielding the following simple dual optimality criterion i j  xi  xj  j  xj     j i  xj  xi  i  xi            Thus at the optimum the two alternative ways of estimating ij  xi   xj   will yield the same result  Calculating the gradient w r t a given ij  xi   xj   has complexity O     and relies only on ij  xi   xj   for edges containing i or j  Thus the gradient can be calculated locally  and gradient descent algorithms can be implemented efficiently  One drawback of gradient based algorithms is their reliance on line search modules for finding a step size that decreases the objective  In the next section we consider updates that are parameter free      Local Marginal Updates  The gradient updates described in the previous section use the difference between two joint distributions  We will now focus on updates relying on the ratio between these distributions  Consider t   t ij  xi   xj     ij  xi   xj   o log  tj i  xj  xi  ti  xi    ti j  xi  xj  tj  xj          where tj i  xj  xi   and ti  xi   are functions of  as in Eq       and o is a step size whose value will be discussed in the next section  As a ratio of two expected values  the update is reminiscent of Generalized Iterative Scaling      We shall assume for simplicity that only one edge is updated at each time step t   Lemma       For     o   min i   j   i j   j i   the dual objective is decreased at every iteration so that D  t      for all t  Furthermore  D  t       holds if and only if the optimum condition of Eq       is satisfied  Any choice of o that is smaller than min i   j   i j   j i   will result in monotone improvement of the objective  In the current implementation we use o      min i   j   i j   j i    This value turns out to minimize a first order approximation of the improvement in the objective  and was found to work well in practice  The convergence to the global optimum now follows from Lemma      Lemma       The updates in Eq       with o as in Lemma     converge to the joint optimum of PTRW and DTRW  Proof  Denote the mapping from t to t   by R t     t     The mapping is clearly continuous  By Lemma     the sequence FD   t       is monotonically decreasing  It is also bounded since FD        is bounded and thus the difference series D  t   converges to zero  Taking t to infinity then implies that t has a convergent subsequence that converges to some    This  will then satisfy FD           FD  R          We know from the Lemma     that such a point necessarily satisfies the zero gradient condition in Eq        and thus   or more precisely  the corresponding   minimizes the dual objective       Tree Re parametrization View  The TRW problem can be interpreted in terms of iterating through different re parametrizations of the distribution p x          Here we present a related view of our algorithm   The update in Eq       is performed on the  variables  An equivalent  and somewhat simpler update may be derived in terms of the variables ti j  xi  xj   and tj  xj    The resulting updates and algorithm are described in Figure    We call the resulting algorithm TRW GP  TRW Geometric Programming    We wish to show that the marginal variables obtained by the algorithm can always be used to obtain the original distribution via Y Y tj i  xj  xi  j i        p x      ct ti  xi  i       For t     this is clearly true  We proceed by induction  Assume that at iteration t we have a reparametrization with constant ct   Substituting the update rule in Figure   and using simple algebra shows that we again have a reparametrization  only with  Convergence Proof  To analyze the convergence of the update in the previous section  we need to consider the resulting change in the objective FD         namely FD   t        FD   t          It can be shown  see App  D  that this difference only depends on the  variables in the TRW GP algorithm  and thus we denote it by D  t    Since FD   t       should be minimized  this difference needs to be non negative  This is indeed guaranteed by the following lemma  see App  D    i  ct     ct eFD    ijE  t       FD   t        ct eD    t          To carefully account for the possibility that some of the converging marginals would involve zero probabilities  the updates in the primal form  along with the objective  can be written in a form without any ratios    GLOBERSON   JAAKKOLA       Inputs  A graph G    E  V    parameter vector  on G  root probabilities i and directed edge probabilities i j for  ij    ji   E     Initialization  Set  i  xi    ei i  xi   and  i j  xi  xj    ei j ij  xi  xj      Algorithm  Iterate until small enough change in marginals   Set o         min i   j   i j   j i    and update  t    xi    ti  xi   i t   i j  xi  xj      P xj     tj i  xj  xi      ti j  xi  xj   oi j      j i i  o  j i     ti j  xi  xj  tj  xj   tj i  xj  xi  ti  xi    tj i  xj  xi  ti  xi   tj  xj     o  i j  Output  Final values of marginals  Figure    The TRW GP algorithm expressed in terms of conditional and singleton marginals  In other words the multiplicative constant turns out to be related to the improvement in the dual function  This creates an interesting link between reparametrization and minimization  and may be used to study message passing algorithms where a dual is more difficult to characterize      Relation to Previous Work  Heskes     recently presented a detailed study of convex free energies  When the entropy term is a positive combination of joint and singleton entropies  and is therefore concave   he provides a local update algorithm that is monotone in the convex dual  and converges to the global optimum  He then discusses the application of the same algorithm to the case where the singleton entropies all have negative weight  and the overall entropy is convex over the set of constraints   In this case  the dual is generally not given in closed form and it is not known if the algorithm decreases it at every step  However  Heskes argues that with sufficient damping the algorithm can be shown to converge  although the exact form of damping is not given  Since the TRW entropy can be shown to decompose into positively weighted pairwise entropies and negatively weighted singleton entropies  it satisfies the above condition in Heskes work  Our analysis provides several advantages over the algorithm in      First  we derive a closed form solution of dual  Second  the dual is unconstrained  and thus allows unconstrained minimization methods to be applied  Third  unlike most belief propagation variants  our algorithm    The discussion in     is in terms of general regions  not just pairs  We present his argument for the simpler pairwise case   is shown to provide a monotone improvement of an objective function    and thus diverges from the standard fixed point analysis used in message passing algorithms  Finally  another algorithm which is guaranteed to converge to a global minimum of convexified free energies is the double loop CCCP algorithm of Yuille       The main disadvantage of CCCP is that each iteration requires solving an optimization problem  This usually results in slower convergence  and furthermore it is not clear what precision is required for the inner loop optimization  and how this affects convergence guarantees  The algorithm we present here is essentially a single loop method  and is thus easier to analyze      Empirical Demonstration  The original TRW message passing  TRW MP  algorithm presented in      is not generally guaranteed to converge  However  we observed empirically that when damping of        is applied to the log messages  convergence is always achieved   To compare TRWMP to TRW GP  we use the pseudomarginals generated by TRW MP  as marginals in the primal objective F        in Eq       This value is not expected to be an upper or lower bound on the optimum of F         since the TRW MP pseudomarginals are    As mentioned above  Heskes presents such an algorithm for positively weighted singleton and pairwise entropies  It is however not clear that such entropies are useful in practice   This observation is in line with Heskes argument that sufficiently damped messages will converge for the case of the TRW free energy    See Equations      and      in              GLOBERSON   JAAKKOLA TRWGP TRWMP TRWMP damped                              Iteration                 PrimalDual Value  PrimalDual Value       TRWGP TRWMP TRWMP damped                              Iteration            Figure     Illustration of the dual message passing algorithm for a        Ising model  The TRW GP curve shows the dual objective value FD        obtained by the TRW GP algorithm  The TRW MP curves show the primal objective values F       obtained by TRW message passing algorithms  The damped TRW MP used a damping of     in the log domain  The MRF parameters were set as follows  F      I     for the left figure  and F      I     for the right figure   not guaranteed to be pairwise consistent  except at the optimum  However  since the TRW MP pseudomarginals converge to the optimal primal marginals  the value F        will converge to the primal optimum  The progress of TRW GP may be monitored by evaluating FD        at every iteration  This value is guaranteed to decrease and converge to the optimum of FD        which is identical to the optimum of F         We can thus observe the rate at which the different algorithms converge to their joint optimum  To study the convergence rate of the two algorithms  we used an Ising model on a        grid with interaction parameters ij drawn uniformly from  I   I   and field parameters i drawn uniformly from  F   FP   The MRF is given by p x     P ij xi xj   iV i xi ijE e where xi           We used a uniform distribution over directed spanning trees calculated as in       Figure    left  shows an example run where the undamped TRW MP algorithm does not converge  but the TRW GP and the damped TRW MP do converge  and do so roughly at the same rate  Figure    right  shows an example where both TRW MP algorithms converge and do so at a faster rate than TRW GP  We experimented with various values of F and I and have observed that at lower interaction levels  e g   I    for F      the TRW MP algorithms outperform TRW GP  whereas for higher interaction levels the undamped TRW MP does not converge  but the damped version converges at roughly the same rate as TRW GP  We also experimented with conjugate gradient minimization of FD         but these did not yield better rates than TRW GP       Conclusions  We presented a novel message passing algorithm whose updates yield a monotone improvement on the dual of the TRW free energy minimization problem  In order to obtain a closed form dual we used two tricks  The first was to decouple different entropies that depend on the same marginals by introducing multiple copies of these marginals  The second was to use uni directional consistency constraints  so that every copy of a joint marginal appears in a single consistency constraint  Although we presented the method in the context of tree decompositions  the algorithm itself still applies as long as i j and i are non negative  although the upper bound on the log partition function may not be guaranteed in this case   The TRW GP algorithm resolves the convergence problems with the undamped TRW MP algorithm  However  we observed empirically that the damped TRW MP algorithm always converges  and typically at a better rate than TRW GP  Thus  the main contribution of the current paper is in introducing a dual framework for message passing algorithms  which could be used to analyze existing algorithms  and possibly develop faster variants in the future  Free energies may be defined using marginals of more than two variables           In a recent paper     we study the relation between such free energies and GP  It will be worthwhile to study generalizations of TRW GP to this case  Another interesting extension is to the MAP problem  where the corresponding variational problem is a linear program  Global convergence results for MAP message passing algorithms such as max product are also hard to obtain in the general case  It turns out that an approach similar to the one presented here may be used to obtained convergent algorithms to solve the MAP linear program  These algorithms will be presented elsewhere   
 Discriminative linear models are a popular tool in machine learning  These can be generally divided into two types  linear classifiers  such as support vector machines  SVMs   which are well studied and provide stateof the art results  and probabilistic models such as logistic regression  One shortcoming of SVMs is that their output  known as the margin  is not calibrated  so that it is difficult to incorporate such models as components of larger systems  This problem is solved in the probabilistic approach  We combine these two approaches above by constructing a model which is both linear in the model parameters and probabilistic  thus allowing maximum margin training with calibrated outputs  Our model assumes that classes correspond to linear subspaces  rather than to half spaces   a view which is closely related to concepts in quantum detection theory  The corresponding optimization problems are semidefinite programs which can be solved efficiently  We illustrate the performance of our algorithm on real world datasets  and show that it outperforms second order kernel methods      Introduction  Support Vector Machines  SVM       are commonly regarded as the state of the art in supervised learning  One of their key advantages is their maximization of the margin  a property which also guarantees certain generalization bounds      A different class of supervised learning algorithms is the one based on probabilistic models  such as logistic regression      Such models are parameterizations of the class conditional distributions  which are trained to maximize the like   Amir Globerson CSAIL Massachusetts Institute of Technology Cambridge  MA        lihood of the observed data  One advantage of probabilistic models is that the probabilities they generate may be used as a calibrated measure of certainty about class prediction  Such a measure may be used in systems which incorporate classifiers as modules  and is generally useful in balancing different types of errors  The confidence measure in SVMs is commonly taken to be the margin of an example  which is a geometric quantity and is not naturally calibrated or even bounded  While there have been previous attempts on assigning probabilistic outputs to SVMs       they have been based on transforming the margin into the        range  and not on a complete probabilistic model  Another integral property of SVMs is of course the half space structure of classes  in the binary case   An equivalent statement is that SVMs assume there is a transformation of inputs into the real line such that positive and negative points correspond to different classes  Moreover  by using kernels  linear separation need only be assumed for a nonlinear transformation of the variables  However  geometric intuition is often lost as a result of the kernel transformation  and the resulting separators are not easily interpretable  In this work  we present a different view of class separation  which incorporates both the concepts of margin maximization and probabilistic modeling  Our approach assumes that classes correspond to orthogonal linear subspaces in feature space  This assumption is reasonable in many domains where the existence or absence of a feature is the key predictor of its class identity  rather than its exact value or its relation to values of other features  For example  in document classification there may be subsets of words  or linear combinations of word counts  whose appearance indicates the document topic  In image classification  a set of pixels may be indicative of image content regardless of their exact intensity ratios  An alternative statement of the problem is that there exists a linear transformation of feature space such that a unique   subset of coordinates is active in each class  In order to measure the degree to which a given input point belongs to a given subspace we use a projection operator which measures what fraction of the points norm lies in a subspace  Such projection operators correspond to matrices with eigenvalues in the discrete set         We relax this assumption to the        range  which makes the model tractable  It also turns out that the output of the projection operators have a natural interpretation as probabilities  and these probabilities are linear functions of the model parameters  the projection matrices   Because the model is both a linear and a probabilistic model  we can efficiently implement both methods that rely on margin maximization  and those that maximize probability related measures such as log likelihood or optimal Bayes errors  All these problems are convex and two of them are Semidefinite Programs  SDP       for which efficient algorithms exist  Our model is closely related to ideas in quantum detection and estimation  where semidefinite matrices are used to generate probabilities  A simple view is that the class conditional models are represented by SDP matrices with a unit trace and the detectors are represented using PSD matrices  We compare the performance of our method to the closely related second order kernels SVM  and show that it achieves improved performance on a handwritten digit classification task  while providing meaningful probabilistic output      The Probabilistic Model  Consider a classification task where x  Rd are the feature vectors  and classes are y              k   Denote the classification rule by f  x    y  We assume that classes reside in linear subspaces Sy  i e   x  Sy  f  x    y  such that Si  Sj        i    j   Si and Sj are orthogonal spaces  and the spaces Sy span the entire space  S   S         Sk   Rd   This corresponds to the assumption that there exists a linear transformation in feature space such that a subset of coordinates is active for a given class  and these coordinates are mutually exclusive  The projection operator on the space Sy is a matrix Ay such that Ay is idempotent  thus  for every x  Sy we have Ay x   x  and symmetric  A y   Ay  Ay   ATy    This implies that if x  Sy then kAy xk    kxk    and if x    Sy then kAy xk   kxk    The above suggests that kAy xk  may be taken as a measure of the degree to which x belongs to class y  Now  note that kAy xk    xT Ay x so that this measure  is in fact a quadratic function of x  and importantly is linear in Ay   Since we are interested in the multiclass setting  it is natural to define kAy xk  as the probability of class y given the point x  p y x     xT      P  y  Ay  x  xT A y x         This implies the probability is invariant to the norm of x and we can thus always normalize x such that kxk       The normalization factor in Eq      makes the probability a nonlinear function of Ay   However  our assumption on P the structure of the classes in fact implies that y Ay   I  To see this  denote the orthogonal basis of Sy by Vy   The S assumption about the structure of Sy implies that y Vy    v            vd   yields an orthogonal basis of the entire space  Denote by matrix whose columns are  vi  ni     Then P V the P T T   I by the assumption of i vi vi   V V y Ay   orthogonality and the fact that Vy is orthogonal to Vy  for y    y     P Since y Ay   I the probabilistic model of Eq      reduces to p y x    xT Ay x         Optimization over the set of idempotent matrices is an integer optimization problem  which seems to be hard to solve  We therefore relax this assumption  and only constrain Ay to be positive semidefinite  and P to satisfy A   I  These two constraints imply y y that the eigenvalues of Ay lie between zero and one  Since idempotent matrices are characterized by eigenvalues in           we can interpret our relaxation as relaxing this eigenvalues constraint by the constraint           see e g             The Learning Problem  We now turn to the problem of learning a classifier using the probabilistic model defined in Eq       Given a labeled sample  xi   yi    i              n  we seek a set of parameters Ay which result in a good classifier  Below we present two approaches to this problem  The first is related to margin based methods  and the second to likelihood based ones       Margin based approaches  A desired property in a classifier is that the probability it assigns to the correct class is higher that those assigned to incorrect classes  In other words  we wish to   maximize the margin between the correct probability p yi  xi   and the incorrect ones p z xi   where z    yi   Define the margin of a point xi by  mi   p yi  xi    max p z xi     z  yi  Then  as in other margin based classifiers  we wish to maximize the minimum margin  In the separable case  i e   there exists a classifier such that all margins on the training set are positive   the margin maximization problem is given by the following semidefinite program  max s t   p y P i  xi    p z xi     y Ay   I Ay o    i   z    yi  If the data is not separable  we add a slack variable i for each sample point P max    i i s t p y P i  xi    p z xi      i i  z    yi     y Ay   I Ay o    i    where     is a tradeoff parameter  We call this method the MaxMargin approach since it seeks a maximum margin model       Likelihood based approaches  Since our model is a parametric family of distributions  one way to optimize it is via standard maximum likelihood  This yields the following optimization problem P max Pi log p yi  xi   s t     y Ay   I Ay o   Note that since p yi  xi   is a linear function of the parameters  its log is concave  and the optimization problem is thus concave  although it is not a standard SDP  since the objective is nonlinear  We do not study this approach further in this manuscript  since we prefer to focus on problems for which standard solvers exist  A related approach is obtained if we consider the measure of success of the predictor to be the probability it assigns to the correct class  This view implies that we should perform the following maximization P max Pi p yi  xi   s t     y Ay   I Ay o   This optimization is very similar to the maximum likelihood one  but without the log function  The objective can also be viewed as the optimal Bayes loss in  prediction given that the true distribution is p y x   We therefore denote this optimization by Bayes  Note that for logistic models such as Conditional Random Field  CRF       this problem is not convex since CRF probabilities are not convex functions of the parameters  Interestingly  this problem may be solved analytically for the binary case as we now show  Denote the two matrices by A  and A    I  A    The constraints imply that the eigenvalues of A  are between zero and one  The objective function then becomes  X X tr A  xi xTi     tr  I  A   xi xTi     i yi     i yi     Omitting the constant term which does not affect the solution we get     X X xi xTi    tr A   xi xTi  i yi     i yi     Let vi and i be the eigenvectors and the eigenvalues of the constant matrix  X X xi xTi  xi xTi   i yi     i yi     Since the objective is linear in the matrix A  we get that A  has the same eigenvectors vi   Let di be the eigenvalues of A    We have that the objective function is given by    X X X  i di   xi xTi    tr A   xi xTi  i yi     i yi     i  Therefore  to maximize the objective function one should set di   sgn i    where we define sgn           To conclude  we showed that the solution of Eq      for two classes can be obtained by computing the difference between the  normalized  covariances matrices per class  and assigning each of the eigenvectors to one of the matrices Ay in accordance with the sign of the corresponding eigenvalue  A similar algorithm was proposed in the context of quantum detection theory where more information is assumed  See the book of Helstrom     for more details      Convex bounds on the zero one loss  A common approach to choosing an optimal classifier is to find the one which minimizes a convex upper bound on the zero one loss  In conditional log linear models      the function  log  p y x  is such a convex upper bound  convex in the model parameters   In      For      the factor in the parenthesis may be interpreted as a lower bound on the probability of correct classification  Thus the max margin method may be viewed as optimizing a  multiplicative  tradeoff between correct classification and margin maximization  Different values of  reflect the weight that should be attributed to classification rate compared to margin   ZeroOne ML Bayes Margin     Convex Bound                 Duality                                   p y   x                          Figure    Convex upper bounds on the zero one loss in the binary case  Curves are shown for the case where y     is the correct class  For the margin bound  a value of        is used  Support Vector Machines      the hinge loss serves as a bound   lzo  x  y  p     p y x              To illustrate the bounds in our models  we focus on the binary class case  Figure   shows the bounds discussed below and their relation to the zero one loss  The simplest linear upper bound on the zero one loss is  see Figure    lBayes  x  y  p         p y x         As its name suggests  it is minimized by the Bayes optimization problem in Eq       The ML problem in Eq      corresponds to minimizing the bound  see Figure    lML  x  y  p     log   p y x         The interpretation of the maximum margin formulation is slightly more complex  Consider the function      p y x           The function lMarg is also an upper bound on the zeroone loss  as can be seen in Figure   and is similar to the hinge loss  with the exception that the former is parameterized by   The objective in Eq      in the binary case can then be written as a sum of elements     lMarg  xi   yi   p      Standard duality transformation yields the dual semidefinite program min s t   The zero one loss is given by  lMarg  x  y  p      max         As in the case of SVM  convex duality may be used to gain important insights into the problem  We obtain the convex dual of Eq      by introducing two sets of dual parameters  The first  corresponding to the normalization constraint  is   a matrix of size d  d  The second  corresponding to the margin constraints  is qyi  y              k and i              n  where we force qyi i             tr   P q    Pi z zi q Pz zi   iT      P        n P T q x x  i yi   y yi i i i yi  y   z qzi  xi xi o         where the last constraint is true for all y  We can use the dual to further interpret the meaning of the  parameter  Assume that       n  where n is the number of examples and           We say that the ith example is not a support vector if the solution of Eq       satisfies qzi     for all z  Intuitively  an example which is not a support vector does not change the solution of the optimization problem and thus can be omitted  without affecting the solution  Note that this definition is somewhat weaker than the standard definition in support vector machines  since we do not have a representer theorem that links the primal and dual solutions  We also say that the ith example is a margin error if i      The following lemma links the value of  to both margin errors and the number of support vectors and is analogous the  property in       proposition      Lemma       Let    i   Ay   be the solution of the primal optimization problem and let  qyi     be the solution of the dual  Then      is an upper bound on the fraction of margin errors      is a lower bound on the fraction of support vectors    Proof  At most a fraction of  examples P Pcan satisfy q         n   This is because zi z Pi z qzi      But from KKT conditions we know that z qzi    if i      Hence the first part of the lemma  Any support vector Pcan contribute at most a mass of    m  to the sum i z qzi      Thus  there are at least n examples which are support vectors      Implementation Issues  The semidefinite programs discussed above can be solved using existing solvers such as CSDP      This package was used in the experiments discussed below  However  for large n or d this approach becomes impractical  An alternative approach  which yielded similar results  is to use a projected sub gradient algorithm      The projected sub gradient algorithm takes small steps along the sub gradient of the objective  followed by Euclidean projection on the set of constraints  To see how it may be applied  note that Eq      may be written as P max    i    p yi  xi     maxz  yi p z xi     P s t y Ay   I Ay o   Thus the objective is a non differentiable function  and the only constraints are positivity of Ay and the normalization constraints  It is straightforward to obtain the sub gradient of the objective  We now turn to the Euclidean projection part of the algorithm  Here the set of constraints is given by n o X Snorm   Ay   Ay   I y  Spos S     n  Ay   A y o    o    Snorm  Spos  of the sets Snorm   Spos is straightforward  one can use Dykstras alternating projection algorithm     to obtain the Euclidean projection on S      Relation to  nd order kernel methods  Our probabilistic model is closely related to SVM with second order kernels  To see this  note that xT Ay x   tr Ay xxT   which may be interpreted as a dot product between the elements of Ay and xxT   This is precisely the form of the predictor obtained for SVM with a second order kernel  There are however several key differences between our approach and the SVM one  The first is that the outputs in our case are automatically normalized probabilities  whereas the SVM need not even be positive  The second is that the bound on the zero one loss used in our learning algorithm is significantly different from that used in SVM  Clearly  the class of models we learn are a subclass of those available to second order SVMs  due to the constraints on the matrices Ay   To gain more insight into the constraints  consider the case where Ay is constrained to be diagonal  The resulting classification rule will be based on the dot product between diag Ay   and the element wise square of x  Since the diagonal elements will then be constrained to be in the range         this case corresponds to a linear SVM on the squared x with box constraints on the weight vectors  This creates an interesting link between our method and linear separators with positive weights such as the Winnow algorithm       The relation between the log likelihood formulation  Eq       and logistic regression is not direct as the relation between the margin formulation  Eq       and SVMs  This is because in our model  probabilities are linear in the parameters  while for logistic regression they are obtained through exponentiation of linear terms   Define the Euclidean projection of the parameters Ay on S by X  Apy     arg min kAy  Ay k        In the experimental evaluations below  we compared our method to second order SVMs  and found that the former achieved better performance  We elaborate on possible reasons for this result in what follows   In the binary class case  this projection can be found analytically  Define the matrix C    A   A    I     and denote by vi   i its eigenvectors and eigenvalues  Then it can be shown that the projection is given by X min    max    i   vi viT   Ap    I  A  Ap        Ay S  y  i  In the multiclass case  there does not seem to be an analytic solution  However  since projection on each  Quantum Mechanics  The formulation we proposed  and especially the Likelihood based approach  are related to analogous detection problems in the quantum mechanics literature  We begin with some definitions  A density operator  is a positive semi definite matrix  with a unit trace  tr         We can think of the density operator as defining a distribution over the eigenvec       In the machine learning formulation given in the current work  we do not assume to be given either the prior probabilities i nor the density operators i   but only a finite sample from both  Specifically  we assume to have only pairs of a vector x and a label y  Where the label y was drawn in accordance to the prior i and the vectors x in accordance to the class conditional probabilities i       Error SVM                               Error MaxMargin PM           Figure    Test error  in percentages  of the MaxMargin algorithm  x axis  vs  test error  in percentages  of SVM  y axis  for all the    label pairs of the USPS dataset  A point above the line y   x indicates better performance for the MaxMargin algorithm  tors of the operators  with a weight proportional to the corresponding eigenvalue  Specifically  denote by P    i i vi viT where kvi k        Then  Pr  vi     i   viT vi   tr vi viT     We can also use the density operator to define a probability measure over every normalized vector x using the same algebraic form and have  Pr  x    tr xxT     We now turn our attention to the problem of quantum hypothesis testing      Assume that there are given k density operators i for i           k  Our goal is to find a set of k operators i which we shall call detection operators  These operators Pare positive semi definite whose sum is the identity  i i   I   These detection operators are used to define the conditional detection probabilities  Pr  state j   state i    tr i j   that the detectors choose the jth state when the ith state is true  Let us denote by j the prior probability of being in jth state  Then  the average detection error is given by  k X k X j  j     i j  tr j i      i  where i j     if i   j and i j     if i    j  The goal of the system designer is to find a set of detection operators i that will minimize the average error  Eldar     proposed a few formulations of the problem as semi definite programs  Note that the above problem is similar to our Likelihood formulation in Eq        Related Work  A few attempts were made to combine large margin classifiers with probabilistic outputs  The most notable example is the work of Platt       This work suggests using a sigmoid on the outputs of the support vector machine  and provides ways to calibrate the parameters of this sigmoid  An alternative approach was discussed by CesaBianchi et al in         They suggested to force the output of a linear classifier to the        range  and thus have a probabilistic interpretation  by assuming that both the input vector x and the weight vector v lie in a ball of radius one  Thus the value of the inner product between the weight vector and the input vector is always in the range         which is mapped linearly into the range         Note that there is no simple and direct extension of this approach into multi class problems  Several directions which relate machine learning and quantum mechanics were proposed recently  Warmuth      presents a generalization of the Bayes rule to the case when the prior is a density matrix  Wolf      provides interesting relations between spectral clustering and other algorithms based on Euclidean distance  and the Born rule  Our likelihood based approach is related to some of the many detection algorithms presented by Eldar      Note that unlike Eldar  we do not assume direct knowledge of a probabilistic model  prior probabilities or density operators  but only a finite sample from it       Experimental Evaluation  To illustrate how our method extracts subspaces from data  we first apply it to a simple two dimensional XOR problem shown in Figure    The resulting PSD matrices Ay turn out to be projection matrices  i e  eigenvalues in         although their eigenvalues could be non integers in principle  Furthermore  we have p yi  xi       for all sample points  We next evaluated our algorithm using the USPS handwritten digits dataset  The training set contains        training examples and the test set has        ex            Bayes MaxMargin           Fraction of Test Examples                                                                    Figure    An example of subspace learning in two dimensions  The classes in this case are the two one dimensional subspaces  i e   lines  corresponding to the vectors v            v            The sample points    points per class  are drawn randomly from these lines  Applying our max margin algorithm with        to this sample results in matrices A    A  with spectra                respectively  The lines corresponding to the dominant directions in each Ay are shown in the figure   amples  Originally  each instance represents an image of a size        of a digit  There are ten possible digits  Since our current implementation  CSDP  is still limited in the data size it can handle  we reduced the dimensionality of the data by replacing each four adjacent pixels with their mean  resulting in image of size       Thus  the dimensionality was reduced from     to     We enumerated over all    pairs of digits and repeated the following process    times  For each pair we randomly chose     examples which were associated with one of the two digits of the current pair  The remaining training examples associated with this pair were used as a validation set  The test set was the standard USPS test set  restricted to the relevant two digits   We trained three algorithms  support vector machines  SVMs   our maximum margin formulation in Eq       denoted by MaxMargin  and our optimal Bayes formulation in Eq       denoted by Bayes   For SVMs we used   values for the regularization parameter  and for the MaxMargin method we tried   values for the regularization parameter  We trained each of the algorithms using all the values of the parameter and picked the one model which achieved minimal error over the validation set  We then used this model to compute the error over the test set  We averaged the results over the    repeats  Figure   summarizes the results for both SVMs and the MaxMargin approach  Each point corresponds to one of the    binary classification problems  A point above                    Threshold          Figure    Fraction of examples in test set which the difference in probability  p   x   p   x   is below a threshold set by a value in the x axis   the line y   x corresponds to a pair where MaxMargin performs better than SVMs  and vise versa  Clearly  MaxMargin outperforms SVMs  as most of the points are above the line y   x  We computed a similar plot for the Bayes algorithm which turned out to be worse than both MaxMargin and SVMs  To better understand the performance of Bayes and MaxMargin we focus our attention on one of the    binary problems  Specifically  we chose the hard task of discriminating between the digits three and five  This is the hardest task for SVMs  We picked one of the partitions of the data into training set and validationset and computed the absolute difference in probability for each of the test examples   p   x   p   x    We then enumerated over several possible threshold values of this difference  and recorded the fraction of test examples for which this difference is higher than the value of the threshold  The results are summarized in Figure   for the MaxMargin and Bayes algorithms  As one can observe from the figure  for the MaxMargin algorithm all of the examples have a difference in probability that is less than      While for the Bayes algorithm the difference of the probabilities is even as high as      This result can be explained by the following observation  The goal of the MaxMargin algorithm is to maximize the number of correct predictions  For this task  there is no need to have a high difference in probabilities  only high enough difference  of about       On the other hand  the Bayes algorithm optimizes the expected error when drawing a label using the probability model p y x   It thus tries to push the probabilities apart from each other  even at the cost of making some prediction error  Indeed  this is the case here  since Bayes generally yields worse generalization error than MaxMargin  However  its probabilities seem to better calibrated  suggesting   that Bayes should in some cases be the preferred algorithmic choice       D P  Bertsekas  Nonlinear Programming  Athena Scientific  Belmont  MA                 B  Borchers  CSDP  a C library for semidefinite programming  Optimization Methods and Software                       Discussion  We presented algorithms for learning subspaces using probabilistic models  This resulted in semidefinite optimization  and allowed both max margin and likelihood objectives  Note that although our presentation referred to the case of orthogonal subspaces  a much wider class of subspaces are separable under our classification rule  intuitively  subspaces such that the angle between them is above    degrees in the binary case   The empirical results presented above show that our method compares favorably with second order SVM  Since our model is effectively a subclass of the latter  it is not immediately clear why this should be the case  There are two differences between our method and SVMs which could shed light on these results  The first is that since we optimize over a constrained parameter set for the weights  generalization error variance is reduced  albeit at the cost of possibly increased bias  It will be very interesting to obtain theoretic results in this respect  While it does not seem like the VC dimension of our class is smaller than the corresponding SVM  there still may be theoretical guarantees which result from our constraints  positive semidefiniteness and normalization  on parameter space  Another possible explanation for the empirical results is the difference in the objective function  and related convex bounds on the zero one loss  While SVM uses a hinge loss to bound the zero one loss  our method effectively uses the bounds discussed in Section      One difference between these two bounds  is that the hinge loss heavily penalizes points with negative margin  whereas in our case this penalty is upper bounded       N  Cesa Bianchi  A  Conconi  and C  Gentile  Learning probabilistic linear threshold classifiers via selective sampling  In COLT               N  Cesa Bianchi  A  Conconi  and C  Gentile  Margin based algorithms for information filtering  In NIPS               R  L  Dykstra  An algorithm for restricted least squares regression  J  Amer  Stat  Assoc                         Y  C  Eldar  Quantum Signal Processing  PhD thesis  MIT            C W  Helstorm  Quantum Detection and Estimation Theorey  Academic Press  San Francisco  CA            A  McCallum J  Lafferty and F  Pereira  Conditional random fields  Probabilistic models for segmenting and labeling sequence data  In ICML     pages                    N  Littlestone  Mistake bounds and logarithmic linear threshold learning algorithms  PhD thesis  U  C  Santa Cruz  March            J C  Platt  Probabilities for SV machines  In A  Smola  P  Bartlett  B  Scholkopf  and D  Schuurmans  editors  Advances in Large Margin Classifiers  pages       MIT press             B  Scholkopf and A  J  Smola  Learning with Kernels  MIT Press  Cambridge  MA             B  Scholkopf  A J  Smola  R  Williamson  and P  Bartlett  New support vector algorithms  Neural Computation                      An interesting extension of our method is to model local interactions via semidefinite matrices  This would correspond to Taskars extension of SVM to the multi label case       and would hopefully share the probabilistic interpretation of Conditional Random Fields            J  Shi and J  Malik  Normalized cuts and image segmentation  IEEE Trans  on Pattern Analysis and Machine Intelligence                       Acknowledgments The authors thank the Rothschild       B  Taskar  C  Guestrin  and D  Koller  Max margin markov networks  In NIPS            Foundation   Yad Hanadiv for their generous support   
 We address the problem of learning the parameters in graphical models when inference is intractable  A common strategy in this case is to replace the partition function with its Bethe approximation  We show that there exists a regime of empirical marginals where such Bethe learning will fail  By failure we mean that the empirical marginals cannot be recovered from the approximated maximum likelihood parameters  i e   moment matching is not achieved   We provide several conditions on empirical marginals that yield outer and inner bounds on the set of Bethe learnable marginals  An interesting implication of our results is that there exists a large class of marginals that cannot be obtained as stable fixed points of belief propagation  Taken together our results provide a novel approach to analyzing learning with Bethe approximations and highlight when it can be expected to work or fail  Probabilistic graphical models         are a powerful tool for describing complex multivariate distributions  They have been used successfully in a wide range of fields  from computational biology to machine vision and natural language processing  To use such a model in practice  one typically needs to solve two related tasks  The first is the inference task which involves calculating probabilities of events under the model  The second task involves learning the parameters of the model from empirical data  Unfortunately  in many models of interest the inference problem is computationally hard  and cannot be solved exactly in practice  This has motivated extensive research into approximate inference schemes  some of which have been quite successful empirically  Perhaps the most well known of these is the belief propaga   tion  BP  algorithm  which is closely related to variational approximations based on Bethe free energies       Another variational approach  which uses convex free energies is the tree reweighted  TRW  method       Although the TRW approach results in convex optimization problems for inference  it sometimes yields marginals that are inferior to those obtained by BP  e g   see       How should one learn the parameters of a model when inference is intractable  The typical approach to parameter learning is likelihood maximization  but when inference is intractable it is also hard to maximize the likelihood   Because of this difficulty  many methods have been devised to approximate the learning problem  One elegant approach is to approximate the likelihood using the same variational approximation that is employed during inference                  Analyzing the performance of approximate learning schemes is challenging  since even the accuracy of the underlying variational approximations is hard to analyze  Furthermore  we do not generally expect the learned model to be similar to the one obtained using exact maximum likelihood  One approach  which has recently been introduced by Wainwright      is to use the notion of moment matching  In exact maximum likelihood learning  the learned model has a nice property  some if its marginals are guaranteed to be identical to those of the empirical data  This property is often referred to as moment matching  Wainwright          has shown that when using convex variational approximations such as TRW  the learned model also has the moment matching property in the following sense  if one applies approximate inference to it  using the same variational approach that was used during learning   the resulting marginals will be equal to    When the data are known to be generated by a graphical model of the same structure  pseudo likelihood     can be used and is consistent  However  this assumption is rarely met in practice  and pseudo likelihood often does not perform well in these cases    the empirical ones  However  these results cannot be applied to learning with Bethe approximations  since the latter are not convex  Because of the success of Bethe approximations in a wide array of applications  it is important to understand the advantages and limitations of learning with those  This is precisely the goal of our work  It may initially seem like learning with Bethe approximations would also result in a moment matching property  In other words  if we use Bethe approximations during both learning and inference  our learned model will agree with the empirical marginals  However  as we show here  the situation is considerably more complex  In the current work we provide some surprising results with respect to moment matching and Bethe approximations  that shed light on the performance of learning with such approximations  and on properties of the BP algorithm  Our main results are   We show that there exist empirical distributions for which Bethe approximations cannot perform moment matching  In other words  if we run BP on the optimal Bethe parameters  we will not recover the empirical marginals  Such empirical distributions are thus bad inputs for Bethe approximations  since the learned parameters cannot be used to reconstruct the original marginals   We provide inner and outer bounds on the set of marginals for which Bethe moment matching is possible  and show that they agree with empirical behavior of Bethe learning  Surprisingly  we show that binary attractive models cannot be learned with Bethe approximations for certain graphs   Our results also provide a novel characterization of BP fixed points  Specifically  we show that there is a large class of marginals that cannot be obtained as stable fixed points of BP  Taken together  our results provide a novel way of analyzing learning with Bethe approximations      Maximum Likelihood in Graphical Models  We focus on pairwise Markov random fields for simplicity  That is  we consider random variables X            XNV and pairwise functions ij  xi   xj   corresponding to edges E in a graph G with NV nodes  The MRF corresponding to these parameters is given by    NV X X   exp  ij  xi   xj     i  xi   p x      Z   i   ijE       where Z   is the partition function and x corresponds to a complete assignment to the NV variables  We wish to learn the parameters  from a sample of size M given by x              x M     A standard approach to parameter learning is to maximize the log likelihood given by            X log p x m            log Z   M m       where  are the empirical marginals given by  ij  xi   xj       i  xi         X xm  x xm  x M m i i j j   X xm  x M m i i  ij  E i              N  and  is the corresponding vector with the parameters ij  xi   xj    i  xi   in appropriate coordinates  The likelihood function     is concave in  and thus does not have local optima  Finding its global maximum is possible when the function  as well as its gradient  can be calculated efficiently  In these cases a variety of methods can be used  such as gradient ascent  iterative proportional fitting or any other general purpose first order convex optimization procedure  A key property of the optimal parameters  M L    is that they satisfy the so called moment matching condition  described next  Define the vector  to be the set of marginals of the model p x    given by  ij  xi   xj   i  xi      p xi   xj     ij  E   p xi      i              N  The moment matching condition for maximum likelihood optimality is then simply  M L          The condition states the following simple fact  the optimal parameters  M L are such that the optimal model p x   M L   has the given empirical marginals  This is a desirable property since the empirical marginals are often a good approximation of the true marginals        Bethe Approximations of the Likelihood  The problem of maximizing the likelihood in Eq    is hard due to the general intractability of the partition function and marginals inference problems  We shall    Dependence on the sample is implicit throughout  When not enough data is available for estimating marginals reliably from data  it is possible to use smoothing or regularization  We do not address this here  but our results can be generalized to these cases      focus on a common approach to this problem  which is to replace log Z   with an approximation F     We shall specifically be interested in the Bethe approximation      defined as follows  First define the negative Bethe free energy as   The subdifferential of F    is defined as follows  For a given  define M    to be the set of vectors  that maximize F       Namely   F             HB     The subdifferential of F    is then Conv  M      the convex hull of the vectors in M     The subdifferential of  B      is thus   Conv  M      Taken together we have that the optimality condition for  B    is        Where the function HB    is the Bethe entropy given by  X X HB       di     i  xi   log i  xi   xi  iV    X X  ij  xi   xj   log ij  xi   xj    ijE xi  xj  and di is the degree of node i in the graph G  The Bethe approximation for the log partition function log Z   is then given by  F      max F      ML  ML    Conv  M   B                 Whenever there is a single maximizer    in M    the condition becomes        resembling the moment matching condition in Eq     However  generally the above condition is more subtle and actually means that when there are multiple maximizers   is not necessarily equal to any of them  In Section   we consider the strong implications that this has on learning with Bethe approximations            Eq    uses the following definitions  ML is the local marginal polytope  which is the set of locally consistent pseudo marginals  defined as  P   ij  xi   xj     i  xi   ij  E       xj   P   x   x       x   ij  E ij i j j j ML         xi   P       i  xi       xi      We are thus interested in maximizing the Bethe likelihood   B            F          max F          ML  One interesting property of the function  B       which is typically overlooked  is that it is in fact a concave function of  and thus it does not have local maxima  This is a simple outcome of the fact that F    is a pointwise maximum over functions that are convex  in fact linear  in  and is thus convex      so that its negation is concave  In what follows  we characterize the global maximizer of the Bethe likelihood and discuss several ways of approximating it  We denote the maximizer by  B          M      arg max F       Optimality Conditions for Bethe Learning  The Bethe likelihood  B      is a concave but nonsmooth function  Thus  a necessary and sufficient condition for  B    to maximize it is that the subdifferential of  B      at  B    contains the all zero vector         In what follows we use this to characterize  B      Maximizing the Bethe Likelihood in Practice  Although  B      is concave  finding its maximum is still hard and there is no known closed form solution or polynomial time algorithm for it  The key difficulty is that both evaluating  B      and calculating a subgradient for it involve maximizing F      over    Since F      is not concave in the general case  this appears to be a hard problem   The common practice in this case is to find a stationary point of F      using BP      and using it as a subgradient in subgradient ascent  Although it is hard to obtain theoretical guarantees for such an approach  it sometimes provides good empirical results           Another common approach comes from studying the tree graph case  In that case  the maximum likelihood parameters for  are given in closed form by  c    defined as       ic  xi     c ij  xi   xj         log i  xi   ij  xi   xj     log i  xi  j  xj    When the graph is not a tree   c    is not necessarily the maximum likelihood parameter  as we also show in what follows  However  it is always true that  is a stationary point of F     c           Specifically  if one initializes BP on the MRF  c    with uniform messages   will be obtained as a fixed point  although this fixed point may be unstable as we show later      This maximization is subject to constraint   ML   In what follows we do not state this explicitly for brevity    We are not aware of complexity results that prove this fact       Bethe Learnable Parameters  Our main goal in the current work is to understand when Bethe learning achieves moment matching  By moment matching we mean that inference on the learned parameter will result in the empirical marginals  as in Eq      In the context of Bethe learning  it is natural to define inference as returning the maximizer of F        One difficulty with this is that F is hard to maximize due to its nonconvexity   However  there is a more fundamental difficulty  F     B     might have multiple distinct global maximizers  In this case  the outcome of the inference step is not well defined  and hence moment matching cannot be achieved  Furthermore  in this case the empirical marginals  will generally not correspond to any of the maximizers of F     B      but will rather lie in their convex hull  see Section       On the other hand  if F     B     has a single global maximum then by Eq    this maximizer is exactly  and we have moment matching  This brings us to our key question  for which values of  will Bethe achieve moment matching  Given the above discussion  these are  for which the optimal  B    has a single maximum  Definition     is Bethe learnable if there exists a  such that  is the unique maximizer of F       In this case  maximizes the Bethe likelihood  i e       B      and  can be recovered from  so that moment matching is achieved  Denote the set of such  by BL   The definition of BL is quite implicit and it is thus not immediately clear what can be said about this set  For example  are there parameters that are not Bethe learnable  Clearly there are parameters that are Bethe learnable since Bethe is exact for trees  see Section       In what follows we show that there are in fact  that are not in BL and characterize those in some cases      Characterizing Unlearnable Marginals  The naive approach to testing if   BL would be to scan all parameters values   and for each of those test if  is the unique maximizer of F       In what follows we provide several simpler approaches  some in closed form  Specifically  Sections     and     provide    Using the same inference approximation in learning and inference is also motivated by the results in          where a similar approach for convex free energies results in moment matching    In practice  maximization will be approximated by running BP on the MRF given by    outer bounds on BL and Section     provides an inner bound       A Condition Using Canonical Parameters  Our first observation in terms of characterizing BL is a lemma that provides a sufficient condition for     BL   In other words  we obtain an outer bound on BL   Lemma    Let   ML and let  c    be its canonical parameter  If  is not a global maximizer of F     c     then     BL   Proof  We are given the fact that      arg max F     c     ML        Asssume by contradiction that   BL so that there is a parameter  for which   arg maxML F       As mentioned in Section      is a fixed point of BP for the parameters  c     Since  maximizes the negative Bethe free energy for   it is also a BP fixed point for       Theorem     Since BP fixed points correspond to re parameterizations of the MRF       and since both  c    and  have the same BP fixed point   it follows that  c    and  are re parametrizations of the same MRF  It is then easy to show that two parameters that are re parametrizations of each other share the same BP fixed points with the same values up to a constant  This implies that  does in fact maximize F     c      contradicting our assumption in Eq      Lemma   provides an easy procedure for excluding points from BL   Given  generate the canonical parameter  c     Run BP with this parameter multiple times  e g   by initializing messages randomly   If a fixed point with value F     c        F     c     is found then     BL   Another interesting implication of Lemma    by negation  is that if  is learnable then its maximum likelihood parameter is necessarily the canonical one  c     Thus  the canonical parameters are in some sense the best choice for maximum likelihood with a Bethe approximation  Namely  they are the correct maximum likelihood parameters when  is learnable  When  is not learnable using Bethe approximation in learning is apparently not a good approach in any case       Closed Form Bounds via the Hessian  Here we provide another outer bound on BL  i e   a criterion for     BL    The key idea is to find marginals  which can never be a maximum  local or global  of F      regardless of the value of   Clearly  such  will not be in BL     For this purpose we will focus on binary pairwise models  Following          we will use a minimal parameterization  In this representation we denote i  xi      as i and ij  xi      xj      as ij   The other singleton and pairwise marginals can be obtained from these via  ij  xi      xj         i  ij  ij  xi      xj         j  ij  ij  xi      xj      i  xi          i  It can be verified that a point is in ML  G  if and only if all the above marginals are non negative  e g   see           The function F      in this case can be expressed as a function of ij   i alone  Furthermore  there is no need to add non negativity constraints since these would result in log of a negative number in the objective  For this unconstrained F       a sufficient condition for  not to be a maximum for any  is that the Hessian of F      at  is not negative semidefinite regardless of the value of   Luckily  the Hessian at F      does not depend on   since F is linear in   and equals the Hessian of the Bethe entropy HB   ij   i     Thus we have  Lemma    For binary variables  if the Hessian of HB   ij   i    at     is not negative semi definite then     BL   Lemma   provides a sufficient condition for     BL   It can be easily tested for any given  by calculating the Hessian at this point and checking its eigenvalues  To better understand the condition on the Hessian  we turn to a more specific scenario which results in a closed form expression on   We focus on marginals  that are homogenous in the sense that all pairwise ij   e for a constant e and all i   v for a constant v    We make no restrictions on the graph structure  The following lemma states a simple sufficient condition for guaranteeing that     BL   We denote by NV the number of variables and NE the number of edges  Lemma    Assume  corresponds to homogenous binary marginals in minimal representation  and  satisfies the following condition  e         NV NV   NE  v    NE v NV     N E   The condition is independent of the graph structure  It only depends on the number of variables and edges   For tree graphs and single loop graphs there are no  that satisfy the conditions  This is consistent with the fact that the Bethe free energy has a unique optimum in these cases and all marginals are Bethe learnable     ij  i  j        The proof of the lemma is given in Appendix A  This result has several interesting implications         Then the Hessian of HB    at  is not negative semidefinite  and hence     BL     Note that ML  G  in this case reduces to the constraints   v     e  v and e      V  As N NE     e g   for complete graphs with NV    the condition becomes e   v   Perhaps surprisingly  this is a condition that is satisfied by any ferromagnetic distribution           This implies that if  are generated from a ferromagnetic disV   BL   In other tribution with N NE     then   words  ferromagnets are not Bethe learnable in this asymptotic regime        Inner Bounds on BL  The results in the previous sections provide outer bounds on BL   In the current section we show how previous results on BP convergence can be utilized to obtain inner bounds on BL   The key idea is to check  given some   whether the canonical parameters  c    yield moment matching  We know that  is a BP fixed point for  c     Thus a sufficient condition for moment matching to take place is that  is the unique stable fixed point of BP    This would imply that at  c    we have moment matching for  and thus   BL   Fortunately there are various results that provide sufficient conditions on a parameter  having a unique stable fixed point  This has been addressed by multiple works in the past  e g                Each of these works provides a different condition on   We are not concerned with which one is better since all can equally well be applied to our case and we can simply take the union of the conditions to obtain a tighter bound  Thus  our condition for   BL is calculated as follows  for a given   calculate  c     Now check whether  c    has a unique BP fixed point  by using one of the conditions in the papers above   If it does  then   BL   In the experiments section we will specifically look at the condition from          The non homogenous form is ij  i j   Stability is needed to guarantee that this point is in fact a global maximum as our analysis requires         Note also     which analyzes unique fixed points  but not necessarily stable          Related Work         Several works have analyzed the behavior of Bethe approximations in graphical models  and their relation to BP  The first key work is       which showed that the fixed points of BP are local optima of the Bethe free energy  Later this result was refined in     to show that the stable fixed points of BP are local minima of the Bethe free energy  Another line of work focuses on conditions under which the BP has a unique fixed point  implying no local minima via       Such works  e g                    typically provide sufficient conditions on the model structure and parameters for BP to have a unique fixed point  As we show in Section      such results can be used to obtain inner bounds on BL   although they were not originally developed for this purpose  There has been less work on understanding learning with Bethe approximations  The canonical parameters  see Section      have been suggested in several works               As we show here  these parameters are generally not the ones optimizing the Bethe likelihood  but when  is learnable  they are in fact optimal  Much stronger theory is available for learning with convex free energies such as tree reweighted variants  In      it is shown that such methods have desirable stability and asymptotic properties  The performance of Bethe learning is not analyzed in this context  since it does not fall under the convex approximations  Our work proposes a novel view of learning with Bethe  which is to focus on the marginals that Bethe can and cannot match during learning  This highlights the regimes where Bethe cannot be expected to work well  and those where it might work  as we show further in our empirical results  Our results provide initial characterization of the set BL in terms of inner and outer bounds  We expect that these can be tightened further      Illustrating the Bounds  In this section we provide several graphical illustrations of the bounds on BL that we presented earlier  We focus on the case of a two dimensional      toroidal grid graph  and on homogenous parameters as described in Section      In this case   can be conveniently represented in two dimensions  i e   v   e    We begin by showing a case where the empirical marginals  are unlearnable  In this case  the maximum Bethe likelihood parameter B    results in a function F    B     which is not maximized by   i e   moment matching is not achieved   Rather  the function F has two other maxima  and  lies in their           v              Empirical marginals           Bethe maximizers                              e                         Figure    Illustration of a case where   denoted by empirical marginals in the figure  does not maximize F     B      However   is obtained as a convex combination of the two global maxima of F     B      The colormap corresponds to the values of F     B      In this case  B    was found by exhaustive search  convex hull  as described in Section      This is shown in Figure    Figure   depicts several results regarding the set BL   The colored regions correspond to marginals which can be obtained via some empirical distribution  i e   the marginal polytope        The blue region indicates marginals that are learnable according to the inner bound in Section      The red region indicates marginals that are unlearnable according to the outer bounds in Sections     and      In this case  lemmas      and   yield identical outer bounds  The region in black is not covered by any of our bounds  However  there is an easy way to check empirically whether it might be learnable  run gradient descent on the Bethe likelihood  using BP to approximate the objective and gradient      and check whether the parameters at convergence satisfy moment matching  It turns out that for the region in black  moment matching is achieved  Note that due to the potential suboptimality of BP  this is not a theoretical guarantee that this region is indeed learnable  i e   it could be that we have reached a suboptimal parameter  or that the reported marginals are not the optimal ones for Bethe   Taken together  the results in Figure   suggest that our outer bounds are tight for the given graph      Discussion  This work presents an analysis of when learning with Bethe is guaranteed to fail  in the sense of not match   This is an approximation since BP does not necessarily find the global optimum of the Bethe free energy    by checking one of our outer bounds   Additionally  we show that in the binary homogenous models  there are graphs where ferromagnetic models are unlearnable              Our analysis of the Hessian in Section     shows that there are marginals  that cannot be local minima of the Bethe free energy  This in turn implies that they will not be stable fixed points of BP  This highlights a very interesting limitation of using BP to approximate marginals  Namely  that there regions of marginals space which will never be obtained as a result of running BP  It will be interesting to study the practical implications of this observations        v                      Unlearnable Learnable  Inner Bound  Learnable  Grad  Opt                                e                         Figure    Illustration of bounds on BL space  Each point in the figure corresponds to an empirical marginal   The blue region shows marginals that are learnable according to Section      The red region shows marginals that are unlearnable according to Sections     and      The black region is not covered by any of our bounds  However  when running gradient ascent on the Bethe likelihood with these marginals  it turns out that moment matching is achieved at convergence  we decide that moment matching is achieved when the absolute difference between empirical and Bethe marginals is less than         ing the moments of the training data  One of the key difficulties of the Bethe approximation of marginals is the non convexity of the Bethe free energy  resulting in local optima during inference  Our results show that when using Bethe within learning  another problem surfaces  even in the case where exact optimization of the Bethe free energy is possible  and hence learning is tractable since the Bethe likelihood is concave   Namely  that for particular empirical marginals  those outside BL   moment matching will not be achieved  Characterizing the set BL is a challenge  and we have presented initial steps in this direction by showing how to obtain inner and outer bounds on it  some in closed form  Our analysis also highlights the fact that the canonical parameters often used in learning are inadequate in some cases  On the other hand  they can be used to obtain outer bounds on BL as in Lemma    Many interesting questions arise from our analysis and deserve further study  e g   when are the inner and outer bounds we presented tight  and whether tighter bounds exist  When are the canonical parameters optimal and in BL   On a practical level our results imply that there are regimes when Bethe learning is bound to fail  and that in some cases they can be inferred from the empirical marginals without running a learning algorithm  e g    Finally  our results do not imply that one should not use Bethe approximations within learning  It has been previously shown that Bethe approximations of marginals outperform convex variants across a wide range of parameter settings      It is thus certainly possible that for data such that   BL the learned parameters will perform well  We intend to address this issue as well as other theoretical questions in future work   A  Proof of Lemma    We first note that the Hessian of HB    has a particularly simple form in the homogeneous case  Denote this Hessian matrix by A  Then its elements correspond to only NV    unique numbers ai  i              V    b  c   d  which are given by           di c v    v   b        v   e       c    v  e        v   e       d     c e v  e  ai      di       The Hessian depends on these values via   ak k  V  l  V l k     b k  V  l  V l  N  k     c k  V  l  E kl A k l    c k  E  l  V lk     d k  l  E k  l      otherwise        where N  k  is the set of neighbors of node k  The indexing scheme is as follows  by k  V we mean k is the coordinate corresponding to k and k  E means k is the coordinate corresponding to some edge in E  The Hessian A is negative semi definite iff for all z it holds that z T Az     We will show that if the   condition in Eq     is satisfied then we can find a z such that z T Az     and therefore A is not negative definite  and the lemma follows  We will define such a z in the following way  zi     if i  V and zi   z  for   we some scalar z  if i  E  Denoting a    v     v obtain after some algebra that          J  Mooij and H  Kappen  On the properties of the Bethe approximation and loopy belief propagation on binary networks  Journal of Statistical Mechanics  Theory and Experiment  page P              z T Az     E  V  a   NE c    NE b   NE z   d    NE zc       R  T  Rockafellar  Convex Analysis  Princeton Mathematical Series   Princeton University Press         The above is a quadratic concave function in z  When its discriminant is greater than zero  it will attain positive values  and A will not be negative definite  The condition on the discriminant corresponds to    NV     c   d  a  c   b    da    NE        Assigning the values of the Hessian and some more algebra leads to the equation       e   v       NV NV   v     v    NE  NE        Switching sides we get the condition in Eq       
 Online sequence prediction is the problem of predicting the next element of a sequence given previous elements  This problem has been extensively studied in the context of individual sequence prediction  where no prior assumptions are made on the origin of the sequence  Individual sequence prediction algorithms work quite well for long sequences  where the algorithm has enough time to learn the temporal structure of the sequence  However  they might give poor predictions for short sequences  A possible remedy is to rely on the general model of prediction with expert advice  where the learner has access to a set of r experts  each of which makes its own predictions on the sequence  It is well known that it is possible to predict almost as well as the best expert if the sequence length is order of log r   But  without firm prior knowledge on the problem  it is not clear how to choose a small set of good experts  In this paper we describe and analyze a new algorithm that learns a good set of experts using a training set of previously observed sequences  We demonstrate the merits of our approach by applying it on the task of click prediction on the web      Introduction Sequence prediction is a key task in machine learning and statistics  It involves predicting the next element in a sequence given the previous elements  Typical applications include stock market prediction  click prediction in web browsing and consumption predicAppearing in Proceedings of the    th International Conference on Machine Learning  Edinburgh  Scotland  UK        Copyright      by the author s  owner s    tion in smart grids  Although the sequence prediction problem has been well studied  current solutions either work for long sequences or require strong prior knowledge  In this work we provide a method that uses training data to learn how to predict a novel sequence  As we shall show  we use the training sequences to obtain the prior knowledge needed for predicting novel sequences  Sequence prediction is most naturally cast as an online prediction problem  Cesa Bianchi and Lugosi         where at every step we predict the next element  and then receive the true value of the element while suffering a loss if we made a prediction error  We are then allowed to improve the model  and predict the next step  The online formulation is natural in most applications since the new elements true value unfolds in real time and we are interested in minimizing the prediction loss of this process  One classical approach to the problem is the so called universal sequence prediction class of methods  Feder et al         Hutter         Such methods guarantee that asymptotically  with sequence size  the model will achieve optimal prediction error  However  the price we pay for universality is that good performance will be reached only after seeing long sequences  Intuitively  the reason for this is that no prior knowledge about the sequence is used  so it may take a while until we have a good model of it  An alternative approach which does introduce prior knowledge is predicting with expert advice  Littlestone and Warmuth        Vovk         Here one has a set of r experts  where each expert is a sequence predictor  The Weighted Majority algorithm  Littlestone and Warmuth        uses such experts to do online prediction  and is guaranteed to perform almost as well as the best expert  More formally  for any sequence of length T   the average number of prediction mistakes of Weighted Majority  WM   is bounded above by the average number of prediction mistakes made by the best   Learning the Experts for Online Sequence Prediction   expert plus log r  T   Thus  the WM algorithm will perform well when for every sequence there exists an expert that performs well on it and when the sequence is long enough  Given the above  its clear that learning from experts will work when the experts fit the sequences we want to predict  Thus a key question  which we address here  is how to choose a good set of experts  We propose to learn these experts from a set of training sequences  In the spirit of empirical risk minimization we shall seek a set of experts that perform well on our training set  This is a highly non trivial task in our case due to several reasons  First  the performance of a pool of experts is measured by the performance of an online algorithm whose parameters are the experts  and its not clear how to optimize this function  We shall see that the hindsight loss is a simpler function to optimize and results in comparable theoretical guarantees  Second  we would like our experts to use arbitrarily long histories in making predictions  but do so without over fitting  We shall show that this can be done by using a variant of context trees  a k a  prediction suffix trees   Finally  its not clear what generalization guarantees  if any  can be expected from such a scheme  We perform a detailed generalization analysis  providing theoretical bounds on the sample complexity of learning a good set of experts  Our learning task is thus as follows  given a training set of sequences  learn a set of experts that will work well for online sequence prediction  In a sense  this can be viewed as a collaborative version of sequence prediction  We provide an objective that corresponds to this discriminative setting and analyze the generalization error of its minimizer  Our theoretical analysis provides generalization bounds that show no over fitting for longer histories  and quantify the advantage of learning in the collaborative setting  We apply our model to synthetic and real world problems and show that it outperforms methods which do not use temporal and collaborative approaches      Problem Formulation Let  be a finite alphabet  A sequence of symbols is a member of  and is denoted by x    x            xT    Online sequence prediction takes place in consecutive rounds  On round t  the forecaster observes the prefix x  t     x            xt    and predicts xt    Then  the next symbol  xt   is revealed and the forecaster pays   xt  xt     That is  it pays   if xt   xt and   otherwise  An expert for sequence prediction is a function f       Such an expert can be used for predicting  the tth symbol by setting xt   f  x  t     Given a set of r such experts  the Weighted Majority  WM  algorithm  Littlestone and Warmuth         see pseudocode below   can be used for predicting almost as well as the best expert  A performance guarantee for WM is provided in the following theorem  Littlestone and Warmuth          Weighted Majority  WM  parameter       initialize  w       r            r  for t                 T choose i  wt at random predict xt   fi  x  t    update rule i  wt    i   wt  i e  fi  x  t    xt   Theorem   The Weighted Majority algorithm  with     log r  T   obtains the following regret bound   T T       log r  P xt   xt    min   fi  x  t    xt       i T T t   T t   It follows that we can predict the sequence reasonably well if two conditions hold     log r  is sufficiently small compared to T      At least one of the experts makes a small number of mistakes on the sequence  Therefore  when choosing a set of experts we face the classical bias complexity tradeoff  On one hand we want r to be small enough so that the regret term  log r  T will be small  On the other hand  different experts will work well on different sequences  and since we do not know the type of sequence we are going to get  we would like to increase r so that the set of experts will be rich enough to explain many types of sequences  In this paper we propose to learn a good set of experts based on a sample of sequences  Formally  let H be a hypothesis class of experts  It is convenient to allow experts to output predictions from a set Y   where we have some way to convert an element from Y into a prediction in   For example  we can use Y   R     where we interpret the prediction y  Y as a score for each of the symbols in   The mapping from a score vector in Y to an actual prediction in  is via arg max y   Therefore  each f  H is a function from  to Y   The loss of a prediction f  x  t    is measured by a loss function l   Y    R  The loss   Learning the Experts for Online Sequence Prediction  function can be the     loss   xt  xt     Later  we use other loss measures that are convex surrogates of the zero one loss  The problem that we consider in this paper can be formalized as follows  We are given a sample of sequences  S    x              x m     where each x i  is assumed to be sampled i i d  from an unknown distribution D over    Our goal is to use S for learning a set of experts  F  H  of size  F    r  where r is a parameter of the learning problem  which should depend on the typical size of T    We wish to learn F such that when running WM on a new sequence with the set F it will have a small number of mistakes  Given an expert f and a sequence x  we denote by L f  x  the average loss of f on x  specifically   principle  namely  to solve the optimization problem    WM F  x i      m i   m  min  F H  F   r  This problem might be difficult to optimize since the objective function involves the activation of an algorithm and does not have a simple mathematical formulation  To overcome this difficulty  we show how a simpler objective may be used  In light of Theorem    generalized to convex surrogate losses  we know that for any sequence x     log  F    WM F  x   min L f  x          f F T Let us slightly overload notation and denote  L f  x       T  T   L F  x    min L f  x     l f  x  t     xt      f F  t    Given a set of experts  F  H  we denote by WM F  x  the averaged loss of applying the WM algorithm on the sequence x with the set of experts F   Therefore  our ultimate goal is to learn a set of experts F which  approximately  minimizes E  WM F  x      xD  Before we describe how we learn F   let us first consider two extreme situations  First  for r      i e  F    f    then WM F  x    L f  x   That is  at prediction time  we simply follow the predictions of the single expert f   This is exactly the standard traditional setting of statistical batch learning  where we would like to learn a model f from a hypothesis class H whose expected loss over a randomly chosen example  in our case x  D  is as small as possible  The problem with this approach is that it might be the case that the sequences are of different types  where no single expert from H is able to accurately predict all of the sequences  On the other extreme  if we set r     i e  F   H  then we revert to the problem of online learning with a hypothesis class H  The problem with this approach is that if H is complex   then the sequence length required in order to guarantee good performance of the online learning might be very large   Thus L F  x  is the hindsight loss when learning the sequence x with experts F   Taking expectation of both sides of Eq    we obtain that    log  F    E  WM F  x    E  L F  x     E   xD xD xD T     The second summand only depends on F via its size  Therefore  for a fixed size of F   we can follow a standard bound minimization approach and aim at minimizing ExD  L F  x   instead of ExD  WM F  x    In other words  we minimize the hindsight loss instead of the online loss  An ERM approach to this minimization yields the following minimization problem on the training set of sequences     L F  x i      m i   m  min  F H  F   r       By definition of L F  x   this can be written equivalently as min  f       fr H  m r     minr wj L fj   x i    m i   w j         where r    w  Rr   w     w         A straightforward approach for learning F when r     is to follow the empirical risk minimization  ERM   Assuming that H can be encoded as a convex set and L f  x  is a convex function   we obtain that the objective of Eq    is convex in f            fr and w              w r  individually but not jointly  This suggests an alternating optimization scheme where one alternates between    As measured  for example  by its Littlestone dimension  Ben David et al             This will be the case for the class H and loss function we use in Section         The Learning Algorithm   Learning the Experts for Online Sequence Prediction  optimizing over ws and over f s  This scheme is especially attractive since minimizing over w for fixed F is straightforward  for each sequence x i  find the best expert and set w i  to   for that expert and   otherwise  Optimizing fi for fixed w can be done via gradient descent when using a smooth loss as we do here  see Sections     and        As mentioned before  any function f      can be described by a context tree  as long as we allow its depth to be large enough   Therefore  without additional constraints  learning the class of all context trees from a finite sample will lead to over fitting  To overcome this  one can constrain the depth of the tree  Alternatively  we can allow any depth but carefully discount long histories as described next        The class of bounded norm context trees  Following  Dekel et al          we aim to balance between long histories  can be very informative but are rare in the data hence are hard to learn  and short histories  less informative but easier to learn   This can be done by defining a norm over matrices corresponding to context trees  where longer histories are penalized more  Formally  for each column i of a context tree matrix U  let d i  be the depth of its corresponding node inthe tree  Let a   a         be a sequence  such that i   ai      Then  we define a norm of vectors to be such that  u        ad i  u i    Thus far we have given a general scheme and have not described the particular set of experts we will use  In what follows we specify those  Any function f      can be described using a multiclass context tree  For our experts  we will be using a generalization of multiclass context trees following Dekel et al          described below  To simplify notation  denote     k                k   A multiclass context tree is a k ary rooted tree  where each node of the tree is associated with a vector z  Rk   The prediction of the tree on a sequence x  t  is determined as follows  We initially start with the vector z      Rk   and set the current node to be the root of the tree  We then add to z the vector associated with the current node and traverse to its xt  child  which becomes the current node  We add again the vector associated with the current node and traverse to its xt  child  This process is repeated until we arrive either to x  or to a leaf of the tree  The final value of z gives a score value to each of the elements in   and the actual prediction is arg maxi zi   It is convenient to represent a context tree as a matrix with k rows as follows  Let us order the nodes of a full k ary tree in a breadth first manner  For simplicity  we restrict ourselves to trees of bounded depth  which can be very large  so this is not a serious limitation   To represent a context tree as a matrix  we set column i of the matrix to be the vector associated with the ith node of the tree  where if the node does not exist in the tree we simply set the column to be the all zeros vector   Similarly  we can map a sequence x  t  to a  vector  x  t               as follows  Suppose that we traverse from the root of a full k ary tree according to the symbols xt    xt            x    as we described before  Then  we set all the coordinates of  x  t    corresponding to nodes we visited in this path to be    and set all the rest of the coordinates to be zero  It is easy to verify that the vector z constructed by a context tree for the history x  t  is U  x  t     where U is the matrix describing the context tree  the size of U is thus         and the columns correspond to the vectors z at each node    i   and a norm over matrices to be U    j Uj     where Uj is the jth row of U  Put another way  the squared norm of U is a weighted sum of the squared Euclidean norms of columns of U  where the weight of column i is ad i    Thus  we assign a higher penalty to columns corresponding to deep nodes of the trees  Consequently  we define the hypothesis class of bounded norm context trees to be HB    U   U  B          Finally  we also need to define scale sensitive loss functions  A common choice is the multiclass log loss          l z  y    log exp   y  y   zy   zy   y    This loss function has the advantages of being a convex surrogate loss for the zero one loss       The LEX algorithm We are now ready to describe our algorithm  which we call LEX  for Learning Experts   Our goal is to minimize the loss in Eq    with respect to the vectors wi and the parameters of the experts  As described in Section      we parameterize each expert by a context tree matrix U  Rk       As mentioned earlier  we can minimize Eq    via alternating optimization where minimizing over w can be done in closed form    Here we take ai   i      Learning the Experts for Online Sequence Prediction  and minimizing over U can be done with gradient descent  Calculating the gradient w r t  U is easy for the log loss  In our implementation we use stochastic gradient descent  where an update is performed after each training sequence is processed      Analysis Define the generalization loss for the set of experts F   LD  F     E L F  x    xD  In light of Eq     in order to bound Ex  WM F  x   it suffices to bound LD  F    In this section we derive bounds on LD  F    Our bounds depend on the following measures  the number of experts  F    a complexity measure of the hypothesis class H  the number of training examples  and the training loss  LS  F         L F  x     S  xS  We first define a complexity measure for a hypothesis class H with respect to a loss function l  Definition   Let H be a class of functions from Z to Q  let Y be a target set  and let l   QY  R be a loss function  We say that the complexity of H is C H  if for any sequence  z    y              zq   yq     Z  Q q and for any       there exists H  H of size  H        q C H     such that for all h  H exists h  H that satisfies  have LD  F    LS  F      is order of r C H      In particular  the sample complexity of learning a set of r experts is r times larger than the sample complexity of learning a single expert  The proof of the theorem is given in the long version of this article  The main ideas of the proof are as follows  First  we construct a cover for the loss class  x   L F  x    F  H   F     r   Then  we bound the Rademacher complexity of this class using a generalization of Dudleys chaining technique  which is similar to a technique recently proposed in Srebro et al          Next  we turn our attention to the specific class of context trees with bounded norm  The following lemma bounds its complexity  Lemma   Let HB be the class of multiclass context trees which maps  into R   as defined in Section      Let l   R      R be a loss function such that l    u  v  R      l u  l   l v  l    u  v   Then  C HB    O B   log k    The proof of the lemma is given in the long version of this article  The main idea is a nice trick showing how to bound the cover of a linear class based on known bounds on the convergence rate of sub gradient mirror descent algorithms  e g   see Nemirovski and Yudin         This is similar to a method due to Zhang         although our bound is slightly better   i   q    l h zi    yi    l h  zi    yi         The multiclass log loss function satisfies the conditions of the above lemma  hence   The reader familiar with covering number bounds can easily recognize C H  as determining the size of a cover of H  It is also easy to verify that if H is a class of binary classifiers then C H  is upper bounded by the VC dimension of H  this follows directly from Sauers lemma   We will later show that the class of bounded norm context trees has a bounded C H  as well   Corollary   Let HB be the class of multiclass context trees and let l be the multiclass log loss  Let D be a probability over  such that there exists some constant T with P len x   T        Then  with probability of at least   over S  Dm   for all F  HB   with  F     r  we have     r B  LD  F    LS  F     O   m  Theorem   Let D be a probability over  such that there exists some constant T with P len x   T        Assume also  that for all x and F  H we have L F  x       C H    Then  with probability of at least     over S  Dm   for all F  H  with  F     r  we have     r C H    LD  F    LS  F     O m The above theorem tells us that if H is of bounded complexity  then the number of samples required to  In summary  if we manage to find a set F  HB of size r that achieves a small hindsight training loss  then it will also achieve a small hindsight generalization loss  Combining this with Eq    yields      r B    log r  E WM F  x    LS  F     O  E   m T Therefore  the performance of the Weighted Majority algorithm is upper bounded by three terms  The training loss of F  which can decrease when increasing r     Learning the Experts for Online Sequence Prediction  the estimation error term  which increases with r   and the online regret term  which also increases with r       Related Work The problem of sequence prediction has a fairly long history and has received much attention from game theorists  Robbins        Blackwell        Hannan         information theorists  Cover and Hart        Cover and Shenhar        Feder et al         Willems et al          and machine learning researchers  Helmbold and Schapire        Pereira and Singer        Cesa Bianchi and Lugosi        Dekel et al          One of the most useful tools is context trees  which store informative histories and the probability of the next symbol given these  However  all of these works consider predicting a sequence from a single source  Indeed  our work extends these single sequence predictions to the collaborative setting where we model different sequences  but constrain the predictors to share some common structure  i e   the experts used in prediction   Another related line of work is multitask prediction  e g   see Ando and Zhang        Abernethy et al          in which one considers several different multiclass prediction problems and seeks a common feature space for those  This setting is different from ours in several ways  First  in the multitask setting one receives a set of training instances from each task  where it is known which sample belongs to each class  In our case  we receive only a set of individual sequences  Furthermore  in the multitask setting  the test data comes from one of the known tasks  whereas we again receive a novel sequence from an unknown source  A more recent approach to sequence modeling is the sequence memoizer  which is based on nonparametric Bayesian models  Wood et al          So far these have been applied to a single type model  e g   language modeling   and not for multiple distinct models as we have here  It is conceivable that a fully Bayesian model for collaborative sequence prediction can be built using these models  and it would be interesting to contrast it with our approach  Another possible approach to the problem is to use probabilistic latent variable models  Hofmann        or their discriminative counterparts  Felzenszwalb et al         Yu and Joachims         Here each sequence will be mapped to a latent variable corresponding to the best expert  Next  given the class and the previous history  a probabilistic suffix tree will be used to generate the next action  However  such a model will not handle long histories appropriately and  is likely to result in overfitting  as our empirical results also show   While it may be possible to add history discounting to such a model  it will be considerably more complex than what we suggest here  In our formulation  the state space  is unstructured  There are cases of interest  where  has structure  For example  it may correspond to the items in an online shopping basket  Prediction in such a setting was recently addressed in Rendle et al          Unlike in our case  they have access to multiple training sequences from particular users  and prediction is done on these users  Furthermore  the temporal model itself is only first order and thus very different from ours  Note that we can easily extend our approach to structured state spaces by using structured prediction instead of multiclass as we do here      Experiments In what follows  we evaluate the performance of the LEX algorithm  see Section      on two datasets  synthetic and real world  We compare it to the baselines described below       Baselines Models We consider three different baselines models  The first is our LEX algorithm with r      we denote this baseline by   LEX   which is in fact a batch trained PST  where training uses the log loss   In this approach all training sequences are modeled via a single PST corresponding to one expert  It thus does not directly model multiple temporal behaviors of the sequences in the data  Our second baseline is an online PST model which is evaluated on each test sequence individually  Training is done using the algorithm in  Dekel et al          Being an online algorithm  it does not use the training data  However  given long enough sequences it will be able to model any deterministic temporal behavior optimally  In other words  this algorithm has the benefit of adaptation but its performance crucially depends on the length of the sequence  We denote this baseline by Online PST  Finally  we consider a generative latent variable model  denoted by LMM  which is a mixture of Markov chains  An order d Markov chain is a basic yet powerful tool for modeling sequences  In LMM we generalize Markov chains by allowing each sequence to be generated by one of r regular Markov models  We think of these r models as different chain types similarly to the r experts of LEX  Specifically  for a sequence x          xt  the r LMM model of order d is defined by    Learning the Experts for Online Sequence Prediction       Synthetic Data We begin by considering sequences that follow one of two temporal patterns  The sequences are generated as follows  First randomly select j         then draw T samples according to the  independent  distribution       if x   j Pr xt   x      We used              otherwise          and generated a set of m        sequences  each of length T        these parameters where selected to resemble the browsing data characteristics   We note that by construction  the maximal possible generalization accuracy on this data is      We evaluate the accuracy of online prediction on     test sequences            Accuracy                 LEX LEX LMM Online PST                           Sample Size            Figure    Test accuracy of online prediction on the synthetic data  See Section      The four algorithms are described in Section       In Fig    we show the accuracy  on test data  of LEX and the three baselines  We notice that LEX approaches     accuracy using about    sequences    LEX and LMM require substantially more samples in order to approach this performance  over     sequences for      accuracy   In other words  in agreement with our theoretical analysis  the sample complexity of LEX is smaller than both   LEX and LMM  The accuracy of online PST is much lower            Accuracy  def r Pr xt  x  t      q   P xt  xtd t    z   q  P z   q  Where z is the latent  unobserved  variable which assigns a chain type to a sequence  Note that the standard Markov chain is simply a   LMM  We learn the parameters of a LMM from training data using EM  The  online  prediction using this model is done by the maximum a posteriori assignment at each point in time  Since LMM does not discount long histories  it is not expected to perform well when d is large and not enough training data is available  Parameters for all algorithms  i e   r and d  were tuned using cross validation                   LEX LEX LMM Online PST                       Sample Size            Figure    Test accuracy of online prediction on the click prediction task  See Section      The four algorithms are described in Section       due to the conservative training of this algorithm       Click Prediction Data Here we consider a challenging task of predicting the browsing pattern of web users  Specifically  we use browsing logs for users in an intra net site  For each session the sequence of url s visited by every user was recorded by the web server  The dataset contains      such sequences of length         The domain of the prediction problem  is of distinct url s and its magnitude is           The data was split into train  validation and test sets  the sizes of the training sets vary  while the validation and test set sizes were fixed at     and     sequences respectively  We applied the three baseline models  and compared their performance to LEX  In this experiment the r experts learned by LEX were combined with an additional expert obtained from training a   LEX algorithm  resulting in a pool of r   learned experts  This addition smoothes performance on short sequences where the WM algorithm might not have enough time to decide which of the r experts to follow  Results are shown in Fig     It can be seen that LEX outperforms the other methods  When considering the difference in accuracy between LEX and   LEX we notice that the added accuracy from multiple experts shrinks as training size increases  This trend agrees with theory  since as more data is available to   LEX  it can use longer histories and eventually will be able to model any temporal behavior  However  as we show in the synthetic experiments  the gap for small data sizes can be considerable    Learning the Experts for Online Sequence Prediction     Discussion We have described and analyzed a method for learning the experts for online sequence prediction  In particular  we specified it to the class of prediction suffix trees  Thus  our experts can capture dependencies on arbitrarily long histories  This is achieved by mapping context trees into a vector space and designing a norm on this space which discounts long histories  As our generalization results show  the complexity of the model is not penalized by the maximal possible length of histories  dimensionality of the matrix U  but rather by the effective needed context based history  captured by the norm of U   Our empirical results show that temporal user specific structure can indeed be used to improve prediction accuracy  The proposed approach can be extended in several ways  First  we can consider different prediction goals  instead of predicting the next symbol in the sequence  corresponding to the next URL  we can have a binary classifier that returns one if a user is likely to take a given action and zero otherwise  Alternatively  we can consider a ranking task where we want to sort actions according to their interest to the user  To use such objectives we will just need to replace our multiclass log loss with the corresponding loss  Finally  we note that our model can be applied to a wide array of practical problems  Some examples are ad placements  course enrollment systems  and enhanced user interface automation  Acknowledgements  This research is supported by the HP Labs Innovation Research Program   
 The introduction of loopy belief propagation  LBP  revitalized the application of graphical models in many domains  Many recent works present improvements on the basic LBP algorithm in an attempt to overcome convergence and local optima problems  Notable among these are convexified free energy approximations that lead to inference procedures with provable convergence and quality properties  However  empirically LBP still outperforms most of its convex variants in a variety of settings  as we also demonstrate here  Motivated by this fact we seek convexified free energies that directly approximate the Bethe free energy  We show that the proposed approximations compare favorably with state of the art convex free energy approximations      Introduction  Computing likelihoods and marginal probabilities is a critical subtask in applications of graphical models  As computing the exact answers is often infeasible  there is a growing need for approximate inference methods  An important class of approximations are variational methods     that pose inference in terms of minimizing the free energy functional  In the last decade  loopy belief propagation  LBP   a simple local message passing procedure  proved to be empirically successful and was used in a variety of applications       The seminal work of Yedidia et al       merged these lines of work by formulating loopy belief propagation in terms of optimizing the Bethe free energy  an approximate free energy functional  LBP suffers from two inherent problems  it fails to converge in some cases  and may converge to local optima due to the non convexity of the Bethe free energy  Several approaches have been introduced to fix the non convergence issue  so that LBP provably converges to a local optimum of the Bethe free energy           However  this still leaves  the problem of local optima  and therefore the dependence of the solution on initial conditions  To alleviate this problem  several works                construct convex free energy approximations  for which there is a single global optimum  Convexity also paved the way for the introduction of provably convergent message passing algorithms for calculating likelihood and marginal probabilities         Moreover  some of these approximations provide upper bounds on the partition function          Despite their algorithmic elegance and convergence properties  convex variants often do not provide better empirical results than LBP  While this observation is shared by many practitioners  it does not have firm theoretical justification  Motivated by this observation  our goal in this work is to construct approximations that are both convex and directly approximate the Bethe free energy  We show how to approximate the Bethe in L  norm and how to find the best upper bound on it for a given random field  We then illustrate the utility of our proposed approximations by comparing them to previously suggested ones across a variety of models and parameterizations      Free Energy Approximations  Probabilistic graphical models provide a succinct language to specify complex joint probabilities over many variables  This is done by factorizing the distribution into a product over local potentials  Let x  X n denote a vector of n discrete random variables  Here we focus on Markov Random Fields where the joint probability is given by      X X   p x       exp   x     i  xi       Z     i where  correspond to subsets of parameters  or factors   and Z    is the partition function that serves to normalize the distribution  We denote marginal distributions over variables and factors by i  xi   and   x    respectively  and the vector of all marginals by   Given such a model  we are interested in computing the marginal probabilities    as well as the partition function   UAI       MESHI ET AL   Z     which is required for calculating the likelihood of evidence  especially in the context of parameter estimation  Finding exact answers for these tasks is theoretically and practically hard and thus many works often resort to approximate inference  A class of popular approximate inference approaches are the variational methods that rely on the following exact formulation of log Z          n o       log Z      max  T    H   M G   The set M G  is known as the marginal polytope associated with a graph G       A vector  is in M G  if it corresponds to the marginals of some distribution p x       i  xi     p xi   M G     p x  s t        x     p x     is defined as the entropy of the unique exponential H  distribution of the form in Eq      consistent with marginals    Finally  the objective in Eq      is the negative of the free       energy functional  denoted F   The solution to the optimization problem in Eq      is precisely the desired vector of marginals of the distribution p x      In itself  this observation is not sufficient to provide an efficient algorithm  since the maximization in Eq      is as hard as the original inference task  Specifically  M G  is   is difficult to characterize and the computation of H  also intractable  so both need to be approximated  First  one can relax the optimization problem to be over an outer bound on the marginal polytope  In particular  it is natural to require that the resulting pseudo marginals obey some local normalization and marginalization constraints  These constraints define the local polytope P     xi i  xi       P  L G          x  xi   x     i  xi   As for the entropy term  a family of entropy approximations with a long history in statistical physicsPis based on a     r cr Hr  r    weighted sum of local entropies Hc   where r are subsets of variables  regions  and the coefficients cr are called counting numbers       The approximate optimization problem then takes the form  n o   log Z      max  T    Hc        L G   The entropy approximation is defined both by the choice of regions and by the choice of counting numbers  This poses two complementary challenges  defining the regions  and assigning counting numbers for these regions  Here we focus on the second problem  which arises for any choice of regions  For simplicity  we limit ourselves to a common choice of regions  over variables and factors  although      the results to follow can be generalized to more elaborate region choices  e g              In this case the approximate entropy takes the form      Hc    X  ci Hi  i      X  c H             i  where ci and c are the counting numbers for variables and factors  respectively  Each set of counting numbers will result in a different   approximation  The Bethe entropy approximation Hb   is defined by choosing c      ci      di  where di        i            Concave Entropy Approximations One shortcoming of the Bethe entropy is that it is not concave  and thus Eq      may have local optima  It is possible to consider instead entropy approximations that are provably concave  Such approximations have been studied extensively in recent years  along with provable convergent algorithms for solving Eq      in these cases  One of the first concave entropy approximations introduced was the tree reweighting  TRW  method of Wainwright et al       The TRW entropy approximation is a convex combination of tree entropies and is concave  Furthermore  it is an up  so that the optimum of Eq      per bound on the true H  yields an upper bound on log Z     More recently  Heskes     derived a set of sufficient condition for c   ci to yield a concave function  He showed   is provably concave that an entropy approximation Hc   for   L G  if there exist auxiliary counting numbers c   cii   ci    such that c    c    X  ci         ci  i       i i  ci    cii   X  i     Message Passing Algorithms  The optimization problem in Eq      can be solved using generic optimization tools  However  message passing algorithms have proved especially useful for this task  Starting with the work of Yedidia et al      many message passing algorithms have been proposed for optimizing variational approximations  Although not all these algorithms are provably convergent  if they do converge  it is to a fixed   is conpoint of Eq       Furthermore if the entropy Hc   cave  this is the global optimum of Eq       Most existing algorithms make the assumption that c      Since in this work we want to explore a broader range of approximations  we derive message passing updates for the more general case  for any c        Our derivation  which follows closely the one of Yedidia et al   results with the following update rules         MESHI ET AL   UAI      that these models are optimized correctly  It is easy to see that if c satisfies  X ci   c     i       i    will solve the factorized then the corresponding Hc   model exactly  We call c values that obey Eq       variable        valid  as the variables are counted correctly in Hc   In a similar way we can define factor valid approximations that satisfy  Figure    Illustration of the counting number space with different regions and point of interest labeled  see text    mi  xi   ni  xi   Where qi    c  qi c  qi   c qi       c qi       m i  xi   c qi    n i  xi   c qi      m i  xi    ci di  m i  xi    n i  xi          and      X     e c   x    x  xi  n i  xi           ei  xi    Y  nj  xj    j  j    i  Y  mi  xi      i       Note that by plugging in the Bethe counting numbers  where c     and ci      di   this reduces back to the standard BP messages  Furthermore  if we set c     as in Yedidia et al        then Eq      and Eq       reduce to the two way algorithm defined there  The above updates are not guaranteed to converge even   is concave  However  we have found that with if Hc   dampening of messages it did converge for all the cases we studied      Properties of Counting Number Space  Given a specific model  different choices of counting numbers lead to different entropy approximations  But what are good counting numbers and how can we find those for a specific model  One desirable property of counting numbers is that they result in concave entropies  as discussed in Section    There are several rationales for choosing those  One is clearly that optimization is globally optimal  The other is   is itself concave       that the true entropy H  Another approach to deriving good counting numbers is   to restrict ourselves to c such that optimization with Hc   is exact for at least some values of    For example  suppose we have a model where   x       for all   i e   a completely factorized model   How should we constrain c such  c              Intuitively  approximations that satisfy both Eq       and Eq       are valid      as they have the appealing property of not over  or under counting variables and factors    Furthermore  for tree in the approximate entropy Hc   structured distributions it has been shown that only valid counting numbers can yield exact results       Figure   illustrates the structure of the above constraints in the space of counting numbers  Note that the Bethe approximation is the single choice of counting numbers that is both factor  and variable valid  The TRW approximation is  by definition  always variable valid  and any distribution over spanning trees results in a different value of c   Finally  we note that for different model structures the counting number space looks different  For example  the Bethe approximation for tree structured distributions is convex  To better understand the properties of different counting numbers  we perform an experiment where the counting number space is two dimensional and can be visualized  For this we use      toroidal grids in which each variable is connected to four neighboring variables by pairwise factors  The joint probability n distribution of the model is given o P P   by  p x       Z  exp i  i xi    i j G i j xi xj   with xi   xj       The field parameters i were drawn uniformly from the range  F   F    and the interaction parameters i j were drawn either from the range  I   I   or from     I   to obtain mixed or attractive potentials respectively          This model structure has inherent symmetry as all factors are pairwise and each variable appears in exactly four factors  Hence  if we choose the counting numbers of the approximation based solely on the structure of the model  we get the same ci for all variables and the same c for all factors  Figure   shows the performance of various approximations on two models  The first model is sampled in an easy regime with relatively weak interaction parameters while the second model is sampled from a more difficult regime with stronger interaction parameters  We observe that most convex free energy approximations have large errors both in the estimate of the logpartition and in that of the marginal beliefs  When looking at subspaces that tend to empirically perform better   UAI       MESHI ET AL        Figure    Quality of different approximations for two instances of the      toroidal grid from different parametric scenarios  In each matrix the x axis denotes the counting number for nodes  ci   and the y axis denotes the counting number for edges of the grid  c    Each pixel in the matrix is the result of running belief propagation with these counting numbers  The subspace of provably convex approximations is bound by solid lines  and the variable valid subspace is marked by a dotted line  The left column shows the error in approximate log partition function    log Z     log Z        the middle column shows the average L  error in approximate marginals over factors and variables  The rightmost column shows in more detail the approximation quality in the variable valid subspace  The colored stars show various approximations  see Figure   and text    than others  the convex subspace does not seem to generally give good approximations  However  we notice that variable valid approximations stand out as the main region of relatively low error  In fact  we note that to the best of our knowledge all free energy approximations suggested in the literature obey this variable valid constraint                     The rightmost column of Figure   shows performance of variable valid approximations  We notice that for almost all models tested the approximation improves as the counting numbers get closer to the Bethe counting numbers  However  in most cases the Bethe approximation outperforms its convex counterparts  We obtained similar results for fully connected graphs and other non pairwise models  not shown    of the model  and adaptive approximations that also take the model parameters into account       Static Approximations  Following the insights of the previous section  it is natural to try to combine the convexity constraints of Eq      and Eq      with the validity constraints defined by Eq        Inside this subspace  a straightforward choice is to find the counting numbers that are closest in terms of Euclidean distance to the Bethe counting numbers  For clarity we denote by b the vector of Bethe counting numbers with bi    di and b      We define the convexBethe c approximation as the solution to the optimization problem    argmin kc  bk        c     Approximating Bethe  The experiments in the previous section demonstrate that the Bethe free energy performs well across a variety of parameter settings  Since we would like to work with convex free energies  a key question is which of the convex free energies comes closest to the performance of Bethe  In what follows  we describe several approaches to obtaining counting numbers that satisfy the above requirements  We divide these into static approximations that determine the counting numbers based only on the structure  s t  ci   c satisfy Eq            This constrained optimization problem can be formulated as a quadratic program and solved using standard solvers  A similar approach was recently studied by Hazan and Shashua      However  it is not clear that the L  metric in counting number space is adequate for approximating Bethe  In principle we would like to approximate the Bethe entropy itself   is a funcrather than its counting numbers  Since Hb     that is tion of  we would like to find a function Hc          MESHI ET AL   UAI       Figure    Comparison of estimation errors the partition function  left column  and the marginal probabilities  right column  for several approximation schemes  In the first row we take F        and attractive potentials  and in the second row F     and mixed potentials  In each graph the x axis corresponds to the interaction meta parameters I   and the y axis shows the error in the log partition estimation  left column  and marginal estimation  right column   Each line describes the average errors over         grid models sampled with the corresponding meta parameters  The TRW approximation in this graph corresponds to the uniform distribution over four spanning trees   closest to it when integrating over all  values  We can put this formally as  Z    Hc       d  argmin  Hb        c  L G   s t  ci   c satisfy Eq         We integrate over L G  since this is the optimization range in Eq      and thus the relevant domain of approximation  Although this integration seems daunting  we can simplify   and Hc     can be the problem by noticing that Hb   written as bT H and cT H respectively  where H is the vector of local entropies  This results in the following quadratic optimization problem  argmin b  c T A b  c         c  s t  ci   c satisfy Eq         where  Z A    H HT d  L G   is the matrix of integration of all pairwise products of local entropy terms  Exact calculation of A is intractable and so we resort to MCMC methods    by performing a random walk inside L G   Starting with a random point inside   Volume computations over such polytopes are generally difficult  but in some special cases may be solved in closed form       L G   i e   a set of consistent marginals    we sample a legal direction  find the two boundaries along this direction  and then sample uniformly a new point from within the bounded interval  A straightforward argument shows that the stationary distribution of this walk is uniform within L G   To determine when the random walk is close to the stationary distribution  we apply a heuristic convergence test by running in parallel several chains from different random starting points and comparing their statistics      Once we determine convergence  we then use samples from the different runs to estimate A  Finally  we solve the optimization problem in Eq       with and without enforcing the variable valid constraints of Eq        and term these approximations convexBethe vv and convexBethe    respectively  We evaluate the quality of these approximations for calculating the marginals and partition function in      nontoroidal grids with various parameterizations  We compare their performance with the Bethe approximation and the TRW approximation using a uniform distribution over four spanning trees  see           Following Wainwright et al        in each trial we set F to a fixed value and gradually increase the interaction strength I   For each com  We also used uniform TRW weights over all spanning trees and got similar results  not shown     UAI       MESHI ET AL        Figure    Comparison of estimation errors in partition function and marginals of the adaptive free energy approximations  The experimental setting is similar to that of Figure     bination of F and I we sample    random models and measure the estimation errors of each approximation  see Figure     We first observe that the Bethe approximation outperforms its convex counterparts in terms of partition function approximation under all settings  However we see that when the field meta parameter is small  F         and the interaction meta parameter is large  I        the convex approximations do better than Bethe in terms of marginal probabilities estimates  These results are consistent with previous studies             Among the convex free energies optimal L  approximation of the Bethe free energy  convexBethe    does better than optimal L  approximation of the Bethe counting numbers  convexBethe c   in most of the range of parameters  convexBethe  does not perform well in the low interaction regime  small I    This is presumably due to the fact that it is not forced to be variable valid  and thus will not be exact for independent  or close to independent  models  When averaging across all parameter settings  convexBethe  yields the best performance among the convex approximations  We conclude that if one seeks a convex c that performs across a range of parameters  it is advantageous to approximate the Bethe entropy function rather than its counting numbers  However  this comes at a price of lower approximation quality in some regimes  Regarding computation time  both heuristics require extra calculations  We note however  that as the computation does not depend on the model parameters  these extra cal   culations need to be performed only once for each model structure  Once the counting numbers are determined  the optimization of the approximate free energy is exactly the same as in standard BP  In addition  the performance of the convexBethe  approximation depends on the quality of the estimation of the matrix A in Eq        This introduces a trade off between the cost of the MCMC simulation and the quality of the approximation  which can be controlled by the MCMC convergence threshold       Adaptive Approximations  The approximations we examined so far were based on the structure of the model alone  and were not tuned to its parameters  Intuitively  a good approximation should assign more weight to stronger interactions than to weaker ones  Indeed  Wainwright et al        introduce a method for finding the optimal weights in TRW  denoted TRW opt   The   and TRW entropy upper bounds the true entropy H  thus the corresponding variational approximation in Eq      results in an upper bound on the true partition function  Wainwright et al  thus seek counting numbers that minimize this upper bound  Here we present a different and simpler approach for adaptively setting the counting numbers  As in the previous section  our motivation is to approximate the performance of the Bethe approximation via convex free energies  One strategy for doing so is to consider only c where    Hb      This implies that the optimum in Eq      Hc   will always upper bound the Bethe optimum  To come as close as possible to the Bethe optimum  we can then min         MESHI ET AL   UAI       Figure    Comparison of partition function and marginal probabilities estimates for several free energy approximations  In each panel the x axis spans values of F and the y axis spans values of I  attractive setting   Each pixel shows the difference between average absolute errors over    random trials for these meta parameters  That is  red pixels show parameterizations where the error of the first approximation is larger  and blue pixels show parameterizations where the error of the second approximation is larger   imize the optimum of Eq      over the counting numbers c  How can we constrain c to upper bound the Bethe free energy  It turns out that there is a simple condition on c that achieves this  as we show next        be free energy approximation Proposition      Let Fc        is  with c  Cvv   The subgradient of max Fc    Proposition      If c  Cvv then the difference between the approximate free energies can be written as         where   maximizes Fc       Hb       Hc    X      c  I        Where Cvv is the variable valid subspace and I       P H i i  i  H     is the multi information of the distribution   see also       Since I        always holds  we get that if c    for   is an upper bound on the Bethe entropy  all   then Hc   This property is not only sufficient but also necessary if we want to find counting numbers for which the bound holds regardless of    Note that the TRW counting numbers satisfy this constraint and thus the TRW approximation is also an upper bound on the Bethe free energy  Finally  we notice that due to the convexity constraints  Eq      and Eq       the resulting entropy approximation is always non negative  unlike Bethe   We now show how to minimize the upper bound on the Bethe free energy  For this we generalize a result of Wainwright et al              max Fc     I     c  Given this gradient  we can use a conditional gradient al     over the set gorithm as in      to minimize max Fc   of c that gives an upper bound on Bethe  Our algorithm is identical to TRW opt except for the choice of search direction within the conditional gradient algorithm  In TRW opt this involves finding a maximum weighted spanning tree while in our case it involves solving a LP  argminc cT I subject to the constraints   We denote the result of this optimization process by convexBethe u   Empirically we find that this method is faster than the TRW iterative optimization algorithm and requires less calls to the inference procedure  More importantly  while finding the optimal counting numbers in TRW is computationally hard for non pairwise models       our method is naturally applicable in the more general setting  To evaluate the above adaptive strategy  we compare it with the convexBethe c approximation and with the Bethe approximation in the same setting we used for the static approximations  see Figure     In addition  Since the choice of the field meta parameter F greatly influences the relative performance of the approximation we conduct experiments to better understand its role  Instead of fixing the   UAI       MESHI ET AL   field meta parameter and varying the coupling strength we plot a two dimensional map where both meta parameters are free to change  see Figure     As we can see in Figure   both adaptive heuristics improve on the static ones  Moreover  our convexBethe u procedure is often more accurate than TRW opt  Yet  both adaptive methods are still inferior to Bethe approximation for most models we tested  except for the particular regions we discuss above  More extensive comparison for different choices of parameters  Figure    reinforces the observation that the accuracy of the approximations differ under various model parameters  This suggests that given the model structure  there is no single best choice of counting numbers which is better under all parametric settings  We do see  however  that the Bethe approximation gives better or equivalent estimates of the log partition function compared to the convex approximations  negative values in the map  except for the region with a very weak field meta parameter  F     and a strong interaction metaparameter  I         Furthermore  we see that the advantage of convex approximations over Bethe in marginals estimation is also in the region where F is weak and I is strong  To examine the generality of these observations  we repeated the experiments described here for models with a structure of fully connected graph over    nodes  see Appendix A   These dense models differ from the sparse grid structured models  yet we get very similar results  We also conducted similar experiments for smaller and larger grids  see Appendix A  and for models with non pairwise potentials  not shown   again with very similar results  We therefore believe that the conclusions we draw here are valid for a wide range of models      Discussion  The study of convex free energies was originally motivated by the realization that loopy belief propagation was optimizing the non convex Bethe free energy  It thus set out to alleviate the non convexity problem in the Bethe optimization procedure  and indeed has resulted in elegant algorithmic message passing solutions for convex free energies  Another interesting application of convex free energies was for optimizing Bethe  or Kikuchi  free energies via sequences of local convex approximations      Although this resulted in faster optimization  it still inherited the localoptima problem of the Bethe optimization  More recently  convex free energy variants were shown to be particularly useful in the context of model selection       Despite these merits  in terms of quality of the approximation  convex free energies are still often not competitive with Bethe and in fact result in poorer performance over a wide range of parameter settings  as we also show here  This leads to the natural question  which we address in this work  what is the best convex approximation to the Bethe      free energy  As we have shown  there are several approaches to this problem  depending on whether we seek a set of counting numbers that is independent of the model parameters  or one that can be tuned adaptively  Our results show that convex Bethe approximations often work better than other schemes  For example  the counting numbers that approximate the Bethe entropy in L  norm across all  values often work better than other choices  Furthermore  our adaptive strategy for choosing the best counting numbers for a given model often works better than other methods such as TRW  Our adaptive procedures are also easily extendible to nonpairwise regions  unlike TRW which becomes intractable in these cases  One might argue that it is more reasonable to directly   rather than the Bethe approximate the true entropy H  entropy  The main difficulty with this approach is that   is not generally known  and thus its approximations H  are typically quite loose  For example  it is not clear how to go about approximating it in L  norm  as we do for Bethe here  The Bethe free energy  on the other hand  is tractable and as we show can be approximated in various ways  Thus  even though we lose by not approximating the true entropy  we gain by obtaining tighter approximations to the Bethe entropy  which typically provides good performance  Another conclusion from our results is that variablevalid counting numbers usually outperform non valid ones  One possible explanation for this fact is that they are guaranteed to give exact results for independent models  An interesting open question is what other constraints we can pose on counting numbers to enforce exactness in different scenarios  and whether we can optimize over the set of such numbers  Acknowledgements We thank Talya Meltzer  Shai Shalev Shwartz  Raanan Fatal and Yair Weiss for helpful remarks  This research was supported in part by a grant from the Israel Science Foundation   
