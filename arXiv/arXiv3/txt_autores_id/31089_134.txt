 The First Order Variable Elimination  FOVE  algorithm allows exact inference to be applied directly to probabilistic relational models  and has proven to be vastly superior to the application of standard inference methods on a grounded propositional model  Still  FOVE operators can be applied under restricted conditions  often forcing one to resort to propositional inference  This paper aims to extend the applicability of FOVE by providing two new model conversion operators  the first and the primary is joint formula conversion and the second is just different counting conversion  These new operations allow efficient inference methods to be applied directly on relational models  where no existing efficient method could be applied hitherto  In addition  aided by these capabilities  we show how to adapt FOVE to provide exact solutions to Maximum Expected Utility  MEU  queries over relational models for decision under uncertainty  Experimental evaluations show our algorithms to provide significant speedup over the alternatives      Introduction  Probabilistic graphical models have been widely used over the last two decades in real world and research applications  One of their sought after features is the ability to compactly represent a set of interdependencies among random variables  providing a platform for efficient inference methods for both exact     and approximate      inference  Probabilistic Relational Models  PRM  extend the propositional models by introducing the concept of domain entities  along with a richer language which depicts the properties of each entity and the various interactions which they exhibit  Naturally  it is desirable  and often much more efficient  to apply inference directly to the relational model   thus avoiding an explicit extraction of the propositional model  The act of exploiting the high level structure in relational models is called lifted inference  This task can be carried out by a family of exact lifted inference algorithms  which are based on the idea of First Order Variable Elimination  FOVE              An important task which is closely related to probabilistic inference  is decision making under uncertainty  The tight connection between the two tasks is exemplified in the influence diagram model      a popular model for decision making  Influence diagrams extend probabilistic models by adding decision and utility components to probabilistic graphical models  The quality of a decision  a set of assignments to decision variables in the influence diagram  is measured by its Expected Utility  EU   Under this principle  the best decision is achieved by maximizing the expected utility  a task that has been studied for both exact resolution     and approximation       In the relational models realm  the study of decision making in influence diagrams has focused mainly on first order MDP       The goal of this paper is to extend the applicability of FOVE in two directions  First  we enrich the set of operators used by FOVE  by  a  introducing a novel model conversion method called joint formula conversion  and  b  generalizing the known counting conversion     operator to support the conversion of just different atoms      Joint formula conversion is a procedure which couples together pairs of atomic formulas  by replacing all their occurrences in the model with a new formula  whose range is a Cartesian product of the original pair  As we explain and demonstrate empirically  the conversion allows a subsequent use of efficient inference operators  counting conversion     and inversion      where previously one would resort to grounding  Additionally  the combination of  a  and  b  allows further lifting in cases that were previously considered hard for lifted inference  Second  we present a solution to decision making in firstorder influence diagrams     based on the FOVE algorithm  the first lifted solution to the best of our knowledge  Our method applies a variation of C FOVE     that computes   maximum expected utility  MEU       We show that variations of counting conversion and inversion can lift the MEU computation  much like in the belief assessment and MPE tasks  Similarly to other FOVE variations  experimental evaluations show our lifted method to be substantially more efficient than the propositional alternative  We note that recent works            demonstrate the advantage of exploiting the logical structure of first order formulas  e g  MLN features       preference rules      for the benefit of efficient lifted inference  FOVE  on the other hand  operates under no assumption on the logical structure of the first order formulas which compose the relational model  A comprehensive comparison study between these different approaches has yet to be conducted      Model Representation  Based on Markov Logic Decision Network  MLDN       and the work of Milch et al       we present a first order model which depicts two types of variables  random variables and decision variables  and two types of factors  probability factors and utility factors       Atoms  Constraints and Parfactors  Each variable induced by the model corresponds to a ground atom of the form p c            cn    where p is a predicate of finite range  range p   and c            cn are constant symbols  An atomic formula p t            tn   where ti is a constant or a logical variable  is called an atom  Each logical variable X is bound by a domain dom X  with cardinality  dom X    or  X   LV    is the set of logical variables referred by   where  is a formula or a set of formulas  Under a set of assignments v  the notation  v  is used to depict the values assigned to   A factor f is a pair  A     consisting of a set of ground formulas and a potential function    A range    R  Under a set of assignments v  the weight of factor f is wf  v        v           m  v    where A                m    A substitution  over a set of logical variables L maps each variable in L to a constant symbol or a logical variable   depicts the result of applying a substitution  on   A constraint C is a pair  F  L   where F is an equational formula on logical variables set L  gr L   C  is a set of substitutions on L under constraint C  where all logical variables of L are substituted with a constant  Similarly to previous work      we require the constraints to be in some normal form  where for each logical variable X   X   C  has a fixed value regardless of the binding of other logical variables in C  We use var   to depict the set of variables specified by  under the set of substitutions gr L   C   and in order to distinguish between the two types of variables in var    rv   is used to depict the set of random vari   ables in   and dv   depicts the set of decision variables  A parfactor g is a tuple  L  C  A     comprised of a set of logical variables  a constraint on L  a set of formulas and a potential  respectively  Applying a substitution  over parfactor g results in g      L    C     A     where L  and C   are obtained by applying substitution on its logical variables  and dropping those mapped to constants  A ground substitution of a parfactor is a factor which was generated by a substitution over all the logical variables  The model contains two types of parfactors  probability and utility  which depict a set of probability and utility factors upon grounding  As a convention   depicts a potential of a probability parfactor  and  depicts a potential of a utility parfactor  The weight of parfactor g  depicted by wg  v   is determined according to its type  The weight of a probability parfactor is wg  v    wf  v   and the f gr g   weight of a utility parfactor is wg  v    f gr g  wf  v   For convenience and clarity  we use the abbreviation     L             i  Li    C  to represent a parfactor constrained by C  which contains a set of formulas             i with their respective variable scopes L            Li   For instance  the notation    s X   t Y  X    X    Y    represents a probability parfactor whose properties are L    X  Y    C     X    Y     X  Y     A    s  t   and        An alternative notation for constraint C is CX  Y        Counting Formulas and Histograms  Counting formulas express a numerical distribution of values on a portion of a formulas groundings  by counting the number of groundings that are assigned each possible value  Instead of covering each possible assignment  the counting formulas are oblivious to the specific permutations which conform to the count formation  The notation of counting formulas is  X C    where  is the counted atom  X is the counted logical variable  and C is the parfactors constraint over the counted population  For example  formula  Y   X  Y    f riends X  Y    counts the Y population of any given X in atom f riends X  Y    under constraint X    Y   The range of a counting formula     X C     depicted by range    is a set of all possible histograms  A histogram is a set of non negative integer counters  each corresponding to a specific assignment in range    where the sum of all counters is  X   C           Joint Formula Conversion Definition  A joint formula is a composite of two formulas  atoms or counting formulas   whose range of assignments is a Cartesian product of the range of its components  For example  j X  Y      a X  Y    b Y  X   depicts a joint formula of atoms a X  Y   and b Y  X   over logical variables X   Table    Joint formula j X  Y      a X  Y    b Y  X   a X  Y            b Y  X           j X  Y                                                                      p Z          p Z                   a X  Y           j X  Y                                                                                        and Y   If a and b are boolean atoms with range a    range b            then range j                    The joined formulas must be of the same type  Namely  both must be decision formulas or random variable formulas  Joint formula conversion is the replacement of all instances of a joint formulas components with the joint formula itself  Similarly to shattering      it can be applied at the beginning or during the inference task  The conversion conserves the assignment space of the original model  such that each assignment to ground atoms in the original model is mapped to a single respective assignment in the converted model  and vise versa  Both assignments  in the original model and in the converted model  yield the same results in all parfactors  For example  in a two parfactor model  a X  Y    b Y  X   and  p Z   a X  Y     a joint formula conversion for j X  Y      a X  Y    b Y  X   converts the model to    j X  Y    j X  Y    and    p Z   j X  Y     such that under each assignment  va   vb   to a ground of j  the converted potentials yield the same values as their original counterparts under assignments va and vb to grounds of a and b  respectively  Parfactor   is compressed further to     j X  Y     since it contains two identical instances of j  The example is illustrated in Table         Motivation and Example Applications  In a sense  joint formula conversion is counter intuitive  Most lifting operators aim to reduce the variable assignment space  or to restructure the model without introducing unnecessary dependencies between variables  Joint formula conversion does the opposite  it deliberately introduces dependencies between formulas  However  this modification in structure may allow the inference task to benefit from lifting operators that would not be used otherwise  More specifically  joint formula conversion is highly efficient in cases where lifting operators are well defined on the joint formula  but not applicable on the separate components of the joint formula   sportsFan X  friends X Y  drinks Y   X    Y  cohesive X    Y  Figure    A Markov logic network for the group cohesiveness problem  X and Y represent individuals of the same group  friendships are defined on pairs of individuals s t  X    Y    Let us demonstrate this with the task of summingout all the random variables from a given parfactor   a X  Y    b Y  X   c X  Z   d Z    Since both counting conversion and inversion are inapplicable in this case  some grounding operation must be applied  However  this overhead can be avoided by applying a joint formula conversion  for which j X  Y      a X  Y    b Y  X    The conversion yields parfactor    j X  Y    c X  Z   d Z    which in turn can be resolved by a sequence of lifting operators   a  Applying counting conversion over j X  Y   w r t  Y    b  Eliminating c X  Z  by inversion   c  Applying counting conversion over d Z  w r t  Z   d  Eliminating  Y  j X  Y    by inversion   e  Eliminating  Z  d Z   by inversion  The amount of work that was invested in the joint formula conversion is therefore negligible compared with the overall computational benefit  In Section    we introduce a variant of counting conversion which allows the conversion of just different atoms  This newly introduced variation  combined with joint formulas  extends the scope of lifted inference in FOVE even further  For example  Figure   presents the group cohesiveness problem  where each member of a given group is examined according to two characteristics  affinity to sports and affinity to alcohol  The problem can be represented by two parfactors     sportsF an X   drinks Y    f riends X  Y    CX  Y    the chance of two individuals being friends  and    f riends X  Y    cohesive  CX  Y    the chance of a group being cohesive  In order to find out what are the chances of a group being cohesive  all variables but cohesive need to be summedout from the model  We start by fusing   and   into  sportsF an X   drinks Y    f riends X  Y    cohesive  CX  Y    and eliminating f riends X  Y   by inversion  resulting in    sportsF an X   drinks Y    cohesive  CX  Y    Since counting conversion and inversion are both inapplicable in the models current form  we apply a joint formula conversion with j X     sportsF an X   drinks X    The conversion results in     j X   j Y    cohesive  CX  Y    and can be followed by a counting conversion of the j instances  which are just different atoms  Hence  the model is converted to       X  j X    cohesive   and the inference task resumes without resorting to grounding         Logical Variables Mapping  A logical variables mapping  or simply  mapping  between two formulas  and   depicted by M    is an isomorphism from the ordered set of logical variables of   LV                       LV         to the ordered set of logical variables of   LV                       LV         where  i  and  j  depict the i th and j th logical variables of  and  under argument list ordering  respectively  Pairing of logical variables from  and  is allowed only in cases where they have the same domain  For example  a possible mapping between a X  Y   and b W  Z  is Ma b    a     b      a     b       provided that dom X    dom Z  and dom Y     dom W    We   to depict a permutation of L   according to use M   L the mapping from  variables to  variables  In the given example  Mab    Z  M      M  Z   A full mapping between  and  is a mapping over all the logical variables of both formulas  and a joint formula conversion is defined according to such a mapping  For example  in model  a X  Y    b Y  X    a joint formula conversion over mapping Ma b    a     b      a     b      results in the joint formula j X  Y      a X  Y    b Y  X    and in a following conversion    j X  Y    j X  Y     which can be simplified further to     j X  Y     On the other hand  a joint formula conversion of the same model over a different mapping  Ma b    a     b      a     b       results in the conversion    j X  Y    j Y  X    yielding no computational gain  Hence  joint formula conversions do not necessarily result in a more efficient inference  and their use should be considered only in cases where computational gain is guaranteed       Usage and Computational Complexity  In the context of current C FOVE implementations  where a greedy algorithm is used to determine which operator to apply next  joint formulas can simply be used when  a  all other lifting attempts fail  and  b  their placement allows subsequent counting conversions and inversions  However  given the proper heuristics  joint formula conversion can be applied at any phase of the inference task  The computational complexity of joint formula conversion is bounded by O krn      where r is the maximum assignment range of any formula in the model  k is the number of parfactors which consist of the joint formulas components  and n is the maximum number of formulas in any of the subject parfactors       Joint Shattering  Before applying a joint formula conversion  a joint shattering has to be carried out  Joint shattering is identical to the already known shattering     process  only that the  formulas which are about to be joined   and   are shattered w r t  their instances under the joint formula  Namely  the joint shattering splits the set of parfactors in the model  such that parfactors which contain  L    are treated as if they contained  L    as well  where L    M   L    Similarly  parfactors which contain  L    are treated as if they contained  L     Let us demonstrate this with an example  Assume a model  a X  Y    b X  Z   CX  Z   which is about to be applied with a joint formula conversion over mapping Ma b    a     b      a     b       where dom X    dom Y     dom Z     x    x     A joint formula j X  Y      a X  Y    b X  Y    cannot be placed in the models current form  for two reasons  The first  is that there are no constraints which prevent an equality between X and Y   hence j x    x    is a possible ground of j in one of the converted parfactors grounding  However  j x    x    implies that the set of random variables in the original model includes b x    x     which is untrue  A second reason is that the placement of j would result in parfactor j  j X  Y    j X  Z   CX  Z    where the two instances of j entail two sets of ground variables which are neither disjoint nor equal  A joint shattering of  a X  Y    b X  Z   CX  Z   treats the parfactor as if it contained both a X  Z  and b X  Y    In this case  the parfactor is split on substitution Y  X  where two parfactors are created     a X  X   b X  Z   CX  Z    and    a X  Y    b X  Z    C X  Y X  Z     a X  X  here is practically a different formula than a X  Y   where X    Y   since the sets of grounds for both are disjoint  Placing the joint formula in the models current form should yield parfactors  j  a X  X   j X  Z   CX  Z   and  j  j X  Y    j X  Z    C X  Y X  Z         Just Different Counting Conversion  The notion of just different atoms was introduced by Braz et al      for the purpose of counting elimination  but has yet to be exploited for the purpose of counting conversion  As mentioned earlier  the combination of counting conversion of just different atoms with joint formulas  extends the scope of lifted inference and provides motivation to explore this variation of counting conversion  For the purpose of simplicity and clarity  we present a version which converts pairs of just different atoms  Note that the procedure can be generalized to any number of just different atom  The simple case of counting conversion  where a single formula is converted  is directly derived from this more general case  Let parfactor g contain two instances of formula        X  L  and      Y  L   where X and Y are logical variables  L is a set of logical variables  X   L and Y   L  Let any ground substitution of L produce a set of just different atoms  namely  for each given substitution of L  choosing one substitution of X restricts Y in only one substitution  and vice versa  An example of such a par    features X   revenue Y   price X   demand Y X        Formally  G   G G   where G contains a set of probability parfactors  and G contains a set of utility parfactors  The expected utility  EU  of model G under assignment vd to  all  its decision variables is given by   profit  Figure    An MLDN for product planning  depicting decision nodes  rectangles   uncertainty nodes  ellipses   and value nodes  diamonds    factor is   Z  X    Z  Y    CX  Y    Finally  let both X and Y be owned exclusively by their  instances  such that no other formula in g contains neither X nor Y   A counting conversion of formulas   and   over logical variables X and Y in parfactor g is a conversion of g    L   C   A     to g     L    C    A          by replacing the two  instances with an arity reduced counting formula  X C     and defining a potential      such that in probability parfactors     N  b            bk          a    a    b            bk    N a   a     a   a  range         and in utility parfactors     N  b            bk          a    a    b            bk      N  a    a     a   a  range         Where   N  a    a                N  a       N  a         N  a       N  a     a    a  a     a       a  and a  are assignments to grounds of   and     b            bk are assignments to grounds of all other formulas  and histogram N    n            nr   is a set of counters for each possible assignment of  a ground of  under r the conditions r    range    and i   ni    X   C     N  a  depicts the value of the entry which counts assignment a  The rest of g  properties are obtained by L    L    X  Y    A    A             and C    C L   the projection of the remaining logical variables   A number comb N   is then attributed to each histogram N comb N         X   C   arange     N  a         Where comb             comb      comb     in joint formulas  and comb       in atoms      MEU  FOVE for MEU  To capture relational decision making settings  we use a model based on Markov Logic Decision Network  MLDN        The model includes probability and utility parfactors  and two types of formulas  random variable formulas and decision formulas   eu G  vd              wg  vd    wg  vd   Z       gG  rv G  gG  In our setting  we can ignore Z  which is the normalizing constant of the MLDN  The maximum expected utility  MEU  of model G is given by     meu G    argmax eu G  vd     max eu G  vd       vd  vd  To illustrate this model  consider Figure   which depicts a first order decision problem  where a product planner has to decide on a line of products for the enterprise market  We seek a decision that maximizes the expect profit  i e   one with maximum expected utility  The planner needs to determine each products set of features and market price  and does so by examining the profile of each of the potential buyers  their yearly revenue and their demand for each of the expected products  In our model  the problem is represented by two parfactors   f eatures X   price X   revenue Y    demand Y  X   and  price X   demand Y  X     depicts probability weights of various interactions between variables  and  depicts the utility portion  profit   The set of decision variables is represented by atoms f eatures X  and price X   and the set of random variables is represented by revenue Y   and demand Y  X        Challenges in Lifted MEU Computation  Lifted MEU introduces several challenges which do not exist in normal lifted inference  The first challenge stems from the presence of two types of formulas  decision and random variables  for which separate elimination procedures are defined  Notably  random variable atoms are eliminated by summing out their effect on the network  whereas decision atoms are maximized out from the network      Consequently  the number comb N   which is typically attributed to each histogram N   serves no part in the elimination process of decision formulas  Additionally  decision formulas can be eliminated only from parfactors which contain no random variable formulas  The second challenge arises from the two separate parts of the MEU expression  which depict the weights of two type of parfactors  probability and utility  The complex structure forces the inversion procedure to be more complicated than in belief assessment  but most importantly  it poses a significant restriction on the inversion of decision formulas  decision formulas can be eliminated by inversion   only when contained in one type of parfactors  This restriction increases the importance of joint formula conversion  which allows counting conversion to be applied where normally such a use would not be allowed  Joint formulas are in no way a panacea for this inherent nature of the problem  however  without joint formulas many MEU computation tasks unnecessarily resort to propositionalization       Framework  Given a model G  we begin by choosing which operator to apply  We have three lifting operators at our disposal  inversion elimination  counting conversion and joint formula conversion  We also have two grounding operators  propositionalization and counting expansion  which are carriedout identically to C FOVE  After applying the operator of choice  we are left with a transformed model  G    whose MEU solution entails the original models MEU  We continue to apply some operator of choice  repeatedly  until all remaining formulas are  a  decision formulas  and  b  ground formulas  Counting formulas with no active logical variables are considered to be ground formulas as well  Lastly  an exhaustive search is issued on the assignment space  in order to find the maximizing assignments of the remaining ground formulas  A final backward phase  similar to the one used in lifted MPE      resolves the assignments of the eliminated decision formulas       Inversion Elimination  Let G denote the set of parfactors which contain formula  in model G  Inversion elimination     of formula  can be applied to model G under three conditions   a  Model G is shattered w r t     b  For each g  G    contains all the logical variables of g   c  The set of formulas in each g  G contains only one instance of   Inversion eliminates  from the model and produces a residual model G    During the elimination procedure  product fusion and summation fusion are repeatedly used  forming a parfactor with a single instance of  which contains all the logical variables of its container parfactor  Product fusion is defined in      and summation fusion is a similar procedure  with the distinction of summing potentials instead of applying multiplication  We now define formally  the procedure for eliminating random variable formulas  and the procedure for the elimination of decision formulas         Eliminating Random Variable Formulas  We assume formula  to reside in both probability and utility parfactors    We start by merging all probability parfac   tors which contain  into g    L   C   A      using a product fusion  Let g    L   C   A     be some utility parfactor which contains   and let g    L   C   A      be a product fusion of g with g   Let L  and L denote the set of logical variables which are unique to  in parfactors g and g   respectively  A parfactor g     L    C    A        is obtained by calculating sum  b            bk         comb a    a  b            bk         arange    Followed by      b            bk     sum  b            bk   L  C         Where A    A       L    L   L    and C     C L    As a convention  b            bk depict k assignments to all formulas in the subject parfactor  except formula   Next  for each of the g parfactors  a respective g     L    C    A        is obtained by calculating  sum  b            bn         comb a    a  b            bn         arange    Followed by    b            bn       sum  b            bn     L    C   sum  b            bk           Where A    A      L    L  L    and C    C L    Note that k  n  since A  A as a result of g being a fusion of g with g   Finally  a residual model G  is obtained by replacing g with g    and replacing each of the g parfactors with its respective g     Equations   and    instruct of exponentiation and multiplication in the combined domain sizes of the removed logical variables  In effect  these operations express the nature of inversion  where numerous variables are eliminated simultaneously  We demonstrate this with a two parfactor model  p X   q X  Y    and  r Y    q X  Y     for which we aim to eliminate random variable atom q X  Y    The elimination of q X  Y   is conducted  in several steps  First  sum is obtained by sum   q   Since the elimination of q removes logical variable Y from parfac Y   tor  p X   q X  Y       is obtained by      sum     Next  we fuse  p X   q X  Y    with  r Y    q X  Y    sum resulting in  p X   is then ob r Y    q X  Y      sum tained by        Here  a removal of q from q  p X   r Y    q X  Y    does not reduce the set of logical sum variables  Hence    is obtained by     sum   without multiplication  A numerical example is given in Table           Eliminating Decision Formulas     If this is not the case  a stub parfactor    is added to the model  such that  will then be contained in both types of parfactors  All table entries in a stub probability parfactor are    and all table entries in a stub utility parfactor are     Here  two additional precondition are required   a  formula  is contained exclusively in utility parfactors or probability parfactors  but not in both   b  All formulas which share   Table    Eliminating rv formula q X  Y   by inversion p X           q X  Y                                    Y       Y    p X       r Y   q X  Y                   p X  r Y                                            Table    Eliminating decision formula d X  Y   by inversion e X           d X  Y                              e X       dmax  X  Y              Y       Y    a parfactor with  are decision formulas  Next  all parfactors which contain  are fused into g    L   C   A      g is obtained by a product fusion if  is contained in probability parfactors  and by a summation fusion otherwise  A parfactor g     L    C    A         is then calculated by maximizing out the entries of   as follows     L  C       max   in probability parfactors                max    L         C  in utility parfactors   L  depicts the set of logical variables which are unique to  in g   A    A       L    L   L    and C      C L    The assignment to  which formed each entry in    is recorded for a backward phase  Finally  a residual model G  is obtained by replacing g with g    Let us examine model  e X   d X  Y     where both e and d are decision atoms  d X  Y   is eliminated from the model by calculating     maxd  Y     and recording the assignments to d which yield the result entries  The exponentiation in  Y   is the result of logical variable Y being removed from the parfactor  The example is illustrated in Table        Experimental Evaluation  We present results of three sets of experiments  all conducted on a E     Intel duo core machine  with    GHz CPU speed and  Gb of RAM  The propositional variable elimination for MEU was implemented in Java  with emphasis on performance  using a minimum deficiency heuristics     for variable ordering  Our lifted inference implementation is based on the Bayesian Logic Inference  BLOG  Engine  as found in http   people csail  mit edu milch blog index html  and was implemented in Java as well  Joint formula conversions were injected manually  prior to running the inference task   Figure   depicts the results of lifted probabilistic inference in model  p X   q X   r Y    s Y     As can be seen  without joint formulas the model resorts to propositional inference and the problem becomes intractable  By introducing the joint formula j X     p X   q X    the problem is quickly solved  Figure   compares the results of propositional MEU vs  lifted MEU  in model    p Y    q X  Y    d Z       e X   r X     e X   q X  Y     where d and e are decision atoms  Here  as in other FOVE variants  computation time is polynomial in the varying sizes of the domain  whereas computation time for the propositional algorithm is exponential in the size of the domain  In Figure    three inference methods are compared  propositional inference  lifted inference  and lifted inference with joint formulas  Here  the propositional algorithm outperforms the lifted algorithm  but with the addition of joint formulas  the lifted algorithm outperforms the propositional algorithm  similarly to previous figures  A closer examination reveals the reason  The input model contains parfactors  d X   e X   p X       q X  Y     q X  Y     p X   and    e X   r X   f  X    where d  e and f are decision atoms  Elimination of r X  by inversion  followed by the elimination of f  X  by inversion  results in parfactor     e X    Two counting conversions of q instances over Y  and Y    result in parfactor      Y   q X  Y      p X    where  Y   q X  Y     is then eliminated by inversion to construct parfactor      p X    Since p X  is included in both  and       its elimination by inversion converts both parfactors into    d X   e X    and        d X   e X    At this phase  the decision atoms d X  and e X  cannot be eliminated by inversion  since they both reside in probability parfactors as well as in utility parfactors  Moreover  the fact that d X  appears with e X  in the same parfactor  prevents a counting conversion of both d X  and e X   The lifted algorithm resolves this conflict by grounding all the instances of the decision atoms  and continuing with a propositional model  However  the propositional algorithm was implemented much more efficiently than the lifted algorithm  which accounts for the performance gap between the two implementations  Once a joint formula j X     d X   e X   replaces all instances of d and e  the X logical variable could be counted out  resulting in instances of  X  j X    and in an efficient lifted inference      Conclusion  We introduced a novel contribution to the field of lifted inference  a model conversion method called joint formula conversion  and a following contribution which extends the counting conversion procedure  We then demonstrated how the new methods accelerates the task of lifted inference in some models  The use of joint formulas need not be limited to exact inference  In fact  we believe that the notion                  x         lifted inference lifted inference with joint formulas  propositional inference lifted inference              milliseconds                    Domain sizes of X and Y      Figure    Inference in model  p X   q X   r Y    s Y                         propositional inference lifted inference lifted inference with joint formulas       milliseconds  milliseconds             x              Domain sizes of X  Y and Z  Figure    MEU in model    p Y    q X  Y    d  Z      e  X   r X    e  X   q X  Y     decision atoms in asterisk   of joint formulas is generic enough to be adopted by some other relational models  such as relational MDP  Our second contribution  the C FOVE adaptation for MEU  is the first algorithm  to the best of our knowledge  to lift MEU computation  One interesting aspect of lifted MEU is that it generalizes many common probabilistic inference tasks  MPE and belief assessment  for instance  are both private cases of MEU computation  but more importantly  lifted MAP estimation  which has yet to be introduced  can be defined as a private case of lifted MEU  where the computational model contains only probability parfactors  Acknowledgements We thank the anonymous reviewers for their comments and useful suggestions  The authors were partly supported by ISF Grant          the Paul Ivanier Center for Robotics Research and Production Management  and the Lynn and William Frankel Center for Computer Science   
 Various tasks in decision making and decision support systems require selecting a preferred subset of a given set of items  Here we focus on problems where the individual items are described using a set of characterizing attributes  and a generic preference specification is required  that is  a specification that can work with an arbitrary set of items  For example  preferences over the content of an online newspaper should have this form  At each viewing  the newspaper contains a subset of the set of articles currently available  Our preference specification over this subset should be provided offline  but we should be able to use it to select a subset of any currently available set of articles  e g   based on their tags  We present a general approach for lifting formalisms for specifying preferences over objects with multiple attributes into ones that specify preferences over subsets of such objects  We also show how we can compute an optimal subset given such a specification in a relatively efficient manner  We provide an empirical evaluation of the approach as well as some worst case complexity results      Introduction Work on reasoning with preferences focuses mostly on the task of recognizing preferred elements within a given set  However  another problem of interest is that of selecting an optimal subset of elements  Optimal subset selection is an important problem with many applications  the choice of feature subsets in machine learning  selection of a preferred bundle of goods  as in  e g   a home entertainment system   finding the best set of items to display on the users screen  selecting the best set of articles for a newspaper or the best members for a committee  etc  Earlier work on this problem has mostly focused on the question of how one can construct an ordering over subsets of elements given an ordering over the elements of the set  Barbera  Bossert    Pattanaik         The main distinction made has been between sets of items that are mutually exclusive  in the sense that only one can eventually materialize  and sets in which the items will jointly materialize  Our formalism is agnostic on this issue  although we are clearly motivated by the latter case  As Barbera et al  note  most past work focused on the case of mutually exclusive elements  This  for example  would be the case if we are selecting a set of alternatives from which some decision maker  or nature  will ultimately choose only one  e g   courses of action   However        AI Access Foundation  All rights reserved    B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  there is a substantial body of work on the latter setting in which items might materialize jointly  and individual items are preferentially comparable  This paper focuses on a somewhat different context for set preference specification  First  we assume that the items from which our subsets are composed are structured  in the sense that some set of attributes is associated with them  For example  if the items are movies  these attributes could be the genre  language  year  director  if the items are politicians  the attributes could be the political views of the politicians on various topics  their party affiliation  their level of experience  Second  we require a generic preference specification  in the sense that it can be used with diverse collections of items  For example  if we are specifying guidelines for the composition of some committee  these guidelines are generic  and can be used to induce a preference relation over subsets of any given set of politicians  provided that the set of attributes is fixed  Third  we do not assume any preferential ordering over the individual items  although that can certainly be captured by one of the attributes describing the items  An instructive example of the type of domain we have in mind is that of personalized online newspapers  First  the problem of selection for a newspaper is one of subset selection  we have to select a subset of the set of available articles to place in the newspaper  Second  the database of articles is constantly changing  Therefore  an approach that requires explicitly specifying preferences for the inclusion of each specific item is inappropriate  both because the number of such items is very large  and because this would require us to constantly change the preference specification as the set of items changes  Finally  we would not want to base our approach on a method for transforming an ordering over items into an ordering over subsets of items  because we do not want to have to rank each item  and because there are obvious instances of complementarity and substitutability  For instance  even if I prefer articles on Britney Spears to articles on any other topic  two very similar articles about her may be less interesting than a set comprising one about her and one about the Spice Girls   One recent work that considers a similar setting is that of desJardins and Wagstaff         which works by specifying preferences over more abstract properties of sets  In particular  desJardins and Wagstaff offer a formalism for preference specification in which users can specify their preferences about the set of values each attribute attains within the selected set of items  One could assert whether the values attained by an attribute on the selected subset should be diverse or concentrated around some specific value  In addition  desJardins and Wagstaff also suggest a heuristic search algorithm for finding good  though not necessarily optimal  such sets of items  In this work  we present a more general  two tiered approach for dealing with set preferences in the above setting  This approach combines a language for specifying certain types of set properties  and an arbitrary preference specification language for expressing preferences over single  attributed items  The basic idea is to first specify the set properties we care about  and then specify preferences over the values of these properties  Such a specification induces a preference ordering over sets based on the values these sets provide to the properties of interest  We believe that the suggested approach is both intuitive and powerful  Although in this paper we focus on a particular set of properties for which we have devised a relatively efficient optimization algorithm  in its most general form  this two tiered approach generalizes the approach of desJardins and Wagstaff        because diversity and specificity are just two set properties  In principle  one can express both more general    We realize that common rules of rationality may not apply to users with such preferences         G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  properties referring to multiple attributes  as well as more general conditional preferences over the values of these properties  Essentially  our approach re states the problem of specifying preferences over sets in terms used to specify preferences over single items  In our formulation  items stand for the possible sets  and attributes of such items are their  user defined  set property values  Thus  in principle  this approach allows us to re use any formalism for specifying preferences over single items  In this paper we will consider two specific instantiations of such a formalism  qualitative preferences based on CP or TCP nets  Boutilier  Brafman  Domshlak  Hoos    Poole        Brafman  Domshlak    Shimony      a   and quantitative preferences represented as generalized additively independent  GAI  value functions  Bacchus   Grove        Fishburn         The algorithm we suggest for computing an optimal subset given qualitative preferences is based on a similar optimization algorithm for TCP nets  But because the number of items in our case is very large  this algorithm is modified substantially to exploit the special structure of these items  These modifications enable us to compute an optimal subset faster      Specifying Set Preferences The formalism we use for set preference specification makes one fundamental assumption  the items from which sets of interest are built are described in terms of some attributes  and the values of these attributes are what distinguishes different items  We shall use S to denote the set of individual items  and X to denote the set of attributes describing these items  For example  imagine that the items in question are US senate members  and the attributes and their values are  Party affiliation  Republican  Democrat   Views  liberal  conservative  ultra conservative   and Experience  experienced  inexperienced       From Properties of Items to Properties of Item Sets Given the set X of item describing attributes  first  we can already talk about more complex item properties  e g   senate members with liberal views  or inexperienced  conservative senate members  More formally  let X be the union of the attribute domains  that is  X    X   x   X  X   x  Dom X     and let LX be the propositional language defined over X with the usual logical operators  LX provides us with a language for describing complex properties of individual items  Since items in S can be viewed as models of LX   we can write o     whenever o  S and o is an item that satisfies the property   LX   Given the language LX   we can now specify arbitrary properties of item sets based on the attribute values of items in a set  such as the property of having at least two Democrats  or having more Democrats than Republicans  More generally  given any item property   LX   we can talk about the number of items in a set that have property   which we denote by    S   that is     S      o  S o        Often the set S is implicitly defined  and we simply write     Thus   Experience experienced  S  is the number of experienced members in S  Often  we simply abbreviate this as  experienced   While      is an integer valued property of sets  we can also specify boolean set properties as follows  h   REL ki  where   LX   REL is a relational operator over integers  and k  Z is a       B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  non negative integer  This property is satisfied by a set S if   o  S o       REL k  In our running example we use the following three set properties   P    h Party affiliation   Republican  Political view   conservative    i  P    h Experience   experienced    i  P    h Political view   liberal    i P  is satisfied  only  by sets with at least two members that are either Republican or conservative  P  is satisfied by sets with at least   experienced members  P  is satisfied by sets with at least one liberal  We can also write h   REL   i  with a similar interpretation  For example  h Republican     Democrat i holds for sets containing more Republicans than Democrats  An even more general language could include arithmetic operators  e g   require twice as many Republicans as Democrats  and aggregate functions  e g   the average number of years on the job   All these are instances of the general notion of specifying properties of sets as a function of the attribute values of the sets members  In this paper  we focus on the above language with the relational operators restricted to equalities and inequalities  We do so because having a clear  concrete setting eases the presentation  and because restricting the language allows us to provide more efficient subset selection algorithms  Indeed  many of the ideas we present here apply to more general languages  In particular  this generality holds both for the overall preference specification methodology  and for the search overCSPs technique for computing optimal subsets introduced later in the paper  However  the more specific techniques we use to implement these ideas  such as bounds generation  and the specific translation of properties into CSPs  rely heavily on the use of specific  more restrictive languages  Finally  we note an important property of our preference specification approach of being independent of the actual set of items available at the moment  This generality is important for many applications where the same reasoning about set preferences must be performed on different  and often initially unknown sets of items  For example  this is the case with specifying guidelines for selecting articles for an online newspaper  or for selecting a set of k results for an information query      Reasoning with Set Preferences Once we have specified the set properties of interest  we can define preferences over the values of these properties using any preference specification formalism  Here we discuss two specific formalisms  namely TCP nets  Brafman et al       a   an extension of CP nets  Boutilier et al          and Generalized Additively Independent  GAI  value functions  Bacchus   Grove        Fishburn         The former is a formalism for purely qualitative preference specification  yielding a partial preference order over the objects of interest  The latter is a quantitative specification formalism that can represent any value function  Let P    P            Pk   be some collection of set properties  A TCP net over P captures statements of the following two types      Conditional Value Preference Statements  If Pi    pi       Pij   pij then Pl   pl is preferred to Pl   p l   That is  when Pi            Pij have a certain value  we prefer one value for Pl to another value for Pl          G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS      Relative Importance Statements  If Pi    pi       Pij   pij then Pl is more important than Pm   That is  when Pi            Pij have a certain value  we prefer a better value for Pl even if we have to compromise on the value of Pm   Each such statement allows us to compare between certain pairs of item sets as follows    The statement if Pi    pi       Pij   pij then Pl   pl is preferred to Pl   p l  implies that given any two sets S  S   for which     Pi    pi       Pij   pij holds      S satisfies Pl   pl and S   satisfies Pl   p l   and     S and S   have identical values on all properties except Pl   we have that S is preferred to S       The statement if Pi    pi       Pij   pij then Pl is more important than Pm  implies that given any two sets S  S   for which     Pi    pi       Pij   pij holds      S has a more preferred value for Pl   and     S and S   have identical values on all attributes except Pl and Pm   we have that S is preferred to S      Notice that we do not care about the value of Pm if Pl is improved   We refer the reader to the work of Brafman et al       a  for more details on TCP nets  their graphical structure  their consistency  etc  The algorithms in this paper  when used with TCP nets  assume an acyclic TCP net Brafman et al   The latter property ensures both consistency of the provided preferences  as well as existence of certain good orderings of P with respect to the TCP net  As an example  consider the following preferences of the president for forming a committee  He prefers at least two members that are either Republican or conservative  that is  he prefers P  to P  unconditionally   Depending on the context  we use P to denote both the property P and the value P   true  We use P to denote P   false   If P  holds  he prefers P  over P   that is  at least two experienced members   so that the committee recommendations carry more weight  If P  holds  he prefers P  to P   that is  all but one are inexperienced  so that it would be easier to influence their decision  The president unconditionally prefers to have at least one liberal  that is  he prefers P  to P    so as to give the appearance of balance  However  P  is less important than both P  and P    There is an additional external constraint  or possibly a preference  that the total number of members be three   GAI value functions map the elements of interest  item sets in our case  into real values quantifying theP relative desirability of these elements  Structure wise  GAI value functions have the form U  S    i       n Ui  Pi  S    where each Pi  P is a subset of properties  For example  the Presidents preferences imply the following GAI structure  U  S    U   P   S   P   S     U   P   S   because the Presidents conditional preferences over P  s value tie P  and P  together  but are independent of P  s value  U  would capture the weight of this conditional preference  combined with the absolute preference for P  s value  U  would represent the value of property P    We might quantify these preferences as follows  U   P    P          U   P    P         U   P    P         U   P    P         while U   P         U   P         Of course  infinitely many other quantifications are possible     Some external constraints  such as this cardinality constraint  can be modeled as a preference with high value importance  In fact  this is how we model cardinality constraints in our implementation         B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY                                          Q     Sopt   while Q contains a set S such that UB S    Value Sopt   do S  argmaxS   Q UB S     Q  QS    S     LB Sopt    UB S      Q  Q  S   o    o  S   S  S  argmaxS   Q Value S     if Value S    Value Sopt   then Sopt  S end if end while return Sopt Figure    Subset space branch and bound search for an optimal subset of available items S      Finding an Optimal Subset In general  given a preference specification and a set S of available items  our goal is to find an optimal subset Sopt  S with respect to the preference specification  That is  for any other set S    S  we have that the properties Sopt satisfies are no less desirable than the properties S   satisfies  We now consider two classes of algorithms for finding such an optimal subset  These two classes of algorithm differ in the space in which they search  In the next section  we describe a comparative empirical evaluation of these algorithms  For our running example we use the following set of available items S  o  o  o  o   Republican Republican Democrat Democrat  conservative ultra conservative conservative liberal  inexperienced experienced experienced experienced      Searching in Sets Space The most obvious approach for generating an optimal subset is to search directly in the space of subsets  A priori this approach is not too attractive  and indeed  we shall see later that our implementation of this approach did not scale up  However  given that often we are interested in sets of small size and that heuristics can be used to enhance search quality  we thought it is worth exploring this approach  A branch and bound  B B  algorithm in the space of sets is depicted in Figure    For each set S  the algorithm assumes access to an upper bound UB S  and to a lower bound LB S  estimates on the maximal value of a superset of S  The algorithm maintains a queue Q of sets  and this queue is initialized to contain only the empty set  At each step  the algorithm selects a highest upper bound set S from the queue  Next  the algorithm removes from Q all sets S   with upper bound UB S     being at most as good as the lower bound LB S  of the selected set S  and adds to Q all the minimal  that is  one item  extensions of S  The latter sets correspond to the successors of S in the search space  Different implementations of the algorithm differ in how they sort the queue  The best first version depicted in the pseudo code sorts the queue according to a heuristic value of the set  and in       G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  our case this heuristic is an upper bound on the value of the sets supersets  In contrast  the depthfirst version always positions the children of the newly expanded node at the front of the queue  We implemented and tested both versions  The method used to generate bounds for a set S must depend on the actual preference representation formalism  as well as on the type of set properties being used  and the idea is more natural given a quantitative value function  For a lower bound LB S  we can use the actual value Value S  of S  Note that it is possible that all descendants of S will have lower values because  in general  set properties may not be monotonic  e g   average value higher than     However  since S itself is a possible solution  this is a valid lower bound  For an upper bound  we proceed as follows  First  we consider which set property values are consistent with S  That is  for each set property  we examine what values S and any of its supersets can potentially provide to that property  For example  consider P  and suppose S contains a single experienced member  So currently  P  holds  However  we can satisfy P  if we add one more experienced member  Thus  both values of P  are consistent with S  In contrast  if we had two experienced members in S  then P  is inconsistent with S because no matter who we add to S  we can never satisfy P    Next  given such sets of possible set properties values with respect to the set S  we can bound the value of S and of any of its supersets by maximizing values locally  Specifically  in a GAI value function  we can look at each local function Ui   and consider which assignment to it  from among the consistent values  would maximize Ui   Clearly  this may result in an overall value overestimation  since we do not know whether these locally optimizing joint assignments are consistent  Similar ideas can be used with other quantitative representations  as in various soft constraint formalisms  Bistarelli  Fargier  Montanari  Rossi  Schiex    Verfaillie         Consider our running example with the GAI value function as at the end of Section    and consider searching for an optimal subset of S    o    o    o    o    using a depth first version of B B  We start with the empty set  and the property values provided by the empty set are P    P    P    Thus  the lower bound LB    which is the value of the empty set  is    For the upper bound UB    we consider the best property values that are individually consistent with the extensions of   which are P    P    P    and their accumulative value is     Sopt is also initialized to the empty set  and next we generate all of the children of the  only possible  selected set   which are all singleton sets   o      o      o      o     Except for  o     they all have lower and upper bounds identical to those of the empty set  and are inserted into the queue   o    has a lower bound of   and the upper bound is     Suppose  o    is the first queue element  and we select it for expansion  This results in adding  o    o      o    o      o    o    into the queue  and the lower and upper bounds of these sets are                            respectively  Next  the set  o    o    is examined with respect to the current Sopt     and Sopt is assigned to  o    o     Since we assumed here a depth first version of B B we proceed with expanding  o    o     obtaining  o    o    o      o    o    o    with lower and upper bounds being  respectively           and           With a lower bound of    for  o    o    o    we can prune away all the rest of the nodes in the queue  and we are done  An important issue for depth first B B is the order in which sets are generated  In our implementation  at each node in the search space  the items in S are ordered according to the sum of the value of the properties they can help satisfy  For example  initially  a conservative member such as o  could help us satisfy P    In contrast to quantitative preference representation formalisms  qualitative preferences typically induce a partial ordering over property collections  In this case  it is harder to generate strict       B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  upper and lower bounds  as they must be comparable to any possible solution  One way to handle this is to linearize the ordering and require the stronger property of optimality with respect to the resulting total order  Here  TCP nets present themselves as a good choice because there is an efficient and simple way of generating a value function consistent with an acyclic TCP net  Brafman   Domshlak         This value function retains the structure of the original network which is important to make the bounds computation efficient  notably  each Ui depends on a small number of property values       Searching over CSPs The attractiveness of the item subsets is evaluated in terms of a fixed collection of set properties P  and thus different sets that provide all identical property values are equivalent from our perspective  The immediate conclusion is that considering separately such preferentially equivalent subsets of available items S is redundant  To remove this redundancy  we suggest an alternative method in which we search directly over set property value combinations  Of course  the problem is that given a set property value combination  it is not obvious whether we can find an actual subset of S that has such a combination of properties  To answer this question  we generate a CSP that is satisfiable if and only if there exists a subset of S with the considered set property values  The overall search procedure schematically works as follows     Systematically generate combinations of set property values     For each such combination  search for a subset of S providing that combination of setproperty values     Output a subset of S satisfying an optimal  achievable  combination of set property values  To make this approach as efficient as possible  we have to do two things  namely      Find a way to prune sub optimal set property value combinations as early as possible      Given a set property value combination  quickly determine whether a subset of S satisfies this combination  Considering the first task  let P            Pk be an ordering of the set properties P   Given such an ordering of P  we incrementally generate a tree of property combinations  The root of that tree corresponds to an empty assignment to P  For each node n corresponding to a partial assignment P    p            Pj   pj   and for every possible value pj   of the property Pj     the tree contains a child of n corresponding to the partial assignment P    p            Pj   pj   Pj     pj     The tree leaves correspond to  all  complete assignments to P  Such a tree for our running example is depicted in Figure    Note that  implicitly  each node in this tree is associated with a  possibly empty  set of subsets of S  notably  the subsets that provide the set property value combination associated with that node  In our search for an optimal set  we expand this tree of set property value combinations while trying to expand as few tree nodes as possible by pruning certain value combinations of P as either    Throughout this paper  we will assume that in preference specifications using TCP nets  there are only conditional preference  CP  arcs  and importance arcs  but no conditional importance  CI  arcs  While our scheme and implementations allow these arcs  CI arcs force the ordering of the set properties to be dynamic  as it may depend on value assignments to previous properties  For clarity of exposition  we thus preferred not to present these technical details         G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS    P    P   P  P  P   P   P    P  P    P  P  P  P  P    P  P   P  P  P   P    P   P   P   P   P   P   P   P   P   P  P   P   P  P    Figure    Illustration of a search tree for our running example  sub optimal with respect to set preferences  or unsatisfiable with respect to S  A standard way to do this is  again  by using a branch and bound search procedure  and this requires from us to derive effective upper and lower bounds on the value of the best subset satisfying a partial value combination for P  In addition  the order we associate with properties and their values affects our pruning ability throughout the search process  To get the most leverage out of our bounds  we would like to explore the children of a node in the decreasing order of their purported attractiveness  Moreover  when fixing the ordering of the set properties themselves  we would like properties that can potentially contribute more to appear earlier in this ordering  For instance  P  s value in our running example has a greater influence on the overall attractiveness of a subset than the value of P    and thus P  should better be branched on first  In addition  P  is preferred to be true  and thus the subtree corresponding to P    true should better be explored first  Similarly  P  is preferred to be true when P    true  and preferred to be false  otherwise  This ordering is reflected in the tree in Figure    for a left to right pre order traversal of the tree  Now  let us consider the second task of determining whether a subset of S satisfies a given setproperty value combination  Given such a partial assignment  to P  we set up the following CSP  First  the CSP has a boolean variable xi for every available item oi  S  In our example  the CSP contains the variables x            x  for items o            o  respectively  Intuitively  xi     encodes oi being a part of our  searched for  subset of S  whereas xi     means that oi is not in that subset  Next  we translate every set property value in  into a certain constraint on these variables  For instance  if  P      true  the constraint C    x    x    x     is added to the CSP  Note that C  explicitly encodes the requirement  of P    true  for the subset to have at least two of the elements that satisfy Republican  conservative  That is because  o    o    o    are all the candidates in S that are either Republican or conservative  Alternately  if  P      f alse  then the constraint C    x    x    x      is added to the CSP  Finally  if  does not specify a value for P    then no constraints related to P  should be added at all  Likewise  for  P      true and  P      true we would add the constraints C    x    x    x     and C    x      respectively  In general  it is not hard to verify that the CSP constructed this way for a concrete item set S and a set property value combination  is solvable if and only if S has a subset satisfying   Moreover  if this CSP is solvable  then any of its solutions explicitly provides us with such a subset of S  It is worth briefly pointing out the difference between the CSPs we generate here and the more typical CSPs usually discussed in the literature  Most work on general CSPs deals with constraints       B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  over small  typically just two variable  subsets of problem variables  In contrast  the constraints in the CSPs generated in our optimization process are global  with each constraint being possibly defined over all the CSP variables  Yet another special property of CSPs constructed for our purposes is that there is a sense in which it is meaningful to talk about partial assignments in our contextunassigned variables can always be regarded de facto as if assigned the value   since the corresponding items  by default  do not belong to the subset we search for  Because partial assignments to set properties P map to CSPs  each node in our tree of setproperty value combinations maps to a CSP  and the entire tree can be viewed as a tree of CSPs  The important property of this tree of CSPs is that the children of each CSP node are CSPs obtained by adding one additional constraint to the parent CSP  notably the constraint corresponding to the additional property value that we want the set to satisfy  This implies that if some CSP node in the tree is unsatisfiable  then all of its descendants are unsatisfiable as well  In fact  we can make a stronger use of the nature of this search tree  recognizing that we can reuse the work done on a parent node to speed up the solution of its children  To see the latter  consider some CSP C in our tree of CSPs  some child CSP C   of C   and let S  S be a solution to C   As C   extends C with a constraint C  any subset S    S ruled out by C will be also ruled out by C     Hence  if solving C and C   considers subsets of S in the same order  that is  by using the same ordering over set elements   then solving C   can start from the leaf node corresponding to S  the solution generated for C   Moreover  if a constraint C represents a boolean set property  and S is not a solution to C     C   C   then S has to be a solution to C   C   which is the sibling of C     Using these ideas  we share the work done on different CSP nodes of our tree of CSPs  In fact  when all set properties are boolean  this approach needs to backtrack over each property at most once  we call this property limited backtracking   thereby considerably improving the empirical performance of the algorithm  The overall branch and bound algorithm in the space of CSPs is depicted in Figure    As is  the algorithm is formulated for the case of quantitative preference formalisms  The formulation of the algorithm for the qualitative case is essentially the same  with minor technical differences and an important computational property  For CP TCP nets  we can guarantee that only limited backtracking is required if we follow the following guidelines  First  we must order the variables  line    in an order consistent with the topology of the network  Note that for TCP nets  this ordering may be conditional  that is  the order of two variables may vary depending on the value of some of the earlier variables  Second  in line    the property values must be  possibly partially  ordered from best to worst  given the values of the parent properties  which must be and will be instantiated earlier   In that case  the first satisfiable set of properties constitutes an optimal choice  Brafman et al       a   Assuming we solve intermediate nodes in the tree of CSPs  we know that we should backtrack at most once in each level assuming boolean set properties  but  again  more backtracks may occur with integer valued properties  The node data structure used by the algorithm has two attributes  For a search node n   n  captures a partial assignment to the set properties P associated with the node n  and  n S captures a subset of S satisfying n  if such exists  and otherwise has the value false  The functions Value  LB  and UB have the same semantics as in the subset space search algorithm in Figure    In the pseudocode we assume a fixed ordering over set property values  line     but one can vary it depending on earlier values  and we exploit that in our implementation   Finally  the       G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS                                                                          Fix an ordering over set properties P Fix an ordering over the values of each set property P  P Fix an ordering over all available items S Q   n      Sopt   while Q is not empty do n  pop Q  construct and solve csp n  if n S    f alse and UB n S    Value Sopt   then if Value n S    Value Sopt   then Sopt  n S end if Let P be the highest ordered set property unassigned by n  for each possible value p of P do n    n    P   p   n S  Q  Q   n      The position of n  in Q depends on the search strategy end for end if end while return Sopt Figure    CSP space branch and bound search for an optimal subset of available items S   pseudo code leaves open the choice of search strategy for used by the branch and bound  and this choice is fully captured by the queue insertion strategy in line     To illustrate the flow of the algorithm  let us consider again our running example  Recall that the example already has a requirement for the discovered subset to be of size    and this translates into a constraint C   x    x    x    x       The first CSP we consider has  C  C    as its only constraints  Assume the CSP variables are ordered as  x    x    x    x     with value   preceding value   for all xi   In that case  the first solution we find is S    x       x       x       x       Our next CSP adds the constraint C    When solving this CSP  we continue to search  using the same order on the xi s and their values  from the current solution S    which turns out to satisfy C  as well  Thus  virtually no effort is required to solve this CSP  Next  we want to also satisfy C    This set of constraints corresponds to a leaf node in the tree of CSPs which corresponds to the complete assignment P  P  P  to the set properties  Our current item set Sopt   S  does not have a liberal  so we have to continue to the assignment S    x       x       x       x       requiring us to backtrack in the CSP solution space over the assignments to x  and x     We now have a set that satisfies the properties in the leftmost leaf node in our tree of CSPs  If we can prove that this setproperty value combination is optimal using our upper lower bounds  we are done  Otherwise  we need to explore additional nodes in our tree of CSPs  In the latter case  the next CSP will correspond to P    P    P    with constraints  C  C    C    C     However  we already have a solution to this node  and it is exactly S    To see that  note that S  was a solution to the parent of our current CSP  but it was not a solution to its sibling  C  C    C    C     Hence  since P  is a boolean property  S  must satisfy  C  C    C    C            B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY      Solving the underlying CSPs Our algorithm for solving the intermediate CSPs is based on the well known backtrack search algorithm  first presented by Prosser        in a simple iterative form  At the same time  we have adapted both the algorithm and some well known enhancements in CSP solving  such as NoGood recording and forward checking  FC   to the specifics of the CSPs in our setting  Initially  variables and their values are statically ordered from the most to least constrained  although we also discuss a few experiments performed with dynamic variable value ordering   Our motivation for static ordering is two fold  First  because the constraints are very much global  we can do the ordering at a preprocessing stage  Second  as discussed in the previous section  static ordering allows us to better utilize solutions of CSPs when solving descendent CSPs  The basic backtrack algorithm  which on its own  unsurpisingly performs quite poorly in our setting  is refined by utilizing the following observations and techniques   Monotonicity of improving constraints  If the operator of the constraint is   and there are more items having the constrained property already in the current partial solution  then one cannot satisfy the constraint by making additional assignments  The same property holds for the constraint operators    and   Using this observation  it is possible to detect the need to backtrack early on in the search   Forward Checking  A certain type of forward checking can be performed for our constraints  Clearly  if satisfying some constraint requires at least k items to be added to the subset  and the number of remaining items that satisfy the desired property is less than k  then the search algorithm must backtrack   Can Must strategy  The can must strategy corresponds to a more advanced check of the interactions between the constraints  The idea is quite simple  if  i  at least p items must be added to the constructed subset to satisfy the constraint Ci    ii  at most q items can be added to the constructed subset without violating another constraint Cj    iii  all the items that can be added and have the property constrained by Ci also have the property constrained by Cj   and  finally   iv  p   q  then both Ci and Cj cannot be satisfied simultaneously  Moreover  no further assignments to yet unassigned variables can resolve this conflict  and thus the situation is a dead end  This kind of reasoning allows discovery of such barren nodes quite early in the search  pruning large portions of the search tree  To reason correctly about the can must strategy  we have to maintain a data structure of unique items for each pair of constraints  as well as to keep track of the number of remaining items that influence property constrained by Ci and do not influence properties constrained by Cj   As an example  assume we are in the middle of the search and we have two set properties  SP     A    a     and SP     A    b      Suppose that we have already picked   items that influence SP  and   items that influence SP    As a result  to satisfy SP    we must add at least another two items that influence it and to satisfy SP  we can add at most one item that influences SP    If all the items that we can choose from  ok    on   have a value a for the attribute A  and value b for the attribute A    then obviously we cannot satisfy both SP  and SP  within this setting  and thus we should backtrack  Finally  below we discuss recording NoGoods  an improvement of the basic backtracking algorithm that proved to have the most impact in our setting        G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS        N O G OOD R ECORDING The standard definition of a NoGood in the CSP literature is that of a partial assignment that cannot be extended into a full solution of the problem  Once we learn a NoGood  we can use it to prune certain paths in the search tree  The smaller the NoGood  the more occasions we can use it  the greater its pruning power  Thus  it is of interest to recognize minimal NoGoods  and different techniques have been developed to perform NoGood resolution in order to produce the best and most general NoGoods possible  see  e g   Dechter        Schiex   Verfaillie        Dago   Verfaillie         As noted earlier  the CSPs we generate differ significantly from the more typical binary CSPs  Consequently  the NoGood recording algorithm has to be adapted accordingly  In particular  because our constraints are global  it makes sense to try generating NoGoods that are global  too  Thus  instead of recording assignments to variables  we record the influence of the current assignment on the constraints  Every variable influences a set of constraints   Thus  as a NoGood  we store the influence the set selected so far has on all the constraints  Specifically  suppose we have generated the set S    and recognized that it is not extensible into a set satisfying the constraints   This immediately follows from the fact that we backtracked over this set   We now generate a NoGood N that records for each property associated with each constraint  how many items satisfying that property occur in S    Now  suppose we encounter a different set S  that has the same effect N on the constraints  If there are fewer options to extend S  than there are to extend S    we know that S    as well  cannot be extended into a solution  However  if there are more options to extend S  than S    we cannot conclude that S  is a NoGood at this point  In order to better quantify the options that were available to extend S  we record  beyond the actual NoGood N   the level  depth  in the assignment tree at which it was generated  Given that the CSP solver uses a static variable ordering  we know that if we encounter a set S that generates the same properties as the NoGood N   at a level no higher than that of S    we can safely prune its extensions  The reason for that is  there are no additional extension options available for S than there were for S    The correctness of the NoGood recording mechanism proposed here depends on having a static variable ordering  as well as a specific value ordering for all the variables in the CSP  namely  h    i  To show correctness  we should note that a NoGood can be used only after it is recorded  Consequently  any node using a NoGood would be to the right in the search tree of a node the NoGood was recorded at  Here we would like to stress again that  since the constraints are global  it does not matter which items are added to the subset  but rather what influence these items had on the constraints  Any two sets having exactly the same influence on the constraints are identical with respect to the optimization process        S EARCH A LGORITHM The procedure depicted in Figure   extends the basic backtrack algorithm by a subroutine C AN I M PROVE which can be altered to include any combination of the in depth checks discussed earlier  to utilize early conflict detection techniques  including the NoGoods check  Also added is a call to the A DD N O G OOD subroutine for recording NoGoods while backtracking  P and n  the generated instance of a CSP problem with variables indexed from   to  S  and the node in the tree space search    We assume without loss of generality that every item in the set of available items influences at least one constraint in the constraint set C   since items that influence no constraint can be safely eliminated         B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  respectively  are the inputs to the procedure  The algorithm systematically tries to assign values to the problem variables  backtracking and recording NoGoods when facing a dead end                                              consistent  n S satisfies n  while not consistent  do     if H AS VALUES P  vars i   and  C AN I MPROVE P    then P i  L ABEL P i  consistent    If current CSP variable has available values  try to set  update consistency else    A DD N O G OOD  P  i    Record NoGood     P i  U NLABEL P i    Backtrack end if if P i     then   If backtracked over the first indexed variable  no solution available return false end if end while return true Figure    Conflict backtrack algorithm with NoGood recording     Experimental Results We evaluate the different algorithms using a subset of the movie database publicly available from imdb com  We simulated a scenario of selecting movies for a three day film festival according to organizers preferences  Three models of growing complexity have been engineered to reflect the preferences of the organizers  these models are defined in terms of       and    set properties  respectively  In addition  the total number of films is constrained to be    which we actually modeled using a very strong preference   Figure   depicts the list P   of the    properties and their alterations  P  and P  consist of the corresponding prefixes  SP  through SP    and SP  through SP    respectively  of P     To produce even more complex problem instances that cause many backtracks in the space of set property assignments we slightly altered the    properties model  creating two   and P      additional models that are denoted henceforth as P          Preference Specification Figure   provides a verbal description of qualitative preferences for the film festival program which we used in our experiments  Figure   depicts a TCP net that encodes these preferences in terms of the more concrete set properties listed in Figure    For the experiments with GAI value functions  these preferences were quantified by compiling this TCP net into a GAI value function that orders the items consistently with that TCP net  Brafman   Domshlak         The task in our empirical evaluation was to find an optimal subset of a set of available movies S   S      S       S       S        where Si corresponds to a set of i movies  and that with respect to each of the five models of preferences over sets  All the experiments were conducted using Pentium     GHz processor with  GB memory running Java     under Windows XP Professional  The runtimes reported in the tables below are all in seconds  with  indicating process incompletion after four hours         G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  SP    h Year           i SP    h Genre   Comedy    i SP    h Genre   Thriller    i SP    h Genre   Family     i SP    h Color   B W     i SP    h Director   Spielberg    i SP     h Director   Spielberg    i SP    h Sound   Mono    i SP    h Genre   War  Genre   Film noir     i  SP     h Genre   War  Genre   Film noir    i SP     h Genre   Film noir    i SP    h Location   North America     i SP     h Actor   Famous  Actress   Famous     i SP     h Actress   Famous    i SP     h Genre   Drama    i SP     h Release Date           i SP     h Net Profit             i SP      h Net Profit             i  Figure    Set properties used in modeling user preferences in the movies selection domain      Alteration of P     to achieve more backtracking   denoted as P           Further alteration of P   to achieve even more backtracking   denoted as P       I prefer new movies to old movies  and therefore prefer that all movies be from      or later  and this is important to me     I love comedies  thrillers and family movies     I prefer not to have too many movies in black and white  not more than one such movie      If all the movies are new  after       then I would prefer to have at least   comedies     If I can find at least   comedies then I also prefer to have more than   family movie  but less then   thrillers  However having the right number of family movies is more important to me than having the right number of thrillers     If not all the movies are new  I prefer to have at least   movies in black and white for the vintage touch     If not all the movies are new  I prefer at least one movie to be directed by Steven Spielberg  but otherwise  I dont like his newer films    If the previous condition holds  then the number of movies with mono sound may be greater than       I prefer not to have any war films or film noir in the festival  However if this condition can not be satisfied  then I prefer not to have any films that were filmed in North America and this is more important to me than my preferences about the movie being in color or in B W      To draw more attention  I prefer all   movies to have famous actors or actresses      To highlight female roles  I prefer at least   movies with a famous actress      I prefer to have at least   dramas because people tend to think dramas are more sophisticated movies than any other genre      I prefer to have at least one classical movie      I prefer to have at least one commercially successful movie  i e  a movie whose net profit was more than one million dollars   Figure    Informal description of the assumed preferences for selecting a set of movies for a film festival program   First  our initial experiments quickly showed that the search in the space of subsets  Table    does not scale up  With just over    elements  it did not converge to an optimal solution within an hour  even when the preference specification involved only   set properties  This outcome holds for all combinations of qualitative and quantitative preference specifications  depth first and best first schemes of branch and bound  and queue ordering based on sets upper bound  lower bound  and        B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  weighted combinations of both  Table   provides a snapshot of the corresponding results for a TCPnet specified over nine set properties  The table describes the total number of subsets generated until an optimal subset was found  see the column Subset until Sopt    the total number of subsets generated until the optimal subset was recognized as optimal  under Subsets generated   DFS appears to be much more effective than BFS  but the branching factor of larger databases overwhelms this approach  Also  it may be thought that with larger databases it should be easier to quickly generate good sets  but we found that for moderately larger  e g        and much larger  e g         datasets  this approach is too slow  Various improvements may be possible  but given the much better performance of the other approach discussed later  they are unlikely to make a difference   SP    SP   SP  SP    SP   SP   SP    SP   SP  SP    SP   SP   SP    SP   SP  SP    SP   SP   SP   SP   SP   SP   SP   SP   SP   SP   SP   SP   SP  SP   SP  SP   SP  SP   SP            SP  SP  SP  SP   SP   SP    SP   SP  SP   SP  SP   SP  SP   SP            SP   SP   SP   SP    SP    SP   SP  SP    SP   SP   SP   SP  SP   SP  SP   SP  SP   SP            SP   SP   SP   SP     SP    SP    SP    SP    SP     SP   SP   SP   SP   SP    SP   SP  SP    SP   SP   SP    SP   SP  SP    SP   SP   SP   SP   SP   SP    SP    SP    SP    SP   SP    SP    SP    SP     SP    SP   SP     SP    SP     SP    SP    SP    SP    SP   SP     SP    SP   SP     SP    SP    Figure    TCP net model of preference over sets of movies for the film festival program  Next  we consider the CSP space branch and bound search  In particular  here we compared between the two variants of this approach that use dynamic and static variable and value orderings  In what follows  these two variants are denoted as BB D and BB S  respectively  While static variable value orderings are usually considered to be a weaker approach to CSP solving  earlier we have shown that  in our domain  static ordering allows for certain optimizations that have a potential to improve the efficiency of the overall problem solving  In particular  static variable ordering allows to record global NoGoods as described in Section        the results for algorithms that record NoGoods are denoted by a name suffix  ng  In addition  we have tried to share        G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  S  S  S   S   S   S   S   S    Method BFS DFS BFS DFS BFS DFS BFS DFS  Subsets until Sopt                                      Subsets generated                                                 Time  sec                                                 Table    A snapshot of the results for subsets space search  The preferences here are specified by a TCP net over nine set properties  Method  S     S      S      S      P  P  P  P  P   BB D BB S BB S inc BB S ng BB S ng inc                                                                                                       P  P  P  P  P   BB D BB S BB S inc BB S ng BB S ng inc                                                                                                          P   P   P   P   P    BB D BB S BB S inc BB S ng BB S ng inc                                                                                                          P     P     P     P    BB S BB S inc BB S ng BB S ng inc                                                                             P      P      P      P      P    BB D BB S BB S inc BB S ng BB S ng inc                                                                                                 Set properties  Table    Empirical results of evaluating the CSP space search procedures with qualitative preference specification using TCP nets   information between consecutive CSP problem instances while doing the search in the tree of CSPs  the algorithms adopting this technique are denoted by a name suffix  inc  Table   depicts the results of the evaluation of all variants of the CSP space branch and bound search algorithm  Figure     First  the table shows that the overhead of maintaining NoGoods does not pay off for the simple preference specifications  However  for the more complex problems requiring more intense CSP solving  the use of NoGood recording proved to be very useful  letting us        B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  Method  S     S      S      S      P  P   BB S BB S                                              P   P    BB S inc BB S ng inc                                              Set properties  Table    Results for the CSP space search with quantitative preference specification using GAI value functions   solve previously unsolvable instances  Next  the reader may notice from the table that  at least for the problems used in our tests  the contribution of the incremental approach is not substantial  For instance  NoGood recording by itself seems to contribute much more to the efficiency of the optimization process  Moreover  for the more complex problems  switching to the incremental version sometimes even leads to performance degradation  It appears that the overhead of maintaining and copying the partial solution in these cases does not pay off  Our next set of experiments mirrored the first one  but now with GAI value functions instead of the purely qualitative TCP nets  The GAI functions were obtained by properly quantifying the qualitative preferences used for the first tests  Table   provides a representative snapshots of the results  With value functions over set properties P  and P  the basic branch and bound algorithm with static variable value orderings performs and scales up  with growing set of alternatives S  quite well  With the more complex value functions over the larger set of properties P   the performance significantly degrades  and even the incrementality enhanced algorithm cannot solve problem instances with more than      CSP variables  On the other hand  adding NoGoods recording proves to dramatically improve the performance  leading to solving even the largest problem instances  Tables   and   suggest a qualitative difference in the performance of the CSP space search with quantitative and qualitative preference representation models  There are good reasons to expect such behavior  First  compact qualitative models of preference may  and typically do  admit more than one optimal  that is  non dominated  solution  That  in principle  makes finding one such optimal solution easier  Second  if the preferences are captured by a TCP net  then there are variable orderings ensuring that the first solution found will be an optimal one  In contrast  with GAI value functions  after we generate an optimal solution  typically we still have to explore the search tree to prove that no better solution exists  In the worst case  we have to explore the entire tree of CSPs  forcing us to explore a number of CSPs that is exponential in  P   In summary  the first conclusion to be taken from our experiments is that subsets space search fails to escape the trap of the large branching factor  while the stratified procedures for CSP space search show a much higher potential  On the problems that require little backtracking in the space of CSPs  the latter procedures are actually very effective for both TCP net and GAI function preference specification  Obviously  if the procedure is forced to explore many different CSPs  the performance unavoidably degrades  We note that  on larger databases  such backtracks often indicate an inherent conflict between desirable set properties  and such conflicts might possibly be recognized and resolved off line  In this work we do not investigate this issue  leaving it as an optional direction for future improvement  The rather non trivial example used in this section provides the reader also with the opportunity to assess the suitability of different preference specification languages  For example  although we        G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  used boolean valued set properties  it may be argued that some of our natural language preference statements would better be expressed using integer valued set properties  Similarly  users may find that some other preference specification formalism  such as soft constraints  Bistarelli et al          can more naturally capture these natural language preferences  This is an opportunity for us to reemphasize that while  for obvious reasons  we had to focus on a concrete choice of language  we believe that the two tiered approach suggested here is far more general      Complexity Analysis Though reasonable runtimes have been obtained by us empirically with search over CSPs  both algorithm classes described above have a worst case exponential running time  This begs the question of whether the problem itself is computationally hard  Obviously  with external constraints  subset optimization is NP hard  Below we show that even without external constraints  the problem typically remains NP hard  even with significant restrictions on the problem  Naturally  the complexity of subset selection depends on the precise nature of the preference specification formalism used  Most of the results presented here assume TCP net based specification  Hardness results for this model immediately apply to the GAI model  based on an existing reduction  Brafman   Domshlak         In some cases  problems that are tractable under the TCPnet model become NP hard when a GAI model is used  instead  Thus  unless stated otherwise  we assume henceforth that preferences over properties are specified by a TCP net  In analyzing the complexity of the problem we consider the following problem parameters   n  the overall number of items in the data set   a  the number of attributes of the items   m  the number of set properties  i e  number of nodes in the TCP net   k  maximal property formula size  defined as the number of logical connectives  and  or  not  in the formula   d maximum attribute domain size  i e  the maximum number of distinct values for each attribute     the number of times an attribute value can appear in the dataset      NP Hard Classes Theorem    When using TCP based preferences over set properties  finding an optimal subset of a given set of items  POS  is NP hard even if the items are described only in terms of binary valued attributes  and all the set properties are atomic  that is  we have d     and k       Proof  The proof is by a polynomial reduction from the well known NP hard Vertex Cover  VC  problem  Given a graph G    V  E   a vertex cover of G is a vertex subset V    V covering all the edges in the graph  that is  for every edge e  E  there is a vertex v  V   such that e is incident on v  The optimization version of VC corresponds to finding a minimal size vertex cover of G  Given an VC problem instance G    V  E   we construct a POS problem instance by specifying a TCP net N and an item set S as follows  For each vertex v  V we create an item o  denoted       B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  Pe   Pe   Pe   Pe   Pe   Pe   Pe   Pe   Pe   Pek  Pek      Pek  SUM SUM      SUM    SUM           SUM n  Figure    TCP net in the reduction from VC to POS in the proof of Theorem    by ov    and thus we have  S     V     n items  For each edge e  E we define an attribute X  denoted by Xe    and thus we have  X      E    a attributes  All the attributes in X are defined to have a binary          domain  For each item ov   the value of each attribute Xe is ov  Xe       if and only if e is incident on v in G  Next  for each edge e  E  we define a binary set property Pe   h Xe      i that takes the value true if and only if at least one item in the selected subset provides the value   to the attribute Xe   In addition  we define a single multi valued empty set property SUM  h  i    The domain of the SUM property is defined to be the integer value range     n   Note that  by construction  the properties utilize only one attribute per property  and thus no logical connectives  providing us with k      The preferences over these set properties are    For each binary property Pe   the preference is for the value true  that is  Pe   Pe      For the empty property SUM we simply prefer smaller values  that is  SUM         SUM       SUM               SUM n  The only edges in the TCP net N   depicted in Figure    are the importance arcs from each Pe to SUM  meaning that we would rather have to temporize in the value of the SUM property than have any of the Pe being f alse  Proposition   ensures that any optimal subset in the POS problem constructed as above always corresponds to a proper vertex cover of G  Proposition    For any subset S of S that is undominated with respect to the constructed TCP net N   and every edge e  E  we have Pe  S    true  Proof  Given an undominated  with respect to N   subset S  S  let Pe be a set property such that Pe  S    f alse  By construction  there exists an item o  S such that o Xe        Considering S     S   o   we have S   being preferred to S with respect to N because  i  S and S   provide exactly the same values to all the set properties except for Pe and SUM   ii  S provides a preferred    Since the formula  inside this set property is degenerate  and in fact equivalent to h true i  every item in the selection set will have to comply with it  This set property is the simplest implementation of a counter        G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  value to SUM while S   provides a preferred value to Pe   and  iii  preferential improvement of Pe dominates that of SUM  Thus S   dominates S  contradicting the assumption that S is undominated  Lemma    For any subset S of S that is undominated with respect to the constructed TCP net N   there exists a vertex cover VS of G with  VS      S   Proof  The proof is straightforward  Let VS    v   ov  S   Because S is undominated with respect to N   from Proposition   we have Pe  S    true for all binary edge related properties Pe   In turn  Pe  S    true implies that o Xe       for at least one item o  S  By the construction  o Xe       if and only if vertex v covers edge e  Together with the mapping between the vertices V and items S being bijective  the latter implies  VS      S   Lemma    There exists a minimal vertex cover of G of size s if and only if there exists a subset S  S undominated with respect to N such that SUM S    s  Proof  Let S be an undominated subset of S with  S    s  By construction  we have Pe  S    true for all binary set properties Pe   and SUM S       s  By Lemma    there exists a vertex cover VS of G with  VS     s  Suppose to the contrary that VS is not minimal  that is  there exists a vertex cover V   of G with  V       s  Now  construct the subset S      ov   v  V      Since the mapping between S and V is bijective  we have  S        V       s  and thus SUM S       s  Likewise  by construction of our set properties and V   being a vertex cover  we have Pe  S    true for all Pe   This  however  implies that S   is preferred to S with respect to N   contradicting the statement that S is undominated  Theorem   now follows immediately from Lemma   and the fact that the reduction is clearly polynomial  Theorem    Given TCP based preferences over set properties  finding an optimal subset of a given set of items  POS  is NP hard even if the items are described in terms of a single attribute  all the set properties are binary valued  each containing at most   logical connectives  that is  we have a     and k       Proof  The proof is by a polynomial reduction from k SAT  for any k     Given a k SAT problem instance over propositional variables V and logical formula   we construct a POS problem instance by specifying a TCP net N and an item set S as follows  For each variable v  V   construct an item ov and an item ov   and thus S contains an item for every possible literal in the formula  The value of the only attribute X is defined as follows  for each item ol   we have A ol     l  where l is a literal  either v or v  for all v  V    The binary set properties P for the TCP net N are now defined as follows   Properties ensuring that a variable assignment is legitimate  For each variable v  V    Pv  h X   v  X   v     i  that is  for any S  S  Pv  S    true if and only if S contains exactly one of the items  ov   ov          B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY   Properties ensuring that  is satisfied  For each clause C    l   l   l           PC  h X   l   X   l   X   l          i that is  for any S  S  PC  S    true if and only if S contains at least one item corresponding to a literal in C  Finally  to complete the preference specification  we make all properties independent  that is  the TCP net has no edges   and for each of the properties we prefer value true to value false  To illustrate the above construction  consider a   SAT formula     x  y  z    y    x  z   For this formula  the construction leads to item ox ox oy oy oz oz  X x x y y z z  Set properties  Px  h X   x  X   x     i Py  h X   y  X   y     i Pz  h X   z  X   z     i PC   h X   x  X   y  X   z    i PC   h X   y    i PC   h X   x  X   z    i  We now show that finding an undominated subset of S with respect to N as above is equivalent to finding a satisfying assignment to   Let S  S be undominated with respect to N   We can show that S provides value true to all set propositions Pv and PC  in this case we call S an ultimately preferred subset  if and only if  is satisfiable  First  let S be an ultimately preferred subset of S  Given such S  we can construct a mapping A   V    true  f alse  such that A v    true if ov  S  and A v    f alse if ov  S  Note that A is well defined because  for an ultimately preferred subset S  all Pv  S    true  and thus  for each v  V   exactly one item from  ov   ov   is present in S  Clearly  A is a legal assignment for   In addition  we have all PC  S    true  Thus  for each clause C    at least one item with X   li  C belongs to S  By construction  this implies that A satisfies all the clauses in   and thus  is satisfiable  Converesly  suppose that S  S is preferentially undominated with respect to N   but is not ultimately preferred  If our POS problem has such an undominated subset S  we show that  is unsatisfiable  Assuming the contrary  let A be a satisfying assignment of   Given A  we construct a subset SA  S as SA    ol   literal l  A   and show that SA dominates S with respect to N  contradicting the assumed undominance of S  and finalizing the proof of Theorem     By construction  since A is a legal assignment to V   we have Pv  SA     true for all set properties Pv   Also  since A is a satisfying assignment for   we have PC  SA     true for all set properties PC   Therefore  SA is actually an ultimately preferred subset of S  Finally  since all the set properties P are preferentially independent in N   and value true is always preferred to value f alse for all the set properties  we have that SA dominates S with respect to N   Notice that Theorems   and   do not subsume each other  Theorem   poses no restriction on the number of item attributes in the problem instance  but does restrict the domain of all the attributes  Theorem   restricts the number of attributes to    but has no restriction on the domain size of this attribute  and its restriction on the property size is looser than that imposed in Theorem          G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  Finally  we note that tightening the condition of Theorem    by allowing only at most   connective in each set property definition prevents us from using the same reduction as in the proof of Theorem   because the respectibe satisfiability problems would be the polynomial time solvable   SAT problems  Our conjecture  however  is that this fragment of POS is still NP hard  In fact  in Section     we show that the corresponding fragment of POS with the GAI preference specification  instead of TCP nets  is indeed NP hard      Tractable Classes Several tractable classes of POS  obtained by further restricting the problem class discussed in Theorem    and characterized by single attribute item description  that is  a       are discussed below  In both trivially tractable  Section        and non trivially tractable  Section        cases  we assume that the relational symbols are either equalities or inequalities  that in the specification of a property only equalities  attribute   value  are used  and in addition we do not allow an empty set property to be specified  The latter restriction is due to the fact that the empty set property is somewhat special  as it enriches the descriptive power by allowing one to simulate an additional attribute in certain cases  and the single attribute restriction is crucial for our tractability result  Before we proceed with the actual results  note that  with a single attribute item description  no two set properties can be in a conflict that demands backtracking while choosing items  i e  during CSP solution   To illustrate such conflicts  consider the following examples        a h A   ai     i   b h A   ai     i  Set property   a is redundant  subsumed by   b        a h A   as      i   b h A   as      i  One of these set properties must be false         a h A   al      i   b h A   al     i  One of these set properties must be false   All such conflicts between set properties can be resolved offline  prior to the actual process of subset selection  totally disregarding the available items  Hence  within the process of subset selection  we assume that there are no conflicts between set properties  Consequently  subset selection can be done in a greedy manner        T RIVIALLY T RACTABLE C LASS Theorem    Finding an optimal subset of a given set of items  POS  with respect to a TCP net preference specification is in P if the items are described in terms of a single attribute  and all the set properties are atomic  that is  we have a     and k       An algorithm for the problem class in Theorem   is depicted in Figure    The algorithm runs in time O m  n   where m is the number of set properties and n is the number of available items S  The for loop in line   of the algorithm iterates over all the set properties  each time checking compatibility with the previously considered properties  which requires  m    time  The procedures G ET S ATISFYING S ET    and H AS S ATISFYING S ET    have to process each item in S only once  Hence  the total running time of the algorithm is O m  n       This runtime analysis does not include the ordering of the TCP net variables that is assumed to be given  One way to do that would be a topological sort of the net  that obviously can be done in polynomial time         B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY                                                                                                 Sopt   Fix a preference ordering over set properties P Pass   for each property P  P do while  not  P  isSatisfied   do if P is in conflict with Pass then Set next value to P w r t  Pass else if H AS S ATISFYING S ET P   then Sopt  Sopt  G ET S ATISFYING S ET P   P  isSatisfied  true Pass  Pass   P   end if end if end while end for return Sopt procedure G ET S ATISFYING S ET P   S for each item o  S do if o has the property value defined by P then S  S   o  end if if  S  P  op P  cardinality then return S end if end for end procedure    Offline conflict resolution    If cardinality of S satisfies P  Figure    A polynomial time algorithm for the POS problems with TCP net preference specification  single attribute item description  and all the set properties being atomic  that is  a     and k              N ON  T RIVIALLY T RACTABLE C LASS At the end of Section     we have mentioned that the complexity of POS under limiting the setproperty description to at most one logical connective is still an open problem  If  however  we impose the limitations summarized in Table    we can show that the problem becomes tractable  Theorem    Finding an optimal subset of a given set of items  POS  with respect to a TCP net preference specification is in P if it is restricted as in Table    First we should discuss the implicit limitations  or special problem properties  that are imposed by the explicit limitations listed in Table          G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS     All the items have only one attribute  a         All the property formulas have at most   connective  k       and are positive  that is  we disallow negation     The empty property is disallowed    The number of attribute value appearances is limited to at most       that is  values in the attribute domain cannot be repeated  Table    Characteristics of the tractable subclass of POS presented in Section           The restriction to at most one attribute value appearance in the data set provides a one toone correspondence between attribute values and items in S  This means that each item can uniquely represent a specific attribute value combination  and vice versa     The restriction to a single attribute item description renders the  connective redundant  That is because the properties using the  logical connective can only be of the form  X   xi  X   xj    Without loss of generality we assume i    j  or otherwise we can simply drop one of the terms   These properties obviously cannot be satisfied because no item can have two different values for the only attribute X  In fact  set properties defined this way are equivalent to a property that is always f alse     The only relevant cardinalities for the set properties are         A property defined using only one connective with the restriction on the number of repetitions is not expressive enough to state a set property involving more than   items  If the value in a set property  h A   ai  A   aj    op  valuei  is greater than    and op         then again it cannot be satisfied  If the op of a property is  or    and the value is greater than    then it can be substituted by an effectively equivalent set property with op being  and value       The algorithm for the problem class in Theorem   is depicted in Figure     This algorithm bears some similarity to the algorithm in Figure    except that here the procedures G ET S ATISFYING S ET and H AS S ATISFYING S ET reason simultaneously about satisfaction of collections of set property values  and do that by utilizing   SAT solving  Specifically  in Table   we show how any valid property in such a POS problem can be translated into a   SAT CNF formula  In Lemma   we prove the correctness of this translation  We should note that by using   SAT we can have an answer to the question Is there a subset of items satisfying some already evaluated set property values  The procedures G ET S ATISFYING S ET and H AS S ATISFYING S ET use the aforementioned reduction to   SAT to provide the answer in polynomial time  Lemma    There is a subset S satisfying all the property values Pass if and only if there is a satisfying assignment A to the   SAT formula constructed from Pass         B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  h X h X h X h X h X h X    xi      i  infeasible   xi     i  infeasible   xi     i  substituted by   xi      i and translated to  vi   clause   xi     i  translated to  vi  v i   clause   xi      i  translated to  v i   clause Properties having   logical connectives  h X   xi  X   xj      i  infeasible h X   xi  X   xj     i  substituted by h X   xi  X   xj      i and translated to  vi   and  vj   clauses h X   xi  X   xj     i  translated to  vi  vj   clause h X   xi  X   xj      i  translated to  vi  vj   and  v i  v j   clauses h X   xi  X   xj     i  translated to  v i  v j   clause h X   xi  X   xj      i  translated to  v i   and  v j   clauses Properties having   logical connective  Table    Translation of the set properties for the POS subclass in Section       to   SAT                                                  Fix a preference ordering over set properties P Sopt   Pass   for each property P  P do while  not  P  isSatisfied   do Set next value to P w r t  Pass if H AS S ATISFYING S ET Pass   then Sopt  G ET S ATISFYING S ET Pass   P  isSatisfied  true Pass  Pass   P   end if end while end for return Sopt    Use reduction to   SAT   Use reduction to   SAT  Figure     A poly time algorithm for the POS problems with TCP net preference specification  and characteristics as in Table     Proof  By construction  we have an injective correspondence between the properties in the POS problem and clauses in the   SAT problem  Every property P  P injectively corresponds to a certain clause P   Every item o  S injectively corresponds to a propositional variable vi  V   Thus  the correspondence between the selected subset S and the assignment A is simply vi   true  o  S              G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  Because the translation is injective and rather straightforward  without introducing any auxiliary clauses or properties   it is trivial that S is a subset that satisfies all the properties in Pass if and only if A is an assignment that satisfies all the clauses in the corresponding   SAT formula  The above shows correctness of the algorithm in Figure     and finalizes the proof of Theorem        Complexity of POS  TCP nets vs  GAI Preference Specification With the restrictions as in Table   we were able to show that the POS problem with TCP net preference specification is tractable by reduction to   SAT  because there is no need to backtrack while searching in the attribute value space  An interesting question is  what if the specification were done using GAI functions  Theorem    Finding an optimal subset of a given set of items  POS  with respect to a GAI preference specification is NP hard even if the items are described in terms of a single attribute  all the set properties are binary valued  each containing at most   logical connective  that is  we have a     and k       Proof  The proof is by a polynomial reduction from MAX  SAT  As far as item definitions and properties are concerned  the reduction is essentially the same as the reduction from k SAT in the proof of Theorem    That is  for each variable v  V   construct an item ov and an item ov   The value of the only attribute X is defined as follows  for item ol   we have A ol     l  where l is a literal  either v or v  for all v  V    Set properties are also as in the proof of Theorem    but now they are limited to only   variables per clauses  re stated for convenience below    For each variable v  V    Pv  h X   v  X   v     i  that is  properties ensuring that a variable assignment is legitimate   For each clause C    l   l        PC  h X   l   X   l      i  that is  properties ensuring that  is satisfied  The value function specification is such that legitimate variable assignments are enforced  and a larger number of clauses satisfied is preferred  This is achieved by using an additively independent value function  i e   where each factor contains a single variable   with values being as follows  Each clause satisfying property has a value of   for being true  and   for being f alse  Each literalsatisfying property has a value of   for being true  and a negative value of  m for being f alse  where m is the number of clauses  Lemma    Given a GAI value function and item set S constructed as above for a   CNF formula   there exists a subset S  S with value of U  S    p if and only if there exists an assignment A satisfying p clauses in         B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  Proof  Let S be any subset of S that has non negative value  This implies by construction  since there are only m clause satisfying properties PC   that all literal satisfying properties must be true for S  and the respective assignment AS can be constructed as in Equation    Conversely  let A be a legitimate assignment to the variables V   One can define a corresponding set SA   for which  by construction  all properties Pv are true  Also  observe that by construction the number of PC set properties that are true on SA is the same as the number of clauses satisfied by the assignment A  The theorem follows immediately from the properties of the construction of the set properties and preferences  At the end of Section     we have noted that if the restrictions on the problem parameters are more severe than in Theorem    by limiting the number of logical connectives per set property to at most    we can no longer show whether the problem is tractable or NP hard under the TCPnet preference specification  However  Theorem   shows that  with preferences specified using a GAI value function  the problem is in fact NP hard  Moreover  the problem class from Theorem   subsumes the class from Theorem    and thus provides an additional result showing that even though with the TCP net specification the respective problem is tractable  with a GAI preference specification it becomes NP hard      Related Work In the introduction  we mentioned the closely related work of desJardins and Wagstaff         In that approach  the motivation to provide the user with a diverse collection of values is either to reflect the set of possible choices better for applications where the user must eventually select a single item  or when the diversity of the selected set is an objective on its own  The work of Price and Messinger        is explicitly concerned with this problem  Specifically  they consider the problem of recommending items to a user  and view it as a type of subset selection problem  For example  suppose we want to recommend a digital camera to a user  We have a large set of available cameras  and we are able to recommend k cameras  Price and Messinger consider the question of how to select this set  proposing that the candidate set will maximize the expected value of the users choice from this set  They suggest a concrete algorithmic approach for handling this problem  The input to their problem is some form of partial representation of the users preferences  which can be diverse  as in our work  and naturally  the concrete techniques are different from ours  Both these papers share the assumption on ranking sets  common to most previous work as discussed by Barbera et al          that ultimately one item will be selected from this set  However  they do not necessarily start out with an initial ranking over single items  and as in our case  the work of desJardins and Wagstaff utilizes the attribute value of items in the selection process  Earlier work on ranking subsets was motivated by problems such as the college admissions problem  Gale   Shapley         where we need to select the best set of fixed cardinality among a pool of college candidates  The admissions officer has various criteria for a good class of students and wishes to come up with an optimal choice  Some of the key questions that concerned this line of work were what are good properties of such set rankings and whether they have some simple representation  An example of a property of the set ranking that may be desirable is the following  given a set S  if we replace some member c  S with some other member c  to obtain the set S     and c  is preferred to c  then S   is preferred to S  An example of a representation of the ranking       G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  is an additive representation where items are associated with real values and one set is preferred to another if the sum of its elements values is larger  It would be interesting to study similar question in our context of structured objects  This question of ranking sets appears in other areas  such as logics of preference and likelihood  For example  the main question considered by Halpern        is how to construct an ordering over formulas based on an ordering over truth assignments  Formulas are associated with the set of worlds in which they are satisfied  and hence  the question of comparing the likelihood of formulas  and  corresponds to that of ranking their respective set of models given the initial ranking on single models  Much work on non monotonic logics uses Shohams preference semantics  Shoham         and semantically  such work  see  e g   Kraus  Lehmann    Magidor        can be viewed as attempting to answer the opposite question  define a ranking over single truth assignments given some  possibly partial  ordering over formulas  i e   sets of models  A number of lines of work are related to our specification and solution methods  The first is the work on Russian Doll Search  RDS   a well known algorithm for combinatorial optimization  originally presented by Verfaillie  Lematre  and Schiex        as an efficient algorithm for Constraint Optimization Problems  COP   The idea behind the approach is to solve consecutively harder problems  Initially  the problem is solved while considering only one variable  The optimal result provides a lower bound  Each iteration  additional variables are considered  until eventually the original problem is solved  By using the lower bound obtained from the previous iteration  and other optimizations  this technique is often able to solve the original problem more efficiently  Recently Rollon and Larrosa        extended Russian Doll Search to support multi objective optimization problems  In a multi objective optimization problem the goal is to optimize several parameters  attributes  of the variables in the problem  Usually all the parameters cannot be simultaneously optimized  The technique of Rollon and Larrosa involves incremental solution with more and more objectives included  and  in this sense  it is related to our search over CSPs approach in which we incrementally consider more and more set properties  Indeed  different desirable set properties can be viewed as different objectives  Another related area is that of Pseudo Boolean Constraint  PBC  Satisfaction Problems  Sheini   Sakallah         A PBC has the form  X wi li  k  i  Here the li s are literals and we interpret their values as being either    false  or    true   the wi are real valued coefficients  and k is an integer  Thus Pseudo Boolean CSPs are a special form of integer programs  and can nicely represent the cardinality constraints we generate  Thus  one option for solving the type of CSPs generated here would be using a dedicated PBC solver  We run several popular PBC solvers on the satisfiability instances generated during the optimization  Pueblo  Sheini   Sakallah         MiniSat  Een   Sorensson         and Galena  Dixon   Ginsberg         These solvers showed comparable results for satisfiable cases  while for the unsatisfiable cases  the PBC solvers showed better performance  This appears to be due to their use of linear programming as a preliminary test for satisfiability  Another line of work that bears important connection to ours is that of winner determination in combinatorial auctions  In regular auctions  bidders bid for a single item  In combinatorial auctions  bidders bid on bundles of items  Thus  bidders must provide their preferences over different subsets of the set of auctioned items  The goal in combinatorial auctions is to allocate the set of       B INSHTOK   B RAFMAN   D OMSHLAK     S HIMONY  goods to different bidders in the best manner  e g   maximizing the payment to the seller or maximizing total welfare   This differs from the problem of selecting a single optimal subset with which we are concerned  However  in both cases  preferences over subsets must be provided to the optimization algorithm  As the number of subsets is exponential in the number of items  researchers in combinatorial auctions have sought bidding languages that can succinctly describe preferences of interest  Boutilier   Hoos        Nisan         What distinguishes our specification approach is its reliance on the existence of item features and the desire to provide a generic specification that does not depend on the concrete set of items  Work in combinatorial auctions also attempts to break the specification in some way  This is typically done by specifying values for small bundles and providing rules for deriving the value of larger sets from the values of the smaller sets      Conclusion We suggested a simple  yet general approach to lifting any attribute based preference specification formalism to one for specifying preferences over sets  We then focused one instantiation of this idea via a concrete language for specifying set properties  and suggested two methods for computing an optimal subset given such a specification  One method is based on searching the space of explicit subsets  while the other searches over implicit subsets represented as CSPs  Both search spaces are meaningful regardless of the specific underlying preference specification algorithm although the precise search and bounds generation method will vary  We focused on two concrete and popular specification formalisms  one qualitative and one quantitative  on which we experiment and provide complexity results  Although the problem is generally NP hard  as expected  the experimental results are quite encouraging  We wish to reemphasize that other choices  both for the set property language and the preference specification formalism are possible  and may be more appropriate in various cases  Indeed  an interesting topic for future research would be to see which choices fit best some natural application areas  whether and how the algorithm presented in this paper can be modified to handle such languages  and how the complexity of the optimal subset selection problem is affected by such choices  Though incremental search over CSPs appears to be the better method for optimal subset selection  it leaves a few questions open  First  it is an interesting question whether an efficient NoGood recording scheme that does not rely on static variable and value orderings exists  Intuitively  such a scheme should exist since the CSPs generated can be efficiently encoded into SAT as a boolean CNF formula  Bailleux   Boufkhad        Een   Sorensson         and clause learning is a well known technique in SAT solving  Second  we have seen that while the incremental approach usually improves the overall performance  its contribution is not substantial and what really improves the performance is better individual CSP solving  This begs two questions      Can we better utilize solutions across CSPs  and     Would representing and solving the CSPs generated as pseudo boolean CSPs  Manquinho   Roussel        or SAT instances lead to faster solution times  Naturally  alternative approaches are also feasible  Finally  in various applications  the set of elements gradually changes  and we need to adapt the selected subset to these changes  An example is when we use this approach to choose the most interesting current articles  and new articles constantly appear  It is likely that in this case the preferred set is similar to the current set  and we would like to formulate an incremental approach that adapts to such changes quickly         G ENERIC P REFERENCES OVER S UBSETS OF S TRUCTURED O BJECTS  Acknowledgments Preliminary versions of this work appeared in  Brafman  Domshlak  Shimony    Silver      b  Binshtok  Brafman  Shimony  Mani    Boutilier         The authors wish to thank our anonymous reviewers for their useful comments and suggestions  Brafman was supported in part by NSF grant IIS          Brafman and Domshlak were supported by the COST action IC      Binshtok  Brafman and Shimony were supported by Deutsche Telekom Laboratories at Ben Gurion University  by the Paul Ivanier Center for Robotics Research and Production Management  and by the Lynn and William Frankel Center for Computer Science   
 We propose a directed graphical representation of util ity functions  called UCP networks  that combines as pects of two existing preference models  generalized additive models and CP networks  The network de composes a utility function into a number of additive factors  with the directionality of the arcs reflecting conditional dependence in the underlying  qualitative  preference ordering under a ceteris paribus interpreta tion  The CP semantics ensures that computing opti mization and dominance queries is very efficient  We also demonstrate the value of this representation in de cision making  Finally  we describe an interactive elic itation procedure that takes advantage of the linear na ture of the constraints on  tradeoff weights  imposed by a UCP network      Introduction  Effective representations for preferences and utility func tions are critical to the success of many AI applications  A good preference or utility representation should capture statements that are natural for users to assess  or are easy to learn from data  it should offer the compact expression of preferences or utilities  and it should support effective inference    A useful design stance for such representation is to exploit the structure of utility functions using notions from multi attribute utility theory  such as conditional preferential in dependence  mutual utility independence  etc        Re cent work has exploited such structure to develop graphical models  Bacchus and Grove        propose an undirected network representation for  quantitative  utility that cap tures conditional additive utility independencies  Boutilier  Brafman  Hoos and Poole     propose a directed network representation for  qualitative  preference functions that captures conditional preference statements under a ceteris paribus  all else equal  assumption  La Mura and Shoham  II  describe a hybrid representation for combining both probabilistic and utility information in a Wldirected graph ical model representing expected utilities directly   In this paper  we propose a new directed network represen tation for utility functions that combines certain aspects of  the first two of these approaches  The UCP network for malism can be viewed as an extension of the CP network model     that allows one to represent quantitative utility information rather than simple preference orderings  The formalism also utilizes the notion of generalized additive independence  GAl       By employing a directed graph  UCP nets allow one to make more powerful statements that are often more natural and lead to more effective infer ences  In particular  we will show that dominance and op timization queries can be answered directly in UCP nets  In addition  the formalism can be used in an interactive elicitation process to determine relevant parameters of the UCP model in a specific decision scenario  We propose a technique for elicitation much like that proposed by Cha jewska  Koller  and Parr     that exploits the linear con straints imposed by a partially specified UCP model to de termine an  optimal  sequence of queries  The rest of this paper is organized as follows  Section   provides necessary background  Section   describes UCP nets  their properties  and their relation to GAl decomposi tions of utility functions and CP networks  Section   dis cusses the problem of optimization in the context of UCP nets  and shows the advantage of this representation tool  Section   explains how elicitation and optimization can be performed concurrently in order to recognize near optimal choices with minimal questioning  We conclude in Sec tion   with a discussion of future work     Background Concepts  We begin with an outline of some relevant notions from multiattribute utility theory       We assume a set of ac tions A is available to a decision maker  each action hav ing one of a number of possible outcomes  The set of all outcomes is designated    A preference ranking is a total preorder t over the set of outcomes  o   t o  means that outcome    is equally or more preferred by the decision maker than o   A utility function is a bounded  real valued function u     f t R  A utility function u induces a pref erence ordering t such that    t    iffu ot   u o    A utility function also induces preferences over lotteries  or distributions over outcomes  where one lottery is preferred to another when its expected utility is greater  When actions   BOUTILIER ET AL   UAI           have uncertain outcomes  thereby generating a distribution over outcomes  preferences for actions can be equated with preferences for the corresponding lotteries       One difficulty encountered in eliciting  representing  and reasoning with preferences and utilities is the size of the outcome space  which is generally determined by a set of variables  We assume a set of variables V  X           X n  characterizing possible outcomes  Each variable X  h as domain D o m  X        x i        x       The set of outcomes is     Dom V  Dom X   x    x Dom Xn  Thus direct assessment of a preference func tion is generally infeasible due to the exponential size of    Fortunately  a preference function can be specified con cisely if it exhibits sufficient structure  We describe certain standard types of structure here  see      for further de tails      Figure    A CP Network       We denote a particular assignment of values to a set X  V as x  and the concatenation of two non intersecting partial assignments by xy  If XU Y V  xy is a complete outcome  and xy is a completion of the partial assignment x  Comp x  denotes the set of completions ofx     A set of features X is preferentially independent of its com plementY   V  X iff  for all x   xz  y   yz  we have  X  Y   X Y   iff  X Y   XzYz  We denote this as PI X  Y   In other words  the structure of the preference relation over assignments to X  when all other features are held fixed  is the same no matter what values these other features take  If PI X Y  and X  Y  x y for any assignment y to V  X  then we say that x  is preferred to x   ceteris paribus  Thus  one can assess the relative preferences over assignments to X once  knowing these preferences do not change as other attributes vary  We define conditional preferential independence analogously  Let X  Y  and Z be nonempty sets that partition V  X and Y are conditionally preferentially independent given an assignment z to Z  denoted CPI X  z Y   iff  for all XI Xz YI Y   we have  In other words  the preferential independence of X andY holds when Z is assigned z  If we have CPI X  z Y  for all z E Dom Z   then X andY are conditionally preferen tially independent given Z  denoted CPI X  Z Y   Decomposability of a preference function often allows one to identify the most preferred outcomes rather readily  Un fortunately  the ceteris paribus component of these defini tions means that the CPI statements are relatively weak  In particular  they do not imply a stance on specific value tradeoff s  For instance  suppose PI  A B  and PI B  A  so that the preferences for values of A and B can be as sessed separately  with a     az and b     bz  Clearly  a b  is the most preferred outcome and a b  is the least  but if feasibility constraints make a   b  impossible  we must be satisfied with one of a b  or a b   With just preferential independence we cannot tell which is most preferred us ing these separate assessments  Stronger conditions  e g    mutual preferential independence         are required before such tradeoff s can be easily evaluated  CP nets     are a graphical representation for structuring In particular  CP nets are directed acyclic graphs whose nodes are the variables of V  We associate a  CPI statements   conditionalpreference table  CPT  with each node X spec ifying a preference order over X s values given each in stantiation of its parents U  and require that CPI X  U  Z  hold  where Z   V   U U  X    CP nets structure these CPI statements so as to support useful inferences about the underlying preference order      In Fig    we see a CP net defined over a set of four boolean variables  where  e g   the CPT for specifies that c is preferred to c when a and b hold  An important property of CP nets is the induced importance it assigns to different variables  nodes  higher up  in the graph are more important than their descendants  Thus  it is more important to obtain preferred values for a node than for any one of its descendants  For example  in the CP net above  we can see that abed  in which a less pre ferred value of appears  is preferred to abed  in which a less preferred value of A appears   This property plays an important role in UCP nets   C  C  Let X           Xk be sets of not necessarily disjoint vari ables such that V uiX   X         Xk are generalized additive independent  GAl  for an underlying utility func tion u if  for any two probability distributions Pr  and Pr  over Dom V  that have the same marginals on each of the sets of variables Xi  u has the same expected value under Pr  and Pr  In other words  the expected value of u is not affected by correlations between the X i  It depends only on the the marginal distributions over each the X i     xk are GAl iff u can be J  Xi   That is  u can be de  It can be shown     that xl      L  l  I  written as u V    composed into a sum of factors over each of these sets of variables  This property generalizes the standard definition of additive utility independence  which requires that the Xi partition V  For UCP nets the ability to deal with overlap ping sets of variables is critical      Adding Utilities to CP Nets  As noted above  the precision of a utility function  as op posed to a preference ordering  is often needed in decision making contexts where uncertainty is a factor  The rep resentation of utility functions should be natural  easy to elicit  compact  in typical cases   and support effective in ference  There are two basic types of queries with regard   BOUTILIER ET Al       h a b c   UA               while h a b c           Thus  the CPT  tables along with the GAJ i nterp r eta tion provide a full spec  ification of the utility function  For example  we have that  u a b c d    fi a    h b                            Figure    A UCP Network to outcomes one will often ask     a  Dominance queries  does one outcome have higher utility than another  i e   u vt      u v       b  Outcome optimization queries  what outcome has maximum utility given some partial assignment  i e   what is ar g m ax  u v     v E Comp x     GAl models allow dominance testing to be performed very effectively  the utility of outcome v is readily determined by looking up the value  i v  of each factor applied to v  and summing them to obtain u v   In contrast  CP nets do not allow straightforward dominance tests  generally re quiring reasonably sophisticated search techniques for all but the simplest network topologies  The relative attrac tiveness of the two approaches is  however  reversed when one considers optimization queries  In CP nets  determin ing the  conditional  maximal outcome in a preference re lation is straightforward  In contrast   maximization in a GAl model requires the use of variable elimination          whose complexity depends on the structure of the modeL       h a b c      j  c d      Notice however that the factors h and h are redundant in the sense that they refer to variables that are included in  J  Thus  this utility function could be represented more concisely using a GAl decomposition containing two fac tors  j  C D  and j  A B C    JI A    h B    h A  B  C   The directionality of the utility augmented CP network  on the surface  seems to serve no purpose other than to break up the GAl factors unnecessarily  However  we can use this directionality to represent CP conditions on the utility function u  and thus provide a sim ple and natural interpretation for the individual factors of u  In particular  we interpret the fact that A and B are parents ofC as asserting that CPJ C   A  B   D   and thus the fac tor h A  B C  specifies the utility of C given A and B  The fact that each node is isolated from the rest of the net work given the values of its parents greatly simplifies utility assessment  Furthermore   this structure supports more ef ficient inference for certain queries than the standard GAl representation  Definition   Let u X           Xn  be a utility function with induced preference relation  A UCP networkfor u is a DAG Gover X         Xn and a quantification  i e   a set of factors    X   Ui  where Ui are the parents of Xi  s t     a  u Xt       Xn  Ldi X   U    b  The DAG G is a valid CP network for   i e   satisfies CPI Xi  U   Z   for each X   where Z     We propose in this section a new network representation for utilities that combines aspects of both CP nets and GAl models  The model is directed  like CP nets  but prefer ences are quantified with utilities  The semantics is given by generalized additive independence along with the con straint that the directed influences reflect the ceteris paribus condition underlying CP nets  By extending CP nets with quantitative uti lity information  expressive power is en hanced and dominance queries become computationally ef ficient  By introducing directionality and a ceteris paribus semantics to the GAl model  we allow utility functions to be expressed more naturally  and permit optimization queries to be answered much more effectively  A UCP net extends a CP net by allowing quantification of nodes with conditional utility information  Semantically  we treat the different factors as generalized additive in dependent of one another  For example  the network in Fig    can be extended with utility information by includ ing a factor for each family in the network  specifically      A   h B   h A  B  C   and j  C D   see Fig      We interpret this network using GAl  u A B C  D   I A    h B    h A B C    j  C D   Each of these factors is quantified by the  now quantitative  CPT ta bles in the network  For example  in Fig    we have that  V   U   u      Xi    Condition  a  means that every UCP net specifies a GAl decomposition of the underlying utility function u  How ever  the acyclic restriction means that not every GAl de composition can be represented in a UCP net  For exam ple  the GAl decomposition u A  B  C  h  A  B C    h C B  would have to converted to the decomposition u A B C    h A B C   where h  I       before it could be represented as a UCP net  Nevertheless  there is a simple case where a GAl decomposition can easily be seen to be representable using a UCP net topology        Proposition   If there exists a ordering of the variables such that under this ordering the last variable in every GAl factor is unique  i e   no variable is last in more than one factor   then the GAl decomposition can be represented with a UCP net topology        Queries regarding optimization with respect to actions are discussed in the next section    GAI optimization can be effected using cost networks        To construct the UCP net in this case  for every factor we make every  last  variable a child and all of the prior vari ables its parents  Even if we can represent a GAl decomposition in a UCP net topology and we parameterize the net using the GAl   BOUTILIER ET AL   UAI          dren  It requires that we check that  for each instantiation of X s children and the parents of its children  whether the decrease in local utility  i e   in factor f x  dominates the  potential  increase it causes in the local utilities of its chil dren  With this definition  we can specify a straightforward nec essary and sufficient condition that ensures a DAG satisfies the CP conditions required by the definition of a UCP net   Figure    The Domination Relation  factors  the the result might not be a UCP net  since the utility function might not satisfy the CP requirements of condition  b   For example   let u be a utility function over  the boolean variables A and B with u ab     u ab     u ab    and u iib       No UCP net can represent          To see this  first notice PI  A  B  fails to holds  since preferences for B depend on A  But we cannot make A a  u   B  since the preferences for A depend on B  can we make B a parent of A for a similar reason     parent of  nor  This example shows that  for a fixed set of variables  UCP nets define a proper subset of all utility functions  but this subset has certain attractive computational properties as well as pragmatic advantages when it comes to elicitation  Given a UCP network U for utility function u  verifying that it satisfies the CP relationships among variables re quired by its definition can be accomplished by tests in volving the local neighborhoods of each node in the net work   Definition   Let X be a variable in a quantified DAG with parents U and children Y    Y         Yn   and let Z  be the parents of Y   excluding X and any elements of U  Let Z U Z   Let U  be the subset of variables in U that are parents of Y   the relationships among these    variables is shown in Fig       We say X dominates its if  for all x    x  such that  children given u E Dom V  fx x   u         x x   u   for all z  y        yn  E Dom Y    E  Dom Z    and for all  fx xl  u   fx x   u        L jy   y   X   u   z     jy   y   x   u   z   i  X dominates its children if this holds for all u  E  Dom V    Testing whether X dominates its children is a local test  in volving only the factor for variable X and those of its chil   The example above can be accommodated by clustering the dependent variables  That is  we can define a new variable C with Dom C    Dom A  x Dom B   In general  any utility function can be represented in a UCP net by clustering appropriate sets of variables  This can be a reasonable approach if the clusters remain relatively small  It is also possible to generalize the definition of a UCP net to allow cycles  This example could be represented by allowing A and B to be parents of one another  Cycles allow one to express a larger set of utility functions  but still do not permit all utility functions to be represented  They also may admit inconsis tency  certain network structures with cycles do not correspond to a consistent utility function satisfying the CPconstraints  an impossibility in acyclic graphs   We refer to     for details   Proposition   Let G be a DAG over  Xi  whose factors fi reflect the GAl structure of utility function u  Then G is a UCP net iff each variable Xi dominates its children  Proof  We need only show that the CP condition holds for iff X dominates its children  Assume the same vari ables stand in relation to X as in the definition of domina tion above  and let W V   U U  X  U Y U Z   i e   all of the other variables in the network   X satisfies the CP condition iff  for all x   x   u  x  uyzw t x uyzw implies x u yzw    x u yzw   for all  yzw    Now x  uyzw t x uyzw iffu x  uyzw   u x uyzw   iff  X     fx x   u    x x   u        L jy   yi  x    u    zi      jy   yi  x   u   z    since the only factors whose values can vary between these two terms are f x and the fy   By definition this relation holds for all values of  y  and  X dominates its children   IIIII  z   and trivially for all w  iff  Determining if a quantified network is in fact a UCP network requires a case by case analysis for each  ex tended family  in the network involving a number of tests exponential in the size of the extended families  by this we refer to a variable  its parents  its children  and its children s parents   Several stronger sufficient conditions exist that are easier to test  Here we present a particularly simple one   Proposition   Let G be a quantified DAG over the set of variables V  For each variable X let U be its set ofparents in G  For X   X  E Dom X   let  Minspan x  x   Minspan X         min  uEDom U  min  xl x EDom X    lfx xt u   fx x  u l    Minspan x   x     Define Maxspan X  analogously with max replacing min  Then G is a UCP net ifMinspan X        Li Maxspan Y   where the Y  are the children ofX  The values of Maxspan and Minspan can be computed for each variable X in   IDom  X  II f xI  time  Thus  this con dition can be checked in time polynomial in the number of network parameters  For purposes of elicitation and computation  it is often con venient to normalize utilities over the range         Simi larly  it is useful to normalize the individual factors of a   BOUTILIER ET AL       UAI      UCP net  In Section   we will consider a normalized vari ant of the UCP net model in which the  rows  of each fac tor are normalized and  tradeoff  weights are used to cali  instantiation of its parents in v i    with all other variables retaining their values from Vi     c  if Xi E Z  then  brate them  Specifically   by the forward sweep algorithm  assuming ties are broken in the same way as   a  For each variable X  with parents U and factor f x  and each u E Dom U   we normalize the function fx x  u  so that its values lie in the range         That is  we insist that minx fx x  u      and    We denote the normalized func maxx fx x  u  tion v x and call it the local value function for X given    u    b  For each  X and instantiation of its  ify a multiplicative tradeoffweight  tradeoffweight a x   parents  r  u   we spec  x  and an additive  parents  It is not hard to see  by the usual transformation  results in utility theory  that every UCP net has an equiva lent normalized representation   in the procedure   since v n t vz for any outcome v z consistent with the evidence  the forward sweep procedure yields an optimal outcome   ill  This algorithm illustrates the sharp contrast between UCP nets and GAl representations  Effective outcome optimiza tion in a GAl model requires that one use a dynamic pro gramming algorithm like variable elimination  As a conse quence  the complexity of such an algorithm exponential in the induced tree width of the GAl model depends crit  Thus  UCP nets offer a valuable restriction of GAl models and generalization of CP nets  In particular  they impose restrictions on the relative strength of the GAl factors  and generalize CP nets to allow for the representation of quan titative utilities  But we preserve the convenient graphical representation of CP nets  and gain considerable computa tional benefits over both models  One of the main reasons to move from qualitative to quan  Optimization Algorithms  The two types of queries discussed above  dominance queries and optimization queries  can both be answered di rectly in UCP nets  Dominance queries can be answered trivially  determining whether u vl      u v   for two complete outcomes simply requires that one extract and sum the values of each factor in the network and then com pare the sums  This can be done in time linear in the size of the network  Thus UCP nets offer the advantages of other additive decompositions  In contrast  dominance testing in CP nets is computationally difficult precisely because the tradeoffs between the  conditional  preference levels for different variables have not been specified  Outcome optimization queries can also be answered di rectly given a UCP net  taking linear time in the network  z E Dom Z   deter Comp z   can be effected  size  Given a partial instantiation  mining argmax u o    o E by a straightforward sweep through the network   Let  X         Xn  be any topological ordering of the network variables excluding Z  We set Z   z  and instantiate each xi in turn to its maximal value given the instantiation of its parents  This procedure exploits the considerable power of the CP semantics to easily find an optimal outcome given  certain observed evidence  or imposed constraints    Proposition   The forward sweep procedure constructs  the optimaloutcomeargmax u v   v  Proof  Let  Yi   The last outcome  ically on the  topology   of the model and the ability to find good elimination orderings   The semantics of such a normalized UCP net is as follows  the utility of any outcome is given by the sum of the terms  for each variable X   rxvx x    a x  where x is the in stantiation of variable X and u is the instantiation of its     v i   Vj    By construction  Vi t vn is precisely that constructed  E  Comp z     vz be any outcome in the set of completions  of z  Define a sequence of outcomes vi     i  n  as follows   a  Vo   Vz   b  if xi  it Z  Vj is constructed by setting the value of Xi to its most preferred value given the  titative preference models is to support decisions under  quantified  uncertainty  Naturally  given a decision prob lem and a fully specified UCP network  determining an optimal course of action is  conceptually  straightforward  W hen the distributions induced by actions can be structured in a Bayes net  UCP nets can be used to help structure the decision problem  Suppose that the distribution over vari ables V determined by an action a is represented as a Bayes net  possibly with a choice node if we wish to represent all actions  and the utility function over outcome space is de termined by a UCP net   To compute the optimal action  we can construct an influence diagram by adding one utility variable Fi for each  nonconstant  factor f x  in the UCP network   Fi  has as parents both  X   and the parents of Xi  in the UCP net  and is quantified using factor f x  from the  UCP net  Variable elimination  e g   Dechter s       MEU  variant  can be used to determine the optimal action     This approach uses the GAl factorization of utilities af forded by the UCP net  but not the CP semantics  We can improve upon these ideas by noticing that our goa is to select the optimal action  not  necessarily  compute tts ex    pected utility  In any GAl representation  we can bound  the error associated with ignoring a utility variable Fi with parents U as follows  L et ei m axu Fi u   minu Fi u      The expected value EV a  of any action  a  is given by  L Pr vla  l  Fi v   L L Pr vla F  v      vEV  i  i  vEV    ften utilities are elicited only over variables that are directly related to preferences  The variables in the Bayes net may include variables not contained in the UCP net    ne might also consider how expected utility networks  l l  might be used in this regard    UA       BOUTILIER ET AL   Let EV i a  be the expected value of action a with re spect to all utility variables except Fi  Then IEV a         tion problem  Given a specific set of questions that can  such that  be posed to the user  the  myopic  value of information for each question with respect its reduction of the minimax re  a  gret can also be computed by solving a linear program  As  is optimal without having to compute the i th term in the above summation  Analogous statements hold for ignoring any subset F of the utility variables  setting ep   LiEFej   such  an incremental procedure can be used to compute a greedy query plan that will ask just enough questions of the user to decide on a course of action whose regret is below some prespecified threshold  if this threshold is set to zero  then the optimal action will be recommended    EV i a  I     e   Thus EV   a     EV   a    if there is some    for all  a     j   a   a  we know  This suggests an incremental technique for computing an optimal  or near optimal  action that exploits the CP semantics of a UCP net  Let X          Xn be a topological ordering of the variables in the UCP net  Our technique runs in  at most   n  stages  where at stage  k   we compute  EV  i k  a  for each action a  If for some a  we have EV  i k   a    EV   i k   a     E i k  for all a    j   a   we know a is optimal and we can terminate without comput ing any further terms  Furthermore  we can remove from consideration at subsequent stages any action whose partial utility differs by more thane  i k  from the  estimated  op timal action at this stage  The motivation for this approach lies in the fact that in a UCP network  variables near the top of the UCP net have a larger impact on utility  and are thus more likely to lead to the separation of actions than factors lower in the net  For example  if action a has high probabil ity of making the most important variable  X   take its most  desired value  while action b is likely to ensure its least de sired value  we may be able to eliminate b from considera tion by just computing the first term of above summation   We can also terminate when the error associated with a  is below some threshold  even if it is not optimal  The computational benefits arise when one considers that computing EV   i   k   a  requires one to do inference only  on those variables that are relevant to predicting F  i k   Furthermore  at each each stage we need only compute the expected value with respect to the newly added utility vari    able  In a problem with no evidence  for example  this can be accomplished by considering only ancestors of the vari ables F  in the Bay es net  An important issue with this iter  To make this more precise  we define a to be a set of actions A  out too much difficulty   Structure elicitation  involving  questions regarding the relative importance of different at tributes  as well as the dependence of these assessments on other attributes should not be especially onerous  Eliciting  value function v x requires ordering a small number of val ues  given a specific parent context  and calibrating these value using  local  standard gambles  again  a relatively un  problematic task  Although the structure and value functions are thus de termined  the tradeoff weights for the normalized UCP network remain unknown  The utility of any outcome v is a linear function of these weights  specifically  ifv in stantiates each variable  Xi  to Xi and parent set  Ui  to ui   then  u v             TU  L      X  VU  X    x        JUi  i  X   Let W be the set of possible instantiations of the tradeoff weights  and u v  w   denote the utility ofv for a particular  instantiation w E W  The expected value of any action a i is also a linear function of the tradeoff weights   EV a   w    rithmic question   Elicitation with UCP nets  decision scenario where each action  the elicitation of both structure and local value functions is something that users will often be able to provide with  results   determining such orderings is an interesting algo       an   As a starting point  we assume that we have been provided with a normalized UCP network  whose structure and local value functions v x have been provided  but whose trade off weights  Tx and ox remain unspecified  We feel that  reusing information computed in earlier iterations  This is  VE is used it might be possible to find variable orderings for each computation that facilitate the reuse of previous        ai E A induces a distribution Pri V  over outcomes  Let    denote the support set for Pr   i e   the set of outcomes v for which Pr i V        We generally assume that Oi is small relative to Dom V    ative procedure is how to minimize overall computation by plausible since  utility  factors generally overlap  and these factors generally have common influences  For example  if    a       L  vEO   Pr i  v   u  v  w    Note that by assumption  Oil is relatively small  so this sum       should contain only a small number of terms  One of the key problems facing the use of decision theoretic models is the elicitation of preference informa tion  In this section we describe one possible procedure for exploiting the structure and semantics of a UCP network to facilitate an incremental elicitation process  More pre cisely  given a specific decision scenario  i e   a set of pos sible actions and the corresponding distributions over out comes they induce and a set of constraints on the tradeoff weights of a normalized UCP network  the  regret  of the  best action can be computed as a simple linear optimiza   We define the optimal action a     with respect to an instan tiation w of the tradeoff weights to be  a     argmaxEV a   w   a   utility function were known to have weights w  a   would be the correct choice of action  The regret of action ai with respect to w is If the  R a   w       EV a    w     EV ai  w     BOUTILIER ET AL       i e   the loss associated with executing ai instead of acting optimally  Let C be a subset of the set of possible instanti ations of the tradeoff weights  W  We define the maximum regret of action ai with respect to C to be  Finally  we define the action a  with minimax regret with respect to C  a      ar g min a   MR  ai   C   The  minimax  regret level of weight set C is MMR  C  MR aC   C   If the only information we have about a user s utility function is that it lies in the set C  then a   is a reasonable choice of action  Specifically  without distribu tional information over the set of possible utility functions  choosing  or recommending  a c minimizes the worst case loss with respect to possible realizations of the utility func tion     If C is defined by a set of linear constraints on the weights  then a  as well as MMR C  can be computed using a set of linear programs  First note that we can compute  for any pair of actions ai and ai using a linear program  we are maximizing a linear function of the weights sub ject to the linear constraints that define C  Solving O n    such linear programs  one for each ordered pair of actions  allows us to identify the action a  that achieves minimax regret and to determine the minimax regret level MMR  C    MMR C  tells us how bad off we could be recommend ing a   In particular if MMR C    MR a   C      then a  dominates all other actions  it is at least as good as any other action for every feasible set of tradeoff weights  How ever  unless C is very refined  i e   is defined by strong con straints   multiple actions will potentially be optimal  i e   will be maximal in certain regions of weight space   To de termine which of these actions to recommend  we need to refine the constraints defining C further  C can contain a range of different linear constraints  One class of constraints in C is imposed by the structure of the network  In particular  each variable must dominate its children  this is a necessary condition in any UCP net  Us ing the same notation for variable X s neighborhood as in Defn     domination imposes the following linear constraint on the weights  for each u  z  y and pair x l  x  E Dom   X  such that v   xt     v   x      we must have   Another class of constraints is the set of bounds that re strict each tradeoff weight  r and u to a specific range  Such bounds are required in order to keep the LP problems  UAI      we have proposed using bounded  Eliciting such bounds from the user is not a difficult task  as one can always start with very loose bounds  For example  the minimum and maximum utility of any possible outcome is a simple uni form bound on the tradeoff weights  Besides these required constraints  C could contain other nonstructurallinear con straints provided by the user  e g   constraints on the rela tive magnitudes of different weights  reflecting degree of importance  or constraints on the relative expected utility of different actions in certain fixed contexts  If minimax regret is zero  or lies below some acceptable threshold  the action a  can be recommended  Otherwise  questions can be asked of the user to help differentiate be tween possible actions  The solution to the above set of O n   linear programs can provide some guidance  For example  the linear program for solving MR ai  C  also yields a solution to the dual problem  This solution pro vides a multiplicative factor associated with every inequal ity in C that tells us how much of a change we can produce in MR  ai  C   in the neighborhood of the optimal solution  by modifying the inequality  Say that the k th inequality is the upper bound  r       and that the value of the k th variable in the dual solution is      This tells us that if we can get the user to tighten their upper bound on  r Jl by   units this might yield a     unit decrease in MR ai  C   By examining the factors associated with the bounds imposed on the weights  those weights that have the most potential to influence MMR  C  could be identified  Furthermore  af ter we have queried the user and obtained an updated bound we need not resolve the linear programs from scratch to re compute the maximum regret of each action  There are many techniques in the LP literature on sensitivity analysis that can be employed to minimize the amount of computa tion that needs to be performed      However  generally for realistic elicitation we cannot rely solely on the recommendations of the linear programs  In particular  sharpening the inequality recommended by the dual solution might not be an easy task for the user  The types of questions that can  reasonably  be asked will be domain dependent  and influenced by factors such as the complexity of the domain  e g   if the number of attributes is manageable  asking a user to compare full outcomes may be acceptable  but otherwise not   the sophistication of the user  and the importance of the decision to be made  To address the general problem here  we will assume a  finite  set of possible questions Q    q        qk   with each Qi having m possible responses r           rf   we fix the num ber of responses simply to streamline the presentation   We suppose that every response adds an additional linear con straint to C  this subsumes the case of sharpening an ex isting constraint   Let C d  denote the set of weights that satisfy C U  r      Then asking a question qi and receiving a response r  will reduce minimax regret by the amount MMR C   MMR C r     This suggests a querying strategy in which questions that have the ability to reduce minimax regret the most are asked first  In a certain sense  asking questions that reduce   UAI      BOUTI LIER ET AL       determine if an optimal decision can be made  If no action  minimax regret can be seen as a distribution free analog of traditional value of information approaches to query  dominates all others  further preferences are elicited  Our  ing  Specifically  the procedure we suggest strongly par allels the elicitation method proposed in      where a dis  approach extends this basic viewpoint in a number of ways  including the utilization of richer utility models and a min  tribution over possible utility functions is used to guide  imax regret model that supports decisions even when no  the interactive elicitation process  In our distribution free model  we cannot define the expected value of a ques tion  but instead use the worst case response to define  action is dominant  ISMAUT does not generally describe means for generating queries automatically or making de cisions when no action is dominant   the minimal improvement we can obtain from some ques tion  The minimax improvement of question q i   Ml q       is mini MMR C    MMR C r       The minimax optimal query with respect to C is that query with maximal im provement M  qi     We note that the improvement M  qi  for any query must be nonnegative  since q   will always re duce the size of the feasible weight space  and generally will be nonzero  This suggests the following abstract elicitation strategy   rf is obtained  refined weight space C r    Then  imal improvement is asked  and response  MMR C rt     is computed by solving the previously spec  rf    ified linear programs with the added constraint Tech niques for sensitivity analysis can be utilized to minimize the work involved in doing these computation  This pro cess is repeated until one of two conditions is met   a  the current weight space admits an action with regret less  than some threshold r  or  b  no query has an improve ment score greater than the cost of that query  This latter condition is typically important in interactive elicitation  while one could ask many questions to narrow down a util ity function so that a  near  optimal decision can be made  one must account for the cost of these questions  e g   the burden they impose on the user   Making this procedure concrete requires having a set of possible questions whose responses induce linear con straints on weight space   As pointed out above  such  questions will in general be domain dependent  However  they might include asking the user to quantify the relative strengths of various tradeoff weights associated with a sin gle variable ax and  r x   For example  asking the user for a value of k such that a   ka   Since this involves the outcomes of a common variable it should be relatively easy for the user to answer  Assessing relative tradeoff weights associated with different variables is a similar  albeit more difficult  question  Sharpening an upper or lower bound on a weight was addressed above  One more type of ques  tion might be to ask the user which of actions a i or aj she would prefer in a specific context  The answer to this ques tion again imposes a linear constraint on weight space  This approach is very similar to that utilized in imprecisely specified multiattribute utility theory  ISMAUT       In such work  standard additive independent utility models are assumed and constraints on tradeoffs weights are used to    The  sequences  of  questions that reduce regret may not be considered if the individual questions in the sequence do not  Circumvent ing this requires l ookahead or some form of dynamic pro gramming  This problem is common to most value of in formation approaches  e g         The use of minimax re gret to select actions should be viewed as reasonable in the  which myopically attempts to improve minimax regret  Given a set of feasible weights C  the query q  with max resulting in a more  Our elicitation procedure has several drawbacks  greedy nature of the algorithm means that  Queries can be ranked simply using their worst case minimax regret  rather than their worst case improvement  since the term MMR  C  is common to all queries and responses   absence of distributional information  However  selecting queries so that the worst response has maximal improve ment may not always be appropriate  and comparing this worst case improvement to the cost of the query may also be questioned  but other strategies are possible  We are currently exploring the use of distributions over weight space  i e   over utility functions  to guide the elici tation process  In the abstract  such a model would be sim ilar to that of Chajewska  Koller  and Parr       The dif  ferences lie in the use o f UCP nets as the underlying util ity representation  and the use of dynamic programming to construct optimal query sequences  rather than using my opic value of information   Integrating this with linear op timization poses some interesting challenges      Concluding Remarks  We have proposed a new directed graphical model for rep resenting utility functions that combines appealing aspects of both CP nets and GAl models  The UCP net formal ism has a number of conceptual and computational advan tages over these models  providing leverage with respect to inference and elicitation  Clearly  practical experience and empirical studies are needed to gauge the ultimate ef fectiveness of UCP nets  However  we are encouraged by the widespread use of additive models  and more recently  by the successful application of CP nets to the problem of preference based Web page content configuration      We are currently in the process of implementing the inter  active elicitation algorithm described in Section    Future research includes the inclusion of distributional informa tion over utility functions  or tradeoff weights   and devel  oping algorithms that compute and use value of informa tion to construct optimal query plans  Another fundamental question pertains to determining optimal query plans when the query space is large or infinite  involving parameterized queries  e g   standard gambles   We expect that the con siderable structure exhibited by the problem  e g   the fact  that the set of actions divides weight space W into a set of convex regions where each action is optimal  will allow optimization over each query type to be effected  without explicit enumeration of all instances        BOUTILIER ET AL   UAI      The investigation of the suggested optimization algorithms   and trade off weight determination under uncertainty   specifically  empirical validation of the incremental vari able elimination approach to decision making described in Section    is a high priority   IEEE Transactions on Systems  Man and Cybernetics   Acknowledgements         R  L  Keeney and H  Raiffa   Decisions with Multiple Objectives  Preferences and Value Trade offs  Wiley   New York          Craig Boutilier and Fahiem Bacchus were supported by Communications and Information Technology Ontario  the Institute for Robotics and Intelligent Systems  and the Natural Sciences and Engineering Research Council of Canada  Ronen Brafman was supported by the Paul lvanier Center for Robotics and Production Management   
 We consider the problem of optimal planning in stochastic domains with resource constraints  where the resources are continuous and the choice of action at each step depends on resource availability  We introduce the HAO  algorithm  a generalization of the AO  algorithm that performs search in a hybrid state space that is modeled using both discrete and continuous state variables  where the continuous variables represent monotonic resources  Like other heuristic search algorithms  HAO  leverages knowledge of the start state and an admissible heuristic to focus computational effort on those parts of the state space that could be reached from the start state by following an optimal policy  We show that this approach is especially effective when resource constraints limit how much of the state space is reachable  Experimental results demonstrate its effectiveness in the domain that motivates our research  automated planning for planetary exploration rovers      Introduction Many NASA planetary exploration missions rely on rovers  mobile robots that carry a suite of scientific instruments for use in characterizing planetary surfaces and transmitting information back to Earth  Because of difficulties in communicating with devices on distant planets  direct human control of rovers by tele operation is infeasible  and rovers must be able to act autonomously for substantial periods of time  For example  the Mars Exploration Rovers  MER   aka  Spirit and Opportunity  are designed to communicate with the ground only twice per Martian day  Autonomous control of planetary exploration rovers presents many challenges for research in automated planning  Progress has been made in meeting some of these challenges  For example  the planning software developed for the Mars Sojourner and MER rovers has contributed significantly  c      AI Access Foundation  All rights reserved    Meuleau  Benazera  Brafman  Hansen   Mausam  to the success of these missions  Bresina  Jonsson  Morris    Rajan         But many important challenges must still be addressed to achieve the more ambitious goals of future missions  Bresina  Dearden  Meuleau  Ramakrishnan  Smith    Washington         Among these challenges is the problem of plan execution in uncertain environments  On planetary surfaces such as Mars  there is uncertainty about the terrain  meteorological conditions  and the state of the rover itself  position  battery charge  solar panels  component wear  etc   In turn  this leads to uncertainty about the outcome of the rovers actions  Much of this uncertainty is about resource consumption  For example  factors such as slope and terrain affect speed of movement and rate of power consumption  making it difficult to predict with certainty how long it will take for a rover to travel between two points  or how much power it will consume in doing so  Because of limits on critical resources such as time and battery power  rover plans are currently very conservative and based on worst case estimates of time and resource usage  In addition  instructions sent to planetary rovers are in the form of a sequential plan for attaining a single goal  e g   photographing an interesting rock   If an action has an unintended outcome that causes a plan to fail  the rover stops and waits for further instructions  it makes no attempt to recover or achieve an alternative goal  This can result in under utilized resources and missed science opportunities  Over the past decade  there has been a great deal of research on how to generate conditional plans in domains with uncertain action outcomes  Much of this work is formalized in the framework of Markov decision processes  Puterman        Boutilier  Dean    Hanks         However  as Bresina et al         point out  important aspects of the rover planning problem are not adequately handled by traditional planning algorithms  including algorithms for Markov decision processes  In particular  most traditional planners assume a discrete state space and a small discrete number of action outcomes  But in automated planning for planetary exploration rovers  critical resources such as time and battery power are continuous  and most of the uncertainty in the domain results from the effect of actions on these variables  This requires a conditional planner that can branch not only on discrete action outcomes  but on the availability of continuous resources  and such a planner must be able to reason about continuous as well as discrete state variables  Closely related to the challenges of uncertain plan execution and continuous resources is the challenge of over subscription planning  The rovers of future missions will have much improved capabilities  Whereas the current MER rovers require an average of three days to visit a single rock  progress in areas such as automatic instrument placement will allow rovers to visit multiple rocks and perform a large number of scientific observations in a single communication cycle  Pedersen  Smith  Deans  Sargent  Kunz  Lees    Rajagopalan         Moreover  communication cycles will lengthen substantially in more distant missions to the moons of Jupiter and Saturn  requiring longer periods of autonomous behavior  As a result  space scientists of future missions are expected to specify a large number of science goals at once  and often this will present what is known as an oversubscription planning problem  This refers to a problem in which it is infeasible to achieve all goals  and the objective is to achieve the best subset of goals within resource constraints  Smith         In the case of the rover  there will be multiple locations the rover could reach  and many experiments the rover could conduct  most combinations of which are infeasible due to resource constraints  The planner must select a feasible subset of these that maximizes expected science return  When action outcomes  including resource consumption  are stochastic  a plan that maximizes expected science return will be a conditional plan that prescribes different courses of action based on the results of previous actions  including resource availability  In this paper  we present an implemented planning algorithm that handles all of these problems together  uncertain action outcomes  limited continuous resources  and over subscription planning  We formalize the rover planning problem as a hybrid state Markov decision process  that is  a Markov decision process  MDP  with both discrete and continuous state variables  and we use the continuous variables to represent resources  The planning algorithm we introduce is a heuristic search algorithm called HAO   for Hybrid state AO   It is a generalization of the classic AO  heuristic search algorithm  Nilsson        Pearl         Whereas AO  searches in discrete state spaces  HAO  solves       HAO   planning problems in hybrid domains with both discrete and continuous state variables  To handle hybrid domains  HAO  builds on earlier work on dynamic programming algorithms for continuous and hybrid state MDPs  in particular  the work of Feng et al          Generalizing AND OR graph search for hybrid state spaces poses a complex challenge  and we only consider a special case of the problem  In particular  continuous variables are used to represent monotonic resources  The search is for the best conditional plan that allows branching not only on the values of the discrete variables  but on the availability of these resources  and does not violate a resource constraint  It is well known that heuristic search can be more efficient than dynamic programming because it uses reachability analysis guided by a heuristic to focus computation on the relevant parts of the state space  We show that for problems with resource constraints  including over subscription planning problems  heuristic search is especially effective because resource constraints can significantly limit reachability  Unlike dynamic programming  a systematic forward search algorithm such as AO  keeps track of the trajectory from the start state to each reachable state  and thus it can check whether the trajectory is feasible or violates a resource constraint  By pruning infeasible trajectories  a heuristic search algorithm can dramatically reduce the number of states that must be considered to find an optimal policy  This is particularly important in our domain where the discrete state space is huge  exponential in the number of goals   and yet the portion reachable from any initial state is relatively small  due to resource constraints      Problem Formulation and Background We start with a formal definition of the planning problem we are tackling  It is a special case of a hybrid state Markov decision process  and so we first define this model  Then we discuss how to include resource constraints and formalize over subscription planning in this model  Finally we review a class of dynamic programming algorithms for solving hybrid state MDPs  since some of these algorithmic techniques will be incorporated in the heuristic search algorithm we develop in Section        Hybrid State Markov Decision Process A hybrid state Markov decision process  or hybrid state MDP  is a factored Markov decision process that has both discrete and continuous state variables  We define it as a tuple  N  X  A  P  R   where N is a discrete state variable  X    X    X         Xd   is a set of continuous state variables  A is a set of actions  P is a stochastic state transition model  and R is a reward function  We describe these elements in more detail below  A hybrid state MDP is sometimes referred to as simply a hybrid MDP  The term hybrid does not refer to the dynamics of the model  which are discrete  Another term for a hybrid state MDP  which originates in the Markov chain literature  is a general state MDP  Although a hybrid state MDP can have multiple discrete variables  this plays no role in the algorithms described in this paper  and so  for notational convenience  we model the discrete component of the state space as a single variable N   Our focus is on the continuous component  We assume N the domain of each continuous variable Xi  X is a closed interval of the real line  and so X   i Xi is the hypercube over which the continuous variables are defined  The state set S of a hybrid state MDP is the set of all possible assignments of values to the state variables  In particular  a hybrid state s  S is a pair  n  x  where n  N is the value of the discrete variable  and x    xi   is a vector of values of the continuous variables  State transitions occur as a result of actions  and the process evolves according to Markovian state transition probabilities Pr s    s  a   where s    n  x  denotes the state before action a and s     n    x    denotes the state after action a  also called the arrival state  These probabilities can be decomposed into        Meuleau  Benazera  Brafman  Hansen   Mausam   the discrete marginals Pr n   n  x  a   For all  n  x  a    Pr n   n  x  a       R  the continuous conditionals Pr x   n  x  a  n     For all  n  x  a  n     x  X Pr x   n  x  a  n   dx       P  n  N  We assume the reward associated with a transition is a function of the arrival state only  and let Rn  x  denote the reward associated with a transition to state  n  x   More complex dependencies are possible  but this is sufficient for the goal based domain models we consider in this paper      Resource Constraints and Over Subscription Planning To model the rover planning problem  we consider a special type of MDP in which the objective is to optimize expected cumulative reward subject to resource constraints  We make the following assumptions   there is an initial allocation of one or more non replenishable resources   each action has some minimum positive consumption of at least one resource  and  once resources are exhausted  no further action can be taken  One way to model an MDP with resource constraints is to formulate it as a constrained MDP  a model that has been widely studied in the operations research community  Altman         In this model  each action a incurs a transition dependent resource cost  Cai  s  s     for each resource i  Given an initial allocation of resources and an initial state  linear programming is used to find the best feasible policy  which may be a randomized policy  Although a constrained MDP models resource consumption  it does not include resources in the state space  As a result  a policy cannot be conditioned upon resource availability  This is not a problem if resource consumption is either deterministic or unobservable  But it is not a good fit for the rover domain  in which resource consumption is stochastic and observable  and the rover should take different actions depending on current resource availability  We adopt a different approach to modeling resource constraints in which resources are included in the state description  Although this increases the size of the state space  it allows decisions to be made based on resource availability  and it allows a stochastic model of resource consumption  Since resources in the rover domain are continuous  we use the continuous variables of a hybrid state MDP to represent resources  Note that the duration of actions is one of the biggest sources of uncertainty in our rover problems  and we model time as one of the continuous resources  Resource constraints are represented in the form of executability constraints on actions  where An  x  denotes the set of actions executable in state  n  x   An action cannot be executed in a state that does not satisfy its minimum resource requirements  Having discussed how to incorporate resource consumption and resource constraints in a hybridstate MDP  we next discuss how to formalize over subscription planning  In our rover planning problem  scientists provide the planner with a set of goals they would like the rover to achieve  where each goal corresponds to a scientific task such as taking a picture of a rock or performing an analysis of a soil sample  The scientists also specify a utility or reward for each goal  Usually only a subset of these goals is feasible under resource constraints  and the problem is to find a feasible plan that maximizes expected utility  Over subscription planning for planetary exploration rovers has been considered by Smith        and van den Briel et al         for deterministic domains  We consider over subscription planning in stochastic domains  especially domains with stochastic resource consumption  This requires construction of conditional plans in which the selection of goals to achieve can change depending on resource availability  In over subscription planning  the utility associated with each goal can be achieved only once  no additional utility is achieved for repeating the task  Therefore  the discrete state must include a set of Boolean variables to keep track of the set of goals achieved so far by the rover  with one Boolean      HAO   variable for each goal  Keeping track of already achieved goals ensures a Markovian reward structure  since achievement of a goal is rewarded only if it was not achieved in the past  However  it also significantly increases the size of the discrete state space  Maintaining history information to ensure a Markovian reward structure is a simple example of planning with non Markovian rewards  Thiebaux  Gretton  Slaney  Price    Kabanza             Optimality Equation The rover planning problem we consider is a special case of a finite horizon hybrid state MDP in which termination occurs after an indefinite number of steps  The Bellman optimality equation for this problem takes the following form  Vn  x      Vn  x        when  n  x  is a terminal state  otherwise      Z X max Pr n    n  x  a  Pr x    n  x  a  n     Rn   x      Vn   x     dx     aAn  x   n  N       x   We define a terminal state as a state in which no actions are eligible to execute  that is  An  x      We use terminal states to model various conditions for plan termination  This includes the situation in which all goals have been achieved  the situation in which resources have been exhausted  and the situation in which an action results in some error condition that requires executing a safe sequence by the rover and terminating plan execution  In addition to terminal states  we assume an explicit initial state denoted  n    x     Assuming that resources are limited and non replenishable  and that every action consumes some resource  and the amount consumed is greater than or equal to some positive quantity c   plan execution will terminate after a finite number of steps  The maximum number of steps is bounded by the initial resource allocation divided by c  the minimal resource consumption per step  The actual number of steps is usually much less and indefinite  because resource consumption is stochastic and because the choice of action influences resource consumption  Because the number of steps it takes for a plan to terminate is bounded but indefinite  we call this a bounded horizon MDP in contrast to a finite horizon MDP  However  we note that any bounded horizon MDP can be converted to a finite horizon MDP by specifying a horizon that is equal to the maximum number of plan steps  and introducing a no op action that is taken in any terminal state  Note that there is usually a difference between the number of plan steps and the time a plan takes to execute  Since we model time as one of the continuous resources  the time it takes to execute a plan step is both state and action dependent  and stochastic  Given a hybrid state MDP with a set of terminal states and an initial state  n    x     the objective is to find a policy      N  X   A  that maximizes expected cumulative reward  specifically  an optimal policy has a value function that satisfies the optimality equation given by Equation      In our rover domain  cumulative reward is equal to the sum of rewards for the goals achieved before reaching a terminal state and there is no direct incentive to save resources  an optimal solution saves resources only if this allows achieving more goals  However  our framework is general enough to allow reasoning about both the cost and the availability of resources  For example  an incentive for conserving resources could be modeled by specifying a reward that is proportional to the amount of resources left unused upon entering the terminal state  Note that our framework allows reasoning about both the cost and availability of resources without needing to formulate this as a problem of multi objective optimization  and we stay in a standard decision theoretic framework      Dynamic Programming for Continuous State and Hybrid State MDPs Because the planning problem we consider is a finite horizon hybrid state MDP  it can be solved by any algorithm for solving finite horizon hybrid state MDPs  Most algorithms for solving hybridstate  and continuous state  MDPs rely on some form of approximation  A widely used approach is      Meuleau  Benazera  Brafman  Hansen   Mausam  Figure    Value function in the initial state of a simple rover problem  optimal expected return as a function of two continuous variables  time and energy remaining    to discretize the continuous state space into a finite number of grid points and solve the resulting finite state MDP using dynamic programming and interpolation  Rust        Munos   Moore         Another approach is parametric function approximation  a function associated with the dynamic programming problem  such as the value function or policy function  is approximated by a smooth function of k unknown parameters  In general  parametric function approximation is faster than grid based approximation  but has the drawback that it may fail to converge  or may converge to an incorrect solution  Parametric function approximation is used by other algorithms for solving continuous state MDPs besides dynamic programming  Reinforcement learning algorithms use artificial neural networks as function approximators  Bertsekas   Tsitsiklis         An approach to solving MDPs called approximate linear programming has been extended to allow continuous as well as discrete state variables  Kveton  Hauskrecht    Guestrin         We review another approach to solving hybrid state  or continuous state  MDPs that assumes the problem has special structure that can be exploited by the dynamic programming algorithm  R The structure assumed by this approach ensures that the convolution x  Pr x    n  x  a  n    Rn   x     Vn   x    dx  in Equation     can be computed exactly in finite time  and the value function computed by dynamic programming is piecewise constant or piecewise linear  The initial idea for this approach is due to the work of Boyan and Littman         who describe a class of MDPs called time dependent MDPs  in which transitions take place along a single  irreversible continuous dimension  They describe a dynamic programming algorithm for computing an exact piecewise linear value function when the transition probabilities are discrete and rewards are piecewise linear  Feng et al         extend this approach to continuous state spaces of more than one dimension  and consider MDPs with discrete transition probabilities and two types of reward models  piecewise constant and piecewise linear  Li and Littman        further extend the approach to allow transition probabilities that are piecewise constant  instead of discrete  although this extension requires some approximation in the dynamic programming algorithm  The problem structure exploited by these algorithms is characteristic of the Mars rover domain and other over subscription planning problems  Figure   shows the optimal value functions from the initial state of a typical Mars rover problem as a function of two continuous variables  the time and energy remaining  Bresina et al          The value functions feature a set of humps and plateaus  each of them representing a region of the state space where similar goals are pursued by the optimal policy  The sharpness of a hump or plateau reflects uncertainty about achieving the goal s   Constraints that impose minimal resource levels before attempting some actions introduce       HAO   sharp cuts in the regions  Plateau regions where the expected reward is nearly constant represent regions of the state space where the optimal policy is the same  and the probability distribution over future histories induced by this optimal policy is nearly constant  The structure in such a value function can be exploited by partitioning the continuous state space into a finite number of hyper rectangular regions   A region is a hyper rectangle if it is the Cartesian product of intervals at each dimension   In each hyper rectangle  the value function is either constant  for a piecewise constant function  or linear  for a piecewise linear function   The resolution of the hyper rectangular partitioning is adjusted to fit the value function  Large hyperrectangles are used to represent large plateaus  Small hyper rectangles are used to represent regions of the state space where a finer discretization of the value function is useful  such as the edges of plateaus and the curved hump where there is more time and energy available  A natural choice of data structures for rectangular partitioning of a continuous space is kd trees  Friedman  Bentley    Finkel         although other choices are possible  Figures   and    in Section     show value functions for the initial state of a simple rover planning problem  created by a piecewise constant partitioning of the continuous state space  The continuous state domains of the transition and reward functions are similarly partitioned into hyper rectangles  The reward function of each action has the same piecewise constant  or piecewiselinear  representation as the value function  The transition function partitions the state space into regions for which the set of outcomes of an action and the probability distribution over the set of outcomes are identical  Following Boyan and Littman         both relative and absolute transitions are supported  A relative outcome can be viewed as shifting a region by a constant   That is  for any two states x and y in the same region  the transition probabilitiesP r x   x  a  and P r y    y  a  are defined in term of the probability of   such that     x   x     y    y   An absolute outcome maps all states in a region to a single state  That is  for any two states x and y in the same region  P r x   x  a    P r x   y  a   We can view a relative outcome as a pair    p   where p is the probability of that outcome  and we can view an absolute outcome as a pair  x    p   This assumes there is only a finite number of non zero probabilities  i e   the probability distribution is discretized  which means that for any state and action  a finite set of states can be reached with non zero probability  This representation guarantees that a dynamic programming update of a piecewise constant value function results in another piecewise constant value function  Feng et al         show that for such transition functions and for any finite horizon  there exists a partition of the continuous space into hyper rectangles over which the optimal value function is piecewise constant or linear  The restriction to discrete transition functions is a strong one  and often means the transition function must be approximated  For example  rover power consumption is normally distributed  and thus must be discretized   Since the amount of power available must be non negative  our implementation truncates any negative part of the normal distribution and renormalizes   Any continuous transition function can be approximated by an appropriately fine discretization  and Feng et al         argue that this provides an attractive alternative to function approximation approaches in that it approximates the model but then solves the approximate model exactly  rather than finding an approximate value function for the original model   For this reason  we will sometimes refer to finding optimal policies and value functions  even when the model has been approximated   To avoid discretizing the transition function  Li and Littman        describe an algorithm that allows piecewise constant transition functions  in exchange for some approximation in the dynamic programming algorithm  Marecki et al        describe a different approach to this class of problems in which probability distributions over resource consumptions are represented with phase type distributions and a dynamic programming algorithm exploits this representation  Although we use the work of Feng et al         in our implementation  the heuristic search algorithm we develop in the next section could use any of these or some other approach to representing and computing value functions and policies for a hybrid state MDP        Meuleau  Benazera  Brafman  Hansen   Mausam     Heuristic Search in a Hybrid State Space In this section  we present the primary contribution of this paper  an approach to solving a special class of hybrid state MDPs using a novel generalization of the heuristic search algorithm AO   In particular  we describe a generalization of this algorithm for solving hybrid state MDPs in which the continuous variables represent monotonic and constrained resources and the acyclic plan found by the search algorithm allows branching on the availability of these resources  The motivation for using heuristic search is the potentially huge size of the state space  which makes dynamic programming infeasible  One reason for this size is the existence of continuous variables  But even if we only consider the discrete component of the state space  the size of the state space is exponential in the number of discrete variables  As is well known  AO  can be very effective in solving planning problems that have a large state space because it only considers states that are reachable from an initial state  and it uses an informative heuristic function to focus on states that are reachable in the course of executing a good plan  As a result  AO  can often find an optimal plan by exploring a small fraction of the entire state space  We begin this section with a review of the standard AO  algorithm  Then we consider how to generalize AO  to search in a hybrid state space and discuss the properties of the generalized algorithm  as well as its most efficient implementations      AO  Recall that AO  is an algorithm for AND OR graph search problems  Nilsson        Pearl         Such graphs arise in problems where there are choices  the OR components   and each choice can have multiple consequences  the AND component   as is the case in planning under uncertainty  Hansen and Zilberstein        show how AND OR graph search techniques can be used in solving MDPs  Following Nilsson        and Hansen and Zilberstein         we define an AND OR graph as a hypergraph  Instead of arcs that connect pairs of nodes as in an ordinary graph  a hypergraph has hyperarcs  or k connectors  that connect a node to a set of k successor nodes  When an MDP is represented by a hypergraph  each node corresponds to a state  the root node corresponds to the start state  and the leaf nodes correspond to terminal states  Thus we often use the word state to refer to the corresponding node in the hypergraph representing an MDP  A k connector corresponds to an action that transforms a state into one of k possible successor states  with a probability attached to each successor such that the probabilities sum to one  In this paper  we assume the AND OR graph is acyclic  which is consistent with our assumption that the underlying MDP has a bounded horizon  In AND OR graph search  a solution takes the form of an acyclic subgraph called a solution graph  which is defined as follows   the start node belongs to a solution graph   for every non terminal node in a solution graph  exactly one outgoing k connector  corresponding to an action  is part of the solution graph and each of its successor nodes also belongs to the solution graph   every directed path in the solution graph terminates at a terminal node  A solution graph that maximizes expected cumulative reward is found by solving the following system of equations      if s is a terminal state  otherwise   P   V   s               maxaA s  P   s S r s  s  a   R s     V  s      where V   s  denotes the expected value of an optimal solution for state s  and V  is called the optimal evaluation function  or value function in MDP terminology   Note that this is identical to      HAO   the optimality equation for hybrid state MDPs defined in Equation      if the latter is restricted to a discrete state space  In keeping with the convention in the literature on MDPs  we treat this as a value maximization problem even though AO  is usually formalized as solving a cost minimization problem  For state space search problems that are formalized as AND OR graphs  an optimal solution graph can be found using the heuristic search algorithm AO   Nilsson        Pearl         Like other heuristic search algorithms  the advantage of AO  over dynamic programming is that it can find an optimal solution for a particular starting state without evaluating all problem states  Therefore  a graph is not usually supplied explicitly to the search algorithm  An implicit graph  G  is specified implicitly by a start node or start state s and a successor function that generates the successors states for any state action pair  The search algorithm constructs an explicit graph  G    that initially consists only of the start state  A tip or leaf state of the explicit graph is said to be terminal if it is a goal state  or some other state in which no action can be taken   otherwise  it is said to be nonterminal  A nonterminal tip state can be expanded by adding to the explicit graph its outgoing k connectors  one for each action  and any successor states not already in the explicit graph  AO  solves a state space search problem by gradually building a solution graph  beginning from the start state  A partial solution graph is defined similarly to a solution graph  with the difference that tip states of a partial solution graph may be nonterminal states of the implicit AND OR graph  A partial solution graph is defined as follows   the start state belongs to a partial solution graph   for every non tip state in a partial solution graph  exactly one outgoing k connector  corresponding to an action  is part of the partial solution graph and each of its successor states also belongs to the partial solution graph   every directed path in a partial solution graph terminates at a tip state of the explicit graph  The value of a partial solution graph is defined similarly to the value of a solution graph  The difference is that if a tip state of a partial solution graph is nonterminal  it does not have a value that can be propagated backwards  Instead  we assume there is an admissible heuristic estimate H s  of the maximal value solution graph for state s  A heuristic evaluation function H is said to be admissible if H s   V   s  for every state s  We can recursively calculate an admissible heuristic estimate V  s  of the optimal value of any state s in the explicit graph as follows      if s is a terminal state  V  s    a nonterminal tip state     H s  if s is P       maxaA s  s  S P r s  s  a   R s     V  s    otherwise        The best partial solution graph can be determined at any time by propagating heuristic estimates from the tip states of the explicit graph to the start state  If we mark the action that maximizes the value of each state  the best partial solution graph can be determined by starting at the root of the graph and selecting the best  i e   marked  action for each reachable state  Table   outlines the AO  algorithm for finding an optimal solution graph in an acyclic AND OR graph  It interleaves forward expansion of the best partial solution with a value update step that updates estimated state values and the best partial solution  In the simplest version of AO   the values of the expanded state and all of its ancestor states in the explicit graph are updated  But in fact  the only ancestor states that need to be re evaluated are those from which the expanded state can be reached by taking marked actions  i e   by choosing the best action for each state   Thus  the parenthetical remark in step   b i of Table   indicates that a parent s  of state s is not added to Z unless both the estimated value of state s has changed and state s can be reached from state s  by choosing the best action for state s    AO  terminates when the policy expansion step does not       Meuleau  Benazera  Brafman  Hansen   Mausam     The explicit graph G  initially consists of the start state s       While the best solution graph has some nonterminal tip state   a  Expand best partial solution  Expand some nonterminal tip state s of the best partial solution graph and add any new successor states to G    For each new state s  added to G  by expanding s  if s  is a terminal state then V  s          else V  s       H s      b  Update state values and mark best actions  i  Create a set Z that contains the expanded state and all of its ancestors in the explicit graph along marked action arcs   I e   only include ancestor states from which the expanded state can be reached by following the current best solution   ii  Repeat the following steps until Z is empty  A  Remove from Z a state s such that no descendant of s in G  occurs in Z  P B  Set V  s     maxaA s  s  P r s   s  a   R s      V  s     and mark the best action for s   When determining the best action resolve ties arbitrarily  but give preference to the currently marked action    c  Identify the best solution graph and all nonterminal states on its fringe    Return an optimal solution graph  Table    AO  algorithm  find any nonterminal states on the fringe of the best solution graph  At this point  the best solution graph is an optimal solution  Following the literature on AND OR graph search  we have so far referred to the solution found by AO  as a solution graph  But in the following  when AO  is used to solve an MDP  we sometimes follow the literature on MDPs in referring to a solution as a policy  We also sometimes refer to it as a policy graph  to indicate that a policy is represented in the form of a graph      Hybrid State AO  We now consider how to generalize AO  to solve a bounded horizon hybrid state MDP  The challenge we face in applying AO  to this problem is the challenge of performing state space search in a hybrid state space  The solution we adopt is to search in an aggregate state space that is represented by an AND OR graph in which there is a node for each distinct value of the discrete component of the state  In other words  each node of the AND OR graph represents a region of the continuous state space in which the discrete value is the same  Given this partition of the continuous state space  we use AND OR graph search techniques to solve the MDP for those parts of the state space that are reachable from the start state under the best policy  However  AND OR graph search techniques must be modified in important ways to allow search in a hybrid state space that is represented in this way  In particular  there is no longer a correspondence between the nodes of the AND OR graph and individual states  Each node now corresponds to a continuous region of the state space  and different actions may be optimal for different hybrid states associated with the same search node  In the case of rover planning  for example  the best action is likely to depend on how much energy or time is remaining  and energy and time are continuous state variables  To address this problem and still find an optimal solution  we attach to each search node a set of functions  of the continuous variables  that make it possible to associate different values  heuristics  and actions with different hybrid states that map to the same search node  As before  the explicit       HAO   search graph consists of all nodes and edges of the AND OR graph that have been generated so far  and describes all the states that have been considered so far by the search algorithm  The difference is that we use a more complex state representation in which a set of continuous functions allows representation and reasoning about the continuous part of the state space associated with a search node  We begin by describing this more complex node data structure  and then we describe the HAO  algorithm        Data Structures Each node n of the explicit AND OR graph G  consists of the following   The value of the discrete state variable   Pointers to its parents and children in the explicit graph and the policy graph   Openn             the Open list  For each x  X  Openn  x  indicates whether  n  x  is on the frontier of the explicit graph  i e   generated but not yet expanded   Closedn             the Closed list  For each x  X  Closedn  x  indicates whether  n  x  is in the interior of the explicit graph  i e   already expanded  Note that  for all  n  x   Openn  x   Closedn  x       A state cannot be both open and closed   There can be parts of the continuous state space associated with a node that are neither open nor closed  Until the explicit graph contains a trajectory from the start state to a particular hybrid state  that hybrid state is not considered generated  even if the search node to which it corresponds has been generated  such states are neither open nor closed  In addition  only non terminal states can be open or closed  Note that we do not refer to open or closed nodes  instead  we refer to the hybrid states associated with nodes as being open or closed   Hn     the heuristic function  For each x  X  Hn  x  is a heuristic estimate of the optimal expected cumulative reward from state  n  x    Vn     the value function  For any open state  n  x   Vn  x    Hn  x   For any closed state  n  x   Vn  x  is obtained by backing up the values of its successor states  as in Equation       n     A  the policy  Note that it is defined for closed states only   Reachablen             For each x  X  Reachablen  x  indicates whether  n  x  is reachable by executing the current best policy beginning from the start state  n    x     We assume that these various continuous functions  which represent information about the hybrid states associated with a search node  partition the state space associated with a node into a discrete number of regions  and associate a distinct value or action with each region  Given such a partitioning  the HAO  algorithm expands and evaluates these regions of the hybrid state space  instead of individual hybrid states  The finiteness of the partition is important in order to ensure that the search frontier can be extended by a finite number of expansions  and to ensure that HAO  can terminate after a finite number of steps  In our implementation of HAO   described in Section    we use the piecewise constant partitioning of a continuous state space proposed by Feng et al          However  any method of discrete partitioning could be used  provided that the condition above holds  for example  Li and Littman        describe an alternative method of partitioning  Note that two forms of state space partitioning are used in our algorithm  First  the hybrid state space is partitioned into a finite number of regions  one for each discrete state  where each of these       Meuleau  Benazera  Brafman  Hansen   Mausam  regions corresponds to a node of the AND OR graph  Second  the continuous state space associated with a particular node is further partitioned into smaller regions based on a piecewise constant representation of a continuous function  such as the one used by Feng et al          In addition to this more complex representation of the nodes of an AND OR graph  our algorithm requires a more complex definition of the the best  partial  solution  In standard AO   the oneto one correspondence between nodes and individual states means that a solution or policy can be represented entirely by a graph  called the  partial  solution graph  in which a single action is associated with each node  In the HAO  algorithm  a continuum of states is associated with each node  and different actions may be optimal for different regions of the state space associated with a particular node  For the HAO  algorithm  a  partial  solution graph is a sub graph of the explicit graph that is defined as follows   the start node belongs to a solution graph   for every non tip node in a solution graph  one or more outgoing k connectors are part of the solution graph  one for each action that is optimal for some hybrid state associated with the node  and each of their successor nodes also belongs to the solution graph   every directed path in the solution graph terminates at a tip node of the explicit graph  The key difference in this definition is that there may be more than one optimal action associated with a node  since different actions may be optimal for different hybrid states associated with the node  A policy is represented not only by a solution graph  but by the continuous functions n     and Reachablen      In particular  a  partial  policy  specifies an action for each reachable region of the continuous state space  The best  partial  policy is the one that satisfies the following optimality equation  Vn  x      Vn  x     Hn  x  when  n  x  is a nonterminal open state      Z X   max Pr n    n  x  a  Pr x    n  x  a  n     Rn   x      Vn   x     dx     Vn  x     when  n  x  is a terminal state   aAn  x   n  N       x   Note that this optimality equation is only satisfied for regions of the state space that are reachable from the start state   n    x    by following an optimal policy        Algorithm Table   gives a high level summary of the HAO  algorithm  In outline  it is the same as the AO  algorithm  and consists of iteration of the same three steps  solution  or policy  expansion  use of dynamic programming to update the current value function and policy  and analysis of reachability to identify the frontier of the solution that is eligible for expansion  In detail  it is modified in several important ways to allow search of a hybrid state space  In the following  we discuss the modifications to each of these three steps  Policy expansion All nodes of the current solution graph are identified and one or more open regions associated with these nodes are selected for expansion  That is  one or more regions of the hybrid state space in the intersection of Open and Reachable is chosen for expansion  All actions applicable to the states in these open regions are simulated  and the results of these actions are added to the explicit graph  In some cases  this means adding a new node to the AND OR graph  In other cases  it simply involves marking one or more regions of the continuous state space associated with an existing node as open  More specifically  when an action leads to a new node  this node is added to the explicit graph  and all states corresponding to this node that are reachable from the expanded region s  after the action under consideration are marked as open  When an action leads to an      HAO      The explicit graph G  initially consists of the start node and corresponding start state  n    x     marked as open and reachable     While Reachablen  x   Openn  x  is non empty for some  n  x    a  Expand best partial solution  Expand one or more region s  of open states on the frontier of the explicit state space that is reachable by following the best partial policy  Add new successor states to G    In some cases  this requires adding a new node to the AND OR graph  In other cases  it simply involves marking one or more regions of the continuous state space associated with an existing node as open  States in the expanded region s  are marked as closed   b  Update state values and mark best actions  i  Create a set Z that contains the node s  associated with the just expanded regions of states and all ancestor nodes in the explicit graph along marked action arcs  ii  Decompose the part of the explicit AND OR graph that consists of nodes in Z into strongly connected components  iii  Repeat the following steps until Z is empty  A  Remove from Z a set of nodes such that     they all belong to the same connected component  and     no descendant of these nodes occurs in Z  B  For every node n in this connected component and for all states  n  x  in any expanded region of node n  set Vn  x       max aAn  x   X  Pr n    n  x  a   Z    Pr x    n  x  a  n     Rn   x      Vn   x     dx     x   n  N  and mark the best action   When determining the best action resolve ties arbitrarily  but give preference to the currently marked action   Repeat until there is no longer a change of value for any of these nodes   c  Identify the best solution graph and all nonterminal states on its frontier  This step updates Reachablen  x      Return an optimal policy  Table    HAO  algorithm  existing node  any region s  of Markov states in this node that is both reachable from the expanded region s  and not marked as closed  is marked open  Expanded regions of the state space are marked as closed  Thus  different regions associated with the same node can be opened and expanded at different times  This process is illustrated in Figure    In this figure  nodes corresponding to a distinct value for the discrete state are represented as rectangles  and circular connectors represent actions  For each node  we see how many distinct continuous regions exist  For each such region we see whether it is closed  C  or open  O   and whether it is reachable from the initial state  R  when executing the current best policy  OPT   For instance  in Figure   a   node At Start  has a single region marked closed and reachable  and node Lost has two regions  the smallest  open and reachable  and the largest  closed and unreachable  Dynamic programming As in standard AO   the value of any newly expanded node n must be updated by computing a Bellman backup based on the value functions of the children of n       Meuleau  Benazera  Brafman  Hansen   Mausam  At Start   At Loc   O  At Start  C  C  R  R  Navigate  Start  Loc    At Loc    OPT  C  R  Navigate  Start  Loc    OPT  R  Navigate  Loc   Loc    Lost O  C  Lost O  R  O  C  C  R  At Loc    Panoramic Camera  O   a  Before expansion  Panoramic Camera   b  After expansion  Figure    Expanding a region of the state space   a  Before expansion  The nodes At Start   At Loc   and Lost have been previously created  The unique region in At Loc   is the next region to be expanded   b  After expansion  The action Navigate Loc   Loc   that can be applied in the expanded region has been added to the graph  This action can lead either to the preexisting node Lost  or to the new node At Loc    The expanded region  in At Loc     as well as the continuous regions reachable from there  in Lost and At Loc     are highlighted in a dotted framed  Following expansion  the expanded region is closed  Discrete state At Loc   has been added to the graph and all its reachable regions are open  Additionally  new open regions have been added to node Lost   in the explicit graph  For each expanded region of the state space associated with node n  each action is evaluated  the best action is selected  and the corresponding continuous value function is associated with the region  The continuous state value function is computed by evaluating the continuous integral in Equation      We can use any method for computing this integral  In our implementation  we use the dynamic programming algorithm of Feng et al          As reviewed in Section      they show that the continuous integral over x  can be computed exactly  as long as the transition and reward functions satisfy certain conditions  Note that  with some hybrid state dynamic programming techniques such as Feng et al          dynamic programming backups may increase the number of pieces of the value function attached to the updated regions  Figure   a    Once the expanded regions of the continuous state space associated with a node n are reevaluated  the new values must be propagated backward in the explicit graph  The backward propagation stops at nodes where the value function is not modified  or at the root node  The standard AO  algorithm  summarized in Figure    assumes that the AND OR graph in which it searches is acyclic  There are extensions of AO  for searching in AND OR graphs that contain cycles  One line of research is concerned with how to find acyclic solutions in AND OR graphs that contain cycles  Jimenez   Torras         Another generalization of AO   called LAO   allows solutions to contain cycles or loops in order to specify policies for infinite horizon MDPs  Hansen   Zilberstein               HAO   At Start   At Loc   C C C  At Start  C  C  R  R  Navigate  Start  Loc    At Loc    OPT  C C C  R R R  Navigate  Loc   Loc    Lost O  O  C  OPT  C  R  At Loc   O  OPT  R R R  Navigate  Loc   Loc    OPT  Navigate  Start  Loc    At Loc    Panoramic Camera  O R   a  Dynamic programming  Lost O  O  C  R  R  R  C  Panoramic Camera   b  Reachability analysis  Figure    Dynamic programming and reachability analysis  Figure   continued    a  Dynamic programming  The optimal policy has been reevaluated and Navigate Loc   Loc   appears optimal in some continuous states of At Loc    Node At Loc   is represented with a finer partition of the continuous state space to illustrate the fact that the backup increased the number of pieces of the value function associated with the expanded region   b  Reachability analysis  The newly created region of At Loc   becomes reachable  as well as the regions of Lost that can be reached through Navigate Loc   Loc     Given our assumption that every action has positive resource consumption  there can be no loops in the state space of our problem because the resources available decrease at each step  But surprisingly  there can be loops in the AND OR graph  This is possible because the AND OR graph represents a projection of the state space onto a smaller space that consists of only the discrete component of the state  For example  it is possible for the rover to return to the same site it has visited before  The rover is not actually in the same state  since it has fewer resources available  But the AND OR graph represents a projection of the state space that does not include the continuous aspects of the state  such as resources  and this means the rover can visit a state that projects to the same node of the AND OR graph as a state it visited earlier  as shown in Figure    As a result  there can be loops in the AND OR graph  and even loops in the part of the AND OR graph that corresponds to a solution  But in a sense  these are phantom loops that can only appear in the projected state space  and not in the real state space  Nevertheless we must modify the dynamic programming  DP  algorithm to deal with these loops  Because there are no loops in the real state space  we know that the exact value function can be updated by a finite number of backups performed in the correct order  with one backup performed for any state that can be visited along a path from the start state to the expanded node s   But because multiple states can map to the same AND OR graph node  the continuous region of the state space associated with a particular node may need to be evaluated more than once  To identify the AND OR graph nodes that need to be evaluated more than once  we use the following two step algorithm        Meuleau  Benazera  Brafman  Hansen   Mausam  At Start   At Location   energy       At Location   energy       At Location    At Start  energy       At Location   energy       At Location   energy       At Location    Figure    Phantom loops in HAO   solid boxes represent Markov states  Dashed boxes represent search nodes  that is  the projection of Markov states on the discrete components  Arrows represent possible state transition  Bold arrows show an instance of phantom loop in the search space   First  we consider the part of the AND OR graph that consists of ancestor nodes of the just expanded node s   This is the set Z of nodes identified at the beginning of the DP step  We decompose this part of the graph into strongly connected components  The graph of strongly connected components is acyclic and can be used to prescribe the order of backups in almost the same way as in the standard AO  algorithm  In particular  the nodes in a particular component are not backed up until all nodes in its descendant components have been backed up  Note that in the case of an acyclic graph  every strongly connected component has a single node  It is only possible for a connected component to have more than one node if there are loops in the AND OR graph  If there are loops in the AND OR graph  the primary change in the DP step of the algorithm occurs when it is time to perform backups on the nodes in a connected component with more than one node  In this case  all nodes in the connected component are evaluated  Then  they are repeatedly re evaluated until the value functions of these nodes converge  that is  until there is no change in the values of any of the nodes  Because there are no loops in the real state space  convergence is guaranteed to occur after a finite number of steps  Typically  it occurs after a very small number of steps  An advantage of decomposing the AND OR graph into connected components is that it identifies loops and localizes their effect to a small number of nodes  In experiments in our test domain  most nodes of the graph need to be evaluated just once during the DP step  and only a small number of nodes  and often none  need to be evaluated more than once  Note that decomposition of the nodes in Z into connected components is a method for improving the efficiency of the dynamic programming step  and is not required for its correctness  The alternative of repeatedly updating all nodes in Z until all their values converge is also correct  although it is likely to result in many useless updates of already converged nodes  Analysis of reachability Change in the value function can lead to change in the optimal policy  and  thus  to change in which states are visited by the best policy  This  in turn  can affect which open regions of the state space are eligible to be expanded  In this final step  HAO  identifies the best  partial  policy and recomputes Reachablen for all nodes and states in the explicit graph  as follows  see Figure   b    For each node n in the best  partial  solution graph  consider each of its parents n  in the solution graph  and all the actions a that can lead from one of the parents to n  Then Reachablen  x  is the support of Pn  x   where X Z Pn  x    Reachablen   x    Pr n   n    x    a  Pr x   n    x    a  n dx         n   a n  X       HAO   that is  Reachablen  x     x  X   Pn  x        In Equation      n is the set of pairs  n    a  where a is the best action in n  for some reachable resource level  n     n    a   N  A   x  X  Pn   x       n   x    a  Pr n   n    x  a         It is clear that we can restrict our attention to state action pairs in n   only  By performing this reachability analysis  HAO  identifies the frontier of the state space that is eligible for expansion  HAO  terminates when this frontier is empty  that is  when it does not find any hybrid states in the intersection of Reachable and Open      Convergence and Error Bounds We next consider some of the theoretical properties of HAO   First  under reasonable assumptions  we prove that HAO  converges to an optimal policy after a finite number of steps  Then we discuss how to use HAO  to find sub optimal policies with error bounds  The proof of convergence after a finite number of steps depends  among other things  on the assumption that a hybrid state MDP has a finite branching factor  In our implementation  this means that for any region of the state space that can be represented by a hyper rectangle  the set of successor regions after an action can be represented by a finite set of hyper rectangles  From this assumption and the assumption that the number of actions is finite  it follows that for every assignment n to the discrete variables  the set  x  n  x is reachable from the initial state using some fixed sequence of actions  is the union of a finite number of open or closed hyper rectangles  This assumption can be viewed as a generalization of the assumption of a finite branching factor in a discrete AND OR graph upon which the finite convergence proof of AO  depends  Theorem   If the heuristic functions Hn are admissible  optimistic   all actions have positive resource consumptions  both continuous backups and action application are computable exactly in finite time  and the branching factor is finite  then     At each step of HAO   Vn  x  is an upper bound on the optimal expected return in  n  x   for all  n  x  expanded by HAO      HAO  terminates after a finite number of steps     After termination  Vn  x  is equal to the optimal expected return in  n  x   for all  n  x  reachable under an optimal policy  i e   Reachablen  x       Proof      The proof is by induction  Every state  n  x  is assigned an initial heuristic estimate  and Vn  x    Hn  x   Vn  x  by the admissibility of the heuristic evaluation function  We make the inductive hypothesis that at some point in the algorithm  Vn  x   Vn  x  for every state  n  x   If a backup is performed for any state  n  x       Z X Vn  x    max Pr n    n  x  a  Pr x    n  x  a  n     Rn   x      Vn   x     dx  aAn  x   x   n  N      max aAn  x   X n  N     Z  Pr n   n  x  a            Pr x   n  x  a  n    Rn   x     x     Vn  x    where the last equality restates the Bellman optimality equation       Vn   x     dx       Meuleau  Benazera  Brafman  Hansen   Mausam      Because each action has positive  bounded from below  resource consumption  and resources are finite and non replenishable  the complete implicit AND OR graph must be finite  For the same reason  this graph can be turned into a finite graph without loops  Along any directed loop in this graph  the amount of maximal available resources must decrease by some   which is a positive lower bound on the amount of resources consumed by an action  Each node in this graph may be expanded a number of times that is bounded by the number of its ancestor   Each time a new ancestor is discovered  it may lead to an update in the set of reachable regions for this node   Moreover  finite branching factor implies that the number of regions considered within each node is bounded  because there are finite ways of reaching this node  each of which contributes a finite number of hyper rectangles   Thus  overall  the number of regions considered is finite  and the processing required for each region expansion is finite  because action application and backups are computed in finite time   This leads to the desired conclusion      The search algorithm terminates when the policy for the start state  n    x    is complete  that is  when it does not lead to any unexpanded states  For every state  n  x  that is reachable by following this policy  it is contradictory to suppose Vn  x    Vn  x  since that implies a complete policy that is better than optimal  By the Bellman optimality equation of Equation      we know that Vn  x   Vn  x  for every state in this complete policy  Therefore  Vn  x    Vn  x     HAO  not only converges to an optimal solution  stopping the algorithm early allows a flexible trade off between solution quality and computation time  If we assume that  in each state  there is a done action that terminates execution with zero reward  in a rover problem  we would then start a safe sequence   then we can evaluate the current policy at each step of the algorithm by assuming that execution ends each time we reach a leaf of the policy graph  Under this assumption  the error of the current policy at each step of the algorithm can be bounded  We show this by using a decomposition of the value function described by Chakrabarti et al        and Hansen and Zilberstein         We note that at any point in the algorithm  the value function can be decomposed into two parts  gn  x  and hn  x   such that gn  x      gn  x        when  n  x  is an open state  on the fringe of the greedy policy  otherwise  Z X    Pr n   n  x  a   Pr x    n  x  a   n     Rn  x    gn   x     dx          x   n  N  and hn  x     Hn  x  when  n  x  is an open state  on the fringe of the greedy policy  otherwise  Z X hn  x    Pr n    n  x  a   Pr x    n  x  a   n    hn   x   dx        n  N  x   where a is the action that maximizes the right hand side of Equation      Note that Vn  x    gn  x    hn  x   We use this decomposition of the value function to bound the error of the best policy found so far  as follows  Theorem   At each step of the HAO  algorithm  the error of the current best policy is bounded by hn   x     Proof  For any state  n  x  in the explicit search space  a lower bound on its optimal value is given by gn  x   which is the value that can be achieved by the current policy when the done action is executed at all fringe states  and an upper bound is given by Vn  x    gn  x    hn  x   as established in Theorem    It follows that hn   x    bounds the difference between the optimal value and the current admissible value of any state  n  x   including the initial state  n    x      Note that the error bound for the initial state is hn   x      Hn   x    at the start of the algorithm  it decreases with the progress of the algorithm  and hn   x        when HAO  converges to an optimal solution       HAO       Heuristic Function The heuristic function Hn focuses the search on reachable states that are most likely to be useful  The more informative the heuristic  the more scalable the search algorithm  In our implementation of HAO  for the rover planning problem  which is described in detail in the next section  we used the simple admissible heuristic function which assigns to each node the sum of all rewards associated with goals that have not been achieved so far  Note that this heuristic function only depends on the discrete component of the state  and not on the continuous variables  that is  the function Hn  x  is constant over all values of x  It is obvious that this heuristic is admissible  since it represents the maximum additional reward that could be achieved by continuing plan execution  Although it is not obvious that a heuristic this simple could be useful  the experimental results we present in Section   show that it is  We considered an additional  more informed heuristic function that solved a relaxed  suitably discretized  version of the planning problem  However  taking into account the time required to compute this heuristic estimate  the simpler heuristic performed better      Expansion Policy HAO  works correctly and converges to an optimal solution no matter which continuous region s  of which node s  are expanded in each iteration  step   a   But the quality of the solution may improve more quickly by using some heuristics to choose which region s  on the fringe to expand next  One simple strategy is to select a node and expand all continuous regions of this node that are open and reachable  In a preliminary implementation  we expanded  the open regions of  the node that is most likely to be reached using the current policy  Changes in the value of these states will have the greatest effect on the value of earlier nodes  Implementing this strategy requires performing the additional work involved in maintaining the probability associated with each state  If such probabilities are available  one could also focus on expanding the most promising node  that is  the node where the integral of Hn  x  times the probability over all values of x is the highest  as described by Mausam  Benazera  Brafman  Meuleau  and Hansen         Hansen and Zilberstein        observed that  in the case of LAO   the algorithm is more efficient if we expand several nodes in the fringe before performing dynamic programming in the explicit graph  This is because the cost of performing the update of a node largely dominates the cost of expanding a node  If we expand only one node of the fringe at each iteration  we might have to perform more DP backups than if we expand several nodes with common ancestors before proceeding to DP  In the limit  we might want to expand all nodes of the fringe at each algorithm iteration  Indeed  this variant of LAO  proved the most efficient  Hansen   Zilberstein         In the case of LAO   updates are expensive because of the loops in the implicit graph  In HAO   the update of a region induces a call to the hybrid dynamic programming module for each open region of the node  Therefore  the same technique is likely to produce the same benefit  Pursuing this idea  we allowed our algorithm to expand all nodes in the fringe and all their descendants up to a fixed depth at each iteration  We defined a parameter  called the expansion horizon and denoted k  to represent  loosely speaking  the number of times the whole fringe is expanded at each iteration  When k      HAO  expands all open and reachable regions of all nodes in the fringe before recomputing the optimal policy  When k      it expands all regions in the fringe and all their children before updating the policy  At k     it also consider the grandchildren of regions in the fringe  and so on  When k tends to infinity  the algorithm essentially performs an exhaustive search  it first expands the graph of all reachable nodes  then performs one pass of  hybrid  dynamic programming in this graph to determine the optimal policy  By balancing node expansion and update  the expansion horizon allows tuning the algorithm behavior from an exhaustive search to a more traditional heuristic search  Our experiments showed that a value of k between   and    is optimal to solve our hardest benchmark problems  see section           Meuleau  Benazera  Brafman  Hansen   Mausam  Start  ObsPt   Unsafe  C  Obs Pt   Featureless C   W  W   W   Obs Pt   ObsPt   Audience  Demo  label    Waypoint Name    Rock   IP   CHAMP  ObsPt  Far    Science Cam   Figure    The K  rover  top left  was developed at the Jet Propulsion Laboratory and NASA Ames Research Center as a prototype for the MER rovers  It is used to test advanced rover software  including automated planners of the rovers activities  Right  topological map of the      IS demo problem  Arrows labeled IP   CHAMP represent the opportunity to deploy the arm against a rock  instrument placement  and take a picture of it with the CHAMP Camera  Arrows labeled Science Cam represent the opportunity to take a remote picture of a rock with the Science Camera       Updating Multiple Regions The expansion policies described above are based on expanding all open regions of one or several nodes simultaneously  They allow leveraging hybrid state dynamic programming techniques such as those of Feng et al         and Li and Littman         These techniques may compute in a single iteration piecewise constant and linear value functions that cover a large range of continuous states  possibly the whole space of possible values  In particular  they can back up in one iteration all continuous states included between given bounds  Therefore  when several open regions of the same node are expanded at the same iteration of HAO   we can update all of them simultaneously by backing up a subset of continuous states that includes all these regions  For instance  one may record lower bounds and upper bounds on each continuous variable over the expanded regions  and then compute a value function that covers the hyper rectangle between these bounds  This modification of the algorithm does not impact convergence  As long as the value of all expanded regions is computed  the convergence proof holds  However  execution time may be adversely affected if the expanded regions are a proper subset of the region of continuous states that is       HAO    a  Value function Vn     for the initial node  The first plateau corresponds to analyzing R   the second plateau to analyzing R   and the third plateau to analyzing both R  and R     b  The policy n     for the starting node shows the partitions of the resource space where different actions are optimal  Dark  no action  Grey  navigation to R   Light  analysis of R    Figure     a  Optimal value function for the initial state of the simple rover problem over all possible values for the continuous resources  time and energy remaining   The value function is partitioned into      pieces   b  Optimal policy for the same set of states   backed up  In that case  the values of states that are not open or not reachable is uselessly computed  which deviates from a pure heuristic search algorithm  However  this modification may also be beneficial because it avoids some redundant computation  Hybrid state dynamic programming techniques manipulate pieces of value functions  Thus  if several expanded regions are included in the same piece of the value function  their value is computed only once  In practice  this benefit may outweigh the cost of evaluating useless regions  Moreover  cost is further reduced by storing the value functions associated with each node of the graph  so that computed values of irrelevant regions are saved in case these regions become eligible for expansion  i e   open and reachable  later  Thus  this variant of HAO  fully exploits hybrid state dynamic programming techniques      Experimental Evaluation In this section  we describe the performance of HAO  in solving planning problems for a simulated planetary exploration rover with two monotonic and continuous valued resources  time and battery power  Section     uses a simple toy example of this problem to illustrate the basic steps of the HAO  algorithm  Section     tests the performance of the algorithm using a realistic  real size NASA simulation of a rover and analyzes the results of the experiments  The simulation uses a model of the K  rover  see Figure    developed for the Intelligent Systems  IS  demo at NASA Ames Research Center in October       Pedersen et al          This is a complex real size model of the K  rover that uses command names understandable by the rovers execution language  so that the plans produced by our algorithm can be directly executed by the rover  For the experiments reported in Section      we did not simplify this NASA simulation model in any way        Meuleau  Benazera  Brafman  Hansen   Mausam  Figure    First iteration of HAO  on the toy problem  The explicit graph is marked by dim edges and the solution graph is marked by thick edges  Tip nodes         and   are shown with constant heuristic functions and expanded nodes      and   are shown with backed up value functions   In the planning problem we consider  an autonomous rover must navigate in a planar graph representing its surroundings and the authorized navigation paths  and schedule observations to be performed on different rocks situated at different locations  Only a subset of its observational goals can be achieved in a single run due to limited resources  Therefore  this is an oversubscribed planning problem  It is also a problem of planning under uncertainty since each action has uncertain positive resource consumptions and a probability of failing  A significant amount of uncertainty in the domain comes from the tracking mechanism used by the rover  Tracking is the process by which the rover recognizes a rock based on certain features in its camera image that are associated with the rock  During mission operations  a problem instance containing a fixed set of locations  paths  and rocks is built from the last panoramic camera image sent by the rover  Each logical rock in this problem instance corresponds to a real rock  and the rover must associate the two on the basis of features that can be detected by its instruments  including its camera  As the rover moves and its camera image changes  the rover must keep track of how those features of the image evolve  This process is uncertain and subject to faults that result in losing track of a rock  In practice  tracking is modeled in the following way   In order to perform a measurement on a rock  the rover must be tracking this rock   To navigate along a path  it must be tracking one of the rocks that enables following this path  The set of rocks that enable each path is part of the problem definition given to the planner   The decision to start tracking a rock must be made before the rover begins to move  Once the rover starts moving  it may keep track of a rock already being tracked or voluntarily stop tracking it  but it cannot acquire a new rock that was not tracked initially        HAO   Figure    Second iteration of HAO  on the toy problem   The rover may randomly lose track of some rocks while navigating along a path  The probability of losing track of a rock depends on the rock and the path followed  it is part of the problem definition given to the planner   There is no way to reacquire a rock whose track has been lost  intentionally or by accident   The number of rocks tracked strongly influences the duration and resource consumption of navigate actions  The higher the number of rocks tracked  the more costly it is to navigate along a path  This is because the rover has to stop regularly to check and record the aspect of each rock being tracked  This creates an incentive to limit the number of rocks tracked by the rover given the set of goals it has chosen and the path it intends to follow  So  the rover initially selects a set of rocks to track and tries to keep this set as small as possible given its goals  Once it starts moving  it may lose track of some rocks  and this may cause it to reconsider the set of goals it will pursue and the route to get to the corresponding rocks  It can also purposely stop tracking a rock when this is no longer necessary given the goals that are left to achieve  Our implementation of HAO  uses the dynamic programming algorithm developed by Feng et al         and summarized in Section     in order to perform backups in a hybrid state space  and partitions the continuous state space associated with a node into piecewise constant regions  It uses multiple region updates as described in Section      an upper bound on the each resource over all expanded regions is computed  and all states included between these bounds and the minimal possible resource levels are updated  In our experiments  we use the variant of the HAO  algorithm described in Section      where a parameter k sets the number of times the whole fringe is expanded at each iteration of HAO   this allows the behavior of the algorithm to be tuned from an exhaustive search to a heuristic search  We used an expansion horizon of k     for the simple example in Section     and a default expansion horizon of k     for the larger examples in Section      Section       describes experiments with different expansion horizons        Meuleau  Benazera  Brafman  Hansen   Mausam  Figure    Third iteration of HAO  on the toy problem  Our implementation of HAO  uses the simple heuristic described in Section      augmented with a small amount of domain knowledge  The value Hn  x  of a state  n  x  is essentially equal to the sum of the utilities of all goals not yet achieved in n  However  if the rover has already moved and a certain rock is not being tracked in state n  then all goals requiring this rock to be tracked are not included in the sum  This reflects the fact that  once the rover has moved  it cannot start tracking a rock any more  and thus all goals that require this rock to be tracked are unreachable  The resulting heuristic is admissible  i e   it never underestimates the value of a state   and it is straightforward to compute  Note that it does not depend on the current resource levels  so that the functions Hn  x  are constant over all values of x      Example We begin with a very simple example of the rover planning problem in order to illustrate the steps of the algorithm  We solve this example using the same implementation of HAO  that we use to solve the more realistic examples considered in Section      In this example  the targets are two rocks  R  and R   positioned at locations L  and L   respectively  The rovers initial location is L   and there is a direct path between L  and L   Analyzing rock R  yields a reward of    and analyzing rock R  yields a reward of     The rovers action set is simplified  Notably  it features a single action Pic Rx  to represents all the steps of analyzing rock Rx  and the stop tracking actions have been removed  Figure   shows the optimal value function and the optimal policy found by HAO  for the starting discrete state  and resources ranging over the whole space of possible values  Figures      and   show the step by step process by which HAO  solves this problem  Using an expansion horizon of k      HAO  solves this problem in three iterations  as follows   Iteration    As shown in Figure    HAO  expands nodes      and   and computes a heuristic function for the new tip nodes         and    The backup step yields value function estimates for nodes      and    HAO  then identifies the best solution graph and a new fringe node          HAO    a       pieces    b      pieces    c      pieces   Figure     Optimal value functions for the initial state of the simple rover problem with increasing initial resource levels  from left to right   The optimal return appears as a three dimensional function carved into the reachable space of the heuristic function  problem name Rover  Rover  Rover  Rover   rover locations           paths  goals  fluents  actions                                                  discrete states  approx                                       reachable discrete states                       explicit graph  optimal policy  longest branch                                                Table    Size of benchmark rover problems   Iteration    As shown in Figure    HAO  expands nodes         and     starting with previous fringe node    and computes heuristic functions for the new tip nodes        and     The heuristic value for node    is zero because  in this state  the rover has lost track of R  and has already analyzed R   The backup step improves the accuracy of the value function in several nodes  Node    is the only new fringe node since    is a terminal node   Iteration    As shown in Figure    HAO  expands node    and node     The search ends after this iteration because there is no more open node in the optimal solution graph  For comparison  Figure    shows how the value function found by HAO  varies with different initial resource levels  In these figures  unreachable states are assigned a large constant heuristic value  so that the value function for reachable states appears as carved in the plateau of the heuristic      Performance Now  we describe HAO s performance in solving four much larger rover planning problems using the NASA simulation model  The characteristics of these problems are displayed in Tables    Columns two to six show the size of the problems in terms of rover locations  paths  and goals  They also show the total number of fluents  Boolean state variables  and actions in each problem  Columns seven to ten report on the size of the discrete state space  The total number of discrete states is two raised to the power of the number of fluents  Although this is a huge state space  only a limited number of states can be reached from the start state  depending on the initial resource levels  The eighth column in Table   shows the number of reachable discrete states if the initial time and energy levels are set to their maximum value   The maximum initial resource levels are based on the scenario of the      IS demo and represent several hours of rover activity   It shows that simple reachability      Meuleau  Benazera  Brafman  Hansen   Mausam                              reachable created expanded in optimal policy      Number of discrete states      Number of discrete states       reachable created expanded in optimal policy                                                Initial energy                                        Initial time                                                       a  Rover        reachable created expanded in optimal policy        Number of discrete states  Number of discrete states                                                        Initial energy                                         reachable created expanded in optimal policy                           Initial time   b  Rover         reachable created expanded in optimal policy         Number of discrete states  Number of discrete states                                                      Initial energy                                            reachable created expanded in optimal policy                     Initial time   c  Rover         reachable created expanded in optimal policy         Number of discrete states  Number of discrete states                                                      Initial energy                                            reachable created expanded in optimal policy                     Initial time   d  Rover  Figure     Number of nodes created and expanded by HAO  vs  number of reachable discrete states  The graphs in the left column are obtained by fixing the initial time to its maximum value and varying the initial energy  The graphs in the right column are obtained by fixing the initial energy to its maximum value and varying the initial time  Results obtained with k           HAO   analysis based on resource availability makes a huge difference  This is partly due to the fact that our planning domain  which is very close to the K  execution language  does not allow many fluents to be true simultaneously  Columns nine and ten show the number of discrete states in the explicit graph and in the optimal policy  More precisely  the former is the number of nodes created by HAO   that is  a subset of the reachable discrete states  The number of reachable discrete states  and thus the size of the graph to explore  may seem small compared to other discrete combinatorial problems solved by AI techniques  But each iteration  a continuous approximation of the two dimensional backup is necessary to evaluate the hybrid state space associated with the graph  Finally  the last column of Table   shows the length of the longest branch in the optimal policy when the initial resource levels are set to their maximum value  The largest of the four instances  that is  Rover   is exactly the problem of the October      IS demo  This is considered a very large rover problem  For example  it is much larger than the problems faced by the MER rovers that never visit more than one rock in a single planning cycle        Efficiency of Pruning In a first set of simulations  we try to evaluate the efficiency of heuristic pruning in HAO   that is  the portion of the discrete search space that is spared from exploration through the use of admissible heuristics  For this purpose  we compare the number of discrete states that are reachable for a given resource level with the number of nodes created and expanded by HAO   We also consider the number of nodes in the optimal policy found by the algorithm  Results for the four benchmark problems are presented in Figure     These curves are obtained by fixing one resource to its maximum possible value and varying the other from   to its maximum  Therefore  they represent problems where mostly one resource is constraining  These result show  notably  that a single resource is enough to constrain the reachability of the state space significantly  Not surprisingly  problems become larger as the initial resources increase  because more discrete states become reachable  Despite the simplicity of the heuristic used  HAO  is able to by pass a significant part of the search space  Moreover  the bigger the problem  the more leverage the algorithm can take from the simple heuristic  These results are quite encouraging  but the number of nodes created and expanded does not always reflect search time  Therefore  we examine the time it takes for HAO  to produce solutions        Search Time Figure    shows HAO  search time for the same set of experiments  These curves do not exhibit the same monotonicity and  instead  appear to show a significant amount of noise  It is surprising that search time does not always increase with an increase in the initial levels of resource  although the search space is bigger  This shows that search complexity does not depend on the size of the search space alone  Other factors must explain complexity peaks as observed in Figure     Because the number of nodes created and expanded by the algorithm does not contain such noise  the reason for the peaks of computation time must be the time spent in dynamic programming backups  Moreover  search time appears closely related to the complexity of the optimal policy  Figure    shows the number of nodes and branches in the policy found by the algorithm  as well as the number of goals pursued by this policy  It shows that   i  in some cases  increasing the initial resource level eliminates the need for branching and reduces the size of the optimal solution   ii  the size of the optimal policy and  secondarily  its number of branches  explains most of the peaks in the search time curves  Therefore  the question is  why does a large solution graph induce a long time spent in backups  There are two possible answers to this question  because the backups take longer and or because more backups are performed  The first explanation is pretty intuitive  When the policy graph contains many branches leading to different combinations of goals  the value functions contain many humps and plateaus  and therefore many pieces  which impacts the complexity of dynamic programming backups  However  we do not have at this time any empirical evidence to                                      Search time  s   Search time  s   Meuleau  Benazera  Brafman  Hansen   Mausam                                                          Initial energy                                        Initial time                         Initial time                                                  Search time  s   Search time  s    a  Rover                                                                         Initial energy                                                  Search time  s   Search time  s    b  Rover                                                                        Initial energy                                        Initial time                                  Initial time                                          Search time  s   Search time  s    c  Rover                                                         Initial energy                      d  Rover  Figure     HAO  search time  The graphs in the left column are obtained by fixing the initial time to its maximum value  and the graphs in the right column are obtained by fixing the initial energy to its maximum  Results obtained with k            HAO   confirm this hypothesis  Conversely  we observe that the peak of Figure    comes with an increase of the number of backups  More work is required to explain this        Expansion Horizon The results of Section       show that HAO  can leverage even a simple admissible heuristic to prune a large portion of the search space  But it does not necessarily follow that HAO  can outperform an exhaustive search algorithm that creates a graph of all reachable states  and then executes one pass of dynamic programming in this graph to find the optimal policy  Although HAO  expands a smaller graph than such an exhaustive search  it must evaluate the graph more often  In Section      we introduced a parameter k for expansion horizon in order to allow adjustment of a trade off between the time spent expanding nodes and the time spent evaluating nodes  We now study the influence of this parameter on the algorithm  Figure    shows the number of nodes created and expanded by HAO  as a function of the expansion horizon for the four benchmark problem instances  Not surprisingly  the algorithm creates and expands more nodes as the expansion horizon increases  Essentially  it behaves more like an exhaustive search as k is increased  For the two smallest problem instances  and for large enough values of k  the number of visited states levels off when the total number of reachable states is reached  For the two largest problem instances  we had to interrupt the experiments once k reached    because search time became too long  Figure    shows the effect of the expansion horizon on the search time of HAO   For the smallest problem instance  Rover    HAO  does not have a clear advantage over an exhaustive search  with k        even though it explores fewer nodes  But for the three larger problem instances  HAO  has a clear advantage  For the Rover  problem instance  the search time of HAO  levels off after k       indicating the limit of reachable states has been reached  However  the duration of such an exhaustive search is several times longer than for HAO  with smaller settings of k  The benefits of HAO  are clearer for the two largest problem instances  As k is increased  the algorithm is quickly overwhelmed by the combinatorial explosion in the size of the search space  and simulations eventually need to be interrupted because search time becomes too long  For these same problem instances and smaller settings of k  HAO  is able to efficiently find optimal solutions  Overall  our results show that there is a clear benefit to using admissible heuristics to prune the search space  although the expansion horizon must be adjusted appropriately in order for HAO  to achieve a favorable trade off between node expansion time and node evaluation time      Conclusion We introduced a heuristic search approach to finding optimal conditional plans in domains characterized by continuous state variables that represent limited  consumable resources  The HAO  algorithm is a variant of the AO  algorithm that  to the best of our knowledge  is the first algorithm to deal with all of the following  limited continuous resources  uncertain action outcomes  and over subscription planning  We tested HAO  in a realistic NASA simulation of a planetary rover  a complex domain of practical importance  and our results demonstrate its effectiveness in solving problems that are too large to be solved by the straightforward application of dynamic programming  It is effective because heuristic search can exploit resource constraints  as well as an admissible heuristic  in order to limit the reachable state space  In our implementation  the HAO  algorithm is integrated with the dynamic programming algorithm of Feng et al          However HAO  can be integrated with other dynamic programming algorithms for solving hybrid state MDPs  The Feng et al  algorithm finds optimal policies under the limiting assumptions that transition probabilities are discrete  and rewards are either piecewiseconstant or piecewise linear  More recently developed dynamic programming algorithms for hybridstate MDPs make less restrictive assumptions  and also have the potential to improve computational       Meuleau  Benazera  Brafman  Hansen   Mausam                                                   Initial energy                           Nodes Branches Goals                                                Initial time        Number of branches and goals         Number of nodes     Number of nodes     Nodes Branches Goals  Number of branches and goals                a  Rover                                                    Initial energy                           Nodes Branches Goals                                                Initial time        Number of branches and goals         Number of nodes  Nodes Branches Goals     Number of nodes    Number of branches and goals                b  Rover                                                    Initial energy                           Nodes Branches Goals                                                Initial time        Number of branches and goals         Number of nodes  Nodes Branches Goals     Number of nodes    Number of branches and goals                c  Rover                                                    Initial energy                           Nodes Branches Goals                                                Initial time        Number of branches and goals          Number of nodes  Nodes Branches Goals     Number of nodes    Number of branches and goals                 d  Rover  Figure     Complexity of the optimal policy  number of nodes  branches  and goals in the optimal policy in the same setting as Figure           HAO        Number of discrete states      Number of discrete states        created expanded                                        Expansion horizon                             created expanded                   a  Rover         Number of discrete states  Number of discrete states      created expanded                                           b  Rover         created expanded               Expansion horizon                                               Expansion horizon          c  Rover               Expansion horizon       d  Rover   Figure     Influence of the expansion horizon on the number of nodes visited by the algorithm  efficiency  Li   Littman        Marecki et al          Integrating HAO  with one of these algorithms could improve performance further  There are several other interesting directions in which this work could be extended  In developing HAO   we made the assumptions that every action consumes some resource and resources are non replenishable  Without these assumptions  the same state could be revisited and an optimal plan could have loops as well as branches  Generalizing our approach to allow plans with loops  which seems necessary to handle replenishable resources  requires generalizing the heuristic search algorithm LAO  to solve hybrid MDPs  Hansen   Zilberstein         Another possible extension is to allow continuous action variables in addition to continuous state variables  Finally  our heuristic search approach could be combined with other approaches to improving scalability  such as hierarchical decomposition  Meuleau   Brafman         This would allow it to handle the even larger state spaces that result when the number of goals in an over subscription planning problem is increased  Acknowledgments This work was funded by the NASA Intelligent Systems program  grant NRA         Eric Hansen was supported in part by a NASA Summer Faculty Fellowship and by funding from the Mississippi Space Grant Consortium  This work was performed while Emmanuel Benazera was working at NASA Ames Research Center and Ronen Brafman was visiting NASA Ames Research Center  both as consultants for the Research Institute for Advanced Computer Science  Ronen Brafman was supported in part by the Lynn and William Frankel Center for Computer Science  the Paul Ivanier Center for Robotics and Production Management  and ISF grant          Nicolas Meuleau is a consultant of Carnegie Mellon University at NASA Ames Research Center        Meuleau  Benazera  Brafman  Hansen   Mausam                          Search time  s   Search time  s                                                               Expansion horizon                    a  Rover                   Search time  s         Search time  s        b  Rover                                    Expansion horizon                                      Expansion horizon          c  Rover               Expansion horizon       d  Rover   Figure     Influence of the expansion horizon on overall search time   
