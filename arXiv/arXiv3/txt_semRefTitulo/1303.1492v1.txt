

Intercausal reasoning is a common inference

pattern involving probabilistic dependence of

causes of an observed common effect. The
sign of this dependence is captured by a qual­
itative property called product synergy. The
current definition of product synergy is insuf­
ficient for intercausal reasoning where there
are additional uninstantiated causes of the
common effect. We propose a new definition
of product synergy and prove its adequacy for
intercausal reasoning with direct and indirect
evidence for the common effect. The new def­
inition is based on a new property matrix half
positive semi-definiteness, a weakened form
of matrix positive semi-definiteness.

1

INTRODUCTION

Intercausal reasoning is a common inference pattern
involving probabilistic dependence of causes of an ob­
served common effect. The most common form of
intercausal reasoning is "explaining away" (Henrion,
1986; Pearl, 1988), which is when given an observed
effect, and increase in probability of one cause, all other
causes of that effect become less likely. For example,
even though the use of fertilizer early in the spring
and the weather throughout the growing season can be
assumed to be probabilistically independent, once we
know that the crop was extremely good, this indepen­
dence vanishes. Upon having heard that the weather
was extraordinarily good, we find that the likelihood
that an efficient fertilizer had b ee n used early in the
spring diminishes - good weather "explains away"
the fertilizer. Although explaining away appears to
be the most common pattern of intercausal reasoning,
the reverse is also possible, i.e., observing one cause
can make other causes more likely. We call both types
of reasoning "intercausal," although strictly speak­
ing it is not necessary that the variables involved
are in causal relationships with one another and our
subsequent analysis captures probabilistic rather than
causal conditions. In fact, two variables a and b will

Max Henrion
Rockwell International Science Center
Palo Alto Laboratory
444 High Street, Suite 400
Palo Alto, CA 94301
henrion@camis.stanford. edu

be in an "intercausal relationship" given a third vari­
able c if they are independent conditional on a set of
variables \]!, but dependent conditional on every set cl>
such that c E cl>. This is captured by the graphical
structure of a Bayesian belief network in which a and
b are direct predecessors of c and there is no arc be­
twe en a and b. The applications of intercausal reason­
ing include algorithms for belief updating in qualita­
tive proba bilistic networks ( Druzdzel & Henrion, 1993;
Henrion & Druzdzel, 1991), appr oximat e search-based
algorithms for BBNs ( Henrion, 1991), and automatic
generation of expl an ations of probabilistic reasoning in
decision support systems (Druzdzel, 1993).
Intercausal reasoning has been captured formally by
a qualitative property called product synergy (Henrion
& Druzdzel, 1991; Wellman & Henrion, 1991). The
sign of the product synergy determines the sign of
the intercausal influence. Previous work on intexcausal
reasoning, and product synergy in particular, concen­
trated on situations where all irrelevant ancestors of
the common effect were assumed to be instantiated.
In this paper we propose a new definition of product
synergy that enables performing intercausal reason ing
in arbitr ary belief networks. We prove that the new
definition is sufficient for intercausal reasoning with
the common effect observed and is also sufficient for
intercausal reasoning with indirect support when the
common effect variable is bin ary.
The influence of indirect evidential support on inter­
causal reasoning in the binary common effect case has
been studied before by Wellman and Henrion (1991)
and by Agosta (1991). Our exposition deals with the
general case including uninstantiated predecessors of
the common effect variable and, therefore, advances
insight into intercausal reasoning beyond what has
been presented in those papers. Another difference
between this and Wellman and Henrion's exposition is
that here we provide more insight into the functional
dependences between nodes in intercausal reasoning.
We improve their theorem listing the conditions for
intercausal reasoning with indirect evidential support.
We generalize Agosta's analysis of intercausal reason­
ing from the binary case. Our analysis of Conditional
Inter-Causally Independent (CICI) node distribu tio ns

318

Druzdzel and Henrion

shows that there is a large class of relations for which
non-trivial evidential support can leave their direct an­
cestors independent.
All random variables that we deal with in this paper
are multiply valued, discrete variables, such as those
represented by nodes of a Bayesian belief network. We
make this assumption for the reasons of convenience in
mathematical derivations and proofs.
Following Wellman ( 1990), we will assume that all con­
ditional probability terms are well defined and those
that appear in the denominators are non-zero. This
assumption is easily relaxed at the cost of explicatory
complexity.
Lower case letters (e.g., x) will stand for random vari­
ables, indexed lower-case letters (e.g., x;) will usually
denote their outcomes. In case of binary random vari­
ables, the two outcomes will be denoted by upper case
(e.g., the two outcomes of a variable c will be denoted
by C and C). Outcomes of random variables are or-.
dered from the highest to the lowest value. And so,
for a random variable a, Va<j (a; ;:::: aj]· For binary
variables C > C, or true>false. Indexed lower case
letter n, such as na denotes the number of outcomes
of a variable a.

Definition 1 (qualitative influence) We say that
a positively influences c, written s+(a, c), iff for all
values a1 > a2, co, and x,
Pr (c;:::: colatx);:::: Pr (c ;:::: co!a2x).

This definition expresses the fact that increasing the
value of a, makes higher values of c more probable.
Negative qualitative influence, s-, and zero qualitative
influence, S0 , are defined analogously by substituting
;:::: by � and = respectively.
Definition 2 (additive synergy) Variables a and b
exhibit positive additive synergy with respect to vari­
able c, written Y+( {a, b }, c), if for all at > a2, bt > b2,
x, and co,
Pr(c � colatbtx) + Pr(c � cola2b2x)
;:::: Pr(c;:::: colatb2x) + Pr(c;:::: co!a2b1x).

The additive synergy is used with respect to two causes
and a common effect. It captures the property that the
joint influence of the two causes is greater than sum of
their individual effects. Negative additive synergy, y-,
and zero additive synergy, Y0 , are defined analogously
by substituting � by � and = respectively.

We will use bold upper-case letters (e.g., M) and bold
lower-case letters (e.g., x) for matrices and vectors re­
spectively. Elements of matrices will be doubly in­
dexed upper-case letters (e.g., M;j ).
The remainder of this paper is structured as follows.
Section 2 reviews the elementary qualitative proper­
ties of probabilistic interactions, as captured in quali­
tative probabilistic networks. Section 3 demonstrates
the problem of sensitivity of the previous definition of
product synergy to the probability distribution over
the values of uninstantiated direct ancestors of the
common effect node. Section 4 proposes a new def­
inition of product synergy that is provably sufficient
and necessary for intercausal reasoning and studies the
properties of intercausal reasoning when the evidential
support for the common effect is direct and indirect.
We discuss intercausal reasoning in Noisy-OR gates in
Section 5. Detailed proofs of all theorems can be found
in the appendix.,
2

QUA LITATIVE PROBA BILISTIC
NETWORKS

Qualitative probabilistic networks (QPNs) (Wellman,
1990) are an abstraction of Bayesian belief networks
replacing numerical relations by specification of quali­
tative properties. So far, three qualitative properties of
probability distributions have been formalized: qual­
itative influence, additive synergy, and product syn­
ergy. Since we will refer to them later in the paper, we
reproduce the definitions of these properties here after
(Wellman & Henrion, 1991).

Figure 1: Intercausal reasoning between a and b with
an additional predecessor variable x.
Definition 3 (product synergy I) Let a, b, and x
be the predecessors of c in a QPN (see Figure 1).
Variables a and b exhibit negative product synergy
with respect to a particular value c0 of c, written
x-({a, b}, c o), if for all al > a2, bt > b2, and x,
JOr(cola1b1x)JOr(cola2b2x)
�
Pr(colathr)Pr(cola2btx).

Positive product synergy, x+, and zero product syn­
ergy, X0, are defined analogously by substituting s
by ;:::: and = respectively. Note that product synergy
is defined with respect to each outcome of the common
effect c. There are, therefore, as many product syner­
gies as there are outcomes in c. For a binary variable
c, there are two product synergies, one for C and one
for C. The practical implication of product synergy
is that, under the specified circumstances, it forms a
sufficient condition for explaining away.
3

UNINSTANTIATED A N CESTOR
NODES

If a and x are both predecessors of c, with conditional
probability distribution Pr(cjax), then the relation be-

Intercausal Reasoning with Uninstantiated Ancestor Nodes

tween a and c depends on x. In other words, the prob­
abilistic influence of one variable on another may de­
pend on additional variables. Hence, the qualitative
properties defined above contain the strong condition
that they must hold for all possible instantiations of x.
If the "irrelevant" node x is uninstantiated, x will not
affect the signs of qualitative influence or additive syn­
ergy. But, surprisingly, it turns out that unobserved
predecessors may affect the product synergy.
We will present an example showing that the presence
of uninstantiated predecessor variables can affect the
intercausal relation between other parents and explain
informally the reasons for that effect. The example of a
simple BBN with binary variables, the associated con­
ditional probability distribution of the common effect
node, and the resulting qualitative properties of the in­
teraction between the variables, are given in Figure 2.
The qualitative properties of the interaction among a,
b, c, and x are all well defined. In particular, product
synergy I for C observed is for a, b, and x pairwise
negative. Still, for some distributions of x, for exam­
ple for Pr(X) = 0.5, the intercausal influence of a on
b is positive (see Figure 3).
Quantitative conditional distribution:
X

Pr(Ciabx)
A
A

B

B

B

B

0.8

0.6

0.2

0.0

I 0.99 I 0.8 I 0.99 I 0.2 I

Qualitative properties:
s+(a,t)
s+(b,c)
s+(x, c)

x-({a,b},C)
x-({a,x},C)
x-({b,x},C)

Figure 2: Example of the effect of an uninstantiated
predecessor node x on intercausal reasoning (see Fig­
ure 1). All pairwise product synergies for C observed
between a, b, and x are negative and all influences of
a, b, and x on c are positive.
Pr(AIBC)-Pr(A[C)

319

nomenon. The sign of intercausal interaction between
a and b is a function of the probability distribution
of x. This function is not linear (it will become ap­
parent in Section 4 that it is quadratic) and the fact
that the function has the same sign at the extremes
does not guarantee the same sign in all the points in
between. In the example above, we are dealing with
negative signs at the extremes (i.e., for Pr(X) = 0
and Pr(X) = 1) and a positive sign for some interval
in between (see Figure 3).
4

PRODUCT SYNERGY II

A key objective for any qualitative property between
two variables in a network is that this is invariant
to the probability distribution of other neighboring
nodes. This invariance allows for drawing conclusions
that are valid regardless of the numerical values of
probability distributions of the neighboring variables.
As we have shown in the previous section, this does not
apply to product synergy as previously defined. In this
section, we propose a new definition of product syn­
ergy that will have this property. The new definition
of product synergy is expressed in terms of a condition
that we term matrix half positive semi-definiteness.
4.1

MATRIX HALF POSITIVE
SEMI-DEFINITENESS

Half positive semi-definiteness is a weakened form of
positive semi-definiteness (see for example (Strang,
1976)). A square n x n matrix M is positive semi­
definite if and only if for any vector x, xTMx 2: 0.
M is half positive semi-definite if the above inequality
holds for any non-negative vector x.
Definition 4 (non-negative matrix) A matrix is
called non-negative (non-positive) if all its elements
are non-negative (non-positive).
Definition 5 (half positive semi-definiteness) A
square n x n matrix M is called half positive semi­
definite (half negative semi-definite) if for any non­
negative vector x consisting of n elements xTMx 2: 0
(xTMx � 0}.

The following theorem addresses the problem of test­
ing whether a given matrix is half positive semi­
definite.

-0.04

Figure 3: The intercausal interaction between a and b
as a function of probability of x.
We propose the following explanation of this phe-

Theorem 1 (half positive semi-definiteness) A
sufficient condition for half positive semi-definiteness
of a matrix is that it is a sum of a positive semi-definite
and a non-negative matrix.

It can be easily shown that the condition is also nec­
essary for 2 x 2 matrices.
Theorem 2 (2

x

2 half positive semi-definiteness)

320

Druzdzel and Henrion

A
necessary
condition
for
half
pos­
itive semi-definiteness of a 2 x 2 matrix is that it is
a sum of a positive semi-definite and a non-negative
matrix.

We can prove this condition also for 3 x 3 matrices. We
conjecture that this condition is true for n x n matrices,
although so far we have not been able to find a general
proof.
Conjecture 1 (half positive semi-definiteness)
sufficient and necessary condition for half positive
semi-definiteness of a square matrix is that it is a sum
of a positive semi-definite and a non-negative matrix.

A

Given Theorem 1, we are still left with the problem
of decomposing a n x n matrix into a sum of two ma­
trices of which one is positive semi-definite and the
other is non-negative. It can be easily shown that this
decomposition is not unique. It seems that a practi­
cal procedure for determining whether a matrix is half
positive semi-definite needs to be based on heuristic
methods. It is easy to prove that half positive semi­
definiteness necessitates 'V; (Dii :::; 0] (consider a vector
x in which only Xi is non-zero). The first test for any
matrix is, therefore, whether the diagonal elements are
non-negative. The heuristic methods might first check
whether the matrix is positive semi-definite by study­
ing its eigenvalues, pivots, or the determinants of its
upper left submatrices. Another easy check is whether
the matrix is non-negative. For any quadratic form,
there exists an equivalent symmetric form, so the ma­
trix will be non-negative if and only if all its diago­
nal elements are non-negative and 'V;j [Dij + Dji � 0],
i.e., the sum of each pair of symmetric off-diagonal
symmetric elements is non-negative. If both tests fail,
one might try to decompose the matrix by subtracting
from its elements positive numbers in such a way that
it becomes positive semi-definite. The subtracted el­
ements compose the non-negative matrix. As already
indicated, this decomposition is not unique.
4.2

PRODUCT SYNERGY II

Definition 6 (product synergy II) Let a, b, and x
be direct predecessors ofc in a QPN (see Figure 1). Let
n, denote the number of possible values of x. Variables
a and b exhibit negative product synergy with respect
to a particular value co of c, regardless of the distri­
bution of x, written x- ({a,b},co), if for all a1 > a2
and for all b1 > b 2, a square n, x n, matrix D with
elements

Dij

=

Pr(coia1blx;)Pr(coia2b2xj)
- Pr(coia2b1x;)Pr(coia1b2xj).

is half negative semi-definite. If D is half positive
semi-definite, a and b exhibit positive product syn­
ergy written as x+({a,b},c0). If D is a zero ma­
trix, a and b exhibit zero product synergy written as
X0 ({a,b },co).

Note that although the definition of product synergy II
covers the situation in which there is only one unin­
stantiated direct predecessor of c, it is easily extensi­
ble to the general case. If there are more than one
uninstantiated direct predecessors, we can conceptu­
ally replace them by a single uninstantiated variable
with the number of outcomes being the product of the
number of outcomes of each variable separately. This
is equivalent to rearranging the conditional distribu­
tion matrix of c.
Unless specified otherwise, in the remainder of this
paper we will use the term product synergy meaning
product synergy II. As product synergy I is a special
case of product synergy II, we propose to adopt this
convention in future references to this work.
4.3

INTERCAUSAL REASONING

The following theorem binds product synergy with in­
tercausal reasoning in case when the common effect
has been observed.
Theorem 3 (intercausal reasoning) Let a, b, and
x be direct predecessors of c such that a and b are
conditionally independent. A sufficient and necessary
condition for s- (a,b) on observation of Co is negative
product synergy, x-({a,b},co).
4.4

INTERCAUSAL REASONING WITH
INDIRECT EVIDENCE

The following theorem binds product synergy with in­
tercausal reasoning in case of indirect support for a
binary common effect.
Theorem 4 (intercausal reasoning) Let a, b, and
x be direct predecessors of c, and c be a direct prede­
cessor of d in a network. Let c be binary. Let there
be no direct links from a or b to d (see Figure 4).
Let X51({a,b},C), X52({a,b},C), Y53({a,b},c), and
S54(c,d).
If 84 = + and 81 = 83, then 851 (a,b) holds in the net­
work with D observed. If 84 = - and 82 =/= 83, then
S52 (a,b) holds in the network with D observed.

X

X01({a,b},C) Y03({a,b},c)
X52({a,b}, C) S54(c,d)
Figure 4: Intercausal reasoning with indirect evidence.
dis observed, x is uninstantiated.

Intercausal Reasoning with Uninstantiated Ancestor Nodes

Theorem 4 is an improvement on the theorem pro­
posed by Wellman and Henrion (1991, Theorem 6),
capturing additional conditions under which the sign
of intercausal inference with indirect support can be
resolved.
Pr(AI BD) -Pr(AID)

It turns out that Noisy-OR gates are robust against
the effect of uninstantiated predecessor variables dis­
cussed in Section 3. The conditional probability dis­
tribution of Noisy-OR gates always results in half neg­
ative semi-definite matrices used in the definition of
product synergy and, effectively, the probability distri­
bution of predecessor nodes never impacts intercausal
reasoning.
5.1

Figure 5: The intercausal interaction between a and b
as a function of the evidential support for c for various
values of qualitative properties of interaction between
a and b.
Figure 5 shows the magnitude of intercausal interac­
tion between a and b as a function of indirect evidential
support for C, for different values of qualitative prop­
erties of interaction between a and b. The strength of
evidential support is expressed by..\, the likelihood ra­
tio of the observed evidence (..\= Pr(DIC)/ Pr(DIC)).
The intercausal influence between a and b is, as ex­
pected, always zero for ..\ = 1.0 (no evidential sup­
port). ..\ = 0 corresponds to perfect evidence against
C (in other words, C is implied by D). ..\ = oo corre­
sponds to perfect evidence for c (in other words, C is
implied by D). In the proof of Theorem 4, we demon­
strate that the interaction is quadratic in ..\ and each
of the curves has at most two zero points (one of these
is a trivial zero point, for ..\ = 1.0). This result is
in agreement with Agosta's (1991) finding that inter­
causal conditional independence in binary variables is
possible at most at one state of evidence.
The product synergy and the additive synergy deter­
mine exactly the interval where the second zero point
falls. The product synergies between a and b for C
and C determine whether the curve is above or below
zero for ..\ = 0 and ..\ = oo· respectively. The additive
synergy helps to locate the second zero point of the
curve. If the evidence is positive (..\ > 1.0), and the
additive synergy is equal to the positive product syn­
ergy, then the second zero point is for ..\ < 1.0. If the
evidence is negative (0 :::; ..\ < 1.0), and the additive
synergy is not equal to the negative product synergy,
then the second zero point is for..\ > 1.0.
5

NOISY-OR DIST RIBUTION S

Noisy-OR gates (Pearl, 1988) are a common form of
probabilistic interaction used in probabilistic models.

321

UNINSTANTIATED PREDECESSOR
VARIABLES

We will demonstrate the behavior of a leaky Noisy-OR
gate c with direct binary predecessors a, b, and x (see
Figure 1). Let p, q, and r, be the inhibitor probabilities
(Pearl, 1988) for nodes a, b, and x with respect to the
node c and l be the leak probability. This determines
the elements Dij of the matrix D (see Definition 6) to
be
Du
D12
D21
D22

-(1- l)pq(1- r)
-(1- l)q(p + (1- p)r)
-(1- l)q(p-r)
-(1 - l)pq

It is easy to verify that D11 :::; 0 and D22 :::; 0. Also,
D12 + D21 = - (1-l)pq(2- r) � 0 ,
which shows that irrespective of the actual values of p,
q, r, and l, a symmetric form of the matrix D is non­
positive and, by Theorem 1, half positive semi-definite.
Binary Noisy-OR gates will, therefore, always exhibit
negative product synergy for the effect observed, re­
gardless of presence or absence of uninstantiated pre­
decessor variable x .
Pr(AIBD)-Pr(AID)

Figure 6: The intercausal interaction between a and
b as a function of the evidential support for c in a
Noisy-OR gate.

5.2

INDIRECT EVIDENCE

As the product synergy given effect observed to be ab­
sent is equal to zero ( i.e., for any Noisy-OR gate we
have X0 ( {a, b}, C)), and the product synergy given ef­
fect observed is negative (i.e., for any Noisy-OR gate

322

Druzdzel and Iienrion

x- ({a,b}, C)), Equation 13 (see the proof of Theo­
rem 4) reduces to
(,\ - 1),\ IX - ({a, b}, C) I $ 0 .
The two zero points of this expression with respect to
,\ are for ,\ = 0 and ,\ = 1. We know that there are no
other zero points (as shown in the proof of Theorem 4) ,
and it follows that intercausal influences in Noisy-OR
gates will always be negative for ,\ > 1 ( positive evi­
dence) and positive for 0 < ,\ < 1 (negative evidence)
(see F igure 6).
6

CONCLUSION

The previous definition of product synergy does not
cover situations where there are additional uninstanti­
ated causes of the common effect. We have introduced
a new definition of product synergy and we proved its
adequacy for intercausal reasoning with common effect
directly observed and also intercausal reasoning with
indirect evidential support when the common effect is
binary. We introduced the term matrix half positive
semi-definiteness, a weakened form of matrix positive
semi-definiteness.

(2 x 2 half positive semi-definiteness)
sufficient and necessary condition for half positive
semi-definiteness of a 2 x 2 matrix is that it is a sum
of a positive semi-definite and a non-negative matrix.

Theorem 2
A

Proof:
It is easy to prove that for any quadratic
form, there exists an equivalent symmetric form, so
let M be a symmetric 2 x 2 matrix of elements a, b, c

If M is half positive semi-definite, we have for any
non-negative vector [x y]

This is equivalent to

(1)
ax2 + by2 + 2cxy � 0.
It is easy to prove that both a and b have to be non­
negative (consider vectors [x 0] and [0 y] respectively ).
Now, we distinguish two cases: (1) if c � 0, then M is
non-negative; (2) if c < 0, then either a > 0 or b > 0
(note that vector x [1 1] yields a+ b + 2c � 0, which
given c < 0 implies a+ b > 0). If a > 0, then we apply
vector x [b - c] and if b > 0, then we apply vector
x [-c a]. In both cases, we obtain ab-c2 � 0, which
is satisfied if and only if M is positive semi-definite.
We have shown that if a 2 x 2 matrix is half positive
semi-definite, then it is either non-negative ( case 1)
or it is positive semi-definite ( case 2). This condition

Intercausal reasoning is useful in qualitative schemes
for reasoning under uncertainty and, because of its
prevalence in commonsense reasoning, valuable for au­
tomatic generation of explanations of probabilistic rea­
soning. The new definition of product synergy allows
for intercausal reasoning in arbitrary belief networks
and directly supports both tasks. As probabilities are
non-negative and, in many cases, the condition of ma­
trix positive definiteness may be too strong, we suspect
that the property of matrix half positive definiteness
that we introduced in this paper will prove theoreti­
cally useful in qualitative analysis of probabilistic rea­
soning.

is actually stronger than the matrix being a sum of
a non-negative and a positive semi-definite matrices.
Such strong form of the condition does not hold for
0
3 x 3 matrices.

APPENDIX: PROOFS

Theorem 3 (intercausal reasoning)

Theorem 1 (half positive semi-definiteness) A

sufficient condition for half positive semi-definiteness
of a matrix is that it is a sum of a positive semi-definite
and a non-negative matrix.
Proof:
Let M M1 + M2, where M1 is positive
semi-definite and M2 is non-negative. Since positive
semi-definiteness holds for any vector x, and in par­
=

ticular for a non-negative one, a positive semi-definite
matrix M1 is also a half positive semi-definite. We
have therefore, xTM1x � 0. Also, a non-negative ma­
trix is half positive semi-definite, since any quadratic
form with all non-negative elements cannot be nega­
tive. We have therefore that xTM2x � 0. Sum of
two non-ne�ative numbers is non-negative, therefore
xTM1x + x M2x � 0. By elementary matrix algebra

$ xTM1x + xTM2x xT (M1 + M2)x xTMx.
This proves that M is half positive semi-definite. 0
0

=

=

=

=

=

Let a, b, and
x be direct predecessors of c such that a and b are con­
ditionally independent ( see Figure 3). A sufficient and
necessary condition for s-(a,b) on observation of co
is negative product synergy, x-({a,b},ca).

Proof:
have

s-(ab)

By the definition of qualitative influence we
{::}

'Vt'tlbl>b2

Pr(a > ailb1co) $ Pr(a > ailb2co). (2)

This is equivalent to
'VNbt>b2

i-1
L[ Pr(ajlb1co)- Pr(ajlb2co)] $0.

j=O

Expansion of both components by Bayes theorem

lntercausal Reasoning with Uninstantiated Ancestor Nodes

n.,

and subsequent simplification yields

- L Pr(cola2b1xp)Pr(xp)
p:=O

'r/;'rlb,>b2

i-1 na

( LL Pr(aj)Pr(ak)(

�

Pr(colakbl)Pr(ak)

q:=O

)

Pr(colakb2)Pr(ak) $ 0.

We multiply both sides by the denominator and, for
the sake of brevity, introduce term A defined as follows
Amn

=

Pr(colambi) Pr(coJanb2)
- Pr(coJanbi)Pr(colamb2).

It is straightforward to verify that 'rim [Amm = 0) and
'rlm¢n [Amn = -Anm ]. Taking this into consideration,
we refine the summation indices, obtaining
i-1 na
L Pr(aj)Pr(a�:)Ajk $ 0. (3)
L
'r/;'r/b,>b2
j=O l:=i
The sufficient and necessary condition for the above to
hold for any distribution of a is
Vi< k Aik $ 0.
Note here that j < k and we can rewrite this inequality
as
'rla1>a2 A12 $ 0.
As 'r/; [Pr(a;) �OJ, sufficiency follows directly from
(3). We prove the necessity by contradiction. Sup­
pose that for some 61 > b2 there exist such a1 > a2
that A12 > 0. Consider a distribution of a in which
Pr(a!) > 0, Pr(a2) > 0, and Pr(a1)+Pr(a2) = 1. By
axioms of probability theory Vm¢t,m¢2 [Pr(am) = 0],
which reduces (3) to
Pr(a1)Pr(a2)A12 :S 0.
This implies that A12 is not positive, which contradicts
the assumption.
We have proven that the sufficient and necessary con­
dition for (2) is
Va1>a2 Vb1>b2

Pr(cola1b1)Pr(coia2b2)
- Pr(coia2b!)Pr(coia1b2) $ 0.

n.,

L Pr(colalblxm)Pr(xm)

m=O

n,

L Pr(cola2b2xn)Pr(xn)

n=O

After rearranging the summation operators, we get
n:a: n.t
L Pr(xm)Pr(xn)
L
'rla,>a,'1b1>b2
m=On=O
( Pr(cola1b1xm)Pr(cola2b2xn)
- Pr(coia2blxm)Pr(coiatb2xn)) $ 0,
which is equal to
n:c nz

LE

Pr(xm)Pr(xn)Dmn $ 0. (5)
m=On=O
This can be written in matrix notation as
Va,>a, vb,>b2

Va,>a, vb,>b2

p

T Dp $ 0.

(6)

where p is a vector of probabilities of various outcomes
of x (p; = Pr(x;)), and D is a square matrix with
elements Dmn. Inequality (6) will hold for any vector
of probabilities p if and only if Dis half negative semi­
definite, which is exactly the condition for the negative
0
product synergy II.
Theorem 4 (intercausal reasoning) Let a, b, and
x be direct predecessors of c , and c be a direct prede­
cessor of d in a network. Let c be binary. Let there
be no direct links from a or b to d (see Figure 4).
Let X6t({a,b},C), X62({a,b},C), Y63({a,b},c), and
S6•(c,d).
I! 84 = + and 81 = 63, then S61 (a,b) holds in the net­
work with D o b s erve d. If 84 = - and 62 =f:. 63, then
362(a, b) holds in the network with D observed.
Proof:
Let na, nc, and nx denote the number of
possible values of a, c , and x respectively. By the
definition of qualitative influence

s-(ab)

<=>

Vi Pr(a > ai\btdo) S Pr(a

>

adb2do).

This is equivalent to
i-1

(4)

Note that this condition is equivalent to product syn­
ergy I if c has no other predecessors than a and b. In
order to express this result in terms of the conditional
distribution of c given all its immediate predecessors,
we introduce x into ( 4).
'rla1>a2 'r/b,>b2

n.,

L Pr(colalb2xq)Pr(xq) $ 0.

Pr(colaibr)Pr(colakb2)

i=Dk=O
-Pr(colakbl)Pr(colaib2)))/

(�

323

'r/;

L [Pr(aiib1do)- Pr(aiib2do)] $ 0.
j:O

Expansion of both components by Bayes theorem
Pr(aiJb.do)

_- Pr(d0!a;b.(r(a;)
Pr(do b.)

and simplification yields
i-1
Vi l: Pr(aj)
j:=O
Pr(doiaibt)Pr(do\b2)- Pr(do)ajb2)Pr(do\bt) <
-0.
Pr( dolbt)Pr(do/b2)

324

Druzdzel and Henrion

Multiplying both sides of the inequality by the denom­
inator, which does not depend on the summation index
and is positive, yields

i-1

It is straightforward to verify that Vm [Cmm 0] and
Vmtn [Cmn -Cnm]. Analogous conditions are valid
for Cmn· Taking this into consideration, we refine the
=

=

summation indices, obtaining

Vi L Pr(aj)( Pr(dolaibl)Pr(dolb2)
j=O
-Pr(dolaib2)Pr(dolb!))::::; 0 .
W e expand the formulas for Pr(d 0) using
nc
Pr(dolaib.) L Pr(doick)Pr(ckiaib.)
k=O
=

and

nc

no.

Pr(dolb.) L Pr(dolcm)L Pr(cmia11b.)Pr(an),
m=O
n=O
=

which, after rearranging the summation terms, yields

i-l no.

nc n c

Vi L L Pr(ai)Pr(an)L L Pr(dolck)Pr(dolcm)
j=O n=O
k=O m=O
( Pr(cklaib1)Pr(cmlanb2)
- Pr(ckiaib2)Pr(cmlanb!))::::; 0. (7)
For a binary c (i.e.,
the following form

nc =

2,

co C, c1 C), (7) takes
=

=

Vi I:�:� l::��o Pr(aj)Pr(ak)
Pr(doiC)Pr(doiC)( Pr(Ciaibl)Pr(Ciakb2)
- Pr(Ciaib2)Pr(C!akb1))
+ Pr(doiC)Pr(doiC)( Pr(Ciaibl)Pr(Ciakb2)
- Pr(Ciaib2)Pr(Ciakbl))
+ Pr(doiC)Pr(doiC)( Pr(Ciaib1)Pr(Ciakb2)
- Pr(Ciaib2)Pr(Ciakb1))
+ Pr(doiC)Pr(doiC)( Pr(Ciaib1)Pr(Ciakb2)
- Pr(Ciaib2)Pr(Ciakbl))::::; 0.
We divide both sides twice by Pr(diC) and substi­
tute A for the likelihood ratio Pr(d!C)/Pr(d!C). Re­
arrangement and simplification yields

Vi l::�:O�L:��o Pr(ai)Pr(ak)(A-1)
( ( A ( Pr(Claib!)Pr(Clakb2)
- Pr(Ciaib2)Pr(Ciakb1))
- ( Pr(Claib1)Pr(Clakb2)
- Pr(Ciaib2)Pr(Ciakb1)))::::; 0 .
For the sake of brevity we introduce terms Cmn and
c mn defined as follows
Cmn Pr(Ciamb!)Pr(Cianb2)
- Pr(Clamb2)Pr(Clanh)
Cmn
Pr(Ciamb!)Pr(Cianb2)
- Pr(Ciamb2)Pr(Cianb1).
=

=

i-1 n,.
Vi LL Pr(ai)Pr(ak)(A - 1)(ACik-Cik)::::; 0.
j=O k=i

(8)
Note here that j < k. The sufficient and necessary
condition for the above to hold for any distribution of
a 1s
(9)
Vi<k (A - 1)(ACjk - Cik) ::::; 0 .
As Vi [ Pr(ai) 2: 0 ), sufficiency follows directly from
(8). We prove the necessity by contradiction. Suppose
there exist j and k such that (A-1)(ACjk-Cjk) >
0. Consider a distribution of a in which Pr(ai) > 0,
Pr(ak) > 0, and Pr(aj)+ Pr(ak) = 1 . By axioms
of probability theory Vm-:pj,m# [ Pr(am) = 0), which
reduces (8) to

Pr(ai)Pr(ak)(A - 1) (ACjk-Cik) ::::; 0.
implies that (A -1)(ACjk-Cjk) is negative,

This
which contradicts the assumption.

We have proven that the sufficient and necessary con­
dition for (8) is

Vi<k
(A-1) ( ( A ( Pr(Ciaib1)Pr(Ciakb2)
(10)
- Pr(Claib2)Pr(Clakbl) )
-( Pr(Ciaib1)Pr(Ciakb2)
- Pr(Ciaib2)Pr(Ciakbl)))::::; 0.
Substituting Pr(C) 1- Pr(C) in (11), and simpli­
=

fying yields an equivalent formula

Vi<k (A-1)
( (A - 1)( Pr(Claibl)Pr(Clakb2)
(11)
- Pr(Ciaib2)Pr(Ciakb!))
+ Pr(Ciaib!)- Pr(Ciakb!)
+ Pr(Ciaib2)- Pr(Ciakb2))::::; 0.
In order to express both results in terms of the condi­
tional distribution of c given all its immediate prede­
cessors, we introduce x into ( 1 1)

Vi<k

(.:\- 1)

nx n�

( A LL Pr(xm)Pr(xn)
m=O n=O
( Pr(Ciaib1xm)Pr(Ciakb2xn)
- Pr(Ciajb2xm)Pr(Ciakb1xn))
n.x
L Pr(xm)Pr(xn)
- mL
=Dn=D
( Pr(Ciaib1xm)Pr(Ciakb2xn)
- Pr(Ciaib2xm)Pr(Ciakb1xn)))::::; 0 .
n.x

·

Intercausal Reasoning with Uninstantiated Ancestor Nodes

The above can be written using matrix notation as
Yi<k

(>.- 1) (>.pT Dp- pTDp) S 0

( 12)

where p is a vector of probabilities of various outcomes
of x (Pi= Pr(x;)), D and D are square matrices with
elements Dmn for c = C and c == C respectively.
Replacement of the matrix expressions by the formulas
used for computing the value of product synergies from
the numerical distribution (we will denote the fact that
they are formulas and not the synergies by enclosing
them in straight brackets, e.g., fX 6� ( {a, b }, C) f) yields
Yi<k (.>.- 1)

(>. fx5•({a, b}, C) f- fX52({a, b}, C) f)::; 0. (13)
A similar procedure with respect to (12) yields
Yi<k (>.- 1)
n:c nx
( ,\ L L,: Pr(xm) Pr(xn)
m=On=O
( Pr(Ciajblxm)Pr(Ciak b2xn)
- Pr(Cjajb2xm)Pr(Cia�cblxn))

325

Richard Duffin for suggesting the term half positive
semi-definiteness. Professors Victor Mizel and Juan
Schaffer were the first to note the conditions for half
positive semi-definiteness. Professor Schaffer's sugges­
tion improved our proof of Theorem 2. Anonymous
reviewers provided useful remarks.
