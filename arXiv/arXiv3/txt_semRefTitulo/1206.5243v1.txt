
Inference problems in graphical models are
often approximated by casting them as constrained optimization problems. Message
passing algorithms, such as belief propagation, have previously been suggested as methods for solving these optimization problems.
However, there are few convergence guarantees for such algorithms, and the algorithms
are therefore not guaranteed to solve the corresponding optimization problem. Here we
present an oriented tree decomposition algorithm that is guaranteed to converge to
the global optimum of the Tree-Reweighted
(TRW) variational problem. Our algorithm
performs local updates in the convex dual
of the TRW problem – an unconstrained
generalized geometric program. Primal updates, also local, correspond to oriented
reparametrization operations that leave the
distribution intact.

1

Introduction

The problem of probabilistic inference in graphical
models refers to the task of calculating marginal distributions or the most likely assignment variables. Both
these problems are generally NP hard, requiring approximate methods.
Many approximate inference methods, including message passing algorithms, can be viewed as trying to
solve a variational formulation of the inference problem. The idea in variational approaches is to cast approximate inference as a constrained minimization of
a free energy function (see [14] for a recent review).
Two key questions arise in this context. The first is
how to choose the free energy, and the second is how to
design efficient algorithms that minimize it. When the
Bethe free energy is used, it has been shown [16] that

Tommi Jaakkola
CSAIL
Massachusetts Institute of Technology
Cambridge, MA 02139

fixed-points of the belief propagation (BP) algorithm
correspond to local minima of the free energy. However, BP is not generally guaranteed to converge to a
fixed-point. Although there do exist algorithms that
are guaranteed to converge to a local minimum of the
Bethe free energy [15, 17], its global minimization is
still a hard non-convex problem for which no efficient
algorithms are known.
The difficulties with the Bethe free energy derive
from its non-convexity and corresponding local minima problem. To avoid this difficulty, several authors
have recently studied convex free energies [6, 7, 13].
The associated convex optimization problems can in
principle be solved using generic convex optimization
procedures [1] with guarantees of finding the global optimum in polynomial time. Although this presents a
significant improvement over the non-convex case, the
generic optimization route may be very costly in large
practical problems. For example, when using a generic
convex solver, every update of the variables has complexity O(n), where n is the number of variables. In
contrast, the optimization using message passing algorithms can be reduced to local updates with O(1)
operations. Interestingly, even in the convex setting,
the convergence of these message passing algorithms
is typically not guaranteed, and damping heuristics
are required to ensure convergence in practice [13]. A
prominent exception is [7] where the author provides
a provably convergent message passing algorithm for
free energies where the entropy term is a non-negative
combination of joint entropies.
Here we provide a provably convergent message passing algorithm for a specific variational setup, namely
the Tree-Reweighted (TRW) optimization problem of
Wainwright et al. [13]. The algorithm we propose is
guaranteed to converge to the global optimum of the
free energy, and does not require additional parameters such as the damping ratio. A key step in obtaining the updates is deriving the convex-dual of TRW,
which we show to be an unconstrained instance of a

134

GLOBERSON & JAAKKOLA
generalized geometric program (GP) [3]. We derive a
message passing algorithm, which we call TRW Geometric Programming (TRW-GP), that yields monotone improvement of the dual GP. We demonstrate the
utility of our TRW-GP algorithm by providing an example where the TRW message passing algorithm in
[13] does not converge, but TRW-GP does.

2

where H(Xi ) is the entropy of µi (xi ) and I(Xi ; Xj )
is the mutual information calculated from µij (xi , xj ).
Note that this expression is independent of the direction of the edges in the tree. We will make use of the
directed edges in the next section.
Define the following variational free energy function
F (µ; ρ, θ)

The Tree-Reweighting Formulation

We consider pairwise Markov random fields (MRF)
over a set of variables x = x1 , . . . , xn . Given a graph
G with n vertices V and a set of edges E, an MRF is
a distribution over x defined by
p(x; θ) =

1 Pij∈E θij (xi ,xj )+Pi∈V
e
Z(θ)

θi (xi )

Our focus here is on approximating singleton
marginals of p(x; θ), namely p(xi ; θ). This problem is
closely related to that of evaluating the partition function Z(θ). We focus on the TRW variational problem
which yields an upper bound on Z(θ) as well as a set of
approximate marginals obtained from the minimizing
solution.
We begin by briefly reviewing the TRW formalism.
Consider a set of k spanning trees on G denoted by
T 1 , . . . , Tk , P
and a distribution ρi over these trees where
ρi ≥ 0 and ρi = 1. To avoid overloading notation in
subsequent analysis, we assume here that the trees are
directed, so that the same tree structure may appear
multiple times with different edge orientations. This
differs from the presentation in [13] though the distinction is immaterial in the remainder of this section.
We also introduce the notion of pseudomarginals
defined as the singleton and pairwise marginals
µi (xi ), µij (xi , xj ) associated with the edges and nodes
of G. We use µ to denote the set of all these marginals
and C(G) the set of µ’s that are pairwise consistent
P
P
µij (xi , xj ) = µi (xi ) ,
µij (xi , xj ) = µj (xj )
xj
xi
P
µi (xi ) = 1 , µij (xi , xj ) ≥ 0 .
xi

For a given tree T and µ ∈ C(G), define the entropy
H(µ; T ) to be the entropy of an MRF on the tree T
with marginals given by µ. Note that only a subset
of the pairwise distributions in µ will be used for each
tree, namely µij (xi , xj ) such that ij is an edge in T .
The tree entropy may be written in closed form as (cf.
[13])
X
X
H(µ; T ) =
H(Xi ) −
I(Xi ; Xj )
(2)
ij∈T

k
X

ρi H(µ; Ti ) .

(3)

i=1

In [13] it is shown that minimizing F (µ; ρ, θ) results
in an upper bound on the log-partition function
log Z(θ) ≤ − min F (µ; ρ, θ) .
µ∈C(G)

(1)

where θij (xi , xj ) and θi (xi ) are parameters, θ denotes
all the parameters, and Z(θ) is the partition function.

i

F (µ; ρ, θ) = −µ · θ −

(4)

The minimization also results in an optimal (minimizing) µ, which is used to approximate the marginals
of p(x; θ). Empirical results in [13] show that TRW
usually performs as well as, and often better than the
standard Bethe free energy approximations, especially
in regimes where BP fails to converge.

3

Conditional Entropies and Directed
Edge Probabilities

Our goal is to use convex duality to obtain the dual
problem of Eq. (4). To achieve this, we first seek a
representation of F (µ; ρ, θ) that is a convex function of
µ for all values of µ, and not just within the consistent
set µ ∈ C(G). For example, the entropy term in Eq. (2)
is concave only for µ ∈ C(G) but not for a general µ.
We therefore seek an alternative expression for the tree
entropy.
Let r(T ) be the root node of T (recall that the trees
are directed). We write the entropy associated with
the tree as
X
H(µ; T ) = H(Xr(T ) ) +
H(Xi |Xj )
(5)
j→i∈T

where j → i ∈ T implies that there is a directed edge
from vertex j to vertex i in the directed tree T . The
conditional entropy H(Xi |Xj ) is assumed to be calculated only on the basis of the joint marginal µij (xi , xj ),
and does not involve µi (xi ). The entropy H(Xr(T ) )
is calculated via the singleton marginal µr(T ) (xr(T ) ).
The expressions in Eq. (5) and Eq. (2) will agree whenever µ ∈ C(G). However, they will yield different results when µ ∈
/ C(G).
The advantage of Eq. (5) is that H(µ; T ) is now a concave function of the set of marginals µ. The concavity
follows immediately from the concavity of H(Xi ) as a
function of µi (xi ) and the concavity of the conditional
entropy H(Xi |Xj ) as a function of µij (xi , xj ) [6].

GLOBERSON & JAAKKOLA
The function F (µ; ρ, θ) involves a summation over a
potentially large number of tree entropies. To express
this compactly while maintaining directionality, we define ρi|j as the probability that the directed edge j → i
is present in a tree drawn according to the distribution
ρ over trees. Similarly, we define ρ◦i as the probability that node i appears as a root. We note that it
is possible to find such edge probabilities for distributions (e.g. uniform) over the set of all spanning trees
by employing a variant of the matrix tree theorem for
directed trees (see [12] p. 141 and [11]).
The function F (µ; ρ, θ) can now be written as
−µ · θ −

X

i∈V

ρ◦i H(Xi ) −

X

ij∈Ē

ρi|j H(Xi |Xj )

now on) and refer to the consistency constraints by
~
C(G).
The TRW primal problem is then
P T RW :

min F (µ; ρ, θ) .

(6)

The TRW Convex Dual

(8)

~
µ∈C(G)

The convex dual of P T RW is derived in App. A. and
is in fact a convex unconstrained minimization problem. In what follows we describe this dual. The dual
variables will be denoted by βij (xi , xj ) for ij ∈ E, and
are not constrained.2 The dual objective is given by
X
X ρ−1 (θ (x )−P
k∈N (i) λk|i (xi ;β))
FD (β; ρ, θ) =
ρ◦i log
e ◦i i i
xi

i

where the edge set Ē contains edges in both directions.
In other words, if ij ∈ Ē then ji is also in Ē. The new
function F (µ; ρ, θ) is convex in µ without assuming
consistency of the marginals.

4

135

where λj|i (xi ; β) is a function of the β variables:
λj|i (xi ; β) = −ρj|i log

X

e

ρ−1
(θij (xi ,xj )+δj|i βij (xi ,xj ))
j|i

xj

and δj|i is defined as

1 ji ∈ E
δj|i =
−1 ij ∈ E .
The dual TRW optimization problem is then

The TRW primal problem is given by
min F (µ; ρ, θ) .

µ∈C(G)

DT RW :
(7)

Since the function F (µ; ρ, θ) is now convex for all µ
and the set of constraints is linear, this optimization
problem is convex and thus has an equivalent convex
dual [1].1 However, it is not immediately clear how
to derive this dual in closed form. The main difficulty is that two terms in the objective F (µ; ρ, θ) depend on µij (xi , xj ), namely H(Xi |Xj ) and H(Xj |Xi ).
To get around this problem we introduce additional
variables to the primal problem. Specifically, we replace µij (xi , xj ) by two copies which we denote by
µi|j (xi , xj ) and µj|i (xi , xj ), and require that these
two copies are identical. The entropy H(Xi |Xj ) is
then evaluated via the variables µi|j (xi , xj ). We shall
also find it convenient to replace the consistency constraints in C(G) by the following equivalent directed
consistency constraints
µi|j (xi , xj ) = µj|i (xi , xj )
P
P
µj|i (xi , xj ) = µi (xi ) ,
µi|j (xi , xj ) = µj (xj )
xj
xi
P
µi (xi ) = 1 , µi|j (xi , xj ) ≥ 0 , µj|i (xi , xj ) ≥ 0 .
xi

For simplicity we will continue to denote the new extended variable set by µ (as we will be using it from
1
Strict duality follows from Slater’s conditions, which
are satisfied in this case.

min FD (β; ρ, θ) .
β

(9)

We re-emphasize the fact the DTRW is an unconstrained minimization of a function of β. The variables λj|i (xi ; β) are introduced merely for the purpose
of notational convenience. The mapping between dual
and primal variables can be shown to be
−1

µi (xi ) ∝ eρ◦i (θi (xi )−
µj|i (xj |xi ) ∝ e

P

k∈N (i)

λk|i (xi ;β))

ρ−1
(θij (xi ,xj )+δj|i βij (xi ,xj ))
j|i

.

(10)

This relation maps the optimal β to the optimal µ,
but we shall also use it for non-optimal values.
The dual objective FD (β; ρ, θ) is a convex function
(see App. B) and therefore has no local minima.

5

Dual Gradient and Optimum

The DTRW problem presented above is unconstrained
and can thus be solved using a variety of gradient
based algorithms, such as conjugate gradient or BFGS
[10]. The gradient of FD (β; ρ, θ) w.r.t. β is
∂FD (β; ρ, θ)
= µi|j (xi |xj )µj (xj ) − µj|i (xj |xi )µi (xi )
∂βij (xi , xj )
where the distributions are given by the dual to primal
mapping in Eq. (10). The gradient is thus a measure
2
Note that β variables are not directed, i.e., there is one
variable βij per edge.

136

GLOBERSON & JAAKKOLA
of the discrepancy between two ways of calculating
the joint pairwise marginal, based on the two different
orientations of the edge ij.
To characterize the optimum of DTRW we set the gradient to zero, yielding the following simple dual optimality criterion
µi|j (xi |xj )µj (xj ) = µj|i (xj |xi )µi (xi ) .

(11)

Thus at the optimum the two alternative ways of estimating µij (xi , xj ) will yield the same result.
Calculating the gradient w.r.t a given βij (xi , xj ) has
complexity O(1), and relies only on βij (xi , xj ) for
edges containing i or j. Thus the gradient can be calculated locally, and gradient descent algorithms can
be implemented efficiently. One drawback of gradient based algorithms is their reliance on line-search
modules for finding a step size that decreases the objective. In the next section we consider updates that
are parameter-free.

6

Local Marginal Updates

The gradient updates described in the previous section
use the difference between two joint distributions. We
will now focus on updates relying on the ratio between
these distributions. Consider
t+1
t
βij
(xi , xj ) = βij
(xi , xj )+ǫ log

µtj|i (xj |xi )µti (xi )

µti|j (xi |xj )µtj (xj )

(12)

where µtj|i (xj |xi ) and µti (xi ) are functions of β as in
Eq. (10) and ǫ is a step size whose value will be discussed in the next section. As a ratio of two expected
values, the update is reminiscent of Generalized Iterative Scaling [5]. We shall assume for simplicity that
only one edge is updated at each time step t.

Lemma 6.1 : For 0 < ǫ < min(ρ◦i , ρ◦j , ρi|j , ρj|i ) the
dual objective is decreased at every iteration so that
∆D (µt ) ≥ 0 for all t. Furthermore, ∆D (µt ) = 0 holds
if and only if the optimum condition of Eq. (11) is
satisfied.
Any choice of ǫ that is smaller than
min(ρ◦i , ρ◦j , ρi|j , ρj|i ) will result in monotone improvement of the objective. In the current implementation we use ǫ = 12 min(ρ◦i , ρ◦j , ρi|j , ρj|i ). This value
turns out to minimize a first order approximation of
the improvement in the objective, and was found to
work well in practice. The convergence to the global
optimum now follows from Lemma 6.1.
Lemma 6.2 : The updates in Eq. (12) with ǫ as in
Lemma 6.1 converge to the joint optimum of PTRW
and DTRW.
Proof: Denote the mapping from µt to µt+1 by
R(µt ) = µt+1 . The mapping is clearly continuous.
By Lemma 6.1 the sequence FD (β t ; ρ, θ) is monotonically decreasing. It is also bounded since FD (β; ρ, θ)
is bounded and thus the difference series ∆D (µt ) converges to zero. Taking t to infinity then implies that
µt has a convergent subsequence that converges to
some µ∗ . This µ∗ will then satisfy FD (µ∗ ; ρ, θ) =
FD (R(µ∗ ); ρ, θ). We know from the Lemma 6.1 that
such a point necessarily satisfies the zero gradient condition in Eq. (11), and thus µ∗ (or more precisely, the
corresponding β) minimizes the dual objective.3

7

Tree Re-parametrization View

The TRW problem can be interpreted in terms of iterating through different re-parametrizations of the distribution p(x; θ) [13]. Here we present a related view
of our algorithm.

The update in Eq. (12) is performed on the β variables.
An equivalent, and somewhat simpler update may be
derived in terms of the variables µti|j (xi |xj ) and µtj (xj ).
The resulting updates and algorithm are described in
Figure 1. We call the resulting algorithm TRW-GP
(TRW Geometric Programming).

We wish to show that the marginal variables obtained
by the algorithm can always be used to obtain the
original distribution via
Y
Y
µtj|i (xj |xi )ρj|i . (13)
p(x; θ) = ct
µti (xi )ρ◦i

6.1

For t = 0 this is clearly true. We proceed by induction.
Assume that at iteration t we have a reparametrization with constant ct . Substituting the update rule in
Figure 1 and using simple algebra shows that we again
have a reparametrization, only with

Convergence Proof

To analyze the convergence of the update in the previous section, we need to consider the resulting change
in the objective FD (β; ρ, θ), namely FD (β t ; ρ, θ) −
FD (β t+1 ; ρ, θ). It can be shown (see App. D) that
this difference only depends on the µ variables in the
TRW-GP algorithm, and thus we denote it by ∆D (µt ).
Since FD (β t ; ρ, θ) should be minimized, this difference
needs to be non-negative. This is indeed guaranteed
by the following lemma (see App. D):

i

ct+1 = ct eFD (β

ij∈Ē

t+1

;ρ,θ)−FD (β t ;ρ,θ)

= ct e−∆D (µ

t

)

.

3
To carefully account for the possibility that some of
the converging marginals would involve zero probabilities,
the updates in the primal form, along with the objective,
can be written in a form without any ratios.

GLOBERSON & JAAKKOLA

137

Inputs: A graph G = (E, V ), parameter vector θ on G, root probabilities ρ◦i and directed edge probabilities
ρi|j for (ij), (ji) ∈ E.
−1

Initialization: Set µ0i (xi ) ∝ eρ◦i θi (xi ) and µ0i|j (xi |xj ) ∝ eρi|j θij (xi ,xj )
−1

Algorithm: Iterate until small enough change in marginals:
• Set ǫ =

1
2

min(ρ◦i , ρ◦j , ρi|j , ρj|i ), and update

µt+1
(xi ) ∝ µti (xi )
i
µt+1
i|j (xi |xj )

∝

P
xj



µtj|i (xj |xi )

−1
µti|j (xi |xj )1−ǫρi|j



!ρj|i ρ◦i
ǫρ−1
j|i

−1

µti|j (xi |xj )µtj (xj )
µtj|i (xj |xi )µti (xi )

µtj|i (xj |xi )µti (xi )
µtj (xj )

ǫρ−1
i|j

Output: Final values of marginals.
Figure 1: The TRW-GP algorithm expressed in terms of conditional and singleton marginals.
In other words the multiplicative constant turns
out to be related to the improvement in the dual
function. This creates an interesting link between
reparametrization and minimization, and may be used
to study message passing algorithms where a dual is
more difficult to characterize.

8

Relation to Previous Work

Heskes [7] recently presented a detailed study of convex free energies. When the entropy term is a positive
combination of joint and singleton entropies (and is
therefore concave), he provides a local update algorithm that is monotone in the convex dual, and converges to the global optimum. He then discusses the
application of the same algorithm to the case where the
singleton entropies all have negative weight, and the
overall entropy is convex over the set of constraints.4
In this case, the dual is generally not given in closed
form and it is not known if the algorithm decreases it
at every step. However, Heskes argues that with sufficient damping the algorithm can be shown to converge,
although the exact form of damping is not given.
Since the TRW entropy can be shown to decompose
into positively weighted pairwise entropies and negatively weighted singleton entropies, it satisfies the
above condition in Heskes’ work. Our analysis provides several advantages over the algorithm in [7].
First, we derive a closed form solution of dual. Second, the dual is unconstrained, and thus allows unconstrained minimization methods to be applied. Third,
unlike most belief propagation variants, our algorithm
4

The discussion in [7] is in terms of general regions,
not just pairs. We present his argument for the simpler
pairwise case.

is shown to provide a monotone improvement of an
objective function5 , and thus diverges from the standard fixed point analysis used in message passing algorithms.
Finally, another algorithm which is guaranteed to converge to a global minimum of convexified free energies
is the double loop CCCP algorithm of Yuille [17]. The
main disadvantage of CCCP is that each iteration requires solving an optimization problem. This usually
results in slower convergence, and furthermore it is
not clear what precision is required for the inner loop
optimization, and how this affects convergence guarantees. The algorithm we present here is essentially a
single loop method, and is thus easier to analyze.

9

Empirical Demonstration

The original TRW message passing (TRW-MP) algorithm presented in [13] is not generally guaranteed to
converge. However, we observed empirically that when
damping of α = 0.5 is applied to the log-messages,
convergence is always achieved.6 To compare TRWMP to TRW-GP, we use the pseudomarginals generated by TRW-MP7 as marginals in the primal objective F (µ; ρ, θ) in Eq. (3). This value is not expected
to be an upper or lower bound on the optimum of
F (µ; ρ, θ), since the TRW-MP pseudomarginals are
5

As mentioned above, Heskes presents such an algorithm for positively weighted singleton and pairwise entropies. It is however not clear that such entropies are
useful in practice
6
This observation is in line with Heskes’ argument that
sufficiently damped messages will converge for the case of
the TRW free energy.
7
See Equations (58) and (59) in [13].

138

GLOBERSON & JAAKKOLA
TRW−GP
TRW−MP
TRW−MP(damped)

880

870

860

850
0

100

Iteration

200

300

140

Primal−Dual Value

Primal−Dual Value

890

TRW−GP
TRW−MP
TRW−MP(damped)

135

130

125

120
0

100

Iteration

200

300

Figure 2:

Illustration of the dual message passing algorithm for a 10 × 10 Ising model. The TRW-GP curve
shows the dual objective value FD (β; ρ, θ) obtained by the
TRW-GP algorithm. The TRW-MP curves show the primal objective values F(µ; ρ, θ) obtained by TRW message
passing algorithms. The damped TRW-MP used a damping of 0.5 in the log domain. The MRF parameters were
set as follows: αF = 1, αI = 9 for the left figure, and
αF = 1, αI = 1 for the right figure.

not guaranteed to be pairwise consistent, except at
the optimum. However, since the TRW-MP pseudomarginals converge to the optimal primal marginals,
the value F (µ; ρ, θ) will converge to the primal optimum. The progress of TRW-GP may be monitored by
evaluating FD (β; ρ, θ) at every iteration. This value is
guaranteed to decrease and converge to the optimum
of FD (β; ρ, θ) which is identical to the optimum of
F (µ; ρ, θ). We can thus observe the rate at which the
different algorithms converge to their joint optimum.
To study the convergence rate of the two algorithms, we used an Ising model on a 10 × 10 grid
with interaction parameters θij drawn uniformly from
[−αI , αI ] and field parameters θi drawn uniformly
from
[−αF , αFP]. The MRF is given by p(x; θ) ∝
P
θij xi xj + i∈V θi xi
ij∈E
e
where xi ∈ {+1, −1}. We
used a uniform distribution over directed spanning
trees calculated as in [11].
Figure 2 (left) shows an example run where the undamped TRW-MP algorithm does not converge, but
the TRW-GP and the damped TRW-MP do converge,
and do so roughly at the same rate. Figure 2 (right)
shows an example where both TRW-MP algorithms
converge and do so at a faster rate than TRW-GP.
We experimented with various values of αF and αI
and have observed that at lower interaction levels (e.g.,
αI ≤ 4 for αF = 1) the TRW-MP algorithms outperform TRW-GP, whereas for higher interaction levels
the undamped TRW-MP does not converge, but the
damped version converges at roughly the same rate as
TRW-GP. We also experimented with conjugate gradient minimization of FD (β; ρ, θ), but these did not
yield better rates than TRW-GP.

10

Conclusions

We presented a novel message passing algorithm whose
updates yield a monotone improvement on the dual of
the TRW free energy minimization problem. In order
to obtain a closed form dual we used two tricks. The
first was to decouple different entropies that depend on
the same marginals by introducing multiple copies of
these marginals. The second was to use uni-directional
consistency constraints, so that every copy of a joint
marginal appears in a single consistency constraint.
Although we presented the method in the context of
tree decompositions, the algorithm itself still applies
as long as ρi|j and ρ◦i are non-negative (although the
upper bound on the log partition function may not be
guaranteed in this case).
The TRW-GP algorithm resolves the convergence
problems with the undamped TRW-MP algorithm.
However, we observed empirically that the damped
TRW-MP algorithm always converges, and typically at
a better rate than TRW-GP. Thus, the main contribution of the current paper is in introducing a dual framework for message passing algorithms, which could be
used to analyze existing algorithms, and possibly develop faster variants in the future.
Free energies may be defined using marginals of more
than two variables [13, 16]. In a recent paper [6]
we study the relation between such free energies and
GP. It will be worthwhile to study generalizations of
TRW-GP to this case. Another interesting extension is
to the MAP problem, where the corresponding variational problem is a linear program. Global convergence
results for MAP message passing algorithms such as
max-product are also hard to obtain in the general
case. It turns out that an approach similar to the one
presented here may be used to obtained convergent
algorithms to solve the MAP linear program. These
algorithms will be presented elsewhere.

