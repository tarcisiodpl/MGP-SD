

A new probabilistic network construction
system, DYNASTY, is proposed for diagnos­
tic reasoning given variables whose probabil­
ities change over time. Diagnostic reason­
ing is formulated as a sequential stochastic
process, and is modeled using influence dia­
grams. Given a set 0 of observations, DY­
NASTY creates an influence diagram in or­
der to devise the best action given 0. Sensi­
tivity analyses are conducted to determine if
the best network has been created, given the
uncertainty in network parameters and topol­
ogy. DYNASTY uses an equivalence class ap­
proach to provide decision thresholds for the
sensitivity analysis. This equivalence-class
approach to diagnostic reasoning differenti­
ates diagnoses only if the required actions are
different. A set of network-topology updat­
ing algorithms are proposed for dynamically
updating the network when necessary.
1

INTRODUCTION

The development of graphical representations for prob­
abilistic models (e.g. belief networks [Pearl, 1988],
influence diagrams (Howard and Matheson, 1981;
Shachter, 1986; Shachter, 1988)) has enabled effi­
cient probabilistic models to be developed for many
tasks, such as diagnostic reasoning (Pearl, 1988; Heck­
erman and Horvitz, 1990], natural language analy­
sis(Goldman and Charniak, 1990], etc. These represen­
tations, by specifying the causal relationships among
variables in a causal graph (and not all possible rela­
tionships), facilitate efficient inference. A great deal of
the recent research in automated probabilistic reason­
ing has focused on developing more efficient and more
general algorithms for causal probabilistic models, and
on methods for incrementally constructing belief net­
works.
However, the application of these techniques and rep-

resentations to complex diagnostic tasks, such as med­
ical diagnosis, have oversimplified such tasks. A com­
mon simplification made in many current approaches
is modeling the diagnostic process as a single-stage,
static process. This is inadequate, as diagnostic rea­
soning is a sequential, dynamic process in which feed­
back is important. Provan and Poole (1991] point out
the necessity of considering this complete process, and
in particular, the effects of feedback.
This paper exteJ;Jds existing diagnostic models to incor­
porate the dynamic and sequential nature of diagnos­
tic reasoning. It proposes techniques for constructing
sequential belief networks, and of dynamically updat­
ing such networks. Many existing techniques for con­
structing belief networks (e.g. (Goldman and Char­
niak, 1990; Heckerman and Horvitz, 1990]) model the
process for one instant of time.1 For certain tasks this
is adequate, but for tasks in which the probabilistic re­
lationships among variables changes over time, it can
be difficult to know when the best model has been con­
structed. This sometimes produces incorrect answers
due to the selection of incorrect probabilities and/or
causal relationships. Hence, both the diagnosis and
the decision taken given this diagnosis may hinge on
whether the best model has been constructed, given
the data at a particular time t. Sensitivity analyses
may be used to test how the data at different times af­
fects the best decision. If the sensitivity analyses show
that a better decision would be made under an alter­
native model, then the model needs to be updated. It
is these sensitivity analyses and model updating tech­
niques that are of interest here. Criteria are proposed
to determine when network topology revisions are nec­
essary given time-varying probabilistic and causal re­
lationships. These criteria are based on examining
the equivalence of outcomes (e.g. treatments for dis­
eases). Algorithms for conducting the necessary revi­
sions are outlined, including refinement and coarsening
techniques (Chang and Fung, 1990], and other network
1This is true even for systems in which the mode], can
be constructed incrementally, e.g. [Goldman and Char­
niak, 1990).

280

Provan

revision algorithms [Pearl, 1988; Srinivas and Breese,
1990]..
This approach makes dynamic network updating pos­
sible, and formalizes the sequential nature of diagnos­
tic reasoning (e.g. to allow feedback into the network).
The explicit introduction of utilities into diagnostic
models2 allows a more realistic formalization of the
diagnostic process. In addition, it is expected that the
techniques developed for diagnostic reasoning m<ty be
applied to other domains, where appropriate.
2

Figure 1: Change over time of likelihood ratio for the
occurrence of Right-Lower-Quadrant pain given a di­
agnosis of appendicitis
P( symptoms !appendicitis)
P( symptoms 1-.appendicttis)

DYNAMICS OF DIAGNOSTIC
REASONING UNDER
UNCERTAINTY

Treating a diagnostic task as being time-independent
can lead to incorrect results in certain domains. Con­
sider medical diagnosis, and in particular the diagnosis
of abdominal pain. Constructing a model for the ob­
servation of abdominal pain should not be done for
a single time interval, since, as noted in [Schwartz et
a/., 1986], many symptoms take on different meanings
as diseases evolve over time, both in terms of their
inter-relationships and the diseases indicated by the
particular symptoms. In a possible case of appendici­
tis, the initial symptoms include non-specific abdom­
inal pain (which could be confused with many other
ailments), and are often accompanied soon thereafter
by gastrointestinal distress and possibly by anorexia
and fever. This pain subsequently becomes localized
to the right lower quadrant (RLQ) of the abdomen
(which then provides a strong indication of appendici­
tis, along with a high white blood count). If the ap­
pendix ruptures, then there are several more symp­
toms; however, a perforated appendix leads to serious
internal complications.3 Given the evolution of a dis­
ease such as appendicitis, the probabilities assigned to
network nodes, and even the topology of the network
itself, must change over time. For example, Figure
1 shows how the likelihood ratio for the diagnosis of
appendicitis might change over time. Clearly, in the
initial stages of appendicitis, many other diagnoses are
equally likely given the symptoms.
A second aspect of this dynamic nature of (diagnostic)
reasoning is the need for modeling the temporal order
of observations. In some cases the temporal sequence
of observations (as opposed to just an unordered list
of the set of observations) can provide strong cues for
a diagnosis. For example, if a woman has abdominal
pain, noting whether this pain is immediately followed
by gastrointestinal distress could help identify a pos2 Utility considerations have been ignored in most formal
models of diagnostic reasoning, except for approaches such
as [Heckerman and Horvitz, 1990].
3Most diagnostic procedures attempt to avoid perfora­
tion and its resulting complications.

Time

sible case of appendicitis, whereas the absence of such
immediate distress would make the presence of a gono­
horreal cyst in the right fallopian tub<' more likely. A
second example is the diagnosis of a car which has
trouble starting. The sequence of events leading to
the inability to start can help identify the problem.
Thus, the inability to start only on mornings after it
has rained may indicate that moisture is getting under
the distributor cap.
A third aspect is the ability to incorporate the effects
of feedback. Feedback can alter not only the proba­
bility assignments to a network, but also the topol­
ogy of the network. For example, consider a network
constructed for a case of RLQ abdominal distress. If
simple stomach upset is diagnosed, and a treatment
of Diovol is administered, the persistence of RLQ ab­
dominal distress will provide feedback to the system
that the diagnosis may be incorrect, and the network
topology and/or probabilities may need to be updated.
This paper proposes extensions to existing network
construction techniques to model diagnostic reasoning
as a sequential, dynamic process using the formalism of
influence diagrams. This proposal is not intended to be
a full temporal calculus based on Bayesian networks, as
discussed in [Kanazawa, 1991], for example. Instead,
it attempts to build simple networks which will real­
istically model the dynamics of diagnostic reasoning
without necessitating the complicated (and computa­
tionally costly) construction and solution of temporal
Bayesian networks.
3

SYSTEM ARCHITECTURE

There are many existing systems and theories for
model construction. Examples of such n<>twork con­
struction frameworks include the proposal of Lf'hmann
[1990], and examples of such systems include Q.\!R­
DT [Shwe and Cooper, 1990] and FRAIL3 [Goldman
and Charniak, 1990]. In each of these proposals, the

Dynamic Network Updating Techniques for Diagnostic Reasoning

goal is to construct a model which completely charac­
terizes the data. However, this goal conflicts with the
need for efficient performance of implemented systems.
Solving Bayesian network models is NP-hard [Cooper,
1990], so the networks constructed must be as small as
possible to ensure efficiency. The proposal presented
in this paper trades off (to some extent) completeness
and accuracy for efficiency, as is done in many other
systems, such as [Heckerman and Horvitz, 1990).4

Figure 2:
NASTY

.�

;
Sensitivity
Analysis

The remainder of the paper discusses the algorithms
used to create an influence diagram from the KB, and
for dynamically altering this influence diagram.

4The appropriate balance of resources between meta­
analysis of model construction and model solution has been
studied by [Horvitz et al., 1989; Breese and Horvitz, 1990].
As an example, the QMR-DT network represents
diseases, 4040 manifestations and 40,740 disease­
manifestation arcs [Heckerman and Horvitz, 1990].
5

534

Heuristics

I

Select
"Best"
Diagnosis

The KB for DYNASTY consists of a network of nodes
and arcs. Nodes represent state variables, and arcs
exist between pairs of nodes related causally and/or
temporally.

Within the general model-construction framework
(such as that described in Lehmann ( 1990)), there is al­
ways uncertainty in choosing the correct model. That
uncertainty may be due to uncertainty in the instru­
ments used to record data, to noise, or to the rela­
tionship between data from observations and causes
for the observations (e.g. the diseases causing the ob­
served symptoms). This paper examines the uncer­
tainty arising from relating observations and causes,
and in particular the temporal uncertainty of this re­
lationship.

l

Influence
Diagram
Model

l

Like several existing network construction methods
(e.g. QMR-DT, FRAIL3), we start with a Knowl­
edge Base (KB) containing (1) causal rules, and (2)
a set of conditional probability tables. From this KB
a network is constructed to solve a given task.

Typically, the complete KB for a given domain is quite
large,5 and given a set 0 of observations, it is necessary
to construct a network containing only the data related
to 0 (and not the entire KB).

DY­

m

KB

A new system architecture proposed to model dynamic
reasoning tasks is depicted in Figure 2. This system is
called DYNASTY, for DYnamic Network Analysis of
System TopologY.

Associated with the network are probability tables for
the conditional probabilities for the network, such as
those required for the construction of a Bayesian net­
work. In addition, utility values are stored for decision­
making.

Network construction methods

4

MODEL CONSTRUCTION
HEURISTICS

4.1

Time Dependence

As noted earlier, diagnostic tasks whose characteristics
change over time have not been modeled in earlier ap­
proaches. The approach taken in DYNASTY is to dis­
cretize the possible times from which the observations
could have occurred. Call 'D,, the network (consisting
of causes and intermediate causes/observations) which
would need to be constructed at time t;. In full gener­
ality, the networks at different times are different, and
they can each be quite large for complicated tasks.
To fully model a diagnostic task, an influence diagram
(ID) containing sub-networks for each time I; would
need to be constructed, given a set 0 of observations.
This is shown in Figure 3.

Figure 3: Most general influence diagram for solving
a stochastic diagnostic task

281

282

Provan

DYNASTY attempts to solve a simplified task: it cre­
ates a network for particular time tj, and then con­
ducts a sensitivity analysis to determine if the action
taken is affected by the choice of time tj. The ID which
would be constructed is shown in Figure 4.
Figure 4: Simplified influence diagram for solving a
stochastic diagnostic task

However, these observations may actually be indica­
tive of the early stages of appendicitis. To make sure
that a possible case of appendicitis might be diag­
nosed, the ID shown in Figure 7 must be constructed.
This ID bears little relation to the ID shown in Fig­
ure 6. The possible treatments include: (1) emetic (for
Figure 7: More complex influence diagram for abdom­
inal pain example

Example 1

Consider the time course of a possible
case of appendicitis. Early in the course of appen­
dicitis, the symptoms could appear to be a simple up­
set stomach. Figure 5 shows the notation necessary
Figure 5: Notation for constructing Abdominal Pain
Influence Diagram
OBSERVATIONS
or

P

N
F

:

HYPOTHESES

=

anorexia
nausea
=: fever
abdominal pain
:

LLQ

_

LLQ pain

RLQ

:

RLQ pain

A
US
FP
GC

::

::

=:

:=

appendicitis
upset stomach
food poisoning

gonohorreal cyst

to construct IDs for this task. If the observations are
nausea and general abdominal pain, then the simple ID
shown in Figure 6 may be constructed. This is an easy
influence diagram to construct and solve. Given an ID

food poisoning), (2) Diovol (for simple upset stomach),
(3) removal of appendix (for appendicitis), or (4) treat­
ment or removal of gonohorreal cyst.
This example shows how, given a set of observations,
uncertainty in the time course of possible diseases may
require entirely different IDs. "'
There are a number of heuristics used in DYNASTY
for network construction. One heuristic is the use of
temporal orderings for probability assignments. This
heuristic is best demonstrated by an example. Con­
sider the diagnosis of a car which infrequently has
problems starting. The two diagnoses under consid­
eration are a distributor cap problem (DC) or an al­
ternator problem (ALT). The weather (Vi') may affect
the diagnosis, as wet conditions can cause condensa­
tion under a distributor....£!!:J>, thereby causing the fail­
ure of the car to start (ST). Other possible causes of
the problems in starting, e.g. the alternator may be
faulty and not recharging the battery, are not affected
by weather conditions. A simple Bayes network for
this problem is shown in Figure 8. Knowledge of the

Figure 6: Simple influence diagram for abdominal pain
example
Figure 8: Bayesian network model for determining the
cause of the failure of a car to start

such as this, the possible treatments are the adminis­
tration of an emetic (for food poisoning) or Diovol (for
simple upset stomach).

history of the correlation between weather conditions

Dynamic Network Updating Techniques for Diagnostic Reasoning

and success in starting the car can significantly affect
the probabilities assigned to the network. For exam­
ple, if the car only gives trouble starting in wet con­
ditions, then the problem is most likely DC; if the car
gives trouble with equal probability in both wet and
dry conditions, then the problem is most likely ALT.
In fact, trouble in a single instance when the weather
is dry will lead to the assignment of a low probabil­
ity to P(DCIST, W). In this case, the history of the
problem is crucial to the probability assignment.
Hence, the history heuristic is the use of temporal his­
tory, whenever possible, in selecting the probabilities
(from the probability tables) to be assigned to the net­
work in consideration. The temporal history is com­
puted simply by tracing the history for a node in the
KB, using revised Truth Maintenance algorithms for
computing the justifications for a node in a depen­
dency network [McAllester, 1990]. The history heuris­
tic also uses triggers to guide probability assignments.
For example, finding a single instance when the car
won't start in dry conditions is a tri� to the assign­
ment of a low probability to P(DCIST, W).
4.2

Sequential Diagnostic Process

The ID framework also allows diagnostic reasoning to
be formulated as a sequential diagnostic process. Us­
ing a result of Tatman and Shachter [ 1990], an ID can
model a sequential process using dynamic program­
ming, provided that the value function Vis separable.
In terms of IDs, a value node is separable if it can
be represented as the sum or product of multiple sub­
value nodes.
Value node separability has been exploited in the de­
sign of a sequential process for image understanding
[Levitt et al., 1990]. In a similar manner, value node
separability is used to model the sequential nature of
diagnostic reasoning. In brief, the decision nodes in
a DYNASTY ID are called treatments, which may be
tests to determine more observations, or actual treat­
ments for hypothesized diseases. In the former case,
given an ID shown in Figure 6, the test T can deter­
mine a new observation 0', creating a new ID with
another decisit>t. node T' (e.g. another test or a treat­
ment) and another value node V'. In this manner,
the sequential nature of tests (or treatments) providing
feedback to the diagnostic process can be modeled. 6
5
5.1

MODEL UPDATING
Overview

In a problem for which probabilities are temporally
dependent, the sensitivity of the computed decisions
6Please refer to [Provan, 1991 ( forthcoming )] for more
details. The presentation here is brief due to space
limitations.

to the temporally-dependent probabilities must be
tested. This provides a threshold for determining when
a better model is warranted. This may require new
probability values (corresponding to a new time t'), or
a new network topology corresponding to time t'.
This sensitivity analysis/model updating in DY­
NASTY occurs in two stages:
F irst, a sensitivity analysis is
conducted to determine if data from time t' pro­
vides a better model than the data from time t.

Sensitivity Analysis

If the network model needs to be
updated, then some of the following processes may
need to be invoked:

Model Updating

I.

New probability values are assigned and
propagated to compute a new network equi­
librium state.
2. Network topology is altered.
3. A new model is built for a different time t'.
These processes are now discussed in greater detail.
5.2

Equivalence Class Sensitivity Analysis

Given the construction of an ID model at time t, a deci­
sion (with accompanying diagnosis) of maximal utility
is computed. For example, in the car diagnosis ex­
ample, the diagnosis might be DC, and the decision
REPLACE-DC. This decision would maximise the re­
quirement of ensuring that the car no longer has trou­
ble starting.
In the process of computing this best decision, the
next-best decision for a different equivalence class is
also recorded. In the car example, this is REPLACE­
ALT. If there is uncertainty concerning which proba­
bilities are correct, then the sensitivity of the decision
to this uncertainty must be determined. This is for­
malised in terms of equivalence classes of decisions as
follows.
5.2.1

Analysis of Equivalence Class es

The equivalence class approach to diagnosis, as origi­
nally formulated in [Provan and Poole, 1991], is sum­
marised here. The rationale is that there is no point in
distinguishing between decision-equivalent diagnoses,
i.e. diagnoses for which the decision taken (e.g. ad­
ministration of drugs to a patient) are the same; as far
as the decision-maker is concerned decision-equivalent
diagnoses should be considered as the same diagnosis.
The aim of diagnostic reasoning is to provide a treat­
ment for a set of observations. From an equivalence­
class point of view, this reduces to refining the set
of use-equivalent possibilities; i.e. one does not care
about distinct diagnoses, but distinct treatments (and
their associated distinct equivalence classes). Thus,

283

284

Provan

use-equivalence induces a partition on the set of diag­
noses, where each partition corresponds to a possible
distinct decision.
Let T be the set of all treatments (or decisions). 7 Let
V be the set of all possible diagnoses.
Definition 5.1 The possible treatment space P
is a subset of Vx T. (D, T) E P means that T is a
possible treatment given that the diagnosis is D E V.

P induces an equivalence relation on the set of diag­
noses. This will be called strong equivalence with re­
spect to P. The idea is that equivalent diagnoses have
the same set of possible treatments.8

and D2 are
to P, written
P if and only if

D1

Definition 5.2 Two diagnoses
strongly equivalent with respect

D1

""P

Dz

if V T

P.

E

T,

(D1,T)

E

(D2, T)

E

5.2.2

Equivalence Class Decision-making

We assume we have a measure p(D,T) of the utility of
treatment T given diagnosis D. We can define the pos­
sible treatment space as the set of diagnoses with the
same utility.9 In this case, "strong use-equivalence"
means having the same utility for each treatment.
Let V be the set of use-diagnoses. For D E V, every
logical model of D has the same utility measure. The
following proposition about the expected value, £(T),
of treatment T was proven in (Provan and Poole, 1991]:
£(T) =

L p(D, T) p(D).
X

(1)

DEV

Under this approach to diagnostic reasoning, diagnoses
are selected such that the expected utility of the treat­
ment is maximised. That is, the goal is to compute 'Yi
such that the expected value of the treatment given by
equation 1 is maximised.
Consider an ID in which the variables are denoted by
X= {x1,.... ,xn}, such that any diagnosis D consists
of a subset of variables X' C X which are not func­
tioning normally (cf. (de J(leer et a/., 1990; Pearl,
1988; Provan and Poole, 1991] for a further descrip­
tion of such diagnostic models). Then equation 1 can
7By a treatment we mean a total prescription of what
to do (i.e., we do not conjoin different treatments - the
conjunction would be one treatment). A treatment may
be a test to distinguish abnormalities, the administration
of drugs, replacement of circuit components, etc.
80ther types of equivalences, e.g. weak equivalence, are
also distinguished in [Provan and Poole, 1991]; such cases
are not discussed here due to space limitations.
9Formally, the treatment in the possible treatment
space would be a pair (T, v) where (D, (T, v)) E P if
I'(D, T) = v.

be rewritten in terms of these variables as
f[TJ=

L LJI.(x,T)xp(x),

(2)

DEV Dl=x

where JI.(x, T) is the value of
true in D.

p(D,T) such

that

x is

The notion behind the sensitivity analysis is as fol­
lows: consider a model constructed at time t, such
that decision T; is the optimal treatment. Call f3 the
expected utility for decision T;. If the probabilities of
certain variables are time-dependent, then these new
probabilities need to be substituted into the model to
check if the decision would change. Note that differ­
ent diagnoses may be computed, but if the decision is
unchanged, then, under this use-equivalent approach,
no network updating is necessary. For network updat­
ing to be necessary, the threshold f3 must be exceeded
by the expected utility of another treatment Tj given
probabilities for timet', i.e.

[

f(Tj] =

]

L L p(x,T)xp(x)

DEV DFX

>

f].

This provides a precise bound on when the treatment
changes. When the threshold is exceeded, then net­
work alterations may be necessary. These updating
methods are now summarised.
5.3

Model Updating Techniques

There are several types of model updating operations,
of which two of the most important are: (1) probability
value updating, and (2) network topology updating.
These are discussed in turn.
5.3.1

Probability Value Updating

This is the simple case of network upd ati n g. If no
changes to the network topology are required when
the model is updated from time t to t', then the re­
quired alterations to the probability values are made,
and these values are propagated to obtain a new net­
work equilibrium state.
For example, during the early stages of appendicitis
diagnosis, probability values may need to be updated
given changes in location of abdominal pain. Possible
changes in probability assignments are shown in Figure
9(b),(c).
5.3.2

Network Topology Updating

Consider the onset of an entirely new set of symptoms
in the observation of a patient with a possible case of
the later stages of appendicitis. These are shown in
F igure 7. If we started with the model in Figure 6,
we see that the topology of the network needs to be
altered.

Dynamic Network Updating Techniques for Diagnostic Reasoning

vides a set of constraints on how M(x) must be
altered. In an analogous manner, constraints can
be defined for the coarsening of the values of the
state space of variable x, flx, where multiple val­
ues of Wx E rlx are combined into a single value
w� E C(wx)·
The coarsening operation is defined similarly
[Chang and Fung, 1990]. The coarsening oper­
ation may lose information during the process
of node aggregation (i.e. the network proba­
bility assignments may be altered). Using the
equivalence-class approach, such information loss
is acceptable if the equivalence class does not
change. Otherwise, approximations may need to
be used [Chang and Fung, 1990].

F igure 9: Early stages of the diagnosis of appendicitis

(a)

(b)

(c)

If changes to the network topology are required when
the model is updated from time t to t', then one of
several algorithms may be used. These algorithms in­
clude:
Refinement/coarsening
operations [Chang and Fung, 1990] are used to
split/merge network nodes respectively. Consider
a network refinement necessary to include new al­
ternatives. For example, in abdominal diagnosis,
the construction of a network which models only
lower abdominal pain may need to be refined to
differentiate right-lower quadrant (RLQ) and left­
lower quadrant (LLQ) pain. Hence, a node mod­
eling lower abdominal pain needs to be split into
nodes for RLQ and LLQ (cf. Figures 9(a),(b)).
Or in the car diagnosis example, the single node
for weather may need to be split into nodes for
wet weather and mixed (wet and dry) weather.
The network changes made for the refine­
ment/coarsening operations are local, and do not
involve all nodes in the network. This is for­
malised as follows. If x is a state node, then
we call lix the predecessors of x in the network,
and I:x the successors of x in the network. The
Markov boundary of x is the minimal set of nodes
which "shield" x from the rest of the network.
The Markov boundary M(x) of node x consists
of lix U I:x U liE,. Hence, ensuring the joint prob­
ability distribution of M(x) is unaffected by the
refinement/coarsening or x ensures that the rest
of the network will be unaffected as well.
For example, it is shown in [Chang and Fung,
1990] that in a refinement of the values of the
state space of variable x, flx, each value Wx E rlx
is refined into multiple values w� E R(wx)· For
each value Wx E rlx which is refined into a value
w� E R(wx),

Refinement/ coarsening

p(I:x lwx, liE, )p(Wx, lix)

2::::

p(I:xlw�, liE.)p(w�, lix) (3)

w�ER(wx)

must be satisfied for all values of lix. This pro-

Instead of splitting and/or
merging existing nodes, completely new nodes
may need to be added to, or particular nodes
deleted from, the network. In such cases a va­
riety of other algorithms are invoked, such as
the reduction and clustering algorithms present
in the IDEAL system algorithm library [Srinivas
and Breese, 1990]. In network addition, the KB
is consulted to determine which nodes must be
added based on causal relationships.
Network Re-instantiation It may turn out that
the network created is inappropriate for the diag­
nostic task. For example, a simple network may
be created which cannot be appropriately aug­
mented to model a more complicated case10 In
such a situation, a completely new network is con­
structed from the KB.
Network additions

5.4

Implementation

The KB is implemented in Common Lisp. Extended
Justification-based TMS (e.g. [McAllester, 1990]) data
structures and algorithms are used for determining
relevant nodes to instantiate given a set of observa­
tions. The inti uence diagrams are implemented using
the IDEAL system [Srinivas and Breese, 1990].
It is hoped that the TraumAID system [\Yeb her et
a/., 1990] will be used as a test-bed for this system.
TraumAID is a decision support tool for the manage­
ment of multiple trauma. Trauma management in­
cludes both diagnosis and treatment, and this diagnos­
tic tool achieves these features using two modules: (1)
a rule-based reasoner which models the relationships
between clinical evidence and diagnostic/therapeutic
goals, and (2) a planner which manages the achieve­
ment of multiple goals. TraumAID is an excellent sys­
tem on which to test the theoretical results because,
unlike most similar systems, it already contains a no101f radical changes must be made to an initial network,
it can be computationally cheaper to create a new net­
work from scratch than to alter the original network using
coarsening/refinement operations.

285

286

Provan

tion of sequential action and change, key elements of
the proposed theory of diagnostic reasoning. Further,
efficient incremental management of action and change
is necessary for trauma management.
6

This paper has described a proposed dynamic network
construction system which can build models for prob­
lems with temporally-dependent probabilities. Heuris­
tics are used to identify the best possible model, and
to test the sensitivity of this model to probability val­
ues over time. Given the network updating capabil­
ities of DYNASTY, the full diagnostic cycle, which
includes feedback from the decisions made, can be in­
corporated into the network. In addition, the ability
to refine/coarsen the network enables different levels
of granularity (i.e. the coarseness of the description of
the system being modeled) to be examined during the
diagnostic process. Most other approaches to diagnos­
tic reasoning (e.g. [de Kleer et a/., 1990]) have no way
of dynamically altering the granularity of the system
description.
Future work includes testing the feasibility of the al­
gorithms in DYNASTY on real-world problems, and
extending and optimising these algorithms. The KB
for the TraumAID system is the first set of real data
for which such tests are proposed.
ACKNOWLEDGEMENTS: The comments of the
anonymous reviewers have led to improvements in the
paper.

[Breese

and Horvitz, 1990] J. Breese and E. Horvitz. Ideal
Reformulation of Belief Networks. In Proc. Con/. Un­
certainty in Artificial Intelligence, pages 64-72, 1990.
Fung,

K.

Chang and R. Fung.

Re­
finement and Coarsening of Bayesian Networks. In

1990]

Proc. Conf. Uncertainty
pages 475-482, 1990.

in Artificial Intelligence,

[Cooper, 1990]

G.F. Cooper. The Computational Com­
plexity of Probabilistic Inference Using Belief Net­
works. Artificial Intelligence,

Kleer et al.,

1990]

(42):393-405, 1990.

J. de Kleer, A. Mackworth, and R.

Reiter. Characterizing Diagnoses.
pages 324-330, 1990.

In Proc. AAAI,

and Charniak, 1990] R. Goldman and E. Char­
niak.
Dynamic Construction of Belief Networks.
In Proc. Conf. Uncertainty in Artificial Intelligence,

90-97, 1990.

[ Heckerman

and Horvitz,

Horvitz.

et a/.,

erman.

720-762,

Strategic Decisions

K. Kanazawa. Logic and Time Nets for

Probabilistic Inference. In Proc. AAAI,

[Lehmann, 1990]

H.P. Lehmann.

A

1991.

Decision-Analytic

Model for Using Scientific Data. In M. Henrion, R.
Shachter, L. Kana!, and J. Lemmer, editors, Un­
certainty in Artificial Intelligence 5, pages
North Holland, 1990.

[Levitt

et a/.,

1990]

309-318,

T. Levitt, J.M. Agosta, and T. Bin­

ford. Model-Based Influence Diagrams for Machine
Vision. In M. Henrion, R. Shachter, L. Kana!, and J.
Lemmer, editors, Uncertainty in Artificial Intelligence

5, North Holland,

[McAllester, 1990]

1990.

D. McAllester. Truth Maintenance. In

Proc. AAAI, pages

[Pearl, 1988]

J. Pearl.

1109-1115, 1990.
Probabilistic Reasoning in Intelli­

gent Systems. Morgan Kaufmann,

1988.

[Provan, 1991 ( forthcoming)]

G.M. Provan. A Decision­
Theoretic Approach to Diagnostic Reasoning. 1991

(forthcoming) .
[Provan and Poole, 1991]

G. M. Provan and D. Poole. A
Utility-Based Analysis of Consistency-Based Diagno­

sis. In Proc. Conf. on Knowledge Representation,
pages 461-472, 1991.

[Schwartz

et al., 1986] S. Schwartz, J. Baron, and J.
Clarke. A Causal Bayesian Model for the Diagno­
sis of Appendicitis. In L. Kana! and Lemmer J., edi­

1990]

D.

Heckerman

and

E.

Problem Formulation as the Reduction of

1989]

[Shachter, 1986]

R. Shachter. Evaluating Influence Dia­
grams. Operati ons Research, 34:871-882, 1986.

[Shachter, 1988]

R. Shachter. Probabilistic Inference and

Influence Diagrams.

Operati ons Research,

36:589-

604, 1988.

[Shwe and

Cooper,

1990]

M. Shwe and G.F. Cooper. An

Empirical Analysis of Likelihood-Weighting Simula­
tion on a Large, Multiply-Connected Belief Network.
In Proc. Conf. Uncertainty in Artificial Intelligence,
pages 498-508, 1990.

[Srinivas

and Breese,

1990]

S.

Srinivas

and

J.

Breese.

IDEAL: A Software Package for Analysis of Influence
Diagrams.

In Proc. Conf. Uncertainly in Artificial

212-219, 1990.

[Tatman and Shachter, 1990]
Dynamic

J. Tatman and R. Shachter.

Programming

and

Influence

Diagrams.

IEEE Trans. Systems, Man and Cybernetics,

20:365-

379, 1990.

a Decision Model. In Proc. Conf. Uncertainty in Ar­
tificial Intelligence, pages 82-89, 1990.

[Horvitz

[Kanazawa, 1991]

Intelligence, pages

[Goldman

pages

and Matheson, 1981] R.A. Howard and J.E.
Matheson. Influence diagrams. In R. Howard and J.
Matheson, editors, T he Principles and Applications of

tors, Proc. Conf. Uncertainty in Artificial Intelligence,
pages 229-236, 1986.

