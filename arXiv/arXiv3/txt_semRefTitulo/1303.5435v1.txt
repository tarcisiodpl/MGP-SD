
In a previous paper [Pearl and Verma, 1991]
we presented an algorithm for extracting
causal influences from independence informa­
tion, where a causal influence was defined as
the existence of a directed arc in all mini­
mal causal models consistent with the data.
In this paper we address the question of de­
ciding whether there exists a causal model
that explains ALL the observed dependencies
and independencies. Formally, given a list
M of conditional independence statements, it
is required to decide whether there exists a
direct e d acyclic graph (dag) D that is per­
fectly consistent with M, namely, every state­
ment in M, and no other, is reflected via d­
separation in D. We present and analyze an
effective algorithm that tests for the existence
of such a dag, and produces one, if it exists.

1

a sequence of local estimation analyses, each involv­
ing a variable and its parent set in the dag. Fourth,
general results are available for reading all implied
independencies directly off the dag [Verma, 1986],
[Pearl, 1988], [Lauritzen et al., 1990] and for deciding
from the topology of two given dags whether they
are equivalent, i.e., whether they specify the same
set of independence-restrictions on the joint distribu­
tion [Frydenberg, 1990], [Verma and Pearl, 1990], and
whether one dag specifies more restrictions than the
other [Pearl et al., 1989]1.

Introduction

Directed acyclic graphs ( dags) have been widely used
for modeling statistical data. Starting with the pio­
neering work of Sewal Wright [Wright, 1921] who in­
troduced path analysis to statistics, through the more
recent development of Bayesian networks and influence
diagrams, dag structures have served primarily for en­
coding causal influences between variables as well
between actions and variables.

as

Even statisticians who usually treat causality with ex­
treme caution, have found the structure of dags to
be an advantageous model for explanatory purposes.
N. Wermuth, for example, mentions several such ad­
vantages [Wermuth, 1991]. F irst, the dag describes a
stepwise stochastic process by which the data could
have been generated and in this sense it may even
"prove the basis for d�veloping causal explanations"
[Cox, 1992]. Second, e ach parameter in the dag has
a well understood meaning since it is a conditional
probability, i.e., it measures the probability of the re­
sponse variable given a particular configuration of the

This paper adds a fifth advantage to the list above.
It presents an algorithm which decides for an ar­
bitrary list of conditional independence statements
whether it defines a dag and, if it does, a correspond­
ing dag is drawn. The algorithm we present has its
basis in the "Inferred-Causation" (IC) algorithm de­
scribed in [Pearl and Verma, 1991] and in Lemmas
1 and 2 of [Verma and Pearl, 1990].
Whereas in
[Pearl and Verma, 1991] we were interested in detect­
ing local relationships that we called "genuine causal
influences", we now consider an entire dag as one unit
which ought to fit the data at hand.
1.1

Problem

Given a list M of conditional independence statements
ranging over a set of variables U it is required to decide
whether there exists a directed acyclic graph (dag) D
that is consistent with M.

Our analysis will focus on lists that are closed un­
der the graphoid axioms (see Appendix for definition).
Section 5 will discuss possible extensions to lists which
are not closed.
1The criterion for dag equivalence is given in Corol­
3.2.
It follows from Frydenberg's analysis of
chain graphs, which applies to strictly positive distribu­
tions.
The more direct analysis of Verma and Pearl
[Verma. and Pearl, 1990] renders the criterion applicable to
arbitrary distributions, as well as to non-probabilistic de­
pendencies of the graphoid type [Pearl a.nd Paz, 1986).

lary

324

Verma and Pearl

1.2

2

Definitions

A dependency model is a list of conditional indepen­
dence statements of the form I(A, BjC), where A, B
and C are disjoint subsets of some set of variables U.
A dag D is consistent with a dependency model M
if every statement in M and no statement outside M
follows from the topology of D. In this case, M is
said to be day-isomorphic. A statement I follows from
the topology of a dag D, if I holds in every proba­
bility distribution P that is compatible with D2 can
be decomposed into a product of conditional probabil ­
ities P(aj7r(a)), over all nodes a E U, where 1i'(a) is a
set containing the parents of a in D. Finally, a state­
ment I( A, BjC) holds in a probability distribution P
iff P(AjC)P(BjC) = P(ABjC).
The following definitions and notation are needed to
understand the proposed solution. A partially directed
acyclic graph (pdag) is a graph which contains both
directed and undirected edges, but it does not contain
any directed cycles. An extension of a pdag G, is any
fully directed acyclic graph, D, which has the same
skeleton (underlying undirected edges) as G and the
same vee structures as G. Three nodes form a vee

;bc, if a --+ b +--- c and a is not
adjacent to c. Two nodes are adjacent, written ab, if
either a - b, a +- b or a- b.
structure, written

1.3

Phase 1 examines the independence statements
in M an d tries to construct a pdag, G with the
following guarantees:

2. If Phase 1 fails to generate a pdng, then M
is not dag-isomorphic.

•

Phase 2 extends a pdag, G, into a dag D, if pos­
sible.
Phase

3 verifies

Generate a pdag G, from M, if possible.

(a, b), look through M
for a statement of the form I( a, bjS), where S is
any set of variables (including 0). Construct an
undirected gr aph G where vertices a an d b are
connected by an edge iff a statement I(a, blS) is
not found in M. Mark every pair of non-adjacent
nodes in G with the set S found in M, call this
set S(a, b).

1. For each pair of variables,

2. For every pair of non-adjacent nodes a and c in
G, test if there is a node b not in S(a, c) that is
adjacent to both a and c. If there is such a node
then direct the arcs a -+ b and c - b unless there
already exists a directed path from b to a or from
b to c, in which case Phase 1 FAILS.

3. If the orientation of Step 2 is completed then
Phase 1 SUCCEEDS, and returns a partially di­
rected graph, G.
Phase 2

Extend G into a dag, D, if possible.

C be

an empty stack and let D equal

G.

1. If M is dag-isomorphic then every extension
of G will be consistent with M.

•

Phase 1

1. Initially let

Overview

Section 2 details the solution to the problem posed in
Sectionl.l. It presents an algorithm which consists of
the following three phases.
•

The DAG Construction Algorithm

2. While D contains any undirected arcs repeat 2a,
2b and 2c:
(a) CloseD under the following four rules, if pos­
sible.

Rule

1: If a ---> b- c and
to c then direct b - c.

Rule 2: If

Rule 3: If

Rule 4: If

if D is consistent with M.

c-+

IfD i s found to b e consistent with M then M is dag­
isomorphic, by definition. If D is found to be incon­
sistent with M then M is not dag-isomorphic and (by
definition) no dag can be consistent with M.
Additional improvements to this algorithm and exten­
sions to the problem are discussed in Section 5.

2 Alternatively, such a. statement corresponds to
sepa.ra.tion condition in D [Pearl, 1988].

a

d­

a

is not adjacent

b
'\.c then a -+
a/'--

c.

then direct

then direct

b---> d.

a - b and

b.

(b) If the closure was successful, i.e. there are no
directed cycles or new vee structures, then:
•

IfD still contains any undirected arcs, se­
lect one and choose a direction for it, push
the arc and a copy of D onto the stack C
and continue the while loop (i.e. go back
to 2a).

•

If G contains no more undirected arcs,
then the while loop is completed, Phase 2
SUCCEEDS, and returns a directed
acyclic graph D.

Causal Explanation

(c) If the closure was unsuccessful, then discard
the current value of D and pop the most re­
cent copy off of the stack along with the se­
lected arc. Reverse the chosen direction of
the arc in D and continue the while loop (i.e.
go back to 2a).
Phase

3

Check if D is consistent with M.
1. Test that every statement I in M holds in D (us­
ing the d-separation criterion? .
2. Pick any total ordering of the nodes which agrees
with the directionality of the D and let Ua stand
for the set of nodes which precede a in this order­

ing. For every node a in D, test if the statement
I(a, Ua \ 7r(a)l7r(a)) is in M.
3. If both tests

are confirmed, EXIT with SUCCESS,
and return D; else, EXIT with FAIL.

3

Correctness

The if part guarantees that every dag D which has the
same skeleton and vee structures as D*, is consistent
with M. The first step of Phase 1 attempts to con­
struct this invariant skeleton if M is dag-isomorphic.
The arrowheads added in the second step identify the
invariant vee structures, again, ifM is dag-isomorphic.

Note however, that Step 2 of Phase 1 directs arcs im­
mediately upon finding one set S satisfying condition
2 of the lemma. This decision is correct due to the
following lemma:
Lemma 3.3
model }.f and

For any dag-isomorphic dependency

any three variables a, b and c forming a
s. t. I(a, ciS) E M and b ¢ S then
'V's I(a, ciS') EM implies b f/: S'.
chain

abc, if 3s

This lemma permits the use of the
orient the vee structures.

first

S found to

If M is not dag-isomorphic it would be possible for

Phase 1 to build a graph that is not a pdag if it weren't
for the failure condition in Step 2. The next example
illustrates a failure resulting from an application of
Phase 1 on a non-dag-isomorphic dependency model.

Example 3.4 Let U = {a, b, c, d} and M be the clo­
sure of the set {I(a, c[0), I(a, dl0), I(b, dl0)} under

Phase 1

symmetry4.

This phase examines M and generates a graph,
G subject to the above guarantees, if possible.
That is, if M is dag-isomorphic then every ex­
tension of G is consistent with M.
The cor­
rectness of Step 1 of this phase follows from
Lemma 3.1 [Verma, 1991][Verma and Pearl, 1990] (a
detailed proof of which is given in the ap­
pendix). This lemma is also the basis for the in­
ference algorithm developed by Spirtes and Glymour
[Spirtes and Glymour, 1991].
Lemma 3.1 Let M be any dag isomorphic depen­

dency model, a dag D is consistent with M iff the
following two conditions hold:
1.

ab in D iff'Vs, I(a,biS) f/: M.

2.

;bc in D iff abc and -,ac (using condition 1} in
D and Vs, if I(a, ciS) EM then b >t. S.

Corollary 3.2 Two dags are equivalent iff they share
the same set of links and same set of vee structures.

Step 1 of Phase 1 will construct the skeleton a-b-e-d,
and S(a,c) = S(a,d) = S(b,d) = 0. Since there is a
chain abc and -,ac and b >t. S(a, c) Step 2 could direct
a ---+ b
c. Similarly since bed and -,bd and c f/:
S(b, d), Step 2 could direct b---+ c ,_d.
•-

One of the two directions would be assigned first,
then upon attempting the second the algorithm would
FAIL.
Phase 2

The task of Ph ase 2 is to find a whether a pdag, G,
has any extensions and to find ()ne if such exists. This
is a purely graph theoretic task; it does not involve M.
To prove that this phase of the construction is correct,
it is sufficient to prove that each of the four rules is
sound, namely, that the orientation choices dictated
by these r u les never need to be revoked.
•

Rule 1: If a ---+ b- c and a is not adjacent to c
then direct b
c.
---+

The only-if portion of this lemma guarantees that:
1. If there exists some dag n• which is consistent
with M, then any dag D consistent with M must
have the same skeleton as n·.
2. Furthermore, every dag D, consistent with M
must have the same vee structures as D*.
3 A linear time algorithm for testing d-separation is re­

ported in [Geiger et a1.,

1990].

•

Directing b - c as b ,_ c would create a new vee
structure, ;bc, thus if there is a consistent exten­
sion it must contain b --+ c.
b
Rule 2: If /' '\. then a ---+c.
ct-- c

4Symmetry states that I(A, B]C) iff I(B, A]C). Unless
otherwise noted, dependency models are assumed to be
closed under symmetry since this is a trivial operation.

325

326

Verma and Pearl

Directing a - c as a ,_ c woul d create a dire cted
cycle, [abcaJ, thus if there is a consi stent extension
it must contain

•

Rule 3, If

a -+

•¢'

c.

then di'"''

b- d.

Directing b- d

as b ,_ d would imply that a - b
must be directed as a ----> b or else there would be
a d irected cycle, [adba]. Now if b- c is directed
as b -+ c then the re is a directed cycle, [bcdb],
and if it is d irect ed as b +- c then there is a new

vee structure, tibc. Thus if there is a consistent
extension it must contain b -+ d.

•

then direct a -+ b ....- c.

Rule 4: If

First , a - b must be directed as a

b or there
dab. If b- c is di­
-+

would be a new vee structure,
rected as b ----> c t hen c - d cannot be directed as
c-+ d or there would be a directed cycle, [cdabcJ.
M oreover , c- d cannot be directed as c - d or

Phase 3

The soundness of Step 1 follows from the definition
of co n sis tency ; it si mp ly checks if each and every
independence statement of M is represented in D.
The soundness of Step 2, n amely that testing only
statments of the form I(a, Ua \ i(a)li(a)) is suffi­
cient follows from the proof of the soundness of d­
se paration[ Verma, 1986].

Phase 1 can be completed in O(IMI +

b

a

bod
c

( a)

c

I

d

/'-.
f

e

(b)

Figure 1: Two pdags which cannot be extended.

Example 3.5 Consi der the graph of Figure l.a. Ini­
tially, no rules apply, so the algorithm would select an
arbitrary arc and direct it, without loss of generality
assume it directs a ---+ b. Now Rule 1 will apply twice,
directing b - c ----> d. However a third application to
infer d -+ a would produce a directed cycle. It is easy
to see that a cycle would result no matter which arc is

ini tially chosen and no matter what initial directional­
ity is assi gned . Thus this graph has no dag extension.
Example 3.6 Consi d er the graph of Figure Lb. Any
appli cation of Rule 1 to direct the arc c - d would
create a new vee structure. Hence this graph as well,
has no dag extension.

IUI2)

steps, as

follows:

Foll owing are two simple examples ofpdags which can­
not be extended into dags.

'-./

Complexity Analysis

4

there would be a new vee structure, bed. Thus if
there is a consistent extension, then it must con­
tain a-+ b- c .

a

3.7 Let U

= a,b,c and M = {I(a,bl0),
Phase 1 will produce an empty
graph which can trivially be extended into an empty
dag. But every ind ependence statement is true in an
empty dag, including, e.g. I(a, bic) which is not in M.
Thus M is not d ag isomorp hic .

Example

I(a, cl0), I(b, cl0)}.

•

Start with a complete graph G. For each st ate­
ment, I(A,BIS) in M, and for each pair of vari­
ables a E A, and b E B remove the links a- b
from G and define S(a, b)= S.

•

For each n ode a let
of neighbors of a.

•

For each separating set S(a, b) defined above, note
that C(a, b) = N(a) U N(b) \ S(a, b) must be chil­
dren of a and b so direct a-+ c- b Vc E C(a, b).

N(a)

=

{bla-b}

be the set

Phase 2 m ay appear to require an exponential amount
of ti me in the worst case due to possible backtrack­
ing in Ste p 2( c). However, we conjecture that if G is
extendible, then Rules 1-4 are sufficient to guarantee
that no choice will ever need to be revoked. Emp ir ical
studies have, so far, confirmed our conjecture. Fur­
ther m ore , [Verma, 1992] p resents an alternative algo­
rithm for Phase 2 based on the maximum cardinality
search developed by [Tarjau a nd Yannakakis, 1984],
and which is provably a linear-time algorithm. This
algorithm, however, is c onsider ably more complicated
and less intuitive than the one presente d here.
If the conjecture is correct, it would be po ssible to
repl ace the backtrack step with a definite failure, in
which case the time com p lexity of this phase would
be polynomial, no more than O(jUJ4 *lEI). On the
other hand, if it is not correct, the complexity could
be exponential in JEI.
Phase 3 can be completed

steps.
5

in

O(IMJ *lEI+ JMI *IUD

Extensions and Improvements

In general, the set of all independence statements
whi ch h old for a given d om ain will grow exp on ent iall y

Causal Explanation

as the number of variables grows. Thus it might be im­
practical to specify M by explicit enumeration of i ts !­
statements . In such cases it may be desirable , instead,
to specify a basis, L, such that M is th e logical closure
of L, (i.e. M = CL(L)), rel ati ve to some semantics,
(e.g. the graphoid axioms, correla ti onal graphoids ax­
ioms, or even probability the or y ).
The major difficulty in permitting the dependency
model to be specified as the closure of some basis lies
in solving the so called membership problem. Simply
stated, the problem is to decide if a particular state­
ment, 10, is contained in the closure , .M, of a given
list of statements, L. In general, membership prob­
lems are often undecidable, and of those that are de­
cidable, many are NP-hard. In particular, the mem­
bership problems for both graphoids and probabilistic
independence are unsolved [Geiger, 1990) .
However, in spite of this difficulty, it may still be pos­
sible to have an effic ient dag construction algorithm,
because the queries required are of a special form. The
algorithm makes four types of queries t o M:
1. "Is there any S

(Phase 1,

Step

1)

s uch

that I( a, biS)

E

CL(L)?"

E

CL(L)?"

2.

"Is bin any set S such t hat I(a, ciS)
(Phase 1, Step 2)

3.

"Is every statement in CL(L) represented
(Phase 3, Step 1)

4. "Is every statement
(Phase 3, Step 2)

represented i n Din

in

D?"

CL(L)?"

Another possible source for simplification is to note
D being tested in Step 2 of Phase 3 is not
dag, but the output of the construction
algorithm. While Example 3.7 demonstrates that it is
possible for D to contain !-statements which are not
in C L(L), it may still be the case that any such !­
statements must have either a certain form or some
other property that would simplify the membership
query.
that the dag
an a rbitra ry

Acknowledgement
We would like to thank P. Spirtes and A. Paz for many
useful discussions. This work was supported in part
by National Science Foundation grant #IRI-88-21444
and State of California MICRO grants #90-126 and
#90-127.

Appendix: Proof of Lemmas
Definition A.1 (d-separation) For any dag D, two
disjoint sets of nodes, X, Y are d-separated given
a third Z, written ID(X, YIZ), if and only if no path
between any node in X and any node in Y is activated
by the set Z.

A path is active given a set Z if and only if every
head to head node of the path is active given Z and
every other node of the path is not in Z.
A node is active given a set Z if and only if there is
a directed path from it to some element of Z.

In the case that M is assumed to be the graphoid clo­
sure of L, queries of type 1, 2 an d 3 are all manageable.
The queries for Phase 1 can b o th be quickly answered
due to the following lemma5:

The three equivalent terms Z-active, "active given Z"
and "activated by Z" are used interchangeably.

Lemma 5.1

Lelllma 3.1 Let M be any dag isomorphic dependency
model, a dag D is consistent with M iff the following
two conditions hold:

s.t.

lf3s s.t. I(a, biS)

I(aA, bBIC)

E

L

E

CL(L) then 3A,B,c

Remark: Note that this simplification is possible due
to the special form of t h e se queries, namely that a
and b are both singletons and any separating set will
suffice.

1.

ab in D if! \:Is, I( a, biS) >t M.

2.

;bc in D iff abc and •ac
I(a, ciS) E M then b fl. S.

qu er ies pose no particular problem since the
axioms of graphoids hold for d-separation. Thus it
is enough to check that each statement in L is rep­
resented in D to ensure that the every statement in
closure of L is repres ented in D.

Proof: There are three
th at the fi rst condition is

However, to check that each statement represented in
D is containe d in CL( L) it is necessary to make the I U I
membership queries explicated in Step 2 of Phase 3.
Although these statements have a special form, it is
yet unclear whether a lemma similar to 5.1 exits to
simplify these queries.

holds.

Type 3

5This lemma follows immediately from the form of the
graphoid axioms.

zn D and \:fs, if

basic parts to the proof, (1)
necessary for consistency, (2)
that the second condition is necessary, and ( 3 ) that
both conditions together are sufficient.
Part 1:

If D is consistent with M then Condition 1

Since D is consistent with M, independence in M is
i d enti cal to tha t in D, so it is enough to show that
two nodes a r e adjacent in D iff there is no way to d­
separate them.

327

328

Verma and Pearl

link between two adjacent nodes is a path which
cannot be deactivated, thus if ab then there could not
i ) EM.
be any set S s . t. I( a, hS

A

It remains to show that if there is no set S s.t.
I(a, bS
i ) E M then then a and b are adjacent. It suf­
fices to considerS= {x #a, b: xis an ancestor of a or
b}. Since, by assumption, a and b are not d-separated
by any set, it must be the case that I(a, biS) r¢. M thus
there must be a path p connecting a and b in D which
is active given S. Since p is S-active, every head to
head node on p must be in or have a descendent in
S. But by the definition of S, every node wh i ch has
a descendant in S must be in S as well. Thus every
head-to-head node on p must be in S. Every other
node on p is an ancestor of a, b or one of the head to
head nodes of the path. Hence every node on p must
be in S with the exception of a and b. Thus every
node of p, except a and b, must be a head-to-head
node. There are only three paths satisfying this con­
dition: a -+ b, a +- b and a ...... c +- b. However the
last case is not possible because c is in S so it must
be an ancestor of either a or b and thus it cannot be
common child of both a and b as well or there would
be a directed cycle. Hence a and b are adjacent.
Part 2 If D is consistent with M then Condition 2
holds.
If b is head-to-head in between a and c t hen the two
link path cannot be de-activated by any set containing
b. The rest of the only-if portion of condition 2 follows
trivially from the definition of a vee structure.
To complete the proof of Part 2, let abc be a chain
with ...,ac. Furthermore, assume that for any set S,
i ) E M implies b ¢. S. If b were not head­
I(a, hS
to-head on the path abc then any set S for which
I(a, ciS) E M would necessarily contain b in order to
deactivate this path. Since -,ac, there must be a such
an S, however by assumption for any such S, b r¢. S.
Thus b must be head-to-head on the p ath abc, hence
it must be the case that

;bc.

Part 3 If Conditions 1 and 2 hold then D is consistent
with M.
If M is dag isomorphic then there must exist a dag
which is consistent with M, call it D*. By Parts 1 and
2 above , D and D* have the same skeletons and vee
structures, so it is enough to prove Proposition A.2:
Proposition A.2 If any two dags, D and E, have the
same skeletons and vee structures then every active
path in one dag corresponds to an active path in the
other.
Let p be an S-active path in D which is minimal in
the following sense: if k is the number of nodes in p,

p1 is the first node and Pic is the last node then (1)
there cannot exist an S-active path b etween p1 and Pk

with strictly fewer than k nodes and (2) there cannot
exist a different S-active path fjJ between p1 and Pk
with exactly k nodes such that for all 1 < i < k, either
¢;= p; or ¢1 is a descendant of Pi.

Since D and E have the same links p must be a path
in E. It can be shown by induction on the number
of head-to-head nodes that p is S-active in E as well.
By definition, a single nodes will be considered as an
active path. The remainder of the proof has three
sub-parts: the first part proves that if p contains no
head-to-head nodes then it isS-active in E, the second
pa r t proves that if p contains at least one head-to-head
node x = Pi then p is S-active in E iff x is S-active in
E, and the third part proves that x is S-active in E.
Sub-Part 1:
If p does not contain any head-to-head nodes in

D

then it would be S-active in E unless it contains a
head-to-head node in E. It is enough to show that p
cannot have any head-to-head nodes in E. Suppose
that some node x = p; were head-to-head in E with
parents y = Pi-t and z = Pi+!, Figure 2 shows the
possible configurations for D.

D
PI . .. y ......
Pr · · · y +Pt · · · Y +-

Figure

2:

X ____, z

x ...... z

x +- z

E

. . . Pk

Pt .. . y ...... X +- z . . .Pk

· · · Pk
· Pic

· ·

D has no head-to-head nodes, but E does.

The parents of p; along p in E would be adjacent in
both D and E since the two graphs share links and
vee structures. But the sequence of nodes formed by
removing p; from p would be a path in D since its par­
ents would be adjacent. Moreover this path would be
5-active since it could contain no head-to-head nodes
(unless D cont ai ned a directed loop). But this path
would contradict Condition 1 of the minimality of p in
D. T herefore if p contains no head-to-head nodes in
D then it is S-active in E.
Sub-Part 2:

Suppose that p contains at least one head-to-head node
x = Pi in D with parents y = Pi-t and z = Pi+t as
shown in Figure 3. Let Pt,i-1 be the subpath of p be-

Pt . . .

Figure

3: D

D

y

____, X

-

z

.. . Pk

has some head-to-head nodes.

tween a and y and Pi+l,k be the subpath between z
and b. Note that i- 1 may equal 1 and/or i + 1 may
equal k, in which case the corresponding subpath(s)
would be a single node. Both PI and P2 are minimal
S-acti ve paths of D and both contain strictly fewer

Causal Explanation
head-to-head nodes than pthus by the inductive hy­
pothesis, they are 5-active in E. If y and z were adja­
cent in D then since both nodes are both 5-active in
D (they are parents of an 5-active node) and neith er
is in 5 (because neither is head-to-head on pin D),
it follows that the path formed by removing x from p
would be 5-active. This path which would contradict
Condition 1 of the minimality of p.
Therefore y and z cannot be adjacent in either gr aph
and must be common parents of x in both. Since x is
head-to-head on pin E and both the subpaths Pt,i-1
and Pi+I,!: are 5-active in E it follows that p would be
5-active in E iff x were 5-active in E.
Sub-Part 3:
Since x is 5-active in D there exists a directed path in
D from x to some node w in S. Let ,P be the shortest
such path. It remains to show (by induction on the
length l of¢) that ¢ is strictly directed from x to w in
E. There are three cases, either l:::: 0, I= 1 or l > 1.
If I= 0 then

x

=

w

and

x

is trivially S-active in E.

If 1 = 1 then ,P is a single link. Consider the parents,
y and z of x. If they were both adjacent to w as in

Pl

...y

D
....... X <--- z

'\.!/

4: A

. . .y --+

D
X ,_ z .

.. Pk

u

!

v

!
w

Figu re 5: A multiple link descendant path.
3.3 For any dag-isomorphic dependency
model M and any chain abc,
if3s s.t. I(a,ciS) EM and b tJ. S then V� I(a, ciS') E
M implies b r¢. S'.

Lemma

Proof: Suppose abc and 3s s.t. I( a, cfS)

E M and
b tJ. S. In order for S to d-separate a and c, it must be
the case that a---> b <--- c- if b were not head-to-head
then this two link path would be active given any set
not containing b. Now since b is head-to-head it must
be the case that any set S which contains b will activate
this two link path, hence for any 5 if I( a, biS) E M
D
then b r¢. S.

. . . Pk

w

Figure

Pl

single link descendant path.

Figure 4 then they would be common parents of w in
D (or there would be a directed loop in D). Thus
the sequence of nodes p' formed by replacing x with
w in p would be an S-active path in D.
This path
would contradict Condition 2 of the minimality of p,
so at least one parent of x must not be adjacent to w.
Without loss of generality, assume y is not adjacent
to w. Since y and w are not parents of x in D, they
cannot both be parents of x in E as the two graphs
share vee structures. Therefore x must be a parent of
w in E and x would be S-active in E.
If 1 > 1 then¢ contains at least two links. Consider the
last two links of¢, shown in Figure 5 whe r e u = ¢1-2,
v = </>r- 1. Note that l- 2 may equall in which case
x = u.
The initial subpath ¢1,1-t must be directed
from x to v by induction. If u were adjacent to w then
there would have been a shorter directed path from
x to w in D, thus u and w are not adjacent and not
parents of v in D so they cannot both be parents of v
in E. Therefore v must be a parent of w in E and ¢
D
is S-active in E.
Corollary 3.2 Two dags are equivalent iff they share
the same set of links and same set of vee structures.
Proof: This result follows directly from the proof of
D
the previous lemma.

Definition A.3

A graphoid is a dependency model
satisfying the following four axioms:
symmetry
decompo sition
weak union
contraction

I(X, YIZ)
¢>
I(Y, XIZ)
I(W,XYIZ) :::} I(W, YIZ)
I(W, XYIZ) :::} I(W, XIY Z)
I(W, YIZ) A I(W, XfYZ)
::;. I(W,XYIZ)

If3s s.t. I(a,bfS) E CL(L) then 3A,B,C
s.t. I(aA, bBIC) E L

Lemma 5.1

Proof: This can be proven by induction on the deriva­
tion of I( a, biS). If th e derivation has length 0 then
the lemma is trivial. If it is of length k then I( a, bf5)

must follow from one of the rules. Each rule has an an­
tecedent with a separated from bin a manner satisfying
the inductive hypothesis. Thus since this antecedent
must have a derivation of length < k the lemma holds.
0
