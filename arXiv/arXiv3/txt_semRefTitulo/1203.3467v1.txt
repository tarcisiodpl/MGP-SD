
Performing sensitivity analysis for influence
diagrams using the decision circuit framework is particularly convenient, since the
partial derivatives with respect to every parameter are readily available [Bhattacharjya
and Shachter, 2007; 2008]. In this paper
we present three non-linear sensitivity analysis methods that utilize this partial derivative information and therefore do not require
re-evaluating the decision situation multiple
times. Specifically, we show how to efficiently
compare strategies in decision situations, perform sensitivity to risk aversion and compute
the value of perfect hedging [Seyller, 2008].

1

INTRODUCTION

Decision making under uncertainty presents several
opportunities and challenges beyond those encountered in pure reasoning under uncertainty. An influence diagram [Howard and Matheson, 1984] is a graphical model that represents the relationships between
the decisions, uncertainties and preferences of a decision maker (DM), and it can be evaluated to reveal
the optimal strategy and the DM’s value for the decision situation. Decision circuits are graphical representations that not only enable efficient evaluation of
influence diagrams [Bhattacharjya and Shachter, 2007;
Shachter and Bhattacharjya, 2010], but also compute
a wide array of sensitivity analysis results [Bhattacharjya and Shachter, 2008]. In this paper, we extend our
previous work on sensitivity analysis and show how decision circuits can also be used to efficiently perform
more sophisticated analysis such as strategy comparisons, sensitivity to risk aversion, and value of perfect
hedging [Seyller, 2008] computations.
Sensitivity analysis refers to observing how the outputs of a system are affected as the inputs are varied.

Ross D. Shachter
Management Science and Engineering
Stanford University
Stanford, CA 94305, USA
shachter@stanford.edu

In decision situations, such analysis can provide the
DM with insights, a better understanding of the situation and clarity of action. Decision circuits extend the
research in arithmetic circuits [Darwiche 2000; 2003]
towards evaluating and analyzing decision situations,
and they reap similar benefits in efficiency.
For belief networks, efficient sensitivity analysis is feasible primarily due to the linear relationship between
marginal probabilities and the parameters (see for instance Castillo et al [1997]; Kjaerulff and van der
Gaag [2000]; van der Gaag and Renooij [2001]; Chan
and Darwiche [2004]). On the other hand, there are
unique challenges in sensitivity analysis for influence
diagrams [Nielsen and Jensen, 2003; Bhattacharjya
and Shachter, 2008] arising due to the non-linearities
created by maximization operations for making decisions, as well as the non-linear utility function for any
DM who is not risk neutral.
There are three main contributions in this paper. The
first is a method for finding the value when the DM
changes the policy for a particular decision while maintaining the other policies at the current optimal strategy. The DM may be interested in comparing the optimal strategy with the status quo or a strategy that
is easier to implement. Second, we present an efficient
way to perform sensitivity to risk aversion, which enables the DM to compare the optimal strategy with
one that might be more flexible. Third, we show how
to compute the value of perfect hedging for any uncertainty, which enables a risk-averse DM to value deals
for reducing the “risk” in her current situation.
The common feature among our methods is that they
all essentially deal with non-linear sensitivity analysis
in some form. While they have previously been difficult to perform using other representations of decision
situations, they can all be performed efficiently using
partial derivatives that are easily obtainable in the decision circuit framework. In Section 2 we review the
literature, while Sections 3, 4 and 5 explain the three
methods respectively. Section 6 concludes the paper.

Gold
price

Prob.

O

high

high
low

0.8
0.1

Amount
of oil

low
0.2

G

0.9

Prob.
high

low

0.3

0.7

Report

Prob.

T

A

“positive”

yes

high

0.75

0.25

yes

low

0.1

0.9

no

high

0

1

no

low

0

1

“negative”

Oil
price

R
A

high

low

0.4

0.6

Value
(M $)

U

Prob.

U

T

O

high

high

300

high

low

120

low

high

50

low

low

-50

NOTATION AND REVIEW

Here we discuss notation, examples, and briefly review the key concepts. We assume that the reader is
generally familiar with decision analysis fundamentals,
including graphical models such as influence diagrams
and belief networks.
2.1

Basic Notation and Examples

Variables are denoted by upper-case letters (X) and
their values by lower-case letters (x). The family for X
also includes its parents Pa(X), and an instantiation
of X’s family is denoted xpa(X). The bold-faced font
indicates a set of variables. Whenever a variable X is
binary, we denote its states as x and x̄.
Consider the influence diagram in Figure 1 [Seyller,
2008]; in this case there are no explicit decisions in the
model. The DM owns an oil field, and believes that the
Amount of oil (A) is independent of the Oil price (O),
but the Gold price (G) and Oil price are dependent.
The utility node U explicitly indicates that she will
reap profits from oil production as determined by the
Oil price and Amount of oil. We will discuss later why
the DM might be concerned about the Gold price, even
though it does not currently contribute to the value. In
Figure 2 [Raiffa, 1968], the DM will decide whether to
explore another field she owns with a seismic Test (T)
to purchase a Report (R). Her testing decision and the
report will be known to her when she decides whether
to drill a Well (W). If she doesn’t perform the test, the
report is not informative and always states “negative”.
In Figure 1, A and O are the value attributes since they
are the parents Pa(U) of utility node U . We assess a
value table v(pa(U)) from a value function v(.) that
characterizes the value of the attributes in terms of a
single numeraire, which we assume is dollars. We also
assume that the analyst has assessed a utility function, P (u|pa(U)) = u(v(pa(U))) where u(.) is a von

A

W

U

high

low

0.35

0.65
Value
(M $)

T

W

A

yes

yes

high

100

yes

yes

low

-70

yes

no

high

-20

yes

no

low

-20

no

yes

high

120

no

yes

low

-50

no

no

high

0

no

no

low

0

Figure 2: An influence diagram with decisions.

Figure 1: An influence diagram without decisions.

2

Prob.

U

A
O

Amount
of oil

Neumann-Morgenstern utility function [von Neumann
and Morgenstern, 1947] such that u is at least as good
and ū is at least as bad as anything that can happen.
Therefore we model U as a binary node, where the
utilities are normalized to lie in the interval (0, 1).
The certain equivalent (CE) of an uncertain V , given
by u−1 (E[u(V )]), represents the certain payment that
the DM finds indifferent to V . Our sensitivity results
will be expressed in terms of the CE rather than utilities because the CE is measured in the same units
as the numeraire for value. Our chosen measure of
value in this paper is dollars, but other numeraires are
possible, such as quality adjusted life years (QALYs),
number of lives saved, etc. Since utilities have an arbitrary scale and are used for the internal computations, they are meaningless to DM. We assume that the
utility function u(.) is strictly increasing and continuously differentiable. The most common utility functions are linear, u(v) = u0 v + u∞ , and exponential,
u(v) = −u0 e−γv + u∞ , where u0 > 0 and γ > 0 (we
choose u0 and u∞ such that u(v) ∈ (0, 1)). The exponential is the only utility function that captures riskaversion and also allows us to express our valuation for
a change in a decision situation as a difference between
CEs with and without the change [Raiffa, 1968].
The conditional probability tables and the value function v(.) are shown along with the influence diagrams
in both Figures 1 and 2. We assume that the DM has
an exponential utility function u(.) with risk aversion
−1
γ = 0.002 (in units of (M $) ) for both examples. Her
CEs for Figures 1 and 2 are $38.99M and $5.21M respectively. In Figure 2, the optimal strategy is to test
and drill the well when the report is “positive” and
not to drill when the report is “negative”.
2.2

Arithmetic and Decision Circuits

We can associate any belief network with a unique
multi-linear function (MLF) over evidence indicators

λx , and network parameters θx|pa(X) . An arithmetic
circuit [Darwiche, 2000; 2003] is a rooted, directed
acyclic graph whose leaf nodes are either constants,
λx or θx|pa(X) , and all other nodes represent summation or multiplication. It can compactly factorize the
MLF for efficient inference and sensitivity analysis.
An evidence indicator λx is binary (0-1) with λx = 0
whenever X has been observed taking another value,
i.e. it is not x. There is an evidence indicator associated with each possible instantiation x of each network
variable X. A network parameter θx|pa(X) represents
a conditional probability, θx|pa(X) = P (x|pa(X)).
There is a network parameter for each possible instantiation xpa(X) of family XPa(X). Each term
in the MLF corresponds to an instantiation z of all
the network variables Z, involving the product of all
evidence indicators and network parameters consistent
P Qwith z. The MLF for a belief network is f =
z
xpa(X)∼z λx θx|pa(X) , where the sum is over every instantiation of all variables in the network and
xpa(X) ∼ z represents all families consistent with z.
As an example, if we treat the utility node
in
P Figure 1 as an uncertainty, the MLF is:
a,o,g,u λa λo λg λu θa θo θg|o θu|a,o . An arithmetic circuit
represents onePparticular
ofPthis MLF,
P factorization
P
such as say:
a λa θ a
o λo θo
g λg θg|o
u λu θu|a,o .
There may be many possible factorizations (and therefore circuits) for a given MLF.
An arithmetic circuit performs inference by ensuring
that the appropriate terms in the joint distribution
are summed. By setting the evidence indicators to 0
or 1 such that they are consistent with the evidence
e, we can compute P (e) in an upward pass, starting
from the leaves and ending at the root. The result of
evaluating the circuit in this upward pass is denoted
as f (e), where f (e) = P (e). We can calculate partial
derivatives by differentiating the circuit through a subsequent downward pass, in which parents are visited
before children. The upward and downward passes are
also referred to as sweeps. The partial derivatives of
the root with respect to every evidence indicator and
network parameter are computed through the downward sweep. Darwiche [2003] shows how these derivatives can answer other inference queries such as conditionals, and also perform sensitivity analysis. We use
the following result in particular for some proofs.
Lemma 1. For every variable X ∈
/ E:
P (x, e) =

∂f
∂λx (e)

For influence diagrams, Bhattacharjya and Shachter
[2007] introduce decision circuits: arithmetic circuits
augmented with maximization nodes. They represent
the dynamic programming function corresponding to

a sequential decision problem. The size of a decision
circuit is the number of edges it contains.
For the decision nodes in an influence diagram, the
evidence indicator λd for decision D is initialized to 0
only if the alternative d is no longer available to the
DM. We assume that each decision has at least two
alternatives. The network parameter θd|pa(D) for a
decision D is initialized to 1 if the alternative is conditionally available under scenario pa(D), and 0 otherwise. Any influence diagram can be transformed to a
diagram with only one utility node U ; the parameters
θu|pa(U) = u(v(pa(U))) are the utilities (normalized
to lie between 0 and 1), and θū|pa(U) = 1 − θu|pa(U) .
An influence diagram represents a total ordering
of the decisions, which enforces a partial order on
the uncertainties. The order of maximization and
summation in the dynamic programming function
must respect this order. For the influence diagram
in Figure 2, the only valid order is T ≺ R ≺
W ≺ AP
≺ U , and one P
possible factorization is:
max
λ
θ
max
λ
θ
t
t
t
w
w
w|tr
r
a λr θr|ta λa θa
P
u λu θu|trw .
Once compiled, a decision circuit can be evaluated in
an upward sweep analogous to arithmetic circuits. Decision circuits are evaluated with evidence e0 = {e, u}
when e is observed. The best outcome u is also deemed
to be observed in e0 since the goal is to find optimal
policies that maximize the probability of the best outcome given the evidence. The value of the root node
of the circuit is denoted g(e0 ). The optimal policies
for all decisions are computed on the upward sweep
at the maximization nodes, where the alternative d∗
with the highest value is chosen, breaking ties arbitrarily. The network parameter θd|pa(D) is set to 0 for
all other alternatives d. The optimal strategy s∗ is the
set of optimal policies θd∗|pa(D) for all decisions.
The circuit can be differentiated in a subsequent downward sweep, by treating max nodes as sum nodes. The
decision circuit’s root is the unnormalized expected
utility; it can be normalized by the probability of evidence P (e), computed by sweeping up the circuit with
evidence e at the optimal strategy, P (e) = g(e|s∗),
although it could be at any strategy since e is not responsive to the decisions. (Note that P (e) can also be
computed using derivatives from a downward sweep,
∂g
∂g
(e0 |s∗) + ∂λ
(e0 |s∗)). Thus the expected
P (e) = ∂λ
u
ū
utility and CE of the optimal strategy are:
Lemma 2. The maximum EU is:
EU (s∗) =

g(e0 |s∗)
g(e|s∗)

Lemma 3. For utility function u(.), the CE is:
CE(s∗) = u−1 (EU (s∗))

Once a decision circuit is compiled, it can be made
even more compact by pruning [Bhattacharjya, 2008],
i.e. exploiting deterministic relationships in the model
to remove nodes and arcs that are not required from
the circuit. For instance, in Figure 2, note that the
Report always reads “negative” if the Test is not performed. Figure 3 shows a part of the pruned decision
circuit for this influence diagram and the asymmetry
that results from pruning is apparent.
2.3

Sensitivity Analysis in Influence
Diagrams

Sensitivity analysis helps drive the conversation between the DM and the analyst. Howard [1968] uses terminology from the systems analysis literature to classify sensitivity analysis into two categories. He refers
to varying a parameter and computing the certain
equivalent at a fixed strategy as open loop analysis;
when the strategy is allowed to vary by re-evaluating
the decision situation, it is closed loop analysis. Closed
loop results require re-evaluating the influence diagram, which can be done as efficiently as possible using
decision circuits. Nonetheless, open loop results can
provide the DM with key insights, using information
that is already computed in the original circuit.
Previous work in sensitivity analysis in influence diagrams has involved varying parameters such as conditional probabilities and finding intervals over which the
current strategy remains optimal [Nielsen and Jensen,
2003; Bhattacharjya and Shachter, 2008], drawing oneway sensitivity plots and computing the value of information [Howard, 1966; Raiffa, 1968]. In this paper we
focus our attention on certain kinds of sensitivity analysis where non-linearity is a critical issue.
2.4

The Value of Perfect Hedging

The notion of hedging is well known particularly in
the financial community and is associated with trading
derivatives due to the long common history they share.
Seyller [2008] writes: “ ... in late 17th century Japan,
a futures market in rice was developed at Dojima, near
Osaka ... It was the first recorded instance in which
such a market was created ”. Seyller defines the value
of hedging from a decision-analytic perspective, and it
is this approach that we use in this paper.
In a decision situation, hedging occurs through a deal
relevant to one we already possess. Suppose we own a
coin toss deal where we receive $50 for heads or pay
$50 for tails. Now consider another deal where the
payoffs are reversed, i.e. we pay for heads and receive
for tails. If we believe heads and tails are equally likely,
then both these deals have identical value when considered separately. Moreover, being risk averse, we have

a negative certain equivalent for either deal. However,
if we were to own both deals, we would neither lose
nor gain money for certain, regardless of the outcome
of the coin toss! Thus, if we already owned one of
these deals, we should be willing to pay for the other.
Any risk averse DM can increase the value of his/her
decision situation by purchasing other relevant deals.
The value of perfect hedging (VoPH) [Seyller, 2008] is
a relatively new tool for the decision analyst, to help
the DM choose deals that can help reduce her “risk”
based on her current portfolio. The VoPH on uncertainty X is defined as the most that the DM should
be willing to pay for the best possible deal Y that is
determined solely by X (i.e. Y is a deterministic function of X), such that E[Y ] = 0. For an important
special case, the following holds true:
Lemma 4. For a risk averse DM with an exponential
utility function, a decision situation with evidence e
and uncertainty X,
V oP H(X|e) = CE P H − CE(s∗),
where CE P H is the CE with the perfect hedge, i.e. the
maximum CE when any deal Y (determined solely by
X) is added to the current situation, under the constraint that E[Y |e] = 0, and CE(s∗) is the CE of the
original situation, without hedging.
VoPH is defined to parallel the value of information
(VoI). A DM should not be willing to pay more than
VoI(X) for any information on uncertainty X. Similarly, a DM should not be willing to pay more than
E[Y ] + V oP H(X) for any deal Y determined solely
by X. One major difference between VoI and VoPH
is that while information is valuable only when it can
affect the DM’s choice, hedging can be valuable even
without changing any decision since it affects the distribution of value. VoPH has several intuitive properties, e.g. it is non-negative for a risk-averse DM and
zero for a risk-neutral DM or when the uncertainty
is not relevant to the value. We will explore VoPH
further in Section 5.

3

COMPARING STRATEGIES

Decision circuits contain indicators λd and network parameters θd|pa(D) for decisions. The power of the indicator λd comes from being able to compute the value
of an alternative (VoA), i.e. the minimum price that
the DM should be willing to accept to forego the alternative in the decision situation, since setting λd = 0
removes alternative d from consideration.
At first glance, it may appear that the derivative
∂g(e0 |s∗)
= 0 captures V oA(d), but this is not true
∂λd
- the optimal policies have already been set to s∗ and

max
Test

the derivative is unable to compare the best alternative
0
|s∗)
= 0, there
with the next best alternative. If ∂g(e
∂λd
is 0 probability of this alternative being chosen at the
0
|s∗)
current optimal strategy s∗. If ∂g(e
= g(e0 |s∗),
∂λd
this alternative is optimal for all observations pa(D)
at s∗, that is, alternative d is always chosen in s∗.
For intermediate values, the derivative is an unnormalized product of utility and probability, and it may
not be particularly meaningful to the DM. Instead, we
suggest using the partial derivatives with respect to
θd|pa(D) for strategy comparisons.
Consider the following sensitivity analysis question:
what is the CE when the policy for only one decision
is changed, while maintaining the policies for other decisions at the current optimal strategy s∗? There are
several reasons why the DM may be interested in such
an analysis. For instance, the proposed optimal strategy may be different from the status quo, or a strategy that is easier to implement, and therefore the DM
may wish to understand the incremental value from
the optimal strategy. We show how this question can
be answered through partial derivatives.
Theorem 1. If we change the current optimal policy for decision D, denoted d ∗ (pa(D)), to d0 (pa(D))
keeping all other policies fixed to optimal strategy s∗,
then the CE of the new strategy s0 is:
hP
i

∂g(e0 |s∗)
1
CE(s0 ) = u−1 g(e|s∗)
pa(D) ∂θ 0
d |pa(D)

Proof. During differentiation on the downward sweep,
the max nodes are treated as sum nodes. For any
strategy s, we can write the root value of the circuit as a linear function of the policies for decision
P P
∂g(e0 |s)
D: g(e0 |s) = d pa(D) θd|pa(D) ∂θ
.
d|pa(D)
0
The strategies s∗ and s only differ by the values of
∂g(e0 |s)
θd|pa(D) . The derivative ∂θ
does not depend on
d|pa(D)
any of the values of θd|pa(D) , because each term in the
linear function contains only one instantiation of fam∂g(e0 |s∗)
∂g(e0 |s0 )
= ∂θ
.
ily DPa(D), therefore ∂θ
d|pa(D)
d|pa(D)
0
The policy d (pa(D)) sets θd0 |pa(D) = 1 and the other
θs to 0, thus:
P
P
∂g(e0 |s0 )
∂g(e0 |s∗)
g(e0 |s0 ) = pa(D) ∂θ
= pa(D) ∂θ
.
0
d |pa(D)
d0 |pa(D)
The required result follows from Lemmas 2 and 3.
From the nature of the dynamic programming solution
procedure for influence diagrams, optimal policies for
all decisions are computed in reverse order, from the
last decision to the first. In decision circuits, this is
done by maximization nodes as optimal policies are
identified during the upward sweep. Therefore, when
the policy for a decision D is modified from strategy
s∗, all the future decisions are guaranteed to remain
optimal since that is how they were determined for

λt

Don’
Don’t test

*

λt

*

θt
“Positive”
Positive”

+

“Negative”
Negative”

max
Drill

Drill

*

*

λw

*

*

*

Drill

*

*

*

θ w|tr

θ w|t r θ w|tr

λw +

+

Don’
Don’t drill

*

*

θ w|t r
+

*

Don’
Don’t drill

*

θ w|tr θ w|tr
+

max

max
Don’
Don’t drill

*

θt

+

*

*

+

*

*

*

Figure 3: Partial decision circuit for the influence diagram
shown in Figure 2.

s∗. However, the policies for earlier decisions may no
longer remain optimal after the policy changes for D.
Let us illustrate Theorem 1 with the partial decision circuit in Figure 3 (for the influence diagram
shown in Figure 2). The current optimal strategy
s∗ is marked using bold arrows at the max nodes.
There is no evidence in this case, therefore e = ∅,
and e0 = {e, u} = u. g(e|s∗) = g(∅|s∗) = 1, g(e0 |s∗)
equals the maximum expected utility (Lemma 2) and
CE(s∗) = $5.21M (Lemma 3).
Suppose the DM switches her choice at the top max
node in Figure 3 to don’t test, while maintaining the
current optimal policy for the drilling decision. It is
optimal to subsequently drill (see the bottom max
node along the don’t test path in Figure 3), which
was determined by the initial dynamic programming
solution procedure. For the
strategy
(don’t test,
 new

0
−1 ∂g(e |s∗)
drill the well), CE = u
= $3.17M . Now
∂θḡ
suppose the DM switches from s∗ to always drilling regardless of what is observed. For the new strategy (test
and drill regardless of what the report
says), CE =

0
∂g(e0 |s∗)
∂g(e0 |s∗)
−1 ∂g(e |s∗)
u
= $ − 16.83M .
∂θw|tr + ∂θw|tr̄ + ∂θw|t̄r̄
This strategy is not optimal given the enforced drilling
policy - it is clearly better not to perform the test, in
which case the CE would be $3.17M (as we noted earlier). The current optimal strategy is better than not
testing and drilling by $(5.21 − 3.17)M = $2.04M . If
there are some organizational concerns related to performing the test, such a strategy comparison can be
beneficial for the DM.
Once the derivatives are available from initial sweeps
through the decision circuit, finding the CE by changing a policy using Theorem 1 is of the complexity of
O(|pa(D)|) (where |pa(D)| is the number of possible
observations for D). This is more efficient than sweeping through the circuit again, but it should be noted

that the earlier decisions are not re-optimized.
While earlier decisions may no longer remain optimal
after a policy change, there are several potential applications of this sort of analysis: 1) DM may be at that
decision epoch and therefore already made the earlier
decisions; 2) There are practical conditions (like organizational reasons) which restrict the earlier decisions.

4

SENSITIVITY TO RISK
AVERSION

It is often difficult to assess the DM’s utility function,
and therefore sensitivity analysis is an instructive technique for understanding the effects of risk attitude on
the optimal strategy and the CE. The local risk aversion for utility function u(.) is a measure of the DM’s
risk attitude at a specific dollar value, and is defined as
00
(v)
[Pratt, 1964; Arrow, 1965]. The exponenγv = − uu0 (v)
tial utility function is the only function that features
constant and non-zero risk aversion; in this case the
local risk aversion is also the global risk aversion (i.e.
it does not depend on v) and is denoted as γ. We will
focus our attention on this important special case.
For small decision problems, CE is typically plotted
against γ by re-evaluating the decision problem multiple times. Sensitivity to risk aversion for larger decision problems is challenging primarily due to two reasons: 1) A change in γ changes all the entries θu|pa(U) ;
2) It is no longer possible to make comparisons in the
utility-space since the utility function itself is modified. However, there is a linear property when only
the utilities are varied, similar to the case when only
the parameters within the same conditional probability table are varied [Chan and Darwiche, 2004]:
Lemma 5. The root of the decision circuit evaluated
at evidence e0 can be written as:
P
∂g(e0 |s∗)
g(e0 |s∗) = pa(U) ∂θ
θu|pa(U) ,
u|pa(U)
where the partial derivatives
on the utilities.

∂g(e0 |s∗)
∂θu|pa(U)

do not depend

We can now compute the partial derivative of CE(s∗)
with respect to any parameter ν of the utility function:
Theorem 2. The partial derivative of CE(s∗) w.r.t
any parameter ν of any utility function u(.) is:
 −1

∂u
P
∂CE(s∗)
∂g(e0 |s∗) ∂u
∂ν |EU (s∗)
=
pa(U) ∂θu|pa(U) ∂ν |v(pa(U))
∂ν
g(e|s∗)
Proof. From Lemmas
2, 3 and 5,


P
∂g(e0 |s∗)
1
CE(s∗) = u−1 g(e|s∗)
pa(U) ∂θu|pa(U) θu|pa(U) .
Parameter ν only affects utilities, not g(e|s∗). The
result follows from the chain rule of differentiation.

The partial derivative from Theorem 2 yields sensitivity to risk aversion for the exponential utility function
when ν = γ, and it depends on readily available partial
derivatives. Note that CE(s∗) is a non-linear function
of γ, and while the derivative can be used for computing the local variation, it cannot entirely determine
the plot across a significant range. However, we show
next that there is a closed-form (non-linear) expression
for the CE(s∗) as a function of γ, in terms of partial
derivatives with respect to the utilities.
Theorem 3. For a DM with an exponential utility
function:
 

0
X
∂g(e |s∗) −γv(paU)
1
e
)/g(e|s∗)
CE(s∗) = ln (
γ
∂θu|pa(U)
pa(U)

Proof. θu|pa(U) = u0 e−γv(pa(U)) − u∞ .
From Lemma 3, u(CE(s∗)) = EU (s∗).
In the expression above,
LHS = u0 e−γCE(s∗) − u∞ .
From Lemmas
2 and 5,


P
∂g(e0 |s∗)
0 −γv(pa(U))
−u∞ )
pa(U) ∂θu|pa(U) (u e
RHS =
.
g(e|s∗)
The
result
follows
from
recognizing
that
P
∂g(e0 |s∗)
=
g(e|s∗),
taking
the
natural
pa(U) ∂θu|pa(U)
log of both sides and rearranging terms.
Theorem 3 is a powerful result that provides a closedform expression capturing sensitivity to γ. Once the
derivatives are available from initial sweeps through
the decision circuit, plotting a graph of CE(s∗) vs. γ is
of the complexity of O(R|pa(U)|) where R is the number of points over which the plot is made and |pa(U)|
is the number of instantiations of the value attributes.
This is much more efficient than re-evaluating the decision situation, which would require O(R(dc)) computations, where dc is the size of the decision circuit. The
caveat is that this is computed at the original optimal
strategy, whereas re-evaluating the decision situation
at a different γ could yield a different optimal strategy.
While sensitivity to risk aversion is crucial in and of
itself, Theorem 3 is particularly applicable for studying the flexibility of strategies. Shachter and Mandelbaum [1996] suggest that a flexible plan must be
able to perform well under unanticipated or unmodeled uncertainty. Under several assumptions and for
a DM with an exponential utility function, they prove
that a more flexible solution is equivalent to a solution
that is preferred for a larger risk aversion; therefore being capable of dealing with unmodeled uncertainties is
equivalent to choosing a less “risky” solution.
Let us demonstrate this with an example, using the influence diagram from Figure 2, which was evaluated at

15.000

hedge Y (determined solely by X) at strategy s∗ is:

10.000

y(x) = E[CE(s ∗ |X)] − CE(s ∗ |x),

CE (in M $)

5.000

0.000
0.000

0.002

0.004

0.006

0.008

0.010

Current risk aversion = 0.002

V oP H(X|e, s∗) = E[CE(s ∗ |X)] − CE(s∗),

-10.000

-15.000

-20.000

Risk aversion
Current optimal strategy

Drill without testing

Neither test nor drill

Figure 4: Sensitivity analysis with respect to risk aversion.
γ = 0.002. The DM re-evaluates the influence diagram
at a lower value, γ = 0 (risk-neutral), and at a higher
value, γ = 0.01. At γ = 0 it is optimal to drill without testing; at γ = 0.01 it is optimal neither to test
nor to drill. As she plots these three strategies with
risk aversion (Figure 4) using Theorem 3, she can compare her current strategy with one that is more flexible
and one that might be less flexible. Apart from the
crossover points in the figure, she can also note that
the difference between the CEs of the current optimal
and the more flexible strategy at her currently assessed
γ = 0.002 is: $(5.21−0)M = $5.21M . She should consider whether she is willing to pay that much for the
gain in flexibility.

5

and the VoPH is:

-5.000

THE VALUE OF PERFECT
HEDGING

The value of perfect hedging (VoPH), reviewed earlier in Section 2.4, is a compelling new technique for
appraising the decision situation. It supports a proactive DM in evaluating the worth of other deals that
are relevant to the current decision situation and can
offset “risk” from the existing distribution of value.
Although the VoPH is a useful concept, computing
it can be extremely challenging. From Lemma 4,
note that finding the perfect hedge and the VoPH entails solving a difficult non-linear optimization problem, since CE P H is a non-linear function of the hedge.
Seyller [2008] employs an exhaustive search method
by sampling over several possible values of the perfect hedge. The theme in this paper is to avoid
re-evaluating the decision situation for computations;
through the theorems in this section, we show that
there is a very efficient way to compute the VoPH at
a fixed strategy using partial derivative information.
Theorem 4. Consider a decision situation with evidence e and exponential utility function. The perfect

where CE(s ∗ |x) is the conditional CE of strategy s∗
given that x is observed, E[CE(s ∗ |X)] is the probability weighted average of these conditional CEs, and
CE(s∗) is the CE of the original situation.
Proof. Let us partition the set of all uncertain variables into X and W. When we introduce additional
value from Y , we change the utilities but the utility
function remains the same, therefore maximizing certain equivalent is the same as maximizing expected
utility. According to Lemma 4, the perfect hedge
(when we observe evidence e and stay at the current
optimal strategy s∗) is the y(x) that solves the following non-linear optimization problem:
X
X
maxy(x)
P (x|e, s∗)
P (w|x, e, s∗)
x

w

[u(v(x, w) + y(x))]
s.t.

X

P (x|e, s∗)y(x) = 0

x

The objective function of the optimization problem
is the expected utility at s∗ with the perfect hedge,
EU P H (s∗). It is a concave function and the constraint
is linear, therefore the necessary conditions are also
sufficient. We first solve
Pfor the Lagrangian multiplier
µ, recognizing that
w P (w|x, e, s∗)u(v(x, w)) =
EU (s ∗ |x). Writing y(x) as a function of µ, we find:
 
1
µ
1
∞
y(x) = ln (u − EU (s ∗ |x)) − ln
γ
γ
γ
Replacing this in the constraint of the optimization
problem, solving for µ and simplifying,
y(x) =

1
ln(u∞ − EU (s ∗ |x))
γ
1X
−
P (x|e, s∗) ln (u∞ − EU (s ∗ |x))
γ x

Adding and subtracting the appropriate constant from
both terms and from Lemma 3 we get the desired
result. V oP H(X|e, s∗) can be computed first by replacing y(x) in the objective function to find EU P H ,
and then using Lemma 3 to find CE P H . The solution yields CE P H = E[CE(s ∗ |X)]. From Lemma 4,
V oP H(X|e, s∗) = E[CE(s ∗ |X)] − CE(s∗), which is
the required solution.

x1

x

x2

x3

DEAL BEFORE
PERFECT HEDGE

DEAL AFTER
PERFECT HEDGE

CE(s*|x1)

E[CE(s*|X)]

CE(s*|x2)

E[CE(s*|X)]

CE(s*|x3)

E[CE(s*|X)]

CE of this deal
= CE(s*)

CE of this deal
= E[CE(s*|X)]

Figure 5: Before and after perfect hedging on X.
Let us explore the intuition behind the above result.
Firstly, note that we have hidden the conditioning on
the evidence e in the term CE(s ∗ |x) and it should
be clear that all CE computations are done conditioned on e (also for the original decision situation).
Theorem 4 reveals that the perfect hedge y(x) is the
dollar value that adds or subtracts value to CE(s ∗ |x)
to make the conditional CE equal to E[CE(s ∗ |X)],
for all states x. It is clear that E[Y ] = 0 because
E[E[CE(s ∗ |X)] − CE(s ∗ |x)] = 0. Perfect hedging
on X reveals an intuitive insight: the perfect hedge
ensures receiving the expected value of the conditional
CEs regardless of the outcome of X. Since the DM
is risk averse, such a deal will never hurt the DM and
thus V oP H(X|e, s∗) ≥ 0. Figure 5 compares the deal
before and after the perfect hedge, as we condition on
some uncertainty X with three states. V oP H(X|e, s∗)
is the difference between the CEs of the two situations.
The obvious next question is: how can we compute the
perfect hedge and the VoPH efficiently? We propose
using partial derivatives as follows.
Theorem 5. Using terminology from the previous theorem,


∂g(e0 |s∗) ∂g(e|s∗)
−1
CE(s ∗ |x) = u
/
∂λx
∂λx
"
#
X ∂g(e|s∗)
1
E[CE(s ∗ |X)] =
CE(s ∗ |x)
g(e|s∗) x
∂λx
Proof. The conditional expected utility EU (s ∗ |x) =
P (u|x, e, s∗) = P (u, e, x|s∗)/P (e, x|s∗). From Lemma
0
|s∗)
and the denominator
1, the numerator is ∂g(e
∂λx
is ∂g(e|s∗)
∂λx . The result for CE(s ∗ |x) follows from
Lemma 3. From P
the definition of expected value,
E[CE(s ∗ |X)] =
∗ |x)).
x (P (x|e, s∗)CE(s

 Again

∂g(e|s∗)
from Lemma 1, P (x|e, s∗) =
/g(e|s∗),
∂λx
which yields the required result for E[CE(s ∗ |X)].

Table 1: VoPH results for the example in Figure 1.
Uncertainty

VoPH (in M $)

Amount of oil
Oil price
Gold price

7.68
3.26
1.61

We see that the conditional CEs are very easy to compute using partial derivatives. Regarding the computational complexity of finding V oP H(X|e, s∗), note
that all the partial derivatives in Theorem 5 are available from four sweeps on the decision circuit: two
sweeps, up and down with evidence e and another
two sweeps, up and down with evidence e0 . Once
we have obtained these derivatives, V oP H(X|e, s∗)
for any particular X can be computed in constant
time. Similar to the previous section, the caveat is
that the solution is at a fixed strategy. In general,
the current optimal strategy may no longer remain
optimal after adding the perfect hedge, and therefore
V oP H(X|e, s∗) ≤ V oP H(X|e).
The ideal application of Theorems 4 and 5 is when
there are no decisions (as in Figure 1a) since we don’t
need to re-evaluate the decision situation. Suppose a
DM (or organization) represents their complex portfolio by a belief network augmented with a utility node,
to capture what is valued. In that situation, we can efficiently identify uncertainties that the DM should consider hedging. Moreover, an arithmetic circuit is sufficient (no maximization) and we can leverage the efficiencies of compact arithmetic circuits [Chavira, 2007].
Table 1 shows the VoPH for all three uncertainties
in the influence diagram in Figure 1 [Seyller, 2008].
Suppose the DM is offered the following deal (perhaps
a futures contract) on the Gold Price for $50M : the
payoff is −$50M when Gold price is high and $100M
when Gold price is low. Then the VoPH informs the
DM that this deal is not worth her perusal, because
the price she should pay for this deal is bounded above
by E[Y ] + V oP H(Y ) = $(43 + 1.61)M = $44.61M .
Although this is a simple example, it is easy to see
that the results scale up for large problems.
In general, we may wish to find the price that the DM
is willing to pay for a specific deal that is determined
by the value attributes in the model, not necessarily
the perfect hedge. In the previous section, we used
partial derivatives with respect to utilities to perform
sensitivity to risk aversion since varying γ changes all
the utilities. A similar approach can be taken to find
the CE (at a fixed strategy) when this new deal is
added to the original situation, because this addition
only affects the utilities. Similar to Theorem 3, we can

formulate a closed form expression for the new CE as
a function of the payoffs from this new deal and partial
derivatives with respect to the utilities.

6

CONCLUSIONS

Sensitivity analysis is crucial in decision analysis, helping the DM consider the value of further information
gathering and the benefits of obtaining greater parameter precision. In this paper, we presented three sensitivity analysis methods that can be easily applied in
the decision circuit framework and do not require reevaluating the decision situation, making them highly
accessible for potentially large decision problems. We
have demonstrated how a DM should study the effect of switching to another policy or choosing a more
flexible solution, as well as find deals that can effectively hedge his/her current portfolio. We have shown
that DMs can gain valuable insights from the partial
derivative information available in decision circuits.
Acknowledgements
We thank Thomas Seyller, Léa Deleris and three
anonymous reviewers for their valuable feedback.
