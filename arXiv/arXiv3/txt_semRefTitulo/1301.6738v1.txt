

In this paper we extend the work of Smith
and Papamichail (1999) and present fast
approximate Bayesian algorithms for learn­
ing in complex scenarios where at any time
frame, the relationships between explanatory
state space variables can be described by
a Bayesian network that evolve dynamically
over time and the observations taken are not
necessarily Gaussian. It uses recent devel­
opments in approximate Bayesian forecast­
ing methods in combination with more fa­
miliar Gaussian propagation algorithms on
junction trees. The procedure for learn­
ing state parameters from data is given ex­
plicitly for common sampling distributions
and the methodology is illustrated through
a real application. The efficiency of the dy­
namic approximation is explored by using the
Hellinger divergence measure and theoretical
bounds for the efficacy of such a procedure
are discussed.
Keywords: Dynamic Generalised Linear Mod­
els, Dynamic Bayesian networks, Hellinger dis­
tance, junction trees.

1

INTRODUCTION

In the last ten years, Bayesian probabilistic net­
works have been largely applied to complicated high­
dimensional problems, where the relationships among
When the de­
several variables are uncertain.
pendence structure in the problem domain remains
fixed, Bayesian inference and efficient algorithms for
structural learning and data propagation are well­
established and widely used in the Statistical and Ar­
tificial Intelligence community.

However in dynamic situations, where typically the do­
main together with the interdependencies among the
variables evolve with time, Bayesian inference and up­
dating algorithms can become progressively hard (see
Boyen and Koller (1998) for an interesting discussion
of these issues). To model such scenarios Bayesian
probabilistic networks need to be defined over state
spaces, i.e. the sets of uncertain quantities or param­
eters defining the stochastic process, which vary over
time.
The first problem faced in dynamic contexts is that
the state space will tend to become rather compli­
cated and may grow enormously with the passage of
time. New variables may be added to the problem
and new conditional independencies are created or old
ones disappear. Moreover, in the applications we have
in mind, where the production of forecast distributions
at each time step is critically important, observations
will arrive sequentially and the system will need to
be updated sequentially after the arrival of each new
data and be ready to receive new information that may
arise.
This scenario occurs in many fields. In clinical investi­
gations data associated with symptoms are monitored
over time. The evidence accumulates as the disease
develops, so different symptoms arise and new data
need to be observed for each patient. In marketing
research for instance we need to predict the sales of
new products in competing markets where new com­
petitors are constantly being introduced (see Smith
and Papamichail, 1999). In the analysis of the fluctu­
ations and behaviour of financial stocks quick forecasts
and predictions are usually demanded in an environ­
ment where causal variables are constantly changing.
In section 5 of this paper we shall illustrate our data
propagation technique through an environmental ap­
plication which involves a complex dynamic process
associated to the radioactive gaseous mass release in
the event of a nuclear accident (Smith et a!. 1995).
Because of the difficulties mentioned above, standard

586

Settimi, Smith, and Gargoum

algebraic updating procedures for Bayesian networks
that are extremely efficient in the static case may be­
come unfeasible when applied to the dynamic context.
On the other hand, numerical Monte Carlo methods
tend to be slow and are fraught with complexity dif­
ficulties compared to their static counterparts even in
much simpler domains (see Shepard and Pitt, 1999).
The dependence structure in the dynamic problems
can be represented by using graphical models whose
structure changes dynamically, accordingly to the evo­
lution of the state space. Following Smith and Pa­
pamichail (1999), we can exploit such a representation
to develop approximate algorithms of propagation and
probability updating for non Gaussian dynamic sys­
tems that use well-established results for non-dynamic
situations. These algorithms are based on a generali­
sation of a time series method first introduced by West
and Harrison (1997) and adopted in Smith (1992).
Such methods are widely used in the simpler time se­
ries setting, for a recent review see Durbin and Koop­
man (1999). Although these procedures are approx­
imate they are algebraic and so extremely efficient.
In section 4 and 5 we show how the exactness of the
approximation can be measured formally. In the ap­
plication we have investigated, the approximations are
extremely good. Finally note that even in applications
where there are no time restrains and accurate numer­
ical routines can be run for long periods of time, this
approximate process is useful both to set the initial
distributional inputs and to monitor the performance
of the numerical algorithms which are often unstable.
We conclude this introduction by reviewing a little
background material from Bayesian graphical mod­
elling in the time dependent perspective. A typical
assumption in dynamic modelling is that domains are
assumed to be Markov, that is predictions about future
states depend only on the current states and therefore
to retrieve information at a certain point of time t we
just need to know the state of the system at time t- 1.
We assume also that the probability distribution over
the states 0T = { 9o, ..., 9r} specifying the stochastic
system till time T, is represented as a directed acyclic
graph (DAG) 9r, whose nodes are the parameters in
0r and that represent the conditional independence
structure implicit in the problem at each time T. The
graphical model YT not only provides a compact rep­
resentation of the joint probability distribution of the
process but also allows us to utilise results and efficient
algorithms that are developed for static Bayesian net­
works.
In particular it is possible to employ the popular prop­
agation algorithms defined over junction trees (see e.g.
Spiegelhalter et al. 1993, Jensen et a!., 1994). A
junction tree is defined as an undirected decompos-

able graph that can be constructed from a DAG g as
follows:
1. form the decomposable graph Q by linking all the
nodes in g that have the same child node, i.e.
have edges directed to the same node;
2. identify a sequence of cliques in Q, where a clique
is a maximally connected subset of nodes, that
satisfies the running intersection property, i.e.
given the sequence C[1], ... C[m], for any i, 2 �
i � m there is an index 1 � r(i) < i such that the
separator S[i, r(i)] defined by S[i,r(i)] = C[i] n
(C[1] U ... U C[i- 1]) is contained in C[i] n C[r(i)];
3. construct the undirected graph whose nodes are
the cliques C[1],. .. ,C[m], where for each i =
1,... , m, the clique C[i] is connected to the clique
C[r(i)] with an undirected edge if S[i, r(i)] f. 0.
Thus fast propagation procedures exist in high di­
mensional systems provided that the dimension of all
cliques is small relative to the dimension of the state
space.
In dynamic problems we can determine the junction
tree 7T associated to the Bayesian probabilistic net­
work YT over the states 0r by applying the construc­
tion above. The cliques Cr[1], ... , Cr[nr] in 7T con­
tain components of the state space 0r and the joint
probability distribution p(0r) is decomposable and
can be written as
p(Gr)

=

rr..:

p(il(0r[i])

m:: 0i)(0r [i,r(i)]).

(1)

Here 0T[i] is a subvector of 0r whose components lie
in the clique C[i], 1 � i � nr. The vector 0r[i,r(i)] is
a subvector of 0r[i] and 0r[r(i)] for r(i) < i and its
components are in the separator Sr[i, r(i)] contained
in the linked cliques CT[i] and Cr[r(i)] for the run­
ning intersection property. Finally p(i) and q( i) are the
marginal densities of 0t[i] and 0r[i,r(i)] respectively
1 � i � nr.
For instance all Markov processes have junction trees
whose nodes all lie on a single line. But a wide range of
other more complicated dependence structures can be
represented in terms of junction tree, see, for example,
Spiegelhalter et a!. (1993), Goldstein (1993). Smith
and Papamichail (1999) discuss in detail the formal
structure of such transformation from dynamic DAG's
to dynamic junction trees.
W hen all the variables in the dynamic system are
Gaussian, fast propagation algorithms over dynamic
junction trees are well known, see for example Smith
et a!. (1995). The probability associated to each clique

Approximate Learning in Complex Dynamic Bayesian Networks

is sequentially updated in the light of incoming data
via Kalman filtering (West and Harrison, 1997) and
calculations are all in closed form as it is shown in
section 2. In the non-linear case, when the sampling
distribution of the observations is not Gaussian, then
typically the posterior distribution of the states in the
system domain can not be determined in closed form
and its calculation usually becomes intractable. How­
ever the conditional independence structure implicit in
the graph still remains valid.
In section 3 we shall present an algebraic approximate
procedure that updates the probability distribution in
each clique for non-linear dynamic processes. By ap­
plying the approximate updating procedure proposed
by West et a!. (1985) for the estimation of the poste­
rior probability of dynamic generalised linear models
we shall be able to develop a propagation algorithm for
dynamic junction trees. This algebraic algorithm has
the advantage of propagating very quickly the infor­
mation through complicated dynamic processes. The
efficiency of this approximation is checked in section 4
by using the Hellinger metric. In section 5 the applica­
tion of such a propagation procedure is discussed for
the Poisson dynamic system associated to a gaseous
mass release process.
2

GAUSSIAN JUNCTION TREES

Let Y t denote an n-dimensional vector of observations
at timet fort = 1, ... , T. The time series Y t is a reali­
sation of a dynamic process whose state space at time
t is denoted by 01 = (61, ..., 91). The class of stochas­
tic processes we are interested in can be characterised
by the following properties:
(i) given the states 0r= (61, 62, ..., 9r) the variables
Y = {Y 1 , .. . , YT} are assumed all independent
of each other i.e. JLf=1 Yil0r.
(ii) The vector Y1,t= 1, ... , T can be partitioned in n1
subvectors Y1 = (Yt[1), ..., Y1(n1]) for 1 � n1 � n
and the density or probability function of each
Y tfj] for each j= 1, ..., n1 depends only on a lin­
ear combination of the states 91fj], say
(2)
-;

where F1fj] is a known matrix. Notice that, given
Atfj), the vector of observations Y tfj] is assumed
independent of all the other components of Y1.
(iii) At any time t the joint density of the states 01 is
Markov with respect to a decomposable directed
graph 9t whose set of nodes contains the states
01. The states 91fj] defined in (ii) are assumed to
lie in a clique, say Ctfj), in 9t.

587

An example of such a process is pictured in the graphs
in Figure 1. Property (ii) indicates that observations
at time t only give direct information about compo­
nents of the state vector at that time and assumption
(iii) ensures that observation vectors give direct infor­
mation about single cliques.
This situation arises very often. For example in a
Dynamic Linear Model (see e.g. West and Harri­
son, 1997 and Harrison and Stevens, 1976) conditional
on the values of states at time t, the observations
Y1, . . . , Yr are independent and furthermore Yi only
depends on current states which lie in the same clique.
In the spatio-temporal process described in Smith et
a!. (1995) an observation is taken at time t whose
expectation is linear in states, the linear combination
depending upon the site at which the observation is
taken.
The propagation procedures to update the Gaussian
probability density p(0t) over the states 01 in the
light of the observation vector Y t are reasonably well­
known and can be defined as follows. Notice that the
same procedure can be applied to determine how states
should be updated from a time series of observations
{ Y 1, , YT}, because the algorithm below can be sim­
ply iterated through the time sequence fort= 1, ..., T.
••.

Firstly construct the junction tree It from the DAG
9t and let Ct[1), ..., Ct[nt] denote the cliques in /1 for
some t. Notice that from the assumptions above each
clique C1fj] contains the states 91 fj] that are related
to some observation vector Y1fj] via the linear combi­
nation in (2). Therefore we assume that observations
Y1fj] give direct information about one clique C1fj] for
j= 1, ..., nt.
Suppose that the states 91fj] in clique C1fj] have a
Gaussian density with mean tt1fj] and covariance ma­
trix �1fj] and a Gaussian vector Y1(j] is observed for
which Ytfj] lL 9tfj]I.Xtfj]. Let mtfj] = F{fj]tt1fj]
and the matrix W 1fj] be the prior mean and covari­
ance matrix of .X1fj] = F{[j]91fj] at time t. After ob­
serving Y1fj], the posterior distribution of At[i] given
Y 1fj] can be calculated as Gaussian with posterior
mean m;fj] and posterior variance Wtfj] obtained by
standard conjugate analysis. Known results from mul­
tivariate normal theory (see for instance Mardia et
a!., 1979) now establish that, provided (Yt[j), 9t(j])
are jointly Gaussian, then the posterior density of
p(9tfj]IYtfj]) is Gaussian with mean ttWJ and covari­
ance matrix �� (j] calculated as

11-;fj]= 1'-tfil

+

A tfj](m; [j]- mtfj])

�;(i]= �t(j] + At[j](Wt"fj]- Wtfj])Af[j]
1
where Atfj]= �tfj]Ftfj](F{[j]�tfj]Ftfj])- .

588

Settimi, Smith, and Gargoum

Figure 1: Example of Bayesian networks and junctions trees for a dynamic process at timet and t + 1
So the posterior density of 81[j] of the random vector
associated with the clique C1[j] conditional on Y t [j]
is easy to calculate. Henceforth we shall call these
densities partial marginals. Of course what we really
need is the posterior clique margins given all the data.
Once these have been calculated, the information ac­
quired by the updated clique(s) must be transmitted
to the rest of the system. So we need to define a
propagation algorithm which updates the probability
density of the cliques that have not directly obtained
information from the data and adjusts the full prob­
ability distribution of the system in the light of all
the data. Notice that the probability decomposition
of p(6t) given by the junction tree Tt is still valid a
posteriori. Algorithms that transmit information from
clique margins to the all system have been around for
some time for discrete probability distributions (see
Spiegelhalter et al. (1993), Dawid (1992), Jensen et al.
1994) and are now well documented (see for example
Almond (1995), Jensen (1996)). Gaussian analogues
of these procedures are very straightforward and are
developed in Lauritzen (1992) and Smith et al. (1995).
One propagation algorithm, which is based on a two­
step algorithm described in Jensen (1996), is outlined
below.
We first introduce some notation. In the junction tree
neighbours of a clique C1[j], 1 � j �
nt are the cliques C1(k] for which either r(j) = k and
S(j, r(j)] is a separator or r(k) = j and S[k, r(k)] is a
separator in T1• Information can only be propagated
through neighbouring cliques.
T1, fort � T, the

To simplify the notation, let U, V denote two neigh­
bouring cliques in Tt. with separator S = U n V. The
cliques U, V have distribution with respective mean

vectors (P.U5
\ • /l-5) and (p.�\5, p.�) and covariance ma­
trices

[ E ���5
E

E5

] [ E ���5
E

E�

]

We shall say the the clique V absorbs from a neigh­
bouring clique U with common separator S, if the
updated distribution of V has new mean vector
(p.':_,5
\ ' Its) and covariance matrix
where Its

=

/l-5, Es = E5

calculated as

p.':_,5
\ = 1'�\5 + Av\5(1'5- p.�)
E':_,5
\ + Av5
\ (E5- E�)A�5
\
\ = Ev5
5
\
E5
E':_,5
=
Av
\ 5
,

(3)

where AV\5 = Eh55
, (E�)-1.
Thus to transmit information from the updated mar­
gins of the observed cliques we follow the two step­
algorithm proposed by Jensen et al. (1994) defined by
the sequence of operations below:
(i) choose a clique in the junction tree Tt, and name
it root.
(ii) apply " absorb" from the cliques that have re­
ceived information to neighbouring cliques follow­
ing paths towards the root clique, until the root
is reached (collect evidence);
(iii) apply "absorb" from the root to the neighbouring
cliques following paths that departs away from the

Approximate Learning in Complex Dynamic Bayesian Networks

root, until all the cliques have "absorbed" infor­
mation (distribute evidence).
At this stage the derived mean vectors and covariance
matrices of the clique Ct[j] will be those of 61[j] con­
ditional on all data Y t (a proof of this assertion can
be found in Dawid, 1992). The full joint probability
density conditional on the data can now be obtained
from the decomposition in equation (1).
Thus provided (Sr, Y T) are jointly Gaussian, the pos­
terior distribution p(SriYT) is simple to calculate al­
gebraically. Indeed it is Gaussian with mean and co­
variance matrix calculated in closed form as sequence
of operations given in (3). However, unless the distri­
bution of Y1[j] given At[i] is purely discrete or Gaus­
sian, there are only few distributions for which an ex­
act algebraic algorithm like the one given above exists
and for which the vector of states Sr continues to
lie in a recognised family of distributions, see Lau­
ritzen (1992) for some exceptions. The problem is
that although the probability breakdown in equation
(1) is still valid, the posterior marginal densities of
the states in cliques that receive information can no
longer be written in closed form. To sidestep these
problems Goldstein (1993) works in a simpler context
of linear estimators and produces algebraic algorithms
to update the probability distribution over the states.
An alternative algorithm (Thomas et al., 1992) uses
numerical integration methods such as Markov Chain
Monte Carlo methods to update the clique margins.
This methods, which can calculate numerical distri­
butions to arbitrary degrees of accuracy, has much to
recommend it. However because its output is not al­
gebraic it tends to be very slow in complex and very
large problems. Furthermore it is much more difficult
to investigate how the system learns from the data and
to monitor the assumed dependence structures in the
light of the data.

--;

In this paper we suggest a different route. This uses
the updating techniques of Dynamic Generalised Lin­
ear Models D.G.L.M's (West and Harrison, 1997). We
treat West and Harrison's algorithm as if it were a
dynamic approximation technique of a full Bayesian
analysis, This interpretation to their algorithm is de­
veloped in Smith (1992). Henceforth for the sake of
simplicity we shall assume that A1[j] = F{Ot[i] is one­
dimensional. However we remark that multivariate
analogues are straightforward to develop.
3

DYNAMIC GENERALISED
LINEAR JUNCTION TREES

Suppose a random variable !Jt[j] belongs to some
parametrised family of densities IJ.i which is closed un-

589

der sampling of an observation Yi[j] whose distribution
conditional on !)t[i]!ies in a family Y. For simplicity
of exposition West and Harrison (1989) choose to re­
strict Y to be the exponential family although this
condition is not strictly necessary for their algorithm
to work. Now assume
(4)
where Yi is a known invertible function and At[j] is a
linear function of the uncertain state vector 91[j] as in
equation (2). Because the distribution of A1[j] is Gaus­
sian it is unlikely that the density of !Jt[j] = gj1(A1[j])
will lie in IJ.i. However, provided that the function Yi
is chosen appropriately and IJ.i is two dimensional it
will often be possible to find a density jl(7)1[j]) E IJ.i
which is very close to the transformed Gaussian den­
sity p(!Jt[j]) of !Jt[j]. In fact in practice this will often
be true when for each index j the functions Yi are iden­
tity maps - see the example in section 5. A more exact
but complicated choice for Yi specified as a function of
the predictive distribution function of !)t[i] is discussed
in Smith (1992).
In practice, to ensure not only that recurrence equa­
tions can be written in a closed form, but also that the
states of the process retain relationships between each
other which are straightforward to explain, we usu­
ally choose simple functions Yi and elementary ways
of approximating p(!)t[i]) by jl(!Jt[i]), for example, by
equating the moments of these two distributions.

Conversely it should be possible to find a transformed
Gaussian density q(!)1[i]) which is close to any density
q(!)t[i]) E IJ.i that might arise in our analysis. Appro­
priate definitions of closeness will be discussed in the
next section. So assume that a good simple approx­
imation of this type is available. We can now find
an approximate algebraic method of probability prop­
agation analogous to the one defined in section 2 for
Gaussian domains.
Suppose that Yi[i] depends on !)1[j] = gj1(At[j]) where

At[i] = F{[j]91[j] is a linear function of Ot[i] whose
components all lie in the same clique Ct [j]. If 91 is
Gaussian then in particular At[j] will be Gaussian.
Now identify the density jl(!)1[j]) lying in a family
closed under sampling to Yi[j]I!Jt[j] which approxi­
mates the density p(!Jt[j]).
Next perform a conjugate analysis to find the poste­
rior density jl(7)1[i]IYi[i]) which will lie in IJ.i. Iden­
tify the Gaussian density on A1[j] for which gj1(At[j])
has approximately the density jl(7)1[i]IYi[i]). Notice
that, through this operation, we have approximately
updated the marginal distributions of the states in the
cliques C1 [j] that are " observed" and furthermore our
approximation sets each of these distribution to be

590

Settimi, Smith, and Gargoum

Prior Distribution of
7Jt[j], At[j]

Distribution of Posterior mean
mt[j] of At[j]
Yi Lii
l 7Jt[j]

Normal

Normal

7Jt[i] � N(mt[iJ, wW])

Posterior variance
w;2 [j] of At[j]

A t[i]Vt[j]=
(1- A t[iJlwWJ

N(7Jt[i], Vt[j])

At[j] = 7Jt[j]

A t[j·]-

Gamma
7Jt[j] � G(at[iJ, .Bt[i])
at[j]= mWJ/wWJ,
.Bt[i] = mt[i]fwWJ
A� N(mt[j], wW])

Poisson
Po(7Jt[j])

Log-normal
log7J � N(at[j], .Bt[ill

Log-normal
log Yi[ili7Jt[j] �

mt[j]= E(7Jt[i]) = e(a,[iJ+!tJ,[i])

N(log7J, Vt[i])

A t[j]m;[i]

A t[j] =

wWJ= Var(7Jt[i]) = (eMil - 1)mWJ
>-t[j] � N(mt[j], wW])

Assuming that the sampling distribution of the obser­
vations Yi[j]is Poisson or Log-normal and that the ob­
servations Yi[j]depend on a linear combination At[j]of
states which lie in a single clique, Table 1displays the
expressions for the mean and variance of the posterior
distribution of At[j]calculated by applying the approx­
imate updating procedure described above, when the
link function 9i is the identity (so At[j] = 7Jt[j]). No­
tice that in Table 1, the updating procedure essentially
consists of approximating the posterior distribution of
At[j]as a Gaussian with mean and variance calculated
from the posterior distribution of 7Jt[i].
Notice that the obvious difference from the Gaussian
case is that now the posterior variance of A[
t i]IYi[i]
can be a function of Yi[i]. Other examples of such
updating using nonlinear link functions are given in
West and Harrison (1997).
Hence the calculation of the marginal distribution over
the "observed" cliques using equations like those in

wWJ
(wWJ+ m[
t j])

(eA.(j]Vt(j]- 1)mi2[jj
(mt[j])(l-A.(j])(Yt[i])A.(j]
.
log(mWJ+ wW]) -logmWJ
A tfj]log(mWJ+ wW])-logmWJ+ Vt[i]
_

Table 1: Some illustrative examples where the link function g(·) is the identity function.
the prior mean and variance of At [j]), respectively.
Gaussian. Thus now we can transmit information and
update the probabilities in the junction tree by using
the propagation algorithm described in section 2 for
Gaussian systems and so calculate the full posterior
distribution over the states. In a time series context
this forms the prior density of the states for the next
vector of observations.

wWJ

wl[i]+ Vt[i]

(mt[j] and wWJ are

Table 1 and then using equation (2) to perform this
approximate probability propagation is just as quick
and simple as the exact case when the sampling dis­
tribution is Gaussian. The speed and simplicity arises
because the method is algebraic and the approximat­
ing distribution over the states 8r is Gaussian. So a
very slight change to the code allows the quick process­
ing of data which does not have a Gaussian sampling
distribution. This is now coded in software: see Smith
and Faria (1997), Smith and Papamichail (1999). Of
course the validity of the approximate updating algo­
rithm described above depends critically on how well
the true posterior density of 8t IY t is approximated by
the Gaussian one calculated by our algorithm. Meth­
ods to check the accuracy of this approximation are
given in the following section.
4

MONITORING THE DYNAMIC
APPROXIMATION

In this paper, we choose the Hellinger metric defined
by

dn(f, h) =

( I /l/2(x)hl/2(x)dx) 1/2
1-

as divergence measure between densities. It always
takes values between zero and one and when f and

Approximate Learning in Complex Dynamic Bayesian Networks

h are absolutely continuous equals one only when the
supports off and h intersect on a set of measure zero.
The Hellinger metric is topologically equivalent to the
variation metric
dv(f, h) = 1/2

J lf(x)-h(x)ldx = s�p IP,(A)-Ph(A)I

where A is any subset of values of x and P1 and Ph
are respectively the probability of the set A under f
and h. Explicitly it can be shown that

see, for example Reiss (1989). So, in particular, when
the Hellinger distance between two densities f and g
is small then we know that all probability statements
associated with the two different models are close. The
Hellinger metric is therefore a useful measure of the
closeness of two densities. Write
l(f,g) = 1 -cfH(f,g)
Then, for example, the Hellinger distance between two
normal densities /1 and h with respective means and
variances (p1, a?), (P2, a�) can be calculated from

12(/!, h) =

1
aw2 exp{
-1/2(a? +a�)- (/.LI- /.L2)2}.
�
2
a +a
l

2

In fact a property of the Hellinger distance which
makes it easier to manipulate than the variation met­
ric is that cfH(f,g) can be calculated in closed form
for densities in most standard families, including the
exponential family. It is also sometimes possible to ex­
plicitly write down the Hellinger distance between two
densities from different families, see Smith (1995).
Thus when f is Gaussian with mean p and variance
a 2 and f' is a Gamma density with the same mean
and variance, then I(!, f') after some algebra can be
calculated as

�f(tr 1]))2 el/2<>

( (1/
[2(!, !') = (27r)-l/22(a-l)(tl/2a r
where a= �-t2fa2.

(5)

We note that the two properties listed below also
hold true both for the variation metric and the pop­
ular Kullback-Leibler separation measure (Kjaerullf,
1 992). Suppose that p and p are joint densities on
X = (X1,X2) which have different margins PI and
PI on X1 but whose conditional densities of X 2 IX 1
agree. Then, directly from (4) we have that
(6)
Now the algorithm we suggest above approximates
only the distribution of >.. The distribution of all the

591

states given A is the same both for the true and the
approximating density. It follows from (6) that the
closeness of the full joint density over all states 9T
depends only on the closeness of our approximation of
the one dimensional normal posterior density of A to
the true posterior density of A . If we can ensure the
approximation of the distribution of A is close to the
true one under our algorithm then our approximation
will be good in the sense that all approximate prob­
ability statements about states will be close to their
exact analogues.
In a dynamic context predictions usually depend only
on a subvector ek of states eT. For example in the
D.G.L.M predictions only depend on the current state
vector. Similarly in Smith et a!. (1995) the compo­
nents of eT lying in cliques which are not parents of
other cliques are the only components required for the
prediction of the future levels of contamination. Now
it is easily checked that
(7)
where Pk,Pk are the densities of ek under the true
model and its approximation. Now consider accom­
modating a sequence of observations Y1, ... Y;, . . . each
vector having components which are functions, pos­
sibly with error, of variables in a single clique, to
obtain an approximate posterior density p on states.
Although errors associated with the approximation,
given in equation (8), will tend to accumulate in p, this
accumulation will tend to be offset by the reduction of
error in (7) associated with the act of marginalising
states relevant for linear prediction.
5

AN EXAMPLE FROM
DISPERSAL MODELLING

In the Gaussian model given in Smith et a!. (1995),
used for predicting air concentrations after a nuclear
accident, it is often most natural to assume that the
distribution of observations conditional on their states
is Poisson. The states eT are the quantities of mass
under puffs and fragments of contamination where
puffs are emitted stochastically from a chimney and
then directed by a known wind-field across space. The
Markov nature of the stochastic emission process and
deterministic fragmentation process, means that the
joint distribution of mass fragments at any time is de­
composable with its clique dimension not greater than
six (see Smith et a!., 1995 , for more details)
The appropriate updating equations for the linear
combination of state vectors A t [j] = Jlt [j] we learn
about, is displayed in Table 1, given a model with
identity link function. It is also possible to calculate an

592

Settimi, Smith, and Gargoum

upper bound on how good the approximation is by us­
ing the Hellinger divergence measure du. Let Po (eT)
denote the Gaussian prior density on the states eT.
Let p and p denote the posterior density on 8T given
the true normalised Gamma likelihood £2 associated
with a Poisson observation Yt or a normalised Gaus­
sian approximation £1 of the D.G.L.M., respectively.
Then by using the equality (6), the Cauchy-Schwartz
inequality on I(p,p) and the triangle inequality on dH
it can be shown after tedious algebra that

where

£1
£2

=
=

J2r[dH(Ll, L2 )+ dH(L2 , £2 )]
1 2
2
eo[(c2 - c2 ) + 2c2 c2 d�(k2 , k2 )] 1

where L2 is a normalised Gaussian likelihood with the
same mean and variance as £2 ,

c�

=Ip�(fJ)d9, q =I p�(9)d9,

c�

=

l .t�(9)d9,

It can be shown that £1 and £2 are very small when
using the D.G.L.M approximation when the parame­
ter a in the Gamma likelihood discussed in (5) is of
moderate size. Note from (5) that .=1 can be calculated
explicitly. All terms in £2 can also be calculated ex­
plicitly, except for �H(k2 , k2 ). This term can be given a
tight explicit upper bound using the triangle inequal­
ity (Gargoum, 1998). So we obtain an explicit upper
bound for �Has a function of the parameters of the
model and the observation.
These calculations are now implemented within RO­
DOS software (Smith and Faria, 1997) and are used
as a diagnostic to check whether the sequential Gaus­
sian updating described above is actually theoretically
justified. For the types of data we experience it has
been checked through many runs of this algorithm
that the Hellinger distances approximations between
the approximate and actual densities are nearly always
bounded by very small numbers.
An exception to this is when the data is incompatible
with the probability statement of the model, however
this extreme event is typically picked up by diagnostics
run with the model. We also may have large discrepan­
cies when the Poisson counts are small. In the chosen

context, main concern is focused to cases where Pois­
son counts are large as they correspond to high levels
of radioactivity. So the clique states ek of interest,
are usually geographically remote from low counts. It
follows that the approximation of the distribution of
ek usually remains a good one. So we have shown
that in at least one application, these methods are not
only very quick but also surprisingly accurate.
In Settimi and Smith (1998) the goodness of such an

algebraic approximation is analysed by using MCMC
methods. The approximated posterior distribution of
the states for a dynamic process with Poisson sampling
distribution is obtained from the algebraic procedure
and compared with the "true" posterior distribution of
the states calculated numerically by a Gibbs sampler.
The results show that the algebraic approximation is
very good when observations are consistent with the
assumed model, however a decay in the efficiency of
the approximation is noted as the observations tend
to depart from the predicted values of the model. To
be more precise, when unexpectedly low counts are
observed, the algebraic method seems to overestimate
future observations, while, if large counts occur, the
approximate method gives prediction similar to the
Gibbs sampler output and the effect of such extreme
data is negligible.
Using the rather crude bounds on the Hellinger dis­
tance, it was possible to show that the aggregated
effect of the sequence of approximation used within
the method could distort any probability forecast by
no more than 0.01. Numerical investigation currently
being undertaken appear to show that this bound is
of order of magnitude too large for the predictions of
high levels of contamination. However even aggregat­
ing on the possible distortions ignoring the effect (6)
and using these crude bounds within the context in
which the software is implemented, we notice that the
contribution of error associated with the approxima­
tion is confounded by other sources of error associated
with the model (see Ranyard and Smith, 1997, for a
discussion of these modelling issues).
6

CONCLUSION

This analogue of dynamic generalised linear models,
when used on junction trees, gives a quick compu­
tational approach for dealing with non-normal data
which is easy to understand, gives a closed form updat­
ing algorithm and provides an approximation whose
validity can be checked numerically - for example by
using the Hellinger distance metric. In an iterative
system where quick calculation is essential and easy
interpretation is paramount it is our opinion that the
methods described in this paper provide a practical

Approximate Learning in Complex Dynamic Bayesian Networks

methodology for quick Bayesian inference in complex
dynamic systems.
Acknowledgements

The research work of Raffaella Settimi and Jim Q.
Smith was supported by Engineering and Physical Sci­
ences Research Council (grant no. GR/K72254)
