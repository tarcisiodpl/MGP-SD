

I

Decision-theoretic control of search has
previously used as its basic unit of com­
putation the generation and evaluation of

I

a complete set of successors. Although this
simplifies analysis. it results in some lost
opportunities for pruning and satisficing.
This paper therefore extends the analysis
of the value of c omputation to cover in­
dividual successor evaluations. The ana­
lytic techniques used may prove useful for
control of reasoning in more general set­
tings. A formula is developed for the ex­
pected value of a node, k of whose n suc­
cessors have been evaluated. This formula
is used to estimate the value of expanding
further successors. using a general formula
for the value of a computation in game­
playing developed in earlier work. VVe ex­
hibit an improved version of the MGSS"
algo rithm giYing empirical results for the
game of Othello.

I
I
I
I
I
I
I
I
I
I
I
I
I

ing are lost. in particular those opportunities taken
by alpha-beta search to stop generating success ors
aos soon as the node is found to be valueless. Sat­
isficing effects are also lost. These come into play
when a node has a large number of successors; it is
often necessary to examine only a small number of
them in order to get a good estimate of the value of
the node [Pearl. 1988].
In this paper. I attempt to rectify the sit.uation by
extending the analysis of the value of computation
to the case of single successor generation and evalu­
ation. To do this, the following steps are followed:
1. Derive a form ula for the expect.ed value of a
node when only a subset of its successors have
been evaluated.
2. Use this formula to estimate the value of ex­

panding further successors. using the general
formula for the value of a computation in game­
playing [Russell and Wefald, 1989].

3. Derive pruning conditions. under which a node ·s
expansion must have zero expected benefit.

.

1

Introduction

[1988, 1989. in
press). the author developed all approach to control­
ling comput.ation based on ma.ximizing the expect.ed
value of comput.at.ion. The method involves dividing
the bac;;e-level decision-making process into atomic
steps, such that the st.ep with the highest expected
value is taken at each juncture until the value of
further computation is negative. The resulting alg�
rithms for single-agent search and game-playing have
exhibited good performance. However, several re­
strictions were imposed to simplify the analysis. One
such restriction identified the computation steps in
game-playing with the complete one-ply expansion
of a leaf node. rather than allowing the program to
control the generation of individual successors. This
si mplificati on has several advantages. including the
fact that the nodes in the tree have well-defined val­
ues at all times when min or min-max backup is
used.
On the other hand, some opportunities for prun-

In earlier work with Eric Wefald

Using the formula from step 2. and the prun­
ing conditions from step 3, implement the alg�
rithm and demonstrate its performance.
The sections of the paper parallel these steps, more
or less. While the formula<? developed look quite
formidable. the basic ideas are straightforward, and
a number of qualitative insights are obtained.
4.

The value of a partially expanded

2

node
Consider a min-node j, k of whose n successors
h ave been generated and evaluated, yielding values
u1
u�,-. The expected value of the node j is clearly
less than or equal to min�: (j) = min( u1
Uk ).
Alpha-beta search uses this inequality to prune cer­
tain nodes before all their successors have been gen­
erated. For a calculation of the expected value of
generating and evaluating one more successor, the
k + 1th, we need a more precise description of the
expected value of the node. To do this, we calculate
a probability distribution for the value of the mini­
mum of the n successors. given that k of the n have
already been evaluated.
•

•

•

•

•

•

I

437

I
I

·;

I
/
0

Figure 1:

Pfo,q for

q

=

standard normal curve

No,1

The desired distribution is essentiallY a truncated
version of the general distribution for the minimum
of some number of random variables. The latter
distribution. which we shall call the p<-distribution
(pronounced ·p-min'). depends on the distribution
from which the random variables are drawn. Let us
assume that the successor values are drawn at ran­
dom from a distribut i. on q. which is specific to the
node being expanded. Define the probability distri­
bution P�.q as the densit�· function of the minimum
of n random variables F1
C, drawn from a distri­
bution q. The relation between q and P�.q is most
easily seen by examining the cumulative distribution
function for p<. The derivation is standard in the
area of order stat.istics.1
•

•

J P�,9(y)dy

-oo

f.',)$ .x)
= prob(min(Ul
= 1- prob(rnin(lTl� .. ·� l:n) > z)
= 1- prob(((-1 > x) A A (Un > x))
= 1- (1- Q(:r))rl
(1)
.

.

.

.•

• • •

where Q is tht> cumulative distribution function cor­
responding to q. Hence

d
P�.q(.x) = d [P�q(:r)] =
x

nq(:r)(1- Q(.x))n-1

Figure 1 shows the distribution P�,9(.x) for n
10 associated with the normal distribution q(.x)

(2)

=
=

1\'o.d.x).

1\'ow we can easily compute the distribution of
the minimum of the n successors, given that k of
1'We assume here that the successor ''alues are inde­
pendent given the distribution. In fact, .we could con­
sider updating the parameters of the distribution as suc­
cessors are observed. While thit< extension would present
no serious difficulty, the results obtained without it. are
adequate.

the n have already been evaluated. If mink is tht>
minimum value of the first k successors. then t he
minimum of all n successors is clearh" less than or
equal to mink. For z· < min1r. the p;obability that
min, = min( u1 . .. .. u, ) lies between :rand :r+d:t is
just P�-1:,9(x )dx. We will use the notation tp�q.m (:r)
(""truncated p-min") for the probability
. distribution
of minn when there are I unevaluated successors and
the minimum of the evaluated successors is m. Then
if :r < m
if :r = m
otherwise

•

:r

P,�9(:r) =

Figure 2: tp�q.-1.1, the density function after two
successors

(3)

where 6(x) is the unit delta-function at :r. A typical
instance of tp< is shown in Figure 2. where it is as­
sumed that six successors have been generated, with
a minimum value of -1.7.
We will use the notation b�9(m) to denote the ex­
pectation of the tp< distribution, as a function of
the truncation point m. A typical inst.ance of b< is
shown in Figure 3. superimposed on its correspond­
ing p< curve. As m - -x. the b< curve is asymp­
totic toy = m. while as m - oc. the curve is asymp­
t.otic to y = c, where c is the expectation of the p<
curve.
The expected value of the node after k suc­
cessors have been evaluate. d is therefore given by
b�-l.:,q(min�:). The function b<, and its dual func­
tion b>, thus replace the standard min and max used
in backing up leaf node values towards the root.
3

The value of evaluating further
successors

In [Russell and Vv'efald. 1989], general formul� are
given for the expected value of carrying out a compu­
tation that affects the estimated value of a node in a
game tree. Here we consider the value of further ex­
panding a min-node j that is in the subtree of some

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I

438

I
\

r-..

I

\

o(

,.-'
�------��-- --�,
��0------ ---------+u
,
.,

I

c

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

F igure

3:

b�,g ( m)

p lot. ted with P�,

q

t op-l evel move /3; ot h er than the current best move
(the three other cases are handled an a l ogou sly ). In
this case the expe cted benefit �( 5j) of the c om p u­
t.ation Sj th at expands some successors of j is given
by

J p;j(x)(;r- a)
oc

E(.�(Sj ))

=

d:r

(4)

a

where Pii is the density function for the new value
of the top-leve l move .8i aft er the c ompu tat ion Sj,
and a is the value of the current best move.

3.1

How node values are propagated

One of the basic t.echniques used in this approa ch is
to wri te the value of the top-leve l move as a func­
tion of the val ue of the leaf node (and other nodes).
Then we can use a standard theorem to re write Pii in
terms of Pii. th e density function for the new value

of the node j.

To derive a formula for the value of the top-level
n ode. I will first go through a particula r exampl e ,
and then ask the r eader to take the ge neral formula
on faith. Consider figure 3.1, which depicts a par­
tial game search tree in which th e root node has
been fully expanded. but other nodes are only par­
tially expanded. The computation under considera­
tion is the further expansion of the node labelled j;
the comp utation will have value. according to equa­
ti on 4, only if it causes the value of node a to be
raised above o. the value of the current best. move.
In the following I will adopt the notation b�(m) to
den ot.e the b< distribution associated with node z
-that is, bt9 where l is t he number of unexpanded

successors of :r and q is the distribution from which
the values of :r 's successors are drawn. �1here no
ambiguity arises, I will use the name of the node to
denote its current value also.

Figure 4: A partial game tree c ontaining p ar tial ly
exp a nded nodes
First consider the value of node a. As e xp lained
in the previous s ecti on ,
a=

b�(min(b,c,d))

Now since b< ( m ) is monotonically in creasi n g in m.
can only increase its value if b has the lowest value
among its siblings and has its valu e increased (we are
assuming that the values of c and d are u na ffect.ed
by an exp an sion of j). It th eref ore makes sense
to rewrite min(b.c.d) as min(bound(a).b) where
bound(a) is the minimum va lue of the oth er succes­
sors of a. Thus
a

a=

b�(min(bound(a), b))

Going down the tree, we can repl ace
u p value of its successors:
a=

b�(b)

=

backed­

b�(min(bound(a).b?(max(i,j)))

Again, we can write
giving us
a=

b by the

mar(i,j)::: max(bound(b),j).

b�(min(bound(a).b?(max(bound(b),j))))

general, the max and min

will intervene in the
and P's a t every max and min
node respectively o n the path from j to the top level.
The general formula for a top-level node n1 in terms
of a min-node j at depth 2d + 1 is therefore
In

composition of b< 's

n1

b�1 (min(bound(n1),

==

•

•

•

b�:h (maz(bound(n2;),
b;M1 (min(bound(n2i+1 )
b�:�4 (max(bound(n2d), j)).. ))) ) .. ) ) ( 5)
•

•

•

•

where n1
n2d are the nodes on the pa th from the
root to j. This expression will be denoted by f(j),
•

.

.

so that f is the pro pag a t.ion function from a node
t.o t.he first level of the t.ree.2 1\ot.e that in t.he st.an­
dard minimax algorithm. the propaga tio n function
is identi. ral except that b< beco me s min. etc
. .
3.2

The new value of the node being
expanded

The computation step Sj will involve evaluating suc­
cessors l· + 1 through k + s. adjusting the estimated
value of the node j. and propagating the effects of
that adjustment. Afte. r the expausion, j will have
t = 11 - k - s successors remaining unexamined.
The values UA·+I
u�:+� of the s successors will
be drawn from the distributi. on q associated with j.
Let. m� = min( uk+l•
, uk+� ). Then after drawing.
the value of the node j will be given by
•

•

•

.

j

=

=

•

•

g(m,) = b�9(min(min�:(j). m,))

{ b�9(m,)

if m, < min�:(j)
b�9(min�: (j)) otherwise

(6)

(going back to the full notation for b < ). Thus j,
considered as a random variable (the new value of
the node after expansion). is a. function g of the ran­
dom variable m,. where g is defined by the above
equation.
3.3

The value of expanding the node

\Ve are now ready to re-express the densit.y function
Pij of the new value of the top-level node (call it n 1)
from which j is descended. \Ve have

111 = f(j)

=

f(g(m, ))

where. again. m, is dist.ributed according to p�9•
Then following the standard theorem for distribu­
tions of functions of random variables, we obtain

P;j(:r)

=

I

P�q(u-1(J-1(:r))) �.u-1(f- 1 (.:r))

l

(i)

Let us consider the sign of the differential expression
in this equation. As mentioned above, both b< and
P are monotonically non-decreasing. as are min and
max. Furthermore. monot.onicity is preserved under
both composit.ion and inversion, hence the differen­
tial expression is always non-negative. Therefore,
combining equations 4 and i, we obtain

J PiJ(:r)(:r- o)d.:r
oc

E(�(SJ ) )

=

Q

"'here the integral range ma�· be r es t ric t e
. d to where
defined. A quirk glanc e back at
the definitions of f and g (equations 5 and 6) will
be enough to
. convince the reader that this expres­
sion for the value of computation is not that easy
to evaluate on the fly: nor does it make i mm ediately

y-1 a nd J-1 ar<'

clear which nodes will ha.ve zero value for expansion.
In the next section both deficiencies are more or less
remedied.
4

Obtaining irrelevance criteria

A node is irrelevant to its top-level ancest.or if there
is no way that a change in the value of the node
can change which move is currently regarded as
best [Russell and Vv'efald, 1989]. This criterion is
equivalent to the rhs of equation 8 being zero. Basi­
cally, this comes about because the min's and max·s
in the definition of f act as a filter on changes being
propagated from the node j whose value is chang­
ing, just as in alpha-beta pruning. It is possible to
rewrite the expression for f to make this clear, and
to yield more explicit irrelevance criteria.3
As before, it. will be simpler to illustrate the
rewriting process on the particular example shown
in figure 3.1. First, note that the propagation func­
tion is monotonic: therefore only increases in node
values along the path from j to a are interesting.
If any max node on the path (such as b) is not the
lowest-valued known successor of its parent, then it.
cannot increase the value of its parent. aud is there­
fore irrelevant. This immediately gives us a pruning
test on max nodes.
We will assume. to simplify the exposition. that
the above pruning test has been implemented, and
we are therefore considering expanding a node j such
that. all of its max ancestors are lowest known suc­
cessors. In the case of figure 3.1, we get. a simplified
expression for a, for values of b close to its current
value:
a=

j

p�9(u)(f(g(u))- a) du(S)

g-1(!-l(o)l

using

u = g-1(f-1(:r))

2Rivest [1988] uses a similar idea to derive his
Min/Max Approximation search algorithm.

b�(b?(max(bound(b),j)))

To rewrite this, we can use the identity

b�(max(:r ,y)) = ma:r(b�(:r),b�(y))
and other analogous identities for b< and for mir1.

It should be noted that these identities hold for
any monotonic function, including arbitrary compo­
sitions of b< and P. We have

a

=
=
=

g-lu-lloo)l
=

439

b�(b?(max(bound(b),j)))
b�(max(b?(bound(b)), b?(j)))
ma.x(b�(b?(bound(b))), b�(b? (j))))

-:::----

30bviously, it is possible to derive these irrelevance
criteria without. recourse to an expression such as f(j ).
as is usually done for alpha-beta search. However, as well
as ensuring that no opportunities for pruning are missed
- as deep cutoffs were missed in alpha-beta -the more
formal analysis should be helpful in more complex cases,
such as probabilistic games, where informal argument
runs out of steam.

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I
I

Thus we see that j will only affect the top-level node
if its ne"· value exceeds bound( b). \\"e can apply the

same re"·riting process to the

f(j ). obtaining
111 =ma:J:(

I
I
I
I
I
I

b�l(b;,2{b�3(b;,.(. .. b;,2d(j))))) (9)
Thus for its effect to be felt. at the top level. the valu('
of j must exc('ed a series of lower bounds derived
from the max nodes on the path to the root. Call
th(' maximum of these bounds 1(j). In t uiti vely. r(j)
is the level that the value of j must reach in order to
have any effect on its top-level ancestor. Since the
value of th e j can never exceed the current minimum
of its successor values. then if this value is less than
r{j) we can deduce that j and all its successors ar('
irrelevant. This gives a second simple pruning test
for relevant nodes.
Assuming that the node j is relevant under the
criteria above. we can now derive an upper bound on
the amount by which the t.op-level node can change
its value. To cut a long story short, the original
expr es sion is simplified to

n1

I
I
I
I
I
I
I
I
I
I
I

b�1 (b�,(bound( 112 ))),
b�1 (b(,2 (b�3(b?,. (bound( n4))))).

=min( b�1(bound(n!)),
b�1 (b�)b�3(bound(n3)))) ),
... .,
b�l(b?.2 (b�/ b;,. (... b ?.2d (j)))))(10)

The minimum bound from the min nodes other than
j is called the � bound [ Russell and v.·efald. 1989]
of the node j. Intuiti vely. b(j) is the highest value
to whicl1 an un boun d ed increase in j can raise i ts
t.op-level ancestor. Clearly, if tJ(j) is lower than a:,
then j and all its descendants are irrelevant.
To summarize. a node that is not a descendant
of the current best move must pass four tests to be
counted as relevan t:

1. Its parent must be relevant (unless
is the root ) .

the pare nt

2. Max nodes must be lowest known s ucc essors .

3. Min

nodes must be able to exceed their ;

bound.

4.

The b value of the node must ex ceed

a:.

If these conditions a re met, then we can write

f(j) =b�1(b;,2(b�3(... b;,2d(j))))
for J-1(a) :S j :S J-1(b). Thus all the cond it ion als
(min's and max's) are eliminated, and we can write
o-�u-1(61)

E(A(Sj ))

=

j

g-l(j-l(o))

p�9(u)(f(g(u))- a ) du

( 11)

+

general expression for

for the rang(' in which y-1 is defined.
T he simplified f fu nc tion is well-behaved. but the
g function contains a discontinuity at u =min�..,(j).
beyond which y-1 is undefined. The expression must
therefore be evaluated by cases. depending on where
the discontinuity falls relative t.o a aiJd b. To cut
another long story short, here are the resulting ex­
pressions:

I.

6, a

>

f((mink(j))
E(�(Sj�)) =

II.

0

( 1 2)

a< f(g(mink(j))) < 6

E(A(Sj, ))

= f(g(mink(j))) [l- P3�9(mink(j))]
a[1- P,�9(b�9-1 (f-1 (a)))]
mink(j )

j

+

p�9(u) f( b�q(u))du (13)

h�q -l(j-1(0'))
III. 6.

a < f(g(mink(j))

E(A(Sj,)) = 6[1- P,�9(b�9-l(f-1 ((6))))
- a[1- p3�q(b�q -l(f-1 (a)))]
b�9 -�u-1<6JJ

+
b�9 -

j

p�9(u)f(b�9 (u) )du (1 4)
1 (f l ( o ))
-

There are three other sets of equations analogous
to these. for max nodes relevant to top-level moves
other than the current best, and for min and max
nodes relevant t.o the current best move.

Implementation

5

The basic structure of the search algorithm is iden­
tical to that of the MGSS* algorithm described
in [Russell a nd V\:efald, 1989]:

1.

Keep taking the computational action with the
highest expected net value (benefit minus cost),
until .n one has positive value.

2. Take the move that has the highest expected
value after the computations in 1.
The algorithm was implemented by rep lac ing the
function that generated all the successors of a node
by one that generates just one more successor. The

441
fulJ(·tion for computing the value of such an expan­
sion is a direct implement.ation of the above for­
mul&. with some approximations: the funct.ion re­
turns the highest expected benefit per successor ex­
panded. The algorithm maint.ains b values for all
relevant nodes. and decides relevance a.c; new nodes
are generated using the criteria given above. Finally,
the backing-up function. formerly min or max, is re­
placed by b< or b> .
All the distributions and backing-up functions can
be calculated exactly in terms of standardized dis­
tributions - those derived from q = /1:0.1, the stan­
dard normal curve. The standardized distributions
are t.abulated offline or computed from an exact for­
mula.
The only difficulty that arises is in computing the
integral of p<(u)f( b< (u)). It is possible to provide a
tabulated value when f consists of only a single ap­
plication of b < or P, but deeper nestings make the
tables unrealistically large. Examination of the b <
and P functions. from which f is composed. shows
that at the low (or high. respectively) end they act
as identit-y functions; thus the significant filtering
comes from the high (or low, respectively) end. The
program therefore approximates f, for the purposes
of the integration. by the b< or P function that
exhibits the most critical filt.ering. \Ve are also ex­
perimenting with other methods of approximation.
The source of all the node-specific functions is the
myst.erious q distribution from which successor val­
ues are drawn. The M Gss· algorithm used statisti­
cal data. gathered for Othello. of the relative value
of the best successor. This corresponds to the p<
function. Given the mean and standard deviation
of this function. it is possible to calculate the mean
and standard deviation of q directly.

6

Performance

The algorithm, which I shall call MGSS2, is tested
by playing an Othello program using it against a
st.andard alpha-bet.a search using the same evalua­
tion function. which is a slight improvement over
that used by BILL [Lee and Mahajan. 1988]. Our re­
sults against alpha-bet.a search to depths 2 and 6 are
summarized in table 1. For each search depth. the
time cost function of MGSS• was adjusted to allow
the algorithm to play at least as well as alpha-beta.
In each t.ournament, games were played from differ­
ent randomly-generated starting positions, with the
two algorithms alternately playing black. The pre­
liminary results show a significant improvement over
the original MGss· algorithm. and a distinct advan­
tage over alpha-beta (roughly 60:1 at depth 6).

7

Conclusions

This paper has taken the application of decision­
theoretic metareasoning to game-playing almost to
its logical extreme. The performance improvements

I
I

Table

1:

Summary of results for Othello

over standard algorithms are expected to be quite
dramatic even on a small-branching-factor game
such as Othello. Because of the satisficing nature of
the search value calculations, the technique should
be much more effective on more complex gan1es
such as Go. The formula> are also applicable. with
slight modification. to probabilistic games such as
backgammon, where the branching factor can be in
the thousands.
The current algorithm generates each successor at
random from the set of successors of a node. ClearlY.
a plausible move generator could be applied to mak�
the selection non-random, with the result that the
value of a node would converge much more rapidly to
the value obtained by generating all successors. The
tools used above can provide a quantitative analysis
of the quality of a plausible move generator. and of
its effectiveness in reducing search.
It is to be expected that several of the techniques
shown below will be useful in many other informa­
tion value calculations, and in providing pruning cri­
teria for search algorithms using backing-up meth­
ods other than min/max. The derivation of the irrel­
evance criterion. and the subsequent simplification
of the search value formula. depended mainly on the
monot.onicity of the backing-up function. Since the
backing-up function is supposed to be an expected­
value calculation [Hansson and Mayer. 1989]. any
reasonable such function should not decrease the
value of a parent if one of its successors becomes
more valuable.
The work needed to apply the idea of informa­
tion value to this problem was st.renuous at times.
Beyond the specific application, it is hoped that
some general insights as to the nature of information
value have been obtained. But in complex decision
syst.ems for real-world problems, one cannot. expect
closed-form expressions for information value t.o be
easily obtainable or computable. The value of cer­
tain types of computation can.. however. be learned
empirically by examining the actual i�1provement
in decision quality that results. Wefald and Rus­
sell [1989] have reported on early efforts in this di­
rection. The efficacy of such learning depends on
having a good understanding of what features of the
an understanding
decision situation are relevant
that can only develop from doing grunt-work like
this.
-

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I
I

442
