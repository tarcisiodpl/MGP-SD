

When using Bayesian networks for modelling
the behavior of man-made machinery, it usu­
ally happens that a large part of the model
is deterministic. For such Bayesian networks
the deterministic part of the model can be
represented as a Boolean function, and a cen­
tral part of belief updating reduces to the
task of calculating the number of satisfying
configurations in a Boolean function. In this
paper we explore how advances in the calcu­
lation of Boolean functions can be adopted
for belief updating, in particular within the
context of troubleshooting. We present ex­
perimental results indicating a substantial
speed-up compared to traditional junction
tree propagation.
1

INTRODUCTION

When building a Bayesian network model it frequently
happens that a large part of the model is determinis­
tic. This happens particularly when modelling the be­
havior of man-made machinery. Then the situation is
that we have a deterministic kernel with surrounding
chance variables, and it seems excessive to use stan­
dard junction tree algorithms for belief updating. First
of all, the calculations in the deterministic kernel are
integer calculations and double precision calculations
are unnecessary complex. However, there may be room
for further improvements. If the deterministic part of
the model is represented as a Boolean function, we
may exploit contemporary advances in calculation of
Boolean functions.
A major advance in Boolean calculation is Binary
Decision Diagrams, particularly Reduced Ordered Bi­
nary Decision Diagrams, ROBDDs[Bryant, 1986]. An
ROBDD is a DAG representation of a Boolean func­
tion. The representation is tailored for fast calculation

Uffe Kjcerulff

of values, but the representation can also be used for
fast calculation of the number of satisfying configura­
tions given an instantiation of a subset of the variables.
To be more precise: let B(X) be a Boolean function
over the Boolean variables X, and let Y � X with
X\Y. Define Cards (1)) on a configuration iJ
Z
of y as the number of configurations z over Z such
that B (1j, z)
true( 1). It turns out that given iJ an
ROBDD representation of B can be constructed such
that Cards can be calculated in time linear in the num­
ber of nodes in the ROBDD. However, the number of
nodes in an ROBDD may be exponential in the num­
ber of variables in the domain of the Boolean function.
=

=

In this paper we exploit the ROBDD representation for
propagation through a Boolean kernel in a Bayesian
network, and we illustrate that a central part of this
propagation is to calculate Cards (i)). We use the tech­
nique on models for troubleshooting. These models
are particularly well suited for ROBDD calculation as
the size of the ROBDD is quadratic in the size of the
domain.
In section 2 we illustrate the use of Cards for prob­
·
ability updating in Bayesian networks. Section 3 is
a brief introduction to ROBDDs and in section 4 we
show how to calculate Cards in an ROBDD. Section
5 introduces the troubleshooting task and the type of
Bayesian network models used. In section 6 the de­
terministic kernel of these models is represented as an
ROBDD and it is shown that the size of this represen­
tation is quadratic in the number of Boolean variables.
In section 7 we outline the propagation algorithms for
various troubleshooting tasks, and in section 8 we re­
port on empirical results indicating a substantial speed
up compared to traditional junction tree propagation.
2

TWO MOTIVATING EXAMPLES

To illustrate the special considerations in connection
with Boolean kernels we shall treat a couple of exam-

427

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

3

ples. First consider the situation in Figure 1.

BOOLEAN FUNCTIONS AND
ROBDDS

This section is a survey of classical logic in the context
of binary decision diagrams.
Figure 1: The Boolean variable A has a parent net­
work of proper chance variables and a child network
representing a Boolean function B.
For the situation in Figure 1 we have (U
P (U)

=

=

WUVU{A}):

Q (W,A)I.t B (V,A),

where 1-l = 1/ Lvu{A} B (V,A) is a normalization con­
stant. Assume we have evidence e ew u ev , where
ev is a configuration y of the variables Y � V, then:
=

P(A,e)

1-l

1-l

L
L
w
w

Q(W,ew,A) L B(Z,y,A)
z

If we extend the example s.t. a Boolean variable C E V
has a child network R (T, C) of proper chance variables,
we get ( the normalization constant is omitted) :
P (U) = Q (W,A)B (V,A)R (T,C)
Assume we have evidence e = ew u ev u er, where ev
is a configuration y of the variables Y � V. If er is
empty then R does not contribute, and the calculations
are as for Figure 1. If not, we have:

L
L (L
w

Q(W,ew,A)

·

B (Z,y, A, C)

Z

C

L

)

T

w

(L
L

B (Z,y,A,C

=

y)

Z

+

T

B (Z,y,A, C =n )

Z
=

L Q(W,ew,A)

R (T,e7,C =n )

)

T
·

w

(

CardB(y,A, C = y)

+

Card8(Y,A, C = n

� R (T,er, C
) � R (T,er, C

=

y)

=n )

All operators in propositional logic can be expressed
using only this operator and this can be done s.t. tests
are only performed on unnegated variables.
Definition 1. An If-then-else Normal Form (INF) is
a Boolean function built entirely from the if-then-else
operator and the constants 0 and 1 s.t. all tests are
performed only on variables.

B

R (T,er,C = y )

L
L

Let X --7 Y1, Y2 denote the if-then-else operator. Then
X --7 Y1 , Y2 is true if either X and Y, are true or X is
false and Y2 is true; the variable X is said to be the
test expression. More formally we have:

Consider the Boolean function B and let B[X H 0]
denote the Boolean function produced by substituting
0 for X in B. The Shannon expansion of B w.r.t. X is
defined as:

R (T,e7, C)

L Q (W,ew,A)·

=

A truth assignment to a Boolean function B is the
same as fixing a set of variables in the domain of B,
i.e., if X is a Boolean variable in the domain of B, then
X can be assigned either 0 or 1 ( denoted [X H 0] and
[X H 1], respectively) .
A Boolean function is said to be a tautology if it yields
true for all truth assignments, and it is satisfiable if it
yields true for at least one truth assignment.

Q(W,ew,A)CardB (y,A),

As the example illustrates, an efficient procedure for
calculating CardB is central for probability updating.

P(A,e) =

The classical calculus for dealing with truth assign­
ments consists of Boolean variables, the constants true
(1) and false (0) and the operators 1\ (conjunction),
V (disjunction), -. (negation), =} (implication) and {:::}
(bi-implication). A combination of these entities form
a Boolean function and the set of all Boolean functions
is known as propositional logic.

)

Again, calculation of Card8 is part of belief updating.

=:

X -t B [(<

H

1], B [X H 0]

From the Shannon expansion we get that any Boolean
function can be expressed in INF by iteratively using
the above substitution scheme on B.
By applying the Shannon expansion to a Boolean func­
tion B w.r.t. an ordering of all the variables in the do­
main of B we get a set of if-then-else expressions which
can be represented as a binary decision tree. The de­
cision tree may contain identical substructures and by
"collapsing" such substructures we get a binary deci­
sion diagram ( BDD) which is a directed acyclic graph.
The ordering of the variables, corresponding to the
order in which the Shannon expansion is performed,

428

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS

is encoded in the BDD hence, we say that the BDD
is an ordered binary decision diagram (OBDD); the
variables occur in the same order on all paths from the
root. If all redundant tests are removed in an OBDD
it is said to be reduced and we have a reduced ordered
binary decision diagram (ROBDD).
Definition 2. A reduced ordered binary decision di­
agram {ROBDD) is a rooted, directed acyclic graph
with
•

•

•

•

ROBDD. The algorithm basically propagates a num­
ber (2 n , where n is the number of distinct variables
in the corresponding Boolean function) from the root
of the ROBDD to the terminal node. The value sent
from a node (including the root) to one of its children
is the value associated with that node divided by 2.
The value associated with a node (except the root) is
the sum of the values sent from its parents (see Fig­
ure 2).

one or two terminal nodes labeled 0 and 1 respec­
tively.
a set of non-terminal nodes of out-degree two with
one outgoing arc labeled 0 and the other 1.
a variable name attached to each non-terminal
node s.t. on all paths from the root to the ter­
minal nodes the variables respect a given linear
ordering.
no two nodes have isomorphic subgraphs.

We will use Eo to denote the set of 0-arcs (drawn as
dashed arcs) and £ 1 to denote the set of l-ares (drawn
as solid arcs).
Theorem 1 ([Bryant, 1986]). For any Boolean
function f : {0,l}n --7 {0,1} there is exactly one
ROBDD B with variables X, < X2 <
< Xn
s.t. B[X, H b1 ,X2 H b2, ... ,Xn H bnJ
f (b1,b2,... ,bn), \i (b1,b2,... ,bn) E {0,l}n.
·

Figure 2: There are 3 satisfying configurations for
the Boolean function "Exactly one variable among
A 1, A 2, A 3 is true" represented by this ROBDD.
Definition 3. Let B = (U,£) be an ROBDD. Propa­
gation in B is the computation of v (u), where u E U
and v : U --7 lR is defined as:

· ·

From Theorem 1 we have that in order to calculate
the number of satisfying configurations in a Boolean
function B we can produce an ROBDD equivalent to
B and then count in this structure.
In the remainder of this paper we assume that an
ROBDD has exactly one terminal node labeled 1, as we
are only interested in the number of satisfying configu­
rations; in this situation we allow non-terminal nodes
with out-degree one. Additionally, we will use the term
"nodes" in the context of ROBDDs and "variables"
when referring to a Boolean function or a Bayesian
network(BN); nodes and variables will be denoted with
lower case letters and upper case letters, respectively
(the nodes representing a variable Xi will each be de­
noted Xi if this does not cause any confusion).
4

2000

CALCULATION OF CARDB
USING ROBDDS

Given an ROBDD representation of a Boolean func­
tion B, the number of satisfying configurations can be
calculated in time linear in the number of nodes in the

•

•

v (r) 2 n , where r is the root in B and n is the
number of distinct variables in B.
LpEnd' v(p) , where nu repre\iu E U\{r}: v (u)
=

=

sents the set of parents for u in B.

So, in order to determine Cards for some Boolean
function B (U) we only need one propagation in the
corresponding ROBDD since Cards
v (l). In case
evidence y has been received on the variables Y � U
we simply modify the algorithm s.t. configurations, in­
consistent with y, does not contribute to the propaga­
tion, i.e., given a configuration y the function v (u)y is
defined as:
=

\iu E U\{r}.. v (u)y

_
-

LvEna v(p)y ,
2

where nR = {p E nul[p (j. Yl or [y(p) = i and (p, u) E
£i]}; y(p) is the state ofp E Y under y and v (r) 2n,
n being the number of distinct variables in B including
those on which evidence has been received. In partic­
ular we have that Cards (i:i) = v (1)y. Notice, that the
structure of the ROBDD is not changed when evidence
is received.
=

The size of the ROBDD has a significant impact on
the performance of the algorithm and the problem of

429

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

identifying a minimal sized ROBDD is NP-complete.
Thus, in the remainder of this paper we shall mainly
focus on troubleshooting models as it turns out that
the structure of such a model ensures that the size of
the corresponding ROBDD is at most quadratic in the
size of the domain.
5

TROUBLESHOOTING

Definition 4. A troubleshooting model is a con­
nected BN T5 =((U =Us U Uc U UA,£), P), where:
•

•

The set Us contains a distinct variable 5 with no
successors, and for each 51 E Us\{5} there exists
a directed path from 51 to 5.
For each variable C EUc there exists an 51 EUs
s.t. C Ens, and nc 0.
=

When troubleshooting a device which is not working
properly we wish to determine the cause of the problem
or find an action sequence repairing the device. At any
time during the process there may be numerous differ­
ent operations that can be performed e.g. a component
can be repaired/replaced or the status of a component
can be investigated. Because such operations can be
expensive and may not result in a functioning device,
it is expedient to determine a sequence of operations
that minimizes the expected cost and (eventually) re­
pairs the device.
[Breese and Heckerman, 1996] presents a method to
myopicly determine such a sequence. The method as­
sumes a BN representing the device in question, and
the BN is assumed to satisfy the following properties.
1. There is only one problem defining variable in the
BN and this variable represents the functional sta­
tus of the device.

2. The device is initially faulty.
3. Exactly one component is malfunctioning causing

the device to be faulty (single fault).
A central task of troubleshooting, within the frame­
work of [Breese and Heckerman, 1996], is the calcula­
tion of Pi =P( C i =faulty!e) which denotes the prob­
ability that component ci is the cause of the problem
given evidence e. So we are looking for a way to exploit
the logical structure of the model when calculating the
probabilities Pi· As such a scheme is strongly depen­
dent on the structure of the troubleshooting model we
give a syntactical definition of this concept. The def­
inition is based on BNs: a BN consists of a directed
acyclic graph G =(U, £) and a joint probability dis­
tribution P(U), where U is a set of variables and £ is
a set of edges connecting the variables in U; we use
sp(X) to denote the state space for a variable X E U.
The joint probability distribution P(U) factorizes over
U s.t. :

P(U)

=

•

•

•

For each variable A EUA there does not exist an
X EU s.t. A E nx.
sp(X) ={ok, �ok}, VX EUs U Uc.
For each X E Us: P(xly) =1 or P(xly)
sp(X) and Vy E sp(nx).

=

0, Vx E

The variable 5 is termed the problem defining variable
and the variables Us are termed system variables. The
variables Uc (termed cause variables) represent the set
of components which can be repaired, and the vari­
ables in UA (termed action variables) represent user
performable operations such as observations and sys­
tem repairing actions; notice that UA is not part of
the actual system specification. In the remainder of
this paper we shall extend the single fault assump­
tion to include the system variables also. That is, if
a system variable 5i is faulty, then there exists ex­
actly one variable X E ns, which is faulty also (see
[Skaanning et al., 1999] for further discussion of this
extension and how the single fault assumption can be
enforced using so-called "constraint variables" ).
Figure 3 depicts a troubleshooting model, where A is
an action variable and 5 represents the problem defin­
ing variable. The variables 51 ,5z,53 and 54 repre­
sent subsystems, which should be read as: the sys­
tem 5 can be decomposed into two subsystems 51 and
5z, and subsystem 51 can be decomposed into 53 and
54. Component C 1 can cause either 53 or 54 to fail,
whereas C z can cause either 5z or 54 to fail (neither
C 1 nor C z can cause two subsystems to fail simultane­
ously). Notice that A is not part of the actual system
model.

IJ P(XInx),

XEU

where nx is the parents of X in G. The set of con­
ditional probability distributions factorizing P(U) ac­
cording to G is denoted P.

Figure 3: A troubleshooting model with five system
variables, two cause variables and one action variable.

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

430

From assumption (2) and (3) we have that:

P(C1 =y, e)
=P(C1 =1J, Cz =n, . . . , Cm =n, e)
m
= P(C1 =y)
P(Ci n)
i=2
�-tB(C1 = y, Cz n, .. . , Cm =n, Us, e)

II

=

.L_

=

Us

II P(Ci

=

i=2

n ) �-tCard s (C1 = y, e),
•

where B(Us, Uc) is a Boolean function (specified in the
following section) and J.t is a normalization constant.
Now, P(C11el = P(C1, e)/P(e) and P(e) is given by:

m

.[_ IJ P(Cd!-!B(C1, ··· , Cm, S, S, . . . , Sn, el
u

i=1

In the remainder of this paper we omit the normaliza­
tion constant.
6

•

m

= P(C1 =y)

P(e) =

(and only one) of its subsystems (Sc) is faulty (if a
cause is not present we can not say anything about its
subsystems). M says that there can be either zero or
at most one cause present (consistent with the system
state). B(U) is the Boolean function representing the
system as a whole. Note that:

ROBDDS AS
TROUBLESHOOTING MODELS

•

The Boolean function is a list of expressions for
local constraints and it can therefore be built in
an incremental fashion.
The Boolean function can easily be modified to
represent any logical relation between the compo­
nents.
The expression ensures the single fault assump­
tion based on the structure of the model, i.e., it is
not necessary to introduce "constraint variables" .

Example 1. The Boolean function representing the
troubleshooting model depicted in Figure 3 is specified
by B:

((SA(S1 l3l Sz)) V (�SA--,51--,Sz))
B1A((S1A(S3 l3l S4)) V (�S1A�s3�S4))

In what follows we shall assume single fault and use
the truth values 1 and 0 to denote the state of a com­
ponent/subsystem (1 indicates a fault).

B3A(Cz:::} (Sz!Zl S4))
84A((SA(C1 IZl Cz)) V (�SA�C1A�Cz))

Now, let nsi be the subsystems which immediately
compose Si E Us and let Sc � Us be the subsys­
tems that component C E Uc can cause to fail; Sc
is the immediate successors of C. The Boolean func­
tion representing the logical kernel of a troubleshoot­
ing model TS =((Us UUc UUA, £), P) is then given by
B(U' =Us UUc):

Given the ordering S, S1, Sz, S3, S4, C1, C2, the
ROBDD corresponding to B is depicted in Figure 4.
Note that all paths from the root S to the terminal
node are consistent with the ordering above.1
D

F(T)

G(C)

(

®

TA

) (

s' v �rA

S'EnT

Q9 T

C=}

1\

�s'

S'EnT

TESc

M

( ® ) (
( f\ ) ( f\
c

sA

v

�sA

CEUc

B(U')

F(T) A

TEUs

1\
CEUc

�c

)

)

)

G(C) AM,

CEUc

where ® �=1 xi denotes an exclusive-or between the
variables {X1, . . . , Xn}. F(T) specifies that if the sys­
tem Tis malfunctioning then one (and only) of its sub­
systems is faulty, and if the system is functioning prop­
erly then all of its subsystems are functioning properly
also. G(C) states that if a cause is present then one

Figure 4: An ROBDD representation of the trou­
bleshooting model depicted in Figure 3.
1The ROBDD was generated by the software tool
http:/ fwww.cs.auc.dk/�behrmann/iben/.

iben,

431

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

Now, as indicated in Section 3, the size of the ROBDD
is dependent on the ordering of the variables. So we
are looking for a general "rule of ordering" producing
ROBDDs of "small" size.
Consider an ordering of the variables where each sys­
tem variable occurs before all the variables repre­
senting its subsystems, and where all the cause vari­
ables occur last in the ordering. By constructing the
ROBDD according to this ordering we get the node
representing the problem defining variable as root and
the nodes representing the cause variables at the bot­
tom (see Figure 4). Moreover, we get an upper bound
on the size of the ROBDD as stated in the following
theorem; note that the action variables are not part of
the logical kernel.
Theorem 2. Let TS=((U =UAUUsUUc,£), P) be a
troubleshooting model. Then the size of the ROBDD,
representing the Boolean function B(Us U Uc), is
O(IUsi2+1Ucl2), if the ordering a: UsUUc H IUsUUcl
satisfies:
•

•

VX E Us: a(X) < a(Y) for each Y E nx.
VZ E Uc there does not exist an X
a(Z) < a(X).

E

Us s.t.

Proof. Assume an indexing of the layers in the
ROBDD s.t. the layers containing the root node and
the terminal node have index 1 and IUs U Ucl + 1, re­
spectively; a layer is the set of nodes representing a
distinct variable.
Now, consider the layers consisting of system nodes
but no cause nodes. The number of nodes in the i'th
layer either equals the number of nodes in the i'th - 1
layer or it has exactly one more node than the i'th- 1
layer. This is the same as saying that at most one
node in the i'th- 1 layer branches in two; if two differ­
ent nodes in a layer branched into two we would have
two distinct paths from a node at a higher level to
these nodes however, this contradicts the single-fault
assumption due to the ordering of the nodes. Thus,
the number of nodes in the layers containing system
1
nodes is at most L. �Z::11 i= IUs l{l�s I+ 1.
For the cause nodes, there can be at most one distinct
path for each of their possible configurations. This
means that the number of nodes in the layers contain­
ing cause nodes is at most IUcl('�cl) = 1Ucl2. Hence,
D
the size of the ROBDD is O(IUsl2 + IUcl2).
In the ROBDDs, we have an all-false path from the
root to the terminal node. Indeed the Boolean function
is true when the model has no fault. However, we can
force S to be true (faulty) to avoid this path.

7

PROPAG ATION USING ROBDDS

For our context, we need to compute the number of
satisfying configurations for each instantiation of the
cause variables (see Section 5). Now, if we order the
variables as described in Theorem 2 we get an ROBDD
where the nodes representing the cause variables are
the nodes closest to the terminal node. This means
that after one propagation we can determine all the
values needed, i.e., the number of configurations con­
sistent with ci=1J and evidence e is given by:

CardB(C=y,e)=

c· )
" v(#\ie'
­

L

CtECt

2

where Ci is the set of nodes Ci with an outgoing 1-arc
and # li is the number of arcs on the path li from the
Ci in question to the terminal node; the single-fault
assumption ensures that there exist exactly one path
from each Ci to the terminal node which include the
1-arc emanating from Ci.
However, this scheme does not take user performable
operations (i.e. UA) into account, and in the follow­
ing section we extend the algorithm to include such
scenarios.
7.1

Inserting evidence

After an action has been performed we may gain new
knowledge about the system. This knowledge is incor­
porated into the model by instantiating the appropri­
ate variable. If either a system variable or a cause vari­
able is instantiated we can use the method described in
Section 4. So, let A E UA be a binary variable associ­
ated with a proper conditional probability distribution
P(AISi) and assume that A= y is observed. In order
to take the state of A into consideration we get:

P(C1 =y, A=y)
=P(Cl =1J,Cz=n, ... ,Cm=n, A=y)
=P(C1 =y) IT P(Ci=n) L (P(A=yiSd
Us
B(C1 =y, Cz=n, ... , Cm =n,Us))
By expanding the sum in the above equation we get:

L P(A=yiSi)B(Cl =y, Cz=n, ... , Cm= n,Us)
Us
=P(A=yiSi=y)CardB(C1 =y, Si=y)
+P(A=yiSi=n)CardB(Cl =1J,Si=n)
(1)

Thus, with one piece of evidence we can retrieve the
probabilities with two propagations. However, if we
have a set of actions u;,._ � UA with parents u;, �Us

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

432

we need to count the number of satisfying configura­
tions consistent with each configuration of U$. So, by
using the above approach, the number of times we need
to count is exponential in the number of variables on
which evidence has been received.
In what follows we will consider a different algorithm,
where all values can be found after one propagation.
Initially we assume that evidence has been received on
exactly one variable, but the algorithm can easily be
generalized to any number of variables.
In order to prove the soundness of the algorithm
we will use the following notation. If B is an
ROBDD with root r, then l;_
{ v i r = v1, . . . , V;_ =
vis a directed path in B} is termed the i'th layer of
B; the layers l1 and ln+ 1 contain the root node and
the terminal node, respectively. So, given a Boolean
function over the variables U = {X1 , Xz, . . . , X n} (or­
dered by index), the corresponding ROBDD can be
1
specified as B =(Us = U��1 lk, £ = £1 U £o); assum­
ing that the variable X;_ is represented by the layer
l_; . Now, let f : sp(W) -t IR be a function where
W ={Xi, . . . , Xi} � U, and assume that the variables
are ordered by index. We define the following parti­
1
tioning of B =(Us = u�;;1 lk, £) w.r.t. f:
=

•

•

•

The root part of B w.r.t. f is given by BT =
1
(Uf3, £f3), where Uf3 = u�: 1lk.
The conditioning part of B w.r.t. f is given by
lk.
Be =(U� , £�), where U� =

ul=i

The terminal part of B w.r.t. f is given by Bt =
1
(U�, £�), where U� = u�,:i +1lk.

For ease of exposition, we shall in the remainder of this
section assume that no evidence has been received on
any variable in Us UUc; the results presented can easily
be generalized to this situation also.
Algorithm 1. Let B =(U = U�11li, £ £1 U £o) be
an ROBDD corresponding to a Boolean function over
the variables U = {X1 , Xz, . . . , Xn}, and assume that
the variables are ordered by index. Let f : sp(W) -t IR
be a function with W � U and let Q =W\{Xj}, where
X i E W is the variable with highest index.
=

i) Propagate from the root to the terminal nodes in
the root part of B.
ii) Use the values obtained in step (i) to perform a
propagation in the conditioning part of B, i. e. , for
each q E sp( Q) :
a) Propagate to layer li.
b) If there exists an arc (p, u) E Ci from a node
p E lj to a node u E li +1 add the value
to the value ofu.

c(ii.X;=;i)v(p)q)

iii) Use the values obtained in step (ii) to propagate
in st.

Note, that the number of variables in the domain off
determines the number of iterations performed by the
algorithm. In particular, if IWI = 1 we only need one
iteration.
Theorem 3. Let B = (U = U �1 li, £ = £1 U£o) be
an ROBDD and let f : sp(W) -t IR be a function where
W � U. If Algorithm 1 is invoked on B, then:

1

v(l)

=

L f(w)Cards(w)

wEsp(W)

Proof. Let Q =W\{Xj}, where X i E W is the variable
i
with highest index. Let q E sp( Q) and let n�q, ) =
{p E nuiP f/. W or (p, u) E £;_}. Then 'v'u E li+ we
have:

1

LqEsp(Q)

v(u)

LqEsp(Q)

(L.bE{0,1},pEn�<i.b l v(p)qf(q, bl)
2

(L.bE{O,l},pEn�'l.bl v(p) (q,b f(q, bl)
)

2
LwEsp(W) (L.vEn� v(p)wf(wl)
2
f
)
(
LwEsp{Wl w LvEn� v(p)w
2
L f(w)v(u)w
wEsp(W)

=
=

t 1 :
Let u E lt, for l > j + 1. Suppose that 'v'p E lv(p) = LwEsp(W) f(w)v(P lw · Then:
v(p) LvEnu LwEsp(W) f(w)v(p)w
=
v(u) LvEnu
2
2
=

In particular we have that for l =n + 1:

v( 1)

LwEsp(W) f(w) LvEnu v(p)w
2

L f(w)Card8(w)
wEsp(W)
Thereby completing the proof.

D

By performing induction in the number of operations
the algorithm can easily be extended to handle multi­
ple functions, assuming that the variables in the do­
main of the functions do not overlap; the variables in
the domain of two functions f and g are said to over­
lap w.r.t. the ordering a if a(Xd < a(X k ) < a(Xj ),
where xk is a variable in the domain of g, and xi and
Xi are the variables in the domain of f with lowest
and highest index, respectively. If the variables of two
functions overlap we can multiply these functions and
consider the resulting function.

433

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

Example 2. Consider the troubleshooting model de­
picted in Figure 3, and assume that action A E UA
is associated with the conditional probability distribu­
tion specified in Table 1; nA = {5z, 54}.

B'

B'

C0

(0.

'•

...

,,

Table 1:
The conditional probability function
P(AI5z, 54).
Sz
Sz

=
=

0.6
0.4

0.3
0.2

1
0

�&
0.4. 2

The ROBDD corresponding to this specification is de­
picted in Figure 4. In the naive approach, if A = y is
observed, we perform three propagations to the termi­
nal node (one propagation for each configuration of 5z
and 54 except for (5z
1 , 54
1 ) due to the single
fault assumption). The resulting counts are weighted
with the appropriate values and then added (see equa­
tion 1): 0 0.3 + 4 0.2 + 1 0.4 + 1 0.6 = 1.8.
=

·

·

=

·

·

When using algorithm 1 we start off by propagating to
the layer l3 (the nodes representing 5z); after propa­
gation, each node in l3 is associated with 25. We then
perform two propagations to the layer ls (the nodes
representing 54); each propagation is conditioned on
the state of 5z, i.e., 1 and 0, respectively. After each
propagation, the resulting value is multiplied with the
appropriate value from the conditional probability ta­
ble and then added to the value associated with its
child. So, the final value can be found with less than
two full propagations (see Figure 5); note that we only
D
perform one propagation in W and in Bt.
Step (ii) of Algorithm 1 can be optimized by start­
ing the iteration with the variable with highest in­
dex, and then iterate in reverse order of their in­
dex. That is, when iterating over the variables
{X1, Xz, . . . , Xt-1, Xt} we can start off by propagat­
ing to the layer containing Xt, for some configuration
of {X1, Xz, . . . , Xt-1}. The values associated with the
nodes Xt-1 can then be used when propagating from
the nodes Xt, for each instance of Xt. The same ap­
plies when considering variables of lower index, i.e.,
we can reuse previous computations. For instance, in
Figure 5 we can use the value from the first iteration
when computing the value 0.2 22 associated with c1
(consistent with (5z = 0, 54 1 ) ).
·

=

8

RESULTS

We have measured the performance of the ROBDD
algorithm by comparing it to the Shafer-Shenoy algo­
rithm [Shafer and Shenoy, 1990] and the Hugin algo­
rithm [Jensen et al., 1990] w.r.t. the number of opera­
tions performed during inference; the number of opera-

2

�

.. ()_
B'

:· .
.

0 4• 2

2

�

_':_.. __

0

·

,.···

- --�r
{a)

8

'Q_......':... �.::. ..... 0..
.

..

.

0 6•2 2

··8

i

.8"

•..··

(bl

Figure 5: Figure (a) depicts the ROBDD after propa­
gation w.r.t. the configuration (5z = 0, 54 = 0). Fig­
ure (b) depicts the ROBDD after the full propagation;
no propagation is performed w.r.t. (Sz
1, 54
1)
due to the single fault assumption.
=

=

tions refers to the number of additions, multiplications
and divisions.
The tests were performed on 225 randomly generated
troubleshooting models (see Definition 4) which dif­
fered in the number of system variables, cause vari­
ables and action variables; the total number of vari­
ables varied from 21 to 322 and for a fixed set of vari­
ables 15 different troubleshooting models were gener­
ated. As the single fault assumption is not ensured in
the troubleshooting models we augmented these mod­
els with constraint variables when using the Hugin al­
gorithm and the Shafer-Shenoy algorithm (the single
fault assumption is naturally ensured in the ROBDD
architecture). Finally, evidence were inserted on the
problem defining variable and on the constraint vari­
ables.
Figure 6 show plots of the number of operations per­
formed as a function of the number of variables in the
models. Note that we use a logarithmic scale on the
y-axis and that the numbers on the x-axis do not rep­
resent the actual number of variables in the models.
The plots show that, w.r.t. the number of operations,
propagation using ROBDDs is considerably more ef­
ficient than both Shafer-Shenoy and Hugin propaga­
tion. Moreover, as indicated in Section 6, the tradi­
tional tradeoff between time and space is less apparent
in the ROBDD architecture, as the space complexity
is O(IUcl2 + IUsl2 ).
It should be noted that the tests were designed to

434

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

""�

20000

I

�
..

ll�

I

•

I

I

I

I

I

1

I

I

1

�

K

10000

I

1000

�

100

•
20

100

I
..
Variable�

1<0

Variable•
Sluorer-Sheuoy

Figure 6: A plot of the number of operations per­
formed by Hugin, Shafer-Shenoy and ROBDD prop­
agation as a function of the number of variables in
randomly generated troubleshooting models (logarith­
mic scale).
compare ROBDD propagation with Shafer-Shenoy and
Hugin propagation, and they should not be seen as a
comparison of Shafer-Shenoy propagation and Hugin
propagation. In particular, we have only considered
troubleshooting models and not Bayesian networks in
general.
The efficiency of the ROBDD architecture is partly
based on the single fault assumption. However, this
assumption can also be exploited in certain trou­
bleshooting models by compiling the original model
TS=((Us UUc UUA,£), P) into a secondary Bayesian
network BN ((UA U{CU
} {S,} £'),P'), where Cis a
variable having a state for each cause variable in the
original model together with a state representing the
situation where no fault is present. S is a problem
defining variable having Cas parent, and UA is the set
of action variables in the original model each having C
as parent. We have compared the ROBDD architec­
ture with this approach using the randomly generated
troubleshooting models from the previous tests (see
Figure 7).
=

By using this secondary representation the speed-up
is less apparent. However, if we allow multiple faults
then this representation can not be used. Moreover,
a troubleshooting model allowing multiple faults will
in general not be simpler than a model with no con­
straints on the number of faults. In the case of ROB­
DDs, assume that the single fault assumption still ap­
plies to the system variables and consider the case
where exactly m components can fail simultaneously;
m is generally "small" . In this situation the number
of nodes in the layers containing system nodes does
not change but the number of nodes in the layers con­
taining cause nodes do: there can be a distinct path
for each configuration of the cause nodes so the num-

Figure 7: A plot of the number of operations per­
formed by ROBDD propagation and Hugin propaga­
tion with a single cause node.
ber of nodes in the layers containing cause nodes is
at most IUcl(l�1). Hence the size of the ROBBD is
O(IUsl2 + IUcl(l�1)); note that in an ROBDD there
does not exist two nodes having isomorphic subgraphs
so the size of the ROBDD is usually much smaller.
Now, as the complexity of propagation in an ROBDD
is linear in its size, the maximum number of operations
performed for m = 2 increases by a factor of n2l ; with
m faults the maximum number of operations increases
i. This corresponds to adding a
by a factor of
constant value to the ROBDD plots in Figure 6 since
we use a logarithmic scale on the y-axis.

n��!=

Furthermore, if we redefine the m-faults assump­
tion to cover at most m faults then the number of
nodes in the layers containing cause nodes is at most
IUcl L�l euicl). Again, it should be noticed that the
actual number of nodes is usually significantly smaller
as isomorphic subgraphs are collapsed.
In case m-faults is extended to include system vari­
ables also, it can be shown that the variables can be
ordered s.t. the number of nodes in the layers contain­
ing system nodes is exponential in m but quadratic in
the number of system variables if m � maxsEUs Ins/
(see Figure 8).
Finally, as the single fault assumption no longer ap­
plies, the number of configurations consistent with
Ct =y and evidence y is given by:
Cards(Ct =y , y)

=

v(c· )-

L 2#\iy,
Ci ECi li E.Ci
�
L

where Ct is the set of nodes Ct with an outgoing 1-arc,
Lt is the set of distinct paths from the Ct in question
to the terminal node and # lt is the number of arcs on
such a path.
Having multiple faults also supports other frame-

UNCERTAINTY IN ARTIFICIAL INTELLIGENCE PROCEEDINGS 2000

435

be ordered s.t. the size of the ROBDD is quadratic in
the size of the domain.

20

40
.so
60
70
Numb:rof•y..emvuiable•inlhed.omaoll

Figure 8: The number of nodes in the layers containing
system nodes as a function of the number of system
variables.
works
like
[de Kleer and Williams, 1987]
and
[Williams and Nayak, 1996]. For instance, in cir­
cuit diagnosis [de Kleer and Williams, 1987] uses a
logical model of the system to be diagnosed and
determines the next action based on expected Shan­
non entropy. To calculate the expected Shannon
entropy they require the conditional probability of
a set of failed components (termed a candidate in
[de Kleer and Williams, 1987]) given some observa­
tion. As their framework does not yield an easy way to
obtain this probability they use an approximation. In
our framework the logical circuits can be represented
as ROBDDs which makes the necessary probabilities
easily available.
So far we have not established a practical upper
bound on the size of ROBDDs with m faults, but
all the examples we have worked with until now have
been of a "small" size. Moreover, several heuristic
methods have been devised for finding a good order­
ing of the variables (see e.g. [Malik et al., 1988] and
(Fujita et al., 1988]).
9

CONCLUSION

When modelling the behavior of man-made machinery
using Bayesian networks it frequently happens that a
large part of the model is deterministic. In this pa­
per we have reduced the task of belief updating in
the deterministic part of such models to the task of
calculating the number of configurations satisfying a
Boolean function. In particular, we have exploited
that a Boolean function can be represented by an
ROBDD, and in this particular framework the number
of satisfying configurations can be calculated in time
linear in the size of the ROBDD.
The use of ROBDDs for belief updating was exempli­
fied in the context of troubleshooting, which is partic­
ular well-suited as it was shown that the variables can

The performance of ROBDD propagation was com­
pared with Shafer-Shenoy and Hugin propagation us­
ing randomly generated troubleshooting models. The
results showed a substantial speed-up and it was
argued that the single-fault assumption, underlying
troubleshooting models, can be weakened without sig­
nificantly affecting the performance of the algorithm
in case the number of faults is "small" .
