

explored by Breese, Beckerman and Kadie

(1998),

have not relied on the order in which users express
We treat collaborative filtering as a univari­
ate time series problem: given a user's previ­
ous votes, predict the next vote. We describe
two families of methods for transforming data
to encode time order in ways amenable to
off-the-shelf classification and density estima­
tion tools. Using a decision-tree learning tool
and two real-world data sets, we compare the
results of these approaches to the results of
collaborative filtering without ordering infor­
mation.

The improvements in both predic­

tive accuracy and in recommendation quality
that we realize advocate the use of predictive
algorithms exploiting the temporal order of
data.

their preferences.

Vector-space methods draw heav­

ily on work in the information retrieval literature (see,
e.g., Baeza-Yates and Ribeiro-Neto,

1999),

where in­

dividual documents are treated as a "bag of words".
Likewise, probabilistic techniques (e.g. Hofmann and
Puzicha,

1999

and Beckerman,

Rounthwaite and Kadie,

2000)

Chickering,

Meek,

have computed proba­

bility distributions over recommendations conditioned
on the entire vote history without regard to time or­
der. In the CF literature, a "bag of votes" (i.e. atem­
poral) assumption prevails, and the collaborative fil­
tering problem is cast as classification (with classes
"relevant" and "irrelevant") or density estimation (of
the probability that a document is relevant, given a
user's votes).
We instead consider collaborative filtering as a univari­

Keywords: Dependency networks, probabilistic deci­
sion trees, language models, collaborative filtering, rec­
ommendation systems.

1

Introduction

The collaborative filtering problem arose in response
to the availability of large volumes of information to
a variety of users. Such information delivery mecha­
nisms as

Usenet and

online catalogs have created large

stores of data, and it has become the users' task to dis­
cover the most relevant items in those stores. Rather
than requiring that users manually sift through the
full space of available items, trusting that authors
respect the available system of topics, CF tools rec­
ommend items of immediate or future interest based
on all users' expressed preferences ("votes"), suggest­
ing those items of interest to other users with similar
tastes.

These votes may be either explicit, as in re­

sponse to a direct inquiry, or implicit, as by the choice
to follow one hyperlink instead of others.
In general, algorithms for the CF task, such as those

ate time series prediction problem, and represent the
time order of a user's votes explicitly when learning a
recommendation model. Further, we encode time or­
der by transforming the data in such a way that stan­
dard atemporallearning algorithms can be applied di­
rectly to the problem. Other authors (cf. Mozer,

1993)

have applied atemporal learning techniques to tempo­
ral data; we describe here two successful generic tech­
niques. As a result, researchers can simply transform
their data as we describe and apply existing tools, in­
stead of having to re-implement various collaborative
filtering algorithms for awareness of vote order. Our
approach allows CF models to encode changes in a
user's preferences over time. It also allows models to
represent (indirectly) structure built into the feature
space that would be lost in a bag of votes representa­
tion. For example, Web page viewing histories ordered
by page request can express the link structure of a Web
site because a user is most likely to follow links from
his current page. Similarly, television viewing histories
encode the weekly schedule of shows: a viewer cannot
hop from

Buffy

the

Vampire Slayer to Dawson's ·Creek

if the two are not contemporaneous.

ZIMDARS ET AL.

UAI2001

For simplicity, we assume for the remainder of this
paper that user preferences are expressed as implicit
votes (see, e.g., Breese et al., 1998). That is, a users'
vote history is a list of items that the user preferred,
as opposed to an explicit ranking of the items. In a
movie domain, for example, this means that a user's
vote history is simply a list of movies that he watched,
and we assume that he preferred those movies to the
ones he did not watch. We note, however, that the
transformations we describe are easily generalized to
explicit voting.
In Section 2, we present two methods for transform­
ing user vote histories that encode time-order infor­
mation in ways that traditional atemporal modeling
algorithms can use. In Section 3, we discuss three
candidate models that can be learned from standard
algorithms applied to the transformed data. In Sec­
tion 4, we describe the data sets and criteria by which
we will compare our approaches, and in Section 5 we
present our experimental results from using decision­
tree learning algorithms.

581

age, and G is a binary variable that denotes the per­
son's gender. Under the iid assumption a learning al­
gorithm can use observed values of S, A, and G for
other people in the population to estimate the distri­
bution p(SIA, G), then make a prediction about the
particular person of interest with that distribution.
In the following sections, we describe how data that
contains vote histories can be transformed, using var­
ious assumptions, into the case representation so that
standard machine-learning algorithms can be used to
predict the next vote in a sequence. First, we need
some notation.
We use item to denote an entity for which users ex­
press preferences by voting, and we use 1 to denote
the total number of such items.

For example, in a

scenario, 1 is the total num­
ber of movies considered by the collaborative-filtering
system. For simplicity we refer to each item by a one­
based integer index. That is, the items in the system
are mapped to the indices:
movie-recommendation

{1, ...,1'}
2

Data Transformations

In this section, we describe two methods that trans­
form time-ordered vote histories into a representation
that traditional atemporal modeling algorithms can
use; we call this representation the case representation.
In the case representation, the data D consists of a set
of cases (or records) {C1, ... ,Cm}, where each case
Ci = { x1, .., Xn} consists of a value for zero or more
of the variables in the domain X = {X1, . . , Xn}.
.

.

The important (sometimes implicit) assumption of
modeling algorithms that use the case representation
is that the observed cases are independent and identi­
cally distributed (iid) from some joint probability dis­
tribution p(X1, ... , Xn)1; an equivalent Bayesian as­
sumption is that the cases are infinitely exchangeable,
meaning that any permutation of a set of cases has
the same probability. The learning algorithms use the
observed case values in D to identify various models
of the generative distribution.
As an example, consider the problem of predicting
whether or not a particular person will watch some
television show based on that person's age and gen­
der. Using the case representation, we might assume
that all people are drawn from some joint probability
distribution p( S,A, G), where S is a binary variable
that indicates whether or not a person watches the
show, A is a continuous variable denoting a person's
1In fact, if we are interested in learning a conditional

model for Y C X, we often need only assume that the

values for the variables in Y are independent samples from
some p(YIX \ Y)

We use Vi to denote the i1h vote history (i.e. user's
votes). In particular, Vi is an ordered list of votes:
{V/,

.

..

, vt'}

where V/ denotes the item index of the j1h vote in the
list, and Ni is the total number of votes made by user

�.

As an example, suppose there are four movies The Ma­
trix, Star Wars, A Fish Called Wanda and Pulp Fic­
tion having indices 1,2,3 and 4, respectively. Suppose
there are two movie watchers in the domain: User 1
watched The Matrix and then watched Pulp Fiction,
and user 2 watched Star Wars, then watched Pulp Fic­
tion, and then watched The Matrix. Then we would
have V1 = {1,4} and V2 {2,4, 1}.
=

For each of the transformations below, we show how
convert from a set of vote histories into (1) a set of
domain variables X= {Xl.···,Xn}, and (2) a set of
cases {C1,... , Cm}, where each case Ci contains a set
of values { x1, . , Xn} for the variables in X. We also
describe what assumptions are made in the original
domain in order for the resulting cases to be iid.
to

. .

2.1

The "Bag-of-votes" Transformation

The first transformation we consider disregards the or­
der of previous votes, corresponding to the assumption
that vote order does not help predict the next vote. As
noted above, this "bag-of-votes" approach is the ap­
proach taken by many collaborative-filtering learning
algorithms.

ZIMDARS ET AL.

582

For each item k, where 1 ::; k ::; /, there is a binary
variable Xj E X, whose states x] and x� correspond
to preferred and not preferred, respectively. There are
no other variables in X. For each vote history V;, we
create a single case Ci with the following values: if
item j occurs at least once anywhere in the sequence
vi, then the value Xj in ci is equal to x] . Otherwise,
the value of Xj in Ci is equal to x5 .
The assumption that the cases are iid corresponds to
assuming that the (unordered) votes of all vote histo­
ries (i.e. users) are all drawn from the same distribu­
tion. Under this assumption, we can use an atemporal
learning algorithm with the cases from previous vote
histories learn a model for p(XJIX\XJ) for all XJ EX,
and then use these models to predict the next vote2
for any vote history.
2.2

The Binning Transformation

The second transformation we consider can be help­
ful when user preferences change over time. Although
the transformation does not explicitly use the order
of the votes, it can exploit temporal structure. The
idea is to (1) separate vote histories into bins by their
size, (2) transform the histories from each bin into
the case representation using the "bag-of-votes" trans­
formation described above, and (3) learn a separate
model from the data in each such bin. W hen it comes
time to predict the next vote in a sequence of size k,
we use the model that was learned on the cases derived
from the vote histories in the bin corresponding to k.
Suppose, for example, that we would like to train one
or more models in order to recommend movies to peo­
ple. It might be reasonable to assume that the op­
timal model for predicting the third movie for some­
one may not be a very good model for predicting the
100th movie. W ith binning, we divide up the range of
the number of movies that have previously been seen
into separate bins, and learn a recommendation model
for each. Thus, we might end up with three mod­
els: (1) a simple model that predicts popular movies
for people who do not go to the movies much, (2) a
model that perhaps identifies general viewing prefer­
ences (e.g. comedies) for the typical viewer, and (3) a
model that identifies subtle preference trends for heavy
movie watchers.
In order to perform binning, there are a number of
parameters that need to be set. First, we need to
decide how many bins to use. Second, we need to
decide, for each bin, what history lengths should be
included in that bin.
2

There are some subtleties, addressed below, about how

this prediction is made.

UAI2001

For the experiments that we present in Section 4, we
tried both two and four bins. For each bin, we set a
minimum and maximum value for the length of the
contained histories. We chose this minimum and max­
imum such that the total number of votes in each bin
are roughly the same.
As described above, the binning approach assigns each
vote history to exactly one bin. An alternative ap­
proach, which we call the prefix approach, is to allow
a single vote history to contribute to multiple bins by
adding an appropriate prefix to all of the "previous"
bins. As an example, suppose there are three bins that
accommodate histories of length up to 5, 10, and 100.
In the prefix approach, a vote history of length 90 will
have (1) the first five votes added to the first bin, (2)
the first ten votes added to the second bin, and (3) the
whole history added to the third bin.
The choice of whether or not to use the prefix approach
to binning will depend on user behavior and domain
structure. We identify the following two hypotheses
that can help determine which method is most appro­
priate.
•

The "expert/novice" hypothesis: Users with long
vote histories ("experts" in the domain) have fun­
damentally different preferences than users with
short vote histories ("novices"). As a result, we
expect that omitting prefixes of longer vote histo­
ries from bins for shorter vote histories will result
in better predictive accuracy than the prefix ap­
proach. The expert/novice hypothesis might hold
when predicting preferences for television viewing,
where couch potatoes might have different view­
ing habits than occasional viewers. On a Web site,
heavy users tend to navigate very differently than
"shallow browsers" (cf. Huberman et al., 1998).

•

The "everyone learns" hypothesis: Users with
long vote histories once expressed similar prefer­
ences to users with short vote histories. Under
this hypothesis, we expect that prefixes of long
vote histories will be distributed similarly to short
vote histories, and therefore their inclusion in the
corresponding bins will provide useful data for the
model-building algorithm; as a result, we hope
that the resulting models will be more accurate.
One can also interpret this hypothesis from the
perspective of domain structure constraining user
behavior. For users of a Web portal, initial votes
may be restricted to the home page and top-level
categories linked from that page. For subsequent
page hits, available links may constrain possible
user votes. In this domain, we would expect users
to have similarly-distributed vote prefixes because
site structure does not allow much room for inno-

UA12001

ZIMDARS ET AL.

vation.
For the domains we consider in Section 4, the latter hy­
pothesis seems more appropriate; although we ideally
should have compared the two, in the interest of time
we only used the prefix approach in our experiments.
We chose the bin boundaries so that the total number
of votes of the original (i.e. non-prefix) histories in
each bin were roughly the same.
W hether or not we use the prefix approach, the addi­
tional computational overhead of binning over no bin­
ning is proportional to a constant factor (the number
of bins), because each bin will contain no more votes ,
and no more vote histories, than would a single model
computed using the entire vote set.

Structural aspects of some prediction domains can
make difficult the choice of vote sub-histories to aug­
ment data for binning. Web sites tend to have a hierar­
chical structure with a home page at the root, but the
same cannot be said for television programming sched­
ules, which reflect periodic structure. When predicting
television viewing habits given a "snapshot" of user
viewing histories, prefixes may not reflect the periodic
nature of the program schedule. In such domains, dif­
ferent choices of contiguous vote sub-histories may be
appropriate, but the resulting profusion of data might
render binning impractical.
We should point out that binning can be applied to
collaborative filtering problems in which the temporal
order of the votes is unknown. Although the prefix ap­
proach may not be appropriate, binning based on the
number of votes can potentially lead to significantly
better accuracy in atemporal domains. Consider, for
example, the problem of recommending items in a gro­
cery store based on the products bought (the recom­
mendation may appear as a targeted coupon on a re­
ceipt). It might turn out that, regardless of the order
in which people put groceries in their shopping cart,
the number of items in their cart may indicate very
different shopping behavior; consequently the binning
approach might yield significantly better models than
a system that ignores the number of votes.
2.3

Data Expansion

The final data transformation we consider, which we
call data expansion, finds inspiration in the language
modeling literature (see, e.g., Chen and Goodman,
1996). This method of data expansion distinguishes
the most recent n votes from the entire vote history, as
well as identifying the order of the most recent votes.
All of the variables that we create in the transforma­
tion are binary, and have states x1 and xO correspond
to preferred and not preferred, respectively.

583

In the case representation, we create one binary vari­
able for each of the I items in the domain: xT =
{X[, ... ,X�}. The "T" superscript in X'[ is meant
to indicate that this is a "target variable" that repre­
sents whether or not the next vote is for item k.
The data expansion transformation is parameterized
by a history length l; this parameter, which corre­
sponds to the "n" parameter in an n-gram language
model, determines how far back in the vote history
to look when predicting the next vote. For each in­
teger history 1 � j � l, we again create one bi­
nary _variable for each of the 1 items in the domain:
{X;1, ... ,X_::;-i}. The "-j" superscript in Xf:j is
meant to indicate that this variable represents whether
or not Ph previous vote (from the one we're predicting)
is for item k. We use XL to denote the set of all lagged
variables (e.g. {X!1, . . ,X_::;-1},{X12, .. . ,X;2}).
.

There is a final set of 1 variables consisting of, for
each item, an indicator of whether or not that item
was voted for at least once previously in the given vote
history. We use xc = {Xf, ... , X0} to denote these
variables. In language-modeling p;rlance, these vari­
ables are known as cache variables.
In contrast to the "bag-of-words" approach, where
each vote history was transformed into a single case, in
the data expansion transformation, each vote in every
history _gets a corresponding case. In particular, for
vote V/, which is the lh vote in the ith vote history,
we define the values for all of the variables as follows.
For simplicity, let v = V/. We set the value of target
variable XJ to xl, and we set the value of all other
target variables to xO. For each history variable x-j
k ,
where 1 � j � l, we set the corresponding value to ei­
ther x1 if the lh previous vote in history i has value k,
or xO otherwise. Finally, we set the value of each cache
variable Xf to either xl if item k occurs as a. vote (at
least once) previous to V/ in Vi, or xO otherwise.
We should point out that in order to feasibly learn
a model using the cases that result from the data­
expansion transformation, the learning algorithm(s)
need to use a sparse representation for the cases. See
(e.g.) Chickering and Heckerman (1999) for a discus­
sion.

Consider our movie example again. For simplicity, we
use M, S, F, and P to label all variables we create
corresponding to movie items The Matrix, Star Wars,
A Fish Called Wanda and Pulp Fiction. Furthermore,
we use 1 and 0 to denote the values preferred and not
preferred, respectively.
Suppose we want to transform a vote history con­
taining The Matrix, Pulp Fiction, and Star Wars, in
that order, into the case representation with a history

584

ZIMDARS ET AL.

length of one. First we define the variables

x

=

for this model is expressed as follows:

r r r r
{ M ,s ,F ,P ,
M�1, 8-1, p-1, p-1,
MC ' SC ' pC , pC}

n

P(C

1

shows the case values that

result.
The learning algorithm we use should build a model
for each of the target variables, using all non-target
variables as predictor variables.

That is, we would

like the model to estimate, for each target variable

XJ E XT' the distribution p(XJIXL' xc).

The iid assumption in the case representation-after
performing the data-expansion transformation with
history-length l-implies that each vote is
a distribution that depends on
previous

l

votes and

(2)

(1)

drawn from

the values of the

the presence or absence of at

least one vote for previous items.

v 1 , ... ,vn )

=

P(C

Models

that can be used for collaborative filtering applica­
tions; when learned from data that is transformed as
described in the previous section, these models can
exploit the vote order to improve recommendation ac­
curacy.

Cheeseman and Stutz

1977).

(1995)

(1)

provide details of

In this setting, prediction for collaborative filtering
follows from the density estimation problem, as the
model predict the item(s) most

likely to receive an af­

firmative vote given the user's vote history.

Other latent class models (Hofmann and Puzicha,

1999)

for collaborative filtering

have been proposed

which place user and item on an equal footing. These
permit construction of a two-sided clustering model
with preference values, but they depend on multino­
mial sampling of (user, item) pairs, and as such do not
generalize naturally to new users.

Decision-tree models

v ious work (cf.

Beckerman et al.,

2000)

constructs

a forest of probabilistic decision trees, one for each
item in the database, using a Bayesian scoring crite­
rion (Chickering, Beckerman, and Meek,

1997).

This

provides a compact encoding of conditional probabil­
ities of recommendations, given previous votes.3
use this approach in Section

We

4 to evaluate our data

Memory-based algorithms

Memory-based collaborative filtering algorithms pre­
dict the votes of the active user based on some partial
information about the active user and a set of weights
calculated from the user database. Memory-based al­
gorithms do not provide the probability that the active
user will vote for a particular item. Instead, the active
user's predicted vote an item is a weighted sum of the
votes of the other users. See Breese et. al

(1998) for

a

more detailed discussion.

A

)

=c

i=l

a specific implementation of the learning algorithm.

transformations.

3.2

) IT P(vi I C

The approach that has proven most effective in pre­

In this section, we describe some well-known models

3.1

=c

the EM algorithm (see Dempster, Laird and Rubin,

3.3
3

= c,

The parameters of this model can be learned using

Next, we consider each vote in the history, and create
a case for each one. Table

UAI2001

Cluster models

standard probabilistic model is the naive Bayes

model with a hidden root node-one where the prob­
abilities of votes are conditionally independent given
membership in an unobserved class variable C, where
C ranges over a fairly small set of discrete values. This

corresponds to the intuition that users may be clus­

tered into certain groups expressing common prefer­
ences and tastes.

The joint probability distribution

3.4

Alternative models

The data expansion technique discussed in Section

2.3

suggests the application of language-modeling algo­
rithms to collaborative filtering. We have conducted

limited experiments with variants of n-gram language
models, and the results are promising (although we do
not present them here).
Hidden Markov models
themselves in this setting,

(HMMs)

also

recommend

but in our experience they

are ill-suited to a na"ive representation of the data,

where each possible vote corresponds to exactly one
feature. This reflects in part the number of parame­
ters that must be estimated when running EM for an
HMM: if the model admits
are

me

+

c2

+

c

c

hidden states, then there

parameters to estimate for the poste­

rior probabilities of states, the state transitions, and
3It also permits the construction of a family of graphical
as dependency networks, which have expres­

models known

sive strength similar to Markov networks.

ZIMDARS ET AL.

UAI2001

Table

585

Case values created for the movie example with the data expansion method.

1:

M1
1

Vote

The Matrix
Pulp Fiction
Star Wars

s·l

FJ

p'l

M-1

0
0
0

0
0
1

0

0

0
0

1

1

0

0

s

·1

F-1

p-

0
0
0

0
0
1

0
0
0

1

Me

se

Fe

p--u

0
1
1

0
0

0
0
0

0
0
1

0

Moreover, models are slow to con­

We used probabilistic decision-tree models for our ex­

verge because collaborative filtering data tend to be

periments, and compared both binning and data ex­

very sparse, in that few users vote on ariy one item. As

pansion to the default "bag-of-votes" approach of ig­

the state priors.

a result, evidence for estimating a particular variable

noring the data order.

is rarely presented in training. This sparsity is

we learned a single decision tree per page

integral

For all of the experiments,
to predict

to the collaborative filtering problem, but lethal to ac­

whether the user requests that page, based on the

curate estimation. Finally, HMMs discard much of a

transformed data available at that time.

user's history in making predictions, and our experi­

greedy tree-growing algorithm in conjunction with the

ments indicate that a long history can be informative.

Bayesian score described by Chickering et. al (1997).

We used a

In particular, the score evaluated the posterior model

4

probability using a flat parameter prior, and a model

Experiments

prior of the form r;,f, where

In this section, we describe the experiments we per­
formed to demonstrate that using vote order can im­
prove the accuracy of models.
We conducted our experiments using two real-world
data sets, both of which are Web user traces. In each,

the notion

of

"user" corresponds

to a

server

session,

and a page request was interpreted as an affirmative
vote.
The first data set consists of session traces from
data encompassed

110587

The training

page requests from

27595

users over three days in late August 1999, and the test
data included

54843 requests

from

13563

users on

14

September of the same year. The requests span a to­
tal

of 8420 URLs, roughly 400 of which correspond to
404 errors for invalid URLs. The average length of a
session trace was 4.007 votes, with a median length of
2, and the longest trace was 93 votes.
second

data

set

uses

session

traces from http://www .msnbc. com/, corresponding
to an

80%/20%

split of users on

The training data include roughly
from

22 December 1998.
1.28 million requests
data include 178158

475769 users, while the test
requests from 87714 users . The requests in these two
data sets span 1001 URLs; it is unclear whether any of
these represent invalid URLS. The average length of a
session trace was

2

experiments.

= 0.01 for all of the

In all of the data transformations described in the pre­
vious section, we created a separate binary variable for
each item that denoted whether or not the next vote
will be for that item. Defining the variables this way
can be problematic for any learning algorithm using
finite data that does not enforce the constraint that
the next vote will be for exactly one item. In particu­

http: //research. microsoft. com/.

T he

f is the number of free

parameters in the tree. We used r;,

2.696

and a longest trace of

vote, with a median length of

407 votes.

Unfortunately, we did not identify other publicly­
available data that records user preferences in time or­
der. The authors' experience with other data suggests
that the techniques outlined here may prove fruitful
with other types of sequential data.

lar, the algorithm we used to learn a forest of decision
trees did not enforce this constraint.

We solved this

problem by using the decision trees to calculate the
posterior probability that each item would be the next

vote, then renormalizing.

We applied two evaluation criteria in our experiments.
For all prediction algorithms, we adopted the "CF ac­
curacy" score outlined by Heckerman et a!.

(2000),

and specialized it to compute the CF score with re­
spect to the next item in the user's history only. The
CF accuracy score attempts to measure the probabil­
ity that a user will view a recommendation presented
in a ranked list with other recommendations. To ap­
proximate this probability, let p(k)

=

2-k/a

denote

the probability that the user views the kth item on
his list (where k counts from

0) .

For the experiments

presented here, we chose a half-life of

a

=

10.

We

computed for each user i, and for each vote vii in his
vote history, a ranked list of recommendations given

Vil,

·

·

·,

Vi(j-1)

·

One may compute the CF accuracy of a general list L

of test items spanning n users. Suppose the model rec­

ommends R; items to each user, and the users actually

prefer sets of M; items. Let O;k denote the indicator

586

ZIMDARS ET AL.

UAI2001

that user i prefers the kth recommendation. Then
accuracy CF (L)

=

n

1
- """"
n �
i

'"'R-lJ.

L.. k-o

•kP (k)

'"'M;-1 p (k)

=l L.. k=O

(2)

Let kii be the ranking assigned by our model to vote

Vij. Scoring one vote at a time, CF accuracy simplifies

to

(3)
Baseline

2 Bins

4

Bins

DE·1

DE·3

DE·S

One may compute CF accuracy for any CF algorithm
that generates a ranked list of recommendations, but

Figure

it provides a criterion specific to the collaborative fil­

constructed for the MSNBC domain.

1:

Collaborative filtering scores of the models

tering task. For the probability models we evaluated,
we also computed the mean log-probability assigned
to each of the user's actual votes, given the preced­
ing vote history. (This log-probability was normalized
over all items in dependency-network models to com­
pensate for potential inconsistencies).

Baseline

2 Bins

4 Bins

DE·1

DE·3

DE·S

-4.89
-4.895

Note that CF accuracy is a function of the relative

magnitude of density estimates, while the log score
depends on the absolute magnitude of the estimates.

5

·4.885

-4.9
-4.905
-4.91

Results

-4.915

The results presented below correspond to three fam­
ilies of models.

The "Baseline" results derive from

a forest of decision trees trained on bag-of-votes data,
shown to be a one of the best models for CF (Breese et
al., 1998).

"2

Bins" and "4 Bins" experiments applied

the binning method described in section

2.2.

Two or

four decision trees are constructed for each Web page,

Figure

2:

Log-probability scores of the models con­

structed for the MSNBC domain.

increase as a function of history length.

This might

suggest that Web page requests depend more strongly

but only one is chosen (according to the partial his­

on immediate links than on the short-term history, and

tory at hand) to make a prediction. The "DE-" exper­

that data expansion mainly embodies this structural

iments expand data as in section 2.3, with histories of

element of the Web surfing domain. (One should not

length 1, 3, and 5.

interpret this

Figure 1 and Figure

2

scores,

for all of the models in the

respectively,

show the CF scores and log

MSNBC domain.

as

a Markov assumption; in our expe­

rience, the cache variables strongly influence predic­
tion.)

The higher CF accuracy results suggest that

the relative magnitude of density estimates is more of­

ten accurate for data-expanded models than binned

There are some interesting observations to make about

models, and these relative estimates determine which

these results. F irst, we see that for the collaborative­

pages show up in a recommendation list.

filtering score, the score got worse as we increased the

number of bins. This may be an artifact of the sparsity

of long traces in Web surfing data, a phenomenon that
has been observed elsewhere (e.g., Huberman et al.,
1998). This may not impair work in other domains;

our experience with data suggests that other frequency
functions for user history length can have thicker tails.

Our results show that unlike for the CF score, the bin­
ning approach dominated both the baseline and the
data-expansion models for log-probability predictive
accuracy.

For this score, the data-expansion models

improved as the history length increased, but only the
model with the longest history (five) was competitive
with the baseline model.

We suspect that the data

Second, we see that all of the data-expansion models

were too sparse to permit accurate parameter esti­

performed significantly better than the baseline with

mates for the models learned under data expansion.

respect to CF accuracy, but that performance did not

In particular, there were roughly 50 percent more pa-

ZIMDARS ET AL.

UA12001

587

rameters to train in each of the data-expansion models

the log score. However, binning models do not indicate

than in the other models, which leads us to suspect

a steep fall-off in CF accuracy relative to the baseline,

that the learning algorithm over-fit for these models

as for the MSNBC data set. We hypothesize that typi­

to some degree. In retrospect, we regret the choice of

cal MSR visitors leave longer page traces than MSNBC

a single value of the model-prior parameter "' for all

users.

data transformations. We expect that if we had tuned
this parameter by splitting up the training data and
maximizing a hold-out prediction accuracy, we would
have identified a smaller "'for the data-expansion mod­
els that yielded better results for both criteria on the
tests set. Improvements in log score as history length
increase demonstrate the value of the additional in­
formation encoded by the expanded data, which com­
pensates in part for having too few data points per
parameter.

6

Conclusion

We have presented two techniques for transforming
data that allow the collaborative filtering problem to
be treated as a time-series prediction task.

Both of

these techniques allow state-of-the-art collaborative
filtering methods to model a richer representation of
data when vote sequence information is available. We
have evaluated these techniques, using probabilistic

Figure 3 and Figure

4

show the CF scores and log

scores, respectively, for all of the models in the MSR
domain.

decision-tree models, with two data sets for which the

order of user votes were known. Results indicate mixed
gains for each approach. Binning user data by history
length improved log-probability scores with respect to

0.6

a bag-of-votes model in our test cases, while data ex­
pansion to introduce history variables improved the

0.5

collaborative filtering accuracy score over baseline.

0.4

